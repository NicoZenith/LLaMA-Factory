10: ➤ Node 10 / 32 starting training…
23: ➤ Node 23 / 32 starting training…
12: ➤ Node 12 / 32 starting training…
 9: ➤ Node 9 / 32 starting training…
 7: ➤ Node 7 / 32 starting training…
17: ➤ Node 17 / 32 starting training…
 2: ➤ Node 2 / 32 starting training…
25: ➤ Node 25 / 32 starting training…
 6: ➤ Node 6 / 32 starting training…
 0: ➤ Node 0 / 32 starting training…
11: ➤ Node 11 / 32 starting training…
14: ➤ Node 14 / 32 starting training…
13: ➤ Node 13 / 32 starting training…
 8: ➤ Node 8 / 32 starting training…
30: ➤ Node 30 / 32 starting training…
 3: ➤ Node 3 / 32 starting training…
21: ➤ Node 21 / 32 starting training…
15: ➤ Node 15 / 32 starting training…
16: ➤ Node 16 / 32 starting training…
 1: ➤ Node 1 / 32 starting training…
 5: ➤ Node 5 / 32 starting training…
22: ➤ Node 22 / 32 starting training…
18: ➤ Node 18 / 32 starting training…
20: ➤ Node 20 / 32 starting training…
19: ➤ Node 19 / 32 starting training…
26: ➤ Node 26 / 32 starting training…
27: ➤ Node 27 / 32 starting training…
28: ➤ Node 28 / 32 starting training…
 4: ➤ Node 4 / 32 starting training…
31: ➤ Node 31 / 32 starting training…
29: ➤ Node 29 / 32 starting training…
24: ➤ Node 24 / 32 starting training…
20: [2025-06-27 21:02:30,414] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
17: [2025-06-27 21:02:30,429] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
14: [2025-06-27 21:02:30,429] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
19: [2025-06-27 21:02:30,436] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
 0: [2025-06-27 21:02:30,438] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
15: [2025-06-27 21:02:30,511] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
16: [2025-06-27 21:02:30,513] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
27: [2025-06-27 21:02:30,520] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
 2: [2025-06-27 21:02:30,533] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
20: df: /users/ndeperr/.triton/autotune: No such file or directory
19: df: /users/ndeperr/.triton/autotune: No such file or directory
17: df: /users/ndeperr/.triton/autotune: No such file or directory
14: df: /users/ndeperr/.triton/autotune: No such file or directory
 0: df: /users/ndeperr/.triton/autotune: No such file or directory
12: [2025-06-27 21:02:30,577] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
30: [2025-06-27 21:02:30,591] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
18: [2025-06-27 21:02:30,609] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
22: [2025-06-27 21:02:30,613] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
25: [2025-06-27 21:02:30,614] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
21: [2025-06-27 21:02:30,616] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
15: df: /users/ndeperr/.triton/autotune: No such file or directory
 5: [2025-06-27 21:02:30,624] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
16: df: /users/ndeperr/.triton/autotune: No such file or directory
27: df: /users/ndeperr/.triton/autotune: No such file or directory
 2: df: /users/ndeperr/.triton/autotune: No such file or directory
28: [2025-06-27 21:02:30,648] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
12: df: /users/ndeperr/.triton/autotune: No such file or directory
13: [2025-06-27 21:02:30,683] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
 9: [2025-06-27 21:02:30,692] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
30: df: /users/ndeperr/.triton/autotune: No such file or directory
10: [2025-06-27 21:02:30,699] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
18: df: /users/ndeperr/.triton/autotune: No such file or directory
25: df: /users/ndeperr/.triton/autotune: No such file or directory
21: df: /users/ndeperr/.triton/autotune: No such file or directory
22: df: /users/ndeperr/.triton/autotune: No such file or directory
 5: df: /users/ndeperr/.triton/autotune: No such file or directory
23: [2025-06-27 21:02:30,755] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
28: df: /users/ndeperr/.triton/autotune: No such file or directory
 3: [2025-06-27 21:02:30,779] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
13: df: /users/ndeperr/.triton/autotune: No such file or directory
 9: df: /users/ndeperr/.triton/autotune: No such file or directory
 6: [2025-06-27 21:02:30,805] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
10: df: /users/ndeperr/.triton/autotune: No such file or directory
23: df: /users/ndeperr/.triton/autotune: No such file or directory
 3: df: /users/ndeperr/.triton/autotune: No such file or directory
 6: df: /users/ndeperr/.triton/autotune: No such file or directory
 8: [2025-06-27 21:02:30,950] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
11: [2025-06-27 21:02:31,036] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
 8: df: /users/ndeperr/.triton/autotune: No such file or directory
 1: [2025-06-27 21:02:31,141] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
11: df: /users/ndeperr/.triton/autotune: No such file or directory
 4: [2025-06-27 21:02:31,172] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
 7: [2025-06-27 21:02:31,229] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
31: [2025-06-27 21:02:31,237] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
 1: df: /users/ndeperr/.triton/autotune: No such file or directory
 4: df: /users/ndeperr/.triton/autotune: No such file or directory
 7: df: /users/ndeperr/.triton/autotune: No such file or directory
31: df: /users/ndeperr/.triton/autotune: No such file or directory
26: [2025-06-27 21:02:31,374] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
26: df: /users/ndeperr/.triton/autotune: No such file or directory
24: [2025-06-27 21:02:31,762] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
29: [2025-06-27 21:02:31,770] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
24: df: /users/ndeperr/.triton/autotune: No such file or directory
29: df: /users/ndeperr/.triton/autotune: No such file or directory
17: [INFO|2025-06-27 21:02:36] llamafactory.cli:143 >> Initializing 4 distributed tasks at: nid005574:29500
17: [INFO|2025-06-27 21:02:36] llamafactory.cli:143 >> Multi-node training enabled: num nodes: 32, node rank: 17
19: [INFO|2025-06-27 21:02:36] llamafactory.cli:143 >> Initializing 4 distributed tasks at: nid005574:29500
19: [INFO|2025-06-27 21:02:36] llamafactory.cli:143 >> Multi-node training enabled: num nodes: 32, node rank: 19
 0: [INFO|2025-06-27 21:02:37] llamafactory.cli:143 >> Initializing 4 distributed tasks at: nid005574:29500
 0: [INFO|2025-06-27 21:02:37] llamafactory.cli:143 >> Multi-node training enabled: num nodes: 32, node rank: 0
15: [INFO|2025-06-27 21:02:37] llamafactory.cli:143 >> Initializing 4 distributed tasks at: nid005574:29500
15: [INFO|2025-06-27 21:02:37] llamafactory.cli:143 >> Multi-node training enabled: num nodes: 32, node rank: 15
25: [INFO|2025-06-27 21:02:37] llamafactory.cli:143 >> Initializing 4 distributed tasks at: nid005574:29500
25: [INFO|2025-06-27 21:02:37] llamafactory.cli:143 >> Multi-node training enabled: num nodes: 32, node rank: 25
 5: [INFO|2025-06-27 21:02:37] llamafactory.cli:143 >> Initializing 4 distributed tasks at: nid005574:29500
 5: [INFO|2025-06-27 21:02:37] llamafactory.cli:143 >> Multi-node training enabled: num nodes: 32, node rank: 5
28: [INFO|2025-06-27 21:02:37] llamafactory.cli:143 >> Initializing 4 distributed tasks at: nid005574:29500
28: [INFO|2025-06-27 21:02:37] llamafactory.cli:143 >> Multi-node training enabled: num nodes: 32, node rank: 28
 6: [INFO|2025-06-27 21:02:37] llamafactory.cli:143 >> Initializing 4 distributed tasks at: nid005574:29500
 6: [INFO|2025-06-27 21:02:37] llamafactory.cli:143 >> Multi-node training enabled: num nodes: 32, node rank: 6
27: [INFO|2025-06-27 21:02:37] llamafactory.cli:143 >> Initializing 4 distributed tasks at: nid005574:29500
27: [INFO|2025-06-27 21:02:37] llamafactory.cli:143 >> Multi-node training enabled: num nodes: 32, node rank: 27
 2: [INFO|2025-06-27 21:02:37] llamafactory.cli:143 >> Initializing 4 distributed tasks at: nid005574:29500
 2: [INFO|2025-06-27 21:02:37] llamafactory.cli:143 >> Multi-node training enabled: num nodes: 32, node rank: 2
22: [INFO|2025-06-27 21:02:37] llamafactory.cli:143 >> Initializing 4 distributed tasks at: nid005574:29500
22: [INFO|2025-06-27 21:02:37] llamafactory.cli:143 >> Multi-node training enabled: num nodes: 32, node rank: 22
23: [INFO|2025-06-27 21:02:37] llamafactory.cli:143 >> Initializing 4 distributed tasks at: nid005574:29500
23: [INFO|2025-06-27 21:02:37] llamafactory.cli:143 >> Multi-node training enabled: num nodes: 32, node rank: 23
13: [INFO|2025-06-27 21:02:37] llamafactory.cli:143 >> Initializing 4 distributed tasks at: nid005574:29500
13: [INFO|2025-06-27 21:02:37] llamafactory.cli:143 >> Multi-node training enabled: num nodes: 32, node rank: 13
21: [INFO|2025-06-27 21:02:37] llamafactory.cli:143 >> Initializing 4 distributed tasks at: nid005574:29500
21: [INFO|2025-06-27 21:02:37] llamafactory.cli:143 >> Multi-node training enabled: num nodes: 32, node rank: 21
 9: [INFO|2025-06-27 21:02:37] llamafactory.cli:143 >> Initializing 4 distributed tasks at: nid005574:29500
 9: [INFO|2025-06-27 21:02:37] llamafactory.cli:143 >> Multi-node training enabled: num nodes: 32, node rank: 9
30: [INFO|2025-06-27 21:02:37] llamafactory.cli:143 >> Initializing 4 distributed tasks at: nid005574:29500
30: [INFO|2025-06-27 21:02:37] llamafactory.cli:143 >> Multi-node training enabled: num nodes: 32, node rank: 30
10: [INFO|2025-06-27 21:02:37] llamafactory.cli:143 >> Initializing 4 distributed tasks at: nid005574:29500
10: [INFO|2025-06-27 21:02:37] llamafactory.cli:143 >> Multi-node training enabled: num nodes: 32, node rank: 10
18: [INFO|2025-06-27 21:02:37] llamafactory.cli:143 >> Initializing 4 distributed tasks at: nid005574:29500
18: [INFO|2025-06-27 21:02:37] llamafactory.cli:143 >> Multi-node training enabled: num nodes: 32, node rank: 18
 3: [INFO|2025-06-27 21:02:37] llamafactory.cli:143 >> Initializing 4 distributed tasks at: nid005574:29500
 3: [INFO|2025-06-27 21:02:37] llamafactory.cli:143 >> Multi-node training enabled: num nodes: 32, node rank: 3
20: [INFO|2025-06-27 21:02:37] llamafactory.cli:143 >> Initializing 4 distributed tasks at: nid005574:29500
20: [INFO|2025-06-27 21:02:37] llamafactory.cli:143 >> Multi-node training enabled: num nodes: 32, node rank: 20
12: [INFO|2025-06-27 21:02:37] llamafactory.cli:143 >> Initializing 4 distributed tasks at: nid005574:29500
12: [INFO|2025-06-27 21:02:37] llamafactory.cli:143 >> Multi-node training enabled: num nodes: 32, node rank: 12
14: [INFO|2025-06-27 21:02:37] llamafactory.cli:143 >> Initializing 4 distributed tasks at: nid005574:29500
14: [INFO|2025-06-27 21:02:37] llamafactory.cli:143 >> Multi-node training enabled: num nodes: 32, node rank: 14
 8: [INFO|2025-06-27 21:02:37] llamafactory.cli:143 >> Initializing 4 distributed tasks at: nid005574:29500
 8: [INFO|2025-06-27 21:02:37] llamafactory.cli:143 >> Multi-node training enabled: num nodes: 32, node rank: 8
16: [INFO|2025-06-27 21:02:37] llamafactory.cli:143 >> Initializing 4 distributed tasks at: nid005574:29500
16: [INFO|2025-06-27 21:02:37] llamafactory.cli:143 >> Multi-node training enabled: num nodes: 32, node rank: 16
 0: W0627 21:02:37.929000 70369654474848 torch/distributed/run.py:793] 
 0: W0627 21:02:37.929000 70369654474848 torch/distributed/run.py:793] *****************************************
 0: W0627 21:02:37.929000 70369654474848 torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
 0: W0627 21:02:37.929000 70369654474848 torch/distributed/run.py:793] *****************************************
17: W0627 21:02:37.936000 70368922962016 torch/distributed/run.py:793] 
17: W0627 21:02:37.936000 70368922962016 torch/distributed/run.py:793] *****************************************
17: W0627 21:02:37.936000 70368922962016 torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
17: W0627 21:02:37.936000 70368922962016 torch/distributed/run.py:793] *****************************************
19: W0627 21:02:37.937000 70369048922208 torch/distributed/run.py:793] 
19: W0627 21:02:37.937000 70369048922208 torch/distributed/run.py:793] *****************************************
19: W0627 21:02:37.937000 70369048922208 torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
19: W0627 21:02:37.937000 70369048922208 torch/distributed/run.py:793] *****************************************
15: W0627 21:02:37.989000 70369318864992 torch/distributed/run.py:793] 
15: W0627 21:02:37.989000 70369318864992 torch/distributed/run.py:793] *****************************************
15: W0627 21:02:37.989000 70369318864992 torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
15: W0627 21:02:37.989000 70369318864992 torch/distributed/run.py:793] *****************************************
25: W0627 21:02:38.060000 70369008617568 torch/distributed/run.py:793] 
25: W0627 21:02:38.060000 70369008617568 torch/distributed/run.py:793] *****************************************
25: W0627 21:02:38.060000 70369008617568 torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
25: W0627 21:02:38.060000 70369008617568 torch/distributed/run.py:793] *****************************************
 5: W0627 21:02:38.074000 70369036994656 torch/distributed/run.py:793] 
 5: W0627 21:02:38.074000 70369036994656 torch/distributed/run.py:793] *****************************************
 5: W0627 21:02:38.074000 70369036994656 torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
 5: W0627 21:02:38.074000 70369036994656 torch/distributed/run.py:793] *****************************************
27: W0627 21:02:38.145000 70369094862944 torch/distributed/run.py:793] 
27: W0627 21:02:38.145000 70369094862944 torch/distributed/run.py:793] *****************************************
27: W0627 21:02:38.145000 70369094862944 torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
27: W0627 21:02:38.145000 70369094862944 torch/distributed/run.py:793] *****************************************
 2: W0627 21:02:38.146000 70369156925536 torch/distributed/run.py:793] 
 2: W0627 21:02:38.146000 70369156925536 torch/distributed/run.py:793] *****************************************
 2: W0627 21:02:38.146000 70369156925536 torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
 2: W0627 21:02:38.146000 70369156925536 torch/distributed/run.py:793] *****************************************
28: W0627 21:02:38.158000 70368962873440 torch/distributed/run.py:793] 
28: W0627 21:02:38.158000 70368962873440 torch/distributed/run.py:793] *****************************************
28: W0627 21:02:38.158000 70368962873440 torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
28: W0627 21:02:38.158000 70368962873440 torch/distributed/run.py:793] *****************************************
 6: W0627 21:02:38.171000 70369600473184 torch/distributed/run.py:793] 
 6: W0627 21:02:38.171000 70369600473184 torch/distributed/run.py:793] *****************************************
 6: W0627 21:02:38.171000 70369600473184 torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
 6: W0627 21:02:38.171000 70369600473184 torch/distributed/run.py:793] *****************************************
23: W0627 21:02:38.221000 70369403996256 torch/distributed/run.py:793] 
23: W0627 21:02:38.221000 70369403996256 torch/distributed/run.py:793] *****************************************
23: W0627 21:02:38.221000 70369403996256 torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
23: W0627 21:02:38.221000 70369403996256 torch/distributed/run.py:793] *****************************************
 1: [INFO|2025-06-27 21:02:38] llamafactory.cli:143 >> Initializing 4 distributed tasks at: nid005574:29500
 1: [INFO|2025-06-27 21:02:38] llamafactory.cli:143 >> Multi-node training enabled: num nodes: 32, node rank: 1
22: W0627 21:02:38.236000 70369700481120 torch/distributed/run.py:793] 
22: W0627 21:02:38.236000 70369700481120 torch/distributed/run.py:793] *****************************************
22: W0627 21:02:38.236000 70369700481120 torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
22: W0627 21:02:38.236000 70369700481120 torch/distributed/run.py:793] *****************************************
13: W0627 21:02:38.249000 70368751257696 torch/distributed/run.py:793] 
13: W0627 21:02:38.249000 70368751257696 torch/distributed/run.py:793] *****************************************
13: W0627 21:02:38.249000 70368751257696 torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
13: W0627 21:02:38.249000 70368751257696 torch/distributed/run.py:793] *****************************************
21: W0627 21:02:38.260000 70369542408288 torch/distributed/run.py:793] 
21: W0627 21:02:38.260000 70369542408288 torch/distributed/run.py:793] *****************************************
21: W0627 21:02:38.260000 70369542408288 torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
21: W0627 21:02:38.260000 70369542408288 torch/distributed/run.py:793] *****************************************
30: W0627 21:02:38.261000 70368834095200 torch/distributed/run.py:793] 
30: W0627 21:02:38.261000 70368834095200 torch/distributed/run.py:793] *****************************************
30: W0627 21:02:38.261000 70368834095200 torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
30: W0627 21:02:38.261000 70368834095200 torch/distributed/run.py:793] *****************************************
 9: W0627 21:02:38.264000 70369632389216 torch/distributed/run.py:793] 
 9: W0627 21:02:38.264000 70369632389216 torch/distributed/run.py:793] *****************************************
 9: W0627 21:02:38.264000 70369632389216 torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
 9: W0627 21:02:38.264000 70369632389216 torch/distributed/run.py:793] *****************************************
 7: [INFO|2025-06-27 21:02:38] llamafactory.cli:143 >> Initializing 4 distributed tasks at: nid005574:29500
 7: [INFO|2025-06-27 21:02:38] llamafactory.cli:143 >> Multi-node training enabled: num nodes: 32, node rank: 7
 4: [INFO|2025-06-27 21:02:38] llamafactory.cli:143 >> Initializing 4 distributed tasks at: nid005574:29500
 4: [INFO|2025-06-27 21:02:38] llamafactory.cli:143 >> Multi-node training enabled: num nodes: 32, node rank: 4
11: [INFO|2025-06-27 21:02:38] llamafactory.cli:143 >> Initializing 4 distributed tasks at: nid005574:29500
11: [INFO|2025-06-27 21:02:38] llamafactory.cli:143 >> Multi-node training enabled: num nodes: 32, node rank: 11
10: W0627 21:02:38.392000 70368853428320 torch/distributed/run.py:793] 
10: W0627 21:02:38.392000 70368853428320 torch/distributed/run.py:793] *****************************************
10: W0627 21:02:38.392000 70368853428320 torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
10: W0627 21:02:38.392000 70368853428320 torch/distributed/run.py:793] *****************************************
 3: W0627 21:02:38.407000 70369173047392 torch/distributed/run.py:793] 
 3: W0627 21:02:38.407000 70369173047392 torch/distributed/run.py:793] *****************************************
 3: W0627 21:02:38.407000 70369173047392 torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
 3: W0627 21:02:38.407000 70369173047392 torch/distributed/run.py:793] *****************************************
20: W0627 21:02:38.417000 70369621313632 torch/distributed/run.py:793] 
20: W0627 21:02:38.417000 70369621313632 torch/distributed/run.py:793] *****************************************
20: W0627 21:02:38.417000 70369621313632 torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
20: W0627 21:02:38.417000 70369621313632 torch/distributed/run.py:793] *****************************************
18: W0627 21:02:38.431000 70369623804000 torch/distributed/run.py:793] 
18: W0627 21:02:38.431000 70369623804000 torch/distributed/run.py:793] *****************************************
18: W0627 21:02:38.431000 70369623804000 torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
18: W0627 21:02:38.431000 70369623804000 torch/distributed/run.py:793] *****************************************
14: W0627 21:02:38.435000 70369276856416 torch/distributed/run.py:793] 
14: W0627 21:02:38.435000 70369276856416 torch/distributed/run.py:793] *****************************************
14: W0627 21:02:38.435000 70369276856416 torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
14: W0627 21:02:38.435000 70369276856416 torch/distributed/run.py:793] *****************************************
 8: W0627 21:02:38.442000 70368966215776 torch/distributed/run.py:793] 
 8: W0627 21:02:38.442000 70368966215776 torch/distributed/run.py:793] *****************************************
 8: W0627 21:02:38.442000 70368966215776 torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
 8: W0627 21:02:38.442000 70368966215776 torch/distributed/run.py:793] *****************************************
29: [INFO|2025-06-27 21:02:38] llamafactory.cli:143 >> Initializing 4 distributed tasks at: nid005574:29500
29: [INFO|2025-06-27 21:02:38] llamafactory.cli:143 >> Multi-node training enabled: num nodes: 32, node rank: 29
31: [INFO|2025-06-27 21:02:38] llamafactory.cli:143 >> Initializing 4 distributed tasks at: nid005574:29500
31: [INFO|2025-06-27 21:02:38] llamafactory.cli:143 >> Multi-node training enabled: num nodes: 32, node rank: 31
12: W0627 21:02:38.640000 70369110788192 torch/distributed/run.py:793] 
12: W0627 21:02:38.640000 70369110788192 torch/distributed/run.py:793] *****************************************
12: W0627 21:02:38.640000 70369110788192 torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
12: W0627 21:02:38.640000 70369110788192 torch/distributed/run.py:793] *****************************************
24: [INFO|2025-06-27 21:02:38] llamafactory.cli:143 >> Initializing 4 distributed tasks at: nid005574:29500
24: [INFO|2025-06-27 21:02:38] llamafactory.cli:143 >> Multi-node training enabled: num nodes: 32, node rank: 24
16: W0627 21:02:38.755000 70369678133344 torch/distributed/run.py:793] 
16: W0627 21:02:38.755000 70369678133344 torch/distributed/run.py:793] *****************************************
16: W0627 21:02:38.755000 70369678133344 torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
16: W0627 21:02:38.755000 70369678133344 torch/distributed/run.py:793] *****************************************
26: [INFO|2025-06-27 21:02:38] llamafactory.cli:143 >> Initializing 4 distributed tasks at: nid005574:29500
26: [INFO|2025-06-27 21:02:38] llamafactory.cli:143 >> Multi-node training enabled: num nodes: 32, node rank: 26
 1: W0627 21:02:39.265000 70369344948320 torch/distributed/run.py:793] 
 1: W0627 21:02:39.265000 70369344948320 torch/distributed/run.py:793] *****************************************
 1: W0627 21:02:39.265000 70369344948320 torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
 1: W0627 21:02:39.265000 70369344948320 torch/distributed/run.py:793] *****************************************
 7: W0627 21:02:39.335000 70369144932448 torch/distributed/run.py:793] 
 7: W0627 21:02:39.335000 70369144932448 torch/distributed/run.py:793] *****************************************
 7: W0627 21:02:39.335000 70369144932448 torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
 7: W0627 21:02:39.335000 70369144932448 torch/distributed/run.py:793] *****************************************
 4: W0627 21:02:39.352000 70369663977568 torch/distributed/run.py:793] 
 4: W0627 21:02:39.352000 70369663977568 torch/distributed/run.py:793] *****************************************
 4: W0627 21:02:39.352000 70369663977568 torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
 4: W0627 21:02:39.352000 70369663977568 torch/distributed/run.py:793] *****************************************
11: W0627 21:02:39.410000 70369052788832 torch/distributed/run.py:793] 
11: W0627 21:02:39.410000 70369052788832 torch/distributed/run.py:793] *****************************************
11: W0627 21:02:39.410000 70369052788832 torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
11: W0627 21:02:39.410000 70369052788832 torch/distributed/run.py:793] *****************************************
29: W0627 21:02:39.619000 70369079068768 torch/distributed/run.py:793] 
29: W0627 21:02:39.619000 70369079068768 torch/distributed/run.py:793] *****************************************
29: W0627 21:02:39.619000 70369079068768 torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
29: W0627 21:02:39.619000 70369079068768 torch/distributed/run.py:793] *****************************************
31: W0627 21:02:39.624000 70369516128352 torch/distributed/run.py:793] 
31: W0627 21:02:39.624000 70369516128352 torch/distributed/run.py:793] *****************************************
31: W0627 21:02:39.624000 70369516128352 torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
31: W0627 21:02:39.624000 70369516128352 torch/distributed/run.py:793] *****************************************
24: W0627 21:02:39.724000 70368912869472 torch/distributed/run.py:793] 
24: W0627 21:02:39.724000 70368912869472 torch/distributed/run.py:793] *****************************************
24: W0627 21:02:39.724000 70368912869472 torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
24: W0627 21:02:39.724000 70368912869472 torch/distributed/run.py:793] *****************************************
26: W0627 21:02:39.828000 70369534412896 torch/distributed/run.py:793] 
26: W0627 21:02:39.828000 70369534412896 torch/distributed/run.py:793] *****************************************
26: W0627 21:02:39.828000 70369534412896 torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
26: W0627 21:02:39.828000 70369534412896 torch/distributed/run.py:793] *****************************************
21: [2025-06-27 21:02:44,988] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
17: [2025-06-27 21:02:45,175] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
17: [2025-06-27 21:02:45,182] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
 5: [2025-06-27 21:02:45,189] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
15: [2025-06-27 21:02:45,194] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
15: [2025-06-27 21:02:45,195] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
 5: [2025-06-27 21:02:45,201] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
27: [2025-06-27 21:02:45,219] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
27: [2025-06-27 21:02:45,222] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
 2: [2025-06-27 21:02:45,230] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
30: [2025-06-27 21:02:45,234] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
 2: [2025-06-27 21:02:45,237] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
30: [2025-06-27 21:02:45,237] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
23: [2025-06-27 21:02:45,261] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
23: [2025-06-27 21:02:45,265] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
 9: [2025-06-27 21:02:45,529] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
 9: [2025-06-27 21:02:45,531] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
13: [2025-06-27 21:02:45,533] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
 9: [2025-06-27 21:02:45,534] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
13: [2025-06-27 21:02:45,536] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
13: [2025-06-27 21:02:45,538] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
25: [2025-06-27 21:02:45,607] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
25: [2025-06-27 21:02:45,609] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
25: [2025-06-27 21:02:45,611] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
 5: [2025-06-27 21:02:45,647] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
12: [2025-06-27 21:02:45,653] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
12: [2025-06-27 21:02:45,663] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
 0: [2025-06-27 21:02:45,664] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
 0: [2025-06-27 21:02:45,666] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
 0: [2025-06-27 21:02:45,668] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
10: [2025-06-27 21:02:45,700] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
10: [2025-06-27 21:02:45,702] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
10: [2025-06-27 21:02:45,703] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
28: [2025-06-27 21:02:45,726] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
28: [2025-06-27 21:02:45,728] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
28: [2025-06-27 21:02:45,730] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
 1: [2025-06-27 21:02:45,755] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
 1: [2025-06-27 21:02:45,759] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
19: [2025-06-27 21:02:45,765] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
19: [2025-06-27 21:02:45,766] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
19: [2025-06-27 21:02:45,768] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
13: [2025-06-27 21:02:45,844] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
25: [2025-06-27 21:02:45,929] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
26: [2025-06-27 21:02:45,972] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
26: [2025-06-27 21:02:45,974] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
26: [2025-06-27 21:02:45,975] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
16: [2025-06-27 21:02:45,999] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
16: [2025-06-27 21:02:46,001] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
16: [2025-06-27 21:02:46,003] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
 7: [2025-06-27 21:02:46,015] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
 7: [2025-06-27 21:02:46,016] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
 7: [2025-06-27 21:02:46,020] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
28: [2025-06-27 21:02:46,032] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
10: [2025-06-27 21:02:46,049] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
11: [2025-06-27 21:02:46,083] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
11: [2025-06-27 21:02:46,085] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
11: [2025-06-27 21:02:46,088] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
 0: [2025-06-27 21:02:46,095] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
19: [2025-06-27 21:02:46,164] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
 5: [2025-06-27 21:02:46,172] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
26: [2025-06-27 21:02:46,250] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
 7: [2025-06-27 21:02:46,328] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
21: [2025-06-27 21:02:46,330] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
17: [2025-06-27 21:02:46,331] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
21: [2025-06-27 21:02:46,332] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
17: [2025-06-27 21:02:46,334] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
21: [2025-06-27 21:02:46,334] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
22: [2025-06-27 21:02:46,342] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
22: [2025-06-27 21:02:46,343] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
15: [2025-06-27 21:02:46,343] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
22: [2025-06-27 21:02:46,345] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
15: [2025-06-27 21:02:46,346] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
22: [2025-06-27 21:02:46,346] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
16: [2025-06-27 21:02:46,378] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
30: [2025-06-27 21:02:46,389] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
30: [2025-06-27 21:02:46,391] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
27: [2025-06-27 21:02:46,404] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
27: [2025-06-27 21:02:46,406] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
11: [2025-06-27 21:02:46,436] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
 2: [2025-06-27 21:02:46,438] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
 2: [2025-06-27 21:02:46,439] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
23: [2025-06-27 21:02:46,446] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
23: [2025-06-27 21:02:46,448] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
 3: [2025-06-27 21:02:46,483] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
 3: [2025-06-27 21:02:46,483] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
 3: [2025-06-27 21:02:46,485] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
 3: [2025-06-27 21:02:46,487] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
 9: [2025-06-27 21:02:46,524] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
 8: [2025-06-27 21:02:46,568] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
 8: [2025-06-27 21:02:46,569] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
 8: [2025-06-27 21:02:46,571] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
 8: [2025-06-27 21:02:46,573] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
29: [2025-06-27 21:02:46,579] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
29: [2025-06-27 21:02:46,579] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
29: [2025-06-27 21:02:46,583] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
31: [2025-06-27 21:02:46,623] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
31: [2025-06-27 21:02:46,624] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
31: [2025-06-27 21:02:46,626] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
31: [2025-06-27 21:02:46,628] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
 6: [2025-06-27 21:02:46,653] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
 6: [2025-06-27 21:02:46,655] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
 6: [2025-06-27 21:02:46,656] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
 6: [2025-06-27 21:02:46,658] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
24: [2025-06-27 21:02:46,674] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
24: [2025-06-27 21:02:46,679] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
24: [2025-06-27 21:02:46,682] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
20: [2025-06-27 21:02:46,745] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
20: [2025-06-27 21:02:46,747] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
20: [2025-06-27 21:02:46,749] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
20: [2025-06-27 21:02:46,750] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
14: [2025-06-27 21:02:46,785] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
14: [2025-06-27 21:02:46,787] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
14: [2025-06-27 21:02:46,791] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
14: [2025-06-27 21:02:46,797] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
 4: [2025-06-27 21:02:46,810] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
 4: [2025-06-27 21:02:46,813] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
 4: [2025-06-27 21:02:46,815] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
 4: [2025-06-27 21:02:46,816] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
12: [2025-06-27 21:02:46,877] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
12: [2025-06-27 21:02:46,880] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
18: [2025-06-27 21:02:46,901] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
18: [2025-06-27 21:02:46,902] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
18: [2025-06-27 21:02:46,904] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
18: [2025-06-27 21:02:46,906] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
 1: [2025-06-27 21:02:46,975] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
 1: [2025-06-27 21:02:46,977] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
21: [2025-06-27 21:02:47,529] [INFO] [comm.py:669:init_distributed] cdb=None
21: [W627 21:02:47.051042172 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
29: [2025-06-27 21:02:47,607] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
17: [2025-06-27 21:02:47,775] [INFO] [comm.py:669:init_distributed] cdb=None
17: [W627 21:02:47.495663879 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
17: [2025-06-27 21:02:47,782] [INFO] [comm.py:669:init_distributed] cdb=None
17: [W627 21:02:47.502185508 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
27: [2025-06-27 21:02:47,859] [INFO] [comm.py:669:init_distributed] cdb=None
27: [2025-06-27 21:02:47,859] [INFO] [comm.py:669:init_distributed] cdb=None
27: [W627 21:02:47.350454475 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
27: [W627 21:02:47.350454539 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
 5: [2025-06-27 21:02:47,885] [INFO] [comm.py:669:init_distributed] cdb=None
 5: [2025-06-27 21:02:47,885] [INFO] [comm.py:669:init_distributed] cdb=None
 5: [W627 21:02:47.141036973 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
 5: [W627 21:02:47.141532509 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
 2: [2025-06-27 21:02:47,902] [INFO] [comm.py:669:init_distributed] cdb=None
 2: [2025-06-27 21:02:47,902] [INFO] [comm.py:669:init_distributed] cdb=None
 2: [W627 21:02:47.366339882 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
 2: [W627 21:02:47.366593730 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
15: [2025-06-27 21:02:47,938] [INFO] [comm.py:669:init_distributed] cdb=None
15: [2025-06-27 21:02:47,938] [INFO] [comm.py:669:init_distributed] cdb=None
24: [2025-06-27 21:02:47,941] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
15: [W627 21:02:47.744251710 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
15: [W627 21:02:47.744820236 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
23: [2025-06-27 21:02:47,945] [INFO] [comm.py:669:init_distributed] cdb=None
23: [2025-06-27 21:02:47,946] [INFO] [comm.py:669:init_distributed] cdb=None
23: [W627 21:02:47.066321075 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
23: [W627 21:02:47.066321139 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
30: [2025-06-27 21:02:48,137] [INFO] [comm.py:669:init_distributed] cdb=None
30: [2025-06-27 21:02:48,137] [INFO] [comm.py:669:init_distributed] cdb=None
30: [W627 21:02:48.252892476 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
30: [W627 21:02:48.253294256 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
 2: [INFO|2025-06-27 21:02:48] llamafactory.hparams.parser:406 >> Process rank: 8, world size: 128, device: cuda:0, distributed training: True, compute dtype: torch.bfloat16
27: [INFO|2025-06-27 21:02:48] llamafactory.hparams.parser:406 >> Process rank: 108, world size: 128, device: cuda:0, distributed training: True, compute dtype: torch.bfloat16
13: [2025-06-27 21:02:48,433] [INFO] [comm.py:669:init_distributed] cdb=None
13: [2025-06-27 21:02:48,434] [INFO] [comm.py:669:init_distributed] cdb=None
13: [W627 21:02:48.650386177 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
13: [W627 21:02:48.650647609 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
13: [2025-06-27 21:02:48,443] [INFO] [comm.py:669:init_distributed] cdb=None
 9: [2025-06-27 21:02:48,470] [INFO] [comm.py:669:init_distributed] cdb=None
 9: [2025-06-27 21:02:48,470] [INFO] [comm.py:669:init_distributed] cdb=None
10: [2025-06-27 21:02:48,504] [INFO] [comm.py:669:init_distributed] cdb=None
10: [2025-06-27 21:02:48,504] [INFO] [comm.py:669:init_distributed] cdb=None
25: [2025-06-27 21:02:48,524] [INFO] [comm.py:669:init_distributed] cdb=None
25: [2025-06-27 21:02:48,525] [INFO] [comm.py:669:init_distributed] cdb=None
13: [W627 21:02:48.740094689 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
 9: [W627 21:02:48.240577101 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
 9: [W627 21:02:48.240577037 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
10: [W627 21:02:48.032543422 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
10: [W627 21:02:48.032543454 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
25: [W627 21:02:48.059305378 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
25: [W627 21:02:48.059648088 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
25: [2025-06-27 21:02:48,546] [INFO] [comm.py:669:init_distributed] cdb=None
25: [W627 21:02:48.081336681 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
 9: [2025-06-27 21:02:48,573] [INFO] [comm.py:669:init_distributed] cdb=None
 9: [W627 21:02:48.289951275 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
 2: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:48,630 >> loading file vocab.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
 2: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:48,630 >> loading file merges.txt from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
 2: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:48,630 >> loading file tokenizer.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
 2: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:48,630 >> loading file added_tokens.json from cache at None
 2: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:48,630 >> loading file special_tokens_map.json from cache at None
 2: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:48,630 >> loading file tokenizer_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
 2: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:48,630 >> loading file chat_template.jinja from cache at None
27: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:48,631 >> loading file vocab.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
27: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:48,631 >> loading file merges.txt from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
27: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:48,631 >> loading file tokenizer.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
27: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:48,631 >> loading file added_tokens.json from cache at None
27: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:48,631 >> loading file special_tokens_map.json from cache at None
27: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:48,631 >> loading file tokenizer_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
27: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:48,631 >> loading file chat_template.jinja from cache at None
21: [INFO|2025-06-27 21:02:48] llamafactory.hparams.parser:406 >> Process rank: 86, world size: 128, device: cuda:2, distributed training: True, compute dtype: torch.bfloat16
10: [2025-06-27 21:02:48,767] [INFO] [comm.py:669:init_distributed] cdb=None
10: [W627 21:02:48.276580770 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
 5: [2025-06-27 21:02:48,795] [INFO] [comm.py:669:init_distributed] cdb=None
 5: [W627 21:02:48.051201341 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
28: [2025-06-27 21:02:48,810] [INFO] [comm.py:669:init_distributed] cdb=None
28: [2025-06-27 21:02:48,810] [INFO] [comm.py:669:init_distributed] cdb=None
28: [W627 21:02:48.181679175 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
28: [W627 21:02:48.181845154 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
12: [2025-06-27 21:02:48,816] [INFO] [comm.py:669:init_distributed] cdb=None
 2: [INFO|tokenization_utils_base.py:2323] 2025-06-27 21:02:48,819 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
12: [W627 21:02:48.859960910 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
27: [INFO|tokenization_utils_base.py:2323] 2025-06-27 21:02:48,823 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
 1: [2025-06-27 21:02:48,855] [INFO] [comm.py:669:init_distributed] cdb=None
 1: [2025-06-27 21:02:48,855] [INFO] [comm.py:669:init_distributed] cdb=None
 1: [W627 21:02:48.373549337 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
 1: [W627 21:02:48.373810001 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
12: [2025-06-27 21:02:48,911] [INFO] [comm.py:669:init_distributed] cdb=None
12: [W627 21:02:48.956068301 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
13: [2025-06-27 21:02:48,982] [INFO] [comm.py:669:init_distributed] cdb=None
13: [W627 21:02:48.206102091 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
25: [2025-06-27 21:02:49,036] [INFO] [comm.py:669:init_distributed] cdb=None
25: [W627 21:02:49.571632801 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
10: [2025-06-27 21:02:49,052] [INFO] [comm.py:669:init_distributed] cdb=None
10: [W627 21:02:49.563058369 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
28: [2025-06-27 21:02:49,060] [INFO] [comm.py:669:init_distributed] cdb=None
28: [W627 21:02:49.432175653 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
28: [2025-06-27 21:02:49,079] [INFO] [comm.py:669:init_distributed] cdb=None
28: [W627 21:02:49.450481242 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
19: [2025-06-27 21:02:49,087] [INFO] [comm.py:669:init_distributed] cdb=None
19: [2025-06-27 21:02:49,087] [INFO] [comm.py:669:init_distributed] cdb=None
19: [2025-06-27 21:02:49,090] [INFO] [comm.py:669:init_distributed] cdb=None
19: [W627 21:02:49.027738365 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
19: [W627 21:02:49.027738301 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
19: [W627 21:02:49.029614556 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
 0: [2025-06-27 21:02:49,110] [INFO] [comm.py:669:init_distributed] cdb=None
 0: [2025-06-27 21:02:49,110] [INFO] [comm.py:669:init_distributed] cdb=None
 0: [2025-06-27 21:02:49,110] [INFO] [comm.py:669:init_distributed] cdb=None
 0: [W627 21:02:49.517297498 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
 0: [W627 21:02:49.517340185 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
 0: [W627 21:02:49.517439605 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
 9: [INFO|2025-06-27 21:02:49] llamafactory.hparams.parser:406 >> Process rank: 36, world size: 128, device: cuda:0, distributed training: True, compute dtype: torch.bfloat16
 2: [INFO|image_processing_base.py:380] 2025-06-27 21:02:49,188 >> loading configuration file preprocessor_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
27: [INFO|image_processing_base.py:380] 2025-06-27 21:02:49,188 >> loading configuration file preprocessor_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
13: [INFO|2025-06-27 21:02:49] llamafactory.hparams.parser:406 >> Process rank: 52, world size: 128, device: cuda:0, distributed training: True, compute dtype: torch.bfloat16
 7: [2025-06-27 21:02:49,248] [INFO] [comm.py:669:init_distributed] cdb=None
 7: [2025-06-27 21:02:49,248] [INFO] [comm.py:669:init_distributed] cdb=None
 7: [W627 21:02:49.264678404 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
 7: [W627 21:02:49.265419051 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
17: [2025-06-27 21:02:49,271] [INFO] [comm.py:669:init_distributed] cdb=None
25: [INFO|2025-06-27 21:02:49] llamafactory.hparams.parser:406 >> Process rank: 100, world size: 128, device: cuda:0, distributed training: True, compute dtype: torch.bfloat16
17: [W627 21:02:49.990871710 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
22: [2025-06-27 21:02:49,282] [INFO] [comm.py:669:init_distributed] cdb=None
22: [2025-06-27 21:02:49,282] [INFO] [comm.py:669:init_distributed] cdb=None
22: [2025-06-27 21:02:49,284] [INFO] [comm.py:669:init_distributed] cdb=None
22: [W627 21:02:49.215619210 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
22: [W627 21:02:49.215619178 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
22: [W627 21:02:49.216739433 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
 9: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,288 >> loading file vocab.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
 9: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,288 >> loading file merges.txt from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
 9: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,288 >> loading file tokenizer.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
 9: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,288 >> loading file added_tokens.json from cache at None
 9: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,288 >> loading file special_tokens_map.json from cache at None
 9: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,288 >> loading file tokenizer_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
 9: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,288 >> loading file chat_template.jinja from cache at None
 5: [2025-06-27 21:02:49,295] [INFO] [comm.py:669:init_distributed] cdb=None
 5: [W627 21:02:49.553490171 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
27: [INFO|image_processing_base.py:380] 2025-06-27 21:02:49,312 >> loading configuration file preprocessor_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
 2: [INFO|image_processing_base.py:380] 2025-06-27 21:02:49,313 >> loading configuration file preprocessor_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
27: [INFO|image_processing_base.py:433] 2025-06-27 21:02:49,314 >> Image processor Qwen2VLImageProcessorFast {
27:   "crop_size": null,
27:   "data_format": "channels_first",
27:   "default_to_square": true,
27:   "device": null,
27:   "do_center_crop": null,
27:   "do_convert_rgb": true,
27:   "do_normalize": true,
27:   "do_rescale": true,
27:   "do_resize": true,
27:   "image_mean": [
27:     0.48145466,
27:     0.4578275,
27:     0.40821073
27:   ],
27:   "image_processor_type": "Qwen2VLImageProcessorFast",
27:   "image_std": [
27:     0.26862954,
27:     0.26130258,
27:     0.27577711
27:   ],
27:   "input_data_format": null,
27:   "max_pixels": 12845056,
27:   "merge_size": 2,
27:   "min_pixels": 3136,
27:   "patch_size": 14,
27:   "processor_class": "Qwen2_5_VLProcessor",
27:   "resample": 3,
27:   "rescale_factor": 0.00392156862745098,
27:   "return_tensors": null,
27:   "size": {
27:     "longest_edge": 12845056,
27:     "shortest_edge": 3136
27:   },
27:   "temporal_patch_size": 2
27: }
27: 
 2: [INFO|image_processing_base.py:433] 2025-06-27 21:02:49,315 >> Image processor Qwen2VLImageProcessorFast {
 2:   "crop_size": null,
 2:   "data_format": "channels_first",
 2:   "default_to_square": true,
 2:   "device": null,
 2:   "do_center_crop": null,
 2:   "do_convert_rgb": true,
 2:   "do_normalize": true,
 2:   "do_rescale": true,
 2:   "do_resize": true,
 2:   "image_mean": [
 2:     0.48145466,
 2:     0.4578275,
 2:     0.40821073
 2:   ],
 2:   "image_processor_type": "Qwen2VLImageProcessorFast",
 2:   "image_std": [
 2:     0.26862954,
 2:     0.26130258,
 2:     0.27577711
 2:   ],
 2:   "input_data_format": null,
 2:   "max_pixels": 12845056,
 2:   "merge_size": 2,
 2:   "min_pixels": 3136,
 2:   "patch_size": 14,
 2:   "processor_class": "Qwen2_5_VLProcessor",
 2:   "resample": 3,
 2:   "rescale_factor": 0.00392156862745098,
 2:   "return_tensors": null,
 2:   "size": {
 2:     "longest_edge": 12845056,
 2:     "shortest_edge": 3136
 2:   },
 2:   "temporal_patch_size": 2
 2: }
 2: 
10: [INFO|2025-06-27 21:02:49] llamafactory.hparams.parser:406 >> Process rank: 40, world size: 128, device: cuda:0, distributed training: True, compute dtype: torch.bfloat16
17: [2025-06-27 21:02:49,342] [INFO] [comm.py:669:init_distributed] cdb=None
 1: [INFO|2025-06-27 21:02:49] llamafactory.hparams.parser:406 >> Process rank: 4, world size: 128, device: cuda:0, distributed training: True, compute dtype: torch.bfloat16
17: [W627 21:02:49.062450787 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
21: [2025-06-27 21:02:49,352] [INFO] [comm.py:669:init_distributed] cdb=None
21: [W627 21:02:49.873092074 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
11: [2025-06-27 21:02:49,366] [INFO] [comm.py:669:init_distributed] cdb=None
11: [2025-06-27 21:02:49,366] [INFO] [comm.py:669:init_distributed] cdb=None
11: [W627 21:02:49.013035899 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
11: [W627 21:02:49.013035835 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
13: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,378 >> loading file vocab.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
13: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,378 >> loading file merges.txt from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
13: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,378 >> loading file tokenizer.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
13: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,378 >> loading file added_tokens.json from cache at None
13: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,378 >> loading file special_tokens_map.json from cache at None
13: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,378 >> loading file tokenizer_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
13: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,378 >> loading file chat_template.jinja from cache at None
22: [2025-06-27 21:02:49,383] [INFO] [comm.py:669:init_distributed] cdb=None
22: [W627 21:02:49.316478911 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
27: [2025-06-27 21:02:49,396] [INFO] [comm.py:669:init_distributed] cdb=None
27: [W627 21:02:49.887744159 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
23: [2025-06-27 21:02:49,432] [INFO] [comm.py:669:init_distributed] cdb=None
27: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,432 >> loading file vocab.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
27: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,432 >> loading file merges.txt from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
27: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,432 >> loading file tokenizer.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
27: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,432 >> loading file added_tokens.json from cache at None
27: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,432 >> loading file special_tokens_map.json from cache at None
27: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,432 >> loading file tokenizer_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
27: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,432 >> loading file chat_template.jinja from cache at None
25: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,435 >> loading file vocab.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
25: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,435 >> loading file merges.txt from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
25: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,435 >> loading file tokenizer.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
25: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,435 >> loading file added_tokens.json from cache at None
25: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,435 >> loading file special_tokens_map.json from cache at None
25: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,436 >> loading file tokenizer_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
25: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,436 >> loading file chat_template.jinja from cache at None
23: [W627 21:02:49.553030297 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
 2: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,442 >> loading file vocab.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
 2: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,442 >> loading file merges.txt from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
 2: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,442 >> loading file tokenizer.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
 2: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,442 >> loading file added_tokens.json from cache at None
 2: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,442 >> loading file special_tokens_map.json from cache at None
 2: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,442 >> loading file tokenizer_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
 2: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,442 >> loading file chat_template.jinja from cache at None
21: [2025-06-27 21:02:49,467] [INFO] [comm.py:669:init_distributed] cdb=None
21: [W627 21:02:49.987725752 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
15: [2025-06-27 21:02:49,472] [INFO] [comm.py:669:init_distributed] cdb=None
27: [2025-06-27 21:02:49,473] [INFO] [comm.py:669:init_distributed] cdb=None
15: [W627 21:02:49.278000116 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
27: [W627 21:02:49.963758308 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
 9: [INFO|tokenization_utils_base.py:2323] 2025-06-27 21:02:49,485 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
21: [2025-06-27 21:02:49,491] [INFO] [comm.py:669:init_distributed] cdb=None
21: [W627 21:02:49.011701893 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
10: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,516 >> loading file vocab.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
10: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,516 >> loading file merges.txt from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
10: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,516 >> loading file tokenizer.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
10: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,516 >> loading file added_tokens.json from cache at None
10: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,516 >> loading file special_tokens_map.json from cache at None
10: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,516 >> loading file tokenizer_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
10: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,516 >> loading file chat_template.jinja from cache at None
 1: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,524 >> loading file vocab.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
 1: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,524 >> loading file merges.txt from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
 1: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,524 >> loading file tokenizer.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
 1: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,524 >> loading file added_tokens.json from cache at None
 1: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,524 >> loading file special_tokens_map.json from cache at None
 1: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,524 >> loading file tokenizer_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
 1: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,524 >> loading file chat_template.jinja from cache at None
16: [2025-06-27 21:02:49,533] [INFO] [comm.py:669:init_distributed] cdb=None
16: [2025-06-27 21:02:49,534] [INFO] [comm.py:669:init_distributed] cdb=None
 2: [2025-06-27 21:02:49,536] [INFO] [comm.py:669:init_distributed] cdb=None
16: [W627 21:02:49.267531672 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
16: [W627 21:02:49.267629396 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
 2: [W627 21:02:49.002304328 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
23: [2025-06-27 21:02:49,545] [INFO] [comm.py:669:init_distributed] cdb=None
23: [W627 21:02:49.665749875 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
19: [2025-06-27 21:02:49,554] [INFO] [comm.py:669:init_distributed] cdb=None
 3: [2025-06-27 21:02:49,557] [INFO] [comm.py:669:init_distributed] cdb=None
 7: [2025-06-27 21:02:49,557] [INFO] [comm.py:669:init_distributed] cdb=None
 3: [2025-06-27 21:02:49,558] [INFO] [comm.py:669:init_distributed] cdb=None
19: [W627 21:02:49.494211389 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
 2: [2025-06-27 21:02:49,559] [INFO] [comm.py:669:init_distributed] cdb=None
 3: [W627 21:02:49.373206755 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
 3: [W627 21:02:49.374154019 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
 7: [W627 21:02:49.565469066 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
 2: [W627 21:02:49.024396155 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
13: [INFO|tokenization_utils_base.py:2323] 2025-06-27 21:02:49,577 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
15: [2025-06-27 21:02:49,578] [INFO] [comm.py:669:init_distributed] cdb=None
16: [2025-06-27 21:02:49,580] [INFO] [comm.py:669:init_distributed] cdb=None
15: [W627 21:02:49.385195571 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
16: [W627 21:02:49.314637020 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
 9: [2025-06-27 21:02:49,591] [INFO] [comm.py:669:init_distributed] cdb=None
 9: [W627 21:02:49.308451093 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
27: [INFO|tokenization_utils_base.py:2323] 2025-06-27 21:02:49,601 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
 2: [INFO|tokenization_utils_base.py:2323] 2025-06-27 21:02:49,610 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
28: [INFO|2025-06-27 21:02:49] llamafactory.hparams.parser:406 >> Process rank: 112, world size: 128, device: cuda:0, distributed training: True, compute dtype: torch.bfloat16
 3: [2025-06-27 21:02:49,624] [INFO] [comm.py:669:init_distributed] cdb=None
25: [INFO|tokenization_utils_base.py:2323] 2025-06-27 21:02:49,627 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
 3: [W627 21:02:49.440870559 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
 3: [2025-06-27 21:02:49,635] [INFO] [comm.py:669:init_distributed] cdb=None
 0: [2025-06-27 21:02:49,636] [INFO] [comm.py:669:init_distributed] cdb=None
 0: [2025-06-27 21:02:49,636] [INFO] [comm.py:700:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
 3: [W627 21:02:49.451368313 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
 0: [W627 21:02:49.042729729 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
 5: [INFO|2025-06-27 21:02:49] llamafactory.hparams.parser:406 >> Process rank: 20, world size: 128, device: cuda:0, distributed training: True, compute dtype: torch.bfloat16
26: [2025-06-27 21:02:49,655] [INFO] [comm.py:669:init_distributed] cdb=None
26: [2025-06-27 21:02:49,656] [INFO] [comm.py:669:init_distributed] cdb=None
26: [2025-06-27 21:02:49,657] [INFO] [comm.py:669:init_distributed] cdb=None
26: [W627 21:02:49.560376576 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
26: [W627 21:02:49.560456926 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
26: [W627 21:02:49.560973996 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
17: [INFO|2025-06-27 21:02:49] llamafactory.hparams.parser:406 >> Process rank: 68, world size: 128, device: cuda:0, distributed training: True, compute dtype: torch.bfloat16
 7: [2025-06-27 21:02:49,690] [INFO] [comm.py:669:init_distributed] cdb=None
10: [INFO|tokenization_utils_base.py:2323] 2025-06-27 21:02:49,696 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
11: [2025-06-27 21:02:49,702] [INFO] [comm.py:669:init_distributed] cdb=None
 1: [INFO|tokenization_utils_base.py:2323] 2025-06-27 21:02:49,705 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
26: [2025-06-27 21:02:49,722] [INFO] [comm.py:669:init_distributed] cdb=None
11: [2025-06-27 21:02:49,778] [INFO] [comm.py:669:init_distributed] cdb=None
30: [2025-06-27 21:02:49,782] [INFO] [comm.py:669:init_distributed] cdb=None
28: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,782 >> loading file vocab.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
28: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,782 >> loading file merges.txt from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
28: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,782 >> loading file tokenizer.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
28: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,782 >> loading file added_tokens.json from cache at None
28: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,782 >> loading file special_tokens_map.json from cache at None
28: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,782 >> loading file tokenizer_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
28: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,782 >> loading file chat_template.jinja from cache at None
30: [2025-06-27 21:02:49,787] [INFO] [comm.py:669:init_distributed] cdb=None
16: [2025-06-27 21:02:49,789] [INFO] [comm.py:669:init_distributed] cdb=None
 7: [W627 21:02:49.811458492 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
30: [W627 21:02:49.915638894 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
30: [W627 21:02:49.915640942 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
26: [W627 21:02:49.708576157 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
16: [W627 21:02:49.538247943 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
11: [W627 21:02:49.450231171 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
11: [W627 21:02:49.450231330 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
21: [INFO|2025-06-27 21:02:49] llamafactory.hparams.parser:406 >> Process rank: 84, world size: 128, device: cuda:0, distributed training: True, compute dtype: torch.bfloat16
23: [INFO|2025-06-27 21:02:49] llamafactory.hparams.parser:406 >> Process rank: 92, world size: 128, device: cuda:0, distributed training: True, compute dtype: torch.bfloat16
15: [INFO|2025-06-27 21:02:49] llamafactory.hparams.parser:406 >> Process rank: 60, world size: 128, device: cuda:0, distributed training: True, compute dtype: torch.bfloat16
17: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,837 >> loading file vocab.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
17: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,837 >> loading file merges.txt from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
17: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,837 >> loading file tokenizer.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
17: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,837 >> loading file added_tokens.json from cache at None
17: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,837 >> loading file special_tokens_map.json from cache at None
17: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,837 >> loading file tokenizer_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
17: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,837 >> loading file chat_template.jinja from cache at None
 5: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,860 >> loading file vocab.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
 5: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,860 >> loading file merges.txt from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
 5: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,860 >> loading file tokenizer.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
 5: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,860 >> loading file added_tokens.json from cache at None
 5: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,861 >> loading file special_tokens_map.json from cache at None
 5: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,861 >> loading file tokenizer_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
 5: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,861 >> loading file chat_template.jinja from cache at None
19: [INFO|2025-06-27 21:02:49] llamafactory.hparams.parser:406 >> Process rank: 76, world size: 128, device: cuda:0, distributed training: True, compute dtype: torch.bfloat16
29: [2025-06-27 21:02:49,904] [INFO] [comm.py:669:init_distributed] cdb=None
29: [2025-06-27 21:02:49,904] [INFO] [comm.py:669:init_distributed] cdb=None
29: [2025-06-27 21:02:49,904] [INFO] [comm.py:669:init_distributed] cdb=None
24: [2025-06-27 21:02:49,911] [INFO] [comm.py:669:init_distributed] cdb=None
24: [2025-06-27 21:02:49,911] [INFO] [comm.py:669:init_distributed] cdb=None
24: [2025-06-27 21:02:49,911] [INFO] [comm.py:669:init_distributed] cdb=None
24: [W627 21:02:49.836789741 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
24: [W627 21:02:49.839460895 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
29: [W627 21:02:49.521521960 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
24: [W627 21:02:49.840200649 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
29: [W627 21:02:49.524792761 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
29: [W627 21:02:49.524887605 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
13: [INFO|image_processing_base.py:380] 2025-06-27 21:02:49,938 >> loading configuration file preprocessor_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
28: [INFO|tokenization_utils_base.py:2323] 2025-06-27 21:02:49,964 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
21: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,966 >> loading file vocab.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
21: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,966 >> loading file merges.txt from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
21: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,966 >> loading file tokenizer.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
21: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,966 >> loading file added_tokens.json from cache at None
21: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,966 >> loading file special_tokens_map.json from cache at None
21: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,966 >> loading file tokenizer_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
21: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,966 >> loading file chat_template.jinja from cache at None
25: [INFO|image_processing_base.py:380] 2025-06-27 21:02:49,976 >> loading configuration file preprocessor_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
22: [INFO|2025-06-27 21:02:49] llamafactory.hparams.parser:406 >> Process rank: 88, world size: 128, device: cuda:0, distributed training: True, compute dtype: torch.bfloat16
15: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,998 >> loading file vocab.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
15: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,998 >> loading file merges.txt from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
15: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,998 >> loading file tokenizer.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
15: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,998 >> loading file added_tokens.json from cache at None
15: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,998 >> loading file special_tokens_map.json from cache at None
15: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,998 >> loading file tokenizer_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
15: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:49,998 >> loading file chat_template.jinja from cache at None
23: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,011 >> loading file vocab.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
23: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,011 >> loading file merges.txt from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
23: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,011 >> loading file tokenizer.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
23: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,011 >> loading file added_tokens.json from cache at None
23: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,011 >> loading file special_tokens_map.json from cache at None
23: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,011 >> loading file tokenizer_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
23: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,011 >> loading file chat_template.jinja from cache at None
17: [INFO|tokenization_utils_base.py:2323] 2025-06-27 21:02:50,016 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
19: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,026 >> loading file vocab.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
19: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,026 >> loading file merges.txt from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
19: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,026 >> loading file tokenizer.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
19: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,026 >> loading file added_tokens.json from cache at None
19: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,026 >> loading file special_tokens_map.json from cache at None
19: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,026 >> loading file tokenizer_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
19: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,026 >> loading file chat_template.jinja from cache at None
 9: [INFO|image_processing_base.py:380] 2025-06-27 21:02:50,031 >> loading configuration file preprocessor_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
 5: [INFO|tokenization_utils_base.py:2323] 2025-06-27 21:02:50,040 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
10: [INFO|image_processing_base.py:380] 2025-06-27 21:02:50,060 >> loading configuration file preprocessor_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
31: [2025-06-27 21:02:50,062] [INFO] [comm.py:669:init_distributed] cdb=None
31: [2025-06-27 21:02:50,062] [INFO] [comm.py:669:init_distributed] cdb=None
31: [2025-06-27 21:02:50,063] [INFO] [comm.py:669:init_distributed] cdb=None
31: [2025-06-27 21:02:50,063] [INFO] [comm.py:669:init_distributed] cdb=None
31: [W627 21:02:50.555187449 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
31: [W627 21:02:50.555347477 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
31: [W627 21:02:50.555734890 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
31: [W627 21:02:50.555959044 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
 1: [INFO|image_processing_base.py:380] 2025-06-27 21:02:50,067 >> loading configuration file preprocessor_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
13: [INFO|image_processing_base.py:380] 2025-06-27 21:02:50,079 >> loading configuration file preprocessor_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
13: [INFO|image_processing_base.py:433] 2025-06-27 21:02:50,081 >> Image processor Qwen2VLImageProcessorFast {
13:   "crop_size": null,
13:   "data_format": "channels_first",
13:   "default_to_square": true,
13:   "device": null,
13:   "do_center_crop": null,
13:   "do_convert_rgb": true,
13:   "do_normalize": true,
13:   "do_rescale": true,
13:   "do_resize": true,
13:   "image_mean": [
13:     0.48145466,
13:     0.4578275,
13:     0.40821073
13:   ],
13:   "image_processor_type": "Qwen2VLImageProcessorFast",
13:   "image_std": [
13:     0.26862954,
13:     0.26130258,
13:     0.27577711
13:   ],
13:   "input_data_format": null,
13:   "max_pixels": 12845056,
13:   "merge_size": 2,
13:   "min_pixels": 3136,
13:   "patch_size": 14,
13:   "processor_class": "Qwen2_5_VLProcessor",
13:   "resample": 3,
13:   "rescale_factor": 0.00392156862745098,
13:   "return_tensors": null,
13:   "size": {
13:     "longest_edge": 12845056,
13:     "shortest_edge": 3136
13:   },
13:   "temporal_patch_size": 2
13: }
13: 
 0: [INFO|2025-06-27 21:02:50] llamafactory.hparams.parser:406 >> Process rank: 0, world size: 128, device: cuda:0, distributed training: True, compute dtype: torch.bfloat16
25: [INFO|image_processing_base.py:380] 2025-06-27 21:02:50,104 >> loading configuration file preprocessor_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
25: [INFO|image_processing_base.py:433] 2025-06-27 21:02:50,106 >> Image processor Qwen2VLImageProcessorFast {
25:   "crop_size": null,
25:   "data_format": "channels_first",
25:   "default_to_square": true,
25:   "device": null,
25:   "do_center_crop": null,
25:   "do_convert_rgb": true,
25:   "do_normalize": true,
25:   "do_rescale": true,
25:   "do_resize": true,
25:   "image_mean": [
25:     0.48145466,
25:     0.4578275,
25:     0.40821073
25:   ],
25:   "image_processor_type": "Qwen2VLImageProcessorFast",
25:   "image_std": [
25:     0.26862954,
25:     0.26130258,
25:     0.27577711
25:   ],
25:   "input_data_format": null,
25:   "max_pixels": 12845056,
25:   "merge_size": 2,
25:   "min_pixels": 3136,
25:   "patch_size": 14,
25:   "processor_class": "Qwen2_5_VLProcessor",
25:   "resample": 3,
25:   "rescale_factor": 0.00392156862745098,
25:   "return_tensors": null,
25:   "size": {
25:     "longest_edge": 12845056,
25:     "shortest_edge": 3136
25:   },
25:   "temporal_patch_size": 2
25: }
25: 
 7: [INFO|2025-06-27 21:02:50] llamafactory.hparams.parser:406 >> Process rank: 28, world size: 128, device: cuda:0, distributed training: True, compute dtype: torch.bfloat16
14: [2025-06-27 21:02:50,122] [INFO] [comm.py:669:init_distributed] cdb=None
14: [2025-06-27 21:02:50,122] [INFO] [comm.py:669:init_distributed] cdb=None
14: [2025-06-27 21:02:50,122] [INFO] [comm.py:669:init_distributed] cdb=None
14: [W627 21:02:50.445622777 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
14: [W627 21:02:50.446142663 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
14: [W627 21:02:50.451595570 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
21: [INFO|tokenization_utils_base.py:2323] 2025-06-27 21:02:50,139 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
 9: [INFO|image_processing_base.py:380] 2025-06-27 21:02:50,153 >> loading configuration file preprocessor_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
 9: [INFO|image_processing_base.py:433] 2025-06-27 21:02:50,155 >> Image processor Qwen2VLImageProcessorFast {
 9:   "crop_size": null,
 9:   "data_format": "channels_first",
 9:   "default_to_square": true,
 9:   "device": null,
 9:   "do_center_crop": null,
 9:   "do_convert_rgb": true,
 9:   "do_normalize": true,
 9:   "do_rescale": true,
 9:   "do_resize": true,
 9:   "image_mean": [
 9:     0.48145466,
 9:     0.4578275,
 9:     0.40821073
 9:   ],
 9:   "image_processor_type": "Qwen2VLImageProcessorFast",
 9:   "image_std": [
 9:     0.26862954,
 9:     0.26130258,
 9:     0.27577711
 9:   ],
 9:   "input_data_format": null,
 9:   "max_pixels": 12845056,
 9:   "merge_size": 2,
 9:   "min_pixels": 3136,
 9:   "patch_size": 14,
 9:   "processor_class": "Qwen2_5_VLProcessor",
 9:   "resample": 3,
 9:   "rescale_factor": 0.00392156862745098,
 9:   "return_tensors": null,
 9:   "size": {
 9:     "longest_edge": 12845056,
 9:     "shortest_edge": 3136
 9:   },
 9:   "temporal_patch_size": 2
 9: }
 9: 
20: [2025-06-27 21:02:50,158] [INFO] [comm.py:669:init_distributed] cdb=None
20: [2025-06-27 21:02:50,158] [INFO] [comm.py:669:init_distributed] cdb=None
20: [2025-06-27 21:02:50,158] [INFO] [comm.py:669:init_distributed] cdb=None
20: [W627 21:02:50.977457381 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
20: [W627 21:02:50.977683134 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
20: [W627 21:02:50.978332937 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
10: [INFO|image_processing_base.py:380] 2025-06-27 21:02:50,178 >> loading configuration file preprocessor_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
10: [INFO|image_processing_base.py:433] 2025-06-27 21:02:50,180 >> Image processor Qwen2VLImageProcessorFast {
10:   "crop_size": null,
10:   "data_format": "channels_first",
10:   "default_to_square": true,
10:   "device": null,
10:   "do_center_crop": null,
10:   "do_convert_rgb": true,
10:   "do_normalize": true,
10:   "do_rescale": true,
10:   "do_resize": true,
10:   "image_mean": [
10:     0.48145466,
10:     0.4578275,
10:     0.40821073
10:   ],
10:   "image_processor_type": "Qwen2VLImageProcessorFast",
10:   "image_std": [
10:     0.26862954,
10:     0.26130258,
10:     0.27577711
10:   ],
10:   "input_data_format": null,
10:   "max_pixels": 12845056,
10:   "merge_size": 2,
10:   "min_pixels": 3136,
10:   "patch_size": 14,
10:   "processor_class": "Qwen2_5_VLProcessor",
10:   "resample": 3,
10:   "rescale_factor": 0.00392156862745098,
10:   "return_tensors": null,
10:   "size": {
10:     "longest_edge": 12845056,
10:     "shortest_edge": 3136
10:   },
10:   "temporal_patch_size": 2
10: }
10: 
15: [INFO|tokenization_utils_base.py:2323] 2025-06-27 21:02:50,181 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
23: [INFO|tokenization_utils_base.py:2323] 2025-06-27 21:02:50,186 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
 1: [INFO|image_processing_base.py:380] 2025-06-27 21:02:50,189 >> loading configuration file preprocessor_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
 1: [INFO|image_processing_base.py:433] 2025-06-27 21:02:50,191 >> Image processor Qwen2VLImageProcessorFast {
 1:   "crop_size": null,
 1:   "data_format": "channels_first",
 1:   "default_to_square": true,
 1:   "device": null,
 1:   "do_center_crop": null,
 1:   "do_convert_rgb": true,
 1:   "do_normalize": true,
 1:   "do_rescale": true,
 1:   "do_resize": true,
 1:   "image_mean": [
 1:     0.48145466,
 1:     0.4578275,
 1:     0.40821073
 1:   ],
 1:   "image_processor_type": "Qwen2VLImageProcessorFast",
 1:   "image_std": [
 1:     0.26862954,
 1:     0.26130258,
 1:     0.27577711
 1:   ],
 1:   "input_data_format": null,
 1:   "max_pixels": 12845056,
 1:   "merge_size": 2,
 1:   "min_pixels": 3136,
 1:   "patch_size": 14,
 1:   "processor_class": "Qwen2_5_VLProcessor",
 1:   "resample": 3,
 1:   "rescale_factor": 0.00392156862745098,
 1:   "return_tensors": null,
 1:   "size": {
 1:     "longest_edge": 12845056,
 1:     "shortest_edge": 3136
 1:   },
 1:   "temporal_patch_size": 2
 1: }
 1: 
11: [INFO|2025-06-27 21:02:50] llamafactory.hparams.parser:406 >> Process rank: 44, world size: 128, device: cuda:0, distributed training: True, compute dtype: torch.bfloat16
13: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,200 >> loading file vocab.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
13: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,200 >> loading file merges.txt from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
13: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,200 >> loading file tokenizer.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
13: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,200 >> loading file added_tokens.json from cache at None
13: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,200 >> loading file special_tokens_map.json from cache at None
13: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,200 >> loading file tokenizer_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
13: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,200 >> loading file chat_template.jinja from cache at None
 8: [2025-06-27 21:02:50,205] [INFO] [comm.py:669:init_distributed] cdb=None
 8: [2025-06-27 21:02:50,205] [INFO] [comm.py:669:init_distributed] cdb=None
19: [INFO|tokenization_utils_base.py:2323] 2025-06-27 21:02:50,207 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
 8: [2025-06-27 21:02:50,208] [INFO] [comm.py:669:init_distributed] cdb=None
 8: [W627 21:02:50.936218603 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
 8: [W627 21:02:50.936428036 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
 8: [W627 21:02:50.938325703 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
22: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,213 >> loading file vocab.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
22: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,213 >> loading file merges.txt from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
22: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,213 >> loading file tokenizer.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
22: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,213 >> loading file added_tokens.json from cache at None
22: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,213 >> loading file special_tokens_map.json from cache at None
22: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,213 >> loading file tokenizer_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
22: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,213 >> loading file chat_template.jinja from cache at None
12: [2025-06-27 21:02:50,220] [INFO] [comm.py:669:init_distributed] cdb=None
12: [W627 21:02:50.264262201 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
12: [2025-06-27 21:02:50,229] [INFO] [comm.py:669:init_distributed] cdb=None
25: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,230 >> loading file vocab.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
25: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,230 >> loading file merges.txt from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
25: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,230 >> loading file tokenizer.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
25: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,230 >> loading file added_tokens.json from cache at None
25: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,230 >> loading file special_tokens_map.json from cache at None
25: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,230 >> loading file tokenizer_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
25: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,230 >> loading file chat_template.jinja from cache at None
12: [W627 21:02:50.274171925 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
 6: [2025-06-27 21:02:50,245] [INFO] [comm.py:669:init_distributed] cdb=None
 6: [2025-06-27 21:02:50,245] [INFO] [comm.py:669:init_distributed] cdb=None
 6: [2025-06-27 21:02:50,245] [INFO] [comm.py:669:init_distributed] cdb=None
 6: [W627 21:02:50.923833504 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
 6: [W627 21:02:50.923833600 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
 6: [W627 21:02:50.924032633 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
16: [INFO|2025-06-27 21:02:50] llamafactory.hparams.parser:406 >> Process rank: 64, world size: 128, device: cuda:0, distributed training: True, compute dtype: torch.bfloat16
 0: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,283 >> loading file vocab.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
 0: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,283 >> loading file merges.txt from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
 0: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,283 >> loading file tokenizer.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
 0: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,283 >> loading file added_tokens.json from cache at None
 0: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,283 >> loading file special_tokens_map.json from cache at None
 0: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,283 >> loading file tokenizer_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
 0: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,283 >> loading file chat_template.jinja from cache at None
27: [INFO|processing_utils.py:884] 2025-06-27 21:02:50,294 >> Processor Qwen2_5_VLProcessor:
27: - image_processor: Qwen2VLImageProcessorFast {
27:   "crop_size": null,
27:   "data_format": "channels_first",
27:   "default_to_square": true,
27:   "device": null,
27:   "do_center_crop": null,
27:   "do_convert_rgb": true,
27:   "do_normalize": true,
27:   "do_rescale": true,
27:   "do_resize": true,
27:   "image_mean": [
27:     0.48145466,
27:     0.4578275,
27:     0.40821073
27:   ],
27:   "image_processor_type": "Qwen2VLImageProcessorFast",
27:   "image_std": [
27:     0.26862954,
27:     0.26130258,
27:     0.27577711
27:   ],
27:   "input_data_format": null,
27:   "max_pixels": 12845056,
27:   "merge_size": 2,
27:   "min_pixels": 3136,
27:   "patch_size": 14,
27:   "processor_class": "Qwen2_5_VLProcessor",
27:   "resample": 3,
27:   "rescale_factor": 0.00392156862745098,
27:   "return_tensors": null,
27:   "size": {
27:     "longest_edge": 12845056,
27:     "shortest_edge": 3136
27:   },
27:   "temporal_patch_size": 2
27: }
27: 
27: - tokenizer: Qwen2TokenizerFast(name_or_path='Qwen/Qwen2.5-VL-7B-Instruct', vocab_size=151643, model_max_length=131072, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
27: 	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
27: 	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
27: 	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
27: 	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
27: 	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
27: 	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
27: 	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
27: 	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
27: 	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
27: 	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
27: 	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
27: 	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
27: 	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
27: 	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
27: 	151657: AddedToken("<tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
27: 	151658: AddedToken("</tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
27: 	151659: AddedToken("<|fim_prefix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
27: 	151660: AddedToken("<|fim_middle|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
27: 	151661: AddedToken("<|fim_suffix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
27: 	151662: AddedToken("<|fim_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
27: 	151663: AddedToken("<|repo_name|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
27: 	151664: AddedToken("<|file_sep|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
27: }
27: )
27: 
27: {
27:   "processor_class": "Qwen2_5_VLProcessor"
27: }
27: 
 2: [INFO|processing_utils.py:884] 2025-06-27 21:02:50,297 >> Processor Qwen2_5_VLProcessor:
 2: - image_processor: Qwen2VLImageProcessorFast {
 2:   "crop_size": null,
 2:   "data_format": "channels_first",
 2:   "default_to_square": true,
 2:   "device": null,
 2:   "do_center_crop": null,
 2:   "do_convert_rgb": true,
 2:   "do_normalize": true,
 2:   "do_rescale": true,
 2:   "do_resize": true,
 2:   "image_mean": [
 2:     0.48145466,
 2:     0.4578275,
 2:     0.40821073
 2:   ],
 2:   "image_processor_type": "Qwen2VLImageProcessorFast",
 2:   "image_std": [
 2:     0.26862954,
 2:     0.26130258,
 2:     0.27577711
 2:   ],
 2:   "input_data_format": null,
 2:   "max_pixels": 12845056,
 2:   "merge_size": 2,
 2:   "min_pixels": 3136,
 2:   "patch_size": 14,
 2:   "processor_class": "Qwen2_5_VLProcessor",
 2:   "resample": 3,
 2:   "rescale_factor": 0.00392156862745098,
 2:   "return_tensors": null,
 2:   "size": {
 2:     "longest_edge": 12845056,
 2:     "shortest_edge": 3136
 2:   },
 2:   "temporal_patch_size": 2
 2: }
 2: 
 2: - tokenizer: Qwen2TokenizerFast(name_or_path='Qwen/Qwen2.5-VL-7B-Instruct', vocab_size=151643, model_max_length=131072, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
 2: 	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 2: 	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 2: 	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 2: 	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 2: 	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 2: 	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 2: 	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 2: 	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 2: 	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 2: 	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 2: 	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 2: 	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 2: 	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 2: 	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 2: 	151657: AddedToken("<tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 2: 	151658: AddedToken("</tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 2: 	151659: AddedToken("<|fim_prefix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 2: 	151660: AddedToken("<|fim_middle|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 2: 	151661: AddedToken("<|fim_suffix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 2: 	151662: AddedToken("<|fim_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 2: 	151663: AddedToken("<|repo_name|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 2: 	151664: AddedToken("<|file_sep|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 2: }
 2: )
 2: 
 2: {
 2:   "processor_class": "Qwen2_5_VLProcessor"
 2: }
 2: 
10: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,299 >> loading file vocab.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
10: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,299 >> loading file merges.txt from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
10: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,299 >> loading file tokenizer.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
10: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,299 >> loading file added_tokens.json from cache at None
10: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,299 >> loading file special_tokens_map.json from cache at None
10: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,299 >> loading file tokenizer_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
10: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,299 >> loading file chat_template.jinja from cache at None
 4: [2025-06-27 21:02:50,307] [INFO] [comm.py:669:init_distributed] cdb=None
 4: [2025-06-27 21:02:50,308] [INFO] [comm.py:669:init_distributed] cdb=None
 4: [2025-06-27 21:02:50,308] [INFO] [comm.py:669:init_distributed] cdb=None
 3: [INFO|2025-06-27 21:02:50] llamafactory.hparams.parser:406 >> Process rank: 12, world size: 128, device: cuda:0, distributed training: True, compute dtype: torch.bfloat16
 4: [W627 21:02:50.954729450 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
 4: [W627 21:02:50.955039903 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
 4: [W627 21:02:50.955168379 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
 1: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,312 >> loading file vocab.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
 1: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,312 >> loading file merges.txt from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
 1: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,312 >> loading file tokenizer.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
 1: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,312 >> loading file added_tokens.json from cache at None
 1: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,312 >> loading file special_tokens_map.json from cache at None
 1: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,312 >> loading file tokenizer_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
 1: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,312 >> loading file chat_template.jinja from cache at None
27: [WARNING|2025-06-27 21:02:50] llamafactory.data.loader:148 >> Loading dataset from disk will ignore other data arguments.
 2: [WARNING|2025-06-27 21:02:50] llamafactory.data.loader:148 >> Loading dataset from disk will ignore other data arguments.
20: [2025-06-27 21:02:50,330] [INFO] [comm.py:669:init_distributed] cdb=None
20: [W627 21:02:50.146443604 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
 7: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,344 >> loading file vocab.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
 7: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,344 >> loading file merges.txt from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
 7: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,344 >> loading file tokenizer.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
 7: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,344 >> loading file added_tokens.json from cache at None
 7: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,344 >> loading file special_tokens_map.json from cache at None
 7: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,344 >> loading file tokenizer_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
 7: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,344 >> loading file chat_template.jinja from cache at None
30: [INFO|2025-06-27 21:02:50] llamafactory.hparams.parser:406 >> Process rank: 120, world size: 128, device: cuda:0, distributed training: True, compute dtype: torch.bfloat16
 8: [2025-06-27 21:02:50,355] [INFO] [comm.py:669:init_distributed] cdb=None
 8: [W627 21:02:50.086705722 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
30: [INFO|2025-06-27 21:02:50] llamafactory.hparams.parser:406 >> Process rank: 123, world size: 128, device: cuda:3, distributed training: True, compute dtype: torch.bfloat16
11: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,366 >> loading file vocab.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
11: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,367 >> loading file merges.txt from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
11: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,367 >> loading file tokenizer.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
11: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,367 >> loading file added_tokens.json from cache at None
11: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,367 >> loading file special_tokens_map.json from cache at None
11: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,367 >> loading file tokenizer_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
11: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,367 >> loading file chat_template.jinja from cache at None
 6: [2025-06-27 21:02:50,369] [INFO] [comm.py:669:init_distributed] cdb=None
13: [INFO|tokenization_utils_base.py:2323] 2025-06-27 21:02:50,371 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
 6: [W627 21:02:50.047073285 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
30: [INFO|2025-06-27 21:02:50] llamafactory.hparams.parser:406 >> Process rank: 121, world size: 128, device: cuda:1, distributed training: True, compute dtype: torch.bfloat16
 4: [2025-06-27 21:02:50,383] [INFO] [comm.py:669:init_distributed] cdb=None
 4: [W627 21:02:50.030916805 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
14: [2025-06-27 21:02:50,391] [INFO] [comm.py:669:init_distributed] cdb=None
14: [W627 21:02:50.713500066 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
 1: [2025-06-27 21:02:50,396] [INFO] [comm.py:669:init_distributed] cdb=None
 1: [2025-06-27 21:02:50,397] [INFO] [comm.py:669:init_distributed] cdb=None
 5: [INFO|image_processing_base.py:380] 2025-06-27 21:02:50,397 >> loading configuration file preprocessor_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
25: [INFO|tokenization_utils_base.py:2323] 2025-06-27 21:02:50,399 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
18: [2025-06-27 21:02:50,399] [INFO] [comm.py:669:init_distributed] cdb=None
18: [2025-06-27 21:02:50,399] [INFO] [comm.py:669:init_distributed] cdb=None
18: [2025-06-27 21:02:50,399] [INFO] [comm.py:669:init_distributed] cdb=None
 1: [W627 21:02:50.914637588 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
 1: [W627 21:02:50.915748499 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
18: [W627 21:02:50.976393917 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
18: [W627 21:02:50.976393981 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
18: [W627 21:02:50.976410813 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
22: [INFO|tokenization_utils_base.py:2323] 2025-06-27 21:02:50,402 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
17: [INFO|image_processing_base.py:380] 2025-06-27 21:02:50,404 >> loading configuration file preprocessor_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
26: [INFO|2025-06-27 21:02:50] llamafactory.hparams.parser:406 >> Process rank: 104, world size: 128, device: cuda:0, distributed training: True, compute dtype: torch.bfloat16
 9: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,461 >> loading file vocab.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
 9: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,461 >> loading file merges.txt from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
 9: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,461 >> loading file tokenizer.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
 9: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,461 >> loading file added_tokens.json from cache at None
 9: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,461 >> loading file special_tokens_map.json from cache at None
 9: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,461 >> loading file tokenizer_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
 9: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,461 >> loading file chat_template.jinja from cache at None
 0: [INFO|tokenization_utils_base.py:2323] 2025-06-27 21:02:50,464 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
10: [INFO|tokenization_utils_base.py:2323] 2025-06-27 21:02:50,465 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
 3: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,470 >> loading file vocab.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
 3: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,470 >> loading file merges.txt from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
 3: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,470 >> loading file tokenizer.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
 3: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,470 >> loading file added_tokens.json from cache at None
 3: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,470 >> loading file special_tokens_map.json from cache at None
 3: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,470 >> loading file tokenizer_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
 3: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,470 >> loading file chat_template.jinja from cache at None
 1: [INFO|tokenization_utils_base.py:2323] 2025-06-27 21:02:50,485 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
21: [INFO|image_processing_base.py:380] 2025-06-27 21:02:50,492 >> loading configuration file preprocessor_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
 7: [INFO|tokenization_utils_base.py:2323] 2025-06-27 21:02:50,513 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
30: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,516 >> loading file vocab.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
30: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,516 >> loading file merges.txt from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
30: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,516 >> loading file tokenizer.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
30: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,516 >> loading file added_tokens.json from cache at None
30: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,516 >> loading file special_tokens_map.json from cache at None
30: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,516 >> loading file tokenizer_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
30: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,516 >> loading file chat_template.jinja from cache at None
 5: [INFO|image_processing_base.py:380] 2025-06-27 21:02:50,520 >> loading configuration file preprocessor_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
 5: [INFO|image_processing_base.py:433] 2025-06-27 21:02:50,522 >> Image processor Qwen2VLImageProcessorFast {
 5:   "crop_size": null,
 5:   "data_format": "channels_first",
 5:   "default_to_square": true,
 5:   "device": null,
 5:   "do_center_crop": null,
 5:   "do_convert_rgb": true,
 5:   "do_normalize": true,
 5:   "do_rescale": true,
 5:   "do_resize": true,
 5:   "image_mean": [
 5:     0.48145466,
 5:     0.4578275,
 5:     0.40821073
 5:   ],
 5:   "image_processor_type": "Qwen2VLImageProcessorFast",
 5:   "image_std": [
 5:     0.26862954,
 5:     0.26130258,
 5:     0.27577711
 5:   ],
 5:   "input_data_format": null,
 5:   "max_pixels": 12845056,
 5:   "merge_size": 2,
 5:   "min_pixels": 3136,
 5:   "patch_size": 14,
 5:   "processor_class": "Qwen2_5_VLProcessor",
 5:   "resample": 3,
 5:   "rescale_factor": 0.00392156862745098,
 5:   "return_tensors": null,
 5:   "size": {
 5:     "longest_edge": 12845056,
 5:     "shortest_edge": 3136
 5:   },
 5:   "temporal_patch_size": 2
 5: }
 5: 
28: [INFO|image_processing_base.py:380] 2025-06-27 21:02:50,526 >> loading configuration file preprocessor_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
17: [INFO|image_processing_base.py:380] 2025-06-27 21:02:50,531 >> loading configuration file preprocessor_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
17: [INFO|image_processing_base.py:433] 2025-06-27 21:02:50,533 >> Image processor Qwen2VLImageProcessorFast {
17:   "crop_size": null,
17:   "data_format": "channels_first",
17:   "default_to_square": true,
17:   "device": null,
17:   "do_center_crop": null,
17:   "do_convert_rgb": true,
17:   "do_normalize": true,
17:   "do_rescale": true,
17:   "do_resize": true,
17:   "image_mean": [
17:     0.48145466,
17:     0.4578275,
17:     0.40821073
17:   ],
17:   "image_processor_type": "Qwen2VLImageProcessorFast",
17:   "image_std": [
17:     0.26862954,
17:     0.26130258,
17:     0.27577711
17:   ],
17:   "input_data_format": null,
17:   "max_pixels": 12845056,
17:   "merge_size": 2,
17:   "min_pixels": 3136,
17:   "patch_size": 14,
17:   "processor_class": "Qwen2_5_VLProcessor",
17:   "resample": 3,
17:   "rescale_factor": 0.00392156862745098,
17:   "return_tensors": null,
17:   "size": {
17:     "longest_edge": 12845056,
17:     "shortest_edge": 3136
17:   },
17:   "temporal_patch_size": 2
17: }
17: 
15: [INFO|image_processing_base.py:380] 2025-06-27 21:02:50,539 >> loading configuration file preprocessor_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
11: [INFO|tokenization_utils_base.py:2323] 2025-06-27 21:02:50,544 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
23: [INFO|image_processing_base.py:380] 2025-06-27 21:02:50,568 >> loading configuration file preprocessor_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
19: [INFO|image_processing_base.py:380] 2025-06-27 21:02:50,570 >> loading configuration file preprocessor_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
26: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,578 >> loading file vocab.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
26: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,578 >> loading file merges.txt from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
26: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,578 >> loading file tokenizer.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
26: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,578 >> loading file added_tokens.json from cache at None
26: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,578 >> loading file special_tokens_map.json from cache at None
26: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,578 >> loading file tokenizer_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
26: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,578 >> loading file chat_template.jinja from cache at None
21: [INFO|image_processing_base.py:380] 2025-06-27 21:02:50,619 >> loading configuration file preprocessor_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
21: [INFO|image_processing_base.py:433] 2025-06-27 21:02:50,621 >> Image processor Qwen2VLImageProcessorFast {
21:   "crop_size": null,
21:   "data_format": "channels_first",
21:   "default_to_square": true,
21:   "device": null,
21:   "do_center_crop": null,
21:   "do_convert_rgb": true,
21:   "do_normalize": true,
21:   "do_rescale": true,
21:   "do_resize": true,
21:   "image_mean": [
21:     0.48145466,
21:     0.4578275,
21:     0.40821073
21:   ],
21:   "image_processor_type": "Qwen2VLImageProcessorFast",
21:   "image_std": [
21:     0.26862954,
21:     0.26130258,
21:     0.27577711
21:   ],
21:   "input_data_format": null,
21:   "max_pixels": 12845056,
21:   "merge_size": 2,
21:   "min_pixels": 3136,
21:   "patch_size": 14,
21:   "processor_class": "Qwen2_5_VLProcessor",
21:   "resample": 3,
21:   "rescale_factor": 0.00392156862745098,
21:   "return_tensors": null,
21:   "size": {
21:     "longest_edge": 12845056,
21:     "shortest_edge": 3136
21:   },
21:   "temporal_patch_size": 2
21: }
21: 
 9: [INFO|tokenization_utils_base.py:2323] 2025-06-27 21:02:50,637 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
16: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,639 >> loading file vocab.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
16: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,639 >> loading file merges.txt from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
16: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,639 >> loading file tokenizer.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
16: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,639 >> loading file added_tokens.json from cache at None
16: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,639 >> loading file special_tokens_map.json from cache at None
16: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,639 >> loading file tokenizer_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
16: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,639 >> loading file chat_template.jinja from cache at None
 3: [INFO|tokenization_utils_base.py:2323] 2025-06-27 21:02:50,644 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
 5: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,644 >> loading file vocab.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
 5: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,644 >> loading file merges.txt from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
 5: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,644 >> loading file tokenizer.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
 5: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,644 >> loading file added_tokens.json from cache at None
 5: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,644 >> loading file special_tokens_map.json from cache at None
 5: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,644 >> loading file tokenizer_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
 5: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,644 >> loading file chat_template.jinja from cache at None
28: [INFO|image_processing_base.py:380] 2025-06-27 21:02:50,652 >> loading configuration file preprocessor_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
28: [INFO|image_processing_base.py:433] 2025-06-27 21:02:50,654 >> Image processor Qwen2VLImageProcessorFast {
28:   "crop_size": null,
28:   "data_format": "channels_first",
28:   "default_to_square": true,
28:   "device": null,
28:   "do_center_crop": null,
28:   "do_convert_rgb": true,
28:   "do_normalize": true,
28:   "do_rescale": true,
28:   "do_resize": true,
28:   "image_mean": [
28:     0.48145466,
28:     0.4578275,
28:     0.40821073
28:   ],
28:   "image_processor_type": "Qwen2VLImageProcessorFast",
28:   "image_std": [
28:     0.26862954,
28:     0.26130258,
28:     0.27577711
28:   ],
28:   "input_data_format": null,
28:   "max_pixels": 12845056,
28:   "merge_size": 2,
28:   "min_pixels": 3136,
28:   "patch_size": 14,
28:   "processor_class": "Qwen2_5_VLProcessor",
28:   "resample": 3,
28:   "rescale_factor": 0.00392156862745098,
28:   "return_tensors": null,
28:   "size": {
28:     "longest_edge": 12845056,
28:     "shortest_edge": 3136
28:   },
28:   "temporal_patch_size": 2
28: }
28: 
15: [INFO|image_processing_base.py:380] 2025-06-27 21:02:50,661 >> loading configuration file preprocessor_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
17: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,661 >> loading file vocab.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
17: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,661 >> loading file merges.txt from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
17: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,661 >> loading file tokenizer.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
17: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,661 >> loading file added_tokens.json from cache at None
17: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,661 >> loading file special_tokens_map.json from cache at None
17: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,661 >> loading file tokenizer_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
17: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,661 >> loading file chat_template.jinja from cache at None
15: [INFO|image_processing_base.py:433] 2025-06-27 21:02:50,663 >> Image processor Qwen2VLImageProcessorFast {
15:   "crop_size": null,
15:   "data_format": "channels_first",
15:   "default_to_square": true,
15:   "device": null,
15:   "do_center_crop": null,
15:   "do_convert_rgb": true,
15:   "do_normalize": true,
15:   "do_rescale": true,
15:   "do_resize": true,
15:   "image_mean": [
15:     0.48145466,
15:     0.4578275,
15:     0.40821073
15:   ],
15:   "image_processor_type": "Qwen2VLImageProcessorFast",
15:   "image_std": [
15:     0.26862954,
15:     0.26130258,
15:     0.27577711
15:   ],
15:   "input_data_format": null,
15:   "max_pixels": 12845056,
15:   "merge_size": 2,
15:   "min_pixels": 3136,
15:   "patch_size": 14,
15:   "processor_class": "Qwen2_5_VLProcessor",
15:   "resample": 3,
15:   "rescale_factor": 0.00392156862745098,
15:   "return_tensors": null,
15:   "size": {
15:     "longest_edge": 12845056,
15:     "shortest_edge": 3136
15:   },
15:   "temporal_patch_size": 2
15: }
15: 
29: [2025-06-27 21:02:50,671] [INFO] [comm.py:669:init_distributed] cdb=None
12: [INFO|2025-06-27 21:02:50] llamafactory.hparams.parser:406 >> Process rank: 48, world size: 128, device: cuda:0, distributed training: True, compute dtype: torch.bfloat16
29: [W627 21:02:50.279149876 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
23: [INFO|image_processing_base.py:380] 2025-06-27 21:02:50,689 >> loading configuration file preprocessor_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
23: [INFO|image_processing_base.py:433] 2025-06-27 21:02:50,691 >> Image processor Qwen2VLImageProcessorFast {
23:   "crop_size": null,
23:   "data_format": "channels_first",
23:   "default_to_square": true,
23:   "device": null,
23:   "do_center_crop": null,
23:   "do_convert_rgb": true,
23:   "do_normalize": true,
23:   "do_rescale": true,
23:   "do_resize": true,
23:   "image_mean": [
23:     0.48145466,
23:     0.4578275,
23:     0.40821073
23:   ],
23:   "image_processor_type": "Qwen2VLImageProcessorFast",
23:   "image_std": [
23:     0.26862954,
23:     0.26130258,
23:     0.27577711
23:   ],
23:   "input_data_format": null,
23:   "max_pixels": 12845056,
23:   "merge_size": 2,
23:   "min_pixels": 3136,
23:   "patch_size": 14,
23:   "processor_class": "Qwen2_5_VLProcessor",
23:   "resample": 3,
23:   "rescale_factor": 0.00392156862745098,
23:   "return_tensors": null,
23:   "size": {
23:     "longest_edge": 12845056,
23:     "shortest_edge": 3136
23:   },
23:   "temporal_patch_size": 2
23: }
23: 
30: [INFO|tokenization_utils_base.py:2323] 2025-06-27 21:02:50,691 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
19: [INFO|image_processing_base.py:380] 2025-06-27 21:02:50,692 >> loading configuration file preprocessor_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
19: [INFO|image_processing_base.py:433] 2025-06-27 21:02:50,694 >> Image processor Qwen2VLImageProcessorFast {
19:   "crop_size": null,
19:   "data_format": "channels_first",
19:   "default_to_square": true,
19:   "device": null,
19:   "do_center_crop": null,
19:   "do_convert_rgb": true,
19:   "do_normalize": true,
19:   "do_rescale": true,
19:   "do_resize": true,
19:   "image_mean": [
19:     0.48145466,
19:     0.4578275,
19:     0.40821073
19:   ],
19:   "image_processor_type": "Qwen2VLImageProcessorFast",
19:   "image_std": [
19:     0.26862954,
19:     0.26130258,
19:     0.27577711
19:   ],
19:   "input_data_format": null,
19:   "max_pixels": 12845056,
19:   "merge_size": 2,
19:   "min_pixels": 3136,
19:   "patch_size": 14,
19:   "processor_class": "Qwen2_5_VLProcessor",
19:   "resample": 3,
19:   "rescale_factor": 0.00392156862745098,
19:   "return_tensors": null,
19:   "size": {
19:     "longest_edge": 12845056,
19:     "shortest_edge": 3136
19:   },
19:   "temporal_patch_size": 2
19: }
19: 
31: [INFO|2025-06-27 21:02:50] llamafactory.hparams.parser:406 >> Process rank: 124, world size: 128, device: cuda:0, distributed training: True, compute dtype: torch.bfloat16
21: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,745 >> loading file vocab.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
21: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,746 >> loading file merges.txt from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
21: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,746 >> loading file tokenizer.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
21: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,746 >> loading file added_tokens.json from cache at None
21: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,746 >> loading file special_tokens_map.json from cache at None
21: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,746 >> loading file tokenizer_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
21: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,746 >> loading file chat_template.jinja from cache at None
26: [INFO|tokenization_utils_base.py:2323] 2025-06-27 21:02:50,751 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
28: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,773 >> loading file vocab.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
28: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,774 >> loading file merges.txt from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
28: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,774 >> loading file tokenizer.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
28: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,774 >> loading file added_tokens.json from cache at None
28: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,774 >> loading file special_tokens_map.json from cache at None
28: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,774 >> loading file tokenizer_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
28: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,774 >> loading file chat_template.jinja from cache at None
15: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,790 >> loading file vocab.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
15: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,790 >> loading file merges.txt from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
15: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,790 >> loading file tokenizer.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
15: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,790 >> loading file added_tokens.json from cache at None
15: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,790 >> loading file special_tokens_map.json from cache at None
15: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,790 >> loading file tokenizer_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
15: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,790 >> loading file chat_template.jinja from cache at None
 5: [INFO|2025-06-27 21:02:50] llamafactory.hparams.parser:406 >> Process rank: 22, world size: 128, device: cuda:2, distributed training: True, compute dtype: torch.bfloat16
23: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,813 >> loading file vocab.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
23: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,813 >> loading file merges.txt from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
23: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,813 >> loading file tokenizer.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
23: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,813 >> loading file added_tokens.json from cache at None
23: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,813 >> loading file special_tokens_map.json from cache at None
23: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,813 >> loading file tokenizer_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
23: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,813 >> loading file chat_template.jinja from cache at None
16: [INFO|tokenization_utils_base.py:2323] 2025-06-27 21:02:50,815 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
 5: [INFO|2025-06-27 21:02:50] llamafactory.hparams.parser:406 >> Process rank: 21, world size: 128, device: cuda:1, distributed training: True, compute dtype: torch.bfloat16
 0: [INFO|image_processing_base.py:380] 2025-06-27 21:02:50,819 >> loading configuration file preprocessor_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
 5: [INFO|tokenization_utils_base.py:2323] 2025-06-27 21:02:50,819 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
22: [INFO|image_processing_base.py:380] 2025-06-27 21:02:50,831 >> loading configuration file preprocessor_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
17: [INFO|tokenization_utils_base.py:2323] 2025-06-27 21:02:50,833 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
19: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,835 >> loading file vocab.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
19: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,835 >> loading file merges.txt from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
19: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,835 >> loading file tokenizer.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
19: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,835 >> loading file added_tokens.json from cache at None
19: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,835 >> loading file special_tokens_map.json from cache at None
19: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,835 >> loading file tokenizer_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
19: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,835 >> loading file chat_template.jinja from cache at None
17: [INFO|2025-06-27 21:02:50] llamafactory.hparams.parser:406 >> Process rank: 69, world size: 128, device: cuda:1, distributed training: True, compute dtype: torch.bfloat16
17: [INFO|2025-06-27 21:02:50] llamafactory.hparams.parser:406 >> Process rank: 70, world size: 128, device: cuda:2, distributed training: True, compute dtype: torch.bfloat16
12: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,855 >> loading file vocab.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
12: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,855 >> loading file merges.txt from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
12: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,855 >> loading file tokenizer.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
12: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,855 >> loading file added_tokens.json from cache at None
12: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,855 >> loading file special_tokens_map.json from cache at None
12: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,855 >> loading file tokenizer_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
12: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,855 >> loading file chat_template.jinja from cache at None
14: [INFO|2025-06-27 21:02:50] llamafactory.hparams.parser:406 >> Process rank: 56, world size: 128, device: cuda:0, distributed training: True, compute dtype: torch.bfloat16
18: [2025-06-27 21:02:50,892] [INFO] [comm.py:669:init_distributed] cdb=None
20: [INFO|2025-06-27 21:02:50] llamafactory.hparams.parser:406 >> Process rank: 80, world size: 128, device: cuda:0, distributed training: True, compute dtype: torch.bfloat16
18: [W627 21:02:50.470033663 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
31: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,900 >> loading file vocab.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
31: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,900 >> loading file merges.txt from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
31: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,900 >> loading file tokenizer.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
31: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,900 >> loading file added_tokens.json from cache at None
31: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,900 >> loading file special_tokens_map.json from cache at None
31: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,900 >> loading file tokenizer_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
31: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:50,900 >> loading file chat_template.jinja from cache at None
 7: [INFO|image_processing_base.py:380] 2025-06-27 21:02:50,906 >> loading configuration file preprocessor_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
11: [INFO|image_processing_base.py:380] 2025-06-27 21:02:50,909 >> loading configuration file preprocessor_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
21: [INFO|tokenization_utils_base.py:2323] 2025-06-27 21:02:50,918 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
 8: [INFO|2025-06-27 21:02:50] llamafactory.hparams.parser:406 >> Process rank: 32, world size: 128, device: cuda:0, distributed training: True, compute dtype: torch.bfloat16
28: [INFO|tokenization_utils_base.py:2323] 2025-06-27 21:02:50,940 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
15: [INFO|2025-06-27 21:02:50] llamafactory.hparams.parser:406 >> Process rank: 62, world size: 128, device: cuda:2, distributed training: True, compute dtype: torch.bfloat16
 0: [INFO|image_processing_base.py:380] 2025-06-27 21:02:50,947 >> loading configuration file preprocessor_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
 0: [INFO|image_processing_base.py:433] 2025-06-27 21:02:50,949 >> Image processor Qwen2VLImageProcessorFast {
 0:   "crop_size": null,
 0:   "data_format": "channels_first",
 0:   "default_to_square": true,
 0:   "device": null,
 0:   "do_center_crop": null,
 0:   "do_convert_rgb": true,
 0:   "do_normalize": true,
 0:   "do_rescale": true,
 0:   "do_resize": true,
 0:   "image_mean": [
 0:     0.48145466,
 0:     0.4578275,
 0:     0.40821073
 0:   ],
 0:   "image_processor_type": "Qwen2VLImageProcessorFast",
 0:   "image_std": [
 0:     0.26862954,
 0:     0.26130258,
 0:     0.27577711
 0:   ],
 0:   "input_data_format": null,
 0:   "max_pixels": 12845056,
 0:   "merge_size": 2,
 0:   "min_pixels": 3136,
 0:   "patch_size": 14,
 0:   "processor_class": "Qwen2_5_VLProcessor",
 0:   "resample": 3,
 0:   "rescale_factor": 0.00392156862745098,
 0:   "return_tensors": null,
 0:   "size": {
 0:     "longest_edge": 12845056,
 0:     "shortest_edge": 3136
 0:   },
 0:   "temporal_patch_size": 2
 0: }
 0: 
27: [INFO|2025-06-27 21:02:50] llamafactory.hparams.parser:406 >> Process rank: 109, world size: 128, device: cuda:1, distributed training: True, compute dtype: torch.bfloat16
22: [INFO|image_processing_base.py:380] 2025-06-27 21:02:50,952 >> loading configuration file preprocessor_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
22: [INFO|image_processing_base.py:433] 2025-06-27 21:02:50,954 >> Image processor Qwen2VLImageProcessorFast {
22:   "crop_size": null,
22:   "data_format": "channels_first",
22:   "default_to_square": true,
22:   "device": null,
22:   "do_center_crop": null,
22:   "do_convert_rgb": true,
22:   "do_normalize": true,
22:   "do_rescale": true,
22:   "do_resize": true,
22:   "image_mean": [
22:     0.48145466,
22:     0.4578275,
22:     0.40821073
22:   ],
22:   "image_processor_type": "Qwen2VLImageProcessorFast",
22:   "image_std": [
22:     0.26862954,
22:     0.26130258,
22:     0.27577711
22:   ],
22:   "input_data_format": null,
22:   "max_pixels": 12845056,
22:   "merge_size": 2,
22:   "min_pixels": 3136,
22:   "patch_size": 14,
22:   "processor_class": "Qwen2_5_VLProcessor",
22:   "resample": 3,
22:   "rescale_factor": 0.00392156862745098,
22:   "return_tensors": null,
22:   "size": {
22:     "longest_edge": 12845056,
22:     "shortest_edge": 3136
22:   },
22:   "temporal_patch_size": 2
22: }
22: 
15: [INFO|tokenization_utils_base.py:2323] 2025-06-27 21:02:50,970 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
15: [INFO|2025-06-27 21:02:50] llamafactory.hparams.parser:406 >> Process rank: 63, world size: 128, device: cuda:3, distributed training: True, compute dtype: torch.bfloat16
23: [INFO|2025-06-27 21:02:50] llamafactory.hparams.parser:406 >> Process rank: 93, world size: 128, device: cuda:1, distributed training: True, compute dtype: torch.bfloat16
23: [INFO|2025-06-27 21:02:50] llamafactory.hparams.parser:406 >> Process rank: 94, world size: 128, device: cuda:2, distributed training: True, compute dtype: torch.bfloat16
23: [INFO|tokenization_utils_base.py:2323] 2025-06-27 21:02:50,984 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
 2: [INFO|2025-06-27 21:02:51] llamafactory.hparams.parser:406 >> Process rank: 9, world size: 128, device: cuda:1, distributed training: True, compute dtype: torch.bfloat16
 3: [INFO|image_processing_base.py:380] 2025-06-27 21:02:51,005 >> loading configuration file preprocessor_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
 6: [INFO|2025-06-27 21:02:51] llamafactory.hparams.parser:406 >> Process rank: 24, world size: 128, device: cuda:0, distributed training: True, compute dtype: torch.bfloat16
19: [INFO|tokenization_utils_base.py:2323] 2025-06-27 21:02:51,012 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
 4: [INFO|2025-06-27 21:02:51] llamafactory.hparams.parser:406 >> Process rank: 16, world size: 128, device: cuda:0, distributed training: True, compute dtype: torch.bfloat16
11: [INFO|image_processing_base.py:380] 2025-06-27 21:02:51,028 >> loading configuration file preprocessor_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
 7: [INFO|image_processing_base.py:380] 2025-06-27 21:02:51,028 >> loading configuration file preprocessor_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
11: [INFO|image_processing_base.py:433] 2025-06-27 21:02:51,030 >> Image processor Qwen2VLImageProcessorFast {
11:   "crop_size": null,
11:   "data_format": "channels_first",
11:   "default_to_square": true,
11:   "device": null,
11:   "do_center_crop": null,
11:   "do_convert_rgb": true,
11:   "do_normalize": true,
11:   "do_rescale": true,
11:   "do_resize": true,
11:   "image_mean": [
11:     0.48145466,
11:     0.4578275,
11:     0.40821073
11:   ],
11:   "image_processor_type": "Qwen2VLImageProcessorFast",
11:   "image_std": [
11:     0.26862954,
11:     0.26130258,
11:     0.27577711
11:   ],
11:   "input_data_format": null,
11:   "max_pixels": 12845056,
11:   "merge_size": 2,
11:   "min_pixels": 3136,
11:   "patch_size": 14,
11:   "processor_class": "Qwen2_5_VLProcessor",
11:   "resample": 3,
11:   "rescale_factor": 0.00392156862745098,
11:   "return_tensors": null,
11:   "size": {
11:     "longest_edge": 12845056,
11:     "shortest_edge": 3136
11:   },
11:   "temporal_patch_size": 2
11: }
11: 
 7: [INFO|image_processing_base.py:433] 2025-06-27 21:02:51,030 >> Image processor Qwen2VLImageProcessorFast {
 7:   "crop_size": null,
 7:   "data_format": "channels_first",
 7:   "default_to_square": true,
 7:   "device": null,
 7:   "do_center_crop": null,
 7:   "do_convert_rgb": true,
 7:   "do_normalize": true,
 7:   "do_rescale": true,
 7:   "do_resize": true,
 7:   "image_mean": [
 7:     0.48145466,
 7:     0.4578275,
 7:     0.40821073
 7:   ],
 7:   "image_processor_type": "Qwen2VLImageProcessorFast",
 7:   "image_std": [
 7:     0.26862954,
 7:     0.26130258,
 7:     0.27577711
 7:   ],
 7:   "input_data_format": null,
 7:   "max_pixels": 12845056,
 7:   "merge_size": 2,
 7:   "min_pixels": 3136,
 7:   "patch_size": 14,
 7:   "processor_class": "Qwen2_5_VLProcessor",
 7:   "resample": 3,
 7:   "rescale_factor": 0.00392156862745098,
 7:   "return_tensors": null,
 7:   "size": {
 7:     "longest_edge": 12845056,
 7:     "shortest_edge": 3136
 7:   },
 7:   "temporal_patch_size": 2
 7: }
 7: 
12: [INFO|tokenization_utils_base.py:2323] 2025-06-27 21:02:51,030 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
30: [INFO|image_processing_base.py:380] 2025-06-27 21:02:51,050 >> loading configuration file preprocessor_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
14: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,053 >> loading file vocab.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
14: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,053 >> loading file merges.txt from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
14: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,053 >> loading file tokenizer.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
14: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,053 >> loading file added_tokens.json from cache at None
14: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,053 >> loading file special_tokens_map.json from cache at None
14: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,053 >> loading file tokenizer_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
14: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,053 >> loading file chat_template.jinja from cache at None
20: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,057 >> loading file vocab.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
20: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,057 >> loading file merges.txt from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
20: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,057 >> loading file tokenizer.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
20: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,057 >> loading file added_tokens.json from cache at None
20: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,057 >> loading file special_tokens_map.json from cache at None
20: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,057 >> loading file tokenizer_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
20: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,057 >> loading file chat_template.jinja from cache at None
13: [INFO|processing_utils.py:884] 2025-06-27 21:02:51,060 >> Processor Qwen2_5_VLProcessor:
13: - image_processor: Qwen2VLImageProcessorFast {
13:   "crop_size": null,
13:   "data_format": "channels_first",
13:   "default_to_square": true,
13:   "device": null,
13:   "do_center_crop": null,
13:   "do_convert_rgb": true,
13:   "do_normalize": true,
13:   "do_rescale": true,
13:   "do_resize": true,
13:   "image_mean": [
13:     0.48145466,
13:     0.4578275,
13:     0.40821073
13:   ],
13:   "image_processor_type": "Qwen2VLImageProcessorFast",
13:   "image_std": [
13:     0.26862954,
13:     0.26130258,
13:     0.27577711
13:   ],
13:   "input_data_format": null,
13:   "max_pixels": 12845056,
13:   "merge_size": 2,
13:   "min_pixels": 3136,
13:   "patch_size": 14,
13:   "processor_class": "Qwen2_5_VLProcessor",
13:   "resample": 3,
13:   "rescale_factor": 0.00392156862745098,
13:   "return_tensors": null,
13:   "size": {
13:     "longest_edge": 12845056,
13:     "shortest_edge": 3136
13:   },
13:   "temporal_patch_size": 2
13: }
13: 
13: - tokenizer: Qwen2TokenizerFast(name_or_path='Qwen/Qwen2.5-VL-7B-Instruct', vocab_size=151643, model_max_length=131072, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
13: 	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
13: 	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
13: 	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
13: 	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
13: 	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
13: 	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
13: 	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
13: 	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
13: 	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
13: 	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
13: 	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
13: 	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
13: 	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
13: 	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
13: 	151657: AddedToken("<tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
13: 	151658: AddedToken("</tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
13: 	151659: AddedToken("<|fim_prefix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
13: 	151660: AddedToken("<|fim_middle|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
13: 	151661: AddedToken("<|fim_suffix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
13: 	151662: AddedToken("<|fim_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
13: 	151663: AddedToken("<|repo_name|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
13: 	151664: AddedToken("<|file_sep|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
13: }
13: )
13: 
13: {
13:   "processor_class": "Qwen2_5_VLProcessor"
13: }
13: 
31: [INFO|tokenization_utils_base.py:2323] 2025-06-27 21:02:51,066 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
 0: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,071 >> loading file vocab.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
 0: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,071 >> loading file merges.txt from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
 0: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,071 >> loading file tokenizer.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
 0: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,071 >> loading file added_tokens.json from cache at None
 0: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,071 >> loading file special_tokens_map.json from cache at None
 0: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,071 >> loading file tokenizer_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
 0: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,071 >> loading file chat_template.jinja from cache at None
22: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,077 >> loading file vocab.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
22: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,077 >> loading file merges.txt from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
22: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,077 >> loading file tokenizer.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
22: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,077 >> loading file added_tokens.json from cache at None
22: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,077 >> loading file special_tokens_map.json from cache at None
22: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,077 >> loading file tokenizer_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
22: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,077 >> loading file chat_template.jinja from cache at None
13: [WARNING|2025-06-27 21:02:51] llamafactory.data.loader:148 >> Loading dataset from disk will ignore other data arguments.
25: [INFO|processing_utils.py:884] 2025-06-27 21:02:51,092 >> Processor Qwen2_5_VLProcessor:
25: - image_processor: Qwen2VLImageProcessorFast {
25:   "crop_size": null,
25:   "data_format": "channels_first",
25:   "default_to_square": true,
25:   "device": null,
25:   "do_center_crop": null,
25:   "do_convert_rgb": true,
25:   "do_normalize": true,
25:   "do_rescale": true,
25:   "do_resize": true,
25:   "image_mean": [
25:     0.48145466,
25:     0.4578275,
25:     0.40821073
25:   ],
25:   "image_processor_type": "Qwen2VLImageProcessorFast",
25:   "image_std": [
25:     0.26862954,
25:     0.26130258,
25:     0.27577711
25:   ],
25:   "input_data_format": null,
25:   "max_pixels": 12845056,
25:   "merge_size": 2,
25:   "min_pixels": 3136,
25:   "patch_size": 14,
25:   "processor_class": "Qwen2_5_VLProcessor",
25:   "resample": 3,
25:   "rescale_factor": 0.00392156862745098,
25:   "return_tensors": null,
25:   "size": {
25:     "longest_edge": 12845056,
25:     "shortest_edge": 3136
25:   },
25:   "temporal_patch_size": 2
25: }
25: 
25: - tokenizer: Qwen2TokenizerFast(name_or_path='Qwen/Qwen2.5-VL-7B-Instruct', vocab_size=151643, model_max_length=131072, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
25: 	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
25: 	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
25: 	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
25: 	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
25: 	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
25: 	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
25: 	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
25: 	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
25: 	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
25: 	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
25: 	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
25: 	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
25: 	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
25: 	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
25: 	151657: AddedToken("<tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
25: 	151658: AddedToken("</tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
25: 	151659: AddedToken("<|fim_prefix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
25: 	151660: AddedToken("<|fim_middle|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
25: 	151661: AddedToken("<|fim_suffix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
25: 	151662: AddedToken("<|fim_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
25: 	151663: AddedToken("<|repo_name|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
25: 	151664: AddedToken("<|file_sep|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
25: }
25: )
25: 
25: {
25:   "processor_class": "Qwen2_5_VLProcessor"
25: }
25: 
 8: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,096 >> loading file vocab.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
 8: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,096 >> loading file merges.txt from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
 8: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,096 >> loading file tokenizer.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
 8: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,096 >> loading file added_tokens.json from cache at None
 8: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,096 >> loading file special_tokens_map.json from cache at None
 8: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,096 >> loading file tokenizer_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
 8: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,096 >> loading file chat_template.jinja from cache at None
26: [INFO|image_processing_base.py:380] 2025-06-27 21:02:51,108 >> loading configuration file preprocessor_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
29: [INFO|2025-06-27 21:02:51] llamafactory.hparams.parser:406 >> Process rank: 116, world size: 128, device: cuda:0, distributed training: True, compute dtype: torch.bfloat16
25: [WARNING|2025-06-27 21:02:51] llamafactory.data.loader:148 >> Loading dataset from disk will ignore other data arguments.
10: [INFO|processing_utils.py:884] 2025-06-27 21:02:51,124 >> Processor Qwen2_5_VLProcessor:
10: - image_processor: Qwen2VLImageProcessorFast {
10:   "crop_size": null,
10:   "data_format": "channels_first",
10:   "default_to_square": true,
10:   "device": null,
10:   "do_center_crop": null,
10:   "do_convert_rgb": true,
10:   "do_normalize": true,
10:   "do_rescale": true,
10:   "do_resize": true,
10:   "image_mean": [
10:     0.48145466,
10:     0.4578275,
10:     0.40821073
10:   ],
10:   "image_processor_type": "Qwen2VLImageProcessorFast",
10:   "image_std": [
10:     0.26862954,
10:     0.26130258,
10:     0.27577711
10:   ],
10:   "input_data_format": null,
10:   "max_pixels": 12845056,
10:   "merge_size": 2,
10:   "min_pixels": 3136,
10:   "patch_size": 14,
10:   "processor_class": "Qwen2_5_VLProcessor",
10:   "resample": 3,
10:   "rescale_factor": 0.00392156862745098,
10:   "return_tensors": null,
10:   "size": {
10:     "longest_edge": 12845056,
10:     "shortest_edge": 3136
10:   },
10:   "temporal_patch_size": 2
10: }
10: 
10: - tokenizer: Qwen2TokenizerFast(name_or_path='Qwen/Qwen2.5-VL-7B-Instruct', vocab_size=151643, model_max_length=131072, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
10: 	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
10: 	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
10: 	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
10: 	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
10: 	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
10: 	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
10: 	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
10: 	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
10: 	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
10: 	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
10: 	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
10: 	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
10: 	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
10: 	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
10: 	151657: AddedToken("<tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
10: 	151658: AddedToken("</tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
10: 	151659: AddedToken("<|fim_prefix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
10: 	151660: AddedToken("<|fim_middle|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
10: 	151661: AddedToken("<|fim_suffix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
10: 	151662: AddedToken("<|fim_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
10: 	151663: AddedToken("<|repo_name|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
10: 	151664: AddedToken("<|file_sep|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
10: }
10: )
10: 
10: {
10:   "processor_class": "Qwen2_5_VLProcessor"
10: }
10: 
 5: [INFO|2025-06-27 21:02:51] llamafactory.hparams.parser:406 >> Process rank: 23, world size: 128, device: cuda:3, distributed training: True, compute dtype: torch.bfloat16
 3: [INFO|image_processing_base.py:380] 2025-06-27 21:02:51,128 >> loading configuration file preprocessor_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
 3: [INFO|image_processing_base.py:433] 2025-06-27 21:02:51,130 >> Image processor Qwen2VLImageProcessorFast {
 3:   "crop_size": null,
 3:   "data_format": "channels_first",
 3:   "default_to_square": true,
 3:   "device": null,
 3:   "do_center_crop": null,
 3:   "do_convert_rgb": true,
 3:   "do_normalize": true,
 3:   "do_rescale": true,
 3:   "do_resize": true,
 3:   "image_mean": [
 3:     0.48145466,
 3:     0.4578275,
 3:     0.40821073
 3:   ],
 3:   "image_processor_type": "Qwen2VLImageProcessorFast",
 3:   "image_std": [
 3:     0.26862954,
 3:     0.26130258,
 3:     0.27577711
 3:   ],
 3:   "input_data_format": null,
 3:   "max_pixels": 12845056,
 3:   "merge_size": 2,
 3:   "min_pixels": 3136,
 3:   "patch_size": 14,
 3:   "processor_class": "Qwen2_5_VLProcessor",
 3:   "resample": 3,
 3:   "rescale_factor": 0.00392156862745098,
 3:   "return_tensors": null,
 3:   "size": {
 3:     "longest_edge": 12845056,
 3:     "shortest_edge": 3136
 3:   },
 3:   "temporal_patch_size": 2
 3: }
 3: 
11: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,152 >> loading file vocab.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
10: [WARNING|2025-06-27 21:02:51] llamafactory.data.loader:148 >> Loading dataset from disk will ignore other data arguments.
11: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,152 >> loading file merges.txt from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
11: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,152 >> loading file tokenizer.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
11: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,152 >> loading file added_tokens.json from cache at None
11: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,152 >> loading file special_tokens_map.json from cache at None
11: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,152 >> loading file tokenizer_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
11: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,152 >> loading file chat_template.jinja from cache at None
 1: [INFO|processing_utils.py:884] 2025-06-27 21:02:51,156 >> Processor Qwen2_5_VLProcessor:
 1: - image_processor: Qwen2VLImageProcessorFast {
 1:   "crop_size": null,
 1:   "data_format": "channels_first",
 1:   "default_to_square": true,
 1:   "device": null,
 1:   "do_center_crop": null,
 1:   "do_convert_rgb": true,
 1:   "do_normalize": true,
 1:   "do_rescale": true,
 1:   "do_resize": true,
 1:   "image_mean": [
 1:     0.48145466,
 1:     0.4578275,
 1:     0.40821073
 1:   ],
 1:   "image_processor_type": "Qwen2VLImageProcessorFast",
 1:   "image_std": [
 1:     0.26862954,
 1:     0.26130258,
 1:     0.27577711
 1:   ],
 1:   "input_data_format": null,
 1:   "max_pixels": 12845056,
 1:   "merge_size": 2,
 1:   "min_pixels": 3136,
 1:   "patch_size": 14,
 1:   "processor_class": "Qwen2_5_VLProcessor",
 1:   "resample": 3,
 1:   "rescale_factor": 0.00392156862745098,
 1:   "return_tensors": null,
 1:   "size": {
 1:     "longest_edge": 12845056,
 1:     "shortest_edge": 3136
 1:   },
 1:   "temporal_patch_size": 2
 1: }
 1: 
 1: - tokenizer: Qwen2TokenizerFast(name_or_path='Qwen/Qwen2.5-VL-7B-Instruct', vocab_size=151643, model_max_length=131072, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
 1: 	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 1: 	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 1: 	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 1: 	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 1: 	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 1: 	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 1: 	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 1: 	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 1: 	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 1: 	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 1: 	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 1: 	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 1: 	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 1: 	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 1: 	151657: AddedToken("<tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 1: 	151658: AddedToken("</tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 1: 	151659: AddedToken("<|fim_prefix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 1: 	151660: AddedToken("<|fim_middle|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 1: 	151661: AddedToken("<|fim_suffix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 1: 	151662: AddedToken("<|fim_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 1: 	151663: AddedToken("<|repo_name|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 1: 	151664: AddedToken("<|file_sep|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 1: }
 1: )
 1: 
 1: {
 1:   "processor_class": "Qwen2_5_VLProcessor"
 1: }
 1: 
 7: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,158 >> loading file vocab.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
 7: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,158 >> loading file merges.txt from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
 7: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,158 >> loading file tokenizer.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
 7: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,158 >> loading file added_tokens.json from cache at None
 7: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,158 >> loading file special_tokens_map.json from cache at None
 7: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,158 >> loading file tokenizer_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
 7: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,158 >> loading file chat_template.jinja from cache at None
30: [INFO|image_processing_base.py:380] 2025-06-27 21:02:51,168 >> loading configuration file preprocessor_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
30: [INFO|image_processing_base.py:433] 2025-06-27 21:02:51,170 >> Image processor Qwen2VLImageProcessorFast {
30:   "crop_size": null,
30:   "data_format": "channels_first",
30:   "default_to_square": true,
30:   "device": null,
30:   "do_center_crop": null,
30:   "do_convert_rgb": true,
30:   "do_normalize": true,
30:   "do_rescale": true,
30:   "do_resize": true,
30:   "image_mean": [
30:     0.48145466,
30:     0.4578275,
30:     0.40821073
30:   ],
30:   "image_processor_type": "Qwen2VLImageProcessorFast",
30:   "image_std": [
30:     0.26862954,
30:     0.26130258,
30:     0.27577711
30:   ],
30:   "input_data_format": null,
30:   "max_pixels": 12845056,
30:   "merge_size": 2,
30:   "min_pixels": 3136,
30:   "patch_size": 14,
30:   "processor_class": "Qwen2_5_VLProcessor",
30:   "resample": 3,
30:   "rescale_factor": 0.00392156862745098,
30:   "return_tensors": null,
30:   "size": {
30:     "longest_edge": 12845056,
30:     "shortest_edge": 3136
30:   },
30:   "temporal_patch_size": 2
30: }
30: 
 6: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,172 >> loading file vocab.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
 6: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,172 >> loading file merges.txt from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
 6: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,172 >> loading file tokenizer.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
 6: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,172 >> loading file added_tokens.json from cache at None
 6: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,172 >> loading file special_tokens_map.json from cache at None
 6: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,172 >> loading file tokenizer_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
 6: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,172 >> loading file chat_template.jinja from cache at None
 4: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,182 >> loading file vocab.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
 4: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,182 >> loading file merges.txt from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
 4: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,182 >> loading file tokenizer.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
 4: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,182 >> loading file added_tokens.json from cache at None
 4: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,182 >> loading file special_tokens_map.json from cache at None
 4: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,182 >> loading file tokenizer_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
 4: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,182 >> loading file chat_template.jinja from cache at None
 1: [WARNING|2025-06-27 21:02:51] llamafactory.data.loader:148 >> Loading dataset from disk will ignore other data arguments.
24: [2025-06-27 21:02:51,197] [INFO] [comm.py:669:init_distributed] cdb=None
16: [INFO|image_processing_base.py:380] 2025-06-27 21:02:51,198 >> loading configuration file preprocessor_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
17: [INFO|2025-06-27 21:02:51] llamafactory.hparams.parser:406 >> Process rank: 71, world size: 128, device: cuda:3, distributed training: True, compute dtype: torch.bfloat16
24: [W627 21:02:51.122591500 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
18: [INFO|2025-06-27 21:02:51] llamafactory.hparams.parser:406 >> Process rank: 72, world size: 128, device: cuda:0, distributed training: True, compute dtype: torch.bfloat16
14: [INFO|tokenization_utils_base.py:2323] 2025-06-27 21:02:51,226 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
20: [INFO|tokenization_utils_base.py:2323] 2025-06-27 21:02:51,228 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
26: [INFO|image_processing_base.py:380] 2025-06-27 21:02:51,231 >> loading configuration file preprocessor_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
26: [INFO|image_processing_base.py:433] 2025-06-27 21:02:51,232 >> Image processor Qwen2VLImageProcessorFast {
26:   "crop_size": null,
26:   "data_format": "channels_first",
26:   "default_to_square": true,
26:   "device": null,
26:   "do_center_crop": null,
26:   "do_convert_rgb": true,
26:   "do_normalize": true,
26:   "do_rescale": true,
26:   "do_resize": true,
26:   "image_mean": [
26:     0.48145466,
26:     0.4578275,
26:     0.40821073
26:   ],
26:   "image_processor_type": "Qwen2VLImageProcessorFast",
26:   "image_std": [
26:     0.26862954,
26:     0.26130258,
26:     0.27577711
26:   ],
26:   "input_data_format": null,
26:   "max_pixels": 12845056,
26:   "merge_size": 2,
26:   "min_pixels": 3136,
26:   "patch_size": 14,
26:   "processor_class": "Qwen2_5_VLProcessor",
26:   "resample": 3,
26:   "rescale_factor": 0.00392156862745098,
26:   "return_tensors": null,
26:   "size": {
26:     "longest_edge": 12845056,
26:     "shortest_edge": 3136
26:   },
26:   "temporal_patch_size": 2
26: }
26: 
 0: [INFO|tokenization_utils_base.py:2323] 2025-06-27 21:02:51,245 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
 3: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,250 >> loading file vocab.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
 3: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,250 >> loading file merges.txt from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
 3: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,250 >> loading file tokenizer.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
 3: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,250 >> loading file added_tokens.json from cache at None
 3: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,250 >> loading file special_tokens_map.json from cache at None
 3: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,250 >> loading file tokenizer_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
 3: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,250 >> loading file chat_template.jinja from cache at None
22: [INFO|tokenization_utils_base.py:2323] 2025-06-27 21:02:51,258 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
 8: [INFO|tokenization_utils_base.py:2323] 2025-06-27 21:02:51,278 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
29: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,281 >> loading file vocab.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
29: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,281 >> loading file merges.txt from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
29: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,281 >> loading file tokenizer.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
29: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,281 >> loading file added_tokens.json from cache at None
29: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,281 >> loading file special_tokens_map.json from cache at None
29: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,281 >> loading file tokenizer_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
29: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,281 >> loading file chat_template.jinja from cache at None
30: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,290 >> loading file vocab.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
30: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,290 >> loading file merges.txt from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
30: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,290 >> loading file tokenizer.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
30: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,290 >> loading file added_tokens.json from cache at None
30: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,290 >> loading file special_tokens_map.json from cache at None
30: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,290 >> loading file tokenizer_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
30: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,290 >> loading file chat_template.jinja from cache at None
 9: [INFO|processing_utils.py:884] 2025-06-27 21:02:51,303 >> Processor Qwen2_5_VLProcessor:
 9: - image_processor: Qwen2VLImageProcessorFast {
 9:   "crop_size": null,
 9:   "data_format": "channels_first",
 9:   "default_to_square": true,
 9:   "device": null,
 9:   "do_center_crop": null,
 9:   "do_convert_rgb": true,
 9:   "do_normalize": true,
 9:   "do_rescale": true,
 9:   "do_resize": true,
 9:   "image_mean": [
 9:     0.48145466,
 9:     0.4578275,
 9:     0.40821073
 9:   ],
 9:   "image_processor_type": "Qwen2VLImageProcessorFast",
 9:   "image_std": [
 9:     0.26862954,
 9:     0.26130258,
 9:     0.27577711
 9:   ],
 9:   "input_data_format": null,
 9:   "max_pixels": 12845056,
 9:   "merge_size": 2,
 9:   "min_pixels": 3136,
 9:   "patch_size": 14,
 9:   "processor_class": "Qwen2_5_VLProcessor",
 9:   "resample": 3,
 9:   "rescale_factor": 0.00392156862745098,
 9:   "return_tensors": null,
 9:   "size": {
 9:     "longest_edge": 12845056,
 9:     "shortest_edge": 3136
 9:   },
 9:   "temporal_patch_size": 2
 9: }
 9: 
 9: - tokenizer: Qwen2TokenizerFast(name_or_path='Qwen/Qwen2.5-VL-7B-Instruct', vocab_size=151643, model_max_length=131072, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
 9: 	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 9: 	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 9: 	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 9: 	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 9: 	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 9: 	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 9: 	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 9: 	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 9: 	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 9: 	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 9: 	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 9: 	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 9: 	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 9: 	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 9: 	151657: AddedToken("<tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 9: 	151658: AddedToken("</tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 9: 	151659: AddedToken("<|fim_prefix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 9: 	151660: AddedToken("<|fim_middle|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 9: 	151661: AddedToken("<|fim_suffix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 9: 	151662: AddedToken("<|fim_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 9: 	151663: AddedToken("<|repo_name|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 9: 	151664: AddedToken("<|file_sep|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 9: }
 9: )
 9: 
 9: {
 9:   "processor_class": "Qwen2_5_VLProcessor"
 9: }
 9: 
15: [INFO|2025-06-27 21:02:51] llamafactory.hparams.parser:406 >> Process rank: 61, world size: 128, device: cuda:1, distributed training: True, compute dtype: torch.bfloat16
23: [INFO|2025-06-27 21:02:51] llamafactory.hparams.parser:406 >> Process rank: 95, world size: 128, device: cuda:3, distributed training: True, compute dtype: torch.bfloat16
 7: [INFO|tokenization_utils_base.py:2323] 2025-06-27 21:02:51,322 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
16: [INFO|image_processing_base.py:380] 2025-06-27 21:02:51,325 >> loading configuration file preprocessor_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
11: [INFO|tokenization_utils_base.py:2323] 2025-06-27 21:02:51,325 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
16: [INFO|image_processing_base.py:433] 2025-06-27 21:02:51,327 >> Image processor Qwen2VLImageProcessorFast {
16:   "crop_size": null,
16:   "data_format": "channels_first",
16:   "default_to_square": true,
16:   "device": null,
16:   "do_center_crop": null,
16:   "do_convert_rgb": true,
16:   "do_normalize": true,
16:   "do_rescale": true,
16:   "do_resize": true,
16:   "image_mean": [
16:     0.48145466,
16:     0.4578275,
16:     0.40821073
16:   ],
16:   "image_processor_type": "Qwen2VLImageProcessorFast",
16:   "image_std": [
16:     0.26862954,
16:     0.26130258,
16:     0.27577711
16:   ],
16:   "input_data_format": null,
16:   "max_pixels": 12845056,
16:   "merge_size": 2,
16:   "min_pixels": 3136,
16:   "patch_size": 14,
16:   "processor_class": "Qwen2_5_VLProcessor",
16:   "resample": 3,
16:   "rescale_factor": 0.00392156862745098,
16:   "return_tensors": null,
16:   "size": {
16:     "longest_edge": 12845056,
16:     "shortest_edge": 3136
16:   },
16:   "temporal_patch_size": 2
16: }
16: 
 9: [WARNING|2025-06-27 21:02:51] llamafactory.data.loader:148 >> Loading dataset from disk will ignore other data arguments.
 6: [INFO|tokenization_utils_base.py:2323] 2025-06-27 21:02:51,347 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
26: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,354 >> loading file vocab.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
26: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,354 >> loading file merges.txt from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
26: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,354 >> loading file tokenizer.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
26: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,354 >> loading file added_tokens.json from cache at None
26: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,354 >> loading file special_tokens_map.json from cache at None
26: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,354 >> loading file tokenizer_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
26: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,354 >> loading file chat_template.jinja from cache at None
 4: [INFO|tokenization_utils_base.py:2323] 2025-06-27 21:02:51,359 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
18: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,377 >> loading file vocab.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
18: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,377 >> loading file merges.txt from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
18: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,377 >> loading file tokenizer.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
18: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,377 >> loading file added_tokens.json from cache at None
18: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,377 >> loading file special_tokens_map.json from cache at None
18: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,377 >> loading file tokenizer_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
18: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,377 >> loading file chat_template.jinja from cache at None
12: [INFO|image_processing_base.py:380] 2025-06-27 21:02:51,410 >> loading configuration file preprocessor_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
31: [INFO|image_processing_base.py:380] 2025-06-27 21:02:51,420 >> loading configuration file preprocessor_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
 3: [INFO|tokenization_utils_base.py:2323] 2025-06-27 21:02:51,421 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
16: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,454 >> loading file vocab.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
16: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,454 >> loading file merges.txt from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
16: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,454 >> loading file tokenizer.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
16: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,454 >> loading file added_tokens.json from cache at None
16: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,454 >> loading file special_tokens_map.json from cache at None
16: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,454 >> loading file tokenizer_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
16: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,454 >> loading file chat_template.jinja from cache at None
29: [INFO|tokenization_utils_base.py:2323] 2025-06-27 21:02:51,459 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
 2: [INFO|2025-06-27 21:02:51] llamafactory.hparams.parser:406 >> Process rank: 11, world size: 128, device: cuda:3, distributed training: True, compute dtype: torch.bfloat16
30: [INFO|tokenization_utils_base.py:2323] 2025-06-27 21:02:51,466 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
27: [INFO|2025-06-27 21:02:51] llamafactory.hparams.parser:406 >> Process rank: 111, world size: 128, device: cuda:3, distributed training: True, compute dtype: torch.bfloat16
27: [INFO|2025-06-27 21:02:51] llamafactory.hparams.parser:406 >> Process rank: 110, world size: 128, device: cuda:2, distributed training: True, compute dtype: torch.bfloat16
 9: [INFO|2025-06-27 21:02:51] llamafactory.hparams.parser:406 >> Process rank: 37, world size: 128, device: cuda:1, distributed training: True, compute dtype: torch.bfloat16
 9: [INFO|2025-06-27 21:02:51] llamafactory.hparams.parser:406 >> Process rank: 38, world size: 128, device: cuda:2, distributed training: True, compute dtype: torch.bfloat16
10: [INFO|2025-06-27 21:02:51] llamafactory.hparams.parser:406 >> Process rank: 43, world size: 128, device: cuda:3, distributed training: True, compute dtype: torch.bfloat16
10: [INFO|2025-06-27 21:02:51] llamafactory.hparams.parser:406 >> Process rank: 41, world size: 128, device: cuda:1, distributed training: True, compute dtype: torch.bfloat16
 2: [INFO|2025-06-27 21:02:51] llamafactory.hparams.parser:406 >> Process rank: 10, world size: 128, device: cuda:2, distributed training: True, compute dtype: torch.bfloat16
13: [INFO|2025-06-27 21:02:51] llamafactory.hparams.parser:406 >> Process rank: 54, world size: 128, device: cuda:2, distributed training: True, compute dtype: torch.bfloat16
 5: [INFO|processing_utils.py:884] 2025-06-27 21:02:51,520 >> Processor Qwen2_5_VLProcessor:
 5: - image_processor: Qwen2VLImageProcessorFast {
 5:   "crop_size": null,
 5:   "data_format": "channels_first",
 5:   "default_to_square": true,
 5:   "device": null,
 5:   "do_center_crop": null,
 5:   "do_convert_rgb": true,
 5:   "do_normalize": true,
 5:   "do_rescale": true,
 5:   "do_resize": true,
 5:   "image_mean": [
 5:     0.48145466,
 5:     0.4578275,
 5:     0.40821073
 5:   ],
 5:   "image_processor_type": "Qwen2VLImageProcessorFast",
 5:   "image_std": [
 5:     0.26862954,
 5:     0.26130258,
 5:     0.27577711
 5:   ],
 5:   "input_data_format": null,
 5:   "max_pixels": 12845056,
 5:   "merge_size": 2,
 5:   "min_pixels": 3136,
 5:   "patch_size": 14,
 5:   "processor_class": "Qwen2_5_VLProcessor",
 5:   "resample": 3,
 5:   "rescale_factor": 0.00392156862745098,
 5:   "return_tensors": null,
 5:   "size": {
 5:     "longest_edge": 12845056,
 5:     "shortest_edge": 3136
 5:   },
 5:   "temporal_patch_size": 2
 5: }
 5: 
 5: - tokenizer: Qwen2TokenizerFast(name_or_path='Qwen/Qwen2.5-VL-7B-Instruct', vocab_size=151643, model_max_length=131072, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
 5: 	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 5: 	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 5: 	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 5: 	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 5: 	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 5: 	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 5: 	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 5: 	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 5: 	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 5: 	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 5: 	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 5: 	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 5: 	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 5: 	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 5: 	151657: AddedToken("<tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 5: 	151658: AddedToken("</tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 5: 	151659: AddedToken("<|fim_prefix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 5: 	151660: AddedToken("<|fim_middle|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 5: 	151661: AddedToken("<|fim_suffix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 5: 	151662: AddedToken("<|fim_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 5: 	151663: AddedToken("<|repo_name|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 5: 	151664: AddedToken("<|file_sep|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 5: }
 5: )
 5: 
 5: {
 5:   "processor_class": "Qwen2_5_VLProcessor"
 5: }
 5: 
13: [INFO|2025-06-27 21:02:51] llamafactory.hparams.parser:406 >> Process rank: 53, world size: 128, device: cuda:1, distributed training: True, compute dtype: torch.bfloat16
13: [INFO|2025-06-27 21:02:51] llamafactory.hparams.parser:406 >> Process rank: 55, world size: 128, device: cuda:3, distributed training: True, compute dtype: torch.bfloat16
26: [INFO|tokenization_utils_base.py:2323] 2025-06-27 21:02:51,527 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
31: [INFO|image_processing_base.py:380] 2025-06-27 21:02:51,539 >> loading configuration file preprocessor_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
31: [INFO|image_processing_base.py:433] 2025-06-27 21:02:51,541 >> Image processor Qwen2VLImageProcessorFast {
31:   "crop_size": null,
31:   "data_format": "channels_first",
31:   "default_to_square": true,
31:   "device": null,
31:   "do_center_crop": null,
31:   "do_convert_rgb": true,
31:   "do_normalize": true,
31:   "do_rescale": true,
31:   "do_resize": true,
31:   "image_mean": [
31:     0.48145466,
31:     0.4578275,
31:     0.40821073
31:   ],
31:   "image_processor_type": "Qwen2VLImageProcessorFast",
31:   "image_std": [
31:     0.26862954,
31:     0.26130258,
31:     0.27577711
31:   ],
31:   "input_data_format": null,
31:   "max_pixels": 12845056,
31:   "merge_size": 2,
31:   "min_pixels": 3136,
31:   "patch_size": 14,
31:   "processor_class": "Qwen2_5_VLProcessor",
31:   "resample": 3,
31:   "rescale_factor": 0.00392156862745098,
31:   "return_tensors": null,
31:   "size": {
31:     "longest_edge": 12845056,
31:     "shortest_edge": 3136
31:   },
31:   "temporal_patch_size": 2
31: }
31: 
17: [INFO|processing_utils.py:884] 2025-06-27 21:02:51,541 >> Processor Qwen2_5_VLProcessor:
17: - image_processor: Qwen2VLImageProcessorFast {
17:   "crop_size": null,
17:   "data_format": "channels_first",
17:   "default_to_square": true,
17:   "device": null,
17:   "do_center_crop": null,
17:   "do_convert_rgb": true,
17:   "do_normalize": true,
17:   "do_rescale": true,
17:   "do_resize": true,
17:   "image_mean": [
17:     0.48145466,
17:     0.4578275,
17:     0.40821073
17:   ],
17:   "image_processor_type": "Qwen2VLImageProcessorFast",
17:   "image_std": [
17:     0.26862954,
17:     0.26130258,
17:     0.27577711
17:   ],
17:   "input_data_format": null,
17:   "max_pixels": 12845056,
17:   "merge_size": 2,
17:   "min_pixels": 3136,
17:   "patch_size": 14,
17:   "processor_class": "Qwen2_5_VLProcessor",
17:   "resample": 3,
17:   "rescale_factor": 0.00392156862745098,
17:   "return_tensors": null,
17:   "size": {
17:     "longest_edge": 12845056,
17:     "shortest_edge": 3136
17:   },
17:   "temporal_patch_size": 2
17: }
17: 
17: - tokenizer: Qwen2TokenizerFast(name_or_path='Qwen/Qwen2.5-VL-7B-Instruct', vocab_size=151643, model_max_length=131072, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
17: 	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
17: 	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
17: 	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
17: 	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
17: 	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
17: 	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
17: 	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
17: 	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
17: 	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
17: 	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
17: 	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
17: 	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
17: 	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
17: 	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
17: 	151657: AddedToken("<tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
17: 	151658: AddedToken("</tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
17: 	151659: AddedToken("<|fim_prefix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
17: 	151660: AddedToken("<|fim_middle|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
17: 	151661: AddedToken("<|fim_suffix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
17: 	151662: AddedToken("<|fim_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
17: 	151663: AddedToken("<|repo_name|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
17: 	151664: AddedToken("<|file_sep|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
17: }
17: )
17: 
17: {
17:   "processor_class": "Qwen2_5_VLProcessor"
17: }
17: 
25: [INFO|2025-06-27 21:02:51] llamafactory.hparams.parser:406 >> Process rank: 103, world size: 128, device: cuda:3, distributed training: True, compute dtype: torch.bfloat16
12: [INFO|image_processing_base.py:380] 2025-06-27 21:02:51,544 >> loading configuration file preprocessor_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
12: [INFO|image_processing_base.py:433] 2025-06-27 21:02:51,546 >> Image processor Qwen2VLImageProcessorFast {
12:   "crop_size": null,
12:   "data_format": "channels_first",
12:   "default_to_square": true,
12:   "device": null,
12:   "do_center_crop": null,
12:   "do_convert_rgb": true,
12:   "do_normalize": true,
12:   "do_rescale": true,
12:   "do_resize": true,
12:   "image_mean": [
12:     0.48145466,
12:     0.4578275,
12:     0.40821073
12:   ],
12:   "image_processor_type": "Qwen2VLImageProcessorFast",
12:   "image_std": [
12:     0.26862954,
12:     0.26130258,
12:     0.27577711
12:   ],
12:   "input_data_format": null,
12:   "max_pixels": 12845056,
12:   "merge_size": 2,
12:   "min_pixels": 3136,
12:   "patch_size": 14,
12:   "processor_class": "Qwen2_5_VLProcessor",
12:   "resample": 3,
12:   "rescale_factor": 0.00392156862745098,
12:   "return_tensors": null,
12:   "size": {
12:     "longest_edge": 12845056,
12:     "shortest_edge": 3136
12:   },
12:   "temporal_patch_size": 2
12: }
12: 
 5: [WARNING|2025-06-27 21:02:51] llamafactory.data.loader:148 >> Loading dataset from disk will ignore other data arguments.
18: [INFO|tokenization_utils_base.py:2323] 2025-06-27 21:02:51,553 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
25: [INFO|2025-06-27 21:02:51] llamafactory.hparams.parser:406 >> Process rank: 101, world size: 128, device: cuda:1, distributed training: True, compute dtype: torch.bfloat16
30: [INFO|2025-06-27 21:02:51] llamafactory.hparams.parser:406 >> Process rank: 122, world size: 128, device: cuda:2, distributed training: True, compute dtype: torch.bfloat16
25: [INFO|2025-06-27 21:02:51] llamafactory.hparams.parser:406 >> Process rank: 102, world size: 128, device: cuda:2, distributed training: True, compute dtype: torch.bfloat16
17: [WARNING|2025-06-27 21:02:51] llamafactory.data.loader:148 >> Loading dataset from disk will ignore other data arguments.
14: [INFO|image_processing_base.py:380] 2025-06-27 21:02:51,581 >> loading configuration file preprocessor_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
28: [INFO|processing_utils.py:884] 2025-06-27 21:02:51,583 >> Processor Qwen2_5_VLProcessor:
28: - image_processor: Qwen2VLImageProcessorFast {
28:   "crop_size": null,
28:   "data_format": "channels_first",
28:   "default_to_square": true,
28:   "device": null,
28:   "do_center_crop": null,
28:   "do_convert_rgb": true,
28:   "do_normalize": true,
28:   "do_rescale": true,
28:   "do_resize": true,
28:   "image_mean": [
28:     0.48145466,
28:     0.4578275,
28:     0.40821073
28:   ],
28:   "image_processor_type": "Qwen2VLImageProcessorFast",
28:   "image_std": [
28:     0.26862954,
28:     0.26130258,
28:     0.27577711
28:   ],
28:   "input_data_format": null,
28:   "max_pixels": 12845056,
28:   "merge_size": 2,
28:   "min_pixels": 3136,
28:   "patch_size": 14,
28:   "processor_class": "Qwen2_5_VLProcessor",
28:   "resample": 3,
28:   "rescale_factor": 0.00392156862745098,
28:   "return_tensors": null,
28:   "size": {
28:     "longest_edge": 12845056,
28:     "shortest_edge": 3136
28:   },
28:   "temporal_patch_size": 2
28: }
28: 
28: - tokenizer: Qwen2TokenizerFast(name_or_path='Qwen/Qwen2.5-VL-7B-Instruct', vocab_size=151643, model_max_length=131072, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
28: 	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
28: 	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
28: 	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
28: 	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
28: 	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
28: 	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
28: 	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
28: 	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
28: 	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
28: 	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
28: 	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
28: 	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
28: 	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
28: 	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
28: 	151657: AddedToken("<tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
28: 	151658: AddedToken("</tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
28: 	151659: AddedToken("<|fim_prefix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
28: 	151660: AddedToken("<|fim_middle|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
28: 	151661: AddedToken("<|fim_suffix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
28: 	151662: AddedToken("<|fim_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
28: 	151663: AddedToken("<|repo_name|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
28: 	151664: AddedToken("<|file_sep|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
28: }
28: )
28: 
28: {
28:   "processor_class": "Qwen2_5_VLProcessor"
28: }
28: 
20: [INFO|image_processing_base.py:380] 2025-06-27 21:02:51,592 >> loading configuration file preprocessor_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
28: [WARNING|2025-06-27 21:02:51] llamafactory.data.loader:148 >> Loading dataset from disk will ignore other data arguments.
21: [INFO|processing_utils.py:884] 2025-06-27 21:02:51,610 >> Processor Qwen2_5_VLProcessor:
21: - image_processor: Qwen2VLImageProcessorFast {
21:   "crop_size": null,
21:   "data_format": "channels_first",
21:   "default_to_square": true,
21:   "device": null,
21:   "do_center_crop": null,
21:   "do_convert_rgb": true,
21:   "do_normalize": true,
21:   "do_rescale": true,
21:   "do_resize": true,
21:   "image_mean": [
21:     0.48145466,
21:     0.4578275,
21:     0.40821073
21:   ],
21:   "image_processor_type": "Qwen2VLImageProcessorFast",
21:   "image_std": [
21:     0.26862954,
21:     0.26130258,
21:     0.27577711
21:   ],
21:   "input_data_format": null,
21:   "max_pixels": 12845056,
21:   "merge_size": 2,
21:   "min_pixels": 3136,
21:   "patch_size": 14,
21:   "processor_class": "Qwen2_5_VLProcessor",
21:   "resample": 3,
21:   "rescale_factor": 0.00392156862745098,
21:   "return_tensors": null,
21:   "size": {
21:     "longest_edge": 12845056,
21:     "shortest_edge": 3136
21:   },
21:   "temporal_patch_size": 2
21: }
21: 
21: - tokenizer: Qwen2TokenizerFast(name_or_path='Qwen/Qwen2.5-VL-7B-Instruct', vocab_size=151643, model_max_length=131072, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
21: 	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
21: 	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
21: 	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
21: 	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
21: 	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
21: 	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
21: 	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
21: 	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
21: 	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
21: 	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
21: 	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
21: 	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
21: 	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
21: 	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
21: 	151657: AddedToken("<tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
21: 	151658: AddedToken("</tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
21: 	151659: AddedToken("<|fim_prefix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
21: 	151660: AddedToken("<|fim_middle|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
21: 	151661: AddedToken("<|fim_suffix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
21: 	151662: AddedToken("<|fim_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
21: 	151663: AddedToken("<|repo_name|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
21: 	151664: AddedToken("<|file_sep|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
21: }
21: )
21: 
21: {
21:   "processor_class": "Qwen2_5_VLProcessor"
21: }
21: 
16: [INFO|tokenization_utils_base.py:2323] 2025-06-27 21:02:51,625 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
21: [WARNING|2025-06-27 21:02:51] llamafactory.data.loader:148 >> Loading dataset from disk will ignore other data arguments.
 8: [INFO|image_processing_base.py:380] 2025-06-27 21:02:51,641 >> loading configuration file preprocessor_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
15: [INFO|processing_utils.py:884] 2025-06-27 21:02:51,664 >> Processor Qwen2_5_VLProcessor:
15: - image_processor: Qwen2VLImageProcessorFast {
15:   "crop_size": null,
15:   "data_format": "channels_first",
15:   "default_to_square": true,
15:   "device": null,
15:   "do_center_crop": null,
15:   "do_convert_rgb": true,
15:   "do_normalize": true,
15:   "do_rescale": true,
15:   "do_resize": true,
15:   "image_mean": [
15:     0.48145466,
15:     0.4578275,
15:     0.40821073
15:   ],
15:   "image_processor_type": "Qwen2VLImageProcessorFast",
15:   "image_std": [
15:     0.26862954,
15:     0.26130258,
15:     0.27577711
15:   ],
15:   "input_data_format": null,
15:   "max_pixels": 12845056,
15:   "merge_size": 2,
15:   "min_pixels": 3136,
15:   "patch_size": 14,
15:   "processor_class": "Qwen2_5_VLProcessor",
15:   "resample": 3,
15:   "rescale_factor": 0.00392156862745098,
15:   "return_tensors": null,
15:   "size": {
15:     "longest_edge": 12845056,
15:     "shortest_edge": 3136
15:   },
15:   "temporal_patch_size": 2
15: }
15: 
15: - tokenizer: Qwen2TokenizerFast(name_or_path='Qwen/Qwen2.5-VL-7B-Instruct', vocab_size=151643, model_max_length=131072, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
15: 	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
15: 	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
15: 	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
15: 	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
15: 	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
15: 	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
15: 	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
15: 	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
15: 	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
15: 	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
15: 	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
15: 	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
15: 	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
15: 	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
15: 	151657: AddedToken("<tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
15: 	151658: AddedToken("</tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
15: 	151659: AddedToken("<|fim_prefix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
15: 	151660: AddedToken("<|fim_middle|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
15: 	151661: AddedToken("<|fim_suffix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
15: 	151662: AddedToken("<|fim_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
15: 	151663: AddedToken("<|repo_name|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
15: 	151664: AddedToken("<|file_sep|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
15: }
15: )
15: 
15: {
15:   "processor_class": "Qwen2_5_VLProcessor"
15: }
15: 
12: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,670 >> loading file vocab.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
12: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,670 >> loading file merges.txt from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
12: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,670 >> loading file tokenizer.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
12: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,670 >> loading file added_tokens.json from cache at None
12: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,670 >> loading file special_tokens_map.json from cache at None
12: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,670 >> loading file tokenizer_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
12: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,670 >> loading file chat_template.jinja from cache at None
21: [INFO|2025-06-27 21:02:51] llamafactory.hparams.parser:406 >> Process rank: 87, world size: 128, device: cuda:3, distributed training: True, compute dtype: torch.bfloat16
21: [INFO|2025-06-27 21:02:51] llamafactory.hparams.parser:406 >> Process rank: 85, world size: 128, device: cuda:1, distributed training: True, compute dtype: torch.bfloat16
23: [INFO|processing_utils.py:884] 2025-06-27 21:02:51,687 >> Processor Qwen2_5_VLProcessor:
23: - image_processor: Qwen2VLImageProcessorFast {
23:   "crop_size": null,
23:   "data_format": "channels_first",
23:   "default_to_square": true,
23:   "device": null,
23:   "do_center_crop": null,
23:   "do_convert_rgb": true,
23:   "do_normalize": true,
23:   "do_rescale": true,
23:   "do_resize": true,
23:   "image_mean": [
23:     0.48145466,
23:     0.4578275,
23:     0.40821073
23:   ],
23:   "image_processor_type": "Qwen2VLImageProcessorFast",
23:   "image_std": [
23:     0.26862954,
23:     0.26130258,
23:     0.27577711
23:   ],
23:   "input_data_format": null,
23:   "max_pixels": 12845056,
23:   "merge_size": 2,
23:   "min_pixels": 3136,
23:   "patch_size": 14,
23:   "processor_class": "Qwen2_5_VLProcessor",
23:   "resample": 3,
23:   "rescale_factor": 0.00392156862745098,
23:   "return_tensors": null,
23:   "size": {
23:     "longest_edge": 12845056,
23:     "shortest_edge": 3136
23:   },
23:   "temporal_patch_size": 2
23: }
23: 
23: - tokenizer: Qwen2TokenizerFast(name_or_path='Qwen/Qwen2.5-VL-7B-Instruct', vocab_size=151643, model_max_length=131072, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
23: 	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
23: 	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
23: 	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
23: 	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
23: 	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
23: 	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
23: 	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
23: 	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
23: 	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
23: 	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
23: 	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
23: 	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
23: 	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
23: 	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
23: 	151657: AddedToken("<tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
23: 	151658: AddedToken("</tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
23: 	151659: AddedToken("<|fim_prefix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
23: 	151660: AddedToken("<|fim_middle|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
23: 	151661: AddedToken("<|fim_suffix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
23: 	151662: AddedToken("<|fim_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
23: 	151663: AddedToken("<|repo_name|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
23: 	151664: AddedToken("<|file_sep|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
23: }
23: )
23: 
23: {
23:   "processor_class": "Qwen2_5_VLProcessor"
23: }
23: 
19: [INFO|processing_utils.py:884] 2025-06-27 21:02:51,694 >> Processor Qwen2_5_VLProcessor:
19: - image_processor: Qwen2VLImageProcessorFast {
19:   "crop_size": null,
19:   "data_format": "channels_first",
19:   "default_to_square": true,
19:   "device": null,
19:   "do_center_crop": null,
19:   "do_convert_rgb": true,
19:   "do_normalize": true,
19:   "do_rescale": true,
19:   "do_resize": true,
19:   "image_mean": [
19:     0.48145466,
19:     0.4578275,
19:     0.40821073
19:   ],
19:   "image_processor_type": "Qwen2VLImageProcessorFast",
19:   "image_std": [
19:     0.26862954,
19:     0.26130258,
19:     0.27577711
19:   ],
19:   "input_data_format": null,
19:   "max_pixels": 12845056,
19:   "merge_size": 2,
19:   "min_pixels": 3136,
19:   "patch_size": 14,
19:   "processor_class": "Qwen2_5_VLProcessor",
19:   "resample": 3,
19:   "rescale_factor": 0.00392156862745098,
19:   "return_tensors": null,
19:   "size": {
19:     "longest_edge": 12845056,
19:     "shortest_edge": 3136
19:   },
19:   "temporal_patch_size": 2
19: }
19: 
19: - tokenizer: Qwen2TokenizerFast(name_or_path='Qwen/Qwen2.5-VL-7B-Instruct', vocab_size=151643, model_max_length=131072, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
19: 	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
19: 	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
19: 	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
19: 	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
19: 	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
19: 	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
19: 	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
19: 	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
19: 	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
19: 	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
19: 	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
19: 	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
19: 	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
19: 	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
19: 	151657: AddedToken("<tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
19: 	151658: AddedToken("</tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
19: 	151659: AddedToken("<|fim_prefix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
19: 	151660: AddedToken("<|fim_middle|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
19: 	151661: AddedToken("<|fim_suffix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
19: 	151662: AddedToken("<|fim_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
19: 	151663: AddedToken("<|repo_name|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
19: 	151664: AddedToken("<|file_sep|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
19: }
19: )
19: 
19: {
19:   "processor_class": "Qwen2_5_VLProcessor"
19: }
19: 
15: [WARNING|2025-06-27 21:02:51] llamafactory.data.loader:148 >> Loading dataset from disk will ignore other data arguments.
 4: [INFO|image_processing_base.py:380] 2025-06-27 21:02:51,711 >> loading configuration file preprocessor_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
20: [INFO|image_processing_base.py:380] 2025-06-27 21:02:51,712 >> loading configuration file preprocessor_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
 6: [INFO|image_processing_base.py:380] 2025-06-27 21:02:51,713 >> loading configuration file preprocessor_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
20: [INFO|image_processing_base.py:433] 2025-06-27 21:02:51,714 >> Image processor Qwen2VLImageProcessorFast {
20:   "crop_size": null,
20:   "data_format": "channels_first",
20:   "default_to_square": true,
20:   "device": null,
20:   "do_center_crop": null,
20:   "do_convert_rgb": true,
20:   "do_normalize": true,
20:   "do_rescale": true,
20:   "do_resize": true,
20:   "image_mean": [
20:     0.48145466,
20:     0.4578275,
20:     0.40821073
20:   ],
20:   "image_processor_type": "Qwen2VLImageProcessorFast",
20:   "image_std": [
20:     0.26862954,
20:     0.26130258,
20:     0.27577711
20:   ],
20:   "input_data_format": null,
20:   "max_pixels": 12845056,
20:   "merge_size": 2,
20:   "min_pixels": 3136,
20:   "patch_size": 14,
20:   "processor_class": "Qwen2_5_VLProcessor",
20:   "resample": 3,
20:   "rescale_factor": 0.00392156862745098,
20:   "return_tensors": null,
20:   "size": {
20:     "longest_edge": 12845056,
20:     "shortest_edge": 3136
20:   },
20:   "temporal_patch_size": 2
20: }
20: 
23: [WARNING|2025-06-27 21:02:51] llamafactory.data.loader:148 >> Loading dataset from disk will ignore other data arguments.
19: [WARNING|2025-06-27 21:02:51] llamafactory.data.loader:148 >> Loading dataset from disk will ignore other data arguments.
 9: [INFO|2025-06-27 21:02:51] llamafactory.hparams.parser:406 >> Process rank: 39, world size: 128, device: cuda:3, distributed training: True, compute dtype: torch.bfloat16
 8: [INFO|image_processing_base.py:380] 2025-06-27 21:02:51,760 >> loading configuration file preprocessor_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
 8: [INFO|image_processing_base.py:433] 2025-06-27 21:02:51,762 >> Image processor Qwen2VLImageProcessorFast {
 8:   "crop_size": null,
 8:   "data_format": "channels_first",
 8:   "default_to_square": true,
 8:   "device": null,
 8:   "do_center_crop": null,
 8:   "do_convert_rgb": true,
 8:   "do_normalize": true,
 8:   "do_rescale": true,
 8:   "do_resize": true,
 8:   "image_mean": [
 8:     0.48145466,
 8:     0.4578275,
 8:     0.40821073
 8:   ],
 8:   "image_processor_type": "Qwen2VLImageProcessorFast",
 8:   "image_std": [
 8:     0.26862954,
 8:     0.26130258,
 8:     0.27577711
 8:   ],
 8:   "input_data_format": null,
 8:   "max_pixels": 12845056,
 8:   "merge_size": 2,
 8:   "min_pixels": 3136,
 8:   "patch_size": 14,
 8:   "processor_class": "Qwen2_5_VLProcessor",
 8:   "resample": 3,
 8:   "rescale_factor": 0.00392156862745098,
 8:   "return_tensors": null,
 8:   "size": {
 8:     "longest_edge": 12845056,
 8:     "shortest_edge": 3136
 8:   },
 8:   "temporal_patch_size": 2
 8: }
 8: 
 0: [INFO|2025-06-27 21:02:51] llamafactory.hparams.parser:406 >> Process rank: 2, world size: 128, device: cuda:2, distributed training: True, compute dtype: torch.bfloat16
10: [INFO|2025-06-27 21:02:51] llamafactory.hparams.parser:406 >> Process rank: 42, world size: 128, device: cuda:2, distributed training: True, compute dtype: torch.bfloat16
29: [INFO|image_processing_base.py:380] 2025-06-27 21:02:51,820 >> loading configuration file preprocessor_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
 4: [INFO|image_processing_base.py:380] 2025-06-27 21:02:51,834 >> loading configuration file preprocessor_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
20: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,835 >> loading file vocab.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
20: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,835 >> loading file merges.txt from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
20: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,835 >> loading file tokenizer.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
20: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,835 >> loading file added_tokens.json from cache at None
20: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,835 >> loading file special_tokens_map.json from cache at None
20: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,835 >> loading file tokenizer_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
20: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,835 >> loading file chat_template.jinja from cache at None
 4: [INFO|image_processing_base.py:433] 2025-06-27 21:02:51,836 >> Image processor Qwen2VLImageProcessorFast {
 4:   "crop_size": null,
 4:   "data_format": "channels_first",
 4:   "default_to_square": true,
 4:   "device": null,
 4:   "do_center_crop": null,
 4:   "do_convert_rgb": true,
 4:   "do_normalize": true,
 4:   "do_rescale": true,
 4:   "do_resize": true,
 4:   "image_mean": [
 4:     0.48145466,
 4:     0.4578275,
 4:     0.40821073
 4:   ],
 4:   "image_processor_type": "Qwen2VLImageProcessorFast",
 4:   "image_std": [
 4:     0.26862954,
 4:     0.26130258,
 4:     0.27577711
 4:   ],
 4:   "input_data_format": null,
 4:   "max_pixels": 12845056,
 4:   "merge_size": 2,
 4:   "min_pixels": 3136,
 4:   "patch_size": 14,
 4:   "processor_class": "Qwen2_5_VLProcessor",
 4:   "resample": 3,
 4:   "rescale_factor": 0.00392156862745098,
 4:   "return_tensors": null,
 4:   "size": {
 4:     "longest_edge": 12845056,
 4:     "shortest_edge": 3136
 4:   },
 4:   "temporal_patch_size": 2
 4: }
 4: 
 6: [INFO|image_processing_base.py:380] 2025-06-27 21:02:51,838 >> loading configuration file preprocessor_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
 6: [INFO|image_processing_base.py:433] 2025-06-27 21:02:51,840 >> Image processor Qwen2VLImageProcessorFast {
 6:   "crop_size": null,
 6:   "data_format": "channels_first",
 6:   "default_to_square": true,
 6:   "device": null,
 6:   "do_center_crop": null,
 6:   "do_convert_rgb": true,
 6:   "do_normalize": true,
 6:   "do_rescale": true,
 6:   "do_resize": true,
 6:   "image_mean": [
 6:     0.48145466,
 6:     0.4578275,
 6:     0.40821073
 6:   ],
 6:   "image_processor_type": "Qwen2VLImageProcessorFast",
 6:   "image_std": [
 6:     0.26862954,
 6:     0.26130258,
 6:     0.27577711
 6:   ],
 6:   "input_data_format": null,
 6:   "max_pixels": 12845056,
 6:   "merge_size": 2,
 6:   "min_pixels": 3136,
 6:   "patch_size": 14,
 6:   "processor_class": "Qwen2_5_VLProcessor",
 6:   "resample": 3,
 6:   "rescale_factor": 0.00392156862745098,
 6:   "return_tensors": null,
 6:   "size": {
 6:     "longest_edge": 12845056,
 6:     "shortest_edge": 3136
 6:   },
 6:   "temporal_patch_size": 2
 6: }
 6: 
12: [INFO|tokenization_utils_base.py:2323] 2025-06-27 21:02:51,842 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
31: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,846 >> loading file vocab.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
31: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,846 >> loading file merges.txt from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
31: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,846 >> loading file tokenizer.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
31: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,846 >> loading file added_tokens.json from cache at None
31: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,846 >> loading file special_tokens_map.json from cache at None
31: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,846 >> loading file tokenizer_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
31: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,846 >> loading file chat_template.jinja from cache at None
28: [INFO|2025-06-27 21:02:51] llamafactory.hparams.parser:406 >> Process rank: 114, world size: 128, device: cuda:2, distributed training: True, compute dtype: torch.bfloat16
12: [INFO|2025-06-27 21:02:51] llamafactory.hparams.parser:406 >> Process rank: 51, world size: 128, device: cuda:3, distributed training: True, compute dtype: torch.bfloat16
12: [INFO|2025-06-27 21:02:51] llamafactory.hparams.parser:406 >> Process rank: 49, world size: 128, device: cuda:1, distributed training: True, compute dtype: torch.bfloat16
14: [INFO|image_processing_base.py:380] 2025-06-27 21:02:51,881 >> loading configuration file preprocessor_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
 8: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,882 >> loading file vocab.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
 8: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,882 >> loading file merges.txt from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
 8: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,882 >> loading file tokenizer.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
 8: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,882 >> loading file added_tokens.json from cache at None
 8: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,882 >> loading file special_tokens_map.json from cache at None
 8: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,882 >> loading file tokenizer_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
 8: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,882 >> loading file chat_template.jinja from cache at None
14: [INFO|image_processing_base.py:433] 2025-06-27 21:02:51,883 >> Image processor Qwen2VLImageProcessorFast {
14:   "crop_size": null,
14:   "data_format": "channels_first",
14:   "default_to_square": true,
14:   "device": null,
14:   "do_center_crop": null,
14:   "do_convert_rgb": true,
14:   "do_normalize": true,
14:   "do_rescale": true,
14:   "do_resize": true,
14:   "image_mean": [
14:     0.48145466,
14:     0.4578275,
14:     0.40821073
14:   ],
14:   "image_processor_type": "Qwen2VLImageProcessorFast",
14:   "image_std": [
14:     0.26862954,
14:     0.26130258,
14:     0.27577711
14:   ],
14:   "input_data_format": null,
14:   "max_pixels": 12845056,
14:   "merge_size": 2,
14:   "min_pixels": 3136,
14:   "patch_size": 14,
14:   "processor_class": "Qwen2_5_VLProcessor",
14:   "resample": 3,
14:   "rescale_factor": 0.00392156862745098,
14:   "return_tensors": null,
14:   "size": {
14:     "longest_edge": 12845056,
14:     "shortest_edge": 3136
14:   },
14:   "temporal_patch_size": 2
14: }
14: 
28: [INFO|2025-06-27 21:02:51] llamafactory.hparams.parser:406 >> Process rank: 113, world size: 128, device: cuda:1, distributed training: True, compute dtype: torch.bfloat16
28: [INFO|2025-06-27 21:02:51] llamafactory.hparams.parser:406 >> Process rank: 115, world size: 128, device: cuda:3, distributed training: True, compute dtype: torch.bfloat16
18: [INFO|image_processing_base.py:380] 2025-06-27 21:02:51,912 >> loading configuration file preprocessor_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
22: [INFO|processing_utils.py:884] 2025-06-27 21:02:51,930 >> Processor Qwen2_5_VLProcessor:
22: - image_processor: Qwen2VLImageProcessorFast {
22:   "crop_size": null,
22:   "data_format": "channels_first",
22:   "default_to_square": true,
22:   "device": null,
22:   "do_center_crop": null,
22:   "do_convert_rgb": true,
22:   "do_normalize": true,
22:   "do_rescale": true,
22:   "do_resize": true,
22:   "image_mean": [
22:     0.48145466,
22:     0.4578275,
22:     0.40821073
22:   ],
22:   "image_processor_type": "Qwen2VLImageProcessorFast",
22:   "image_std": [
22:     0.26862954,
22:     0.26130258,
22:     0.27577711
22:   ],
22:   "input_data_format": null,
22:   "max_pixels": 12845056,
22:   "merge_size": 2,
22:   "min_pixels": 3136,
22:   "patch_size": 14,
22:   "processor_class": "Qwen2_5_VLProcessor",
22:   "resample": 3,
22:   "rescale_factor": 0.00392156862745098,
22:   "return_tensors": null,
22:   "size": {
22:     "longest_edge": 12845056,
22:     "shortest_edge": 3136
22:   },
22:   "temporal_patch_size": 2
22: }
22: 
22: - tokenizer: Qwen2TokenizerFast(name_or_path='Qwen/Qwen2.5-VL-7B-Instruct', vocab_size=151643, model_max_length=131072, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
22: 	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
22: 	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
22: 	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
22: 	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
22: 	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
22: 	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
22: 	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
22: 	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
22: 	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
22: 	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
22: 	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
22: 	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
22: 	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
22: 	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
22: 	151657: AddedToken("<tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
22: 	151658: AddedToken("</tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
22: 	151659: AddedToken("<|fim_prefix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
22: 	151660: AddedToken("<|fim_middle|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
22: 	151661: AddedToken("<|fim_suffix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
22: 	151662: AddedToken("<|fim_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
22: 	151663: AddedToken("<|repo_name|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
22: 	151664: AddedToken("<|file_sep|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
22: }
22: )
22: 
22: {
22:   "processor_class": "Qwen2_5_VLProcessor"
22: }
22: 
 0: [INFO|processing_utils.py:884] 2025-06-27 21:02:51,931 >> Processor Qwen2_5_VLProcessor:
 0: - image_processor: Qwen2VLImageProcessorFast {
 0:   "crop_size": null,
 0:   "data_format": "channels_first",
 0:   "default_to_square": true,
 0:   "device": null,
 0:   "do_center_crop": null,
 0:   "do_convert_rgb": true,
 0:   "do_normalize": true,
 0:   "do_rescale": true,
 0:   "do_resize": true,
 0:   "image_mean": [
 0:     0.48145466,
 0:     0.4578275,
 0:     0.40821073
 0:   ],
 0:   "image_processor_type": "Qwen2VLImageProcessorFast",
 0:   "image_std": [
 0:     0.26862954,
 0:     0.26130258,
 0:     0.27577711
 0:   ],
 0:   "input_data_format": null,
 0:   "max_pixels": 12845056,
 0:   "merge_size": 2,
 0:   "min_pixels": 3136,
 0:   "patch_size": 14,
 0:   "processor_class": "Qwen2_5_VLProcessor",
 0:   "resample": 3,
 0:   "rescale_factor": 0.00392156862745098,
 0:   "return_tensors": null,
 0:   "size": {
 0:     "longest_edge": 12845056,
 0:     "shortest_edge": 3136
 0:   },
 0:   "temporal_patch_size": 2
 0: }
 0: 
 0: - tokenizer: Qwen2TokenizerFast(name_or_path='Qwen/Qwen2.5-VL-7B-Instruct', vocab_size=151643, model_max_length=131072, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
 0: 	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 0: 	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 0: 	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 0: 	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 0: 	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 0: 	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 0: 	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 0: 	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 0: 	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 0: 	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 0: 	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 0: 	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 0: 	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 0: 	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 0: 	151657: AddedToken("<tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 0: 	151658: AddedToken("</tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 0: 	151659: AddedToken("<|fim_prefix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 0: 	151660: AddedToken("<|fim_middle|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 0: 	151661: AddedToken("<|fim_suffix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 0: 	151662: AddedToken("<|fim_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 0: 	151663: AddedToken("<|repo_name|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 0: 	151664: AddedToken("<|file_sep|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 0: }
 0: )
 0: 
 0: {
 0:   "processor_class": "Qwen2_5_VLProcessor"
 0: }
 0: 
 1: [INFO|2025-06-27 21:02:51] llamafactory.hparams.parser:406 >> Process rank: 5, world size: 128, device: cuda:1, distributed training: True, compute dtype: torch.bfloat16
29: [INFO|image_processing_base.py:380] 2025-06-27 21:02:51,947 >> loading configuration file preprocessor_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
29: [INFO|image_processing_base.py:433] 2025-06-27 21:02:51,949 >> Image processor Qwen2VLImageProcessorFast {
29:   "crop_size": null,
29:   "data_format": "channels_first",
29:   "default_to_square": true,
29:   "device": null,
29:   "do_center_crop": null,
29:   "do_convert_rgb": true,
29:   "do_normalize": true,
29:   "do_rescale": true,
29:   "do_resize": true,
29:   "image_mean": [
29:     0.48145466,
29:     0.4578275,
29:     0.40821073
29:   ],
29:   "image_processor_type": "Qwen2VLImageProcessorFast",
29:   "image_std": [
29:     0.26862954,
29:     0.26130258,
29:     0.27577711
29:   ],
29:   "input_data_format": null,
29:   "max_pixels": 12845056,
29:   "merge_size": 2,
29:   "min_pixels": 3136,
29:   "patch_size": 14,
29:   "processor_class": "Qwen2_5_VLProcessor",
29:   "resample": 3,
29:   "rescale_factor": 0.00392156862745098,
29:   "return_tensors": null,
29:   "size": {
29:     "longest_edge": 12845056,
29:     "shortest_edge": 3136
29:   },
29:   "temporal_patch_size": 2
29: }
29: 
 4: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,957 >> loading file vocab.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
 4: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,957 >> loading file merges.txt from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
 4: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,957 >> loading file tokenizer.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
 4: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,957 >> loading file added_tokens.json from cache at None
 4: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,957 >> loading file special_tokens_map.json from cache at None
 4: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,957 >> loading file tokenizer_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
 4: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,957 >> loading file chat_template.jinja from cache at None
22: [WARNING|2025-06-27 21:02:51] llamafactory.data.loader:148 >> Loading dataset from disk will ignore other data arguments.
 6: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,959 >> loading file vocab.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
 6: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,959 >> loading file merges.txt from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
 6: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,959 >> loading file tokenizer.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
 6: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,959 >> loading file added_tokens.json from cache at None
 6: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,959 >> loading file special_tokens_map.json from cache at None
 6: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,959 >> loading file tokenizer_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
 6: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:51,959 >> loading file chat_template.jinja from cache at None
 0: [WARNING|2025-06-27 21:02:51] llamafactory.data.loader:148 >> Loading dataset from disk will ignore other data arguments.
 7: [INFO|processing_utils.py:884] 2025-06-27 21:02:51,962 >> Processor Qwen2_5_VLProcessor:
 7: - image_processor: Qwen2VLImageProcessorFast {
 7:   "crop_size": null,
 7:   "data_format": "channels_first",
 7:   "default_to_square": true,
 7:   "device": null,
 7:   "do_center_crop": null,
 7:   "do_convert_rgb": true,
 7:   "do_normalize": true,
 7:   "do_rescale": true,
 7:   "do_resize": true,
 7:   "image_mean": [
 7:     0.48145466,
 7:     0.4578275,
 7:     0.40821073
 7:   ],
 7:   "image_processor_type": "Qwen2VLImageProcessorFast",
 7:   "image_std": [
 7:     0.26862954,
 7:     0.26130258,
 7:     0.27577711
 7:   ],
 7:   "input_data_format": null,
 7:   "max_pixels": 12845056,
 7:   "merge_size": 2,
 7:   "min_pixels": 3136,
 7:   "patch_size": 14,
 7:   "processor_class": "Qwen2_5_VLProcessor",
 7:   "resample": 3,
 7:   "rescale_factor": 0.00392156862745098,
 7:   "return_tensors": null,
 7:   "size": {
 7:     "longest_edge": 12845056,
 7:     "shortest_edge": 3136
 7:   },
 7:   "temporal_patch_size": 2
 7: }
 7: 
 7: - tokenizer: Qwen2TokenizerFast(name_or_path='Qwen/Qwen2.5-VL-7B-Instruct', vocab_size=151643, model_max_length=131072, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
 7: 	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 7: 	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 7: 	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 7: 	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 7: 	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 7: 	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 7: 	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 7: 	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 7: 	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 7: 	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 7: 	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 7: 	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 7: 	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 7: 	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 7: 	151657: AddedToken("<tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 7: 	151658: AddedToken("</tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 7: 	151659: AddedToken("<|fim_prefix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 7: 	151660: AddedToken("<|fim_middle|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 7: 	151661: AddedToken("<|fim_suffix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 7: 	151662: AddedToken("<|fim_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 7: 	151663: AddedToken("<|repo_name|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 7: 	151664: AddedToken("<|file_sep|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 7: }
 7: )
 7: 
 7: {
 7:   "processor_class": "Qwen2_5_VLProcessor"
 7: }
 7: 
19: [INFO|2025-06-27 21:02:51] llamafactory.hparams.parser:406 >> Process rank: 77, world size: 128, device: cuda:1, distributed training: True, compute dtype: torch.bfloat16
19: [INFO|2025-06-27 21:02:51] llamafactory.hparams.parser:406 >> Process rank: 79, world size: 128, device: cuda:3, distributed training: True, compute dtype: torch.bfloat16
 7: [WARNING|2025-06-27 21:02:51] llamafactory.data.loader:148 >> Loading dataset from disk will ignore other data arguments.
14: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:52,002 >> loading file vocab.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
14: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:52,002 >> loading file merges.txt from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
14: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:52,002 >> loading file tokenizer.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
14: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:52,002 >> loading file added_tokens.json from cache at None
14: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:52,002 >> loading file special_tokens_map.json from cache at None
14: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:52,002 >> loading file tokenizer_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
20: [INFO|tokenization_utils_base.py:2323] 2025-06-27 21:02:52,002 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
14: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:52,002 >> loading file chat_template.jinja from cache at None
31: [INFO|tokenization_utils_base.py:2323] 2025-06-27 21:02:52,010 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
18: [INFO|image_processing_base.py:380] 2025-06-27 21:02:52,033 >> loading configuration file preprocessor_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
18: [INFO|image_processing_base.py:433] 2025-06-27 21:02:52,035 >> Image processor Qwen2VLImageProcessorFast {
18:   "crop_size": null,
18:   "data_format": "channels_first",
18:   "default_to_square": true,
18:   "device": null,
18:   "do_center_crop": null,
18:   "do_convert_rgb": true,
18:   "do_normalize": true,
18:   "do_rescale": true,
18:   "do_resize": true,
18:   "image_mean": [
18:     0.48145466,
18:     0.4578275,
18:     0.40821073
18:   ],
18:   "image_processor_type": "Qwen2VLImageProcessorFast",
18:   "image_std": [
18:     0.26862954,
18:     0.26130258,
18:     0.27577711
18:   ],
18:   "input_data_format": null,
18:   "max_pixels": 12845056,
18:   "merge_size": 2,
18:   "min_pixels": 3136,
18:   "patch_size": 14,
18:   "processor_class": "Qwen2_5_VLProcessor",
18:   "resample": 3,
18:   "rescale_factor": 0.00392156862745098,
18:   "return_tensors": null,
18:   "size": {
18:     "longest_edge": 12845056,
18:     "shortest_edge": 3136
18:   },
18:   "temporal_patch_size": 2
18: }
18: 
 8: [INFO|tokenization_utils_base.py:2323] 2025-06-27 21:02:52,057 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
 3: [INFO|processing_utils.py:884] 2025-06-27 21:02:52,079 >> Processor Qwen2_5_VLProcessor:
 3: - image_processor: Qwen2VLImageProcessorFast {
 3:   "crop_size": null,
 3:   "data_format": "channels_first",
 3:   "default_to_square": true,
 3:   "device": null,
 3:   "do_center_crop": null,
 3:   "do_convert_rgb": true,
 3:   "do_normalize": true,
 3:   "do_rescale": true,
 3:   "do_resize": true,
 3:   "image_mean": [
 3:     0.48145466,
 3:     0.4578275,
 3:     0.40821073
 3:   ],
 3:   "image_processor_type": "Qwen2VLImageProcessorFast",
 3:   "image_std": [
 3:     0.26862954,
 3:     0.26130258,
 3:     0.27577711
 3:   ],
 3:   "input_data_format": null,
 3:   "max_pixels": 12845056,
 3:   "merge_size": 2,
 3:   "min_pixels": 3136,
 3:   "patch_size": 14,
 3:   "processor_class": "Qwen2_5_VLProcessor",
 3:   "resample": 3,
 3:   "rescale_factor": 0.00392156862745098,
 3:   "return_tensors": null,
 3:   "size": {
 3:     "longest_edge": 12845056,
 3:     "shortest_edge": 3136
 3:   },
 3:   "temporal_patch_size": 2
 3: }
 3: 
 3: - tokenizer: Qwen2TokenizerFast(name_or_path='Qwen/Qwen2.5-VL-7B-Instruct', vocab_size=151643, model_max_length=131072, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
 3: 	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 3: 	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 3: 	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 3: 	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 3: 	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 3: 	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 3: 	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 3: 	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 3: 	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 3: 	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 3: 	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 3: 	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 3: 	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 3: 	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 3: 	151657: AddedToken("<tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 3: 	151658: AddedToken("</tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 3: 	151659: AddedToken("<|fim_prefix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 3: 	151660: AddedToken("<|fim_middle|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 3: 	151661: AddedToken("<|fim_suffix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 3: 	151662: AddedToken("<|fim_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 3: 	151663: AddedToken("<|repo_name|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 3: 	151664: AddedToken("<|file_sep|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 3: }
 3: )
 3: 
 3: {
 3:   "processor_class": "Qwen2_5_VLProcessor"
 3: }
 3: 
29: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:52,081 >> loading file vocab.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
29: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:52,081 >> loading file merges.txt from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
29: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:52,081 >> loading file tokenizer.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
29: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:52,081 >> loading file added_tokens.json from cache at None
29: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:52,081 >> loading file special_tokens_map.json from cache at None
29: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:52,081 >> loading file tokenizer_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
29: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:52,081 >> loading file chat_template.jinja from cache at None
 3: [WARNING|2025-06-27 21:02:52] llamafactory.data.loader:148 >> Loading dataset from disk will ignore other data arguments.
 4: [INFO|tokenization_utils_base.py:2323] 2025-06-27 21:02:52,130 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
 6: [INFO|tokenization_utils_base.py:2323] 2025-06-27 21:02:52,130 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
 0: [INFO|2025-06-27 21:02:52] llamafactory.hparams.parser:406 >> Process rank: 1, world size: 128, device: cuda:1, distributed training: True, compute dtype: torch.bfloat16
 0: [INFO|2025-06-27 21:02:52] llamafactory.hparams.parser:406 >> Process rank: 3, world size: 128, device: cuda:3, distributed training: True, compute dtype: torch.bfloat16
22: [INFO|2025-06-27 21:02:52] llamafactory.hparams.parser:406 >> Process rank: 91, world size: 128, device: cuda:3, distributed training: True, compute dtype: torch.bfloat16
18: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:52,154 >> loading file vocab.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
18: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:52,154 >> loading file merges.txt from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
18: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:52,154 >> loading file tokenizer.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
18: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:52,154 >> loading file added_tokens.json from cache at None
18: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:52,154 >> loading file special_tokens_map.json from cache at None
18: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:52,154 >> loading file tokenizer_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
18: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:52,154 >> loading file chat_template.jinja from cache at None
22: [INFO|2025-06-27 21:02:52] llamafactory.hparams.parser:406 >> Process rank: 90, world size: 128, device: cuda:2, distributed training: True, compute dtype: torch.bfloat16
22: [INFO|2025-06-27 21:02:52] llamafactory.hparams.parser:406 >> Process rank: 89, world size: 128, device: cuda:1, distributed training: True, compute dtype: torch.bfloat16
14: [INFO|tokenization_utils_base.py:2323] 2025-06-27 21:02:52,172 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
11: [INFO|processing_utils.py:884] 2025-06-27 21:02:52,173 >> Processor Qwen2_5_VLProcessor:
11: - image_processor: Qwen2VLImageProcessorFast {
11:   "crop_size": null,
11:   "data_format": "channels_first",
11:   "default_to_square": true,
11:   "device": null,
11:   "do_center_crop": null,
11:   "do_convert_rgb": true,
11:   "do_normalize": true,
11:   "do_rescale": true,
11:   "do_resize": true,
11:   "image_mean": [
11:     0.48145466,
11:     0.4578275,
11:     0.40821073
11:   ],
11:   "image_processor_type": "Qwen2VLImageProcessorFast",
11:   "image_std": [
11:     0.26862954,
11:     0.26130258,
11:     0.27577711
11:   ],
11:   "input_data_format": null,
11:   "max_pixels": 12845056,
11:   "merge_size": 2,
11:   "min_pixels": 3136,
11:   "patch_size": 14,
11:   "processor_class": "Qwen2_5_VLProcessor",
11:   "resample": 3,
11:   "rescale_factor": 0.00392156862745098,
11:   "return_tensors": null,
11:   "size": {
11:     "longest_edge": 12845056,
11:     "shortest_edge": 3136
11:   },
11:   "temporal_patch_size": 2
11: }
11: 
11: - tokenizer: Qwen2TokenizerFast(name_or_path='Qwen/Qwen2.5-VL-7B-Instruct', vocab_size=151643, model_max_length=131072, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
11: 	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
11: 	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
11: 	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
11: 	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
11: 	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
11: 	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
11: 	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
11: 	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
11: 	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
11: 	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
11: 	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
11: 	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
11: 	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
11: 	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
11: 	151657: AddedToken("<tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
11: 	151658: AddedToken("</tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
11: 	151659: AddedToken("<|fim_prefix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
11: 	151660: AddedToken("<|fim_middle|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
11: 	151661: AddedToken("<|fim_suffix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
11: 	151662: AddedToken("<|fim_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
11: 	151663: AddedToken("<|repo_name|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
11: 	151664: AddedToken("<|file_sep|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
11: }
11: )
11: 
11: {
11:   "processor_class": "Qwen2_5_VLProcessor"
11: }
11: 
30: [INFO|processing_utils.py:884] 2025-06-27 21:02:52,174 >> Processor Qwen2_5_VLProcessor:
30: - image_processor: Qwen2VLImageProcessorFast {
30:   "crop_size": null,
30:   "data_format": "channels_first",
30:   "default_to_square": true,
30:   "device": null,
30:   "do_center_crop": null,
30:   "do_convert_rgb": true,
30:   "do_normalize": true,
30:   "do_rescale": true,
30:   "do_resize": true,
30:   "image_mean": [
30:     0.48145466,
30:     0.4578275,
30:     0.40821073
30:   ],
30:   "image_processor_type": "Qwen2VLImageProcessorFast",
30:   "image_std": [
30:     0.26862954,
30:     0.26130258,
30:     0.27577711
30:   ],
30:   "input_data_format": null,
30:   "max_pixels": 12845056,
30:   "merge_size": 2,
30:   "min_pixels": 3136,
30:   "patch_size": 14,
30:   "processor_class": "Qwen2_5_VLProcessor",
30:   "resample": 3,
30:   "rescale_factor": 0.00392156862745098,
30:   "return_tensors": null,
30:   "size": {
30:     "longest_edge": 12845056,
30:     "shortest_edge": 3136
30:   },
30:   "temporal_patch_size": 2
30: }
30: 
30: - tokenizer: Qwen2TokenizerFast(name_or_path='Qwen/Qwen2.5-VL-7B-Instruct', vocab_size=151643, model_max_length=131072, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
30: 	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
30: 	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
30: 	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
30: 	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
30: 	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
30: 	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
30: 	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
30: 	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
30: 	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
30: 	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
30: 	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
30: 	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
30: 	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
30: 	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
30: 	151657: AddedToken("<tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
30: 	151658: AddedToken("</tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
30: 	151659: AddedToken("<|fim_prefix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
30: 	151660: AddedToken("<|fim_middle|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
30: 	151661: AddedToken("<|fim_suffix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
30: 	151662: AddedToken("<|fim_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
30: 	151663: AddedToken("<|repo_name|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
30: 	151664: AddedToken("<|file_sep|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
30: }
30: )
30: 
30: {
30:   "processor_class": "Qwen2_5_VLProcessor"
30: }
30: 
26: [INFO|processing_utils.py:884] 2025-06-27 21:02:52,181 >> Processor Qwen2_5_VLProcessor:
26: - image_processor: Qwen2VLImageProcessorFast {
26:   "crop_size": null,
26:   "data_format": "channels_first",
26:   "default_to_square": true,
26:   "device": null,
26:   "do_center_crop": null,
26:   "do_convert_rgb": true,
26:   "do_normalize": true,
26:   "do_rescale": true,
26:   "do_resize": true,
26:   "image_mean": [
26:     0.48145466,
26:     0.4578275,
26:     0.40821073
26:   ],
26:   "image_processor_type": "Qwen2VLImageProcessorFast",
26:   "image_std": [
26:     0.26862954,
26:     0.26130258,
26:     0.27577711
26:   ],
26:   "input_data_format": null,
26:   "max_pixels": 12845056,
26:   "merge_size": 2,
26:   "min_pixels": 3136,
26:   "patch_size": 14,
26:   "processor_class": "Qwen2_5_VLProcessor",
26:   "resample": 3,
26:   "rescale_factor": 0.00392156862745098,
26:   "return_tensors": null,
26:   "size": {
26:     "longest_edge": 12845056,
26:     "shortest_edge": 3136
26:   },
26:   "temporal_patch_size": 2
26: }
26: 
26: - tokenizer: Qwen2TokenizerFast(name_or_path='Qwen/Qwen2.5-VL-7B-Instruct', vocab_size=151643, model_max_length=131072, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
26: 	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
26: 	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
26: 	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
26: 	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
26: 	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
26: 	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
26: 	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
26: 	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
26: 	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
26: 	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
26: 	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
26: 	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
26: 	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
26: 	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
26: 	151657: AddedToken("<tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
26: 	151658: AddedToken("</tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
26: 	151659: AddedToken("<|fim_prefix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
26: 	151660: AddedToken("<|fim_middle|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
26: 	151661: AddedToken("<|fim_suffix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
26: 	151662: AddedToken("<|fim_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
26: 	151663: AddedToken("<|repo_name|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
26: 	151664: AddedToken("<|file_sep|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
26: }
26: )
26: 
26: {
26:   "processor_class": "Qwen2_5_VLProcessor"
26: }
26: 
 7: [INFO|2025-06-27 21:02:52] llamafactory.hparams.parser:406 >> Process rank: 29, world size: 128, device: cuda:1, distributed training: True, compute dtype: torch.bfloat16
12: [INFO|2025-06-27 21:02:52] llamafactory.hparams.parser:406 >> Process rank: 50, world size: 128, device: cuda:2, distributed training: True, compute dtype: torch.bfloat16
30: [WARNING|2025-06-27 21:02:52] llamafactory.data.loader:148 >> Loading dataset from disk will ignore other data arguments.
11: [WARNING|2025-06-27 21:02:52] llamafactory.data.loader:148 >> Loading dataset from disk will ignore other data arguments.
26: [WARNING|2025-06-27 21:02:52] llamafactory.data.loader:148 >> Loading dataset from disk will ignore other data arguments.
 7: [INFO|2025-06-27 21:02:52] llamafactory.hparams.parser:406 >> Process rank: 30, world size: 128, device: cuda:2, distributed training: True, compute dtype: torch.bfloat16
10: [INFO|2025-06-27 21:02:52] llamafactory.data.loader:143 >> Loaded tokenized dataset from /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/tokenizer.
28: [INFO|2025-06-27 21:02:52] llamafactory.data.loader:143 >> Loaded tokenized dataset from /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/tokenizer.
25: [INFO|2025-06-27 21:02:52] llamafactory.data.loader:143 >> Loaded tokenized dataset from /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/tokenizer.
 1: [INFO|2025-06-27 21:02:52] llamafactory.data.loader:143 >> Loaded tokenized dataset from /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/tokenizer.
 5: [INFO|2025-06-27 21:02:52] llamafactory.data.loader:143 >> Loaded tokenized dataset from /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/tokenizer.
 9: [INFO|2025-06-27 21:02:52] llamafactory.data.loader:143 >> Loaded tokenized dataset from /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/tokenizer.
21: [INFO|2025-06-27 21:02:52] llamafactory.data.loader:143 >> Loaded tokenized dataset from /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/tokenizer.
29: [INFO|tokenization_utils_base.py:2323] 2025-06-27 21:02:52,253 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
 2: [INFO|2025-06-27 21:02:52] llamafactory.data.loader:143 >> Loaded tokenized dataset from /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/tokenizer.
18: [INFO|tokenization_utils_base.py:2323] 2025-06-27 21:02:52,324 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
19: [INFO|2025-06-27 21:02:52] llamafactory.hparams.parser:406 >> Process rank: 78, world size: 128, device: cuda:2, distributed training: True, compute dtype: torch.bfloat16
11: [INFO|2025-06-27 21:02:52] llamafactory.hparams.parser:406 >> Process rank: 46, world size: 128, device: cuda:2, distributed training: True, compute dtype: torch.bfloat16
11: [INFO|2025-06-27 21:02:52] llamafactory.hparams.parser:406 >> Process rank: 47, world size: 128, device: cuda:3, distributed training: True, compute dtype: torch.bfloat16
 1: [INFO|configuration_utils.py:693] 2025-06-27 21:02:52,365 >> loading configuration file config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/config.json
25: [INFO|configuration_utils.py:693] 2025-06-27 21:02:52,365 >> loading configuration file config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/config.json
 9: [INFO|configuration_utils.py:693] 2025-06-27 21:02:52,365 >> loading configuration file config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/config.json
 5: [INFO|configuration_utils.py:693] 2025-06-27 21:02:52,365 >> loading configuration file config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/config.json
28: [INFO|configuration_utils.py:693] 2025-06-27 21:02:52,365 >> loading configuration file config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/config.json
21: [INFO|configuration_utils.py:693] 2025-06-27 21:02:52,365 >> loading configuration file config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/config.json
 1: [INFO|configuration_utils.py:765] 2025-06-27 21:02:52,367 >> Model config Qwen2_5_VLConfig {
 1:   "architectures": [
 1:     "Qwen2_5_VLForConditionalGeneration"
 1:   ],
 1:   "attention_dropout": 0.0,
 1:   "bos_token_id": 151643,
 1:   "eos_token_id": 151645,
 1:   "hidden_act": "silu",
 1:   "hidden_size": 3584,
 1:   "image_token_id": 151655,
 1:   "initializer_range": 0.02,
 1:   "intermediate_size": 18944,
 1:   "max_position_embeddings": 128000,
 1:   "max_window_layers": 28,
 1:   "model_type": "qwen2_5_vl",
 1:   "num_attention_heads": 28,
 1:   "num_hidden_layers": 28,
 1:   "num_key_value_heads": 4,
 1:   "rms_norm_eps": 1e-06,
 1:   "rope_scaling": {
 1:     "mrope_section": [
 1:       16,
 1:       24,
 1:       24
 1:     ],
 1:     "rope_type": "default",
 1:     "type": "default"
 1:   },
 1:   "rope_theta": 1000000.0,
 1:   "sliding_window": 32768,
 1:   "tie_word_embeddings": false,
 1:   "torch_dtype": "bfloat16",
 1:   "transformers_version": "4.51.3",
 1:   "use_cache": true,
 1:   "use_sliding_window": false,
 1:   "video_token_id": 151656,
 1:   "vision_config": {
 1:     "depth": 32,
 1:     "fullatt_block_indexes": [
 1:       7,
 1:       15,
 1:       23,
 1:       31
 1:     ],
 1:     "hidden_act": "silu",
 1:     "hidden_size": 1280,
 1:     "in_channels": 3,
 1:     "in_chans": 3,
 1:     "intermediate_size": 3420,
 1:     "model_type": "qwen2_5_vl",
 1:     "num_heads": 16,
 1:     "out_hidden_size": 3584,
 1:     "patch_size": 14,
 1:     "spatial_merge_size": 2,
 1:     "spatial_patch_size": 14,
 1:     "temporal_patch_size": 2,
 1:     "tokens_per_second": 2,
 1:     "window_size": 112
 1:   },
 1:   "vision_end_token_id": 151653,
 1:   "vision_start_token_id": 151652,
 1:   "vision_token_id": 151654,
 1:   "vocab_size": 152064
 1: }
 1: 
 1: [INFO|2025-06-27 21:02:52] llamafactory.model.model_utils.kv_cache:143 >> KV cache is disabled during training.
25: [INFO|configuration_utils.py:765] 2025-06-27 21:02:52,367 >> Model config Qwen2_5_VLConfig {
25:   "architectures": [
25:     "Qwen2_5_VLForConditionalGeneration"
25:   ],
25:   "attention_dropout": 0.0,
25:   "bos_token_id": 151643,
25:   "eos_token_id": 151645,
25:   "hidden_act": "silu",
25:   "hidden_size": 3584,
25:   "image_token_id": 151655,
25:   "initializer_range": 0.02,
25:   "intermediate_size": 18944,
25:   "max_position_embeddings": 128000,
25:   "max_window_layers": 28,
25:   "model_type": "qwen2_5_vl",
25:   "num_attention_heads": 28,
25:   "num_hidden_layers": 28,
25:   "num_key_value_heads": 4,
25:   "rms_norm_eps": 1e-06,
25:   "rope_scaling": {
25:     "mrope_section": [
25:       16,
25:       24,
25:       24
25:     ],
25:     "rope_type": "default",
25:     "type": "default"
25:   },
25:   "rope_theta": 1000000.0,
25:   "sliding_window": 32768,
25:   "tie_word_embeddings": false,
25:   "torch_dtype": "bfloat16",
25:   "transformers_version": "4.51.3",
25:   "use_cache": true,
25:   "use_sliding_window": false,
25:   "video_token_id": 151656,
25:   "vision_config": {
25:     "depth": 32,
25:     "fullatt_block_indexes": [
25:       7,
25: [INFO|2025-06-27 21:02:52] llamafactory.model.model_utils.kv_cache:143 >> KV cache is disabled during training.
25:       15,
25:       23,
25:       31
25:     ],
25:     "hidden_act": "silu",
25:     "hidden_size": 1280,
25:     "in_channels": 3,
25:     "in_chans": 3,
25:     "intermediate_size": 3420,
25:     "model_type": "qwen2_5_vl",
25:     "num_heads": 16,
25:     "out_hidden_size": 3584,
25:     "patch_size": 14,
25:     "spatial_merge_size": 2,
25:     "spatial_patch_size": 14,
25:     "temporal_patch_size": 2,
25:     "tokens_per_second": 2,
25:     "window_size": 112
25:   },
25:   "vision_end_token_id": 151653,
25:   "vision_start_token_id": 151652,
25:   "vision_token_id": 151654,
25:   "vocab_size": 152064
25: }
25: 
21: [INFO|configuration_utils.py:765] 2025-06-27 21:02:52,368 >> Model config Qwen2_5_VLConfig {
21:   "architectures": [
21:     "Qwen2_5_VLForConditionalGeneration"
21:   ],
21:   "attention_dropout": 0.0,
21:   "bos_token_id": 151643,
21:   "eos_token_id": 151645,
21:   "hidden_act": "silu",
21:   "hidden_size": 3584,
21:   "image_token_id": 151655,
21:   "initializer_range": 0.02,
21:   "intermediate_size": 18944,
21:   "max_position_embeddings": 128000,
21:   "max_window_layers": 28,
21:   "model_type": "qwen2_5_vl",
21:   "num_attention_heads": 28,
21:   "num_hidden_layers": 28,
21:   "num_key_value_heads": 4,
21:   "rms_norm_eps": 1e-06,
21:   "rope_scaling": {
21:     "mrope_section": [
21:       16,
21:       24,
21:       24
21:     ],
21:     "rope_type": "default",
21:     "type": "default"
21:   },
21:   "rope_theta": 1000000.0,
21:   "sliding_window": 32768,
21:   "tie_word_embeddings": false,
21:   "torch_dtype": "bfloat16",
21:   "transformers_version": "4.51.3",
21:   "use_cache": true,
21:   "use_sliding_window": false,
21:   "video_token_id": 151656,
21:   "vision_config": {
21:     "depth": 32,
21:     "fullatt_block_indexes": [
21:       7,
 9: [INFO|configuration_utils.py:765] 2025-06-27 21:02:52,368 >> Model config Qwen2_5_VLConfig {
 9:   "architectures": [
 9:     "Qwen2_5_VLForConditionalGeneration"
 9:   ],
 9:   "attention_dropout": 0.0,
 9:   "bos_token_id": 151643,
 9:   "eos_token_id": 151645,
 9:   "hidden_act": "silu",
 9:   "hidden_size": 3584,
 9:   "image_token_id": 151655,
 9:   "initializer_range": 0.02,
 9:   "intermediate_size": 18944,
 9:   "max_position_embeddings": 128000,
 9:   "max_window_layers": 28,
 9:   "model_type": "qwen2_5_vl",
 9:   "num_attention_heads": 28,
 9:   "num_hidden_layers": 28,
 9:   "num_key_value_heads": 4,
 9:   "rms_norm_eps": 1e-06,
 9:   "rope_scaling": {
 9:     "mrope_section": [
 9:       16,
 9:       24,
 9:       24
 9:     ],
 9:     "rope_type": "default",
 9:     "type": "default"
 9:   },
 9:   "rope_theta": 1000000.0,
 9:   "sliding_window": 32768,
 9:   "tie_word_embeddings": false,
 9:   "torch_dtype": "bfloat16",
 9:   "transformers_version": "4.51.3",
 9:   "use_cache": true,
 9:   "use_sliding_window": false,
 9:   "video_token_id": 151656,
 9:   "vision_config": {
 9:     "depth": 32,
 9:     "fullatt_block_indexes": [
 9:       7,
21: [INFO|2025-06-27 21:02:52] llamafactory.model.model_utils.kv_cache:143 >> KV cache is disabled during training.
 5: [INFO|configuration_utils.py:765] 2025-06-27 21:02:52,368 >> Model config Qwen2_5_VLConfig {
 5:   "architectures": [
 5:     "Qwen2_5_VLForConditionalGeneration"
 5:   ],
 5:   "attention_dropout": 0.0,
 5:   "bos_token_id": 151643,
 5:   "eos_token_id": 151645,
 5:   "hidden_act": "silu",
 5:   "hidden_size": 3584,
 5:   "image_token_id": 151655,
 5:   "initializer_range": 0.02,
 5:   "intermediate_size": 18944,
 5:   "max_position_embeddings": 128000,
 5:   "max_window_layers": 28,
 5:   "model_type": "qwen2_5_vl",
 5:   "num_attention_heads": 28,
 5:   "num_hidden_layers": 28,
 5:   "num_key_value_heads": 4,
 5:   "rms_norm_eps": 1e-06,
 5:   "rope_scaling": {
 5:     "mrope_section": [
 5:       16,
 5:       24,
 5:       24
 5:     ],
 5:     "rope_type": "default",
 5:     "type": "default"
 5:   },
 5:   "rope_theta": 1000000.0,
 5:   "sliding_window": 32768,
 5:   "tie_word_embeddings": false,
 5:   "torch_dtype": "bfloat16",
 5:   "transformers_version": "4.51.3",
 5:   "use_cache": true,
 5:   "use_sliding_window": false,
 5:   "video_token_id": 151656,
 5:   "vision_config": {
 5:     "depth": 32,
 5:     "fullatt_block_indexes": [
 5:       7,
 9: [INFO|2025-06-27 21:02:52] llamafactory.model.model_utils.kv_cache:143 >> KV cache is disabled during training.
21:       15,
21:       23,
21:       31
21:     ],
21:     "hidden_act": "silu",
21:     "hidden_size": 1280,
21:     "in_channels": 3,
21:     "in_chans": 3,
21:     "intermediate_size": 3420,
21:     "model_type": "qwen2_5_vl",
21:     "num_heads": 16,
21:     "out_hidden_size": 3584,
21:     "patch_size": 14,
21:     "spatial_merge_size": 2,
21:     "spatial_patch_size": 14,
21:     "temporal_patch_size": 2,
21:     "tokens_per_second": 2,
21:     "window_size": 112
21:   },
21:   "vision_end_token_id": 151653,
21:   "vision_start_token_id": 151652,
21:   "vision_token_id": 151654,
21:   "vocab_size": 152064
21: }
21: 
 5: [INFO|2025-06-27 21:02:52] llamafactory.model.model_utils.kv_cache:143 >> KV cache is disabled during training.
 9:       15,
 9:       23,
 9:       31
 9:     ],
 9:     "hidden_act": "silu",
 9:     "hidden_size": 1280,
 9:     "in_channels": 3,
 9:     "in_chans": 3,
 9:     "intermediate_size": 3420,
 9:     "model_type": "qwen2_5_vl",
 9:     "num_heads": 16,
 9:     "out_hidden_size": 3584,
 9:     "patch_size": 14,
 9:     "spatial_merge_size": 2,
 9:     "spatial_patch_size": 14,
 9:     "temporal_patch_size": 2,
 9:     "tokens_per_second": 2,
 9:     "window_size": 112
 9:   },
 9:   "vision_end_token_id": 151653,
 9:   "vision_start_token_id": 151652,
 9:   "vision_token_id": 151654,
 9:   "vocab_size": 152064
 9: }
 9: 
28: [INFO|2025-06-27 21:02:52] llamafactory.model.model_utils.kv_cache:143 >> KV cache is disabled during training.
 5:       15,
 5:       23,
 5:       31
 5:     ],
 5:     "hidden_act": "silu",
 5:     "hidden_size": 1280,
 5:     "in_channels": 3,
 5:     "in_chans": 3,
 5:     "intermediate_size": 3420,
 5:     "model_type": "qwen2_5_vl",
 5:     "num_heads": 16,
 5:     "out_hidden_size": 3584,
 5:     "patch_size": 14,
 5:     "spatial_merge_size": 2,
 5:     "spatial_patch_size": 14,
 5:     "temporal_patch_size": 2,
 5:     "tokens_per_second": 2,
 5:     "window_size": 112
 5:   },
 5:   "vision_end_token_id": 151653,
 5:   "vision_start_token_id": 151652,
 5:   "vision_token_id": 151654,
 5:   "vocab_size": 152064
 5: }
 5: 
28: [INFO|configuration_utils.py:765] 2025-06-27 21:02:52,368 >> Model config Qwen2_5_VLConfig {
28:   "architectures": [
28:     "Qwen2_5_VLForConditionalGeneration"
28:   ],
28:   "attention_dropout": 0.0,
28:   "bos_token_id": 151643,
28:   "eos_token_id": 151645,
28:   "hidden_act": "silu",
28:   "hidden_size": 3584,
28:   "image_token_id": 151655,
28:   "initializer_range": 0.02,
28:   "intermediate_size": 18944,
28:   "max_position_embeddings": 128000,
28:   "max_window_layers": 28,
28:   "model_type": "qwen2_5_vl",
28:   "num_attention_heads": 28,
28:   "num_hidden_layers": 28,
28:   "num_key_value_heads": 4,
28:   "rms_norm_eps": 1e-06,
28:   "rope_scaling": {
28:     "mrope_section": [
28:       16,
28:       24,
28:       24
28:     ],
28:     "rope_type": "default",
28:     "type": "default"
28:   },
28:   "rope_theta": 1000000.0,
28:   "sliding_window": 32768,
28:   "tie_word_embeddings": false,
28:   "torch_dtype": "bfloat16",
28:   "transformers_version": "4.51.3",
28:   "use_cache": true,
28:   "use_sliding_window": false,
28:   "video_token_id": 151656,
28:   "vision_config": {
28:     "depth": 32,
28:     "fullatt_block_indexes": [
28:       7,
28:       15,
28:       23,
28:       31
28:     ],
28:     "hidden_act": "silu",
28:     "hidden_size": 1280,
28:     "in_channels": 3,
28:     "in_chans": 3,
28:     "intermediate_size": 3420,
28:     "model_type": "qwen2_5_vl",
28:     "num_heads": 16,
28:     "out_hidden_size": 3584,
28:     "patch_size": 14,
28:     "spatial_merge_size": 2,
28:     "spatial_patch_size": 14,
28:     "temporal_patch_size": 2,
28:     "tokens_per_second": 2,
28:     "window_size": 112
28:   },
28:   "vision_end_token_id": 151653,
28:   "vision_start_token_id": 151652,
28:   "vision_token_id": 151654,
28:   "vocab_size": 152064
28: }
28: 
10: [INFO|configuration_utils.py:693] 2025-06-27 21:02:52,369 >> loading configuration file config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/config.json
10: [INFO|configuration_utils.py:765] 2025-06-27 21:02:52,372 >> Model config Qwen2_5_VLConfig {
10:   "architectures": [
10:     "Qwen2_5_VLForConditionalGeneration"
10:   ],
10:   "attention_dropout": 0.0,
10:   "bos_token_id": 151643,
10:   "eos_token_id": 151645,
10:   "hidden_act": "silu",
10:   "hidden_size": 3584,
10:   "image_token_id": 151655,
10:   "initializer_range": 0.02,
10:   "intermediate_size": 18944,
10:   "max_position_embeddings": 128000,
10:   "max_window_layers": 28,
10:   "model_type": "qwen2_5_vl",
10:   "num_attention_heads": 28,
10:   "num_hidden_layers": 28,
10:   "num_key_value_heads": 4,
10:   "rms_norm_eps": 1e-06,
10:   "rope_scaling": {
10:     "mrope_section": [
10:       16,
10:       24,
10:       24
10:     ],
10:     "rope_type": "default",
10:     "type": "default"
10:   },
10:   "rope_theta": 1000000.0,
10:   "sliding_window": 32768,
10:   "tie_word_embeddings": false,
10:   "torch_dtype": "bfloat16",
10:   "transformers_version": "4.51.3",
10:   "use_cache": true,
10:   "use_sliding_window": false,
10:   "video_token_id": 151656,
10:   "vision_config": {
10:     "depth": 32,
10:     "fullatt_block_indexes": [
10:       7,
10:       15,
10:       23,
10:       31
10:     ],
10:     "hidden_act": "silu",
10:     "hidden_size": 1280,
10:     "in_channels": 3,
10:     "in_chans": 3,
10:     "intermediate_size": 3420,
10:     "model_type": "qwen2_5_vl",
10:     "num_heads": 16,
10:     "out_hidden_size": 3584,
10:     "patch_size": 14,
10:     "spatial_merge_size": 2,
10:     "spatial_patch_size": 14,
10:     "temporal_patch_size": 2,
10:     "tokens_per_second": 2,
10:     "window_size": 112
10:   },
10:   "vision_end_token_id": 151653,
10:   "vision_start_token_id": 151652,
10:   "vision_token_id": 151654,
10:   "vocab_size": 152064
10: }
10: 
10: [INFO|2025-06-27 21:02:52] llamafactory.model.model_utils.kv_cache:143 >> KV cache is disabled during training.
21: [INFO|modeling_utils.py:1124] 2025-06-27 21:02:52,386 >> loading weights file model.safetensors from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/model.safetensors.index.json
25: [INFO|modeling_utils.py:1124] 2025-06-27 21:02:52,388 >> loading weights file model.safetensors from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/model.safetensors.index.json
28: [INFO|modeling_utils.py:1124] 2025-06-27 21:02:52,389 >> loading weights file model.safetensors from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/model.safetensors.index.json
 1: [INFO|modeling_utils.py:1124] 2025-06-27 21:02:52,389 >> loading weights file model.safetensors from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/model.safetensors.index.json
 9: [INFO|modeling_utils.py:1124] 2025-06-27 21:02:52,390 >> loading weights file model.safetensors from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/model.safetensors.index.json
 5: [INFO|modeling_utils.py:1124] 2025-06-27 21:02:52,390 >> loading weights file model.safetensors from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/model.safetensors.index.json
10: [INFO|modeling_utils.py:1124] 2025-06-27 21:02:52,394 >> loading weights file model.safetensors from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/model.safetensors.index.json
 1: [INFO|2025-06-27 21:02:52] llamafactory.hparams.parser:406 >> Process rank: 6, world size: 128, device: cuda:2, distributed training: True, compute dtype: torch.bfloat16
 1: [INFO|2025-06-27 21:02:52] llamafactory.hparams.parser:406 >> Process rank: 7, world size: 128, device: cuda:3, distributed training: True, compute dtype: torch.bfloat16
 1: [INFO|modeling_utils.py:3726] 2025-06-27 21:02:52,410 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model
 5: [INFO|modeling_utils.py:3726] 2025-06-27 21:02:52,410 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model
 1: [2025-06-27 21:02:52,410] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
 5: [2025-06-27 21:02:52,411] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
21: [INFO|modeling_utils.py:3726] 2025-06-27 21:02:52,411 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model
21: [2025-06-27 21:02:52,411] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
21: [2025-06-27 21:02:52,411] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
 9: [INFO|modeling_utils.py:3726] 2025-06-27 21:02:52,414 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model
25: [INFO|modeling_utils.py:3726] 2025-06-27 21:02:52,414 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model
28: [INFO|modeling_utils.py:3726] 2025-06-27 21:02:52,414 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model
10: [INFO|modeling_utils.py:3726] 2025-06-27 21:02:52,414 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model
28: [2025-06-27 21:02:52,414] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
25: [2025-06-27 21:02:52,414] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
 9: [2025-06-27 21:02:52,414] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
10: [2025-06-27 21:02:52,414] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
 1: [INFO|configuration_utils.py:1142] 2025-06-27 21:02:52,416 >> Generate config GenerationConfig {
 1:   "bos_token_id": 151643,
 1:   "eos_token_id": 151645,
 1:   "use_cache": false
 1: }
 1: 
 1: [INFO|modeling_utils.py:2167] 2025-06-27 21:02:52,416 >> Instantiating Qwen2_5_VisionTransformerPretrainedModel model under default dtype torch.float32.
21: [INFO|configuration_utils.py:1142] 2025-06-27 21:02:52,417 >> Generate config GenerationConfig {
21:   "bos_token_id": 151643,
21:   "eos_token_id": 151645,
21:   "use_cache": false
21: }
21: 
21: [INFO|modeling_utils.py:2167] 2025-06-27 21:02:52,417 >> Instantiating Qwen2_5_VisionTransformerPretrainedModel model under default dtype torch.float32.
 5: [INFO|configuration_utils.py:1142] 2025-06-27 21:02:52,417 >> Generate config GenerationConfig {
 5:   "bos_token_id": 151643,
 5:   "eos_token_id": 151645,
 5:   "use_cache": false
 5: }
 5: 
 5: [INFO|modeling_utils.py:2167] 2025-06-27 21:02:52,418 >> Instantiating Qwen2_5_VisionTransformerPretrainedModel model under default dtype torch.float32.
25: [INFO|configuration_utils.py:1142] 2025-06-27 21:02:52,419 >> Generate config GenerationConfig {
25:   "bos_token_id": 151643,
25:   "eos_token_id": 151645,
25:   "use_cache": false
25: }
25: 
28: [INFO|configuration_utils.py:1142] 2025-06-27 21:02:52,420 >> Generate config GenerationConfig {
28:   "bos_token_id": 151643,
28:   "eos_token_id": 151645,
28:   "use_cache": false
28: }
28: 
25: [INFO|modeling_utils.py:2167] 2025-06-27 21:02:52,420 >> Instantiating Qwen2_5_VisionTransformerPretrainedModel model under default dtype torch.float32.
28: [INFO|modeling_utils.py:2167] 2025-06-27 21:02:52,420 >> Instantiating Qwen2_5_VisionTransformerPretrainedModel model under default dtype torch.float32.
10: [INFO|configuration_utils.py:1142] 2025-06-27 21:02:52,420 >> Generate config GenerationConfig {
10:   "bos_token_id": 151643,
10:   "eos_token_id": 151645,
10:   "use_cache": false
10: }
10: 
10: [INFO|modeling_utils.py:2167] 2025-06-27 21:02:52,420 >> Instantiating Qwen2_5_VisionTransformerPretrainedModel model under default dtype torch.float32.
 9: [INFO|configuration_utils.py:1142] 2025-06-27 21:02:52,422 >> Generate config GenerationConfig {
 9:   "bos_token_id": 151643,
 9:   "eos_token_id": 151645,
 9:   "use_cache": false
 9: }
 9: 
 9: [INFO|modeling_utils.py:2167] 2025-06-27 21:02:52,423 >> Instantiating Qwen2_5_VisionTransformerPretrainedModel model under default dtype torch.float32.
23: [INFO|2025-06-27 21:02:52] llamafactory.data.loader:143 >> Loaded tokenized dataset from /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/tokenizer.
 2: [INFO|configuration_utils.py:693] 2025-06-27 21:02:52,435 >> loading configuration file config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/config.json
 2: [INFO|configuration_utils.py:765] 2025-06-27 21:02:52,437 >> Model config Qwen2_5_VLConfig {
 2:   "architectures": [
 2:     "Qwen2_5_VLForConditionalGeneration"
 2:   ],
 2:   "attention_dropout": 0.0,
 2:   "bos_token_id": 151643,
 2:   "eos_token_id": 151645,
 2:   "hidden_act": "silu",
 2:   "hidden_size": 3584,
 2:   "image_token_id": 151655,
 2:   "initializer_range": 0.02,
 2:   "intermediate_size": 18944,
 2:   "max_position_embeddings": 128000,
 2:   "max_window_layers": 28,
 2:   "model_type": "qwen2_5_vl",
 2:   "num_attention_heads": 28,
 2:   "num_hidden_layers": 28,
 2:   "num_key_value_heads": 4,
 2:   "rms_norm_eps": 1e-06,
 2:   "rope_scaling": {
 2:     "mrope_section": [
 2:       16,
 2:       24,
 2:       24
 2:     ],
 2:     "rope_type": "default",
 2:     "type": "default"
 2:   },
 2:   "rope_theta": 1000000.0,
 2:   "sliding_window": 32768,
 2:   "tie_word_embeddings": false,
 2:   "torch_dtype": "bfloat16",
 2:   "transformers_version": "4.51.3",
 2:   "use_cache": true,
 2:   "use_sliding_window": false,
 2:   "video_token_id": 151656,
 2:   "vision_config": {
 2:     "depth": 32,
 2:     "fullatt_block_indexes": [
 2:       7,
 2:       15,
 2:       23,
 2:       31
 2:     ],
 2:     "hidden_act": "silu",
 2:     "hidden_size": 1280,
 2:     "in_channels": 3,
 2:     "in_chans": 3,
 2:     "intermediate_size": 3420,
 2:     "model_type": "qwen2_5_vl",
 2:     "num_heads": 16,
 2:     "out_hidden_size": 3584,
 2:     "patch_size": 14,
 2:     "spatial_merge_size": 2,
 2:     "spatial_patch_size": 14,
 2:     "temporal_patch_size": 2,
 2:     "tokens_per_second": 2,
 2:     "window_size": 112
 2:   },
 2:   "vision_end_token_id": 151653,
 2:   "vision_start_token_id": 151652,
 2:   "vision_token_id": 151654,
 2:   "vocab_size": 152064
 2: }
 2: 
 2: [INFO|2025-06-27 21:02:52] llamafactory.model.model_utils.kv_cache:143 >> KV cache is disabled during training.
 2: [INFO|modeling_utils.py:1124] 2025-06-27 21:02:52,455 >> loading weights file model.safetensors from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/model.safetensors.index.json
 2: [INFO|modeling_utils.py:3726] 2025-06-27 21:02:52,463 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model
 2: [2025-06-27 21:02:52,463] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
27: [INFO|2025-06-27 21:02:52] llamafactory.data.loader:143 >> Loaded tokenized dataset from /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/tokenizer.
 2: [INFO|configuration_utils.py:1142] 2025-06-27 21:02:52,468 >> Generate config GenerationConfig {
 2:   "bos_token_id": 151643,
 2:   "eos_token_id": 151645,
 2:   "use_cache": false
 2: }
 2: 
 2: [INFO|modeling_utils.py:2167] 2025-06-27 21:02:52,468 >> Instantiating Qwen2_5_VisionTransformerPretrainedModel model under default dtype torch.float32.
15: [INFO|2025-06-27 21:02:52] llamafactory.data.loader:143 >> Loaded tokenized dataset from /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/tokenizer.
16: [INFO|processing_utils.py:884] 2025-06-27 21:02:52,479 >> Processor Qwen2_5_VLProcessor:
16: - image_processor: Qwen2VLImageProcessorFast {
16:   "crop_size": null,
16:   "data_format": "channels_first",
16:   "default_to_square": true,
16:   "device": null,
16:   "do_center_crop": null,
16:   "do_convert_rgb": true,
16:   "do_normalize": true,
16:   "do_rescale": true,
16:   "do_resize": true,
16:   "image_mean": [
16:     0.48145466,
16:     0.4578275,
16:     0.40821073
16:   ],
16:   "image_processor_type": "Qwen2VLImageProcessorFast",
16:   "image_std": [
16:     0.26862954,
16:     0.26130258,
16:     0.27577711
16:   ],
16:   "input_data_format": null,
16:   "max_pixels": 12845056,
16:   "merge_size": 2,
16:   "min_pixels": 3136,
16:   "patch_size": 14,
16:   "processor_class": "Qwen2_5_VLProcessor",
16:   "resample": 3,
16:   "rescale_factor": 0.00392156862745098,
16:   "return_tensors": null,
16:   "size": {
16:     "longest_edge": 12845056,
16:     "shortest_edge": 3136
16:   },
16:   "temporal_patch_size": 2
16: }
16: 
16: - tokenizer: Qwen2TokenizerFast(name_or_path='Qwen/Qwen2.5-VL-7B-Instruct', vocab_size=151643, model_max_length=131072, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
16: 	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
16: 	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
16: 	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
16: 	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
16: 	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
16: 	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
16: 	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
16: 	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
16: 	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
16: 	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
16: 	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
16: 	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
16: 	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
16: 	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
16: 	151657: AddedToken("<tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
16: 	151658: AddedToken("</tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
16: 	151659: AddedToken("<|fim_prefix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
16: 	151660: AddedToken("<|fim_middle|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
16: 	151661: AddedToken("<|fim_suffix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
16: 	151662: AddedToken("<|fim_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
16: 	151663: AddedToken("<|repo_name|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
16: 	151664: AddedToken("<|file_sep|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
16: }
16: )
16: 
16: {
16:   "processor_class": "Qwen2_5_VLProcessor"
16: }
16: 
16: [WARNING|2025-06-27 21:02:52] llamafactory.data.loader:148 >> Loading dataset from disk will ignore other data arguments.
12: [INFO|processing_utils.py:884] 2025-06-27 21:02:52,514 >> Processor Qwen2_5_VLProcessor:
12: - image_processor: Qwen2VLImageProcessorFast {
12:   "crop_size": null,
12:   "data_format": "channels_first",
12:   "default_to_square": true,
12:   "device": null,
12:   "do_center_crop": null,
12:   "do_convert_rgb": true,
12:   "do_normalize": true,
12:   "do_rescale": true,
12:   "do_resize": true,
12:   "image_mean": [
12:     0.48145466,
12:     0.4578275,
12:     0.40821073
12:   ],
12:   "image_processor_type": "Qwen2VLImageProcessorFast",
12:   "image_std": [
12:     0.26862954,
12:     0.26130258,
12:     0.27577711
12:   ],
12:   "input_data_format": null,
12:   "max_pixels": 12845056,
12:   "merge_size": 2,
12:   "min_pixels": 3136,
12:   "patch_size": 14,
12:   "processor_class": "Qwen2_5_VLProcessor",
12:   "resample": 3,
12:   "rescale_factor": 0.00392156862745098,
12:   "return_tensors": null,
12:   "size": {
12:     "longest_edge": 12845056,
12:     "shortest_edge": 3136
12:   },
12:   "temporal_patch_size": 2
12: }
12: 
12: - tokenizer: Qwen2TokenizerFast(name_or_path='Qwen/Qwen2.5-VL-7B-Instruct', vocab_size=151643, model_max_length=131072, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
12: 	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
12: 	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
12: 	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
12: 	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
12: 	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
12: 	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
12: 	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
12: 	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
12: 	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
12: 	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
12: 	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
12: 	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
12: 	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
12: 	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
12: 	151657: AddedToken("<tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
12: 	151658: AddedToken("</tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
12: 	151659: AddedToken("<|fim_prefix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
12: 	151660: AddedToken("<|fim_middle|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
12: 	151661: AddedToken("<|fim_suffix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
12: 	151662: AddedToken("<|fim_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
12: 	151663: AddedToken("<|repo_name|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
12: 	151664: AddedToken("<|file_sep|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
12: }
12: )
12: 
12: {
12:   "processor_class": "Qwen2_5_VLProcessor"
12: }
12: 
24: [INFO|2025-06-27 21:02:52] llamafactory.hparams.parser:406 >> Process rank: 96, world size: 128, device: cuda:0, distributed training: True, compute dtype: torch.bfloat16
13: [INFO|2025-06-27 21:02:52] llamafactory.data.loader:143 >> Loaded tokenized dataset from /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/tokenizer.
16: [INFO|2025-06-27 21:02:52] llamafactory.hparams.parser:406 >> Process rank: 67, world size: 128, device: cuda:3, distributed training: True, compute dtype: torch.bfloat16
16: [INFO|2025-06-27 21:02:52] llamafactory.hparams.parser:406 >> Process rank: 65, world size: 128, device: cuda:1, distributed training: True, compute dtype: torch.bfloat16
12: [WARNING|2025-06-27 21:02:52] llamafactory.data.loader:148 >> Loading dataset from disk will ignore other data arguments.
 7: [INFO|2025-06-27 21:02:52] llamafactory.hparams.parser:406 >> Process rank: 31, world size: 128, device: cuda:3, distributed training: True, compute dtype: torch.bfloat16
16: [INFO|2025-06-27 21:02:52] llamafactory.hparams.parser:406 >> Process rank: 66, world size: 128, device: cuda:2, distributed training: True, compute dtype: torch.bfloat16
23: [INFO|configuration_utils.py:693] 2025-06-27 21:02:52,570 >> loading configuration file config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/config.json
23: [INFO|configuration_utils.py:765] 2025-06-27 21:02:52,572 >> Model config Qwen2_5_VLConfig {
23:   "architectures": [
23:     "Qwen2_5_VLForConditionalGeneration"
23:   ],
23:   "attention_dropout": 0.0,
23:   "bos_token_id": 151643,
23:   "eos_token_id": 151645,
23:   "hidden_act": "silu",
23:   "hidden_size": 3584,
23:   "image_token_id": 151655,
23:   "initializer_range": 0.02,
23:   "intermediate_size": 18944,
23:   "max_position_embeddings": 128000,
23:   "max_window_layers": 28,
23:   "model_type": "qwen2_5_vl",
23:   "num_attention_heads": 28,
23:   "num_hidden_layers": 28,
23:   "num_key_value_heads": 4,
23:   "rms_norm_eps": 1e-06,
23:   "rope_scaling": {
23:     "mrope_section": [
23:       16,
23:       24,
23:       24
23:     ],
23:     "rope_type": "default",
23:     "type": "default"
23:   },
23:   "rope_theta": 1000000.0,
23:   "sliding_window": 32768,
23:   "tie_word_embeddings": false,
23:   "torch_dtype": "bfloat16",
23:   "transformers_version": "4.51.3",
23:   "use_cache": true,
23:   "use_sliding_window": false,
23:   "video_token_id": 151656,
23:   "vision_config": {
23:     "depth": 32,
23:     "fullatt_block_indexes": [
23:       7,
23:       15,
23:       23,
23:       31
23:     ],
23:     "hidden_act": "silu",
23:     "hidden_size": 1280,
23:     "in_channels": 3,
23:     "in_chans": 3,
23:     "intermediate_size": 3420,
23:     "model_type": "qwen2_5_vl",
23:     "num_heads": 16,
23:     "out_hidden_size": 3584,
23:     "patch_size": 14,
23:     "spatial_merge_size": 2,
23:     "spatial_patch_size": 14,
23:     "temporal_patch_size": 2,
23:     "tokens_per_second": 2,
23:     "window_size": 112
23:   },
23:   "vision_end_token_id": 151653,
23:   "vision_start_token_id": 151652,
23:   "vision_token_id": 151654,
23:   "vocab_size": 152064
23: }
23: 
23: [INFO|2025-06-27 21:02:52] llamafactory.model.model_utils.kv_cache:143 >> KV cache is disabled during training.
23: [INFO|modeling_utils.py:1124] 2025-06-27 21:02:52,594 >> loading weights file model.safetensors from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/model.safetensors.index.json
 3: [INFO|2025-06-27 21:02:52] llamafactory.hparams.parser:406 >> Process rank: 14, world size: 128, device: cuda:2, distributed training: True, compute dtype: torch.bfloat16
15: [INFO|configuration_utils.py:693] 2025-06-27 21:02:52,601 >> loading configuration file config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/config.json
 3: [INFO|2025-06-27 21:02:52] llamafactory.hparams.parser:406 >> Process rank: 15, world size: 128, device: cuda:3, distributed training: True, compute dtype: torch.bfloat16
23: [INFO|modeling_utils.py:3726] 2025-06-27 21:02:52,606 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model
23: [2025-06-27 21:02:52,606] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
27: [INFO|configuration_utils.py:693] 2025-06-27 21:02:52,597 >> loading configuration file config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/config.json
 3: [INFO|2025-06-27 21:02:52] llamafactory.hparams.parser:406 >> Process rank: 13, world size: 128, device: cuda:1, distributed training: True, compute dtype: torch.bfloat16
15: [INFO|configuration_utils.py:765] 2025-06-27 21:02:52,604 >> Model config Qwen2_5_VLConfig {
15:   "architectures": [
15:     "Qwen2_5_VLForConditionalGeneration"
15:   ],
15:   "attention_dropout": 0.0,
15:   "bos_token_id": 151643,
15:   "eos_token_id": 151645,
15:   "hidden_act": "silu",
15:   "hidden_size": 3584,
15:   "image_token_id": 151655,
15:   "initializer_range": 0.02,
15:   "intermediate_size": 18944,
15:   "max_position_embeddings": 128000,
15:   "max_window_layers": 28,
15:   "model_type": "qwen2_5_vl",
15:   "num_attention_heads": 28,
15:   "num_hidden_layers": 28,
15:   "num_key_value_heads": 4,
15:   "rms_norm_eps": 1e-06,
15:   "rope_scaling": {
15:     "mrope_section": [
15:       16,
15:       24,
15:       24
15:     ],
15:     "rope_type": "default",
15:     "type": "default"
15:   },
15:   "rope_theta": 1000000.0,
15:   "sliding_window": 32768,
15:   "tie_word_embeddings": false,
15:   "torch_dtype": "bfloat16",
15:   "transformers_version": "4.51.3",
15:   "use_cache": true,
15:   "use_sliding_window": false,
15:   "video_token_id": 151656,
15:   "vision_config": {
15:     "depth": 32,
15:     "fullatt_block_indexes": [
15:       7,
15: [INFO|2025-06-27 21:02:52] llamafactory.model.model_utils.kv_cache:143 >> KV cache is disabled during training.
27: [INFO|configuration_utils.py:765] 2025-06-27 21:02:52,599 >> Model config Qwen2_5_VLConfig {
27:   "architectures": [
27:     "Qwen2_5_VLForConditionalGeneration"
27:   ],
27:   "attention_dropout": 0.0,
27:   "bos_token_id": 151643,
27:   "eos_token_id": 151645,
27:   "hidden_act": "silu",
27:   "hidden_size": 3584,
27:   "image_token_id": 151655,
27:   "initializer_range": 0.02,
27:   "intermediate_size": 18944,
27:   "max_position_embeddings": 128000,
27:   "max_window_layers": 28,
27:   "model_type": "qwen2_5_vl",
27:   "num_attention_heads": 28,
27:   "num_hidden_layers": 28,
27:   "num_key_value_heads": 4,
27:   "rms_norm_eps": 1e-06,
27:   "rope_scaling": {
27:     "mrope_section": [
27:       16,
27:       24,
27:       24
27:     ],
27:     "rope_type": "default",
27:     "type": "default"
27:   },
27:   "rope_theta": 1000000.0,
27:   "sliding_window": 32768,
27:   "tie_word_embeddings": false,
27:   "torch_dtype": "bfloat16",
27:   "transformers_version": "4.51.3",
27:   "use_cache": true,
27:   "use_sliding_window": false,
27:   "video_token_id": 151656,
27:   "vision_config": {
27:     "depth": 32,
27:     "fullatt_block_indexes": [
27:       7,
27: [INFO|2025-06-27 21:02:52] llamafactory.model.model_utils.kv_cache:143 >> KV cache is disabled during training.
15:       15,
15:       23,
15:       31
15:     ],
15:     "hidden_act": "silu",
15:     "hidden_size": 1280,
15:     "in_channels": 3,
15:     "in_chans": 3,
15:     "intermediate_size": 3420,
15:     "model_type": "qwen2_5_vl",
15:     "num_heads": 16,
15:     "out_hidden_size": 3584,
15:     "patch_size": 14,
15:     "spatial_merge_size": 2,
15:     "spatial_patch_size": 14,
15:     "temporal_patch_size": 2,
15:     "tokens_per_second": 2,
15:     "window_size": 112
15:   },
15:   "vision_end_token_id": 151653,
15:   "vision_start_token_id": 151652,
15:   "vision_token_id": 151654,
15:   "vocab_size": 152064
15: }
15: 
27: [2025-06-27 21:02:52,627] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
23: [INFO|configuration_utils.py:1142] 2025-06-27 21:02:52,615 >> Generate config GenerationConfig {
23:   "bos_token_id": 151643,
23:   "eos_token_id": 151645,
23:   "use_cache": false
23: }
23: 
27:       15,
27:       23,
27:       31
27:     ],
27:     "hidden_act": "silu",
27:     "hidden_size": 1280,
27:     "in_channels": 3,
27:     "in_chans": 3,
27:     "intermediate_size": 3420,
27:     "model_type": "qwen2_5_vl",
27:     "num_heads": 16,
27:     "out_hidden_size": 3584,
27:     "patch_size": 14,
27:     "spatial_merge_size": 2,
27:     "spatial_patch_size": 14,
27:     "temporal_patch_size": 2,
27:     "tokens_per_second": 2,
27:     "window_size": 112
27:   },
27:   "vision_end_token_id": 151653,
27:   "vision_start_token_id": 151652,
27:   "vision_token_id": 151654,
27:   "vocab_size": 152064
27: }
27: 
23: [INFO|modeling_utils.py:2167] 2025-06-27 21:02:52,615 >> Instantiating Qwen2_5_VisionTransformerPretrainedModel model under default dtype torch.float32.
15: [INFO|modeling_utils.py:1124] 2025-06-27 21:02:52,627 >> loading weights file model.safetensors from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/model.safetensors.index.json
27: [INFO|modeling_utils.py:1124] 2025-06-27 21:02:52,617 >> loading weights file model.safetensors from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/model.safetensors.index.json
27: [INFO|modeling_utils.py:3726] 2025-06-27 21:02:52,627 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model
27: [INFO|configuration_utils.py:1142] 2025-06-27 21:02:52,632 >> Generate config GenerationConfig {
27:   "bos_token_id": 151643,
27:   "eos_token_id": 151645,
27:   "use_cache": false
27: }
27: 
27: [INFO|modeling_utils.py:2167] 2025-06-27 21:02:52,632 >> Instantiating Qwen2_5_VisionTransformerPretrainedModel model under default dtype torch.float32.
15: [INFO|modeling_utils.py:3726] 2025-06-27 21:02:52,638 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model
15: [2025-06-27 21:02:52,638] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
15: [INFO|configuration_utils.py:1142] 2025-06-27 21:02:52,647 >> Generate config GenerationConfig {
15:   "bos_token_id": 151643,
15:   "eos_token_id": 151645,
15:   "use_cache": false
15: }
15: 
15: [INFO|modeling_utils.py:2167] 2025-06-27 21:02:52,647 >> Instantiating Qwen2_5_VisionTransformerPretrainedModel model under default dtype torch.float32.
13: [INFO|configuration_utils.py:693] 2025-06-27 21:02:52,649 >> loading configuration file config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/config.json
13: [INFO|configuration_utils.py:765] 2025-06-27 21:02:52,651 >> Model config Qwen2_5_VLConfig {
13:   "architectures": [
13:     "Qwen2_5_VLForConditionalGeneration"
13:   ],
13:   "attention_dropout": 0.0,
13:   "bos_token_id": 151643,
13:   "eos_token_id": 151645,
13:   "hidden_act": "silu",
13:   "hidden_size": 3584,
13:   "image_token_id": 151655,
13:   "initializer_range": 0.02,
13:   "intermediate_size": 18944,
13:   "max_position_embeddings": 128000,
13:   "max_window_layers": 28,
13:   "model_type": "qwen2_5_vl",
13:   "num_attention_heads": 28,
13:   "num_hidden_layers": 28,
13:   "num_key_value_heads": 4,
13:   "rms_norm_eps": 1e-06,
13:   "rope_scaling": {
13:     "mrope_section": [
13:       16,
13:       24,
13:       24
13:     ],
13:     "rope_type": "default",
13:     "type": "default"
13:   },
13:   "rope_theta": 1000000.0,
13:   "sliding_window": 32768,
13:   "tie_word_embeddings": false,
13:   "torch_dtype": "bfloat16",
13:   "transformers_version": "4.51.3",
13:   "use_cache": true,
13:   "use_sliding_window": false,
13:   "video_token_id": 151656,
13:   "vision_config": {
13:     "depth": 32,
13:     "fullatt_block_indexes": [
13:       7,
13:       15,
13:       23,
13:       31
13:     ],
13:     "hidden_act": "silu",
13:     "hidden_size": 1280,
13:     "in_channels": 3,
13:     "in_chans": 3,
13:     "intermediate_size": 3420,
13:     "model_type": "qwen2_5_vl",
13:     "num_heads": 16,
13:     "out_hidden_size": 3584,
13:     "patch_size": 14,
13:     "spatial_merge_size": 2,
13:     "spatial_patch_size": 14,
13:     "temporal_patch_size": 2,
13:     "tokens_per_second": 2,
13:     "window_size": 112
13:   },
13:   "vision_end_token_id": 151653,
13:   "vision_start_token_id": 151652,
13:   "vision_token_id": 151654,
13:   "vocab_size": 152064
13: }
13: 
13: [INFO|2025-06-27 21:02:52] llamafactory.model.model_utils.kv_cache:143 >> KV cache is disabled during training.
20: [INFO|processing_utils.py:884] 2025-06-27 21:02:52,653 >> Processor Qwen2_5_VLProcessor:
20: - image_processor: Qwen2VLImageProcessorFast {
20:   "crop_size": null,
20:   "data_format": "channels_first",
20:   "default_to_square": true,
20:   "device": null,
20:   "do_center_crop": null,
20:   "do_convert_rgb": true,
20:   "do_normalize": true,
20:   "do_rescale": true,
20:   "do_resize": true,
20:   "image_mean": [
20:     0.48145466,
20:     0.4578275,
20:     0.40821073
20:   ],
20:   "image_processor_type": "Qwen2VLImageProcessorFast",
20:   "image_std": [
20:     0.26862954,
20:     0.26130258,
20:     0.27577711
20:   ],
20:   "input_data_format": null,
20:   "max_pixels": 12845056,
20:   "merge_size": 2,
20:   "min_pixels": 3136,
20:   "patch_size": 14,
20:   "processor_class": "Qwen2_5_VLProcessor",
20:   "resample": 3,
20:   "rescale_factor": 0.00392156862745098,
20:   "return_tensors": null,
20:   "size": {
20:     "longest_edge": 12845056,
20:     "shortest_edge": 3136
20:   },
20:   "temporal_patch_size": 2
20: }
20: 
20: - tokenizer: Qwen2TokenizerFast(name_or_path='Qwen/Qwen2.5-VL-7B-Instruct', vocab_size=151643, model_max_length=131072, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
20: 	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
20: 	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
20: 	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
20: 	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
20: 	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
20: 	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
20: 	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
20: 	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
20: 	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
20: 	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
20: 	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
20: 	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
20: 	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
20: 	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
20: 	151657: AddedToken("<tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
20: 	151658: AddedToken("</tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
20: 	151659: AddedToken("<|fim_prefix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
20: 	151660: AddedToken("<|fim_middle|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
20: 	151661: AddedToken("<|fim_suffix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
20: 	151662: AddedToken("<|fim_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
20: 	151663: AddedToken("<|repo_name|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
20: 	151664: AddedToken("<|file_sep|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
20: }
20: )
20: 
20: {
20:   "processor_class": "Qwen2_5_VLProcessor"
20: }
20: 
31: [INFO|processing_utils.py:884] 2025-06-27 21:02:52,660 >> Processor Qwen2_5_VLProcessor:
31: - image_processor: Qwen2VLImageProcessorFast {
31:   "crop_size": null,
31:   "data_format": "channels_first",
31:   "default_to_square": true,
31:   "device": null,
31:   "do_center_crop": null,
31:   "do_convert_rgb": true,
31:   "do_normalize": true,
31:   "do_rescale": true,
31:   "do_resize": true,
31:   "image_mean": [
31:     0.48145466,
31:     0.4578275,
31:     0.40821073
31:   ],
31:   "image_processor_type": "Qwen2VLImageProcessorFast",
31:   "image_std": [
31:     0.26862954,
31:     0.26130258,
31:     0.27577711
31:   ],
31:   "input_data_format": null,
31:   "max_pixels": 12845056,
31:   "merge_size": 2,
31:   "min_pixels": 3136,
31:   "patch_size": 14,
31:   "processor_class": "Qwen2_5_VLProcessor",
31:   "resample": 3,
31:   "rescale_factor": 0.00392156862745098,
31:   "return_tensors": null,
31:   "size": {
31:     "longest_edge": 12845056,
31:     "shortest_edge": 3136
31:   },
31:   "temporal_patch_size": 2
31: }
31: 
31: - tokenizer: Qwen2TokenizerFast(name_or_path='Qwen/Qwen2.5-VL-7B-Instruct', vocab_size=151643, model_max_length=131072, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
31: 	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
31: 	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
31: 	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
31: 	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
31: 	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
31: 	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
31: 	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
31: 	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
31: 	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
31: 	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
31: 	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
31: 	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
31: 	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
31: 	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
31: 	151657: AddedToken("<tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
31: 	151658: AddedToken("</tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
31: 	151659: AddedToken("<|fim_prefix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
31: 	151660: AddedToken("<|fim_middle|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
31: 	151661: AddedToken("<|fim_suffix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
31: 	151662: AddedToken("<|fim_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
31: 	151663: AddedToken("<|repo_name|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
31: 	151664: AddedToken("<|file_sep|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
31: }
31: )
31: 
31: {
31:   "processor_class": "Qwen2_5_VLProcessor"
31: }
31: 
11: [INFO|2025-06-27 21:02:52] llamafactory.hparams.parser:406 >> Process rank: 45, world size: 128, device: cuda:1, distributed training: True, compute dtype: torch.bfloat16
13: [INFO|modeling_utils.py:1124] 2025-06-27 21:02:52,671 >> loading weights file model.safetensors from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/model.safetensors.index.json
20: [WARNING|2025-06-27 21:02:52] llamafactory.data.loader:148 >> Loading dataset from disk will ignore other data arguments.
13: [INFO|modeling_utils.py:3726] 2025-06-27 21:02:52,682 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model
13: [2025-06-27 21:02:52,682] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
31: [WARNING|2025-06-27 21:02:52] llamafactory.data.loader:148 >> Loading dataset from disk will ignore other data arguments.
13: [INFO|configuration_utils.py:1142] 2025-06-27 21:02:52,687 >> Generate config GenerationConfig {
13:   "bos_token_id": 151643,
13:   "eos_token_id": 151645,
13:   "use_cache": false
13: }
13: 
13: [INFO|modeling_utils.py:2167] 2025-06-27 21:02:52,688 >> Instantiating Qwen2_5_VisionTransformerPretrainedModel model under default dtype torch.float32.
24: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:52,688 >> loading file vocab.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
24: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:52,688 >> loading file merges.txt from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
24: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:52,688 >> loading file tokenizer.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
24: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:52,688 >> loading file added_tokens.json from cache at None
24: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:52,688 >> loading file special_tokens_map.json from cache at None
24: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:52,688 >> loading file tokenizer_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
24: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:52,688 >> loading file chat_template.jinja from cache at None
26: [INFO|2025-06-27 21:02:52] llamafactory.hparams.parser:406 >> Process rank: 106, world size: 128, device: cuda:2, distributed training: True, compute dtype: torch.bfloat16
26: [INFO|2025-06-27 21:02:52] llamafactory.hparams.parser:406 >> Process rank: 107, world size: 128, device: cuda:3, distributed training: True, compute dtype: torch.bfloat16
 8: [INFO|processing_utils.py:884] 2025-06-27 21:02:52,713 >> Processor Qwen2_5_VLProcessor:
 8: - image_processor: Qwen2VLImageProcessorFast {
 8:   "crop_size": null,
 8:   "data_format": "channels_first",
 8:   "default_to_square": true,
 8:   "device": null,
 8:   "do_center_crop": null,
 8:   "do_convert_rgb": true,
 8:   "do_normalize": true,
 8:   "do_rescale": true,
 8:   "do_resize": true,
 8:   "image_mean": [
 8:     0.48145466,
 8:     0.4578275,
 8:     0.40821073
 8:   ],
 8:   "image_processor_type": "Qwen2VLImageProcessorFast",
 8:   "image_std": [
 8:     0.26862954,
 8:     0.26130258,
 8:     0.27577711
 8:   ],
 8:   "input_data_format": null,
 8:   "max_pixels": 12845056,
 8:   "merge_size": 2,
 8:   "min_pixels": 3136,
 8:   "patch_size": 14,
 8:   "processor_class": "Qwen2_5_VLProcessor",
 8:   "resample": 3,
 8:   "rescale_factor": 0.00392156862745098,
 8:   "return_tensors": null,
 8:   "size": {
 8:     "longest_edge": 12845056,
 8:     "shortest_edge": 3136
 8:   },
 8:   "temporal_patch_size": 2
 8: }
 8: 
 8: - tokenizer: Qwen2TokenizerFast(name_or_path='Qwen/Qwen2.5-VL-7B-Instruct', vocab_size=151643, model_max_length=131072, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
 8: 	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 8: 	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 8: 	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 8: 	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 8: 	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 8: 	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 8: 	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 8: 	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 8: 	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 8: 	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 8: 	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 8: 	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 8: 	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 8: 	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 8: 	151657: AddedToken("<tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 8: 	151658: AddedToken("</tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 8: 	151659: AddedToken("<|fim_prefix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 8: 	151660: AddedToken("<|fim_middle|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 8: 	151661: AddedToken("<|fim_suffix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 8: 	151662: AddedToken("<|fim_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 8: 	151663: AddedToken("<|repo_name|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 8: 	151664: AddedToken("<|file_sep|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 8: }
 8: )
 8: 
 8: {
 8:   "processor_class": "Qwen2_5_VLProcessor"
 8: }
 8: 
26: [INFO|2025-06-27 21:02:52] llamafactory.hparams.parser:406 >> Process rank: 105, world size: 128, device: cuda:1, distributed training: True, compute dtype: torch.bfloat16
 0: [INFO|2025-06-27 21:02:52] llamafactory.data.loader:143 >> Loaded tokenized dataset from /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/tokenizer.
 8: [WARNING|2025-06-27 21:02:52] llamafactory.data.loader:148 >> Loading dataset from disk will ignore other data arguments.
22: [INFO|2025-06-27 21:02:52] llamafactory.data.loader:143 >> Loaded tokenized dataset from /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/tokenizer.
 5: [2025-06-27 21:02:52,749] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
 7: [INFO|2025-06-27 21:02:52] llamafactory.data.loader:143 >> Loaded tokenized dataset from /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/tokenizer.
19: [INFO|2025-06-27 21:02:52] llamafactory.data.loader:143 >> Loaded tokenized dataset from /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/tokenizer.
 6: [INFO|processing_utils.py:884] 2025-06-27 21:02:52,787 >> Processor Qwen2_5_VLProcessor:
 6: - image_processor: Qwen2VLImageProcessorFast {
 6:   "crop_size": null,
 6:   "data_format": "channels_first",
 6:   "default_to_square": true,
 6:   "device": null,
 6:   "do_center_crop": null,
 6:   "do_convert_rgb": true,
 6:   "do_normalize": true,
 6:   "do_rescale": true,
 6:   "do_resize": true,
 6:   "image_mean": [
 6:     0.48145466,
 6:     0.4578275,
 6:     0.40821073
 6:   ],
 6:   "image_processor_type": "Qwen2VLImageProcessorFast",
 6:   "image_std": [
 6:     0.26862954,
 6:     0.26130258,
 6:     0.27577711
 6:   ],
 6:   "input_data_format": null,
 6:   "max_pixels": 12845056,
 6:   "merge_size": 2,
 6:   "min_pixels": 3136,
 6:   "patch_size": 14,
 6:   "processor_class": "Qwen2_5_VLProcessor",
 6:   "resample": 3,
 6:   "rescale_factor": 0.00392156862745098,
 6:   "return_tensors": null,
 6:   "size": {
 6:     "longest_edge": 12845056,
 6:     "shortest_edge": 3136
 6:   },
 6:   "temporal_patch_size": 2
 6: }
 6: 
 6: - tokenizer: Qwen2TokenizerFast(name_or_path='Qwen/Qwen2.5-VL-7B-Instruct', vocab_size=151643, model_max_length=131072, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
 6: 	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 6: 	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 6: 	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 6: 	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 6: 	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 6: 	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 6: 	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 6: 	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 6: 	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 6: 	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 6: 	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 6: 	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 6: 	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 6: 	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 6: 	151657: AddedToken("<tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 6: 	151658: AddedToken("</tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 6: 	151659: AddedToken("<|fim_prefix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 6: 	151660: AddedToken("<|fim_middle|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 6: 	151661: AddedToken("<|fim_suffix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 6: 	151662: AddedToken("<|fim_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 6: 	151663: AddedToken("<|repo_name|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 6: 	151664: AddedToken("<|file_sep|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 6: }
 6: )
 6: 
 6: {
 6:   "processor_class": "Qwen2_5_VLProcessor"
 6: }
 6: 
 4: [INFO|processing_utils.py:884] 2025-06-27 21:02:52,792 >> Processor Qwen2_5_VLProcessor:
 4: - image_processor: Qwen2VLImageProcessorFast {
 4:   "crop_size": null,
 4:   "data_format": "channels_first",
 4:   "default_to_square": true,
 4:   "device": null,
 4:   "do_center_crop": null,
 4:   "do_convert_rgb": true,
 4:   "do_normalize": true,
 4:   "do_rescale": true,
 4:   "do_resize": true,
 4:   "image_mean": [
 4:     0.48145466,
 4:     0.4578275,
 4:     0.40821073
 4:   ],
 4:   "image_processor_type": "Qwen2VLImageProcessorFast",
 4:   "image_std": [
 4:     0.26862954,
 4:     0.26130258,
 4:     0.27577711
 4:   ],
 4:   "input_data_format": null,
 4:   "max_pixels": 12845056,
 4:   "merge_size": 2,
 4:   "min_pixels": 3136,
 4:   "patch_size": 14,
 4:   "processor_class": "Qwen2_5_VLProcessor",
 4:   "resample": 3,
 4:   "rescale_factor": 0.00392156862745098,
 4:   "return_tensors": null,
 4:   "size": {
 4:     "longest_edge": 12845056,
 4:     "shortest_edge": 3136
 4:   },
 4:   "temporal_patch_size": 2
 4: }
 4: 
 4: - tokenizer: Qwen2TokenizerFast(name_or_path='Qwen/Qwen2.5-VL-7B-Instruct', vocab_size=151643, model_max_length=131072, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
 4: 	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 4: 	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 4: 	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 4: 	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 4: 	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 4: 	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 4: 	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 4: 	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 4: 	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 4: 	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 4: 	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 4: 	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 4: 	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 4: 	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
 4: 	151657: AddedToken("<tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 4: 	151658: AddedToken("</tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 4: 	151659: AddedToken("<|fim_prefix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 4: 	151660: AddedToken("<|fim_middle|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 4: 	151661: AddedToken("<|fim_suffix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 4: 	151662: AddedToken("<|fim_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 4: 	151663: AddedToken("<|repo_name|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 4: 	151664: AddedToken("<|file_sep|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
 4: }
 4: )
 4: 
 4: {
 4:   "processor_class": "Qwen2_5_VLProcessor"
 4: }
 4: 
 6: [WARNING|2025-06-27 21:02:52] llamafactory.data.loader:148 >> Loading dataset from disk will ignore other data arguments.
 4: [WARNING|2025-06-27 21:02:52] llamafactory.data.loader:148 >> Loading dataset from disk will ignore other data arguments.
14: [INFO|processing_utils.py:884] 2025-06-27 21:02:52,825 >> Processor Qwen2_5_VLProcessor:
14: - image_processor: Qwen2VLImageProcessorFast {
14:   "crop_size": null,
14:   "data_format": "channels_first",
14:   "default_to_square": true,
14:   "device": null,
14:   "do_center_crop": null,
14:   "do_convert_rgb": true,
14:   "do_normalize": true,
14:   "do_rescale": true,
14:   "do_resize": true,
14:   "image_mean": [
14:     0.48145466,
14:     0.4578275,
14:     0.40821073
14:   ],
14:   "image_processor_type": "Qwen2VLImageProcessorFast",
14:   "image_std": [
14:     0.26862954,
14:     0.26130258,
14:     0.27577711
14:   ],
14:   "input_data_format": null,
14:   "max_pixels": 12845056,
14:   "merge_size": 2,
14:   "min_pixels": 3136,
14:   "patch_size": 14,
14:   "processor_class": "Qwen2_5_VLProcessor",
14:   "resample": 3,
14:   "rescale_factor": 0.00392156862745098,
14:   "return_tensors": null,
14:   "size": {
14:     "longest_edge": 12845056,
14:     "shortest_edge": 3136
14:   },
14:   "temporal_patch_size": 2
14: }
14: 
14: - tokenizer: Qwen2TokenizerFast(name_or_path='Qwen/Qwen2.5-VL-7B-Instruct', vocab_size=151643, model_max_length=131072, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
14: 	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
14: 	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
14: 	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
14: 	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
14: 	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
14: 	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
14: 	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
14: 	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
14: 	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
14: 	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
14: 	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
14: 	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
14: 	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
14: 	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
14: 	151657: AddedToken("<tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
14: 	151658: AddedToken("</tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
14: 	151659: AddedToken("<|fim_prefix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
14: 	151660: AddedToken("<|fim_middle|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
14: 	151661: AddedToken("<|fim_suffix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
14: 	151662: AddedToken("<|fim_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
14: 	151663: AddedToken("<|repo_name|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
14: 	151664: AddedToken("<|file_sep|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
14: }
14: )
14: 
14: {
14:   "processor_class": "Qwen2_5_VLProcessor"
14: }
14: 
26: [INFO|2025-06-27 21:02:52] llamafactory.data.loader:143 >> Loaded tokenized dataset from /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/tokenizer.
14: [WARNING|2025-06-27 21:02:52] llamafactory.data.loader:148 >> Loading dataset from disk will ignore other data arguments.
30: [INFO|2025-06-27 21:02:52] llamafactory.data.loader:143 >> Loaded tokenized dataset from /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/tokenizer.
11: [INFO|2025-06-27 21:02:52] llamafactory.data.loader:143 >> Loaded tokenized dataset from /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/tokenizer.
 0: [INFO|configuration_utils.py:693] 2025-06-27 21:02:52,861 >> loading configuration file config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/config.json
17: [INFO|2025-06-27 21:02:52] llamafactory.data.loader:143 >> Loaded tokenized dataset from /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/tokenizer.
 0: [INFO|configuration_utils.py:765] 2025-06-27 21:02:52,863 >> Model config Qwen2_5_VLConfig {
 0:   "architectures": [
 0:     "Qwen2_5_VLForConditionalGeneration"
 0:   ],
 0:   "attention_dropout": 0.0,
 0:   "bos_token_id": 151643,
 0:   "eos_token_id": 151645,
 0:   "hidden_act": "silu",
 0:   "hidden_size": 3584,
 0:   "image_token_id": 151655,
 0:   "initializer_range": 0.02,
 0:   "intermediate_size": 18944,
 0:   "max_position_embeddings": 128000,
 0:   "max_window_layers": 28,
 0:   "model_type": "qwen2_5_vl",
 0:   "num_attention_heads": 28,
 0:   "num_hidden_layers": 28,
 0:   "num_key_value_heads": 4,
 0:   "rms_norm_eps": 1e-06,
 0:   "rope_scaling": {
 0:     "mrope_section": [
 0:       16,
 0:       24,
 0:       24
 0:     ],
 0:     "rope_type": "default",
 0:     "type": "default"
 0:   },
 0:   "rope_theta": 1000000.0,
 0:   "sliding_window": 32768,
 0:   "tie_word_embeddings": false,
 0:   "torch_dtype": "bfloat16",
 0:   "transformers_version": "4.51.3",
 0:   "use_cache": true,
 0:   "use_sliding_window": false,
 0:   "video_token_id": 151656,
 0:   "vision_config": {
 0:     "depth": 32,
 0:     "fullatt_block_indexes": [
 0:       7,
 0:       15,
 0:       23,
 0:       31
 0:     ],
 0:     "hidden_act": "silu",
 0:     "hidden_size": 1280,
 0:     "in_channels": 3,
 0:     "in_chans": 3,
 0:     "intermediate_size": 3420,
 0:     "model_type": "qwen2_5_vl",
 0:     "num_heads": 16,
 0:     "out_hidden_size": 3584,
 0:     "patch_size": 14,
 0:     "spatial_merge_size": 2,
 0:     "spatial_patch_size": 14,
 0:     "temporal_patch_size": 2,
 0:     "tokens_per_second": 2,
 0:     "window_size": 112
 0:   },
 0:   "vision_end_token_id": 151653,
 0:   "vision_start_token_id": 151652,
 0:   "vision_token_id": 151654,
 0:   "vocab_size": 152064
 0: }
 0: 
 0: [INFO|2025-06-27 21:02:52] llamafactory.model.model_utils.kv_cache:143 >> KV cache is disabled during training.
24: [INFO|tokenization_utils_base.py:2323] 2025-06-27 21:02:52,872 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
 0: [INFO|modeling_utils.py:1124] 2025-06-27 21:02:52,887 >> loading weights file model.safetensors from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/model.safetensors.index.json
22: [INFO|configuration_utils.py:693] 2025-06-27 21:02:52,888 >> loading configuration file config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/config.json
27: [2025-06-27 21:02:52,890] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
22: [INFO|configuration_utils.py:765] 2025-06-27 21:02:52,891 >> Model config Qwen2_5_VLConfig {
22:   "architectures": [
22:     "Qwen2_5_VLForConditionalGeneration"
22:   ],
22:   "attention_dropout": 0.0,
22:   "bos_token_id": 151643,
22:   "eos_token_id": 151645,
22:   "hidden_act": "silu",
22:   "hidden_size": 3584,
22:   "image_token_id": 151655,
22:   "initializer_range": 0.02,
22:   "intermediate_size": 18944,
22:   "max_position_embeddings": 128000,
22:   "max_window_layers": 28,
22:   "model_type": "qwen2_5_vl",
22:   "num_attention_heads": 28,
22:   "num_hidden_layers": 28,
22:   "num_key_value_heads": 4,
22:   "rms_norm_eps": 1e-06,
22:   "rope_scaling": {
22:     "mrope_section": [
22:       16,
22:       24,
22:       24
22:     ],
22:     "rope_type": "default",
22:     "type": "default"
22:   },
22:   "rope_theta": 1000000.0,
22:   "sliding_window": 32768,
22:   "tie_word_embeddings": false,
22:   "torch_dtype": "bfloat16",
22:   "transformers_version": "4.51.3",
22:   "use_cache": true,
22:   "use_sliding_window": false,
22:   "video_token_id": 151656,
22:   "vision_config": {
22:     "depth": 32,
22:     "fullatt_block_indexes": [
22:       7,
22:       15,
22:       23,
22:       31
22:     ],
22:     "hidden_act": "silu",
22:     "hidden_size": 1280,
22:     "in_channels": 3,
22:     "in_chans": 3,
22:     "intermediate_size": 3420,
22:     "model_type": "qwen2_5_vl",
22:     "num_heads": 16,
22:     "out_hidden_size": 3584,
22:     "patch_size": 14,
22:     "spatial_merge_size": 2,
22:     "spatial_patch_size": 14,
22:     "temporal_patch_size": 2,
22:     "tokens_per_second": 2,
22:     "window_size": 112
22:   },
22:   "vision_end_token_id": 151653,
22:   "vision_start_token_id": 151652,
22:   "vision_token_id": 151654,
22:   "vocab_size": 152064
22: }
22: 
22: [INFO|2025-06-27 21:02:52] llamafactory.model.model_utils.kv_cache:143 >> KV cache is disabled during training.
 7: [INFO|configuration_utils.py:693] 2025-06-27 21:02:52,893 >> loading configuration file config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/config.json
 0: [INFO|modeling_utils.py:3726] 2025-06-27 21:02:52,895 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model
 0: [2025-06-27 21:02:52,895] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
 7: [INFO|configuration_utils.py:765] 2025-06-27 21:02:52,895 >> Model config Qwen2_5_VLConfig {
 7:   "architectures": [
 7:     "Qwen2_5_VLForConditionalGeneration"
 7:   ],
 7:   "attention_dropout": 0.0,
 7:   "bos_token_id": 151643,
 7:   "eos_token_id": 151645,
 7:   "hidden_act": "silu",
 7:   "hidden_size": 3584,
 7:   "image_token_id": 151655,
 7:   "initializer_range": 0.02,
 7:   "intermediate_size": 18944,
 7:   "max_position_embeddings": 128000,
 7:   "max_window_layers": 28,
 7:   "model_type": "qwen2_5_vl",
 7:   "num_attention_heads": 28,
 7:   "num_hidden_layers": 28,
 7:   "num_key_value_heads": 4,
 7:   "rms_norm_eps": 1e-06,
 7:   "rope_scaling": {
 7:     "mrope_section": [
 7:       16,
 7:       24,
 7:       24
 7:     ],
 7:     "rope_type": "default",
 7:     "type": "default"
 7:   },
 7:   "rope_theta": 1000000.0,
 7:   "sliding_window": 32768,
 7:   "tie_word_embeddings": false,
 7:   "torch_dtype": "bfloat16",
 7:   "transformers_version": "4.51.3",
 7:   "use_cache": true,
 7:   "use_sliding_window": false,
 7:   "video_token_id": 151656,
 7:   "vision_config": {
 7:     "depth": 32,
 7:     "fullatt_block_indexes": [
 7:       7,
 7:       15,
 7:       23,
 7:       31
 7:     ],
 7:     "hidden_act": "silu",
 7:     "hidden_size": 1280,
 7:     "in_channels": 3,
 7:     "in_chans": 3,
 7:     "intermediate_size": 3420,
 7:     "model_type": "qwen2_5_vl",
 7:     "num_heads": 16,
 7:     "out_hidden_size": 3584,
 7:     "patch_size": 14,
 7:     "spatial_merge_size": 2,
 7:     "spatial_patch_size": 14,
 7:     "temporal_patch_size": 2,
 7:     "tokens_per_second": 2,
 7:     "window_size": 112
 7:   },
 7:   "vision_end_token_id": 151653,
 7:   "vision_start_token_id": 151652,
 7:   "vision_token_id": 151654,
 7:   "vocab_size": 152064
 7: }
 7: 
 7: [INFO|2025-06-27 21:02:52] llamafactory.model.model_utils.kv_cache:143 >> KV cache is disabled during training.
 0: [INFO|configuration_utils.py:1142] 2025-06-27 21:02:52,902 >> Generate config GenerationConfig {
 0:   "bos_token_id": 151643,
 0:   "eos_token_id": 151645,
 0:   "use_cache": false
 0: }
 0: 
 0: [INFO|modeling_utils.py:2167] 2025-06-27 21:02:52,902 >> Instantiating Qwen2_5_VisionTransformerPretrainedModel model under default dtype torch.float32.
19: [INFO|configuration_utils.py:693] 2025-06-27 21:02:52,906 >> loading configuration file config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/config.json
19: [INFO|configuration_utils.py:765] 2025-06-27 21:02:52,909 >> Model config Qwen2_5_VLConfig {
19:   "architectures": [
19:     "Qwen2_5_VLForConditionalGeneration"
19:   ],
19:   "attention_dropout": 0.0,
19:   "bos_token_id": 151643,
19:   "eos_token_id": 151645,
19:   "hidden_act": "silu",
19:   "hidden_size": 3584,
19:   "image_token_id": 151655,
19:   "initializer_range": 0.02,
19:   "intermediate_size": 18944,
19:   "max_position_embeddings": 128000,
19:   "max_window_layers": 28,
19:   "model_type": "qwen2_5_vl",
19:   "num_attention_heads": 28,
19:   "num_hidden_layers": 28,
19:   "num_key_value_heads": 4,
19:   "rms_norm_eps": 1e-06,
19:   "rope_scaling": {
19:     "mrope_section": [
19:       16,
19:       24,
19:       24
19:     ],
19:     "rope_type": "default",
19:     "type": "default"
19:   },
19:   "rope_theta": 1000000.0,
19:   "sliding_window": 32768,
19:   "tie_word_embeddings": false,
19:   "torch_dtype": "bfloat16",
19:   "transformers_version": "4.51.3",
19:   "use_cache": true,
19:   "use_sliding_window": false,
19:   "video_token_id": 151656,
19:   "vision_config": {
19:     "depth": 32,
19:     "fullatt_block_indexes": [
19:       7,
19:       15,
19:       23,
19:       31
19:     ],
19:     "hidden_act": "silu",
19:     "hidden_size": 1280,
19:     "in_channels": 3,
19:     "in_chans": 3,
19:     "intermediate_size": 3420,
19:     "model_type": "qwen2_5_vl",
19:     "num_heads": 16,
19:     "out_hidden_size": 3584,
19:     "patch_size": 14,
19:     "spatial_merge_size": 2,
19:     "spatial_patch_size": 14,
19:     "temporal_patch_size": 2,
19:     "tokens_per_second": 2,
19:     "window_size": 112
19:   },
19:   "vision_end_token_id": 151653,
19:   "vision_start_token_id": 151652,
19:   "vision_token_id": 151654,
19:   "vocab_size": 152064
19: }
19: 
19: [INFO|2025-06-27 21:02:52] llamafactory.model.model_utils.kv_cache:143 >> KV cache is disabled during training.
22: [INFO|modeling_utils.py:1124] 2025-06-27 21:02:52,916 >> loading weights file model.safetensors from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/model.safetensors.index.json
 7: [INFO|modeling_utils.py:1124] 2025-06-27 21:02:52,917 >> loading weights file model.safetensors from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/model.safetensors.index.json
15: [2025-06-27 21:02:52,918] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
22: [INFO|modeling_utils.py:3726] 2025-06-27 21:02:52,926 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model
22: [2025-06-27 21:02:52,926] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
 5: [2025-06-27 21:02:52,929] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
 7: [INFO|modeling_utils.py:3726] 2025-06-27 21:02:52,929 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model
19: [INFO|modeling_utils.py:1124] 2025-06-27 21:02:52,929 >> loading weights file model.safetensors from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/model.safetensors.index.json
 7: [2025-06-27 21:02:52,929] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
15: [2025-06-27 21:02:52,931] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
22: [INFO|configuration_utils.py:1142] 2025-06-27 21:02:52,935 >> Generate config GenerationConfig {
22:   "bos_token_id": 151643,
22:   "eos_token_id": 151645,
22:   "use_cache": false
22: }
22: 
22: [INFO|modeling_utils.py:2167] 2025-06-27 21:02:52,935 >> Instantiating Qwen2_5_VisionTransformerPretrainedModel model under default dtype torch.float32.
 7: [INFO|configuration_utils.py:1142] 2025-06-27 21:02:52,935 >> Generate config GenerationConfig {
 7:   "bos_token_id": 151643,
 7:   "eos_token_id": 151645,
 7:   "use_cache": false
 7: }
 7: 
 7: [INFO|modeling_utils.py:2167] 2025-06-27 21:02:52,936 >> Instantiating Qwen2_5_VisionTransformerPretrainedModel model under default dtype torch.float32.
29: [INFO|processing_utils.py:884] 2025-06-27 21:02:52,936 >> Processor Qwen2_5_VLProcessor:
29: - image_processor: Qwen2VLImageProcessorFast {
29:   "crop_size": null,
29:   "data_format": "channels_first",
29:   "default_to_square": true,
29:   "device": null,
29:   "do_center_crop": null,
29:   "do_convert_rgb": true,
29:   "do_normalize": true,
29:   "do_rescale": true,
29:   "do_resize": true,
29:   "image_mean": [
29:     0.48145466,
29:     0.4578275,
29:     0.40821073
29:   ],
29:   "image_processor_type": "Qwen2VLImageProcessorFast",
29:   "image_std": [
29:     0.26862954,
29:     0.26130258,
29:     0.27577711
29:   ],
29:   "input_data_format": null,
29:   "max_pixels": 12845056,
29:   "merge_size": 2,
29:   "min_pixels": 3136,
29:   "patch_size": 14,
29:   "processor_class": "Qwen2_5_VLProcessor",
29:   "resample": 3,
29:   "rescale_factor": 0.00392156862745098,
29:   "return_tensors": null,
29:   "size": {
29:     "longest_edge": 12845056,
29:     "shortest_edge": 3136
29:   },
29:   "temporal_patch_size": 2
29: }
29: 
29: - tokenizer: Qwen2TokenizerFast(name_or_path='Qwen/Qwen2.5-VL-7B-Instruct', vocab_size=151643, model_max_length=131072, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
29: 	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
29: 	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
29: 	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
29: 	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
29: 	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
29: 	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
29: 	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
29: 	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
29: 	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
29: 	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
29: 	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
29: 	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
29: 	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
29: 	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
29: 	151657: AddedToken("<tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
29: 	151658: AddedToken("</tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
29: 	151659: AddedToken("<|fim_prefix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
29: 	151660: AddedToken("<|fim_middle|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
29: 	151661: AddedToken("<|fim_suffix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
29: 	151662: AddedToken("<|fim_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
29: 	151663: AddedToken("<|repo_name|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
29: 	151664: AddedToken("<|file_sep|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
29: }
29: )
29: 
29: {
29:   "processor_class": "Qwen2_5_VLProcessor"
29: }
29: 
19: [INFO|modeling_utils.py:3726] 2025-06-27 21:02:52,941 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model
19: [2025-06-27 21:02:52,941] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
19: [INFO|configuration_utils.py:1142] 2025-06-27 21:02:52,950 >> Generate config GenerationConfig {
19:   "bos_token_id": 151643,
19:   "eos_token_id": 151645,
19:   "use_cache": false
19: }
19: 
 2: [2025-06-27 21:02:52,950] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
19: [INFO|modeling_utils.py:2167] 2025-06-27 21:02:52,950 >> Instantiating Qwen2_5_VisionTransformerPretrainedModel model under default dtype torch.float32.
26: [INFO|configuration_utils.py:693] 2025-06-27 21:02:52,952 >> loading configuration file config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/config.json
26: [INFO|configuration_utils.py:765] 2025-06-27 21:02:52,955 >> Model config Qwen2_5_VLConfig {
26:   "architectures": [
26:     "Qwen2_5_VLForConditionalGeneration"
26:   ],
26:   "attention_dropout": 0.0,
26:   "bos_token_id": 151643,
26:   "eos_token_id": 151645,
26:   "hidden_act": "silu",
26:   "hidden_size": 3584,
26:   "image_token_id": 151655,
26:   "initializer_range": 0.02,
26:   "intermediate_size": 18944,
26:   "max_position_embeddings": 128000,
26:   "max_window_layers": 28,
26:   "model_type": "qwen2_5_vl",
26:   "num_attention_heads": 28,
26:   "num_hidden_layers": 28,
26:   "num_key_value_heads": 4,
26:   "rms_norm_eps": 1e-06,
26:   "rope_scaling": {
26:     "mrope_section": [
26:       16,
26:       24,
26:       24
26:     ],
26:     "rope_type": "default",
26:     "type": "default"
26:   },
26:   "rope_theta": 1000000.0,
26:   "sliding_window": 32768,
26:   "tie_word_embeddings": false,
26:   "torch_dtype": "bfloat16",
26:   "transformers_version": "4.51.3",
26:   "use_cache": true,
26:   "use_sliding_window": false,
26:   "video_token_id": 151656,
26:   "vision_config": {
26:     "depth": 32,
26:     "fullatt_block_indexes": [
26:       7,
26:       15,
26:       23,
26:       31
26:     ],
26:     "hidden_act": "silu",
26:     "hidden_size": 1280,
26:     "in_channels": 3,
26:     "in_chans": 3,
26:     "intermediate_size": 3420,
26:     "model_type": "qwen2_5_vl",
26:     "num_heads": 16,
26:     "out_hidden_size": 3584,
26:     "patch_size": 14,
26:     "spatial_merge_size": 2,
26:     "spatial_patch_size": 14,
26:     "temporal_patch_size": 2,
26:     "tokens_per_second": 2,
26:     "window_size": 112
26:   },
26:   "vision_end_token_id": 151653,
26:   "vision_start_token_id": 151652,
26:   "vision_token_id": 151654,
26:   "vocab_size": 152064
26: }
26: 
26: [INFO|2025-06-27 21:02:52] llamafactory.model.model_utils.kv_cache:143 >> KV cache is disabled during training.
29: [WARNING|2025-06-27 21:02:52] llamafactory.data.loader:148 >> Loading dataset from disk will ignore other data arguments.
31: [INFO|2025-06-27 21:02:52] llamafactory.hparams.parser:406 >> Process rank: 127, world size: 128, device: cuda:3, distributed training: True, compute dtype: torch.bfloat16
26: [INFO|modeling_utils.py:1124] 2025-06-27 21:02:52,976 >> loading weights file model.safetensors from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/model.safetensors.index.json
11: [INFO|configuration_utils.py:693] 2025-06-27 21:02:52,979 >> loading configuration file config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/config.json
18: [INFO|processing_utils.py:884] 2025-06-27 21:02:52,979 >> Processor Qwen2_5_VLProcessor:
18: - image_processor: Qwen2VLImageProcessorFast {
18:   "crop_size": null,
18:   "data_format": "channels_first",
18:   "default_to_square": true,
18:   "device": null,
18:   "do_center_crop": null,
18:   "do_convert_rgb": true,
18:   "do_normalize": true,
18:   "do_rescale": true,
18:   "do_resize": true,
18:   "image_mean": [
18:     0.48145466,
18:     0.4578275,
18:     0.40821073
18:   ],
18:   "image_processor_type": "Qwen2VLImageProcessorFast",
18:   "image_std": [
18:     0.26862954,
18:     0.26130258,
18:     0.27577711
18:   ],
18:   "input_data_format": null,
18:   "max_pixels": 12845056,
18:   "merge_size": 2,
18:   "min_pixels": 3136,
18:   "patch_size": 14,
18:   "processor_class": "Qwen2_5_VLProcessor",
18:   "resample": 3,
18:   "rescale_factor": 0.00392156862745098,
18:   "return_tensors": null,
18:   "size": {
18:     "longest_edge": 12845056,
18:     "shortest_edge": 3136
18:   },
18:   "temporal_patch_size": 2
18: }
18: 
18: - tokenizer: Qwen2TokenizerFast(name_or_path='Qwen/Qwen2.5-VL-7B-Instruct', vocab_size=151643, model_max_length=131072, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
18: 	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
18: 	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
18: 	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
18: 	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
18: 	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
18: 	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
18: 	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
18: 	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
18: 	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
18: 	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
18: 	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
18: 	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
18: 	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
18: 	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
18: 	151657: AddedToken("<tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
18: 	151658: AddedToken("</tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
18: 	151659: AddedToken("<|fim_prefix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
18: 	151660: AddedToken("<|fim_middle|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
18: 	151661: AddedToken("<|fim_suffix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
18: 	151662: AddedToken("<|fim_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
18: 	151663: AddedToken("<|repo_name|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
18: 	151664: AddedToken("<|file_sep|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
18: }
18: )
18: 
18: {
18:   "processor_class": "Qwen2_5_VLProcessor"
18: }
18: 
26: [INFO|modeling_utils.py:3726] 2025-06-27 21:02:52,981 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model
26: [2025-06-27 21:02:52,981] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
11: [INFO|configuration_utils.py:765] 2025-06-27 21:02:52,982 >> Model config Qwen2_5_VLConfig {
11:   "architectures": [
11:     "Qwen2_5_VLForConditionalGeneration"
11:   ],
11:   "attention_dropout": 0.0,
11:   "bos_token_id": 151643,
11:   "eos_token_id": 151645,
11:   "hidden_act": "silu",
11:   "hidden_size": 3584,
11:   "image_token_id": 151655,
11:   "initializer_range": 0.02,
11:   "intermediate_size": 18944,
11:   "max_position_embeddings": 128000,
11:   "max_window_layers": 28,
11:   "model_type": "qwen2_5_vl",
11:   "num_attention_heads": 28,
11:   "num_hidden_layers": 28,
11:   "num_key_value_heads": 4,
11:   "rms_norm_eps": 1e-06,
11:   "rope_scaling": {
11:     "mrope_section": [
11:       16,
11:       24,
11:       24
11:     ],
11:     "rope_type": "default",
11:     "type": "default"
11:   },
11:   "rope_theta": 1000000.0,
11:   "sliding_window": 32768,
11:   "tie_word_embeddings": false,
11:   "torch_dtype": "bfloat16",
11:   "transformers_version": "4.51.3",
11:   "use_cache": true,
11:   "use_sliding_window": false,
11:   "video_token_id": 151656,
11:   "vision_config": {
11:     "depth": 32,
11:     "fullatt_block_indexes": [
11:       7,
11:       15,
11:       23,
11:       31
11:     ],
11:     "hidden_act": "silu",
11:     "hidden_size": 1280,
11:     "in_channels": 3,
11:     "in_chans": 3,
11:     "intermediate_size": 3420,
11:     "model_type": "qwen2_5_vl",
11:     "num_heads": 16,
11:     "out_hidden_size": 3584,
11:     "patch_size": 14,
11:     "spatial_merge_size": 2,
11:     "spatial_patch_size": 14,
11:     "temporal_patch_size": 2,
11:     "tokens_per_second": 2,
11:     "window_size": 112
11:   },
11:   "vision_end_token_id": 151653,
11:   "vision_start_token_id": 151652,
11:   "vision_token_id": 151654,
11:   "vocab_size": 152064
11: }
11: 
11: [INFO|2025-06-27 21:02:52] llamafactory.model.model_utils.kv_cache:143 >> KV cache is disabled during training.
23: [2025-06-27 21:02:52,983] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
26: [INFO|configuration_utils.py:1142] 2025-06-27 21:02:52,987 >> Generate config GenerationConfig {
26:   "bos_token_id": 151643,
26:   "eos_token_id": 151645,
26:   "use_cache": false
26: }
26: 
26: [INFO|modeling_utils.py:2167] 2025-06-27 21:02:52,987 >> Instantiating Qwen2_5_VisionTransformerPretrainedModel model under default dtype torch.float32.
17: [INFO|configuration_utils.py:693] 2025-06-27 21:02:52,987 >> loading configuration file config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/config.json
12: [INFO|2025-06-27 21:02:52] llamafactory.data.loader:143 >> Loaded tokenized dataset from /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/tokenizer.
17: [INFO|configuration_utils.py:765] 2025-06-27 21:02:52,990 >> Model config Qwen2_5_VLConfig {
17:   "architectures": [
17:     "Qwen2_5_VLForConditionalGeneration"
17:   ],
17:   "attention_dropout": 0.0,
17:   "bos_token_id": 151643,
17:   "eos_token_id": 151645,
17:   "hidden_act": "silu",
17:   "hidden_size": 3584,
17:   "image_token_id": 151655,
17:   "initializer_range": 0.02,
17:   "intermediate_size": 18944,
17:   "max_position_embeddings": 128000,
17:   "max_window_layers": 28,
17:   "model_type": "qwen2_5_vl",
17:   "num_attention_heads": 28,
17:   "num_hidden_layers": 28,
17:   "num_key_value_heads": 4,
17:   "rms_norm_eps": 1e-06,
17:   "rope_scaling": {
17:     "mrope_section": [
17:       16,
17:       24,
17:       24
17:     ],
17:     "rope_type": "default",
17:     "type": "default"
17:   },
17:   "rope_theta": 1000000.0,
17:   "sliding_window": 32768,
17:   "tie_word_embeddings": false,
17:   "torch_dtype": "bfloat16",
17:   "transformers_version": "4.51.3",
17:   "use_cache": true,
17:   "use_sliding_window": false,
17:   "video_token_id": 151656,
17:   "vision_config": {
17:     "depth": 32,
17:     "fullatt_block_indexes": [
17:       7,
17:       15,
17:       23,
17:       31
17:     ],
17:     "hidden_act": "silu",
17:     "hidden_size": 1280,
17:     "in_channels": 3,
17:     "in_chans": 3,
17:     "intermediate_size": 3420,
17:     "model_type": "qwen2_5_vl",
17:     "num_heads": 16,
17:     "out_hidden_size": 3584,
17:     "patch_size": 14,
17:     "spatial_merge_size": 2,
17:     "spatial_patch_size": 14,
17:     "temporal_patch_size": 2,
17:     "tokens_per_second": 2,
17:     "window_size": 112
17:   },
17:   "vision_end_token_id": 151653,
17:   "vision_start_token_id": 151652,
17:   "vision_token_id": 151654,
17:   "vocab_size": 152064
17: }
17: 
17: [INFO|2025-06-27 21:02:52] llamafactory.model.model_utils.kv_cache:143 >> KV cache is disabled during training.
14: [INFO|2025-06-27 21:02:52] llamafactory.hparams.parser:406 >> Process rank: 58, world size: 128, device: cuda:2, distributed training: True, compute dtype: torch.bfloat16
14: [INFO|2025-06-27 21:02:52] llamafactory.hparams.parser:406 >> Process rank: 57, world size: 128, device: cuda:1, distributed training: True, compute dtype: torch.bfloat16
20: [INFO|2025-06-27 21:02:52] llamafactory.data.loader:143 >> Loaded tokenized dataset from /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/tokenizer.
31: [INFO|2025-06-27 21:02:53] llamafactory.data.loader:143 >> Loaded tokenized dataset from /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/tokenizer.
11: [INFO|modeling_utils.py:1124] 2025-06-27 21:02:53,002 >> loading weights file model.safetensors from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/model.safetensors.index.json
16: [INFO|2025-06-27 21:02:53] llamafactory.data.loader:143 >> Loaded tokenized dataset from /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/tokenizer.
30: [2025-06-27 21:02:53,004] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
30: [2025-06-27 21:02:53,004] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
17: [INFO|modeling_utils.py:1124] 2025-06-27 21:02:53,005 >> loading weights file model.safetensors from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/model.safetensors.index.json
18: [WARNING|2025-06-27 21:02:53] llamafactory.data.loader:148 >> Loading dataset from disk will ignore other data arguments.
11: [INFO|modeling_utils.py:3726] 2025-06-27 21:02:53,008 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model
11: [2025-06-27 21:02:53,008] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
30: [INFO|configuration_utils.py:693] 2025-06-27 21:02:53,008 >> loading configuration file config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/config.json
31: [INFO|2025-06-27 21:02:53] llamafactory.hparams.parser:406 >> Process rank: 125, world size: 128, device: cuda:1, distributed training: True, compute dtype: torch.bfloat16
31: [INFO|2025-06-27 21:02:53] llamafactory.hparams.parser:406 >> Process rank: 126, world size: 128, device: cuda:2, distributed training: True, compute dtype: torch.bfloat16
17: [INFO|modeling_utils.py:3726] 2025-06-27 21:02:53,009 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model
17: [2025-06-27 21:02:53,010] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
17: [2025-06-27 21:02:53,010] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
30: [INFO|configuration_utils.py:765] 2025-06-27 21:02:53,010 >> Model config Qwen2_5_VLConfig {
30:   "architectures": [
30:     "Qwen2_5_VLForConditionalGeneration"
30:   ],
30:   "attention_dropout": 0.0,
30:   "bos_token_id": 151643,
30:   "eos_token_id": 151645,
30:   "hidden_act": "silu",
30:   "hidden_size": 3584,
30:   "image_token_id": 151655,
30:   "initializer_range": 0.02,
30:   "intermediate_size": 18944,
30:   "max_position_embeddings": 128000,
30:   "max_window_layers": 28,
30:   "model_type": "qwen2_5_vl",
30:   "num_attention_heads": 28,
30:   "num_hidden_layers": 28,
30:   "num_key_value_heads": 4,
30:   "rms_norm_eps": 1e-06,
30:   "rope_scaling": {
30:     "mrope_section": [
30:       16,
30:       24,
30:       24
30:     ],
30:     "rope_type": "default",
30:     "type": "default"
30:   },
30:   "rope_theta": 1000000.0,
30:   "sliding_window": 32768,
30:   "tie_word_embeddings": false,
30:   "torch_dtype": "bfloat16",
30:   "transformers_version": "4.51.3",
30:   "use_cache": true,
30:   "use_sliding_window": false,
30:   "video_token_id": 151656,
30:   "vision_config": {
30:     "depth": 32,
30:     "fullatt_block_indexes": [
30:       7,
30:       15,
30:       23,
30:       31
30:     ],
30:     "hidden_act": "silu",
30:     "hidden_size": 1280,
30:     "in_channels": 3,
30:     "in_chans": 3,
30:     "intermediate_size": 3420,
30:     "model_type": "qwen2_5_vl",
30:     "num_heads": 16,
30:     "out_hidden_size": 3584,
30:     "patch_size": 14,
30:     "spatial_merge_size": 2,
30:     "spatial_patch_size": 14,
30:     "temporal_patch_size": 2,
30:     "tokens_per_second": 2,
30:     "window_size": 112
30:   },
30:   "vision_end_token_id": 151653,
30:   "vision_start_token_id": 151652,
30:   "vision_token_id": 151654,
30:   "vocab_size": 152064
30: }
30: 
30: [INFO|2025-06-27 21:02:53] llamafactory.model.model_utils.kv_cache:143 >> KV cache is disabled during training.
17: [2025-06-27 21:02:53,012] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
11: [INFO|configuration_utils.py:1142] 2025-06-27 21:02:53,013 >> Generate config GenerationConfig {
11:   "bos_token_id": 151643,
11:   "eos_token_id": 151645,
11:   "use_cache": false
11: }
11: 
11: [INFO|modeling_utils.py:2167] 2025-06-27 21:02:53,013 >> Instantiating Qwen2_5_VisionTransformerPretrainedModel model under default dtype torch.float32.
17: [INFO|configuration_utils.py:1142] 2025-06-27 21:02:53,016 >> Generate config GenerationConfig {
17:   "bos_token_id": 151643,
17:   "eos_token_id": 151645,
17:   "use_cache": false
17: }
17: 
17: [INFO|modeling_utils.py:2167] 2025-06-27 21:02:53,016 >> Instantiating Qwen2_5_VisionTransformerPretrainedModel model under default dtype torch.float32.
 8: [INFO|2025-06-27 21:02:53] llamafactory.data.loader:143 >> Loaded tokenized dataset from /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/tokenizer.
 5: [2025-06-27 21:02:53,044] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
30: [INFO|modeling_utils.py:1124] 2025-06-27 21:02:53,051 >> loading weights file model.safetensors from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/model.safetensors.index.json
30: [INFO|modeling_utils.py:3726] 2025-06-27 21:02:53,052 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model
30: [2025-06-27 21:02:53,052] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
30: [INFO|configuration_utils.py:1142] 2025-06-27 21:02:53,058 >> Generate config GenerationConfig {
30:   "bos_token_id": 151643,
30:   "eos_token_id": 151645,
30:   "use_cache": false
30: }
30: 
30: [INFO|modeling_utils.py:2167] 2025-06-27 21:02:53,059 >> Instantiating Qwen2_5_VisionTransformerPretrainedModel model under default dtype torch.float32.
 8: [INFO|2025-06-27 21:02:53] llamafactory.hparams.parser:406 >> Process rank: 34, world size: 128, device: cuda:2, distributed training: True, compute dtype: torch.bfloat16
 8: [INFO|2025-06-27 21:02:53] llamafactory.hparams.parser:406 >> Process rank: 33, world size: 128, device: cuda:1, distributed training: True, compute dtype: torch.bfloat16
23: [2025-06-27 21:02:53,083] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
 0: nid005574:69058:69058 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
 0: nid005574:69058:69058 [0] NCCL INFO Bootstrap : Using hsn0:172.28.18.192<0>
 0: nid005574:69058:69058 [0] NCCL INFO cudaDriverVersion 12060
 0: nid005574:69058:69058 [0] NCCL INFO NCCL version 2.22.3+cuda12.6
 9: nid005588:35935:35935 [0] NCCL INFO cudaDriverVersion 12060
28: nid005929:16030:16030 [0] NCCL INFO cudaDriverVersion 12060
28: nid005929:16030:16030 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
 9: nid005588:35935:35935 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
 7: nid005585:122005:122005 [0] NCCL INFO cudaDriverVersion 12060
25: nid005919:107462:107462 [0] NCCL INFO cudaDriverVersion 12060
25: nid005919:107462:107462 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
 7: nid005585:122005:122005 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
 1: nid005576:147557:147557 [0] NCCL INFO cudaDriverVersion 12060
 1: nid005576:147557:147557 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
22: nid005915:274814:274814 [0] NCCL INFO cudaDriverVersion 12060
22: nid005915:274814:274814 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
 9: nid005588:35935:35935 [0] NCCL INFO Bootstrap : Using hsn0:172.28.18.240<0>
 9: nid005588:35935:35935 [0] NCCL INFO NCCL version 2.22.3+cuda12.6
13: nid005595:197883:197883 [0] NCCL INFO cudaDriverVersion 12060
10: nid005590:110710:110710 [0] NCCL INFO cudaDriverVersion 12060
13: nid005595:197883:197883 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
28: nid005929:16030:16030 [0] NCCL INFO Bootstrap : Using hsn0:172.28.23.132<0>
28: nid005929:16030:16030 [0] NCCL INFO NCCL version 2.22.3+cuda12.6
10: nid005590:110710:110710 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
 7: nid005585:122005:122005 [0] NCCL INFO Bootstrap : Using hsn0:172.28.18.236<0>
 7: nid005585:122005:122005 [0] NCCL INFO NCCL version 2.22.3+cuda12.6
 1: nid005576:147557:147557 [0] NCCL INFO Bootstrap : Using hsn0:172.28.18.200<0>
25: nid005919:107462:107462 [0] NCCL INFO Bootstrap : Using hsn0:172.28.23.100<0>
25: nid005919:107462:107462 [0] NCCL INFO NCCL version 2.22.3+cuda12.6
 1: nid005576:147557:147557 [0] NCCL INFO NCCL version 2.22.3+cuda12.6
22: nid005915:274814:274814 [0] NCCL INFO Bootstrap : Using hsn0:172.28.23.84<0>
22: nid005915:274814:274814 [0] NCCL INFO NCCL version 2.22.3+cuda12.6
13: nid005595:197883:197883 [0] NCCL INFO Bootstrap : Using hsn0:172.28.19.12<0>
10: nid005590:110710:110710 [0] NCCL INFO Bootstrap : Using hsn0:172.28.18.248<0>
10: nid005590:110710:110710 [0] NCCL INFO NCCL version 2.22.3+cuda12.6
13: nid005595:197883:197883 [0] NCCL INFO NCCL version 2.22.3+cuda12.6
17: nid005803:180733:180733 [1] NCCL INFO cudaDriverVersion 12060
17: nid005803:180733:180733 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
17: nid005803:180733:180733 [1] NCCL INFO Bootstrap : Using hsn0:172.28.21.212<0>
17: nid005803:180733:180733 [1] NCCL INFO NCCL version 2.22.3+cuda12.6
 2: nid005577:17422:17422 [0] NCCL INFO cudaDriverVersion 12060
 2: nid005577:17422:17422 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
 2: nid005577:17423:17423 [1] NCCL INFO cudaDriverVersion 12060
 2: nid005577:17423:17423 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
 2: nid005577:17422:17422 [0] NCCL INFO Bootstrap : Using hsn0:172.28.18.204<0>
 2: nid005577:17423:17423 [1] NCCL INFO Bootstrap : Using hsn0:172.28.18.204<0>
 2: nid005577:17422:17422 [0] NCCL INFO NCCL version 2.22.3+cuda12.6
 2: nid005577:17423:17423 [1] NCCL INFO NCCL version 2.22.3+cuda12.6
17: nid005803:180734:180734 [2] NCCL INFO cudaDriverVersion 12060
23: nid005917:276886:276886 [1] NCCL INFO cudaDriverVersion 12060
23: nid005917:276886:276886 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
23: nid005917:276886:276886 [1] NCCL INFO Bootstrap : Using hsn0:172.28.23.92<0>
23: nid005917:276886:276886 [1] NCCL INFO NCCL version 2.22.3+cuda12.6
15: nid005601:210679:210679 [3] NCCL INFO cudaDriverVersion 12060
15: nid005601:210679:210679 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
27: nid005922:80741:80741 [0] NCCL INFO cudaDriverVersion 12060
27: nid005922:80741:80741 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
21: nid005914:166786:166786 [2] NCCL INFO cudaDriverVersion 12060
21: nid005914:166786:166786 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
15: nid005601:210679:210679 [3] NCCL INFO Bootstrap : Using hsn0:172.28.49.117<0>
15: nid005601:210679:210679 [3] NCCL INFO NCCL version 2.22.3+cuda12.6
21: nid005914:166784:166784 [0] NCCL INFO cudaDriverVersion 12060
21: nid005914:166786:166786 [2] NCCL INFO Bootstrap : Using hsn0:172.28.23.80<0>
21: nid005914:166786:166786 [2] NCCL INFO NCCL version 2.22.3+cuda12.6
27: nid005922:80742:80742 [1] NCCL INFO cudaDriverVersion 12060
27: nid005922:80741:80741 [0] NCCL INFO Bootstrap : Using hsn0:172.28.48.251<0>
21: nid005914:166784:166784 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
27: nid005922:80741:80741 [0] NCCL INFO NCCL version 2.22.3+cuda12.6
27: nid005922:80742:80742 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
21: nid005914:166784:166784 [0] NCCL INFO Bootstrap : Using hsn0:172.28.23.80<0>
21: nid005914:166784:166784 [0] NCCL INFO NCCL version 2.22.3+cuda12.6
27: nid005922:80742:80742 [1] NCCL INFO Bootstrap : Using hsn0:172.28.48.251<0>
27: nid005922:80742:80742 [1] NCCL INFO NCCL version 2.22.3+cuda12.6
15: nid005601:210678:210678 [2] NCCL INFO cudaDriverVersion 12060
23: nid005917:276887:276887 [2] NCCL INFO cudaDriverVersion 12060
15: nid005601:210676:210676 [0] NCCL INFO cudaDriverVersion 12060
23: nid005917:276885:276885 [0] NCCL INFO cudaDriverVersion 12060
20: [INFO|configuration_utils.py:693] 2025-06-27 21:02:53,120 >> loading configuration file config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/config.json
 5: nid005582:196714:196714 [1] NCCL INFO cudaDriverVersion 12060
 5: nid005582:196714:196714 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
 5: nid005582:196714:196714 [1] NCCL INFO Bootstrap : Using hsn0:172.28.18.224<0>
 5: nid005582:196714:196714 [1] NCCL INFO NCCL version 2.22.3+cuda12.6
20: [INFO|configuration_utils.py:765] 2025-06-27 21:02:53,122 >> Model config Qwen2_5_VLConfig {
20:   "architectures": [
20:     "Qwen2_5_VLForConditionalGeneration"
20:   ],
20:   "attention_dropout": 0.0,
20:   "bos_token_id": 151643,
20:   "eos_token_id": 151645,
20:   "hidden_act": "silu",
20:   "hidden_size": 3584,
20:   "image_token_id": 151655,
20:   "initializer_range": 0.02,
20:   "intermediate_size": 18944,
20:   "max_position_embeddings": 128000,
20:   "max_window_layers": 28,
20:   "model_type": "qwen2_5_vl",
20:   "num_attention_heads": 28,
20:   "num_hidden_layers": 28,
20:   "num_key_value_heads": 4,
20:   "rms_norm_eps": 1e-06,
20:   "rope_scaling": {
20:     "mrope_section": [
20:       16,
20:       24,
20:       24
20:     ],
20:     "rope_type": "default",
20:     "type": "default"
20:   },
20:   "rope_theta": 1000000.0,
20:   "sliding_window": 32768,
20:   "tie_word_embeddings": false,
20:   "torch_dtype": "bfloat16",
20:   "transformers_version": "4.51.3",
20:   "use_cache": true,
20:   "use_sliding_window": false,
20:   "video_token_id": 151656,
20:   "vision_config": {
20:     "depth": 32,
20:     "fullatt_block_indexes": [
20:       7,
20:       15,
20:       23,
20:       31
20:     ],
20:     "hidden_act": "silu",
20:     "hidden_size": 1280,
20:     "in_channels": 3,
20:     "in_chans": 3,
20:     "intermediate_size": 3420,
20:     "model_type": "qwen2_5_vl",
20:     "num_heads": 16,
20:     "out_hidden_size": 3584,
20:     "patch_size": 14,
20:     "spatial_merge_size": 2,
20:     "spatial_patch_size": 14,
20:     "temporal_patch_size": 2,
20:     "tokens_per_second": 2,
20:     "window_size": 112
20:   },
20:   "vision_end_token_id": 151653,
20:   "vision_start_token_id": 151652,
20:   "vision_token_id": 151654,
20:   "vocab_size": 152064
20: }
20: 
20: [INFO|2025-06-27 21:02:53] llamafactory.model.model_utils.kv_cache:143 >> KV cache is disabled during training.
31: [INFO|configuration_utils.py:693] 2025-06-27 21:02:53,123 >> loading configuration file config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/config.json
12: [INFO|configuration_utils.py:693] 2025-06-27 21:02:53,123 >> loading configuration file config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/config.json
31: [INFO|configuration_utils.py:765] 2025-06-27 21:02:53,125 >> Model config Qwen2_5_VLConfig {
31:   "architectures": [
31:     "Qwen2_5_VLForConditionalGeneration"
31:   ],
31:   "attention_dropout": 0.0,
31:   "bos_token_id": 151643,
31:   "eos_token_id": 151645,
31:   "hidden_act": "silu",
31:   "hidden_size": 3584,
31:   "image_token_id": 151655,
31:   "initializer_range": 0.02,
31:   "intermediate_size": 18944,
31:   "max_position_embeddings": 128000,
31:   "max_window_layers": 28,
31:   "model_type": "qwen2_5_vl",
31:   "num_attention_heads": 28,
31:   "num_hidden_layers": 28,
31:   "num_key_value_heads": 4,
31:   "rms_norm_eps": 1e-06,
31:   "rope_scaling": {
31:     "mrope_section": [
31:       16,
31:       24,
31:       24
31:     ],
31:     "rope_type": "default",
31:     "type": "default"
31:   },
31:   "rope_theta": 1000000.0,
31:   "sliding_window": 32768,
31:   "tie_word_embeddings": false,
31:   "torch_dtype": "bfloat16",
31:   "transformers_version": "4.51.3",
31:   "use_cache": true,
31:   "use_sliding_window": false,
31:   "video_token_id": 151656,
31:   "vision_config": {
31:     "depth": 32,
31:     "fullatt_block_indexes": [
31:       7,
31:       15,
31:       23,
31:       31
31:     ],
31:     "hidden_act": "silu",
31:     "hidden_size": 1280,
31:     "in_channels": 3,
31:     "in_chans": 3,
31:     "intermediate_size": 3420,
31:     "model_type": "qwen2_5_vl",
31:     "num_heads": 16,
31:     "out_hidden_size": 3584,
31:     "patch_size": 14,
31:     "spatial_merge_size": 2,
31:     "spatial_patch_size": 14,
31:     "temporal_patch_size": 2,
31:     "tokens_per_second": 2,
31:     "window_size": 112
31:   },
31:   "vision_end_token_id": 151653,
31:   "vision_start_token_id": 151652,
31:   "vision_token_id": 151654,
31:   "vocab_size": 152064
31: }
31: 
31: [INFO|2025-06-27 21:02:53] llamafactory.model.model_utils.kv_cache:143 >> KV cache is disabled during training.
12: [INFO|configuration_utils.py:765] 2025-06-27 21:02:53,126 >> Model config Qwen2_5_VLConfig {
12:   "architectures": [
12:     "Qwen2_5_VLForConditionalGeneration"
12:   ],
12:   "attention_dropout": 0.0,
12:   "bos_token_id": 151643,
12:   "eos_token_id": 151645,
12:   "hidden_act": "silu",
12:   "hidden_size": 3584,
12:   "image_token_id": 151655,
12:   "initializer_range": 0.02,
12:   "intermediate_size": 18944,
12:   "max_position_embeddings": 128000,
12:   "max_window_layers": 28,
12:   "model_type": "qwen2_5_vl",
12:   "num_attention_heads": 28,
12:   "num_hidden_layers": 28,
12:   "num_key_value_heads": 4,
12:   "rms_norm_eps": 1e-06,
12:   "rope_scaling": {
12:     "mrope_section": [
12:       16,
12:       24,
12:       24
12:     ],
12:     "rope_type": "default",
12:     "type": "default"
12:   },
12:   "rope_theta": 1000000.0,
12:   "sliding_window": 32768,
12:   "tie_word_embeddings": false,
12:   "torch_dtype": "bfloat16",
12:   "transformers_version": "4.51.3",
12:   "use_cache": true,
12:   "use_sliding_window": false,
12:   "video_token_id": 151656,
12:   "vision_config": {
12:     "depth": 32,
12:     "fullatt_block_indexes": [
12:       7,
12:       15,
12:       23,
12:       31
12:     ],
12:     "hidden_act": "silu",
12:     "hidden_size": 1280,
12:     "in_channels": 3,
12:     "in_chans": 3,
12:     "intermediate_size": 3420,
12:     "model_type": "qwen2_5_vl",
12:     "num_heads": 16,
12:     "out_hidden_size": 3584,
12:     "patch_size": 14,
12:     "spatial_merge_size": 2,
12:     "spatial_patch_size": 14,
12:     "temporal_patch_size": 2,
12:     "tokens_per_second": 2,
12:     "window_size": 112
12:   },
12:   "vision_end_token_id": 151653,
12:   "vision_start_token_id": 151652,
12:   "vision_token_id": 151654,
12:   "vocab_size": 152064
12: }
12: 
12: [INFO|2025-06-27 21:02:53] llamafactory.model.model_utils.kv_cache:143 >> KV cache is disabled during training.
30: nid005936:49911:49911 [3] NCCL INFO cudaDriverVersion 12060
30: nid005936:49911:49911 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
30: nid005936:49911:49911 [3] NCCL INFO Bootstrap : Using hsn0:172.28.50.23<0>
30: nid005936:49911:49911 [3] NCCL INFO NCCL version 2.22.3+cuda12.6
 5: nid005582:196715:196715 [2] NCCL INFO cudaDriverVersion 12060
 5: nid005582:196713:196713 [0] NCCL INFO cudaDriverVersion 12060
19: nid005912:12435:12435 [0] NCCL INFO cudaDriverVersion 12060
19: nid005912:12435:12435 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
 5: nid005582:196716:196716 [3] NCCL INFO cudaDriverVersion 12060
19: nid005912:12435:12435 [0] NCCL INFO Bootstrap : Using hsn0:172.28.23.72<0>
19: nid005912:12435:12435 [0] NCCL INFO NCCL version 2.22.3+cuda12.6
30: nid005936:49909:49909 [1] NCCL INFO cudaDriverVersion 12060
30: nid005936:49909:49909 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
30: nid005936:49909:49909 [1] NCCL INFO Bootstrap : Using hsn0:172.28.50.23<0>
30: nid005936:49909:49909 [1] NCCL INFO NCCL version 2.22.3+cuda12.6
16: [INFO|configuration_utils.py:693] 2025-06-27 21:02:53,133 >> loading configuration file config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/config.json
16: [INFO|configuration_utils.py:765] 2025-06-27 21:02:53,136 >> Model config Qwen2_5_VLConfig {
16:   "architectures": [
16:     "Qwen2_5_VLForConditionalGeneration"
16:   ],
16:   "attention_dropout": 0.0,
16:   "bos_token_id": 151643,
16:   "eos_token_id": 151645,
16:   "hidden_act": "silu",
16:   "hidden_size": 3584,
16:   "image_token_id": 151655,
16:   "initializer_range": 0.02,
16:   "intermediate_size": 18944,
16:   "max_position_embeddings": 128000,
16:   "max_window_layers": 28,
16:   "model_type": "qwen2_5_vl",
16:   "num_attention_heads": 28,
16:   "num_hidden_layers": 28,
16:   "num_key_value_heads": 4,
16:   "rms_norm_eps": 1e-06,
16:   "rope_scaling": {
16:     "mrope_section": [
16:       16,
16:       24,
16:       24
16:     ],
16:     "rope_type": "default",
16:     "type": "default"
16:   },
16:   "rope_theta": 1000000.0,
16:   "sliding_window": 32768,
16:   "tie_word_embeddings": false,
16:   "torch_dtype": "bfloat16",
16:   "transformers_version": "4.51.3",
16:   "use_cache": true,
16:   "use_sliding_window": false,
16:   "video_token_id": 151656,
16:   "vision_config": {
16:     "depth": 32,
16:     "fullatt_block_indexes": [
16:       7,
16:       15,
16:       23,
16:       31
16:     ],
16:     "hidden_act": "silu",
16:     "hidden_size": 1280,
16:     "in_channels": 3,
16:     "in_chans": 3,
16:     "intermediate_size": 3420,
16:     "model_type": "qwen2_5_vl",
16:     "num_heads": 16,
16:     "out_hidden_size": 3584,
16:     "patch_size": 14,
16:     "spatial_merge_size": 2,
16:     "spatial_patch_size": 14,
16:     "temporal_patch_size": 2,
16:     "tokens_per_second": 2,
16:     "window_size": 112
16:   },
16:   "vision_end_token_id": 151653,
16:   "vision_start_token_id": 151652,
16:   "vision_token_id": 151654,
16:   "vocab_size": 152064
16: }
16: 
16: [INFO|2025-06-27 21:02:53] llamafactory.model.model_utils.kv_cache:143 >> KV cache is disabled during training.
20: [INFO|2025-06-27 21:02:53] llamafactory.hparams.parser:406 >> Process rank: 81, world size: 128, device: cuda:1, distributed training: True, compute dtype: torch.bfloat16
26: nid005920:67123:67123 [0] NCCL INFO cudaDriverVersion 12060
26: nid005920:67123:67123 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
26: nid005920:67123:67123 [0] NCCL INFO Bootstrap : Using hsn0:172.28.23.104<0>
26: nid005920:67123:67123 [0] NCCL INFO NCCL version 2.22.3+cuda12.6
31: [INFO|modeling_utils.py:1124] 2025-06-27 21:02:53,148 >> loading weights file model.safetensors from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/model.safetensors.index.json
12: [INFO|modeling_utils.py:1124] 2025-06-27 21:02:53,148 >> loading weights file model.safetensors from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/model.safetensors.index.json
20: [INFO|modeling_utils.py:1124] 2025-06-27 21:02:53,150 >> loading weights file model.safetensors from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/model.safetensors.index.json
 8: [INFO|configuration_utils.py:693] 2025-06-27 21:02:53,154 >> loading configuration file config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/config.json
12: [INFO|modeling_utils.py:3726] 2025-06-27 21:02:53,155 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model
31: [INFO|modeling_utils.py:3726] 2025-06-27 21:02:53,155 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model
12: [2025-06-27 21:02:53,155] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
31: [2025-06-27 21:02:53,155] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
 8: [INFO|configuration_utils.py:765] 2025-06-27 21:02:53,156 >> Model config Qwen2_5_VLConfig {
 8:   "architectures": [
 8:     "Qwen2_5_VLForConditionalGeneration"
 8:   ],
 8:   "attention_dropout": 0.0,
 8:   "bos_token_id": 151643,
 8:   "eos_token_id": 151645,
 8:   "hidden_act": "silu",
 8:   "hidden_size": 3584,
 8:   "image_token_id": 151655,
 8:   "initializer_range": 0.02,
 8:   "intermediate_size": 18944,
 8:   "max_position_embeddings": 128000,
 8:   "max_window_layers": 28,
 8:   "model_type": "qwen2_5_vl",
 8:   "num_attention_heads": 28,
 8:   "num_hidden_layers": 28,
 8:   "num_key_value_heads": 4,
 8:   "rms_norm_eps": 1e-06,
 8:   "rope_scaling": {
 8:     "mrope_section": [
 8:       16,
 8:       24,
 8:       24
 8:     ],
 8:     "rope_type": "default",
 8:     "type": "default"
 8:   },
 8:   "rope_theta": 1000000.0,
 8:   "sliding_window": 32768,
 8:   "tie_word_embeddings": false,
 8:   "torch_dtype": "bfloat16",
 8:   "transformers_version": "4.51.3",
 8:   "use_cache": true,
 8:   "use_sliding_window": false,
 8:   "video_token_id": 151656,
 8:   "vision_config": {
 8:     "depth": 32,
 8:     "fullatt_block_indexes": [
 8:       7,
 8:       15,
 8:       23,
 8:       31
 8:     ],
 8:     "hidden_act": "silu",
 8:     "hidden_size": 1280,
 8:     "in_channels": 3,
 8:     "in_chans": 3,
 8:     "intermediate_size": 3420,
 8:     "model_type": "qwen2_5_vl",
 8:     "num_heads": 16,
 8:     "out_hidden_size": 3584,
 8:     "patch_size": 14,
 8:     "spatial_merge_size": 2,
 8:     "spatial_patch_size": 14,
 8:     "temporal_patch_size": 2,
 8:     "tokens_per_second": 2,
 8:     "window_size": 112
 8:   },
 8:   "vision_end_token_id": 151653,
 8:   "vision_start_token_id": 151652,
 8:   "vision_token_id": 151654,
 8:   "vocab_size": 152064
 8: }
 8: 
 8: [INFO|2025-06-27 21:02:53] llamafactory.model.model_utils.kv_cache:143 >> KV cache is disabled during training.
16: [INFO|modeling_utils.py:1124] 2025-06-27 21:02:53,159 >> loading weights file model.safetensors from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/model.safetensors.index.json
20: [INFO|modeling_utils.py:3726] 2025-06-27 21:02:53,160 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model
20: [2025-06-27 21:02:53,160] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
20: [INFO|2025-06-27 21:02:53] llamafactory.hparams.parser:406 >> Process rank: 83, world size: 128, device: cuda:3, distributed training: True, compute dtype: torch.bfloat16
31: [INFO|configuration_utils.py:1142] 2025-06-27 21:02:53,161 >> Generate config GenerationConfig {
31:   "bos_token_id": 151643,
31:   "eos_token_id": 151645,
31:   "use_cache": false
31: }
31: 
31: [INFO|modeling_utils.py:2167] 2025-06-27 21:02:53,161 >> Instantiating Qwen2_5_VisionTransformerPretrainedModel model under default dtype torch.float32.
12: [INFO|configuration_utils.py:1142] 2025-06-27 21:02:53,162 >> Generate config GenerationConfig {
12:   "bos_token_id": 151643,
12:   "eos_token_id": 151645,
12:   "use_cache": false
12: }
12: 
12: [INFO|modeling_utils.py:2167] 2025-06-27 21:02:53,162 >> Instantiating Qwen2_5_VisionTransformerPretrainedModel model under default dtype torch.float32.
20: [INFO|2025-06-27 21:02:53] llamafactory.hparams.parser:406 >> Process rank: 82, world size: 128, device: cuda:2, distributed training: True, compute dtype: torch.bfloat16
16: [INFO|modeling_utils.py:3726] 2025-06-27 21:02:53,166 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model
16: [2025-06-27 21:02:53,166] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
20: [INFO|configuration_utils.py:1142] 2025-06-27 21:02:53,169 >> Generate config GenerationConfig {
20:   "bos_token_id": 151643,
20:   "eos_token_id": 151645,
20:   "use_cache": false
20: }
20: 
20: [INFO|modeling_utils.py:2167] 2025-06-27 21:02:53,170 >> Instantiating Qwen2_5_VisionTransformerPretrainedModel model under default dtype torch.float32.
16: [INFO|configuration_utils.py:1142] 2025-06-27 21:02:53,173 >> Generate config GenerationConfig {
16:   "bos_token_id": 151643,
16:   "eos_token_id": 151645,
16:   "use_cache": false
16: }
16: 
16: [INFO|modeling_utils.py:2167] 2025-06-27 21:02:53,173 >> Instantiating Qwen2_5_VisionTransformerPretrainedModel model under default dtype torch.float32.
28: nid005929:16030:16526 [0] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
28: nid005929:16030:16526 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
28: nid005929:16030:16526 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
28: nid005929:16030:16526 [0] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
28: nid005929:16030:16526 [0] NCCL INFO NET/OFI Using Libfabric version 1.22
28: nid005929:16030:16526 [0] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
28: 
28: nid005929:16030:16526 [0] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
 8: [INFO|modeling_utils.py:1124] 2025-06-27 21:02:53,181 >> loading weights file model.safetensors from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/model.safetensors.index.json
28: nid005929:16030:16526 [0] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
28: nid005929:16030:16526 [0] NCCL INFO NET/OFI Using transport protocol SENDRECV
28: nid005929:16030:16526 [0] NCCL INFO NET/OFI Creating one domain per process
28: nid005929:16030:16526 [0] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
28: nid005929:16030:16526 [0] NCCL INFO NET/OFI Support for global registrations: false
28: nid005929:16030:16526 [0] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
28: nid005929:16030:16526 [0] NCCL INFO Using network AWS Libfabric
 8: [INFO|modeling_utils.py:3726] 2025-06-27 21:02:53,190 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model
 8: [2025-06-27 21:02:53,190] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
11: nid005591:191603:191603 [0] NCCL INFO cudaDriverVersion 12060
11: nid005591:191603:191603 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
11: nid005591:191603:191603 [0] NCCL INFO Bootstrap : Using hsn0:172.28.18.252<0>
11: nid005591:191603:191603 [0] NCCL INFO NCCL version 2.22.3+cuda12.6
 8: [INFO|configuration_utils.py:1142] 2025-06-27 21:02:53,199 >> Generate config GenerationConfig {
 8:   "bos_token_id": 151643,
 8:   "eos_token_id": 151645,
 8:   "use_cache": false
 8: }
 8: 
 8: [INFO|modeling_utils.py:2167] 2025-06-27 21:02:53,199 >> Instantiating Qwen2_5_VisionTransformerPretrainedModel model under default dtype torch.float32.
 6: [INFO|2025-06-27 21:02:53] llamafactory.hparams.parser:406 >> Process rank: 27, world size: 128, device: cuda:3, distributed training: True, compute dtype: torch.bfloat16
17: nid005803:180734:180734 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
17: nid005803:180734:180734 [2] NCCL INFO Bootstrap : Using hsn0:172.28.21.212<0>
17: nid005803:180734:180734 [2] NCCL INFO NCCL version 2.22.3+cuda12.6
23: nid005917:276887:276887 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
23: nid005917:276887:276887 [2] NCCL INFO Bootstrap : Using hsn0:172.28.23.92<0>
23: nid005917:276887:276887 [2] NCCL INFO NCCL version 2.22.3+cuda12.6
17: nid005803:180732:180732 [0] NCCL INFO cudaDriverVersion 12060
23: nid005917:276885:276885 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
23: nid005917:276885:276885 [0] NCCL INFO Bootstrap : Using hsn0:172.28.23.92<0>
23: nid005917:276885:276885 [0] NCCL INFO NCCL version 2.22.3+cuda12.6
 8: [INFO|2025-06-27 21:02:53] llamafactory.hparams.parser:406 >> Process rank: 35, world size: 128, device: cuda:3, distributed training: True, compute dtype: torch.bfloat16
14: [INFO|2025-06-27 21:02:53] llamafactory.data.loader:143 >> Loaded tokenized dataset from /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/tokenizer.
 5: nid005582:196715:196715 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
 5: nid005582:196715:196715 [2] NCCL INFO Bootstrap : Using hsn0:172.28.18.224<0>
 5: nid005582:196715:196715 [2] NCCL INFO NCCL version 2.22.3+cuda12.6
15: nid005601:210678:210678 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
15: nid005601:210678:210678 [2] NCCL INFO Bootstrap : Using hsn0:172.28.49.117<0>
15: nid005601:210678:210678 [2] NCCL INFO NCCL version 2.22.3+cuda12.6
14: [INFO|2025-06-27 21:02:53] llamafactory.hparams.parser:406 >> Process rank: 59, world size: 128, device: cuda:3, distributed training: True, compute dtype: torch.bfloat16
 6: [INFO|2025-06-27 21:02:53] llamafactory.hparams.parser:406 >> Process rank: 25, world size: 128, device: cuda:1, distributed training: True, compute dtype: torch.bfloat16
 6: [INFO|2025-06-27 21:02:53] llamafactory.hparams.parser:406 >> Process rank: 26, world size: 128, device: cuda:2, distributed training: True, compute dtype: torch.bfloat16
 4: [INFO|2025-06-27 21:02:53] llamafactory.hparams.parser:406 >> Process rank: 19, world size: 128, device: cuda:3, distributed training: True, compute dtype: torch.bfloat16
 4: [INFO|2025-06-27 21:02:53] llamafactory.hparams.parser:406 >> Process rank: 18, world size: 128, device: cuda:2, distributed training: True, compute dtype: torch.bfloat16
12: nid005594:53085:53085 [0] NCCL INFO cudaDriverVersion 12060
12: nid005594:53085:53085 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
12: nid005594:53085:53085 [0] NCCL INFO Bootstrap : Using hsn0:172.28.19.8<0>
12: nid005594:53085:53085 [0] NCCL INFO NCCL version 2.22.3+cuda12.6
31: nid005937:256589:256589 [0] NCCL INFO cudaDriverVersion 12060
31: nid005937:256589:256589 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
31: nid005937:256589:256589 [0] NCCL INFO Bootstrap : Using hsn0:172.28.49.135<0>
31: nid005937:256589:256589 [0] NCCL INFO NCCL version 2.22.3+cuda12.6
 4: [INFO|2025-06-27 21:02:53] llamafactory.hparams.parser:406 >> Process rank: 17, world size: 128, device: cuda:1, distributed training: True, compute dtype: torch.bfloat16
 5: nid005582:196716:196716 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
 5: nid005582:196713:196713 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
16: nid005802:6297:6297 [0] NCCL INFO cudaDriverVersion 12060
16: nid005802:6297:6297 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
 5: nid005582:196716:196716 [3] NCCL INFO Bootstrap : Using hsn0:172.28.18.224<0>
 5: nid005582:196713:196713 [0] NCCL INFO Bootstrap : Using hsn0:172.28.18.224<0>
 5: nid005582:196716:196716 [3] NCCL INFO NCCL version 2.22.3+cuda12.6
 5: nid005582:196713:196713 [0] NCCL INFO NCCL version 2.22.3+cuda12.6
16: nid005802:6297:6297 [0] NCCL INFO Bootstrap : Using hsn0:172.28.21.208<0>
16: nid005802:6297:6297 [0] NCCL INFO NCCL version 2.22.3+cuda12.6
30: nid005936:49908:49908 [0] NCCL INFO cudaDriverVersion 12060
15: nid005601:210676:210676 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
15: nid005601:210676:210676 [0] NCCL INFO Bootstrap : Using hsn0:172.28.49.117<0>
15: nid005601:210676:210676 [0] NCCL INFO NCCL version 2.22.3+cuda12.6
20: nid005913:292681:292681 [0] NCCL INFO cudaDriverVersion 12060
20: nid005913:292681:292681 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
20: nid005913:292681:292681 [0] NCCL INFO Bootstrap : Using hsn0:172.28.23.76<0>
20: nid005913:292681:292681 [0] NCCL INFO NCCL version 2.22.3+cuda12.6
 8: nid005586:68926:68926 [0] NCCL INFO cudaDriverVersion 12060
 8: nid005586:68926:68926 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
 8: nid005586:68926:68926 [0] NCCL INFO Bootstrap : Using hsn0:172.28.48.231<0>
 8: nid005586:68926:68926 [0] NCCL INFO NCCL version 2.22.3+cuda12.6
18: [INFO|2025-06-27 21:02:53] llamafactory.hparams.parser:406 >> Process rank: 74, world size: 128, device: cuda:2, distributed training: True, compute dtype: torch.bfloat16
18: [INFO|2025-06-27 21:02:53] llamafactory.hparams.parser:406 >> Process rank: 73, world size: 128, device: cuda:1, distributed training: True, compute dtype: torch.bfloat16
17: nid005803:180732:180732 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
17: nid005803:180732:180732 [0] NCCL INFO Bootstrap : Using hsn0:172.28.21.212<0>
17: nid005803:180732:180732 [0] NCCL INFO NCCL version 2.22.3+cuda12.6
14: [INFO|configuration_utils.py:693] 2025-06-27 21:02:53,410 >> loading configuration file config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/config.json
14: [INFO|configuration_utils.py:765] 2025-06-27 21:02:53,413 >> Model config Qwen2_5_VLConfig {
14:   "architectures": [
14:     "Qwen2_5_VLForConditionalGeneration"
14:   ],
14:   "attention_dropout": 0.0,
14:   "bos_token_id": 151643,
14:   "eos_token_id": 151645,
14:   "hidden_act": "silu",
14:   "hidden_size": 3584,
14:   "image_token_id": 151655,
14:   "initializer_range": 0.02,
14:   "intermediate_size": 18944,
14:   "max_position_embeddings": 128000,
14:   "max_window_layers": 28,
14:   "model_type": "qwen2_5_vl",
14:   "num_attention_heads": 28,
14:   "num_hidden_layers": 28,
14:   "num_key_value_heads": 4,
14:   "rms_norm_eps": 1e-06,
14:   "rope_scaling": {
14:     "mrope_section": [
14:       16,
14:       24,
14:       24
14:     ],
14:     "rope_type": "default",
14:     "type": "default"
14:   },
14:   "rope_theta": 1000000.0,
14:   "sliding_window": 32768,
14:   "tie_word_embeddings": false,
14:   "torch_dtype": "bfloat16",
14:   "transformers_version": "4.51.3",
14:   "use_cache": true,
14:   "use_sliding_window": false,
14:   "video_token_id": 151656,
14:   "vision_config": {
14:     "depth": 32,
14:     "fullatt_block_indexes": [
14:       7,
14:       15,
14:       23,
14:       31
14:     ],
14:     "hidden_act": "silu",
14:     "hidden_size": 1280,
14:     "in_channels": 3,
14:     "in_chans": 3,
14:     "intermediate_size": 3420,
14:     "model_type": "qwen2_5_vl",
14:     "num_heads": 16,
14:     "out_hidden_size": 3584,
14:     "patch_size": 14,
14:     "spatial_merge_size": 2,
14:     "spatial_patch_size": 14,
14:     "temporal_patch_size": 2,
14:     "tokens_per_second": 2,
14:     "window_size": 112
14:   },
14:   "vision_end_token_id": 151653,
14:   "vision_start_token_id": 151652,
14:   "vision_token_id": 151654,
14:   "vocab_size": 152064
14: }
14: 
14: [INFO|2025-06-27 21:02:53] llamafactory.model.model_utils.kv_cache:143 >> KV cache is disabled during training.
24: [INFO|image_processing_base.py:380] 2025-06-27 21:02:53,414 >> loading configuration file preprocessor_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
14: [INFO|modeling_utils.py:1124] 2025-06-27 21:02:53,434 >> loading weights file model.safetensors from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/model.safetensors.index.json
29: [INFO|2025-06-27 21:02:53] llamafactory.data.loader:143 >> Loaded tokenized dataset from /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/tokenizer.
14: [INFO|modeling_utils.py:3726] 2025-06-27 21:02:53,442 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model
14: [2025-06-27 21:02:53,442] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
14: [INFO|configuration_utils.py:1142] 2025-06-27 21:02:53,448 >> Generate config GenerationConfig {
14:   "bos_token_id": 151643,
14:   "eos_token_id": 151645,
14:   "use_cache": false
14: }
14: 
14: [INFO|modeling_utils.py:2167] 2025-06-27 21:02:53,449 >> Instantiating Qwen2_5_VisionTransformerPretrainedModel model under default dtype torch.float32.
23: [2025-06-27 21:02:53,453] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
 7: nid005585:122005:122496 [0] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
 7: nid005585:122005:122496 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
 7: nid005585:122005:122496 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
 7: nid005585:122005:122496 [0] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
 7: nid005585:122005:122496 [0] NCCL INFO NET/OFI Using Libfabric version 1.22
 7: nid005585:122005:122496 [0] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
 7: 
 7: nid005585:122005:122496 [0] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
 7: nid005585:122005:122496 [0] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
 7: nid005585:122005:122496 [0] NCCL INFO NET/OFI Using transport protocol SENDRECV
 7: nid005585:122005:122496 [0] NCCL INFO NET/OFI Creating one domain per process
 7: nid005585:122005:122496 [0] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
 7: nid005585:122005:122496 [0] NCCL INFO NET/OFI Support for global registrations: false
 7: nid005585:122005:122496 [0] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
23: nid005917:276888:276888 [3] NCCL INFO cudaDriverVersion 12060
23: nid005917:276888:276888 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
23: nid005917:276888:276888 [3] NCCL INFO Bootstrap : Using hsn0:172.28.23.92<0>
30: nid005936:49908:49908 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
23: nid005917:276888:276888 [3] NCCL INFO NCCL version 2.22.3+cuda12.6
30: nid005936:49908:49908 [0] NCCL INFO Bootstrap : Using hsn0:172.28.50.23<0>
30: nid005936:49908:49908 [0] NCCL INFO NCCL version 2.22.3+cuda12.6
 7: nid005585:122005:122496 [0] NCCL INFO Using network AWS Libfabric
18: [INFO|2025-06-27 21:02:53] llamafactory.data.loader:143 >> Loaded tokenized dataset from /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/tokenizer.
23: nid005917:276887:277420 [2] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
23: nid005917:276886:277419 [1] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
23: nid005917:276886:277419 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
23: nid005917:276887:277420 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
23: nid005917:276887:277420 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
23: nid005917:276886:277419 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
23: nid005917:276887:277420 [2] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
23: nid005917:276886:277419 [1] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
23: nid005917:276886:277419 [1] NCCL INFO NET/OFI Using Libfabric version 1.22
23: nid005917:276887:277420 [2] NCCL INFO NET/OFI Using Libfabric version 1.22
23: nid005917:276886:277419 [1] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
23: nid005917:276887:277420 [2] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
23: nid005917:276885:277421 [0] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
23: nid005917:276885:277421 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
23: nid005917:276885:277421 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
23: nid005917:276885:277421 [0] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
23: nid005917:276885:277421 [0] NCCL INFO NET/OFI Using Libfabric version 1.22
23: nid005917:276885:277421 [0] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
23: 
23: nid005917:276887:277420 [2] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
23: 
23: nid005917:276886:277419 [1] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
23: 
23: nid005917:276885:277421 [0] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
 2: [2025-06-27 21:02:53,518] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
23: nid005917:276886:277419 [1] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
23: nid005917:276886:277419 [1] NCCL INFO NET/OFI Using transport protocol SENDRECV
23: nid005917:276886:277419 [1] NCCL INFO NET/OFI Creating one domain per process
23: nid005917:276887:277420 [2] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
23: nid005917:276887:277420 [2] NCCL INFO NET/OFI Using transport protocol SENDRECV
23: nid005917:276887:277420 [2] NCCL INFO NET/OFI Creating one domain per process
23: nid005917:276886:277419 [1] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
23: nid005917:276885:277421 [0] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
23: nid005917:276885:277421 [0] NCCL INFO NET/OFI Using transport protocol SENDRECV
23: nid005917:276885:277421 [0] NCCL INFO NET/OFI Creating one domain per process
23: nid005917:276887:277420 [2] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
23: nid005917:276885:277421 [0] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
23: nid005917:276886:277419 [1] NCCL INFO NET/OFI Support for global registrations: false
23: nid005917:276886:277419 [1] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
23: nid005917:276885:277421 [0] NCCL INFO NET/OFI Support for global registrations: false
23: nid005917:276885:277421 [0] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
24: [INFO|image_processing_base.py:380] 2025-06-27 21:02:53,535 >> loading configuration file preprocessor_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
23: nid005917:276887:277420 [2] NCCL INFO NET/OFI Support for global registrations: false
23: nid005917:276887:277420 [2] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
24: [INFO|image_processing_base.py:433] 2025-06-27 21:02:53,537 >> Image processor Qwen2VLImageProcessorFast {
24:   "crop_size": null,
24:   "data_format": "channels_first",
24:   "default_to_square": true,
24:   "device": null,
24:   "do_center_crop": null,
24:   "do_convert_rgb": true,
24:   "do_normalize": true,
24:   "do_rescale": true,
24:   "do_resize": true,
24:   "image_mean": [
24:     0.48145466,
24:     0.4578275,
24:     0.40821073
24:   ],
24:   "image_processor_type": "Qwen2VLImageProcessorFast",
24:   "image_std": [
24:     0.26862954,
24:     0.26130258,
24:     0.27577711
24:   ],
24:   "input_data_format": null,
24:   "max_pixels": 12845056,
24:   "merge_size": 2,
24:   "min_pixels": 3136,
24:   "patch_size": 14,
24:   "processor_class": "Qwen2_5_VLProcessor",
24:   "resample": 3,
24:   "rescale_factor": 0.00392156862745098,
24:   "return_tensors": null,
24:   "size": {
24:     "longest_edge": 12845056,
24:     "shortest_edge": 3136
24:   },
24:   "temporal_patch_size": 2
24: }
24: 
23: nid005917:276886:277419 [1] NCCL INFO Using network AWS Libfabric
23: nid005917:276885:277421 [0] NCCL INFO Using network AWS Libfabric
23: nid005917:276887:277420 [2] NCCL INFO Using network AWS Libfabric
24: [INFO|2025-06-27 21:02:53] llamafactory.hparams.parser:406 >> Process rank: 98, world size: 128, device: cuda:2, distributed training: True, compute dtype: torch.bfloat16
24: [INFO|2025-06-27 21:02:53] llamafactory.hparams.parser:406 >> Process rank: 99, world size: 128, device: cuda:3, distributed training: True, compute dtype: torch.bfloat16
24: [INFO|2025-06-27 21:02:53] llamafactory.hparams.parser:406 >> Process rank: 97, world size: 128, device: cuda:1, distributed training: True, compute dtype: torch.bfloat16
13: [2025-06-27 21:02:53,541] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
13: [2025-06-27 21:02:53,541] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
13: [2025-06-27 21:02:53,542] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
25: [2025-06-27 21:02:53,550] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
25: [2025-06-27 21:02:53,551] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
29: [INFO|configuration_utils.py:693] 2025-06-27 21:02:53,562 >> loading configuration file config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/config.json
29: [INFO|configuration_utils.py:765] 2025-06-27 21:02:53,564 >> Model config Qwen2_5_VLConfig {
29:   "architectures": [
29:     "Qwen2_5_VLForConditionalGeneration"
29:   ],
29:   "attention_dropout": 0.0,
29:   "bos_token_id": 151643,
29:   "eos_token_id": 151645,
29:   "hidden_act": "silu",
29:   "hidden_size": 3584,
29:   "image_token_id": 151655,
29:   "initializer_range": 0.02,
29:   "intermediate_size": 18944,
29:   "max_position_embeddings": 128000,
29:   "max_window_layers": 28,
29:   "model_type": "qwen2_5_vl",
29:   "num_attention_heads": 28,
29:   "num_hidden_layers": 28,
29:   "num_key_value_heads": 4,
29:   "rms_norm_eps": 1e-06,
29:   "rope_scaling": {
29:     "mrope_section": [
29:       16,
29:       24,
29:       24
29:     ],
29:     "rope_type": "default",
29:     "type": "default"
29:   },
29:   "rope_theta": 1000000.0,
29:   "sliding_window": 32768,
29:   "tie_word_embeddings": false,
29:   "torch_dtype": "bfloat16",
29:   "transformers_version": "4.51.3",
29:   "use_cache": true,
29:   "use_sliding_window": false,
29:   "video_token_id": 151656,
29:   "vision_config": {
29:     "depth": 32,
29:     "fullatt_block_indexes": [
29:       7,
29:       15,
29:       23,
29:       31
29:     ],
29:     "hidden_act": "silu",
29:     "hidden_size": 1280,
29:     "in_channels": 3,
29:     "in_chans": 3,
29:     "intermediate_size": 3420,
29:     "model_type": "qwen2_5_vl",
29:     "num_heads": 16,
29:     "out_hidden_size": 3584,
29:     "patch_size": 14,
29:     "spatial_merge_size": 2,
29:     "spatial_patch_size": 14,
29:     "temporal_patch_size": 2,
29:     "tokens_per_second": 2,
29:     "window_size": 112
29:   },
29:   "vision_end_token_id": 151653,
29:   "vision_start_token_id": 151652,
29:   "vision_token_id": 151654,
29:   "vocab_size": 152064
29: }
29: 
29: [INFO|2025-06-27 21:02:53] llamafactory.model.model_utils.kv_cache:143 >> KV cache is disabled during training.
 9: [2025-06-27 21:02:53,566] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
 9: [2025-06-27 21:02:53,566] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
18: [INFO|2025-06-27 21:02:53] llamafactory.hparams.parser:406 >> Process rank: 75, world size: 128, device: cuda:3, distributed training: True, compute dtype: torch.bfloat16
29: [INFO|modeling_utils.py:1124] 2025-06-27 21:02:53,583 >> loading weights file model.safetensors from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/model.safetensors.index.json
29: [INFO|modeling_utils.py:3726] 2025-06-27 21:02:53,592 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model
29: [2025-06-27 21:02:53,592] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
 9: nid005588:35937:35937 [2] NCCL INFO cudaDriverVersion 12060
 9: nid005588:35937:35937 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
 9: nid005588:35937:35937 [2] NCCL INFO Bootstrap : Using hsn0:172.28.18.240<0>
 9: nid005588:35937:35937 [2] NCCL INFO NCCL version 2.22.3+cuda12.6
 9: nid005588:35936:35936 [1] NCCL INFO cudaDriverVersion 12060
 9: nid005588:35936:35936 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
 9: nid005588:35936:35936 [1] NCCL INFO Bootstrap : Using hsn0:172.28.18.240<0>
 9: nid005588:35936:35936 [1] NCCL INFO NCCL version 2.22.3+cuda12.6
29: [INFO|configuration_utils.py:1142] 2025-06-27 21:02:53,599 >> Generate config GenerationConfig {
29:   "bos_token_id": 151643,
29:   "eos_token_id": 151645,
29:   "use_cache": false
29: }
29: 
29: [INFO|modeling_utils.py:2167] 2025-06-27 21:02:53,599 >> Instantiating Qwen2_5_VisionTransformerPretrainedModel model under default dtype torch.float32.
10: [2025-06-27 21:02:53,612] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
10: [2025-06-27 21:02:53,614] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
30: [2025-06-27 21:02:53,619] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
29: [INFO|2025-06-27 21:02:53] llamafactory.hparams.parser:406 >> Process rank: 119, world size: 128, device: cuda:3, distributed training: True, compute dtype: torch.bfloat16
29: [INFO|2025-06-27 21:02:53] llamafactory.hparams.parser:406 >> Process rank: 117, world size: 128, device: cuda:1, distributed training: True, compute dtype: torch.bfloat16
29: [INFO|2025-06-27 21:02:53] llamafactory.hparams.parser:406 >> Process rank: 118, world size: 128, device: cuda:2, distributed training: True, compute dtype: torch.bfloat16
 2: [2025-06-27 21:02:53,623] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
 9: nid005588:35935:36428 [0] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
 9: nid005588:35935:36428 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
 9: nid005588:35935:36428 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
 9: nid005588:35935:36428 [0] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
 9: nid005588:35935:36428 [0] NCCL INFO NET/OFI Using Libfabric version 1.22
 9: nid005588:35935:36428 [0] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
18: [INFO|configuration_utils.py:693] 2025-06-27 21:02:53,626 >> loading configuration file config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/config.json
 2: nid005577:17425:17425 [3] NCCL INFO cudaDriverVersion 12060
 2: nid005577:17425:17425 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
 2: nid005577:17425:17425 [3] NCCL INFO Bootstrap : Using hsn0:172.28.18.204<0>
 2: nid005577:17425:17425 [3] NCCL INFO NCCL version 2.22.3+cuda12.6
18: [INFO|configuration_utils.py:765] 2025-06-27 21:02:53,628 >> Model config Qwen2_5_VLConfig {
18:   "architectures": [
18:     "Qwen2_5_VLForConditionalGeneration"
18:   ],
18:   "attention_dropout": 0.0,
18:   "bos_token_id": 151643,
18:   "eos_token_id": 151645,
18:   "hidden_act": "silu",
18:   "hidden_size": 3584,
18:   "image_token_id": 151655,
18:   "initializer_range": 0.02,
18:   "intermediate_size": 18944,
18:   "max_position_embeddings": 128000,
18:   "max_window_layers": 28,
18:   "model_type": "qwen2_5_vl",
18:   "num_attention_heads": 28,
18:   "num_hidden_layers": 28,
18:   "num_key_value_heads": 4,
18:   "rms_norm_eps": 1e-06,
18:   "rope_scaling": {
18:     "mrope_section": [
18:       16,
18:       24,
18:       24
18:     ],
18:     "rope_type": "default",
18:     "type": "default"
18:   },
18:   "rope_theta": 1000000.0,
18:   "sliding_window": 32768,
18:   "tie_word_embeddings": false,
18:   "torch_dtype": "bfloat16",
18:   "transformers_version": "4.51.3",
18:   "use_cache": true,
18:   "use_sliding_window": false,
18:   "video_token_id": 151656,
18:   "vision_config": {
18:     "depth": 32,
18:     "fullatt_block_indexes": [
18:       7,
18:       15,
18:       23,
18:       31
18:     ],
18:     "hidden_act": "silu",
18:     "hidden_size": 1280,
18:     "in_channels": 3,
18:     "in_chans": 3,
18:     "intermediate_size": 3420,
18:     "model_type": "qwen2_5_vl",
18:     "num_heads": 16,
18:     "out_hidden_size": 3584,
18:     "patch_size": 14,
18:     "spatial_merge_size": 2,
18:     "spatial_patch_size": 14,
18:     "temporal_patch_size": 2,
18:     "tokens_per_second": 2,
18:     "window_size": 112
18:   },
18:   "vision_end_token_id": 151653,
18:   "vision_start_token_id": 151652,
18:   "vision_token_id": 151654,
18:   "vocab_size": 152064
18: }
18: 
18: [INFO|2025-06-27 21:02:53] llamafactory.model.model_utils.kv_cache:143 >> KV cache is disabled during training.
 9: 
 9: nid005588:35935:36428 [0] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
 9: nid005588:35935:36428 [0] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
 9: nid005588:35935:36428 [0] NCCL INFO NET/OFI Using transport protocol SENDRECV
 9: nid005588:35935:36428 [0] NCCL INFO NET/OFI Creating one domain per process
 9: nid005588:35935:36428 [0] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
14: nid005600:217720:217720 [0] NCCL INFO cudaDriverVersion 12060
14: nid005600:217720:217720 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
14: nid005600:217720:217720 [0] NCCL INFO Bootstrap : Using hsn0:172.28.50.5<0>
14: nid005600:217720:217720 [0] NCCL INFO NCCL version 2.22.3+cuda12.6
 9: nid005588:35935:36428 [0] NCCL INFO NET/OFI Support for global registrations: false
 9: nid005588:35935:36428 [0] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
 9: nid005588:35935:36428 [0] NCCL INFO Using network AWS Libfabric
25: nid005919:107465:107465 [3] NCCL INFO cudaDriverVersion 12060
25: nid005919:107465:107465 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
25: nid005919:107463:107463 [1] NCCL INFO cudaDriverVersion 12060
25: nid005919:107463:107463 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
25: nid005919:107465:107465 [3] NCCL INFO Bootstrap : Using hsn0:172.28.23.100<0>
25: nid005919:107465:107465 [3] NCCL INFO NCCL version 2.22.3+cuda12.6
25: nid005919:107463:107463 [1] NCCL INFO Bootstrap : Using hsn0:172.28.23.100<0>
25: nid005919:107463:107463 [1] NCCL INFO NCCL version 2.22.3+cuda12.6
25: [2025-06-27 21:02:53,644] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
13: nid005595:197885:197885 [2] NCCL INFO cudaDriverVersion 12060
13: nid005595:197885:197885 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
13: nid005595:197884:197884 [1] NCCL INFO cudaDriverVersion 12060
13: nid005595:197884:197884 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
13: nid005595:197884:197884 [1] NCCL INFO Bootstrap : Using hsn0:172.28.19.12<0>
13: nid005595:197885:197885 [2] NCCL INFO Bootstrap : Using hsn0:172.28.19.12<0>
13: nid005595:197885:197885 [2] NCCL INFO NCCL version 2.22.3+cuda12.6
13: nid005595:197884:197884 [1] NCCL INFO NCCL version 2.22.3+cuda12.6
 2: nid005577:17424:17424 [2] NCCL INFO cudaDriverVersion 12060
 2: nid005577:17424:17424 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
13: nid005595:197886:197886 [3] NCCL INFO cudaDriverVersion 12060
13: nid005595:197886:197886 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
 2: nid005577:17424:17424 [2] NCCL INFO Bootstrap : Using hsn0:172.28.18.204<0>
 2: nid005577:17424:17424 [2] NCCL INFO NCCL version 2.22.3+cuda12.6
13: nid005595:197886:197886 [3] NCCL INFO Bootstrap : Using hsn0:172.28.19.12<0>
13: nid005595:197886:197886 [3] NCCL INFO NCCL version 2.22.3+cuda12.6
18: [INFO|modeling_utils.py:1124] 2025-06-27 21:02:53,651 >> loading weights file model.safetensors from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/model.safetensors.index.json
18: [INFO|modeling_utils.py:3726] 2025-06-27 21:02:53,663 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model
18: [2025-06-27 21:02:53,663] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
 3: [INFO|2025-06-27 21:02:53] llamafactory.data.loader:143 >> Loaded tokenized dataset from /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/tokenizer.
21: nid005914:166784:167271 [0] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
21: nid005914:166786:167270 [2] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
21: nid005914:166784:167271 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
21: nid005914:166786:167270 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
21: nid005914:166784:167271 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
21: nid005914:166786:167270 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
21: nid005914:166784:167271 [0] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
21: nid005914:166786:167270 [2] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
21: nid005914:166784:167271 [0] NCCL INFO NET/OFI Using Libfabric version 1.22
21: nid005914:166786:167270 [2] NCCL INFO NET/OFI Using Libfabric version 1.22
21: nid005914:166784:167271 [0] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
21: nid005914:166786:167270 [2] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
 2: nid005577:17423:17952 [1] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
 2: nid005577:17423:17952 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
 2: nid005577:17423:17952 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
 2: nid005577:17423:17952 [1] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
 2: nid005577:17423:17952 [1] NCCL INFO NET/OFI Using Libfabric version 1.22
 2: nid005577:17423:17952 [1] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
24: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:53,666 >> loading file vocab.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
24: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:53,666 >> loading file merges.txt from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
24: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:53,666 >> loading file tokenizer.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
24: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:53,666 >> loading file added_tokens.json from cache at None
24: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:53,666 >> loading file special_tokens_map.json from cache at None
24: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:53,666 >> loading file tokenizer_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
24: [INFO|tokenization_utils_base.py:2060] 2025-06-27 21:02:53,666 >> loading file chat_template.jinja from cache at None
 2: nid005577:17422:17953 [0] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
 2: nid005577:17422:17953 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
 2: nid005577:17422:17953 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
 2: nid005577:17422:17953 [0] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
 2: nid005577:17422:17953 [0] NCCL INFO NET/OFI Using Libfabric version 1.22
 2: nid005577:17422:17953 [0] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
18: [INFO|configuration_utils.py:1142] 2025-06-27 21:02:53,669 >> Generate config GenerationConfig {
18:   "bos_token_id": 151643,
18:   "eos_token_id": 151645,
18:   "use_cache": false
18: }
18: 
18: [INFO|modeling_utils.py:2167] 2025-06-27 21:02:53,669 >> Instantiating Qwen2_5_VisionTransformerPretrainedModel model under default dtype torch.float32.
22: nid005915:274814:275290 [0] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
22: nid005915:274814:275290 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
22: nid005915:274814:275290 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
22: nid005915:274814:275290 [0] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
22: nid005915:274814:275290 [0] NCCL INFO NET/OFI Using Libfabric version 1.22
22: nid005915:274814:275290 [0] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
25: nid005919:107464:107464 [2] NCCL INFO cudaDriverVersion 12060
25: nid005919:107464:107464 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
25: nid005919:107464:107464 [2] NCCL INFO Bootstrap : Using hsn0:172.28.23.100<0>
25: nid005919:107464:107464 [2] NCCL INFO NCCL version 2.22.3+cuda12.6
 2: 
 2: nid005577:17423:17952 [1] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
21: 
21: nid005914:166786:167270 [2] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
21: 
21: nid005914:166784:167271 [0] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
 2: nid005577:17423:17952 [1] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
 2: nid005577:17423:17952 [1] NCCL INFO NET/OFI Using transport protocol SENDRECV
 2: nid005577:17423:17952 [1] NCCL INFO NET/OFI Creating one domain per process
 2: 
 2: nid005577:17422:17953 [0] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
 2: nid005577:17423:17952 [1] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
 2: nid005577:17422:17953 [0] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
 2: nid005577:17422:17953 [0] NCCL INFO NET/OFI Using transport protocol SENDRECV
 2: nid005577:17422:17953 [0] NCCL INFO NET/OFI Creating one domain per process
 2: nid005577:17422:17953 [0] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
22: 
22: nid005915:274814:275290 [0] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
13: nid005595:197883:198429 [0] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
13: nid005595:197883:198429 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
13: nid005595:197883:198429 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
13: nid005595:197883:198429 [0] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
13: nid005595:197883:198429 [0] NCCL INFO NET/OFI Using Libfabric version 1.22
13: nid005595:197883:198429 [0] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
25: nid005919:107462:107959 [0] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
25: nid005919:107462:107959 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
25: nid005919:107462:107959 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
25: nid005919:107462:107959 [0] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
25: nid005919:107462:107959 [0] NCCL INFO NET/OFI Using Libfabric version 1.22
25: nid005919:107462:107959 [0] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
22: nid005915:274814:275290 [0] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
22: nid005915:274814:275290 [0] NCCL INFO NET/OFI Using transport protocol SENDRECV
22: nid005915:274814:275290 [0] NCCL INFO NET/OFI Creating one domain per process
22: nid005915:274814:275290 [0] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
 2: nid005577:17423:17952 [1] NCCL INFO NET/OFI Support for global registrations: false
 2: nid005577:17423:17952 [1] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
 2: nid005577:17422:17953 [0] NCCL INFO NET/OFI Support for global registrations: false
 2: nid005577:17422:17953 [0] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
30: nid005936:49910:49910 [2] NCCL INFO cudaDriverVersion 12060
30: nid005936:49910:49910 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
 2: nid005577:17423:17952 [1] NCCL INFO Using network AWS Libfabric
21: nid005914:166784:167271 [0] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
21: nid005914:166784:167271 [0] NCCL INFO NET/OFI Using transport protocol SENDRECV
21: nid005914:166784:167271 [0] NCCL INFO NET/OFI Creating one domain per process
21: nid005914:166786:167270 [2] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
21: nid005914:166786:167270 [2] NCCL INFO NET/OFI Using transport protocol SENDRECV
21: nid005914:166786:167270 [2] NCCL INFO NET/OFI Creating one domain per process
30: nid005936:49910:49910 [2] NCCL INFO Bootstrap : Using hsn0:172.28.50.23<0>
30: nid005936:49910:49910 [2] NCCL INFO NCCL version 2.22.3+cuda12.6
21: nid005914:166784:167271 [0] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
21: [2025-06-27 21:02:53,681] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
21: nid005914:166786:167270 [2] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
10: nid005590:110713:110713 [3] NCCL INFO cudaDriverVersion 12060
 2: nid005577:17422:17953 [0] NCCL INFO Using network AWS Libfabric
22: nid005915:274814:275290 [0] NCCL INFO NET/OFI Support for global registrations: false
22: nid005915:274814:275290 [0] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
10: nid005590:110713:110713 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
13: 
13: nid005595:197883:198429 [0] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
10: nid005590:110713:110713 [3] NCCL INFO Bootstrap : Using hsn0:172.28.18.248<0>
10: nid005590:110713:110713 [3] NCCL INFO NCCL version 2.22.3+cuda12.6
10: nid005590:110711:110711 [1] NCCL INFO cudaDriverVersion 12060
10: nid005590:110711:110711 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
13: nid005595:197883:198429 [0] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
13: nid005595:197883:198429 [0] NCCL INFO NET/OFI Using transport protocol SENDRECV
13: nid005595:197883:198429 [0] NCCL INFO NET/OFI Creating one domain per process
10: nid005590:110711:110711 [1] NCCL INFO Bootstrap : Using hsn0:172.28.18.248<0>
10: nid005590:110711:110711 [1] NCCL INFO NCCL version 2.22.3+cuda12.6
 9: [2025-06-27 21:02:53,683] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
13: nid005595:197883:198429 [0] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
22: nid005915:274814:275290 [0] NCCL INFO Using network AWS Libfabric
21: nid005914:166784:167271 [0] NCCL INFO NET/OFI Support for global registrations: false
21: nid005914:166784:167271 [0] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
21: nid005914:166786:167270 [2] NCCL INFO NET/OFI Support for global registrations: false
21: nid005914:166786:167270 [2] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
25: 
25: nid005919:107462:107959 [0] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
25: nid005919:107462:107959 [0] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
25: nid005919:107462:107959 [0] NCCL INFO NET/OFI Using transport protocol SENDRECV
25: nid005919:107462:107959 [0] NCCL INFO NET/OFI Creating one domain per process
25: nid005919:107462:107959 [0] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
21: nid005914:166784:167271 [0] NCCL INFO Using network AWS Libfabric
21: nid005914:166786:167270 [2] NCCL INFO Using network AWS Libfabric
13: nid005595:197883:198429 [0] NCCL INFO NET/OFI Support for global registrations: false
13: nid005595:197883:198429 [0] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
28: nid005929:16030:16526 [0] NCCL INFO DMA-BUF is available on GPU device 0
13: nid005595:197883:198429 [0] NCCL INFO Using network AWS Libfabric
25: nid005919:107462:107959 [0] NCCL INFO NET/OFI Support for global registrations: false
25: nid005919:107462:107959 [0] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
21: [2025-06-27 21:02:53,692] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
25: nid005919:107462:107959 [0] NCCL INFO Using network AWS Libfabric
10: nid005590:110710:111197 [0] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
10: nid005590:110710:111197 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
10: nid005590:110710:111197 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
10: nid005590:110710:111197 [0] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
10: nid005590:110710:111197 [0] NCCL INFO NET/OFI Using Libfabric version 1.22
10: nid005590:110710:111197 [0] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
15: [2025-06-27 21:02:53,715] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
10: 
10: nid005590:110710:111197 [0] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
30: nid005936:49909:50450 [1] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
30: nid005936:49909:50450 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
30: nid005936:49909:50450 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
30: nid005936:49909:50450 [1] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
30: nid005936:49909:50450 [1] NCCL INFO NET/OFI Using Libfabric version 1.22
30: nid005936:49909:50450 [1] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
10: nid005590:110710:111197 [0] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
10: nid005590:110710:111197 [0] NCCL INFO NET/OFI Using transport protocol SENDRECV
10: nid005590:110710:111197 [0] NCCL INFO NET/OFI Creating one domain per process
10: nid005590:110710:111197 [0] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
30: nid005936:49911:50449 [3] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
30: nid005936:49911:50449 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
30: nid005936:49911:50449 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
30: nid005936:49911:50449 [3] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
30: nid005936:49911:50449 [3] NCCL INFO NET/OFI Using Libfabric version 1.22
30: nid005936:49911:50449 [3] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
30: nid005936:49908:50465 [0] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
30: nid005936:49908:50465 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
30: nid005936:49908:50465 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
30: nid005936:49908:50465 [0] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
30: nid005936:49908:50465 [0] NCCL INFO NET/OFI Using Libfabric version 1.22
30: nid005936:49908:50465 [0] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
10: nid005590:110710:111197 [0] NCCL INFO NET/OFI Support for global registrations: false
10: nid005590:110710:111197 [0] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
10: nid005590:110710:111197 [0] NCCL INFO Using network AWS Libfabric
30: 
30: nid005936:49909:50450 [1] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
 1: nid005576:147557:148053 [0] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
 1: nid005576:147557:148053 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
 1: nid005576:147557:148053 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
 1: nid005576:147557:148053 [0] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
 1: nid005576:147557:148053 [0] NCCL INFO NET/OFI Using Libfabric version 1.22
 1: nid005576:147557:148053 [0] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
30: 
30: nid005936:49911:50449 [3] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
30: 
30: nid005936:49908:50465 [0] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
 1: 
 1: nid005576:147557:148053 [0] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
 1: nid005576:147557:148053 [0] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
 1: nid005576:147557:148053 [0] NCCL INFO NET/OFI Using transport protocol SENDRECV
 1: nid005576:147557:148053 [0] NCCL INFO NET/OFI Creating one domain per process
 1: nid005576:147557:148053 [0] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
 0: nid005574:69058:69552 [0] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
 0: nid005574:69058:69552 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
 0: nid005574:69058:69552 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
 0: nid005574:69058:69552 [0] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
 0: nid005574:69058:69552 [0] NCCL INFO NET/OFI Using Libfabric version 1.22
 0: nid005574:69058:69552 [0] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
30: nid005936:49909:50450 [1] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
30: nid005936:49909:50450 [1] NCCL INFO NET/OFI Using transport protocol SENDRECV
30: nid005936:49909:50450 [1] NCCL INFO NET/OFI Creating one domain per process
30: nid005936:49909:50450 [1] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
 1: nid005576:147557:148053 [0] NCCL INFO NET/OFI Support for global registrations: false
 1: nid005576:147557:148053 [0] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
30: nid005936:49911:50449 [3] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
30: nid005936:49911:50449 [3] NCCL INFO NET/OFI Using transport protocol SENDRECV
30: nid005936:49911:50449 [3] NCCL INFO NET/OFI Creating one domain per process
 5: nid005582:196715:197387 [2] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
 5: nid005582:196715:197387 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
 5: nid005582:196715:197387 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
 5: nid005582:196715:197387 [2] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
 5: nid005582:196715:197387 [2] NCCL INFO NET/OFI Using Libfabric version 1.22
 5: nid005582:196715:197387 [2] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
 5: nid005582:196716:197388 [3] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
 5: nid005582:196716:197388 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
 5: nid005582:196716:197388 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
30: nid005936:49908:50465 [0] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
30: nid005936:49908:50465 [0] NCCL INFO NET/OFI Using transport protocol SENDRECV
30: nid005936:49908:50465 [0] NCCL INFO NET/OFI Creating one domain per process
 5: nid005582:196716:197388 [3] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
 5: nid005582:196716:197388 [3] NCCL INFO NET/OFI Using Libfabric version 1.22
 5: nid005582:196716:197388 [3] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
30: nid005936:49911:50449 [3] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
30: nid005936:49908:50465 [0] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
 5: nid005582:196714:197386 [1] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
 5: nid005582:196714:197386 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
 5: nid005582:196714:197386 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
 5: nid005582:196714:197386 [1] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
 5: nid005582:196714:197386 [1] NCCL INFO NET/OFI Using Libfabric version 1.22
 5: nid005582:196714:197386 [1] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
 1: nid005576:147557:148053 [0] NCCL INFO Using network AWS Libfabric
 5: nid005582:196713:197389 [0] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
 5: nid005582:196713:197389 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
 5: nid005582:196713:197389 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
 5: nid005582:196713:197389 [0] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
 5: nid005582:196713:197389 [0] NCCL INFO NET/OFI Using Libfabric version 1.22
 5: nid005582:196713:197389 [0] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
 0: 
 0: nid005574:69058:69552 [0] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
30: nid005936:49909:50450 [1] NCCL INFO NET/OFI Support for global registrations: false
30: nid005936:49909:50450 [1] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
 0: nid005574:69058:69552 [0] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
 0: nid005574:69058:69552 [0] NCCL INFO NET/OFI Using transport protocol SENDRECV
 0: nid005574:69058:69552 [0] NCCL INFO NET/OFI Creating one domain per process
 0: nid005574:69058:69552 [0] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
30: nid005936:49908:50465 [0] NCCL INFO NET/OFI Support for global registrations: false
30: nid005936:49908:50465 [0] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
30: nid005936:49910:50467 [2] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
30: nid005936:49910:50467 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
30: nid005936:49910:50467 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
30: nid005936:49910:50467 [2] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
30: nid005936:49910:50467 [2] NCCL INFO NET/OFI Using Libfabric version 1.22
30: nid005936:49910:50467 [2] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
30: nid005936:49911:50449 [3] NCCL INFO NET/OFI Support for global registrations: false
30: nid005936:49911:50449 [3] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
30: nid005936:49909:50450 [1] NCCL INFO Using network AWS Libfabric
30: nid005936:49908:50465 [0] NCCL INFO Using network AWS Libfabric
 0: nid005574:69058:69552 [0] NCCL INFO NET/OFI Support for global registrations: false
 0: nid005574:69058:69552 [0] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
30: nid005936:49911:50449 [3] NCCL INFO Using network AWS Libfabric
30: 
30: nid005936:49910:50467 [2] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
 0: nid005574:69058:69552 [0] NCCL INFO Using network AWS Libfabric
30: nid005936:49910:50467 [2] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
30: nid005936:49910:50467 [2] NCCL INFO NET/OFI Using transport protocol SENDRECV
30: nid005936:49910:50467 [2] NCCL INFO NET/OFI Creating one domain per process
30: nid005936:49910:50467 [2] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
15: nid005601:210677:210677 [1] NCCL INFO cudaDriverVersion 12060
15: nid005601:210677:210677 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
15: nid005601:210677:210677 [1] NCCL INFO Bootstrap : Using hsn0:172.28.49.117<0>
15: nid005601:210677:210677 [1] NCCL INFO NCCL version 2.22.3+cuda12.6
26: nid005920:67123:67613 [0] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
26: nid005920:67123:67613 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
26: nid005920:67123:67613 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
26: nid005920:67123:67613 [0] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
26: nid005920:67123:67613 [0] NCCL INFO NET/OFI Using Libfabric version 1.22
26: nid005920:67123:67613 [0] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
30: nid005936:49910:50467 [2] NCCL INFO NET/OFI Support for global registrations: false
30: nid005936:49910:50467 [2] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
 5: 
 5: nid005582:196714:197386 [1] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
 5: 
 5: nid005582:196715:197387 [2] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
 5: 
 5: nid005582:196713:197389 [0] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
 5: 
 5: nid005582:196716:197388 [3] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
30: nid005936:49910:50467 [2] NCCL INFO Using network AWS Libfabric
26: 
26: nid005920:67123:67613 [0] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
26: nid005920:67123:67613 [0] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
26: nid005920:67123:67613 [0] NCCL INFO NET/OFI Using transport protocol SENDRECV
26: nid005920:67123:67613 [0] NCCL INFO NET/OFI Creating one domain per process
26: nid005920:67123:67613 [0] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
20: nid005913:292681:293089 [0] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
20: nid005913:292681:293089 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
20: nid005913:292681:293089 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
20: nid005913:292681:293089 [0] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
20: nid005913:292681:293089 [0] NCCL INFO NET/OFI Using Libfabric version 1.22
20: nid005913:292681:293089 [0] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
26: nid005920:67123:67613 [0] NCCL INFO NET/OFI Support for global registrations: false
26: nid005920:67123:67613 [0] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
26: nid005920:67123:67613 [0] NCCL INFO Using network AWS Libfabric
20: 
20: nid005913:292681:293089 [0] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
20: nid005913:292681:293089 [0] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
20: nid005913:292681:293089 [0] NCCL INFO NET/OFI Using transport protocol SENDRECV
20: nid005913:292681:293089 [0] NCCL INFO NET/OFI Creating one domain per process
20: nid005913:292681:293089 [0] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
 5: nid005582:196714:197386 [1] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
 5: nid005582:196714:197386 [1] NCCL INFO NET/OFI Using transport protocol SENDRECV
 5: nid005582:196714:197386 [1] NCCL INFO NET/OFI Creating one domain per process
20: nid005913:292681:293089 [0] NCCL INFO NET/OFI Support for global registrations: false
20: nid005913:292681:293089 [0] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
12: nid005594:53085:53561 [0] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
12: nid005594:53085:53561 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
12: nid005594:53085:53561 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
12: nid005594:53085:53561 [0] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
12: nid005594:53085:53561 [0] NCCL INFO NET/OFI Using Libfabric version 1.22
12: nid005594:53085:53561 [0] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
 5: nid005582:196714:197386 [1] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
20: nid005913:292681:293089 [0] NCCL INFO Using network AWS Libfabric
15: nid005601:210679:211194 [3] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
15: nid005601:210678:211209 [2] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
15: nid005601:210678:211209 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
15: nid005601:210679:211194 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
15: nid005601:210678:211209 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
15: nid005601:210679:211194 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
15: nid005601:210678:211209 [2] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
15: nid005601:210679:211194 [3] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
15: nid005601:210678:211209 [2] NCCL INFO NET/OFI Using Libfabric version 1.22
15: nid005601:210679:211194 [3] NCCL INFO NET/OFI Using Libfabric version 1.22
15: nid005601:210678:211209 [2] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
15: nid005601:210679:211194 [3] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
15: nid005601:210676:211210 [0] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
15: nid005601:210676:211210 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
15: nid005601:210676:211210 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
15: nid005601:210676:211210 [0] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
15: nid005601:210676:211210 [0] NCCL INFO NET/OFI Using Libfabric version 1.22
15: nid005601:210676:211210 [0] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
12: 
12: nid005594:53085:53561 [0] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
 5: nid005582:196713:197389 [0] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
 5: nid005582:196713:197389 [0] NCCL INFO NET/OFI Using transport protocol SENDRECV
 5: nid005582:196713:197389 [0] NCCL INFO NET/OFI Creating one domain per process
 5: nid005582:196714:197386 [1] NCCL INFO NET/OFI Support for global registrations: false
 5: nid005582:196714:197386 [1] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
12: nid005594:53085:53561 [0] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
12: nid005594:53085:53561 [0] NCCL INFO NET/OFI Using transport protocol SENDRECV
12: nid005594:53085:53561 [0] NCCL INFO NET/OFI Creating one domain per process
 5: nid005582:196713:197389 [0] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
12: nid005594:53085:53561 [0] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
 5: nid005582:196716:197388 [3] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
 5: nid005582:196716:197388 [3] NCCL INFO NET/OFI Using transport protocol SENDRECV
 5: nid005582:196716:197388 [3] NCCL INFO NET/OFI Creating one domain per process
 5: nid005582:196715:197387 [2] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
 5: nid005582:196715:197387 [2] NCCL INFO NET/OFI Using transport protocol SENDRECV
 5: nid005582:196715:197387 [2] NCCL INFO NET/OFI Creating one domain per process
 5: nid005582:196716:197388 [3] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
 5: nid005582:196715:197387 [2] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
 5: nid005582:196714:197386 [1] NCCL INFO Using network AWS Libfabric
29: nid005932:167680:167680 [0] NCCL INFO cudaDriverVersion 12060
29: nid005932:167680:167680 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
 3: [INFO|configuration_utils.py:693] 2025-06-27 21:02:53,791 >> loading configuration file config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/config.json
29: nid005932:167680:167680 [0] NCCL INFO Bootstrap : Using hsn0:172.28.23.144<0>
29: nid005932:167680:167680 [0] NCCL INFO NCCL version 2.22.3+cuda12.6
 5: nid005582:196713:197389 [0] NCCL INFO NET/OFI Support for global registrations: false
 5: nid005582:196713:197389 [0] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
 5: nid005582:196715:197387 [2] NCCL INFO NET/OFI Support for global registrations: false
 5: nid005582:196715:197387 [2] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
12: nid005594:53085:53561 [0] NCCL INFO NET/OFI Support for global registrations: false
12: nid005594:53085:53561 [0] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
 3: [INFO|configuration_utils.py:765] 2025-06-27 21:02:53,793 >> Model config Qwen2_5_VLConfig {
 3:   "architectures": [
 3:     "Qwen2_5_VLForConditionalGeneration"
 3:   ],
 3:   "attention_dropout": 0.0,
 3:   "bos_token_id": 151643,
 3:   "eos_token_id": 151645,
 3:   "hidden_act": "silu",
 3:   "hidden_size": 3584,
 3:   "image_token_id": 151655,
 3:   "initializer_range": 0.02,
 3:   "intermediate_size": 18944,
 3:   "max_position_embeddings": 128000,
 3:   "max_window_layers": 28,
 3:   "model_type": "qwen2_5_vl",
 3:   "num_attention_heads": 28,
 3:   "num_hidden_layers": 28,
 3:   "num_key_value_heads": 4,
 3:   "rms_norm_eps": 1e-06,
 3:   "rope_scaling": {
 3:     "mrope_section": [
 3:       16,
 3:       24,
 3:       24
 3:     ],
 3:     "rope_type": "default",
 3:     "type": "default"
 3:   },
 3:   "rope_theta": 1000000.0,
 3:   "sliding_window": 32768,
 3:   "tie_word_embeddings": false,
 3:   "torch_dtype": "bfloat16",
 3:   "transformers_version": "4.51.3",
 3:   "use_cache": true,
 3:   "use_sliding_window": false,
 3:   "video_token_id": 151656,
 3:   "vision_config": {
 3:     "depth": 32,
 3:     "fullatt_block_indexes": [
 3:       7,
 3:       15,
 3:       23,
 3:       31
 3:     ],
 3:     "hidden_act": "silu",
 3:     "hidden_size": 1280,
 3:     "in_channels": 3,
 3:     "in_chans": 3,
 3:     "intermediate_size": 3420,
 3:     "model_type": "qwen2_5_vl",
 3:     "num_heads": 16,
 3:     "out_hidden_size": 3584,
 3:     "patch_size": 14,
 3:     "spatial_merge_size": 2,
 3:     "spatial_patch_size": 14,
 3:     "temporal_patch_size": 2,
 3:     "tokens_per_second": 2,
 3:     "window_size": 112
 3:   },
 3:   "vision_end_token_id": 151653,
 3:   "vision_start_token_id": 151652,
 3:   "vision_token_id": 151654,
 3:   "vocab_size": 152064
 3: }
 3: 
 3: [INFO|2025-06-27 21:02:53] llamafactory.model.model_utils.kv_cache:143 >> KV cache is disabled during training.
 5: nid005582:196716:197388 [3] NCCL INFO NET/OFI Support for global registrations: false
 5: nid005582:196716:197388 [3] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
15: 
15: nid005601:210679:211194 [3] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
15: 
15: nid005601:210678:211209 [2] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
15: 
15: nid005601:210676:211210 [0] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
12: nid005594:53085:53561 [0] NCCL INFO Using network AWS Libfabric
 5: nid005582:196715:197387 [2] NCCL INFO Using network AWS Libfabric
 5: nid005582:196713:197389 [0] NCCL INFO Using network AWS Libfabric
 5: nid005582:196716:197388 [3] NCCL INFO Using network AWS Libfabric
10: [2025-06-27 21:02:53,805] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
15: nid005601:210679:211194 [3] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
15: nid005601:210679:211194 [3] NCCL INFO NET/OFI Using transport protocol SENDRECV
15: nid005601:210679:211194 [3] NCCL INFO NET/OFI Creating one domain per process
15: nid005601:210679:211194 [3] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
15: nid005601:210678:211209 [2] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
15: nid005601:210678:211209 [2] NCCL INFO NET/OFI Using transport protocol SENDRECV
15: nid005601:210678:211209 [2] NCCL INFO NET/OFI Creating one domain per process
15: nid005601:210676:211210 [0] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
15: nid005601:210676:211210 [0] NCCL INFO NET/OFI Using transport protocol SENDRECV
15: nid005601:210676:211210 [0] NCCL INFO NET/OFI Creating one domain per process
15: nid005601:210678:211209 [2] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
15: nid005601:210676:211210 [0] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
15: nid005601:210679:211194 [3] NCCL INFO NET/OFI Support for global registrations: false
15: nid005601:210679:211194 [3] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
 3: [INFO|modeling_utils.py:1124] 2025-06-27 21:02:53,812 >> loading weights file model.safetensors from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/model.safetensors.index.json
31: nid005937:256589:256847 [0] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
31: nid005937:256589:256847 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
31: nid005937:256589:256847 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
31: nid005937:256589:256847 [0] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
31: nid005937:256589:256847 [0] NCCL INFO NET/OFI Using Libfabric version 1.22
31: nid005937:256589:256847 [0] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
15: nid005601:210676:211210 [0] NCCL INFO NET/OFI Support for global registrations: false
15: nid005601:210676:211210 [0] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
15: nid005601:210678:211209 [2] NCCL INFO NET/OFI Support for global registrations: false
15: nid005601:210678:211209 [2] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
15: nid005601:210679:211194 [3] NCCL INFO Using network AWS Libfabric
15: nid005601:210676:211210 [0] NCCL INFO Using network AWS Libfabric
15: nid005601:210678:211209 [2] NCCL INFO Using network AWS Libfabric
31: 
31: nid005937:256589:256847 [0] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
31: nid005937:256589:256847 [0] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
31: nid005937:256589:256847 [0] NCCL INFO NET/OFI Using transport protocol SENDRECV
31: nid005937:256589:256847 [0] NCCL INFO NET/OFI Creating one domain per process
 3: [INFO|modeling_utils.py:3726] 2025-06-27 21:02:53,822 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model
 3: [2025-06-27 21:02:53,822] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
31: nid005937:256589:256847 [0] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
15: nid005601:210677:211211 [1] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
15: nid005601:210677:211211 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
15: nid005601:210677:211211 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
15: nid005601:210677:211211 [1] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
15: nid005601:210677:211211 [1] NCCL INFO NET/OFI Using Libfabric version 1.22
15: nid005601:210677:211211 [1] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
31: nid005937:256589:256847 [0] NCCL INFO NET/OFI Support for global registrations: false
31: nid005937:256589:256847 [0] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
15: 
15: nid005601:210677:211211 [1] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
 3: [INFO|configuration_utils.py:1142] 2025-06-27 21:02:53,827 >> Generate config GenerationConfig {
 3:   "bos_token_id": 151643,
 3:   "eos_token_id": 151645,
 3:   "use_cache": false
 3: }
 3: 
 3: [INFO|modeling_utils.py:2167] 2025-06-27 21:02:53,827 >> Instantiating Qwen2_5_VisionTransformerPretrainedModel model under default dtype torch.float32.
15: nid005601:210677:211211 [1] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
15: nid005601:210677:211211 [1] NCCL INFO NET/OFI Using transport protocol SENDRECV
15: nid005601:210677:211211 [1] NCCL INFO NET/OFI Creating one domain per process
15: nid005601:210677:211211 [1] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
31: nid005937:256589:256847 [0] NCCL INFO Using network AWS Libfabric
15: nid005601:210677:211211 [1] NCCL INFO NET/OFI Support for global registrations: false
15: nid005601:210677:211211 [1] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
15: nid005601:210677:211211 [1] NCCL INFO Using network AWS Libfabric
27: [2025-06-27 21:02:53,834] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
27: [2025-06-27 21:02:53,836] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
28: [2025-06-27 21:02:53,837] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
17: [2025-06-27 21:02:53,843] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
 4: [INFO|2025-06-27 21:02:53] llamafactory.data.loader:143 >> Loaded tokenized dataset from /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/tokenizer.
18: nid005911:38864:38864 [0] NCCL INFO cudaDriverVersion 12060
18: nid005911:38864:38864 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
18: nid005911:38864:38864 [0] NCCL INFO Bootstrap : Using hsn0:172.28.23.68<0>
18: nid005911:38864:38864 [0] NCCL INFO NCCL version 2.22.3+cuda12.6
24: [INFO|tokenization_utils_base.py:2323] 2025-06-27 21:02:53,851 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
28: [2025-06-27 21:02:53,855] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
28: nid005929:16031:16031 [1] NCCL INFO cudaDriverVersion 12060
28: nid005929:16031:16031 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
28: nid005929:16031:16031 [1] NCCL INFO Bootstrap : Using hsn0:172.28.23.132<0>
28: nid005929:16031:16031 [1] NCCL INFO NCCL version 2.22.3+cuda12.6
 8: nid005586:68926:69401 [0] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
 8: nid005586:68926:69401 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
 8: nid005586:68926:69401 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
 8: nid005586:68926:69401 [0] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
 8: nid005586:68926:69401 [0] NCCL INFO NET/OFI Using Libfabric version 1.22
 8: nid005586:68926:69401 [0] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
19: nid005912:12435:12909 [0] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
19: nid005912:12435:12909 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
19: nid005912:12435:12909 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
19: nid005912:12435:12909 [0] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
19: nid005912:12435:12909 [0] NCCL INFO NET/OFI Using Libfabric version 1.22
19: nid005912:12435:12909 [0] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
17: nid005803:180735:180735 [3] NCCL INFO cudaDriverVersion 12060
17: nid005803:180735:180735 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
16: nid005802:6297:6852 [0] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
16: nid005802:6297:6852 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
16: nid005802:6297:6852 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
16: nid005802:6297:6852 [0] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
16: nid005802:6297:6852 [0] NCCL INFO NET/OFI Using Libfabric version 1.22
16: nid005802:6297:6852 [0] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
14: nid005600:217720:218195 [0] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
14: nid005600:217720:218195 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
14: nid005600:217720:218195 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
14: nid005600:217720:218195 [0] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
14: nid005600:217720:218195 [0] NCCL INFO NET/OFI Using Libfabric version 1.22
14: nid005600:217720:218195 [0] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
17: nid005803:180735:180735 [3] NCCL INFO Bootstrap : Using hsn0:172.28.21.212<0>
17: nid005803:180735:180735 [3] NCCL INFO NCCL version 2.22.3+cuda12.6
11: nid005591:191603:192099 [0] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
11: nid005591:191603:192099 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
11: nid005591:191603:192099 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
11: nid005591:191603:192099 [0] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
11: nid005591:191603:192099 [0] NCCL INFO NET/OFI Using Libfabric version 1.22
11: nid005591:191603:192099 [0] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
27: nid005922:80743:80743 [2] NCCL INFO cudaDriverVersion 12060
27: nid005922:80743:80743 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
27: nid005922:80743:80743 [2] NCCL INFO Bootstrap : Using hsn0:172.28.48.251<0>
27: nid005922:80743:80743 [2] NCCL INFO NCCL version 2.22.3+cuda12.6
27: nid005922:80744:80744 [3] NCCL INFO cudaDriverVersion 12060
27: nid005922:80744:80744 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
 8: 
 8: nid005586:68926:69401 [0] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
27: nid005922:80744:80744 [3] NCCL INFO Bootstrap : Using hsn0:172.28.48.251<0>
27: nid005922:80744:80744 [3] NCCL INFO NCCL version 2.22.3+cuda12.6
19: 
19: nid005912:12435:12909 [0] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
 8: nid005586:68926:69401 [0] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
 8: nid005586:68926:69401 [0] NCCL INFO NET/OFI Using transport protocol SENDRECV
 8: nid005586:68926:69401 [0] NCCL INFO NET/OFI Creating one domain per process
 8: nid005586:68926:69401 [0] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
19: nid005912:12435:12909 [0] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
19: nid005912:12435:12909 [0] NCCL INFO NET/OFI Using transport protocol SENDRECV
19: nid005912:12435:12909 [0] NCCL INFO NET/OFI Creating one domain per process
28: nid005929:16032:16032 [2] NCCL INFO cudaDriverVersion 12060
19: nid005912:12435:12909 [0] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
28: nid005929:16032:16032 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
14: 
14: nid005600:217720:218195 [0] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
16: 
16: nid005802:6297:6852 [0] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
28: nid005929:16032:16032 [2] NCCL INFO Bootstrap : Using hsn0:172.28.23.132<0>
28: nid005929:16032:16032 [2] NCCL INFO NCCL version 2.22.3+cuda12.6
14: nid005600:217720:218195 [0] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
14: nid005600:217720:218195 [0] NCCL INFO NET/OFI Using transport protocol SENDRECV
14: nid005600:217720:218195 [0] NCCL INFO NET/OFI Creating one domain per process
14: nid005600:217720:218195 [0] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
16: nid005802:6297:6852 [0] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
16: nid005802:6297:6852 [0] NCCL INFO NET/OFI Using transport protocol SENDRECV
16: nid005802:6297:6852 [0] NCCL INFO NET/OFI Creating one domain per process
16: nid005802:6297:6852 [0] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
 8: nid005586:68926:69401 [0] NCCL INFO NET/OFI Support for global registrations: false
 8: nid005586:68926:69401 [0] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
19: nid005912:12435:12909 [0] NCCL INFO NET/OFI Support for global registrations: false
19: nid005912:12435:12909 [0] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
11: 
11: nid005591:191603:192099 [0] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
11: nid005591:191603:192099 [0] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
11: nid005591:191603:192099 [0] NCCL INFO NET/OFI Using transport protocol SENDRECV
11: nid005591:191603:192099 [0] NCCL INFO NET/OFI Creating one domain per process
11: nid005591:191603:192099 [0] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
 8: nid005586:68926:69401 [0] NCCL INFO Using network AWS Libfabric
14: nid005600:217720:218195 [0] NCCL INFO NET/OFI Support for global registrations: false
14: nid005600:217720:218195 [0] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
16: nid005802:6297:6852 [0] NCCL INFO NET/OFI Support for global registrations: false
16: nid005802:6297:6852 [0] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
19: nid005912:12435:12909 [0] NCCL INFO Using network AWS Libfabric
14: nid005600:217720:218195 [0] NCCL INFO Using network AWS Libfabric
16: nid005802:6297:6852 [0] NCCL INFO Using network AWS Libfabric
11: nid005591:191603:192099 [0] NCCL INFO NET/OFI Support for global registrations: false
11: nid005591:191603:192099 [0] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
11: nid005591:191603:192099 [0] NCCL INFO Using network AWS Libfabric
27: nid005922:80741:81228 [0] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
27: nid005922:80741:81228 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
27: nid005922:80741:81228 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
27: nid005922:80741:81228 [0] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
27: nid005922:80741:81228 [0] NCCL INFO NET/OFI Using Libfabric version 1.22
27: nid005922:80741:81228 [0] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
17: nid005803:180733:181262 [1] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
17: nid005803:180733:181262 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
17: nid005803:180733:181262 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
17: nid005803:180733:181262 [1] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
17: nid005803:180733:181262 [1] NCCL INFO NET/OFI Using Libfabric version 1.22
17: nid005803:180733:181262 [1] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
17: nid005803:180734:181263 [2] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
17: nid005803:180734:181263 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
17: nid005803:180734:181263 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
17: nid005803:180734:181263 [2] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
17: nid005803:180734:181263 [2] NCCL INFO NET/OFI Using Libfabric version 1.22
17: nid005803:180734:181263 [2] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
17: nid005803:180732:181264 [0] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
17: nid005803:180732:181264 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
17: nid005803:180732:181264 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
17: nid005803:180732:181264 [0] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
17: nid005803:180732:181264 [0] NCCL INFO NET/OFI Using Libfabric version 1.22
17: nid005803:180732:181264 [0] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
27: 
27: nid005922:80741:81228 [0] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
27: nid005922:80741:81228 [0] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
27: nid005922:80741:81228 [0] NCCL INFO NET/OFI Using transport protocol SENDRECV
27: nid005922:80741:81228 [0] NCCL INFO NET/OFI Creating one domain per process
27: nid005922:80741:81228 [0] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
27: nid005922:80742:81229 [1] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
27: nid005922:80742:81229 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
27: nid005922:80742:81229 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
27: nid005922:80742:81229 [1] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
27: nid005922:80742:81229 [1] NCCL INFO NET/OFI Using Libfabric version 1.22
27: nid005922:80742:81229 [1] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
17: 
17: nid005803:180733:181262 [1] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
17: 
17: nid005803:180734:181263 [2] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
27: nid005922:80741:81228 [0] NCCL INFO NET/OFI Support for global registrations: false
27: 
27: nid005922:80742:81229 [1] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
27: nid005922:80741:81228 [0] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
17: 
17: nid005803:180732:181264 [0] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
27: nid005922:80742:81229 [1] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
27: nid005922:80742:81229 [1] NCCL INFO NET/OFI Using transport protocol SENDRECV
27: nid005922:80742:81229 [1] NCCL INFO NET/OFI Creating one domain per process
27: nid005922:80742:81229 [1] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
 1: [2025-06-27 21:02:53,908] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
12: [2025-06-27 21:02:53,908] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
27: nid005922:80741:81228 [0] NCCL INFO Using network AWS Libfabric
27: nid005922:80742:81229 [1] NCCL INFO NET/OFI Support for global registrations: false
27: nid005922:80742:81229 [1] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
17: nid005803:180733:181262 [1] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
17: nid005803:180733:181262 [1] NCCL INFO NET/OFI Using transport protocol SENDRECV
17: nid005803:180733:181262 [1] NCCL INFO NET/OFI Creating one domain per process
17: nid005803:180734:181263 [2] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
17: nid005803:180734:181263 [2] NCCL INFO NET/OFI Using transport protocol SENDRECV
17: nid005803:180734:181263 [2] NCCL INFO NET/OFI Creating one domain per process
27: nid005922:80742:81229 [1] NCCL INFO Using network AWS Libfabric
17: nid005803:180733:181262 [1] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
12: [2025-06-27 21:02:53,916] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
17: nid005803:180734:181263 [2] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
17: nid005803:180732:181264 [0] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
17: nid005803:180732:181264 [0] NCCL INFO NET/OFI Using transport protocol SENDRECV
17: nid005803:180732:181264 [0] NCCL INFO NET/OFI Creating one domain per process
17: nid005803:180732:181264 [0] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
17: nid005803:180733:181262 [1] NCCL INFO NET/OFI Support for global registrations: false
17: nid005803:180733:181262 [1] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
17: nid005803:180734:181263 [2] NCCL INFO NET/OFI Support for global registrations: false
17: nid005803:180734:181263 [2] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
17: nid005803:180732:181264 [0] NCCL INFO NET/OFI Support for global registrations: false
17: nid005803:180732:181264 [0] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
17: nid005803:180733:181262 [1] NCCL INFO Using network AWS Libfabric
17: nid005803:180734:181263 [2] NCCL INFO Using network AWS Libfabric
17: nid005803:180732:181264 [0] NCCL INFO Using network AWS Libfabric
28: nid005929:16031:16569 [1] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
28: nid005929:16031:16569 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
28: nid005929:16031:16569 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
28: nid005929:16031:16569 [1] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
28: nid005929:16031:16569 [1] NCCL INFO NET/OFI Using Libfabric version 1.22
28: nid005929:16031:16569 [1] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
28: 
28: nid005929:16031:16569 [1] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
19: [2025-06-27 21:02:53,943] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
29: nid005932:167680:168169 [0] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
29: nid005932:167680:168169 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
29: nid005932:167680:168169 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
29: nid005932:167680:168169 [0] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
29: nid005932:167680:168169 [0] NCCL INFO NET/OFI Using Libfabric version 1.22
29: nid005932:167680:168169 [0] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
28: nid005929:16031:16569 [1] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
28: nid005929:16031:16569 [1] NCCL INFO NET/OFI Using transport protocol SENDRECV
28: nid005929:16031:16569 [1] NCCL INFO NET/OFI Creating one domain per process
28: nid005929:16031:16569 [1] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
28: nid005929:16032:16570 [2] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
28: nid005929:16032:16570 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
28: nid005929:16032:16570 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
28: nid005929:16032:16570 [2] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
28: nid005929:16032:16570 [2] NCCL INFO NET/OFI Using Libfabric version 1.22
28: nid005929:16032:16570 [2] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
28: 
28: nid005929:16032:16570 [2] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
28: nid005929:16031:16569 [1] NCCL INFO NET/OFI Support for global registrations: false
28: nid005929:16031:16569 [1] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
28: nid005929:16032:16570 [2] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
28: nid005929:16032:16570 [2] NCCL INFO NET/OFI Using transport protocol SENDRECV
28: nid005929:16032:16570 [2] NCCL INFO NET/OFI Creating one domain per process
28: nid005929:16032:16570 [2] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
29: 
29: nid005932:167680:168169 [0] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
28: nid005929:16031:16569 [1] NCCL INFO Using network AWS Libfabric
29: nid005932:167680:168169 [0] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
29: nid005932:167680:168169 [0] NCCL INFO NET/OFI Using transport protocol SENDRECV
29: nid005932:167680:168169 [0] NCCL INFO NET/OFI Creating one domain per process
29: nid005932:167680:168169 [0] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
28: nid005929:16032:16570 [2] NCCL INFO NET/OFI Support for global registrations: false
28: nid005929:16032:16570 [2] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
29: nid005932:167680:168169 [0] NCCL INFO NET/OFI Support for global registrations: false
29: nid005932:167680:168169 [0] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
28: nid005929:16032:16570 [2] NCCL INFO Using network AWS Libfabric
29: nid005932:167680:168169 [0] NCCL INFO Using network AWS Libfabric
 0: [2025-06-27 21:02:53,965] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
 4: [INFO|configuration_utils.py:693] 2025-06-27 21:02:53,968 >> loading configuration file config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/config.json
 4: [INFO|configuration_utils.py:765] 2025-06-27 21:02:53,970 >> Model config Qwen2_5_VLConfig {
 4:   "architectures": [
 4:     "Qwen2_5_VLForConditionalGeneration"
 4:   ],
 4:   "attention_dropout": 0.0,
 4:   "bos_token_id": 151643,
 4:   "eos_token_id": 151645,
 4:   "hidden_act": "silu",
 4:   "hidden_size": 3584,
 4:   "image_token_id": 151655,
 4:   "initializer_range": 0.02,
 4:   "intermediate_size": 18944,
 4:   "max_position_embeddings": 128000,
 4:   "max_window_layers": 28,
 4:   "model_type": "qwen2_5_vl",
 4:   "num_attention_heads": 28,
 4:   "num_hidden_layers": 28,
 4:   "num_key_value_heads": 4,
 4:   "rms_norm_eps": 1e-06,
 4:   "rope_scaling": {
 4:     "mrope_section": [
 4:       16,
 4:       24,
 4:       24
 4:     ],
 4:     "rope_type": "default",
 4:     "type": "default"
 4:   },
 4:   "rope_theta": 1000000.0,
 4:   "sliding_window": 32768,
 4:   "tie_word_embeddings": false,
 4:   "torch_dtype": "bfloat16",
 4:   "transformers_version": "4.51.3",
 4:   "use_cache": true,
 4:   "use_sliding_window": false,
 4:   "video_token_id": 151656,
 4:   "vision_config": {
 4:     "depth": 32,
 4:     "fullatt_block_indexes": [
 4:       7,
 4:       15,
 4:       23,
 4:       31
 4:     ],
 4:     "hidden_act": "silu",
 4:     "hidden_size": 1280,
 4:     "in_channels": 3,
 4:     "in_chans": 3,
 4:     "intermediate_size": 3420,
 4:     "model_type": "qwen2_5_vl",
 4:     "num_heads": 16,
 4:     "out_hidden_size": 3584,
 4:     "patch_size": 14,
 4:     "spatial_merge_size": 2,
 4:     "spatial_patch_size": 14,
 4:     "temporal_patch_size": 2,
 4:     "tokens_per_second": 2,
 4:     "window_size": 112
 4:   },
 4:   "vision_end_token_id": 151653,
 4:   "vision_start_token_id": 151652,
 4:   "vision_token_id": 151654,
 4:   "vocab_size": 152064
 4: }
 4: 
 4: [INFO|2025-06-27 21:02:53] llamafactory.model.model_utils.kv_cache:143 >> KV cache is disabled during training.
19: [2025-06-27 21:02:53,971] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
28: [2025-06-27 21:02:53,972] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
 7: nid005585:122005:122496 [0] NCCL INFO DMA-BUF is available on GPU device 0
18: nid005911:38864:39357 [0] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
18: nid005911:38864:39357 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
18: nid005911:38864:39357 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
18: nid005911:38864:39357 [0] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
18: nid005911:38864:39357 [0] NCCL INFO NET/OFI Using Libfabric version 1.22
18: nid005911:38864:39357 [0] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
 4: [INFO|modeling_utils.py:1124] 2025-06-27 21:02:53,992 >> loading weights file model.safetensors from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/model.safetensors.index.json
 3: nid005580:71819:71819 [0] NCCL INFO cudaDriverVersion 12060
 3: nid005580:71819:71819 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
 3: nid005580:71819:71819 [0] NCCL INFO Bootstrap : Using hsn0:172.28.18.216<0>
 3: nid005580:71819:71819 [0] NCCL INFO NCCL version 2.22.3+cuda12.6
 4: [INFO|modeling_utils.py:3726] 2025-06-27 21:02:53,997 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model
 4: [2025-06-27 21:02:53,997] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
18: 
18: nid005911:38864:39357 [0] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
18: nid005911:38864:39357 [0] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
18: nid005911:38864:39357 [0] NCCL INFO NET/OFI Using transport protocol SENDRECV
18: nid005911:38864:39357 [0] NCCL INFO NET/OFI Creating one domain per process
18: nid005911:38864:39357 [0] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
 4: [INFO|configuration_utils.py:1142] 2025-06-27 21:02:54,003 >> Generate config GenerationConfig {
 4:   "bos_token_id": 151643,
 4:   "eos_token_id": 151645,
 4:   "use_cache": false
 4: }
 4: 
 4: [INFO|modeling_utils.py:2167] 2025-06-27 21:02:54,003 >> Instantiating Qwen2_5_VisionTransformerPretrainedModel model under default dtype torch.float32.
18: nid005911:38864:39357 [0] NCCL INFO NET/OFI Support for global registrations: false
18: nid005911:38864:39357 [0] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
18: nid005911:38864:39357 [0] NCCL INFO Using network AWS Libfabric
23: nid005917:276888:277422 [3] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
23: nid005917:276888:277422 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
23: nid005917:276888:277422 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
23: nid005917:276888:277422 [3] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
23: nid005917:276888:277422 [3] NCCL INFO NET/OFI Using Libfabric version 1.22
23: nid005917:276888:277422 [3] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
23: 
23: nid005917:276888:277422 [3] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
23: nid005917:276888:277422 [3] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
23: nid005917:276888:277422 [3] NCCL INFO NET/OFI Using transport protocol SENDRECV
23: nid005917:276888:277422 [3] NCCL INFO NET/OFI Creating one domain per process
23: nid005917:276888:277422 [3] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
23: nid005917:276888:277422 [3] NCCL INFO NET/OFI Support for global registrations: false
23: nid005917:276888:277422 [3] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
23: nid005917:276888:277422 [3] NCCL INFO Using network AWS Libfabric
 6: [INFO|2025-06-27 21:02:54] llamafactory.data.loader:143 >> Loaded tokenized dataset from /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/tokenizer.
 0: [2025-06-27 21:02:54,088] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
 0: [2025-06-27 21:02:54,093] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
 3: nid005580:71819:72290 [0] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
 3: nid005580:71819:72290 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
 3: nid005580:71819:72290 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
 3: nid005580:71819:72290 [0] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
 3: nid005580:71819:72290 [0] NCCL INFO NET/OFI Using Libfabric version 1.22
 3: nid005580:71819:72290 [0] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
 3: 
 3: nid005580:71819:72290 [0] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
 3: nid005580:71819:72290 [0] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
 3: nid005580:71819:72290 [0] NCCL INFO NET/OFI Using transport protocol SENDRECV
 3: nid005580:71819:72290 [0] NCCL INFO NET/OFI Creating one domain per process
 3: nid005580:71819:72290 [0] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
 3: nid005580:71819:72290 [0] NCCL INFO NET/OFI Support for global registrations: false
 3: nid005580:71819:72290 [0] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
 3: nid005580:71819:72290 [0] NCCL INFO Using network AWS Libfabric
22: [2025-06-27 21:02:54,137] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
 9: nid005588:35935:36428 [0] NCCL INFO DMA-BUF is available on GPU device 0
22: [2025-06-27 21:02:54,158] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
 9: nid005588:35938:35938 [3] NCCL INFO cudaDriverVersion 12060
 9: nid005588:35938:35938 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
 9: nid005588:35938:35938 [3] NCCL INFO Bootstrap : Using hsn0:172.28.18.240<0>
 9: nid005588:35938:35938 [3] NCCL INFO NCCL version 2.22.3+cuda12.6
 7: [2025-06-27 21:02:54,162] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
 9: nid005588:35936:36472 [1] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
 9: nid005588:35936:36472 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
 9: nid005588:35936:36472 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
 9: nid005588:35936:36472 [1] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
 9: nid005588:35936:36472 [1] NCCL INFO NET/OFI Using Libfabric version 1.22
 9: nid005588:35936:36472 [1] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
 9: nid005588:35937:36471 [2] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
 9: nid005588:35937:36471 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
 9: nid005588:35937:36471 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
 9: nid005588:35937:36471 [2] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
 9: nid005588:35937:36471 [2] NCCL INFO NET/OFI Using Libfabric version 1.22
 9: nid005588:35937:36471 [2] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
 9: 
 9: nid005588:35936:36472 [1] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
 9: 
 9: nid005588:35937:36471 [2] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
 9: nid005588:35936:36472 [1] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
 9: nid005588:35936:36472 [1] NCCL INFO NET/OFI Using transport protocol SENDRECV
 9: nid005588:35936:36472 [1] NCCL INFO NET/OFI Creating one domain per process
 9: nid005588:35936:36472 [1] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
 9: nid005588:35937:36471 [2] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
 9: nid005588:35937:36471 [2] NCCL INFO NET/OFI Using transport protocol SENDRECV
 9: nid005588:35937:36471 [2] NCCL INFO NET/OFI Creating one domain per process
 9: nid005588:35937:36471 [2] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
 9: nid005588:35936:36472 [1] NCCL INFO NET/OFI Support for global registrations: false
 9: nid005588:35936:36472 [1] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
 7: nid005585:122006:122006 [1] NCCL INFO cudaDriverVersion 12060
 7: nid005585:122006:122006 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
 7: [2025-06-27 21:02:54,182] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
 7: nid005585:122006:122006 [1] NCCL INFO Bootstrap : Using hsn0:172.28.18.236<0>
 7: nid005585:122006:122006 [1] NCCL INFO NCCL version 2.22.3+cuda12.6
 9: nid005588:35937:36471 [2] NCCL INFO NET/OFI Support for global registrations: false
 9: nid005588:35937:36471 [2] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
 9: nid005588:35936:36472 [1] NCCL INFO Using network AWS Libfabric
 9: nid005588:35937:36471 [2] NCCL INFO Using network AWS Libfabric
22: nid005915:274814:275290 [0] NCCL INFO DMA-BUF is available on GPU device 0
 6: [INFO|configuration_utils.py:693] 2025-06-27 21:02:54,189 >> loading configuration file config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/config.json
 6: [INFO|configuration_utils.py:765] 2025-06-27 21:02:54,191 >> Model config Qwen2_5_VLConfig {
 6:   "architectures": [
 6:     "Qwen2_5_VLForConditionalGeneration"
 6:   ],
 6:   "attention_dropout": 0.0,
 6:   "bos_token_id": 151643,
 6:   "eos_token_id": 151645,
 6:   "hidden_act": "silu",
 6:   "hidden_size": 3584,
 6:   "image_token_id": 151655,
 6:   "initializer_range": 0.02,
 6:   "intermediate_size": 18944,
 6:   "max_position_embeddings": 128000,
 6:   "max_window_layers": 28,
 6:   "model_type": "qwen2_5_vl",
 6:   "num_attention_heads": 28,
 6:   "num_hidden_layers": 28,
 6:   "num_key_value_heads": 4,
 6:   "rms_norm_eps": 1e-06,
 6:   "rope_scaling": {
 6:     "mrope_section": [
 6:       16,
 6:       24,
 6:       24
 6:     ],
 6:     "rope_type": "default",
 6:     "type": "default"
 6:   },
 6:   "rope_theta": 1000000.0,
 6:   "sliding_window": 32768,
 6:   "tie_word_embeddings": false,
 6:   "torch_dtype": "bfloat16",
 6:   "transformers_version": "4.51.3",
 6:   "use_cache": true,
 6:   "use_sliding_window": false,
 6:   "video_token_id": 151656,
 6:   "vision_config": {
 6:     "depth": 32,
 6:     "fullatt_block_indexes": [
 6:       7,
 6:       15,
 6:       23,
 6:       31
 6:     ],
 6:     "hidden_act": "silu",
 6:     "hidden_size": 1280,
 6:     "in_channels": 3,
 6:     "in_chans": 3,
 6:     "intermediate_size": 3420,
 6:     "model_type": "qwen2_5_vl",
 6:     "num_heads": 16,
 6:     "out_hidden_size": 3584,
 6:     "patch_size": 14,
 6:     "spatial_merge_size": 2,
 6:     "spatial_patch_size": 14,
 6:     "temporal_patch_size": 2,
 6:     "tokens_per_second": 2,
 6:     "window_size": 112
 6:   },
 6:   "vision_end_token_id": 151653,
 6:   "vision_start_token_id": 151652,
 6:   "vision_token_id": 151654,
 6:   "vocab_size": 152064
 6: }
 6: 
 6: [INFO|2025-06-27 21:02:54] llamafactory.model.model_utils.kv_cache:143 >> KV cache is disabled during training.
22: [2025-06-27 21:02:54,193] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
13: nid005595:197883:198429 [0] NCCL INFO DMA-BUF is available on GPU device 0
 4: nid005581:264523:264523 [0] NCCL INFO cudaDriverVersion 12060
 4: nid005581:264523:264523 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
 4: nid005581:264523:264523 [0] NCCL INFO Bootstrap : Using hsn0:172.28.18.220<0>
 4: nid005581:264523:264523 [0] NCCL INFO NCCL version 2.22.3+cuda12.6
 7: nid005585:122007:122007 [2] NCCL INFO cudaDriverVersion 12060
 7: nid005585:122007:122007 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
 7: nid005585:122007:122007 [2] NCCL INFO Bootstrap : Using hsn0:172.28.18.236<0>
 7: nid005585:122007:122007 [2] NCCL INFO NCCL version 2.22.3+cuda12.6
25: nid005919:107462:107959 [0] NCCL INFO DMA-BUF is available on GPU device 0
22: nid005915:274815:274815 [1] NCCL INFO cudaDriverVersion 12060
22: nid005915:274815:274815 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
22: nid005915:274815:274815 [1] NCCL INFO Bootstrap : Using hsn0:172.28.23.84<0>
22: nid005915:274817:274817 [3] NCCL INFO cudaDriverVersion 12060
22: nid005915:274815:274815 [1] NCCL INFO NCCL version 2.22.3+cuda12.6
22: nid005915:274817:274817 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
22: nid005915:274817:274817 [3] NCCL INFO Bootstrap : Using hsn0:172.28.23.84<0>
22: nid005915:274817:274817 [3] NCCL INFO NCCL version 2.22.3+cuda12.6
 6: [INFO|modeling_utils.py:1124] 2025-06-27 21:02:54,211 >> loading weights file model.safetensors from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/model.safetensors.index.json
13: nid005595:197885:198470 [2] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
13: nid005595:197884:198471 [1] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
13: nid005595:197884:198471 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
13: nid005595:197885:198470 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
13: nid005595:197884:198471 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
13: nid005595:197885:198470 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
13: nid005595:197884:198471 [1] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
13: nid005595:197885:198470 [2] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
13: nid005595:197884:198471 [1] NCCL INFO NET/OFI Using Libfabric version 1.22
13: nid005595:197885:198470 [2] NCCL INFO NET/OFI Using Libfabric version 1.22
13: nid005595:197885:198470 [2] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
13: nid005595:197884:198471 [1] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
22: nid005915:274816:274816 [2] NCCL INFO cudaDriverVersion 12060
22: nid005915:274816:274816 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
13: nid005595:197886:198472 [3] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
13: nid005595:197886:198472 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
13: nid005595:197886:198472 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
13: nid005595:197886:198472 [3] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
13: nid005595:197886:198472 [3] NCCL INFO NET/OFI Using Libfabric version 1.22
13: nid005595:197886:198472 [3] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
 6: [INFO|modeling_utils.py:3726] 2025-06-27 21:02:54,217 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model
 6: [2025-06-27 21:02:54,217] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
22: nid005915:274816:274816 [2] NCCL INFO Bootstrap : Using hsn0:172.28.23.84<0>
22: nid005915:274816:274816 [2] NCCL INFO NCCL version 2.22.3+cuda12.6
13: 
13: nid005595:197885:198470 [2] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
13: 
13: nid005595:197884:198471 [1] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
 6: [INFO|configuration_utils.py:1142] 2025-06-27 21:02:54,222 >> Generate config GenerationConfig {
 6:   "bos_token_id": 151643,
 6:   "eos_token_id": 151645,
 6:   "use_cache": false
 6: }
 6: 
 6: [INFO|modeling_utils.py:2167] 2025-06-27 21:02:54,222 >> Instantiating Qwen2_5_VisionTransformerPretrainedModel model under default dtype torch.float32.
25: nid005919:107465:108002 [3] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
25: nid005919:107465:108002 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
25: nid005919:107465:108002 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
25: nid005919:107465:108002 [3] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
25: nid005919:107465:108002 [3] NCCL INFO NET/OFI Using Libfabric version 1.22
25: nid005919:107465:108002 [3] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
25: nid005919:107463:108001 [1] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
25: nid005919:107463:108001 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
25: nid005919:107463:108001 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
25: nid005919:107463:108001 [1] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
25: nid005919:107463:108001 [1] NCCL INFO NET/OFI Using Libfabric version 1.22
25: nid005919:107463:108001 [1] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
13: 
13: nid005595:197886:198472 [3] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
25: 
25: nid005919:107465:108002 [3] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
25: 
25: nid005919:107463:108001 [1] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
13: nid005595:197885:198470 [2] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
13: nid005595:197885:198470 [2] NCCL INFO NET/OFI Using transport protocol SENDRECV
13: nid005595:197885:198470 [2] NCCL INFO NET/OFI Creating one domain per process
13: nid005595:197885:198470 [2] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
13: nid005595:197884:198471 [1] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
13: nid005595:197884:198471 [1] NCCL INFO NET/OFI Using transport protocol SENDRECV
13: nid005595:197884:198471 [1] NCCL INFO NET/OFI Creating one domain per process
25: nid005919:107465:108002 [3] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
25: nid005919:107465:108002 [3] NCCL INFO NET/OFI Using transport protocol SENDRECV
25: nid005919:107465:108002 [3] NCCL INFO NET/OFI Creating one domain per process
13: nid005595:197884:198471 [1] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
13: nid005595:197886:198472 [3] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
13: nid005595:197886:198472 [3] NCCL INFO NET/OFI Using transport protocol SENDRECV
13: nid005595:197886:198472 [3] NCCL INFO NET/OFI Creating one domain per process
25: nid005919:107465:108002 [3] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
25: nid005919:107464:108003 [2] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
25: nid005919:107464:108003 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
25: nid005919:107464:108003 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
25: nid005919:107464:108003 [2] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
25: nid005919:107464:108003 [2] NCCL INFO NET/OFI Using Libfabric version 1.22
25: nid005919:107464:108003 [2] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
13: nid005595:197886:198472 [3] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
25: nid005919:107463:108001 [1] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
25: nid005919:107463:108001 [1] NCCL INFO NET/OFI Using transport protocol SENDRECV
25: nid005919:107463:108001 [1] NCCL INFO NET/OFI Creating one domain per process
25: nid005919:107463:108001 [1] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
13: nid005595:197885:198470 [2] NCCL INFO NET/OFI Support for global registrations: false
13: nid005595:197885:198470 [2] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
25: nid005919:107465:108002 [3] NCCL INFO NET/OFI Support for global registrations: false
25: nid005919:107465:108002 [3] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
13: nid005595:197884:198471 [1] NCCL INFO NET/OFI Support for global registrations: false
13: nid005595:197884:198471 [1] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
13: nid005595:197886:198472 [3] NCCL INFO NET/OFI Support for global registrations: false
13: nid005595:197886:198472 [3] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
10: nid005590:110710:111197 [0] NCCL INFO DMA-BUF is available on GPU device 0
25: 
25: nid005919:107464:108003 [2] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
 1: nid005576:147557:148053 [0] NCCL INFO DMA-BUF is available on GPU device 0
25: nid005919:107463:108001 [1] NCCL INFO NET/OFI Support for global registrations: false
25: nid005919:107463:108001 [1] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
13: nid005595:197885:198470 [2] NCCL INFO Using network AWS Libfabric
25: nid005919:107465:108002 [3] NCCL INFO Using network AWS Libfabric
25: nid005919:107464:108003 [2] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
25: nid005919:107464:108003 [2] NCCL INFO NET/OFI Using transport protocol SENDRECV
25: nid005919:107464:108003 [2] NCCL INFO NET/OFI Creating one domain per process
25: nid005919:107464:108003 [2] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
13: nid005595:197886:198472 [3] NCCL INFO Using network AWS Libfabric
13: nid005595:197884:198471 [1] NCCL INFO Using network AWS Libfabric
25: nid005919:107463:108001 [1] NCCL INFO Using network AWS Libfabric
25: nid005919:107464:108003 [2] NCCL INFO NET/OFI Support for global registrations: false
25: nid005919:107464:108003 [2] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
25: nid005919:107464:108003 [2] NCCL INFO Using network AWS Libfabric
 1: nid005576:147558:147558 [1] NCCL INFO cudaDriverVersion 12060
 1: nid005576:147558:147558 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
10: nid005590:110712:110712 [2] NCCL INFO cudaDriverVersion 12060
 1: nid005576:147558:147558 [1] NCCL INFO Bootstrap : Using hsn0:172.28.18.200<0>
 1: nid005576:147558:147558 [1] NCCL INFO NCCL version 2.22.3+cuda12.6
10: nid005590:110712:110712 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
10: nid005590:110712:110712 [2] NCCL INFO Bootstrap : Using hsn0:172.28.18.248<0>
10: nid005590:110712:110712 [2] NCCL INFO NCCL version 2.22.3+cuda12.6
 7: nid005585:122006:122526 [1] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
 7: nid005585:122006:122526 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
 7: nid005585:122006:122526 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
 7: nid005585:122006:122526 [1] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
 7: nid005585:122006:122526 [1] NCCL INFO NET/OFI Using Libfabric version 1.22
 7: nid005585:122006:122526 [1] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
 7: 
 7: nid005585:122006:122526 [1] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
 7: nid005585:122006:122526 [1] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
 7: nid005585:122006:122526 [1] NCCL INFO NET/OFI Using transport protocol SENDRECV
 7: nid005585:122006:122526 [1] NCCL INFO NET/OFI Creating one domain per process
 7: nid005585:122006:122526 [1] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
 0: nid005574:69058:69552 [0] NCCL INFO DMA-BUF is available on GPU device 0
10: nid005590:110711:111241 [1] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
10: nid005590:110711:111241 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
10: nid005590:110711:111241 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
10: nid005590:110711:111241 [1] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
10: nid005590:110711:111241 [1] NCCL INFO NET/OFI Using Libfabric version 1.22
10: nid005590:110711:111241 [1] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
 7: nid005585:122006:122526 [1] NCCL INFO NET/OFI Support for global registrations: false
 7: nid005585:122006:122526 [1] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
10: nid005590:110713:111240 [3] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
10: nid005590:110713:111240 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
10: nid005590:110713:111240 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
10: nid005590:110713:111240 [3] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
10: nid005590:110713:111240 [3] NCCL INFO NET/OFI Using Libfabric version 1.22
10: nid005590:110713:111240 [3] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
 7: nid005585:122006:122526 [1] NCCL INFO Using network AWS Libfabric
10: 
10: nid005590:110711:111241 [1] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
10: nid005590:110711:111241 [1] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
10: nid005590:110711:111241 [1] NCCL INFO NET/OFI Using transport protocol SENDRECV
10: nid005590:110711:111241 [1] NCCL INFO NET/OFI Creating one domain per process
10: 
10: nid005590:110713:111240 [3] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
10: nid005590:110711:111241 [1] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
 7: nid005585:122007:122527 [2] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
 7: nid005585:122007:122527 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
 7: nid005585:122007:122527 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
 7: nid005585:122007:122527 [2] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
 7: nid005585:122007:122527 [2] NCCL INFO NET/OFI Using Libfabric version 1.22
 7: nid005585:122007:122527 [2] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
26: nid005920:67123:67613 [0] NCCL INFO DMA-BUF is available on GPU device 0
10: nid005590:110713:111240 [3] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
10: nid005590:110713:111240 [3] NCCL INFO NET/OFI Using transport protocol SENDRECV
10: nid005590:110713:111240 [3] NCCL INFO NET/OFI Creating one domain per process
10: nid005590:110713:111240 [3] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
22: nid005915:274817:275333 [3] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
22: nid005915:274817:275333 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
22: nid005915:274817:275333 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
22: nid005915:274817:275333 [3] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
22: nid005915:274817:275333 [3] NCCL INFO NET/OFI Using Libfabric version 1.22
22: nid005915:274817:275333 [3] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
 7: 
 7: nid005585:122007:122527 [2] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
10: nid005590:110711:111241 [1] NCCL INFO NET/OFI Support for global registrations: false
10: nid005590:110711:111241 [1] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
 0: nid005574:69060:69060 [2] NCCL INFO cudaDriverVersion 12060
 0: nid005574:69060:69060 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
22: nid005915:274815:275332 [1] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
22: nid005915:274815:275332 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
22: nid005915:274815:275332 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
22: nid005915:274815:275332 [1] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
22: nid005915:274815:275332 [1] NCCL INFO NET/OFI Using Libfabric version 1.22
22: nid005915:274815:275332 [1] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
 0: nid005574:69060:69060 [2] NCCL INFO Bootstrap : Using hsn0:172.28.18.192<0>
 0: nid005574:69060:69060 [2] NCCL INFO NCCL version 2.22.3+cuda12.6
 7: nid005585:122007:122527 [2] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
 7: nid005585:122007:122527 [2] NCCL INFO NET/OFI Using transport protocol SENDRECV
 7: nid005585:122007:122527 [2] NCCL INFO NET/OFI Creating one domain per process
10: nid005590:110713:111240 [3] NCCL INFO NET/OFI Support for global registrations: false
10: nid005590:110713:111240 [3] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
 7: nid005585:122007:122527 [2] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
10: nid005590:110711:111241 [1] NCCL INFO Using network AWS Libfabric
22: 
22: nid005915:274817:275333 [3] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
10: nid005590:110713:111240 [3] NCCL INFO Using network AWS Libfabric
 7: nid005585:122007:122527 [2] NCCL INFO NET/OFI Support for global registrations: false
 7: nid005585:122007:122527 [2] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
22: 
22: nid005915:274815:275332 [1] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
22: nid005915:274817:275333 [3] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
22: nid005915:274817:275333 [3] NCCL INFO NET/OFI Using transport protocol SENDRECV
22: nid005915:274817:275333 [3] NCCL INFO NET/OFI Creating one domain per process
22: nid005915:274817:275333 [3] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
 7: nid005585:122007:122527 [2] NCCL INFO Using network AWS Libfabric
22: nid005915:274815:275332 [1] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
22: nid005915:274815:275332 [1] NCCL INFO NET/OFI Using transport protocol SENDRECV
22: nid005915:274815:275332 [1] NCCL INFO NET/OFI Creating one domain per process
 0: nid005574:69059:69059 [1] NCCL INFO cudaDriverVersion 12060
22: nid005915:274815:275332 [1] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
 0: nid005574:69059:69059 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
 0: nid005574:69059:69059 [1] NCCL INFO Bootstrap : Using hsn0:172.28.18.192<0>
 0: nid005574:69059:69059 [1] NCCL INFO NCCL version 2.22.3+cuda12.6
 0: nid005574:69061:69061 [3] NCCL INFO cudaDriverVersion 12060
 0: nid005574:69061:69061 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
 0: nid005574:69061:69061 [3] NCCL INFO Bootstrap : Using hsn0:172.28.18.192<0>
 0: nid005574:69061:69061 [3] NCCL INFO NCCL version 2.22.3+cuda12.6
22: nid005915:274816:275334 [2] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
22: nid005915:274816:275334 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
22: nid005915:274816:275334 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
22: nid005915:274816:275334 [2] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
22: nid005915:274816:275334 [2] NCCL INFO NET/OFI Using Libfabric version 1.22
22: nid005915:274816:275334 [2] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
22: nid005915:274817:275333 [3] NCCL INFO NET/OFI Support for global registrations: false
22: nid005915:274817:275333 [3] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
22: nid005915:274815:275332 [1] NCCL INFO NET/OFI Support for global registrations: false
22: nid005915:274815:275332 [1] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
22: 
22: nid005915:274816:275334 [2] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
22: nid005915:274817:275333 [3] NCCL INFO Using network AWS Libfabric
22: nid005915:274816:275334 [2] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
22: nid005915:274816:275334 [2] NCCL INFO NET/OFI Using transport protocol SENDRECV
22: nid005915:274816:275334 [2] NCCL INFO NET/OFI Creating one domain per process
22: nid005915:274816:275334 [2] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
22: nid005915:274815:275332 [1] NCCL INFO Using network AWS Libfabric
22: nid005915:274816:275334 [2] NCCL INFO NET/OFI Support for global registrations: false
22: nid005915:274816:275334 [2] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
22: nid005915:274816:275334 [2] NCCL INFO Using network AWS Libfabric
20: nid005913:292681:293089 [0] NCCL INFO DMA-BUF is available on GPU device 0
12: nid005594:53085:53561 [0] NCCL INFO DMA-BUF is available on GPU device 0
 1: nid005576:147558:148070 [1] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
 1: nid005576:147558:148070 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
 1: nid005576:147558:148070 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
 1: nid005576:147558:148070 [1] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
 1: nid005576:147558:148070 [1] NCCL INFO NET/OFI Using Libfabric version 1.22
 1: nid005576:147558:148070 [1] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
 4: nid005581:264523:265016 [0] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
 4: nid005581:264523:265016 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
 4: nid005581:264523:265016 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
 4: nid005581:264523:265016 [0] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
 4: nid005581:264523:265016 [0] NCCL INFO NET/OFI Using Libfabric version 1.22
 4: nid005581:264523:265016 [0] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
 1: 
 1: nid005576:147558:148070 [1] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
 1: nid005576:147558:148070 [1] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
 1: nid005576:147558:148070 [1] NCCL INFO NET/OFI Using transport protocol SENDRECV
 1: nid005576:147558:148070 [1] NCCL INFO NET/OFI Creating one domain per process
 1: nid005576:147558:148070 [1] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
 4: 
 4: nid005581:264523:265016 [0] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
 1: nid005576:147558:148070 [1] NCCL INFO NET/OFI Support for global registrations: false
 1: nid005576:147558:148070 [1] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
 4: nid005581:264523:265016 [0] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
 4: nid005581:264523:265016 [0] NCCL INFO NET/OFI Using transport protocol SENDRECV
 4: nid005581:264523:265016 [0] NCCL INFO NET/OFI Creating one domain per process
12: nid005594:53088:53088 [3] NCCL INFO cudaDriverVersion 12060
12: nid005594:53088:53088 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
 4: nid005581:264523:265016 [0] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
12: nid005594:53088:53088 [3] NCCL INFO Bootstrap : Using hsn0:172.28.19.8<0>
12: nid005594:53088:53088 [3] NCCL INFO NCCL version 2.22.3+cuda12.6
12: nid005594:53086:53086 [1] NCCL INFO cudaDriverVersion 12060
12: nid005594:53086:53086 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
 1: nid005576:147558:148070 [1] NCCL INFO Using network AWS Libfabric
12: nid005594:53086:53086 [1] NCCL INFO Bootstrap : Using hsn0:172.28.19.8<0>
12: nid005594:53086:53086 [1] NCCL INFO NCCL version 2.22.3+cuda12.6
 4: nid005581:264523:265016 [0] NCCL INFO NET/OFI Support for global registrations: false
 4: nid005581:264523:265016 [0] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
31: nid005937:256589:256847 [0] NCCL INFO DMA-BUF is available on GPU device 0
 4: nid005581:264523:265016 [0] NCCL INFO Using network AWS Libfabric
 0: nid005574:69059:69601 [1] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
 0: nid005574:69059:69601 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
 0: nid005574:69059:69601 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
 0: nid005574:69059:69601 [1] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
 0: nid005574:69059:69601 [1] NCCL INFO NET/OFI Using Libfabric version 1.22
 0: nid005574:69059:69601 [1] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
 0: nid005574:69060:69600 [2] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
 0: nid005574:69060:69600 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
 0: nid005574:69060:69600 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
 0: nid005574:69060:69600 [2] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
 0: nid005574:69060:69600 [2] NCCL INFO NET/OFI Using Libfabric version 1.22
 0: nid005574:69060:69600 [2] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
 0: nid005574:69061:69602 [3] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
 0: nid005574:69061:69602 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
 0: nid005574:69061:69602 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
 0: nid005574:69061:69602 [3] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
 0: nid005574:69061:69602 [3] NCCL INFO NET/OFI Using Libfabric version 1.22
 0: nid005574:69061:69602 [3] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
 0: 
 0: nid005574:69060:69600 [2] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
 0: 
 0: nid005574:69059:69601 [1] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
 0: 
 0: nid005574:69061:69602 [3] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
12: [2025-06-27 21:02:54,361] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
 0: nid005574:69061:69602 [3] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
 0: nid005574:69061:69602 [3] NCCL INFO NET/OFI Using transport protocol SENDRECV
 0: nid005574:69061:69602 [3] NCCL INFO NET/OFI Creating one domain per process
 0: nid005574:69060:69600 [2] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
 0: nid005574:69060:69600 [2] NCCL INFO NET/OFI Using transport protocol SENDRECV
 0: nid005574:69060:69600 [2] NCCL INFO NET/OFI Creating one domain per process
 0: nid005574:69059:69601 [1] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
 0: nid005574:69059:69601 [1] NCCL INFO NET/OFI Using transport protocol SENDRECV
 0: nid005574:69059:69601 [1] NCCL INFO NET/OFI Creating one domain per process
 0: nid005574:69061:69602 [3] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
 0: nid005574:69059:69601 [1] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
 0: nid005574:69060:69600 [2] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
 0: nid005574:69061:69602 [3] NCCL INFO NET/OFI Support for global registrations: false
 0: nid005574:69061:69602 [3] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
 0: nid005574:69059:69601 [1] NCCL INFO NET/OFI Support for global registrations: false
 0: nid005574:69059:69601 [1] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
 0: nid005574:69060:69600 [2] NCCL INFO NET/OFI Support for global registrations: false
 0: nid005574:69060:69600 [2] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
 0: nid005574:69061:69602 [3] NCCL INFO Using network AWS Libfabric
 0: nid005574:69059:69601 [1] NCCL INFO Using network AWS Libfabric
 0: nid005574:69060:69600 [2] NCCL INFO Using network AWS Libfabric
11: [2025-06-27 21:02:54,377] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
12: nid005594:53087:53087 [2] NCCL INFO cudaDriverVersion 12060
12: nid005594:53087:53087 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
12: nid005594:53087:53087 [2] NCCL INFO Bootstrap : Using hsn0:172.28.19.8<0>
12: nid005594:53087:53087 [2] NCCL INFO NCCL version 2.22.3+cuda12.6
 8: nid005586:68926:69401 [0] NCCL INFO DMA-BUF is available on GPU device 0
16: nid005802:6297:6852 [0] NCCL INFO DMA-BUF is available on GPU device 0
14: nid005600:217720:218195 [0] NCCL INFO DMA-BUF is available on GPU device 0
11: nid005591:191603:192099 [0] NCCL INFO DMA-BUF is available on GPU device 0
12: nid005594:53088:53605 [3] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
12: nid005594:53088:53605 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
12: nid005594:53088:53605 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
12: nid005594:53088:53605 [3] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
12: nid005594:53088:53605 [3] NCCL INFO NET/OFI Using Libfabric version 1.22
12: nid005594:53088:53605 [3] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
19: nid005912:12435:12909 [0] NCCL INFO DMA-BUF is available on GPU device 0
12: nid005594:53086:53606 [1] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
12: nid005594:53086:53606 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
12: nid005594:53086:53606 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
12: nid005594:53086:53606 [1] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
12: nid005594:53086:53606 [1] NCCL INFO NET/OFI Using Libfabric version 1.22
12: nid005594:53086:53606 [1] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
12: 
12: nid005594:53088:53605 [3] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
 6: nid005584:28285:28285 [0] NCCL INFO cudaDriverVersion 12060
 6: nid005584:28285:28285 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
 6: nid005584:28285:28285 [0] NCCL INFO Bootstrap : Using hsn0:172.28.18.232<0>
 6: nid005584:28285:28285 [0] NCCL INFO NCCL version 2.22.3+cuda12.6
12: nid005594:53088:53605 [3] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
12: nid005594:53088:53605 [3] NCCL INFO NET/OFI Using transport protocol SENDRECV
12: nid005594:53088:53605 [3] NCCL INFO NET/OFI Creating one domain per process
12: 
12: nid005594:53086:53606 [1] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
12: nid005594:53088:53605 [3] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
11: nid005591:191606:191606 [3] NCCL INFO cudaDriverVersion 12060
11: nid005591:191606:191606 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
12: nid005594:53086:53606 [1] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
12: nid005594:53086:53606 [1] NCCL INFO NET/OFI Using transport protocol SENDRECV
12: nid005594:53086:53606 [1] NCCL INFO NET/OFI Creating one domain per process
12: nid005594:53086:53606 [1] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
11: nid005591:191606:191606 [3] NCCL INFO Bootstrap : Using hsn0:172.28.18.252<0>
11: nid005591:191606:191606 [3] NCCL INFO NCCL version 2.22.3+cuda12.6
12: nid005594:53088:53605 [3] NCCL INFO NET/OFI Support for global registrations: false
12: nid005594:53088:53605 [3] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
19: nid005912:12438:12438 [3] NCCL INFO cudaDriverVersion 12060
19: nid005912:12438:12438 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
19: nid005912:12436:12436 [1] NCCL INFO cudaDriverVersion 12060
19: nid005912:12436:12436 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
19: nid005912:12438:12438 [3] NCCL INFO Bootstrap : Using hsn0:172.28.23.72<0>
19: nid005912:12436:12436 [1] NCCL INFO Bootstrap : Using hsn0:172.28.23.72<0>
19: nid005912:12438:12438 [3] NCCL INFO NCCL version 2.22.3+cuda12.6
19: nid005912:12436:12436 [1] NCCL INFO NCCL version 2.22.3+cuda12.6
12: nid005594:53088:53605 [3] NCCL INFO Using network AWS Libfabric
12: nid005594:53086:53606 [1] NCCL INFO NET/OFI Support for global registrations: false
12: nid005594:53086:53606 [1] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
12: nid005594:53086:53606 [1] NCCL INFO Using network AWS Libfabric
11: nid005591:191606:192116 [3] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
11: nid005591:191606:192116 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
11: nid005591:191606:192116 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
11: nid005591:191606:192116 [3] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
11: nid005591:191606:192116 [3] NCCL INFO NET/OFI Using Libfabric version 1.22
11: nid005591:191606:192116 [3] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
19: nid005912:12438:12958 [3] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
19: nid005912:12438:12958 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
19: nid005912:12438:12958 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
19: nid005912:12438:12958 [3] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
19: nid005912:12438:12958 [3] NCCL INFO NET/OFI Using Libfabric version 1.22
19: nid005912:12438:12958 [3] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
19: nid005912:12436:12959 [1] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
19: nid005912:12436:12959 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
19: nid005912:12436:12959 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
19: nid005912:12436:12959 [1] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
19: nid005912:12436:12959 [1] NCCL INFO NET/OFI Using Libfabric version 1.22
19: nid005912:12436:12959 [1] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
11: 
11: nid005591:191606:192116 [3] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
11: nid005591:191606:192116 [3] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
11: nid005591:191606:192116 [3] NCCL INFO NET/OFI Using transport protocol SENDRECV
11: nid005591:191606:192116 [3] NCCL INFO NET/OFI Creating one domain per process
11: nid005591:191606:192116 [3] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
19: 
19: nid005912:12438:12958 [3] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
19: 
19: nid005912:12436:12959 [1] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
19: nid005912:12438:12958 [3] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
19: nid005912:12438:12958 [3] NCCL INFO NET/OFI Using transport protocol SENDRECV
19: nid005912:12438:12958 [3] NCCL INFO NET/OFI Creating one domain per process
19: nid005912:12438:12958 [3] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
19: nid005912:12436:12959 [1] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
19: nid005912:12436:12959 [1] NCCL INFO NET/OFI Using transport protocol SENDRECV
19: nid005912:12436:12959 [1] NCCL INFO NET/OFI Creating one domain per process
19: nid005912:12436:12959 [1] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
11: nid005591:191606:192116 [3] NCCL INFO NET/OFI Support for global registrations: false
11: nid005591:191606:192116 [3] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
11: nid005591:191606:192116 [3] NCCL INFO Using network AWS Libfabric
19: nid005912:12438:12958 [3] NCCL INFO NET/OFI Support for global registrations: false
19: nid005912:12438:12958 [3] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
19: nid005912:12436:12959 [1] NCCL INFO NET/OFI Support for global registrations: false
19: nid005912:12436:12959 [1] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
19: nid005912:12438:12958 [3] NCCL INFO Using network AWS Libfabric
19: nid005912:12436:12959 [1] NCCL INFO Using network AWS Libfabric
24: [INFO|processing_utils.py:884] 2025-06-27 21:02:54,511 >> Processor Qwen2_5_VLProcessor:
24: - image_processor: Qwen2VLImageProcessorFast {
24:   "crop_size": null,
24:   "data_format": "channels_first",
24:   "default_to_square": true,
24:   "device": null,
24:   "do_center_crop": null,
24:   "do_convert_rgb": true,
24:   "do_normalize": true,
24:   "do_rescale": true,
24:   "do_resize": true,
24:   "image_mean": [
24:     0.48145466,
24:     0.4578275,
24:     0.40821073
24:   ],
24:   "image_processor_type": "Qwen2VLImageProcessorFast",
24:   "image_std": [
24:     0.26862954,
24:     0.26130258,
24:     0.27577711
24:   ],
24:   "input_data_format": null,
24:   "max_pixels": 12845056,
24:   "merge_size": 2,
24:   "min_pixels": 3136,
24:   "patch_size": 14,
24:   "processor_class": "Qwen2_5_VLProcessor",
24:   "resample": 3,
24:   "rescale_factor": 0.00392156862745098,
24:   "return_tensors": null,
24:   "size": {
24:     "longest_edge": 12845056,
24:     "shortest_edge": 3136
24:   },
24:   "temporal_patch_size": 2
24: }
24: 
24: - tokenizer: Qwen2TokenizerFast(name_or_path='Qwen/Qwen2.5-VL-7B-Instruct', vocab_size=151643, model_max_length=131072, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
24: 	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
24: 	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
24: 	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
24: 	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
24: 	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
24: 	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
24: 	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
24: 	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
24: 	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
24: 	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
24: 	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
24: 	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
24: 	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
24: 	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
24: 	151657: AddedToken("<tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
24: 	151658: AddedToken("</tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
24: 	151659: AddedToken("<|fim_prefix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
24: 	151660: AddedToken("<|fim_middle|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
24: 	151661: AddedToken("<|fim_suffix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
24: 	151662: AddedToken("<|fim_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
24: 	151663: AddedToken("<|repo_name|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
24: 	151664: AddedToken("<|file_sep|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
24: }
24: )
24: 
24: {
24:   "processor_class": "Qwen2_5_VLProcessor"
24: }
24: 
18: nid005911:38864:39357 [0] NCCL INFO DMA-BUF is available on GPU device 0
 2: nid005577:17425:17981 [3] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
 2: nid005577:17425:17981 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
 2: nid005577:17425:17981 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
 2: nid005577:17425:17981 [3] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
 2: nid005577:17425:17981 [3] NCCL INFO NET/OFI Using Libfabric version 1.22
 2: nid005577:17425:17981 [3] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
 2: 
 2: nid005577:17425:17981 [3] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
 2: nid005577:17425:17981 [3] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
 2: nid005577:17425:17981 [3] NCCL INFO NET/OFI Using transport protocol SENDRECV
 2: nid005577:17425:17981 [3] NCCL INFO NET/OFI Creating one domain per process
 2: nid005577:17425:17981 [3] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
 6: nid005584:28285:28774 [0] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
 6: nid005584:28285:28774 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
 6: nid005584:28285:28774 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
 6: nid005584:28285:28774 [0] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
 6: nid005584:28285:28774 [0] NCCL INFO NET/OFI Using Libfabric version 1.22
 6: nid005584:28285:28774 [0] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
 2: nid005577:17425:17981 [3] NCCL INFO NET/OFI Support for global registrations: false
 2: nid005577:17425:17981 [3] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
 2: nid005577:17425:17981 [3] NCCL INFO Using network AWS Libfabric
 6: 
 6: nid005584:28285:28774 [0] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
 6: nid005584:28285:28774 [0] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
 6: nid005584:28285:28774 [0] NCCL INFO NET/OFI Using transport protocol SENDRECV
 6: nid005584:28285:28774 [0] NCCL INFO NET/OFI Creating one domain per process
 6: nid005584:28285:28774 [0] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
24: [WARNING|2025-06-27 21:02:54] llamafactory.data.loader:148 >> Loading dataset from disk will ignore other data arguments.
 6: nid005584:28285:28774 [0] NCCL INFO NET/OFI Support for global registrations: false
 6: nid005584:28285:28774 [0] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
 6: nid005584:28285:28774 [0] NCCL INFO Using network AWS Libfabric
29: nid005932:167680:168169 [0] NCCL INFO DMA-BUF is available on GPU device 0
 7: [2025-06-27 21:02:54,552] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
 3: [2025-06-27 21:02:54,580] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
 3: [2025-06-27 21:02:54,590] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
 3: nid005580:71819:72290 [0] NCCL INFO DMA-BUF is available on GPU device 0
 3: nid005580:71822:71822 [3] NCCL INFO cudaDriverVersion 12060
 3: nid005580:71822:71822 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
 3: nid005580:71822:71822 [3] NCCL INFO Bootstrap : Using hsn0:172.28.18.216<0>
 3: nid005580:71822:71822 [3] NCCL INFO NCCL version 2.22.3+cuda12.6
 3: nid005580:71820:71820 [1] NCCL INFO cudaDriverVersion 12060
 3: nid005580:71820:71820 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
 3: nid005580:71820:71820 [1] NCCL INFO Bootstrap : Using hsn0:172.28.18.216<0>
 3: nid005580:71820:71820 [1] NCCL INFO NCCL version 2.22.3+cuda12.6
21: nid005914:166784:167271 [0] NCCL INFO DMA-BUF is available on GPU device 0
 1: [2025-06-27 21:02:54,673] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
 1: [2025-06-27 21:02:54,674] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
21: nid005914:166786:167270 [2] NCCL INFO DMA-BUF is available on GPU device 2
21: nid005914:166787:166787 [3] NCCL INFO cudaDriverVersion 12060
21: nid005914:166787:166787 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
21: nid005914:166787:166787 [3] NCCL INFO Bootstrap : Using hsn0:172.28.23.80<0>
21: nid005914:166787:166787 [3] NCCL INFO NCCL version 2.22.3+cuda12.6
21: nid005914:166785:166785 [1] NCCL INFO cudaDriverVersion 12060
21: nid005914:166785:166785 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
21: nid005914:166785:166785 [1] NCCL INFO Bootstrap : Using hsn0:172.28.23.80<0>
21: nid005914:166785:166785 [1] NCCL INFO NCCL version 2.22.3+cuda12.6
 3: [2025-06-27 21:02:54,714] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
 2: nid005577:17422:17953 [0] NCCL INFO DMA-BUF is available on GPU device 0
 2: nid005577:17423:17952 [1] NCCL INFO DMA-BUF is available on GPU device 1
 3: nid005580:71822:72337 [3] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
 3: nid005580:71822:72337 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
 3: nid005580:71822:72337 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
 3: nid005580:71822:72337 [3] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
 3: nid005580:71822:72337 [3] NCCL INFO NET/OFI Using Libfabric version 1.22
 3: nid005580:71822:72337 [3] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
 3: nid005580:71820:72338 [1] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
 3: nid005580:71820:72338 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
 3: nid005580:71820:72338 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
 3: nid005580:71820:72338 [1] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
 3: nid005580:71820:72338 [1] NCCL INFO NET/OFI Using Libfabric version 1.22
 3: nid005580:71820:72338 [1] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
 3: 
 3: nid005580:71822:72337 [3] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
 3: 
 3: nid005580:71820:72338 [1] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
 3: nid005580:71821:71821 [2] NCCL INFO cudaDriverVersion 12060
 3: nid005580:71821:71821 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
 3: nid005580:71821:71821 [2] NCCL INFO Bootstrap : Using hsn0:172.28.18.216<0>
 3: nid005580:71821:71821 [2] NCCL INFO NCCL version 2.22.3+cuda12.6
 3: nid005580:71822:72337 [3] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
 3: nid005580:71822:72337 [3] NCCL INFO NET/OFI Using transport protocol SENDRECV
 3: nid005580:71822:72337 [3] NCCL INFO NET/OFI Creating one domain per process
 3: nid005580:71822:72337 [3] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
 3: nid005580:71820:72338 [1] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
 3: nid005580:71820:72338 [1] NCCL INFO NET/OFI Using transport protocol SENDRECV
 3: nid005580:71820:72338 [1] NCCL INFO NET/OFI Creating one domain per process
 3: nid005580:71820:72338 [1] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
 3: nid005580:71822:72337 [3] NCCL INFO NET/OFI Support for global registrations: false
 3: nid005580:71822:72337 [3] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
 3: nid005580:71820:72338 [1] NCCL INFO NET/OFI Support for global registrations: false
 3: nid005580:71820:72338 [1] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
 3: nid005580:71822:72337 [3] NCCL INFO Using network AWS Libfabric
 3: nid005580:71820:72338 [1] NCCL INFO Using network AWS Libfabric
21: nid005914:166785:167301 [1] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
21: nid005914:166785:167301 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
21: nid005914:166785:167301 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
21: nid005914:166785:167301 [1] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
21: nid005914:166785:167301 [1] NCCL INFO NET/OFI Using Libfabric version 1.22
21: nid005914:166785:167301 [1] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
21: nid005914:166787:167300 [3] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
21: nid005914:166787:167300 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
21: nid005914:166787:167300 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
21: nid005914:166787:167300 [3] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
21: nid005914:166787:167300 [3] NCCL INFO NET/OFI Using Libfabric version 1.22
21: nid005914:166787:167300 [3] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
21: 
21: nid005914:166785:167301 [1] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
21: nid005914:166785:167301 [1] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
21: nid005914:166785:167301 [1] NCCL INFO NET/OFI Using transport protocol SENDRECV
21: nid005914:166785:167301 [1] NCCL INFO NET/OFI Creating one domain per process
21: nid005914:166785:167301 [1] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
21: 
21: nid005914:166787:167300 [3] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
21: nid005914:166787:167300 [3] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
21: nid005914:166787:167300 [3] NCCL INFO NET/OFI Using transport protocol SENDRECV
21: nid005914:166787:167300 [3] NCCL INFO NET/OFI Creating one domain per process
21: nid005914:166787:167300 [3] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
21: nid005914:166785:167301 [1] NCCL INFO NET/OFI Support for global registrations: false
21: nid005914:166785:167301 [1] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
21: nid005914:166787:167300 [3] NCCL INFO NET/OFI Support for global registrations: false
21: nid005914:166787:167300 [3] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
21: nid005914:166785:167301 [1] NCCL INFO Using network AWS Libfabric
21: nid005914:166787:167300 [3] NCCL INFO Using network AWS Libfabric
 1: nid005576:147558:148070 [1] NCCL INFO DMA-BUF is available on GPU device 1
 4: nid005581:264523:265016 [0] NCCL INFO DMA-BUF is available on GPU device 0
11: [2025-06-27 21:02:54,842] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
26: [2025-06-27 21:02:54,847] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
 1: nid005576:147560:147560 [3] NCCL INFO cudaDriverVersion 12060
 1: nid005576:147560:147560 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
 1: nid005576:147559:147559 [2] NCCL INFO cudaDriverVersion 12060
 1: nid005576:147559:147559 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
 1: nid005576:147560:147560 [3] NCCL INFO Bootstrap : Using hsn0:172.28.18.200<0>
 1: nid005576:147559:147559 [2] NCCL INFO Bootstrap : Using hsn0:172.28.18.200<0>
 1: nid005576:147560:147560 [3] NCCL INFO NCCL version 2.22.3+cuda12.6
 1: nid005576:147559:147559 [2] NCCL INFO NCCL version 2.22.3+cuda12.6
19: [2025-06-27 21:02:54,853] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
16: [2025-06-27 21:02:54,855] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
28: nid005929:16031:16569 [1] NCCL INFO DMA-BUF is available on GPU device 1
26: [2025-06-27 21:02:54,861] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
26: nid005920:67124:67124 [1] NCCL INFO cudaDriverVersion 12060
26: nid005920:67124:67124 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
26: nid005920:67124:67124 [1] NCCL INFO Bootstrap : Using hsn0:172.28.23.104<0>
26: nid005920:67124:67124 [1] NCCL INFO NCCL version 2.22.3+cuda12.6
26: [2025-06-27 21:02:54,874] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
16: nid005802:6298:6298 [1] NCCL INFO cudaDriverVersion 12060
16: nid005802:6298:6298 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
16: nid005802:6298:6298 [1] NCCL INFO Bootstrap : Using hsn0:172.28.21.208<0>
16: nid005802:6298:6298 [1] NCCL INFO NCCL version 2.22.3+cuda12.6
27: nid005922:80742:81229 [1] NCCL INFO DMA-BUF is available on GPU device 1
26: nid005920:67126:67126 [3] NCCL INFO cudaDriverVersion 12060
26: nid005920:67126:67126 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
26: nid005920:67126:67126 [3] NCCL INFO Bootstrap : Using hsn0:172.28.23.104<0>
26: nid005920:67126:67126 [3] NCCL INFO NCCL version 2.22.3+cuda12.6
16: [2025-06-27 21:02:54,890] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
26: nid005920:67125:67125 [2] NCCL INFO cudaDriverVersion 12060
26: nid005920:67125:67125 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
16: [2025-06-27 21:02:54,895] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
26: nid005920:67125:67125 [2] NCCL INFO Bootstrap : Using hsn0:172.28.23.104<0>
26: nid005920:67125:67125 [2] NCCL INFO NCCL version 2.22.3+cuda12.6
24: [INFO|2025-06-27 21:02:54] llamafactory.data.loader:143 >> Loaded tokenized dataset from /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/tokenizer.
 1: nid005576:147560:148100 [3] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
 1: nid005576:147560:148100 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
 1: nid005576:147560:148100 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
 1: nid005576:147560:148100 [3] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
 1: nid005576:147560:148100 [3] NCCL INFO NET/OFI Using Libfabric version 1.22
 1: nid005576:147560:148100 [3] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
 1: nid005576:147559:148101 [2] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
 1: nid005576:147559:148101 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
 1: nid005576:147559:148101 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
 1: nid005576:147559:148101 [2] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
 1: nid005576:147559:148101 [2] NCCL INFO NET/OFI Using Libfabric version 1.22
 1: nid005576:147559:148101 [2] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
27: nid005922:80741:81228 [0] NCCL INFO DMA-BUF is available on GPU device 0
16: nid005802:6299:6299 [2] NCCL INFO cudaDriverVersion 12060
16: nid005802:6299:6299 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
16: nid005802:6299:6299 [2] NCCL INFO Bootstrap : Using hsn0:172.28.21.208<0>
16: nid005802:6299:6299 [2] NCCL INFO NCCL version 2.22.3+cuda12.6
 1: 
 1: nid005576:147560:148100 [3] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
 1: 
 1: nid005576:147559:148101 [2] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
 1: nid005576:147560:148100 [3] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
 1: nid005576:147560:148100 [3] NCCL INFO NET/OFI Using transport protocol SENDRECV
 1: nid005576:147560:148100 [3] NCCL INFO NET/OFI Creating one domain per process
 1: nid005576:147559:148101 [2] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
 1: nid005576:147559:148101 [2] NCCL INFO NET/OFI Using transport protocol SENDRECV
 1: nid005576:147559:148101 [2] NCCL INFO NET/OFI Creating one domain per process
 1: nid005576:147560:148100 [3] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
 1: nid005576:147559:148101 [2] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
16: nid005802:6300:6300 [3] NCCL INFO cudaDriverVersion 12060
16: nid005802:6300:6300 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
16: nid005802:6300:6300 [3] NCCL INFO Bootstrap : Using hsn0:172.28.21.208<0>
16: nid005802:6300:6300 [3] NCCL INFO NCCL version 2.22.3+cuda12.6
 1: nid005576:147560:148100 [3] NCCL INFO NET/OFI Support for global registrations: false
 1: nid005576:147560:148100 [3] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
 1: nid005576:147559:148101 [2] NCCL INFO NET/OFI Support for global registrations: false
 1: nid005576:147559:148101 [2] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
 1: nid005576:147560:148100 [3] NCCL INFO Using network AWS Libfabric
 1: nid005576:147559:148101 [2] NCCL INFO Using network AWS Libfabric
26: nid005920:67124:67660 [1] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
26: nid005920:67124:67660 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
27: nid005922:80744:81259 [3] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
27: nid005922:80744:81259 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
27: nid005922:80744:81259 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
26: nid005920:67124:67660 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
26: nid005920:67124:67660 [1] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
26: nid005920:67124:67660 [1] NCCL INFO NET/OFI Using Libfabric version 1.22
27: nid005922:80744:81259 [3] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
26: nid005920:67124:67660 [1] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
27: nid005922:80744:81259 [3] NCCL INFO NET/OFI Using Libfabric version 1.22
27: nid005922:80744:81259 [3] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
27: nid005922:80743:81258 [2] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
27: nid005922:80743:81258 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
27: nid005922:80743:81258 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
27: nid005922:80743:81258 [2] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
27: nid005922:80743:81258 [2] NCCL INFO NET/OFI Using Libfabric version 1.22
27: nid005922:80743:81258 [2] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
26: 
26: nid005920:67124:67660 [1] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
26: nid005920:67124:67660 [1] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
26: nid005920:67124:67660 [1] NCCL INFO NET/OFI Using transport protocol SENDRECV
26: nid005920:67124:67660 [1] NCCL INFO NET/OFI Creating one domain per process
26: nid005920:67124:67660 [1] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
27: 
27: nid005922:80744:81259 [3] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
27: 
27: nid005922:80743:81258 [2] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
16: nid005802:6298:6897 [1] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
16: nid005802:6298:6897 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
16: nid005802:6298:6897 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
16: nid005802:6298:6897 [1] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
16: nid005802:6298:6897 [1] NCCL INFO NET/OFI Using Libfabric version 1.22
16: nid005802:6298:6897 [1] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
26: nid005920:67124:67660 [1] NCCL INFO NET/OFI Support for global registrations: false
26: nid005920:67124:67660 [1] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
26: nid005920:67124:67660 [1] NCCL INFO Using network AWS Libfabric
27: nid005922:80743:81258 [2] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
27: nid005922:80743:81258 [2] NCCL INFO NET/OFI Using transport protocol SENDRECV
27: nid005922:80743:81258 [2] NCCL INFO NET/OFI Creating one domain per process
16: 
16: nid005802:6298:6897 [1] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
27: nid005922:80744:81259 [3] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
27: nid005922:80744:81259 [3] NCCL INFO NET/OFI Using transport protocol SENDRECV
27: nid005922:80744:81259 [3] NCCL INFO NET/OFI Creating one domain per process
27: nid005922:80743:81258 [2] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
27: nid005922:80744:81259 [3] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
16: nid005802:6298:6897 [1] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
16: nid005802:6298:6897 [1] NCCL INFO NET/OFI Using transport protocol SENDRECV
16: nid005802:6298:6897 [1] NCCL INFO NET/OFI Creating one domain per process
26: nid005920:67126:67661 [3] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
26: nid005920:67126:67661 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
26: nid005920:67126:67661 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
26: nid005920:67126:67661 [3] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
26: nid005920:67126:67661 [3] NCCL INFO NET/OFI Using Libfabric version 1.22
26: nid005920:67126:67661 [3] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
16: nid005802:6298:6897 [1] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
27: nid005922:80743:81258 [2] NCCL INFO NET/OFI Support for global registrations: false
27: nid005922:80743:81258 [2] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
27: nid005922:80744:81259 [3] NCCL INFO NET/OFI Support for global registrations: false
27: nid005922:80744:81259 [3] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
16: nid005802:6298:6897 [1] NCCL INFO NET/OFI Support for global registrations: false
16: nid005802:6298:6897 [1] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
26: 
26: nid005920:67126:67661 [3] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
27: nid005922:80743:81258 [2] NCCL INFO Using network AWS Libfabric
27: nid005922:80744:81259 [3] NCCL INFO Using network AWS Libfabric
26: nid005920:67126:67661 [3] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
26: nid005920:67126:67661 [3] NCCL INFO NET/OFI Using transport protocol SENDRECV
26: nid005920:67126:67661 [3] NCCL INFO NET/OFI Creating one domain per process
26: nid005920:67126:67661 [3] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
16: nid005802:6298:6897 [1] NCCL INFO Using network AWS Libfabric
26: nid005920:67126:67661 [3] NCCL INFO NET/OFI Support for global registrations: false
26: nid005920:67126:67661 [3] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
26: nid005920:67126:67661 [3] NCCL INFO Using network AWS Libfabric
28: nid005929:16032:16570 [2] NCCL INFO DMA-BUF is available on GPU device 2
11: [2025-06-27 21:02:54,972] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
28: nid005929:16033:16033 [3] NCCL INFO cudaDriverVersion 12060
28: nid005929:16033:16033 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
28: nid005929:16033:16033 [3] NCCL INFO Bootstrap : Using hsn0:172.28.23.132<0>
28: nid005929:16033:16033 [3] NCCL INFO NCCL version 2.22.3+cuda12.6
14: [2025-06-27 21:02:55,000] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
11: nid005591:191606:192116 [3] NCCL INFO DMA-BUF is available on GPU device 3
14: nid005600:217722:217722 [2] NCCL INFO cudaDriverVersion 12060
14: nid005600:217722:217722 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
14: nid005600:217722:217722 [2] NCCL INFO Bootstrap : Using hsn0:172.28.50.5<0>
14: nid005600:217722:217722 [2] NCCL INFO NCCL version 2.22.3+cuda12.6
11: nid005591:191605:191605 [2] NCCL INFO cudaDriverVersion 12060
11: nid005591:191605:191605 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
11: nid005591:191605:191605 [2] NCCL INFO Bootstrap : Using hsn0:172.28.18.252<0>
11: nid005591:191605:191605 [2] NCCL INFO NCCL version 2.22.3+cuda12.6
11: nid005591:191604:191604 [1] NCCL INFO cudaDriverVersion 12060
11: nid005591:191604:191604 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
11: nid005591:191604:191604 [1] NCCL INFO Bootstrap : Using hsn0:172.28.18.252<0>
11: nid005591:191604:191604 [1] NCCL INFO NCCL version 2.22.3+cuda12.6
24: [INFO|configuration_utils.py:693] 2025-06-27 21:02:55,033 >> loading configuration file config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/config.json
24: [INFO|configuration_utils.py:765] 2025-06-27 21:02:55,035 >> Model config Qwen2_5_VLConfig {
24:   "architectures": [
24:     "Qwen2_5_VLForConditionalGeneration"
24:   ],
24:   "attention_dropout": 0.0,
24:   "bos_token_id": 151643,
24:   "eos_token_id": 151645,
24:   "hidden_act": "silu",
24:   "hidden_size": 3584,
24:   "image_token_id": 151655,
24:   "initializer_range": 0.02,
24:   "intermediate_size": 18944,
24:   "max_position_embeddings": 128000,
24:   "max_window_layers": 28,
24:   "model_type": "qwen2_5_vl",
24:   "num_attention_heads": 28,
24:   "num_hidden_layers": 28,
24:   "num_key_value_heads": 4,
24:   "rms_norm_eps": 1e-06,
24:   "rope_scaling": {
24:     "mrope_section": [
24:       16,
24:       24,
24:       24
24:     ],
24:     "rope_type": "default",
24:     "type": "default"
24:   },
24:   "rope_theta": 1000000.0,
24:   "sliding_window": 32768,
24:   "tie_word_embeddings": false,
24:   "torch_dtype": "bfloat16",
24:   "transformers_version": "4.51.3",
24:   "use_cache": true,
24:   "use_sliding_window": false,
24:   "video_token_id": 151656,
24:   "vision_config": {
24:     "depth": 32,
24:     "fullatt_block_indexes": [
24:       7,
24:       15,
24:       23,
24:       31
24:     ],
24:     "hidden_act": "silu",
24:     "hidden_size": 1280,
24:     "in_channels": 3,
24:     "in_chans": 3,
24:     "intermediate_size": 3420,
24:     "model_type": "qwen2_5_vl",
24:     "num_heads": 16,
24:     "out_hidden_size": 3584,
24:     "patch_size": 14,
24:     "spatial_merge_size": 2,
24:     "spatial_patch_size": 14,
24:     "temporal_patch_size": 2,
24:     "tokens_per_second": 2,
24:     "window_size": 112
24:   },
24:   "vision_end_token_id": 151653,
24:   "vision_start_token_id": 151652,
24:   "vision_token_id": 151654,
24:   "vocab_size": 152064
24: }
24: 
24: [INFO|2025-06-27 21:02:55] llamafactory.model.model_utils.kv_cache:143 >> KV cache is disabled during training.
 8: [2025-06-27 21:02:55,037] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
 8: [2025-06-27 21:02:55,037] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
28: nid005929:16033:16573 [3] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
28: nid005929:16033:16573 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
28: nid005929:16033:16573 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
28: nid005929:16033:16573 [3] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
28: nid005929:16033:16573 [3] NCCL INFO NET/OFI Using Libfabric version 1.22
28: nid005929:16033:16573 [3] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
14: [2025-06-27 21:02:55,045] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
28: 
28: nid005929:16033:16573 [3] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
28: nid005929:16033:16573 [3] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
28: nid005929:16033:16573 [3] NCCL INFO NET/OFI Using transport protocol SENDRECV
28: nid005929:16033:16573 [3] NCCL INFO NET/OFI Creating one domain per process
28: nid005929:16033:16573 [3] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
 6: nid005584:28285:28774 [0] NCCL INFO DMA-BUF is available on GPU device 0
31: [2025-06-27 21:02:55,054] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
28: nid005929:16033:16573 [3] NCCL INFO NET/OFI Support for global registrations: false
28: nid005929:16033:16573 [3] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
31: [2025-06-27 21:02:55,054] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
28: nid005929:16033:16573 [3] NCCL INFO Using network AWS Libfabric
24: [INFO|modeling_utils.py:1124] 2025-06-27 21:02:55,058 >> loading weights file model.safetensors from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/model.safetensors.index.json
 8: nid005586:68928:68928 [2] NCCL INFO cudaDriverVersion 12060
 8: nid005586:68928:68928 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
 8: nid005586:68927:68927 [1] NCCL INFO cudaDriverVersion 12060
 8: nid005586:68927:68927 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
 8: nid005586:68928:68928 [2] NCCL INFO Bootstrap : Using hsn0:172.28.48.231<0>
 8: nid005586:68927:68927 [1] NCCL INFO Bootstrap : Using hsn0:172.28.48.231<0>
 8: nid005586:68927:68927 [1] NCCL INFO NCCL version 2.22.3+cuda12.6
 8: nid005586:68928:68928 [2] NCCL INFO NCCL version 2.22.3+cuda12.6
14: nid005600:217721:217721 [1] NCCL INFO cudaDriverVersion 12060
14: nid005600:217721:217721 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
14: nid005600:217721:217721 [1] NCCL INFO Bootstrap : Using hsn0:172.28.50.5<0>
14: nid005600:217721:217721 [1] NCCL INFO NCCL version 2.22.3+cuda12.6
24: [INFO|modeling_utils.py:3726] 2025-06-27 21:02:55,075 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model
24: [2025-06-27 21:02:55,075] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
31: nid005937:256592:256592 [3] NCCL INFO cudaDriverVersion 12060
31: nid005937:256592:256592 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
31: nid005937:256591:256591 [2] NCCL INFO cudaDriverVersion 12060
31: nid005937:256591:256591 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
31: nid005937:256591:256591 [2] NCCL INFO Bootstrap : Using hsn0:172.28.49.135<0>
31: nid005937:256592:256592 [3] NCCL INFO Bootstrap : Using hsn0:172.28.49.135<0>
31: nid005937:256591:256591 [2] NCCL INFO NCCL version 2.22.3+cuda12.6
31: nid005937:256592:256592 [3] NCCL INFO NCCL version 2.22.3+cuda12.6
24: [INFO|configuration_utils.py:1142] 2025-06-27 21:02:55,081 >> Generate config GenerationConfig {
24:   "bos_token_id": 151643,
24:   "eos_token_id": 151645,
24:   "use_cache": false
24: }
24: 
24: [INFO|modeling_utils.py:2167] 2025-06-27 21:02:55,081 >> Instantiating Qwen2_5_VisionTransformerPretrainedModel model under default dtype torch.float32.
11: nid005591:191605:192144 [2] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
11: nid005591:191605:192144 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
11: nid005591:191605:192144 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
11: nid005591:191605:192144 [2] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
11: nid005591:191605:192144 [2] NCCL INFO NET/OFI Using Libfabric version 1.22
11: nid005591:191605:192144 [2] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
14: nid005600:217722:218227 [2] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
14: nid005600:217722:218227 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
14: nid005600:217722:218227 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
14: nid005600:217722:218227 [2] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
14: nid005600:217722:218227 [2] NCCL INFO NET/OFI Using Libfabric version 1.22
14: nid005600:217722:218227 [2] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
11: nid005591:191604:192145 [1] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
11: nid005591:191604:192145 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
11: nid005591:191604:192145 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
11: nid005591:191604:192145 [1] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
11: nid005591:191604:192145 [1] NCCL INFO NET/OFI Using Libfabric version 1.22
11: nid005591:191604:192145 [1] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
11: 
11: nid005591:191605:192144 [2] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
11: nid005591:191605:192144 [2] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
11: nid005591:191605:192144 [2] NCCL INFO NET/OFI Using transport protocol SENDRECV
11: nid005591:191605:192144 [2] NCCL INFO NET/OFI Creating one domain per process
11: nid005591:191605:192144 [2] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
20: [2025-06-27 21:02:55,096] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
14: 
14: nid005600:217722:218227 [2] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
11: 
11: nid005591:191604:192145 [1] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
31: [2025-06-27 21:02:55,098] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
14: nid005600:217722:218227 [2] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
14: nid005600:217722:218227 [2] NCCL INFO NET/OFI Using transport protocol SENDRECV
14: nid005600:217722:218227 [2] NCCL INFO NET/OFI Creating one domain per process
11: nid005591:191604:192145 [1] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
11: nid005591:191604:192145 [1] NCCL INFO NET/OFI Using transport protocol SENDRECV
11: nid005591:191604:192145 [1] NCCL INFO NET/OFI Creating one domain per process
14: nid005600:217722:218227 [2] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
11: nid005591:191604:192145 [1] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
20: [2025-06-27 21:02:55,099] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
11: nid005591:191605:192144 [2] NCCL INFO NET/OFI Support for global registrations: false
11: nid005591:191605:192144 [2] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
11: nid005591:191605:192144 [2] NCCL INFO Using network AWS Libfabric
11: nid005591:191604:192145 [1] NCCL INFO NET/OFI Support for global registrations: false
11: nid005591:191604:192145 [1] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
14: nid005600:217722:218227 [2] NCCL INFO NET/OFI Support for global registrations: false
14: nid005600:217722:218227 [2] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
11: nid005591:191604:192145 [1] NCCL INFO Using network AWS Libfabric
14: nid005600:217722:218227 [2] NCCL INFO Using network AWS Libfabric
20: nid005913:292684:292684 [3] NCCL INFO cudaDriverVersion 12060
20: nid005913:292684:292684 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
20: nid005913:292684:292684 [3] NCCL INFO Bootstrap : Using hsn0:172.28.23.76<0>
20: nid005913:292684:292684 [3] NCCL INFO NCCL version 2.22.3+cuda12.6
31: nid005937:256590:256590 [1] NCCL INFO cudaDriverVersion 12060
31: nid005937:256590:256590 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
31: nid005937:256590:256590 [1] NCCL INFO Bootstrap : Using hsn0:172.28.49.135<0>
31: nid005937:256590:256590 [1] NCCL INFO NCCL version 2.22.3+cuda12.6
20: nid005913:292682:292682 [1] NCCL INFO cudaDriverVersion 12060
20: nid005913:292682:292682 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
20: nid005913:292682:292682 [1] NCCL INFO Bootstrap : Using hsn0:172.28.23.76<0>
20: nid005913:292682:292682 [1] NCCL INFO NCCL version 2.22.3+cuda12.6
 8: nid005586:68928:69450 [2] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
 8: nid005586:68927:69451 [1] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
 8: nid005586:68927:69451 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
 8: nid005586:68928:69450 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
 8: nid005586:68927:69451 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
 8: nid005586:68928:69450 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
 8: nid005586:68927:69451 [1] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
 8: nid005586:68928:69450 [2] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
 8: nid005586:68927:69451 [1] NCCL INFO NET/OFI Using Libfabric version 1.22
 8: nid005586:68928:69450 [2] NCCL INFO NET/OFI Using Libfabric version 1.22
 8: nid005586:68928:69450 [2] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
 8: nid005586:68927:69451 [1] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
 8: 
 8: nid005586:68927:69451 [1] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
 8: 
 8: nid005586:68928:69450 [2] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
 8: nid005586:68927:69451 [1] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
 8: nid005586:68927:69451 [1] NCCL INFO NET/OFI Using transport protocol SENDRECV
 8: nid005586:68927:69451 [1] NCCL INFO NET/OFI Creating one domain per process
 8: nid005586:68928:69450 [2] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
 8: nid005586:68928:69450 [2] NCCL INFO NET/OFI Using transport protocol SENDRECV
 8: nid005586:68928:69450 [2] NCCL INFO NET/OFI Creating one domain per process
 8: nid005586:68927:69451 [1] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
 8: nid005586:68928:69450 [2] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
 8: nid005586:68927:69451 [1] NCCL INFO NET/OFI Support for global registrations: false
 8: nid005586:68927:69451 [1] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
 8: nid005586:68928:69450 [2] NCCL INFO NET/OFI Support for global registrations: false
 8: nid005586:68928:69450 [2] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
31: nid005937:256592:257124 [3] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
31: nid005937:256592:257124 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
31: nid005937:256592:257124 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
31: nid005937:256592:257124 [3] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
31: nid005937:256592:257124 [3] NCCL INFO NET/OFI Using Libfabric version 1.22
31: nid005937:256592:257124 [3] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
 8: nid005586:68927:69451 [1] NCCL INFO Using network AWS Libfabric
 8: nid005586:68928:69450 [2] NCCL INFO Using network AWS Libfabric
31: nid005937:256591:257123 [2] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
31: nid005937:256591:257123 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
31: nid005937:256591:257123 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
31: nid005937:256591:257123 [2] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
31: nid005937:256591:257123 [2] NCCL INFO NET/OFI Using Libfabric version 1.22
31: nid005937:256591:257123 [2] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
10: nid005590:110713:111240 [3] NCCL INFO DMA-BUF is available on GPU device 3
31: 
31: nid005937:256592:257124 [3] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
31: 
31: nid005937:256591:257123 [2] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
31: nid005937:256592:257124 [3] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
31: nid005937:256592:257124 [3] NCCL INFO NET/OFI Using transport protocol SENDRECV
31: nid005937:256592:257124 [3] NCCL INFO NET/OFI Creating one domain per process
31: nid005937:256592:257124 [3] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
31: nid005937:256591:257123 [2] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
31: nid005937:256591:257123 [2] NCCL INFO NET/OFI Using transport protocol SENDRECV
31: nid005937:256591:257123 [2] NCCL INFO NET/OFI Creating one domain per process
31: nid005937:256591:257123 [2] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
20: [2025-06-27 21:02:55,155] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
31: nid005937:256592:257124 [3] NCCL INFO NET/OFI Support for global registrations: false
31: nid005937:256592:257124 [3] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
31: nid005937:256591:257123 [2] NCCL INFO NET/OFI Support for global registrations: false
31: nid005937:256591:257123 [2] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
31: nid005937:256592:257124 [3] NCCL INFO Using network AWS Libfabric
31: nid005937:256591:257123 [2] NCCL INFO Using network AWS Libfabric
20: nid005913:292683:292683 [2] NCCL INFO cudaDriverVersion 12060
20: nid005913:292683:292683 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
20: nid005913:292683:292683 [2] NCCL INFO Bootstrap : Using hsn0:172.28.23.76<0>
20: nid005913:292683:292683 [2] NCCL INFO NCCL version 2.22.3+cuda12.6
 9: nid005588:35937:36471 [2] NCCL INFO DMA-BUF is available on GPU device 2
 2: nid005577:17425:17981 [3] NCCL INFO DMA-BUF is available on GPU device 3
20: nid005913:292682:293200 [1] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
20: nid005913:292684:293199 [3] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
20: nid005913:292684:293199 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
20: nid005913:292682:293200 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
20: nid005913:292684:293199 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
20: nid005913:292682:293200 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
20: nid005913:292684:293199 [3] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
20: nid005913:292682:293200 [1] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
20: nid005913:292684:293199 [3] NCCL INFO NET/OFI Using Libfabric version 1.22
20: nid005913:292682:293200 [1] NCCL INFO NET/OFI Using Libfabric version 1.22
20: nid005913:292682:293200 [1] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
20: nid005913:292684:293199 [3] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
 9: nid005588:35936:36472 [1] NCCL INFO DMA-BUF is available on GPU device 1
20: 
20: nid005913:292682:293200 [1] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
20: 
20: nid005913:292684:293199 [3] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
20: nid005913:292682:293200 [1] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
20: nid005913:292682:293200 [1] NCCL INFO NET/OFI Using transport protocol SENDRECV
20: nid005913:292682:293200 [1] NCCL INFO NET/OFI Creating one domain per process
20: nid005913:292684:293199 [3] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
20: nid005913:292684:293199 [3] NCCL INFO NET/OFI Using transport protocol SENDRECV
20: nid005913:292684:293199 [3] NCCL INFO NET/OFI Creating one domain per process
20: nid005913:292682:293200 [1] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
20: nid005913:292684:293199 [3] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
20: nid005913:292682:293200 [1] NCCL INFO NET/OFI Support for global registrations: false
20: nid005913:292682:293200 [1] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
20: nid005913:292684:293199 [3] NCCL INFO NET/OFI Support for global registrations: false
20: nid005913:292684:293199 [3] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
20: nid005913:292682:293200 [1] NCCL INFO Using network AWS Libfabric
20: nid005913:292684:293199 [3] NCCL INFO Using network AWS Libfabric
 2: nid005577:17424:17982 [2] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
 2: nid005577:17424:17982 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
 2: nid005577:17424:17982 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
 2: nid005577:17424:17982 [2] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
 2: nid005577:17424:17982 [2] NCCL INFO NET/OFI Using Libfabric version 1.22
 2: nid005577:17424:17982 [2] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
23: nid005917:276886:277419 [1] NCCL INFO DMA-BUF is available on GPU device 1
 2: 
 2: nid005577:17424:17982 [2] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
 2: nid005577:17424:17982 [2] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
 2: nid005577:17424:17982 [2] NCCL INFO NET/OFI Using transport protocol SENDRECV
 2: nid005577:17424:17982 [2] NCCL INFO NET/OFI Creating one domain per process
 2: nid005577:17424:17982 [2] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
 2: nid005577:17424:17982 [2] NCCL INFO NET/OFI Support for global registrations: false
 2: nid005577:17424:17982 [2] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
 2: nid005577:17424:17982 [2] NCCL INFO Using network AWS Libfabric
 9: nid005588:35938:36474 [3] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
 9: nid005588:35938:36474 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
 9: nid005588:35938:36474 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
 9: nid005588:35938:36474 [3] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
 9: nid005588:35938:36474 [3] NCCL INFO NET/OFI Using Libfabric version 1.22
 9: nid005588:35938:36474 [3] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
 9: 
 9: nid005588:35938:36474 [3] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
 9: nid005588:35938:36474 [3] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
 9: nid005588:35938:36474 [3] NCCL INFO NET/OFI Using transport protocol SENDRECV
 9: nid005588:35938:36474 [3] NCCL INFO NET/OFI Creating one domain per process
 9: nid005588:35938:36474 [3] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
 9: nid005588:35938:36474 [3] NCCL INFO NET/OFI Support for global registrations: false
 9: nid005588:35938:36474 [3] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
 9: nid005588:35938:36474 [3] NCCL INFO Using network AWS Libfabric
 7: nid005585:122006:122526 [1] NCCL INFO DMA-BUF is available on GPU device 1
14: [2025-06-27 21:02:55,244] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
26: nid005920:67125:67662 [2] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
26: nid005920:67125:67662 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
26: nid005920:67125:67662 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
26: nid005920:67125:67662 [2] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
26: nid005920:67125:67662 [2] NCCL INFO NET/OFI Using Libfabric version 1.22
26: nid005920:67125:67662 [2] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
26: 
26: nid005920:67125:67662 [2] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
26: nid005920:67125:67662 [2] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
26: nid005920:67125:67662 [2] NCCL INFO NET/OFI Using transport protocol SENDRECV
26: nid005920:67125:67662 [2] NCCL INFO NET/OFI Creating one domain per process
26: nid005920:67125:67662 [2] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
26: nid005920:67125:67662 [2] NCCL INFO NET/OFI Support for global registrations: false
26: nid005920:67125:67662 [2] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
24: nid005918:92504:92504 [0] NCCL INFO cudaDriverVersion 12060
24: nid005918:92504:92504 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
26: nid005920:67125:67662 [2] NCCL INFO Using network AWS Libfabric
24: nid005918:92504:92504 [0] NCCL INFO Bootstrap : Using hsn0:172.28.23.96<0>
24: nid005918:92504:92504 [0] NCCL INFO NCCL version 2.22.3+cuda12.6
10: nid005590:110711:111241 [1] NCCL INFO DMA-BUF is available on GPU device 1
 7: nid005585:122007:122527 [2] NCCL INFO DMA-BUF is available on GPU device 2
 7: nid005585:122008:122008 [3] NCCL INFO cudaDriverVersion 12060
 7: nid005585:122008:122008 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
 7: nid005585:122008:122008 [3] NCCL INFO Bootstrap : Using hsn0:172.28.18.236<0>
 7: nid005585:122008:122008 [3] NCCL INFO NCCL version 2.22.3+cuda12.6
10: nid005590:110712:111243 [2] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
10: nid005590:110712:111243 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
10: nid005590:110712:111243 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
10: nid005590:110712:111243 [2] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
10: nid005590:110712:111243 [2] NCCL INFO NET/OFI Using Libfabric version 1.22
10: nid005590:110712:111243 [2] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
10: 
10: nid005590:110712:111243 [2] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
17: nid005803:180732:181264 [0] NCCL INFO DMA-BUF is available on GPU device 0
10: nid005590:110712:111243 [2] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
10: nid005590:110712:111243 [2] NCCL INFO NET/OFI Using transport protocol SENDRECV
10: nid005590:110712:111243 [2] NCCL INFO NET/OFI Creating one domain per process
10: nid005590:110712:111243 [2] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
 6: [2025-06-27 21:02:55,314] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
10: nid005590:110712:111243 [2] NCCL INFO NET/OFI Support for global registrations: false
10: nid005590:110712:111243 [2] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
10: nid005590:110712:111243 [2] NCCL INFO Using network AWS Libfabric
 6: [2025-06-27 21:02:55,318] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
 4: [2025-06-27 21:02:55,335] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
 6: nid005584:28286:28286 [1] NCCL INFO cudaDriverVersion 12060
 6: nid005584:28286:28286 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
 6: nid005584:28286:28286 [1] NCCL INFO Bootstrap : Using hsn0:172.28.18.232<0>
 6: nid005584:28286:28286 [1] NCCL INFO NCCL version 2.22.3+cuda12.6
 6: nid005584:28287:28287 [2] NCCL INFO cudaDriverVersion 12060
 6: nid005584:28287:28287 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
 6: nid005584:28287:28287 [2] NCCL INFO Bootstrap : Using hsn0:172.28.18.232<0>
 6: nid005584:28287:28287 [2] NCCL INFO NCCL version 2.22.3+cuda12.6
23: nid005917:276887:277420 [2] NCCL INFO DMA-BUF is available on GPU device 2
 4: nid005581:264526:264526 [3] NCCL INFO cudaDriverVersion 12060
 4: nid005581:264526:264526 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
 4: nid005581:264526:264526 [3] NCCL INFO Bootstrap : Using hsn0:172.28.18.220<0>
 4: nid005581:264526:264526 [3] NCCL INFO NCCL version 2.22.3+cuda12.6
 4: [2025-06-27 21:02:55,356] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
 7: nid005585:122008:122545 [3] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
 7: nid005585:122008:122545 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
 7: nid005585:122008:122545 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
 7: nid005585:122008:122545 [3] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
 7: nid005585:122008:122545 [3] NCCL INFO NET/OFI Using Libfabric version 1.22
 7: nid005585:122008:122545 [3] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
 7: 
 7: nid005585:122008:122545 [3] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
 7: nid005585:122008:122545 [3] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
 7: nid005585:122008:122545 [3] NCCL INFO NET/OFI Using transport protocol SENDRECV
 7: nid005585:122008:122545 [3] NCCL INFO NET/OFI Creating one domain per process
 7: nid005585:122008:122545 [3] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
 7: nid005585:122008:122545 [3] NCCL INFO NET/OFI Support for global registrations: false
 7: nid005585:122008:122545 [3] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
 6: [2025-06-27 21:02:55,368] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
 7: nid005585:122008:122545 [3] NCCL INFO Using network AWS Libfabric
 4: nid005581:264524:264524 [1] NCCL INFO cudaDriverVersion 12060
 4: nid005581:264524:264524 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
 4: nid005581:264524:264524 [1] NCCL INFO Bootstrap : Using hsn0:172.28.18.220<0>
 4: nid005581:264524:264524 [1] NCCL INFO NCCL version 2.22.3+cuda12.6
23: nid005917:276885:277421 [0] NCCL INFO DMA-BUF is available on GPU device 0
18: [2025-06-27 21:02:55,386] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
24: nid005918:92504:93029 [0] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
24: nid005918:92504:93029 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
24: nid005918:92504:93029 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
24: nid005918:92504:93029 [0] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
24: nid005918:92504:93029 [0] NCCL INFO NET/OFI Using Libfabric version 1.22
24: nid005918:92504:93029 [0] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
 6: nid005584:28288:28288 [3] NCCL INFO cudaDriverVersion 12060
 6: nid005584:28288:28288 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
 6: nid005584:28288:28288 [3] NCCL INFO Bootstrap : Using hsn0:172.28.18.232<0>
 6: nid005584:28288:28288 [3] NCCL INFO NCCL version 2.22.3+cuda12.6
24: 
24: nid005918:92504:93029 [0] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
24: nid005918:92504:93029 [0] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
24: nid005918:92504:93029 [0] NCCL INFO NET/OFI Using transport protocol SENDRECV
24: nid005918:92504:93029 [0] NCCL INFO NET/OFI Creating one domain per process
24: nid005918:92504:93029 [0] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
12: nid005594:53088:53605 [3] NCCL INFO DMA-BUF is available on GPU device 3
24: nid005918:92504:93029 [0] NCCL INFO NET/OFI Support for global registrations: false
24: nid005918:92504:93029 [0] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
18: nid005911:38865:38865 [1] NCCL INFO cudaDriverVersion 12060
18: nid005911:38865:38865 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
18: nid005911:38865:38865 [1] NCCL INFO Bootstrap : Using hsn0:172.28.23.68<0>
18: nid005911:38865:38865 [1] NCCL INFO NCCL version 2.22.3+cuda12.6
24: nid005918:92504:93029 [0] NCCL INFO Using network AWS Libfabric
18: [2025-06-27 21:02:55,410] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
 6: nid005584:28286:28818 [1] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
 6: nid005584:28286:28818 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
 6: nid005584:28286:28818 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
 6: nid005584:28286:28818 [1] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
 6: nid005584:28286:28818 [1] NCCL INFO NET/OFI Using Libfabric version 1.22
 6: nid005584:28286:28818 [1] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
12: nid005594:53086:53606 [1] NCCL INFO DMA-BUF is available on GPU device 1
 6: 
 6: nid005584:28286:28818 [1] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
 6: nid005584:28286:28818 [1] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
 6: nid005584:28286:28818 [1] NCCL INFO NET/OFI Using transport protocol SENDRECV
 6: nid005584:28286:28818 [1] NCCL INFO NET/OFI Creating one domain per process
 6: nid005584:28287:28819 [2] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
 6: nid005584:28287:28819 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
 6: nid005584:28287:28819 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
 6: nid005584:28287:28819 [2] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
 6: nid005584:28287:28819 [2] NCCL INFO NET/OFI Using Libfabric version 1.22
 6: nid005584:28287:28819 [2] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
 6: nid005584:28286:28818 [1] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
 6: 
 6: nid005584:28287:28819 [2] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
 6: nid005584:28286:28818 [1] NCCL INFO NET/OFI Support for global registrations: false
 6: nid005584:28286:28818 [1] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
17: nid005803:180733:181262 [1] NCCL INFO DMA-BUF is available on GPU device 1
 6: nid005584:28287:28819 [2] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
 6: nid005584:28287:28819 [2] NCCL INFO NET/OFI Using transport protocol SENDRECV
 6: nid005584:28287:28819 [2] NCCL INFO NET/OFI Creating one domain per process
 4: nid005581:264526:265063 [3] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
 4: nid005581:264526:265063 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
 4: nid005581:264526:265063 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
 4: nid005581:264526:265063 [3] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
 4: nid005581:264526:265063 [3] NCCL INFO NET/OFI Using Libfabric version 1.22
 4: nid005581:264526:265063 [3] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
 6: nid005584:28287:28819 [2] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
 6: nid005584:28286:28818 [1] NCCL INFO Using network AWS Libfabric
18: nid005911:38866:38866 [2] NCCL INFO cudaDriverVersion 12060
18: nid005911:38866:38866 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
 4: 
 4: nid005581:264526:265063 [3] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
 6: nid005584:28287:28819 [2] NCCL INFO NET/OFI Support for global registrations: false
 6: nid005584:28287:28819 [2] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
18: nid005911:38866:38866 [2] NCCL INFO Bootstrap : Using hsn0:172.28.23.68<0>
18: nid005911:38866:38866 [2] NCCL INFO NCCL version 2.22.3+cuda12.6
 4: nid005581:264526:265063 [3] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
 4: nid005581:264526:265063 [3] NCCL INFO NET/OFI Using transport protocol SENDRECV
 4: nid005581:264526:265063 [3] NCCL INFO NET/OFI Creating one domain per process
 4: nid005581:264526:265063 [3] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
 6: nid005584:28287:28819 [2] NCCL INFO Using network AWS Libfabric
17: nid005803:180734:181263 [2] NCCL INFO DMA-BUF is available on GPU device 2
 4: nid005581:264526:265063 [3] NCCL INFO NET/OFI Support for global registrations: false
 4: nid005581:264526:265063 [3] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
 4: nid005581:264526:265063 [3] NCCL INFO Using network AWS Libfabric
12: nid005594:53087:53607 [2] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
12: nid005594:53087:53607 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
12: nid005594:53087:53607 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
12: nid005594:53087:53607 [2] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
12: nid005594:53087:53607 [2] NCCL INFO NET/OFI Using Libfabric version 1.22
12: nid005594:53087:53607 [2] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
12: 
12: nid005594:53087:53607 [2] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
12: nid005594:53087:53607 [2] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
12: nid005594:53087:53607 [2] NCCL INFO NET/OFI Using transport protocol SENDRECV
12: nid005594:53087:53607 [2] NCCL INFO NET/OFI Creating one domain per process
12: nid005594:53087:53607 [2] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
17: nid005803:180735:181265 [3] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
17: nid005803:180735:181265 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
17: nid005803:180735:181265 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
17: nid005803:180735:181265 [3] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
17: nid005803:180735:181265 [3] NCCL INFO NET/OFI Using Libfabric version 1.22
17: nid005803:180735:181265 [3] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
12: nid005594:53087:53607 [2] NCCL INFO NET/OFI Support for global registrations: false
12: nid005594:53087:53607 [2] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
17: 
17: nid005803:180735:181265 [3] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
17: nid005803:180735:181265 [3] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
17: nid005803:180735:181265 [3] NCCL INFO NET/OFI Using transport protocol SENDRECV
17: nid005803:180735:181265 [3] NCCL INFO NET/OFI Creating one domain per process
17: nid005803:180735:181265 [3] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
12: nid005594:53087:53607 [2] NCCL INFO Using network AWS Libfabric
19: nid005912:12438:12958 [3] NCCL INFO DMA-BUF is available on GPU device 3
17: nid005803:180735:181265 [3] NCCL INFO NET/OFI Support for global registrations: false
17: nid005803:180735:181265 [3] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
17: nid005803:180735:181265 [3] NCCL INFO Using network AWS Libfabric
16: nid005802:6298:6897 [1] NCCL INFO DMA-BUF is available on GPU device 1
18: nid005911:38865:39420 [1] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
18: nid005911:38865:39420 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
18: nid005911:38865:39420 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
18: nid005911:38865:39420 [1] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
18: nid005911:38865:39420 [1] NCCL INFO NET/OFI Using Libfabric version 1.22
18: nid005911:38865:39420 [1] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
 4: [2025-06-27 21:02:55,476] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
18: 
18: nid005911:38865:39420 [1] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
18: nid005911:38865:39420 [1] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
18: nid005911:38865:39420 [1] NCCL INFO NET/OFI Using transport protocol SENDRECV
18: nid005911:38865:39420 [1] NCCL INFO NET/OFI Creating one domain per process
18: nid005911:38865:39420 [1] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
16: nid005802:6299:6898 [2] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
16: nid005802:6299:6898 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
16: nid005802:6299:6898 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
16: nid005802:6299:6898 [2] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
16: nid005802:6299:6898 [2] NCCL INFO NET/OFI Using Libfabric version 1.22
16: nid005802:6299:6898 [2] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
18: nid005911:38865:39420 [1] NCCL INFO NET/OFI Support for global registrations: false
18: nid005911:38865:39420 [1] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
18: nid005911:38865:39420 [1] NCCL INFO Using network AWS Libfabric
16: 
16: nid005802:6299:6898 [2] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
16: nid005802:6299:6898 [2] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
16: nid005802:6299:6898 [2] NCCL INFO NET/OFI Using transport protocol SENDRECV
16: nid005802:6299:6898 [2] NCCL INFO NET/OFI Creating one domain per process
16: nid005802:6299:6898 [2] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
16: nid005802:6299:6898 [2] NCCL INFO NET/OFI Support for global registrations: false
16: nid005802:6299:6898 [2] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
16: nid005802:6300:6899 [3] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
16: nid005802:6300:6899 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
16: nid005802:6300:6899 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
16: nid005802:6300:6899 [3] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
16: nid005802:6300:6899 [3] NCCL INFO NET/OFI Using Libfabric version 1.22
16: nid005802:6300:6899 [3] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
16: nid005802:6299:6898 [2] NCCL INFO Using network AWS Libfabric
16: 
16: nid005802:6300:6899 [3] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
16: nid005802:6300:6899 [3] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
16: nid005802:6300:6899 [3] NCCL INFO NET/OFI Using transport protocol SENDRECV
16: nid005802:6300:6899 [3] NCCL INFO NET/OFI Creating one domain per process
16: nid005802:6300:6899 [3] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
16: nid005802:6300:6899 [3] NCCL INFO NET/OFI Support for global registrations: false
16: nid005802:6300:6899 [3] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
16: nid005802:6300:6899 [3] NCCL INFO Using network AWS Libfabric
19: nid005912:12436:12959 [1] NCCL INFO DMA-BUF is available on GPU device 1
 4: nid005581:264524:265064 [1] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
 4: nid005581:264524:265064 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
 4: nid005581:264524:265064 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
 4: nid005581:264524:265064 [1] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
 4: nid005581:264524:265064 [1] NCCL INFO NET/OFI Using Libfabric version 1.22
 4: nid005581:264524:265064 [1] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
19: nid005912:12437:12437 [2] NCCL INFO cudaDriverVersion 12060
19: nid005912:12437:12437 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
19: nid005912:12437:12437 [2] NCCL INFO Bootstrap : Using hsn0:172.28.23.72<0>
19: nid005912:12437:12437 [2] NCCL INFO NCCL version 2.22.3+cuda12.6
 4: 
 4: nid005581:264524:265064 [1] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
 4: nid005581:264524:265064 [1] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
 4: nid005581:264524:265064 [1] NCCL INFO NET/OFI Using transport protocol SENDRECV
 4: nid005581:264524:265064 [1] NCCL INFO NET/OFI Creating one domain per process
 4: nid005581:264524:265064 [1] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
 4: nid005581:264524:265064 [1] NCCL INFO NET/OFI Support for global registrations: false
 4: nid005581:264524:265064 [1] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
 4: nid005581:264524:265064 [1] NCCL INFO Using network AWS Libfabric
23: nid005917:276888:277422 [3] NCCL INFO DMA-BUF is available on GPU device 3
24: [2025-06-27 21:02:55,551] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
28: nid005929:16033:16573 [3] NCCL INFO DMA-BUF is available on GPU device 3
24: [2025-06-27 21:02:55,553] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
18: [2025-06-27 21:02:55,555] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
19: nid005912:12437:12976 [2] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
19: nid005912:12437:12976 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
19: nid005912:12437:12976 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
19: nid005912:12437:12976 [2] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
19: nid005912:12437:12976 [2] NCCL INFO NET/OFI Using Libfabric version 1.22
19: nid005912:12437:12976 [2] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
19: 
19: nid005912:12437:12976 [2] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
19: nid005912:12437:12976 [2] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
19: nid005912:12437:12976 [2] NCCL INFO NET/OFI Using transport protocol SENDRECV
19: nid005912:12437:12976 [2] NCCL INFO NET/OFI Creating one domain per process
19: nid005912:12437:12976 [2] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
19: nid005912:12437:12976 [2] NCCL INFO NET/OFI Support for global registrations: false
19: nid005912:12437:12976 [2] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
19: nid005912:12437:12976 [2] NCCL INFO Using network AWS Libfabric
24: [2025-06-27 21:02:55,602] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
 8: [2025-06-27 21:02:55,609] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
14: nid005600:217722:218227 [2] NCCL INFO DMA-BUF is available on GPU device 2
29: [2025-06-27 21:02:55,618] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
29: [2025-06-27 21:02:55,618] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
14: nid005600:217723:217723 [3] NCCL INFO cudaDriverVersion 12060
14: nid005600:217723:217723 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
14: nid005600:217723:217723 [3] NCCL INFO Bootstrap : Using hsn0:172.28.50.5<0>
14: nid005600:217723:217723 [3] NCCL INFO NCCL version 2.22.3+cuda12.6
14: nid005600:217721:218228 [1] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
14: nid005600:217721:218228 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
14: nid005600:217721:218228 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
14: nid005600:217721:218228 [1] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
14: nid005600:217721:218228 [1] NCCL INFO NET/OFI Using Libfabric version 1.22
14: nid005600:217721:218228 [1] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
29: [2025-06-27 21:02:55,643] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
14: 
14: nid005600:217721:218228 [1] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
14: nid005600:217721:218228 [1] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
14: nid005600:217721:218228 [1] NCCL INFO NET/OFI Using transport protocol SENDRECV
14: nid005600:217721:218228 [1] NCCL INFO NET/OFI Creating one domain per process
14: nid005600:217721:218228 [1] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
14: nid005600:217721:218228 [1] NCCL INFO NET/OFI Support for global registrations: false
14: nid005600:217721:218228 [1] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
29: nid005932:167682:167682 [2] NCCL INFO cudaDriverVersion 12060
29: nid005932:167682:167682 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
29: nid005932:167681:167681 [1] NCCL INFO cudaDriverVersion 12060
29: nid005932:167681:167681 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
29: nid005932:167681:167681 [1] NCCL INFO Bootstrap : Using hsn0:172.28.23.144<0>
29: nid005932:167682:167682 [2] NCCL INFO Bootstrap : Using hsn0:172.28.23.144<0>
29: nid005932:167682:167682 [2] NCCL INFO NCCL version 2.22.3+cuda12.6
29: nid005932:167681:167681 [1] NCCL INFO NCCL version 2.22.3+cuda12.6
14: nid005600:217721:218228 [1] NCCL INFO Using network AWS Libfabric
18: nid005911:38866:39421 [2] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
18: nid005911:38866:39421 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
18: nid005911:38866:39421 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
18: nid005911:38866:39421 [2] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
18: nid005911:38866:39421 [2] NCCL INFO NET/OFI Using Libfabric version 1.22
18: nid005911:38866:39421 [2] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
18: 
18: nid005911:38866:39421 [2] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
29: nid005932:167683:167683 [3] NCCL INFO cudaDriverVersion 12060
29: nid005932:167683:167683 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
29: nid005932:167683:167683 [3] NCCL INFO Bootstrap : Using hsn0:172.28.23.144<0>
29: nid005932:167683:167683 [3] NCCL INFO NCCL version 2.22.3+cuda12.6
18: nid005911:38866:39421 [2] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
18: nid005911:38866:39421 [2] NCCL INFO NET/OFI Using transport protocol SENDRECV
18: nid005911:38866:39421 [2] NCCL INFO NET/OFI Creating one domain per process
18: nid005911:38866:39421 [2] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
18: nid005911:38866:39421 [2] NCCL INFO NET/OFI Support for global registrations: false
18: nid005911:38866:39421 [2] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
18: nid005911:38866:39421 [2] NCCL INFO Using network AWS Libfabric
 3: nid005580:71822:72337 [3] NCCL INFO DMA-BUF is available on GPU device 3
30: nid005936:49909:50450 [1] NCCL INFO DMA-BUF is available on GPU device 1
13: nid005595:197885:198470 [2] NCCL INFO DMA-BUF is available on GPU device 2
29: nid005932:167682:168229 [2] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
29: nid005932:167681:168228 [1] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
29: nid005932:167681:168228 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
29: nid005932:167682:168229 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
29: nid005932:167682:168229 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
29: nid005932:167681:168228 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
29: nid005932:167681:168228 [1] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
29: nid005932:167682:168229 [2] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
29: nid005932:167681:168228 [1] NCCL INFO NET/OFI Using Libfabric version 1.22
29: nid005932:167682:168229 [2] NCCL INFO NET/OFI Using Libfabric version 1.22
29: nid005932:167682:168229 [2] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
29: nid005932:167681:168228 [1] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
25: nid005919:107465:108002 [3] NCCL INFO DMA-BUF is available on GPU device 3
 2: nid005577:17424:17982 [2] NCCL INFO DMA-BUF is available on GPU device 2
29: 
29: nid005932:167682:168229 [2] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
29: 
29: nid005932:167681:168228 [1] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
13: nid005595:197886:198472 [3] NCCL INFO DMA-BUF is available on GPU device 3
30: nid005936:49908:50465 [0] NCCL INFO DMA-BUF is available on GPU device 0
29: nid005932:167682:168229 [2] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
29: nid005932:167682:168229 [2] NCCL INFO NET/OFI Using transport protocol SENDRECV
29: nid005932:167682:168229 [2] NCCL INFO NET/OFI Creating one domain per process
29: nid005932:167681:168228 [1] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
29: nid005932:167681:168228 [1] NCCL INFO NET/OFI Using transport protocol SENDRECV
29: nid005932:167681:168228 [1] NCCL INFO NET/OFI Creating one domain per process
29: nid005932:167682:168229 [2] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
29: nid005932:167681:168228 [1] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
25: nid005919:107463:108001 [1] NCCL INFO DMA-BUF is available on GPU device 1
13: nid005595:197884:198471 [1] NCCL INFO DMA-BUF is available on GPU device 1
29: nid005932:167682:168229 [2] NCCL INFO NET/OFI Support for global registrations: false
29: nid005932:167681:168228 [1] NCCL INFO NET/OFI Support for global registrations: false
29: nid005932:167682:168229 [2] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
29: nid005932:167681:168228 [1] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
 9: nid005588:35938:36474 [3] NCCL INFO DMA-BUF is available on GPU device 3
30: nid005936:49911:50449 [3] NCCL INFO DMA-BUF is available on GPU device 3
29: nid005932:167682:168229 [2] NCCL INFO Using network AWS Libfabric
29: nid005932:167681:168228 [1] NCCL INFO Using network AWS Libfabric
29: nid005932:167683:168230 [3] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
29: nid005932:167683:168230 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
29: nid005932:167683:168230 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
29: nid005932:167683:168230 [3] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
29: nid005932:167683:168230 [3] NCCL INFO NET/OFI Using Libfabric version 1.22
29: nid005932:167683:168230 [3] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
25: nid005919:107464:108003 [2] NCCL INFO DMA-BUF is available on GPU device 2
29: 
29: nid005932:167683:168230 [3] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
29: nid005932:167683:168230 [3] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
29: nid005932:167683:168230 [3] NCCL INFO NET/OFI Using transport protocol SENDRECV
29: nid005932:167683:168230 [3] NCCL INFO NET/OFI Creating one domain per process
29: nid005932:167683:168230 [3] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
30: nid005936:49910:50467 [2] NCCL INFO DMA-BUF is available on GPU device 2
29: nid005932:167683:168230 [3] NCCL INFO NET/OFI Support for global registrations: false
29: nid005932:167683:168230 [3] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
29: nid005932:167683:168230 [3] NCCL INFO Using network AWS Libfabric
 3: nid005580:71820:72338 [1] NCCL INFO DMA-BUF is available on GPU device 1
 5: nid005582:196714:197386 [1] NCCL INFO DMA-BUF is available on GPU device 1
22: nid005915:274817:275333 [3] NCCL INFO DMA-BUF is available on GPU device 3
 3: nid005580:71821:72339 [2] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
 3: nid005580:71821:72339 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
 3: nid005580:71821:72339 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
 3: nid005580:71821:72339 [2] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
 3: nid005580:71821:72339 [2] NCCL INFO NET/OFI Using Libfabric version 1.22
 3: nid005580:71821:72339 [2] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
 5: nid005582:196715:197387 [2] NCCL INFO DMA-BUF is available on GPU device 2
 3: 
 3: nid005580:71821:72339 [2] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
22: nid005915:274815:275332 [1] NCCL INFO DMA-BUF is available on GPU device 1
15: nid005601:210679:211194 [3] NCCL INFO DMA-BUF is available on GPU device 3
 3: nid005580:71821:72339 [2] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
 3: nid005580:71821:72339 [2] NCCL INFO NET/OFI Using transport protocol SENDRECV
 3: nid005580:71821:72339 [2] NCCL INFO NET/OFI Creating one domain per process
 3: nid005580:71821:72339 [2] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
 3: nid005580:71821:72339 [2] NCCL INFO NET/OFI Support for global registrations: false
 3: nid005580:71821:72339 [2] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
 5: nid005582:196713:197389 [0] NCCL INFO DMA-BUF is available on GPU device 0
 3: nid005580:71821:72339 [2] NCCL INFO Using network AWS Libfabric
22: nid005915:274816:275334 [2] NCCL INFO DMA-BUF is available on GPU device 2
15: nid005601:210676:211210 [0] NCCL INFO DMA-BUF is available on GPU device 0
21: nid005914:166785:167301 [1] NCCL INFO DMA-BUF is available on GPU device 1
 5: nid005582:196716:197388 [3] NCCL INFO DMA-BUF is available on GPU device 3
21: nid005914:166787:167300 [3] NCCL INFO DMA-BUF is available on GPU device 3
15: nid005601:210678:211209 [2] NCCL INFO DMA-BUF is available on GPU device 2
15: nid005601:210677:211211 [1] NCCL INFO DMA-BUF is available on GPU device 1
10: nid005590:110712:111243 [2] NCCL INFO DMA-BUF is available on GPU device 2
 0: nid005574:69061:69602 [3] NCCL INFO DMA-BUF is available on GPU device 3
 0: nid005574:69059:69601 [1] NCCL INFO DMA-BUF is available on GPU device 1
 7: nid005585:122008:122545 [3] NCCL INFO DMA-BUF is available on GPU device 3
 0: nid005574:69060:69600 [2] NCCL INFO DMA-BUF is available on GPU device 2
 1: nid005576:147560:148100 [3] NCCL INFO DMA-BUF is available on GPU device 3
 1: nid005576:147559:148101 [2] NCCL INFO DMA-BUF is available on GPU device 2
27: nid005922:80743:81258 [2] NCCL INFO DMA-BUF is available on GPU device 2
12: nid005594:53087:53607 [2] NCCL INFO DMA-BUF is available on GPU device 2
17: nid005803:180735:181265 [3] NCCL INFO DMA-BUF is available on GPU device 3
27: nid005922:80744:81259 [3] NCCL INFO DMA-BUF is available on GPU device 3
24: nid005918:92504:93029 [0] NCCL INFO DMA-BUF is available on GPU device 0
 8: nid005586:68927:69451 [1] NCCL INFO DMA-BUF is available on GPU device 1
24: nid005918:92505:92505 [1] NCCL INFO cudaDriverVersion 12060
24: nid005918:92505:92505 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
24: nid005918:92506:92506 [2] NCCL INFO cudaDriverVersion 12060
24: nid005918:92506:92506 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
24: nid005918:92507:92507 [3] NCCL INFO cudaDriverVersion 12060
24: nid005918:92507:92507 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
24: nid005918:92506:92506 [2] NCCL INFO Bootstrap : Using hsn0:172.28.23.96<0>
24: nid005918:92507:92507 [3] NCCL INFO Bootstrap : Using hsn0:172.28.23.96<0>
24: nid005918:92505:92505 [1] NCCL INFO Bootstrap : Using hsn0:172.28.23.96<0>
24: nid005918:92506:92506 [2] NCCL INFO NCCL version 2.22.3+cuda12.6
24: nid005918:92507:92507 [3] NCCL INFO NCCL version 2.22.3+cuda12.6
24: nid005918:92505:92505 [1] NCCL INFO NCCL version 2.22.3+cuda12.6
11: nid005591:191605:192144 [2] NCCL INFO DMA-BUF is available on GPU device 2
19: nid005912:12437:12976 [2] NCCL INFO DMA-BUF is available on GPU device 2
31: nid005937:256592:257124 [3] NCCL INFO DMA-BUF is available on GPU device 3
11: nid005591:191604:192145 [1] NCCL INFO DMA-BUF is available on GPU device 1
24: nid005918:92507:93078 [3] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
24: nid005918:92507:93078 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
24: nid005918:92507:93078 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
24: nid005918:92507:93078 [3] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
24: nid005918:92507:93078 [3] NCCL INFO NET/OFI Using Libfabric version 1.22
24: nid005918:92507:93078 [3] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
 8: nid005586:68928:69450 [2] NCCL INFO DMA-BUF is available on GPU device 2
24: nid005918:92505:93080 [1] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
24: nid005918:92506:93079 [2] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
24: nid005918:92506:93079 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
24: nid005918:92505:93080 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
24: nid005918:92506:93079 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
24: nid005918:92505:93080 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
24: nid005918:92506:93079 [2] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
24: nid005918:92505:93080 [1] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
24: nid005918:92506:93079 [2] NCCL INFO NET/OFI Using Libfabric version 1.22
24: nid005918:92505:93080 [1] NCCL INFO NET/OFI Using Libfabric version 1.22
24: nid005918:92506:93079 [2] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
24: nid005918:92505:93080 [1] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
24: 
24: nid005918:92507:93078 [3] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
24: nid005918:92507:93078 [3] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
24: nid005918:92507:93078 [3] NCCL INFO NET/OFI Using transport protocol SENDRECV
24: nid005918:92507:93078 [3] NCCL INFO NET/OFI Creating one domain per process
24: nid005918:92507:93078 [3] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
 8: nid005586:68929:68929 [3] NCCL INFO cudaDriverVersion 12060
 8: nid005586:68929:68929 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
24: 
24: nid005918:92505:93080 [1] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
24: 
24: nid005918:92506:93079 [2] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
 8: nid005586:68929:68929 [3] NCCL INFO Bootstrap : Using hsn0:172.28.48.231<0>
 8: nid005586:68929:68929 [3] NCCL INFO NCCL version 2.22.3+cuda12.6
24: nid005918:92507:93078 [3] NCCL INFO NET/OFI Support for global registrations: false
24: nid005918:92507:93078 [3] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
24: nid005918:92505:93080 [1] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
24: nid005918:92505:93080 [1] NCCL INFO NET/OFI Using transport protocol SENDRECV
24: nid005918:92505:93080 [1] NCCL INFO NET/OFI Creating one domain per process
24: nid005918:92506:93079 [2] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
24: nid005918:92506:93079 [2] NCCL INFO NET/OFI Using transport protocol SENDRECV
24: nid005918:92506:93079 [2] NCCL INFO NET/OFI Creating one domain per process
26: nid005920:67124:67660 [1] NCCL INFO DMA-BUF is available on GPU device 1
24: nid005918:92505:93080 [1] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
24: nid005918:92506:93079 [2] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
24: nid005918:92507:93078 [3] NCCL INFO Using network AWS Libfabric
24: nid005918:92505:93080 [1] NCCL INFO NET/OFI Support for global registrations: false
24: nid005918:92505:93080 [1] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
24: nid005918:92506:93079 [2] NCCL INFO NET/OFI Support for global registrations: false
24: nid005918:92506:93079 [2] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
24: nid005918:92505:93080 [1] NCCL INFO Using network AWS Libfabric
24: nid005918:92506:93079 [2] NCCL INFO Using network AWS Libfabric
14: nid005600:217721:218228 [1] NCCL INFO DMA-BUF is available on GPU device 1
31: nid005937:256591:257123 [2] NCCL INFO DMA-BUF is available on GPU device 2
20: nid005913:292684:293199 [3] NCCL INFO DMA-BUF is available on GPU device 3
14: nid005600:217723:218244 [3] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
14: nid005600:217723:218244 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
14: nid005600:217723:218244 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
14: nid005600:217723:218244 [3] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
14: nid005600:217723:218244 [3] NCCL INFO NET/OFI Using Libfabric version 1.22
14: nid005600:217723:218244 [3] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
14: 
14: nid005600:217723:218244 [3] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
14: nid005600:217723:218244 [3] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
14: nid005600:217723:218244 [3] NCCL INFO NET/OFI Using transport protocol SENDRECV
14: nid005600:217723:218244 [3] NCCL INFO NET/OFI Creating one domain per process
31: nid005937:256590:257125 [1] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
31: nid005937:256590:257125 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
31: nid005937:256590:257125 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
31: nid005937:256590:257125 [1] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
31: nid005937:256590:257125 [1] NCCL INFO NET/OFI Using Libfabric version 1.22
31: nid005937:256590:257125 [1] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
14: nid005600:217723:218244 [3] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
31: 
31: nid005937:256590:257125 [1] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
14: nid005600:217723:218244 [3] NCCL INFO NET/OFI Support for global registrations: false
14: nid005600:217723:218244 [3] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
31: nid005937:256590:257125 [1] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
31: nid005937:256590:257125 [1] NCCL INFO NET/OFI Using transport protocol SENDRECV
31: nid005937:256590:257125 [1] NCCL INFO NET/OFI Creating one domain per process
31: nid005937:256590:257125 [1] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
14: nid005600:217723:218244 [3] NCCL INFO Using network AWS Libfabric
31: nid005937:256590:257125 [1] NCCL INFO NET/OFI Support for global registrations: false
31: nid005937:256590:257125 [1] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
31: nid005937:256590:257125 [1] NCCL INFO Using network AWS Libfabric
20: nid005913:292682:293200 [1] NCCL INFO DMA-BUF is available on GPU device 1
 8: nid005586:68929:69489 [3] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
 8: nid005586:68929:69489 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
 8: nid005586:68929:69489 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
 8: nid005586:68929:69489 [3] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
 8: nid005586:68929:69489 [3] NCCL INFO NET/OFI Using Libfabric version 1.22
 8: nid005586:68929:69489 [3] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
 8: 
 8: nid005586:68929:69489 [3] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
 8: nid005586:68929:69489 [3] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
 8: nid005586:68929:69489 [3] NCCL INFO NET/OFI Using transport protocol SENDRECV
 8: nid005586:68929:69489 [3] NCCL INFO NET/OFI Creating one domain per process
 8: nid005586:68929:69489 [3] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
 8: nid005586:68929:69489 [3] NCCL INFO NET/OFI Support for global registrations: false
 8: nid005586:68929:69489 [3] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
 8: nid005586:68929:69489 [3] NCCL INFO Using network AWS Libfabric
20: nid005913:292683:293201 [2] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
20: nid005913:292683:293201 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
20: nid005913:292683:293201 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
20: nid005913:292683:293201 [2] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
20: nid005913:292683:293201 [2] NCCL INFO NET/OFI Using Libfabric version 1.22
20: nid005913:292683:293201 [2] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
20: 
20: nid005913:292683:293201 [2] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
20: nid005913:292683:293201 [2] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
20: nid005913:292683:293201 [2] NCCL INFO NET/OFI Using transport protocol SENDRECV
20: nid005913:292683:293201 [2] NCCL INFO NET/OFI Creating one domain per process
20: nid005913:292683:293201 [2] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
20: nid005913:292683:293201 [2] NCCL INFO NET/OFI Support for global registrations: false
20: nid005913:292683:293201 [2] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
20: nid005913:292683:293201 [2] NCCL INFO Using network AWS Libfabric
18: nid005911:38865:39420 [1] NCCL INFO DMA-BUF is available on GPU device 1
 3: nid005580:71821:72339 [2] NCCL INFO DMA-BUF is available on GPU device 2
26: nid005920:67126:67661 [3] NCCL INFO DMA-BUF is available on GPU device 3
 4: nid005581:264526:265063 [3] NCCL INFO DMA-BUF is available on GPU device 3
 6: nid005584:28286:28818 [1] NCCL INFO DMA-BUF is available on GPU device 1
 6: nid005584:28287:28819 [2] NCCL INFO DMA-BUF is available on GPU device 2
 4: nid005581:264524:265064 [1] NCCL INFO DMA-BUF is available on GPU device 1
 4: nid005581:264525:264525 [2] NCCL INFO cudaDriverVersion 12060
 4: nid005581:264525:264525 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
26: nid005920:67125:67662 [2] NCCL INFO DMA-BUF is available on GPU device 2
 4: nid005581:264525:264525 [2] NCCL INFO Bootstrap : Using hsn0:172.28.18.220<0>
 4: nid005581:264525:264525 [2] NCCL INFO NCCL version 2.22.3+cuda12.6
 6: nid005584:28288:28820 [3] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
 6: nid005584:28288:28820 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
 6: nid005584:28288:28820 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
 6: nid005584:28288:28820 [3] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
 6: nid005584:28288:28820 [3] NCCL INFO NET/OFI Using Libfabric version 1.22
 6: nid005584:28288:28820 [3] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
 6: 
 6: nid005584:28288:28820 [3] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
 6: nid005584:28288:28820 [3] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
 6: nid005584:28288:28820 [3] NCCL INFO NET/OFI Using transport protocol SENDRECV
 6: nid005584:28288:28820 [3] NCCL INFO NET/OFI Creating one domain per process
 6: nid005584:28288:28820 [3] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
 6: nid005584:28288:28820 [3] NCCL INFO NET/OFI Support for global registrations: false
 6: nid005584:28288:28820 [3] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
 6: nid005584:28288:28820 [3] NCCL INFO Using network AWS Libfabric
16: nid005802:6299:6898 [2] NCCL INFO DMA-BUF is available on GPU device 2
16: nid005802:6300:6899 [3] NCCL INFO DMA-BUF is available on GPU device 3
18: nid005911:38866:39421 [2] NCCL INFO DMA-BUF is available on GPU device 2
18: nid005911:38867:38867 [3] NCCL INFO cudaDriverVersion 12060
18: nid005911:38867:38867 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to hsn
18: nid005911:38867:38867 [3] NCCL INFO Bootstrap : Using hsn0:172.28.23.68<0>
18: nid005911:38867:38867 [3] NCCL INFO NCCL version 2.22.3+cuda12.6
 4: nid005581:264525:265067 [2] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
 4: nid005581:264525:265067 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
 4: nid005581:264525:265067 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
 4: nid005581:264525:265067 [2] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
 4: nid005581:264525:265067 [2] NCCL INFO NET/OFI Using Libfabric version 1.22
 4: nid005581:264525:265067 [2] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
 4: 
 4: nid005581:264525:265067 [2] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
 4: nid005581:264525:265067 [2] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
 4: nid005581:264525:265067 [2] NCCL INFO NET/OFI Using transport protocol SENDRECV
 4: nid005581:264525:265067 [2] NCCL INFO NET/OFI Creating one domain per process
 4: nid005581:264525:265067 [2] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
 4: nid005581:264525:265067 [2] NCCL INFO NET/OFI Support for global registrations: false
 4: nid005581:264525:265067 [2] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
 4: nid005581:264525:265067 [2] NCCL INFO Using network AWS Libfabric
18: nid005911:38867:39424 [3] NCCL INFO NET/Plugin: Plugin name set by env to libnccl-net-ofi.so
18: nid005911:38867:39424 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.
18: nid005911:38867:39424 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.
18: nid005911:38867:39424 [3] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.14.0
18: nid005911:38867:39424 [3] NCCL INFO NET/OFI Using Libfabric version 1.22
18: nid005911:38867:39424 [3] NCCL INFO NET/OFI Using CUDA driver version 12060 with runtime 12060
18: 
18: nid005911:38867:39424 [3] nccl_net_ofi_rdma_init:7978 NCCL WARN NET/OFI OFI fi_getinfo() call failed: No data available
18: nid005911:38867:39424 [3] NCCL INFO NET/OFI Selected provider is cxi, fabric is cxi (found 4 nics)
18: nid005911:38867:39424 [3] NCCL INFO NET/OFI Using transport protocol SENDRECV
18: nid005911:38867:39424 [3] NCCL INFO NET/OFI Creating one domain per process
18: nid005911:38867:39424 [3] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR
18: nid005911:38867:39424 [3] NCCL INFO NET/OFI Support for global registrations: false
18: nid005911:38867:39424 [3] NCCL INFO NET/OFI Support for DMA-BUF registrations: false
18: nid005911:38867:39424 [3] NCCL INFO Using network AWS Libfabric
14: nid005600:217723:218244 [3] NCCL INFO DMA-BUF is available on GPU device 3
31: nid005937:256590:257125 [1] NCCL INFO DMA-BUF is available on GPU device 1
 8: nid005586:68929:69489 [3] NCCL INFO DMA-BUF is available on GPU device 3
20: nid005913:292683:293201 [2] NCCL INFO DMA-BUF is available on GPU device 2
 6: nid005584:28288:28820 [3] NCCL INFO DMA-BUF is available on GPU device 3
 4: nid005581:264525:265067 [2] NCCL INFO DMA-BUF is available on GPU device 2
18: nid005911:38867:39424 [3] NCCL INFO DMA-BUF is available on GPU device 3
29: nid005932:167682:168229 [2] NCCL INFO DMA-BUF is available on GPU device 2
29: nid005932:167681:168228 [1] NCCL INFO DMA-BUF is available on GPU device 1
29: nid005932:167683:168230 [3] NCCL INFO DMA-BUF is available on GPU device 3
24: nid005918:92507:93078 [3] NCCL INFO DMA-BUF is available on GPU device 3
24: nid005918:92505:93080 [1] NCCL INFO DMA-BUF is available on GPU device 1
24: nid005918:92506:93079 [2] NCCL INFO DMA-BUF is available on GPU device 2
26: nid005920:67126:67661 [3] NCCL INFO ncclCommInitRank comm 0xaaab209d4590 rank 107 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 commId 0x1958874c5d2a0126 - Init START
26: nid005920:67125:67662 [2] NCCL INFO ncclCommInitRank comm 0xaaaaf841bf30 rank 106 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 commId 0x1958874c5d2a0126 - Init START
27: nid005922:80743:81258 [2] NCCL INFO ncclCommInitRank comm 0xaaab0b1de990 rank 110 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 commId 0x1958874c5d2a0126 - Init START
27: nid005922:80741:81228 [0] NCCL INFO ncclCommInitRank comm 0xaaab18560ec0 rank 108 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 commId 0x1958874c5d2a0126 - Init START
27: nid005922:80742:81229 [1] NCCL INFO ncclCommInitRank comm 0xaaab00b73210 rank 109 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 commId 0x1958874c5d2a0126 - Init START
26: nid005920:67124:67660 [1] NCCL INFO ncclCommInitRank comm 0xaaab0de132b0 rank 105 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 commId 0x1958874c5d2a0126 - Init START
27: nid005922:80744:81259 [3] NCCL INFO ncclCommInitRank comm 0xaaaabb7ab7a0 rank 111 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 commId 0x1958874c5d2a0126 - Init START
26: nid005920:67123:67613 [0] NCCL INFO ncclCommInitRank comm 0xaaab021f2d20 rank 104 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 commId 0x1958874c5d2a0126 - Init START
28: nid005929:16030:16526 [0] NCCL INFO ncclCommInitRank comm 0xaaaad57d3fc0 rank 112 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 commId 0x1958874c5d2a0126 - Init START
28: nid005929:16031:16569 [1] NCCL INFO ncclCommInitRank comm 0xaaaaf8401170 rank 113 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 commId 0x1958874c5d2a0126 - Init START
28: nid005929:16033:16573 [3] NCCL INFO ncclCommInitRank comm 0xaaaade0c3510 rank 115 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 commId 0x1958874c5d2a0126 - Init START
28: nid005929:16032:16570 [2] NCCL INFO ncclCommInitRank comm 0xaaab2fba3240 rank 114 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 commId 0x1958874c5d2a0126 - Init START
25: nid005919:107464:108003 [2] NCCL INFO ncclCommInitRank comm 0xaaab1682a750 rank 102 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 commId 0x1958874c5d2a0126 - Init START
25: nid005919:107465:108002 [3] NCCL INFO ncclCommInitRank comm 0xaaaad4543ad0 rank 103 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 commId 0x1958874c5d2a0126 - Init START
29: nid005932:167681:168228 [1] NCCL INFO ncclCommInitRank comm 0xaaaac3b4db00 rank 117 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 commId 0x1958874c5d2a0126 - Init START
29: nid005932:167680:168169 [0] NCCL INFO ncclCommInitRank comm 0xaaab03ee4fa0 rank 116 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 commId 0x1958874c5d2a0126 - Init START
29: nid005932:167683:168230 [3] NCCL INFO ncclCommInitRank comm 0xaaab0adabbc0 rank 119 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 commId 0x1958874c5d2a0126 - Init START
25: nid005919:107463:108001 [1] NCCL INFO ncclCommInitRank comm 0xaaaaf8221890 rank 101 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 commId 0x1958874c5d2a0126 - Init START
29: nid005932:167682:168229 [2] NCCL INFO ncclCommInitRank comm 0xaaab2bddcec0 rank 118 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 commId 0x1958874c5d2a0126 - Init START
31: nid005937:256590:257125 [1] NCCL INFO ncclCommInitRank comm 0xaaab10443c40 rank 125 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 commId 0x1958874c5d2a0126 - Init START
31: nid005937:256589:256847 [0] NCCL INFO ncclCommInitRank comm 0xaaab2c295d90 rank 124 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 commId 0x1958874c5d2a0126 - Init START
30: nid005936:49908:50465 [0] NCCL INFO ncclCommInitRank comm 0xaaaafc2a9750 rank 120 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 commId 0x1958874c5d2a0126 - Init START
30: nid005936:49910:50467 [2] NCCL INFO ncclCommInitRank comm 0xaaaad8cb00f0 rank 122 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 commId 0x1958874c5d2a0126 - Init START
30: nid005936:49909:50450 [1] NCCL INFO ncclCommInitRank comm 0xaaaacaa5c1a0 rank 121 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 commId 0x1958874c5d2a0126 - Init START
30: nid005936:49911:50449 [3] NCCL INFO ncclCommInitRank comm 0xaaaad877afc0 rank 123 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 commId 0x1958874c5d2a0126 - Init START
24: nid005918:92507:93078 [3] NCCL INFO ncclCommInitRank comm 0xaaaae09e21b0 rank 99 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 commId 0x1958874c5d2a0126 - Init START
24: nid005918:92506:93079 [2] NCCL INFO ncclCommInitRank comm 0xaaab22641a60 rank 98 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 commId 0x1958874c5d2a0126 - Init START
25: nid005919:107462:107959 [0] NCCL INFO ncclCommInitRank comm 0xaaab262294f0 rank 100 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 commId 0x1958874c5d2a0126 - Init START
31: nid005937:256591:257123 [2] NCCL INFO ncclCommInitRank comm 0xaaaafcfbaf70 rank 126 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 commId 0x1958874c5d2a0126 - Init START
 0: nid005574:69061:69602 [3] NCCL INFO ncclCommInitRank comm 0xaaaad3e5bbc0 rank 3 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 commId 0x1958874c5d2a0126 - Init START
 0: nid005574:69060:69600 [2] NCCL INFO ncclCommInitRank comm 0xaaaaedbf8c70 rank 2 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 commId 0x1958874c5d2a0126 - Init START
 0: nid005574:69059:69601 [1] NCCL INFO ncclCommInitRank comm 0xaaaad1289f50 rank 1 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 commId 0x1958874c5d2a0126 - Init START
31: nid005937:256592:257124 [3] NCCL INFO ncclCommInitRank comm 0xaaaaedf436d0 rank 127 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 commId 0x1958874c5d2a0126 - Init START
24: nid005918:92505:93080 [1] NCCL INFO ncclCommInitRank comm 0xaaab23b3bb80 rank 97 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 commId 0x1958874c5d2a0126 - Init START
 0: nid005574:69058:69552 [0] NCCL INFO ncclCommInitRank comm 0xaaab0113f7d0 rank 0 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 commId 0x1958874c5d2a0126 - Init START
24: nid005918:92504:93029 [0] NCCL INFO ncclCommInitRank comm 0xaaaaf3895ae0 rank 96 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 commId 0x1958874c5d2a0126 - Init START
23: nid005917:276888:277422 [3] NCCL INFO ncclCommInitRank comm 0xaaaaf34fa080 rank 95 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 commId 0x1958874c5d2a0126 - Init START
 1: nid005576:147559:148101 [2] NCCL INFO ncclCommInitRank comm 0xaaab1c4d2400 rank 6 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 commId 0x1958874c5d2a0126 - Init START
 1: nid005576:147560:148100 [3] NCCL INFO ncclCommInitRank comm 0xaaaaea94c330 rank 7 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 commId 0x1958874c5d2a0126 - Init START
 1: nid005576:147558:148070 [1] NCCL INFO ncclCommInitRank comm 0xaaaaf8e03070 rank 5 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 commId 0x1958874c5d2a0126 - Init START
 1: nid005576:147557:148053 [0] NCCL INFO ncclCommInitRank comm 0xaaab2078f8e0 rank 4 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 commId 0x1958874c5d2a0126 - Init START
23: nid005917:276887:277420 [2] NCCL INFO ncclCommInitRank comm 0xaaaaf1b2b6f0 rank 94 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 commId 0x1958874c5d2a0126 - Init START
 2: nid005577:17425:17981 [3] NCCL INFO ncclCommInitRank comm 0xaaab1accc2e0 rank 11 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 commId 0x1958874c5d2a0126 - Init START
 2: nid005577:17424:17982 [2] NCCL INFO ncclCommInitRank comm 0xaaaaec29b7f0 rank 10 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 commId 0x1958874c5d2a0126 - Init START
 2: nid005577:17423:17952 [1] NCCL INFO ncclCommInitRank comm 0xaaaaf479b750 rank 9 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 commId 0x1958874c5d2a0126 - Init START
 2: nid005577:17422:17953 [0] NCCL INFO ncclCommInitRank comm 0xaaaaf334fcf0 rank 8 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 commId 0x1958874c5d2a0126 - Init START
 3: nid005580:71819:72290 [0] NCCL INFO ncclCommInitRank comm 0xaaab065e8c10 rank 12 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 commId 0x1958874c5d2a0126 - Init START
 3: nid005580:71821:72339 [2] NCCL INFO ncclCommInitRank comm 0xaaaada12b8c0 rank 14 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 commId 0x1958874c5d2a0126 - Init START
23: nid005917:276886:277419 [1] NCCL INFO ncclCommInitRank comm 0xaaab0f582930 rank 93 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 commId 0x1958874c5d2a0126 - Init START
22: nid005915:274817:275333 [3] NCCL INFO ncclCommInitRank comm 0xaaab11483950 rank 91 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 commId 0x1958874c5d2a0126 - Init START
22: nid005915:274816:275334 [2] NCCL INFO ncclCommInitRank comm 0xaaaafe3ab720 rank 90 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 commId 0x1958874c5d2a0126 - Init START
23: nid005917:276885:277421 [0] NCCL INFO ncclCommInitRank comm 0xaaaae40fdd90 rank 92 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 commId 0x1958874c5d2a0126 - Init START
22: nid005915:274815:275332 [1] NCCL INFO ncclCommInitRank comm 0xaaab0ea2ac20 rank 89 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 commId 0x1958874c5d2a0126 - Init START
 4: nid005581:264525:265067 [2] NCCL INFO ncclCommInitRank comm 0xaaaaf1142f20 rank 18 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 commId 0x1958874c5d2a0126 - Init START
 4: nid005581:264526:265063 [3] NCCL INFO ncclCommInitRank comm 0xaaaae8963db0 rank 19 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 commId 0x1958874c5d2a0126 - Init START
 3: nid005580:71820:72338 [1] NCCL INFO ncclCommInitRank comm 0xaaaac543b4a0 rank 13 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 commId 0x1958874c5d2a0126 - Init START
 4: nid005581:264523:265016 [0] NCCL INFO ncclCommInitRank comm 0xaaaafba8b880 rank 16 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 commId 0x1958874c5d2a0126 - Init START
 3: nid005580:71822:72337 [3] NCCL INFO ncclCommInitRank comm 0xaaab06b93260 rank 15 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 commId 0x1958874c5d2a0126 - Init START
22: nid005915:274814:275290 [0] NCCL INFO ncclCommInitRank comm 0xaaaad1683e90 rank 88 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 commId 0x1958874c5d2a0126 - Init START
 4: nid005581:264524:265064 [1] NCCL INFO ncclCommInitRank comm 0xaaaad9b8a440 rank 17 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 commId 0x1958874c5d2a0126 - Init START
21: nid005914:166787:167300 [3] NCCL INFO ncclCommInitRank comm 0xaaaadea21c50 rank 87 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 commId 0x1958874c5d2a0126 - Init START
21: nid005914:166786:167270 [2] NCCL INFO ncclCommInitRank comm 0xaaab02d82db0 rank 86 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 commId 0x1958874c5d2a0126 - Init START
 6: nid005584:28285:28774 [0] NCCL INFO ncclCommInitRank comm 0xaaaafc6efb40 rank 24 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 commId 0x1958874c5d2a0126 - Init START
 6: nid005584:28288:28820 [3] NCCL INFO ncclCommInitRank comm 0xaaaaf69fb200 rank 27 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 commId 0x1958874c5d2a0126 - Init START
 5: nid005582:196715:197387 [2] NCCL INFO ncclCommInitRank comm 0xaaaaeab5be10 rank 22 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 commId 0x1958874c5d2a0126 - Init START
 5: nid005582:196714:197386 [1] NCCL INFO ncclCommInitRank comm 0xaaab201019a0 rank 21 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 commId 0x1958874c5d2a0126 - Init START
 5: nid005582:196713:197389 [0] NCCL INFO ncclCommInitRank comm 0xaaab12118df0 rank 20 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 commId 0x1958874c5d2a0126 - Init START
 6: nid005584:28286:28818 [1] NCCL INFO ncclCommInitRank comm 0xaaab2173c180 rank 25 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 commId 0x1958874c5d2a0126 - Init START
 6: nid005584:28287:28819 [2] NCCL INFO ncclCommInitRank comm 0xaaab07a0c730 rank 26 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 commId 0x1958874c5d2a0126 - Init START
 7: nid005585:122008:122545 [3] NCCL INFO ncclCommInitRank comm 0xaaaaedf73db0 rank 31 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 commId 0x1958874c5d2a0126 - Init START
 7: nid005585:122005:122496 [0] NCCL INFO ncclCommInitRank comm 0xaaab166fca20 rank 28 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 commId 0x1958874c5d2a0126 - Init START
 5: nid005582:196716:197388 [3] NCCL INFO ncclCommInitRank comm 0xaaab1215f930 rank 23 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 commId 0x1958874c5d2a0126 - Init START
21: nid005914:166785:167301 [1] NCCL INFO ncclCommInitRank comm 0xaaaaf1392a50 rank 85 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 commId 0x1958874c5d2a0126 - Init START
21: nid005914:166784:167271 [0] NCCL INFO ncclCommInitRank comm 0xaaab092dcbd0 rank 84 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 commId 0x1958874c5d2a0126 - Init START
 9: nid005588:35937:36471 [2] NCCL INFO ncclCommInitRank comm 0xaaaae8a0c3a0 rank 38 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 commId 0x1958874c5d2a0126 - Init START
 9: nid005588:35938:36474 [3] NCCL INFO ncclCommInitRank comm 0xaaaadbd50910 rank 39 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 commId 0x1958874c5d2a0126 - Init START
 9: nid005588:35936:36472 [1] NCCL INFO ncclCommInitRank comm 0xaaab298ab220 rank 37 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 commId 0x1958874c5d2a0126 - Init START
 7: nid005585:122006:122526 [1] NCCL INFO ncclCommInitRank comm 0xaaab0e87b260 rank 29 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 commId 0x1958874c5d2a0126 - Init START
 7: nid005585:122007:122527 [2] NCCL INFO ncclCommInitRank comm 0xaaaadd869ba0 rank 30 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 commId 0x1958874c5d2a0126 - Init START
20: nid005913:292684:293199 [3] NCCL INFO ncclCommInitRank comm 0xaaaae94038c0 rank 83 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 commId 0x1958874c5d2a0126 - Init START
20: nid005913:292683:293201 [2] NCCL INFO ncclCommInitRank comm 0xaaaaf0f2a8d0 rank 82 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 commId 0x1958874c5d2a0126 - Init START
 9: nid005588:35935:36428 [0] NCCL INFO ncclCommInitRank comm 0xaaab148fdb70 rank 36 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 commId 0x1958874c5d2a0126 - Init START
20: nid005913:292681:293089 [0] NCCL INFO ncclCommInitRank comm 0xaaab2e755bf0 rank 80 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 commId 0x1958874c5d2a0126 - Init START
18: nid005911:38867:39424 [3] NCCL INFO ncclCommInitRank comm 0xaaab31f11170 rank 75 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 commId 0x1958874c5d2a0126 - Init START
19: nid005912:12437:12976 [2] NCCL INFO ncclCommInitRank comm 0xaaaaec4bb890 rank 78 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 commId 0x1958874c5d2a0126 - Init START
19: nid005912:12438:12958 [3] NCCL INFO ncclCommInitRank comm 0xaaaae3c43340 rank 79 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 commId 0x1958874c5d2a0126 - Init START
20: nid005913:292682:293200 [1] NCCL INFO ncclCommInitRank comm 0xaaaaf6e99730 rank 81 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 commId 0x1958874c5d2a0126 - Init START
19: nid005912:12436:12959 [1] NCCL INFO ncclCommInitRank comm 0xaaaaeb758490 rank 77 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 commId 0x1958874c5d2a0126 - Init START
19: nid005912:12435:12909 [0] NCCL INFO ncclCommInitRank comm 0xaaab04d29d70 rank 76 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 commId 0x1958874c5d2a0126 - Init START
13: nid005595:197886:198472 [3] NCCL INFO ncclCommInitRank comm 0xaaaaea46b560 rank 55 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 commId 0x1958874c5d2a0126 - Init START
13: nid005595:197885:198470 [2] NCCL INFO ncclCommInitRank comm 0xaaab3c8b15f0 rank 54 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 commId 0x1958874c5d2a0126 - Init START
13: nid005595:197884:198471 [1] NCCL INFO ncclCommInitRank comm 0xaaab0cbd2c40 rank 53 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 commId 0x1958874c5d2a0126 - Init START
10: nid005590:110710:111197 [0] NCCL INFO ncclCommInitRank comm 0xaaab23d6b530 rank 40 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 commId 0x1958874c5d2a0126 - Init START
 8: nid005586:68929:69489 [3] NCCL INFO ncclCommInitRank comm 0xaaab0425a760 rank 35 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 commId 0x1958874c5d2a0126 - Init START
 8: nid005586:68928:69450 [2] NCCL INFO ncclCommInitRank comm 0xaaaaf16101a0 rank 34 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 commId 0x1958874c5d2a0126 - Init START
 8: nid005586:68927:69451 [1] NCCL INFO ncclCommInitRank comm 0xaaaaec21b350 rank 33 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 commId 0x1958874c5d2a0126 - Init START
 8: nid005586:68926:69401 [0] NCCL INFO ncclCommInitRank comm 0xaaab12790160 rank 32 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 commId 0x1958874c5d2a0126 - Init START
10: nid005590:110712:111243 [2] NCCL INFO ncclCommInitRank comm 0xaaab104db470 rank 42 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 commId 0x1958874c5d2a0126 - Init START
10: nid005590:110711:111241 [1] NCCL INFO ncclCommInitRank comm 0xaaab10df3460 rank 41 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 commId 0x1958874c5d2a0126 - Init START
16: nid005802:6300:6899 [3] NCCL INFO ncclCommInitRank comm 0xaaaae402b650 rank 67 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 commId 0x1958874c5d2a0126 - Init START
16: nid005802:6299:6898 [2] NCCL INFO ncclCommInitRank comm 0xaaab08f00a50 rank 66 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 commId 0x1958874c5d2a0126 - Init START
11: nid005591:191604:192145 [1] NCCL INFO ncclCommInitRank comm 0xaaab196cb950 rank 45 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 commId 0x1958874c5d2a0126 - Init START
11: nid005591:191603:192099 [0] NCCL INFO ncclCommInitRank comm 0xaaaaf7916bf0 rank 44 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 commId 0x1958874c5d2a0126 - Init START
12: nid005594:53087:53607 [2] NCCL INFO ncclCommInitRank comm 0xaaab36e31f10 rank 50 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 commId 0x1958874c5d2a0126 - Init START
12: nid005594:53085:53561 [0] NCCL INFO ncclCommInitRank comm 0xaaab0e435340 rank 48 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 commId 0x1958874c5d2a0126 - Init START
12: nid005594:53086:53606 [1] NCCL INFO ncclCommInitRank comm 0xaaaadbafb110 rank 49 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 commId 0x1958874c5d2a0126 - Init START
12: nid005594:53088:53605 [3] NCCL INFO ncclCommInitRank comm 0xaaab14e02fb0 rank 51 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 commId 0x1958874c5d2a0126 - Init START
10: nid005590:110713:111240 [3] NCCL INFO ncclCommInitRank comm 0xaaab375e3b60 rank 43 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 commId 0x1958874c5d2a0126 - Init START
15: nid005601:210678:211209 [2] NCCL INFO ncclCommInitRank comm 0xaaab22984300 rank 62 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 commId 0x1958874c5d2a0126 - Init START
15: nid005601:210679:211194 [3] NCCL INFO ncclCommInitRank comm 0xaaab0b2c3130 rank 63 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 commId 0x1958874c5d2a0126 - Init START
11: nid005591:191606:192116 [3] NCCL INFO ncclCommInitRank comm 0xaaaae7d03880 rank 47 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 commId 0x1958874c5d2a0126 - Init START
11: nid005591:191605:192144 [2] NCCL INFO ncclCommInitRank comm 0xaaaafb513f80 rank 46 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 commId 0x1958874c5d2a0126 - Init START
17: nid005803:180735:181265 [3] NCCL INFO ncclCommInitRank comm 0xaaab10aa06b0 rank 71 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 commId 0x1958874c5d2a0126 - Init START
15: nid005601:210677:211211 [1] NCCL INFO ncclCommInitRank comm 0xaaaaee59b4c0 rank 61 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 commId 0x1958874c5d2a0126 - Init START
15: nid005601:210676:211210 [0] NCCL INFO ncclCommInitRank comm 0xaaab05fd2fb0 rank 60 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 commId 0x1958874c5d2a0126 - Init START
17: nid005803:180734:181263 [2] NCCL INFO ncclCommInitRank comm 0xaaab0a6d9870 rank 70 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 commId 0x1958874c5d2a0126 - Init START
18: nid005911:38865:39420 [1] NCCL INFO ncclCommInitRank comm 0xaaaae2c31590 rank 73 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 commId 0x1958874c5d2a0126 - Init START
18: nid005911:38864:39357 [0] NCCL INFO ncclCommInitRank comm 0xaaaade95adc0 rank 72 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 commId 0x1958874c5d2a0126 - Init START
18: nid005911:38866:39421 [2] NCCL INFO ncclCommInitRank comm 0xaaaafa2a9ac0 rank 74 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 commId 0x1958874c5d2a0126 - Init START
17: nid005803:180733:181262 [1] NCCL INFO ncclCommInitRank comm 0xaaab1f57afc0 rank 69 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 commId 0x1958874c5d2a0126 - Init START
17: nid005803:180732:181264 [0] NCCL INFO ncclCommInitRank comm 0xaaaad12a2680 rank 68 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 commId 0x1958874c5d2a0126 - Init START
16: nid005802:6298:6897 [1] NCCL INFO ncclCommInitRank comm 0xaaab06e0b4f0 rank 65 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 commId 0x1958874c5d2a0126 - Init START
13: nid005595:197883:198429 [0] NCCL INFO ncclCommInitRank comm 0xaaab1fa69360 rank 52 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 commId 0x1958874c5d2a0126 - Init START
16: nid005802:6297:6852 [0] NCCL INFO ncclCommInitRank comm 0xaaab18b83d10 rank 64 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 commId 0x1958874c5d2a0126 - Init START
14: nid005600:217723:218244 [3] NCCL INFO ncclCommInitRank comm 0xaaab2a979520 rank 59 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 commId 0x1958874c5d2a0126 - Init START
14: nid005600:217722:218227 [2] NCCL INFO ncclCommInitRank comm 0xaaaada11bcd0 rank 58 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 commId 0x1958874c5d2a0126 - Init START
14: nid005600:217721:218228 [1] NCCL INFO ncclCommInitRank comm 0xaaaacda93d30 rank 57 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 commId 0x1958874c5d2a0126 - Init START
14: nid005600:217720:218195 [0] NCCL INFO ncclCommInitRank comm 0xaaaadc9bcbc0 rank 56 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 commId 0x1958874c5d2a0126 - Init START
22: nid005915:274817:275333 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff,ff000000,00000000,00000000,00000000,00000000,00000000,00000000
 9: nid005588:35937:36471 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,ffffffff,ffff0000,00000000,00000000,00000000,00000000
22: nid005915:274817:275333 [3] NCCL INFO NVLS multicast support is not available on dev 3
22: nid005915:274817:275333 [3] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
 9: nid005588:35937:36471 [2] NCCL INFO NVLS multicast support is not available on dev 2
 9: nid005588:35937:36471 [2] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
 9: nid005588:35936:36472 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,ffffff00,00000000,00000000
 9: nid005588:35936:36472 [1] NCCL INFO NVLS multicast support is not available on dev 1
 9: nid005588:35936:36472 [1] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
22: nid005915:274816:275334 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,ffffffff,ffff0000,00000000,00000000,00000000,00000000
 9: nid005588:35935:36428 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff,ffffffff
 5: nid005582:196715:197387 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,ffffffff,ffff0000,00000000,00000000,00000000,00000000
 5: nid005582:196715:197387 [2] NCCL INFO NVLS multicast support is not available on dev 2
 5: nid005582:196715:197387 [2] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
 9: nid005588:35935:36428 [0] NCCL INFO NVLS multicast support is not available on dev 0
 5: nid005582:196714:197386 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,ffffff00,00000000,00000000
22: nid005915:274816:275334 [2] NCCL INFO NVLS multicast support is not available on dev 2
22: nid005915:274816:275334 [2] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
 9: nid005588:35935:36428 [0] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
 5: nid005582:196714:197386 [1] NCCL INFO NVLS multicast support is not available on dev 1
 5: nid005582:196714:197386 [1] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
 5: nid005582:196713:197389 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff,ffffffff
 5: nid005582:196716:197388 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff,ff000000,00000000,00000000,00000000,00000000,00000000,00000000
 9: nid005588:35938:36474 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff,ff000000,00000000,00000000,00000000,00000000,00000000,00000000
 5: nid005582:196716:197388 [3] NCCL INFO NVLS multicast support is not available on dev 3
 5: nid005582:196716:197388 [3] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
 9: nid005588:35938:36474 [3] NCCL INFO NVLS multicast support is not available on dev 3
 5: nid005582:196713:197389 [0] NCCL INFO NVLS multicast support is not available on dev 0
 0: nid005574:69060:69600 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,ffffffff,ffff0000,00000000,00000000,00000000,00000000
 0: nid005574:69061:69602 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff,ff000000,00000000,00000000,00000000,00000000,00000000,00000000
 9: nid005588:35938:36474 [3] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
 5: nid005582:196713:197389 [0] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
22: nid005915:274815:275332 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,ffffff00,00000000,00000000
 0: nid005574:69061:69602 [3] NCCL INFO NVLS multicast support is not available on dev 3
 0: nid005574:69060:69600 [2] NCCL INFO NVLS multicast support is not available on dev 2
 0: nid005574:69061:69602 [3] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
22: nid005915:274814:275290 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff,ffffffff
 0: nid005574:69060:69600 [2] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
22: nid005915:274815:275332 [1] NCCL INFO NVLS multicast support is not available on dev 1
22: nid005915:274815:275332 [1] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
 0: nid005574:69059:69601 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,ffffff00,00000000,00000000
 0: nid005574:69059:69601 [1] NCCL INFO NVLS multicast support is not available on dev 1
 0: nid005574:69059:69601 [1] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
 0: nid005574:69058:69552 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff,ffffffff
22: nid005915:274814:275290 [0] NCCL INFO NVLS multicast support is not available on dev 0
22: nid005915:274814:275290 [0] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
 0: nid005574:69058:69552 [0] NCCL INFO NVLS multicast support is not available on dev 0
 0: nid005574:69058:69552 [0] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
31: nid005937:256590:257125 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,ffffff00,00000000,00000000
31: nid005937:256590:257125 [1] NCCL INFO NVLS multicast support is not available on dev 1
31: nid005937:256590:257125 [1] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
31: nid005937:256589:256847 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff,ffffffff
31: nid005937:256589:256847 [0] NCCL INFO NVLS multicast support is not available on dev 0
31: nid005937:256589:256847 [0] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
31: nid005937:256591:257123 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,ffffffff,ffff0000,00000000,00000000,00000000,00000000
31: nid005937:256592:257124 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff,ff000000,00000000,00000000,00000000,00000000,00000000,00000000
31: nid005937:256591:257123 [2] NCCL INFO NVLS multicast support is not available on dev 2
31: nid005937:256591:257123 [2] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
31: nid005937:256592:257124 [3] NCCL INFO NVLS multicast support is not available on dev 3
31: nid005937:256592:257124 [3] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
 6: nid005584:28285:28774 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff,ffffffff
 6: nid005584:28285:28774 [0] NCCL INFO NVLS multicast support is not available on dev 0
 6: nid005584:28285:28774 [0] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
 6: nid005584:28288:28820 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff,ff000000,00000000,00000000,00000000,00000000,00000000,00000000
 6: nid005584:28288:28820 [3] NCCL INFO NVLS multicast support is not available on dev 3
 6: nid005584:28288:28820 [3] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
 6: nid005584:28287:28819 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,ffffffff,ffff0000,00000000,00000000,00000000,00000000
 6: nid005584:28287:28819 [2] NCCL INFO NVLS multicast support is not available on dev 2
 6: nid005584:28287:28819 [2] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
 6: nid005584:28286:28818 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,ffffff00,00000000,00000000
 6: nid005584:28286:28818 [1] NCCL INFO NVLS multicast support is not available on dev 1
 6: nid005584:28286:28818 [1] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
20: nid005913:292684:293199 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff,ff000000,00000000,00000000,00000000,00000000,00000000,00000000
20: nid005913:292681:293089 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff,ffffffff
20: nid005913:292684:293199 [3] NCCL INFO NVLS multicast support is not available on dev 3
20: nid005913:292684:293199 [3] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
20: nid005913:292681:293089 [0] NCCL INFO NVLS multicast support is not available on dev 0
20: nid005913:292681:293089 [0] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
20: nid005913:292683:293201 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,ffffffff,ffff0000,00000000,00000000,00000000,00000000
23: nid005917:276885:277421 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff,ffffffff
20: nid005913:292683:293201 [2] NCCL INFO NVLS multicast support is not available on dev 2
20: nid005913:292682:293200 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,ffffff00,00000000,00000000
23: nid005917:276887:277420 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,ffffffff,ffff0000,00000000,00000000,00000000,00000000
20: nid005913:292683:293201 [2] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
20: nid005913:292682:293200 [1] NCCL INFO NVLS multicast support is not available on dev 1
23: nid005917:276885:277421 [0] NCCL INFO NVLS multicast support is not available on dev 0
20: nid005913:292682:293200 [1] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
23: nid005917:276885:277421 [0] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
23: nid005917:276888:277422 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff,ff000000,00000000,00000000,00000000,00000000,00000000,00000000
23: nid005917:276886:277419 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,ffffff00,00000000,00000000
23: nid005917:276887:277420 [2] NCCL INFO NVLS multicast support is not available on dev 2
23: nid005917:276887:277420 [2] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
23: nid005917:276888:277422 [3] NCCL INFO NVLS multicast support is not available on dev 3
23: nid005917:276886:277419 [1] NCCL INFO NVLS multicast support is not available on dev 1
23: nid005917:276888:277422 [3] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
23: nid005917:276886:277419 [1] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
11: nid005591:191603:192099 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff,ffffffff
11: nid005591:191603:192099 [0] NCCL INFO NVLS multicast support is not available on dev 0
11: nid005591:191603:192099 [0] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
11: nid005591:191604:192145 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,ffffff00,00000000,00000000
30: nid005936:49909:50450 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,ffffff00,00000000,00000000
30: nid005936:49909:50450 [1] NCCL INFO NVLS multicast support is not available on dev 1
30: nid005936:49909:50450 [1] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
30: nid005936:49911:50449 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff,ff000000,00000000,00000000,00000000,00000000,00000000,00000000
30: nid005936:49911:50449 [3] NCCL INFO NVLS multicast support is not available on dev 3
30: nid005936:49911:50449 [3] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
14: nid005600:217723:218244 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff,ff000000,00000000,00000000,00000000,00000000,00000000,00000000
30: nid005936:49910:50467 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,ffffffff,ffff0000,00000000,00000000,00000000,00000000
30: nid005936:49910:50467 [2] NCCL INFO NVLS multicast support is not available on dev 2
30: nid005936:49910:50467 [2] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
14: nid005600:217723:218244 [3] NCCL INFO NVLS multicast support is not available on dev 3
14: nid005600:217723:218244 [3] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
30: nid005936:49908:50465 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff,ffffffff
14: nid005600:217722:218227 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,ffffffff,ffff0000,00000000,00000000,00000000,00000000
14: nid005600:217722:218227 [2] NCCL INFO NVLS multicast support is not available on dev 2
30: nid005936:49908:50465 [0] NCCL INFO NVLS multicast support is not available on dev 0
14: nid005600:217722:218227 [2] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
10: nid005590:110713:111240 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff,ff000000,00000000,00000000,00000000,00000000,00000000,00000000
10: nid005590:110710:111197 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff,ffffffff
10: nid005590:110713:111240 [3] NCCL INFO NVLS multicast support is not available on dev 3
10: nid005590:110713:111240 [3] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
10: nid005590:110710:111197 [0] NCCL INFO NVLS multicast support is not available on dev 0
10: nid005590:110710:111197 [0] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
10: nid005590:110711:111241 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,ffffff00,00000000,00000000
14: nid005600:217721:218228 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,ffffff00,00000000,00000000
14: nid005600:217721:218228 [1] NCCL INFO NVLS multicast support is not available on dev 1
14: nid005600:217721:218228 [1] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
10: nid005590:110712:111243 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,ffffffff,ffff0000,00000000,00000000,00000000,00000000
10: nid005590:110711:111241 [1] NCCL INFO NVLS multicast support is not available on dev 1
10: nid005590:110711:111241 [1] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
10: nid005590:110712:111243 [2] NCCL INFO NVLS multicast support is not available on dev 2
10: nid005590:110712:111243 [2] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
15: nid005601:210679:211194 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff,ff000000,00000000,00000000,00000000,00000000,00000000,00000000
15: nid005601:210677:211211 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,ffffff00,00000000,00000000
15: nid005601:210679:211194 [3] NCCL INFO NVLS multicast support is not available on dev 3
15: nid005601:210679:211194 [3] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
15: nid005601:210677:211211 [1] NCCL INFO NVLS multicast support is not available on dev 1
15: nid005601:210678:211209 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,ffffffff,ffff0000,00000000,00000000,00000000,00000000
15: nid005601:210677:211211 [1] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
15: nid005601:210678:211209 [2] NCCL INFO NVLS multicast support is not available on dev 2
15: nid005601:210676:211210 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff,ffffffff
15: nid005601:210678:211209 [2] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
15: nid005601:210676:211210 [0] NCCL INFO NVLS multicast support is not available on dev 0
15: nid005601:210676:211210 [0] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
14: nid005600:217720:218195 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff,ffffffff
14: nid005600:217720:218195 [0] NCCL INFO NVLS multicast support is not available on dev 0
14: nid005600:217720:218195 [0] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
16: nid005802:6297:6852 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff,ffffffff
16: nid005802:6299:6898 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,ffffffff,ffff0000,00000000,00000000,00000000,00000000
16: nid005802:6299:6898 [2] NCCL INFO NVLS multicast support is not available on dev 2
16: nid005802:6299:6898 [2] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
16: nid005802:6300:6899 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff,ff000000,00000000,00000000,00000000,00000000,00000000,00000000
16: nid005802:6297:6852 [0] NCCL INFO NVLS multicast support is not available on dev 0
16: nid005802:6298:6897 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,ffffff00,00000000,00000000
16: nid005802:6298:6897 [1] NCCL INFO NVLS multicast support is not available on dev 1
16: nid005802:6298:6897 [1] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
16: nid005802:6300:6899 [3] NCCL INFO NVLS multicast support is not available on dev 3
16: nid005802:6300:6899 [3] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
16: nid005802:6297:6852 [0] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
 2: nid005577:17423:17952 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,ffffff00,00000000,00000000
 2: nid005577:17423:17952 [1] NCCL INFO NVLS multicast support is not available on dev 1
 2: nid005577:17423:17952 [1] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
 3: nid005580:71821:72339 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,ffffffff,ffff0000,00000000,00000000,00000000,00000000
 3: nid005580:71822:72337 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff,ff000000,00000000,00000000,00000000,00000000,00000000,00000000
 3: nid005580:71821:72339 [2] NCCL INFO NVLS multicast support is not available on dev 2
 3: nid005580:71821:72339 [2] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
 3: nid005580:71820:72338 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,ffffff00,00000000,00000000
 3: nid005580:71819:72290 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff,ffffffff
 3: nid005580:71822:72337 [3] NCCL INFO NVLS multicast support is not available on dev 3
 3: nid005580:71822:72337 [3] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
 3: nid005580:71820:72338 [1] NCCL INFO NVLS multicast support is not available on dev 1
 3: nid005580:71819:72290 [0] NCCL INFO NVLS multicast support is not available on dev 0
 3: nid005580:71820:72338 [1] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
 2: nid005577:17422:17953 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff,ffffffff
 3: nid005580:71819:72290 [0] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
 2: nid005577:17424:17982 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,ffffffff,ffff0000,00000000,00000000,00000000,00000000
 2: nid005577:17422:17953 [0] NCCL INFO NVLS multicast support is not available on dev 0
 2: nid005577:17424:17982 [2] NCCL INFO NVLS multicast support is not available on dev 2
 2: nid005577:17422:17953 [0] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
 2: nid005577:17424:17982 [2] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
 2: nid005577:17425:17981 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff,ff000000,00000000,00000000,00000000,00000000,00000000,00000000
 2: nid005577:17425:17981 [3] NCCL INFO NVLS multicast support is not available on dev 3
 2: nid005577:17425:17981 [3] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
13: nid005595:197886:198472 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff,ff000000,00000000,00000000,00000000,00000000,00000000,00000000
13: nid005595:197886:198472 [3] NCCL INFO NVLS multicast support is not available on dev 3
13: nid005595:197886:198472 [3] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
13: nid005595:197885:198470 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,ffffffff,ffff0000,00000000,00000000,00000000,00000000
13: nid005595:197884:198471 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,ffffff00,00000000,00000000
13: nid005595:197885:198470 [2] NCCL INFO NVLS multicast support is not available on dev 2
13: nid005595:197885:198470 [2] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
13: nid005595:197884:198471 [1] NCCL INFO NVLS multicast support is not available on dev 1
13: nid005595:197884:198471 [1] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
13: nid005595:197883:198429 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff,ffffffff
13: nid005595:197883:198429 [0] NCCL INFO NVLS multicast support is not available on dev 0
13: nid005595:197883:198429 [0] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
 7: nid005585:122008:122545 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff,ff000000,00000000,00000000,00000000,00000000,00000000,00000000
 7: nid005585:122008:122545 [3] NCCL INFO NVLS multicast support is not available on dev 3
 7: nid005585:122008:122545 [3] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
28: nid005929:16031:16569 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,ffffff00,00000000,00000000
 4: nid005581:264526:265063 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff,ff000000,00000000,00000000,00000000,00000000,00000000,00000000
25: nid005919:107462:107959 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff,ffffffff
 7: nid005585:122006:122526 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,ffffff00,00000000,00000000
28: nid005929:16031:16569 [1] NCCL INFO NVLS multicast support is not available on dev 1
 4: nid005581:264526:265063 [3] NCCL INFO NVLS multicast support is not available on dev 3
28: nid005929:16031:16569 [1] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
28: nid005929:16030:16526 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff,ffffffff
 4: nid005581:264526:265063 [3] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
 7: nid005585:122006:122526 [1] NCCL INFO NVLS multicast support is not available on dev 1
 7: nid005585:122005:122496 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff,ffffffff
25: nid005919:107462:107959 [0] NCCL INFO NVLS multicast support is not available on dev 0
28: nid005929:16032:16570 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,ffffffff,ffff0000,00000000,00000000,00000000,00000000
 7: nid005585:122006:122526 [1] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
25: nid005919:107462:107959 [0] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
28: nid005929:16030:16526 [0] NCCL INFO NVLS multicast support is not available on dev 0
25: nid005919:107465:108002 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff,ff000000,00000000,00000000,00000000,00000000,00000000,00000000
28: nid005929:16032:16570 [2] NCCL INFO NVLS multicast support is not available on dev 2
28: nid005929:16030:16526 [0] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
28: nid005929:16032:16570 [2] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
28: nid005929:16033:16573 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff,ff000000,00000000,00000000,00000000,00000000,00000000,00000000
 7: nid005585:122007:122527 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,ffffffff,ffff0000,00000000,00000000,00000000,00000000
 7: nid005585:122005:122496 [0] NCCL INFO NVLS multicast support is not available on dev 0
28: nid005929:16033:16573 [3] NCCL INFO NVLS multicast support is not available on dev 3
 7: nid005585:122005:122496 [0] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
28: nid005929:16033:16573 [3] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
18: nid005911:38865:39420 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,ffffff00,00000000,00000000
27: nid005922:80743:81258 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,ffffffff,ffff0000,00000000,00000000,00000000,00000000
 7: nid005585:122007:122527 [2] NCCL INFO NVLS multicast support is not available on dev 2
 4: nid005581:264525:265067 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,ffffffff,ffff0000,00000000,00000000,00000000,00000000
 4: nid005581:264525:265067 [2] NCCL INFO NVLS multicast support is not available on dev 2
18: nid005911:38866:39421 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,ffffffff,ffff0000,00000000,00000000,00000000,00000000
 4: nid005581:264525:265067 [2] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
 7: nid005585:122007:122527 [2] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
27: nid005922:80743:81258 [2] NCCL INFO NVLS multicast support is not available on dev 2
27: nid005922:80743:81258 [2] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
18: nid005911:38865:39420 [1] NCCL INFO NVLS multicast support is not available on dev 1
18: nid005911:38865:39420 [1] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
18: nid005911:38866:39421 [2] NCCL INFO NVLS multicast support is not available on dev 2
18: nid005911:38866:39421 [2] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
18: nid005911:38864:39357 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff,ffffffff
27: nid005922:80742:81229 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,ffffff00,00000000,00000000
18: nid005911:38867:39424 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff,ff000000,00000000,00000000,00000000,00000000,00000000,00000000
 4: nid005581:264523:265016 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff,ffffffff
18: nid005911:38864:39357 [0] NCCL INFO NVLS multicast support is not available on dev 0
18: nid005911:38864:39357 [0] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
27: nid005922:80741:81228 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff,ffffffff
27: nid005922:80744:81259 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff,ff000000,00000000,00000000,00000000,00000000,00000000,00000000
18: nid005911:38867:39424 [3] NCCL INFO NVLS multicast support is not available on dev 3
27: nid005922:80742:81229 [1] NCCL INFO NVLS multicast support is not available on dev 1
18: nid005911:38867:39424 [3] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
27: nid005922:80742:81229 [1] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
27: nid005922:80744:81259 [3] NCCL INFO NVLS multicast support is not available on dev 3
27: nid005922:80741:81228 [0] NCCL INFO NVLS multicast support is not available on dev 0
 4: nid005581:264523:265016 [0] NCCL INFO NVLS multicast support is not available on dev 0
27: nid005922:80744:81259 [3] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
27: nid005922:80741:81228 [0] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
 4: nid005581:264523:265016 [0] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
 4: nid005581:264524:265064 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,ffffff00,00000000,00000000
12: nid005594:53086:53606 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,ffffff00,00000000,00000000
12: nid005594:53087:53607 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,ffffffff,ffff0000,00000000,00000000,00000000,00000000
12: nid005594:53087:53607 [2] NCCL INFO NVLS multicast support is not available on dev 2
12: nid005594:53087:53607 [2] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
12: nid005594:53086:53606 [1] NCCL INFO NVLS multicast support is not available on dev 1
12: nid005594:53086:53606 [1] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
12: nid005594:53085:53561 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff,ffffffff
12: nid005594:53088:53605 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff,ff000000,00000000,00000000,00000000,00000000,00000000,00000000
12: nid005594:53085:53561 [0] NCCL INFO NVLS multicast support is not available on dev 0
12: nid005594:53085:53561 [0] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
12: nid005594:53088:53605 [3] NCCL INFO NVLS multicast support is not available on dev 3
12: nid005594:53088:53605 [3] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
21: nid005914:166787:167300 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff,ff000000,00000000,00000000,00000000,00000000,00000000,00000000
21: nid005914:166785:167301 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,ffffff00,00000000,00000000
21: nid005914:166785:167301 [1] NCCL INFO NVLS multicast support is not available on dev 1
21: nid005914:166785:167301 [1] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
21: nid005914:166787:167300 [3] NCCL INFO NVLS multicast support is not available on dev 3
21: nid005914:166787:167300 [3] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
21: nid005914:166786:167270 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,ffffffff,ffff0000,00000000,00000000,00000000,00000000
21: nid005914:166786:167270 [2] NCCL INFO NVLS multicast support is not available on dev 2
21: nid005914:166786:167270 [2] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
21: nid005914:166784:167271 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff,ffffffff
21: nid005914:166784:167271 [0] NCCL INFO NVLS multicast support is not available on dev 0
21: nid005914:166784:167271 [0] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
 8: nid005586:68929:69489 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff,ff000000,00000000,00000000,00000000,00000000,00000000,00000000
17: nid005803:180734:181263 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,ffffffff,ffff0000,00000000,00000000,00000000,00000000
 8: nid005586:68929:69489 [3] NCCL INFO NVLS multicast support is not available on dev 3
17: nid005803:180734:181263 [2] NCCL INFO NVLS multicast support is not available on dev 2
17: nid005803:180734:181263 [2] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
17: nid005803:180733:181262 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,ffffff00,00000000,00000000
 8: nid005586:68929:69489 [3] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
 8: nid005586:68926:69401 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff,ffffffff
17: nid005803:180733:181262 [1] NCCL INFO NVLS multicast support is not available on dev 1
17: nid005803:180733:181262 [1] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
 8: nid005586:68926:69401 [0] NCCL INFO NVLS multicast support is not available on dev 0
17: nid005803:180732:181264 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff,ffffffff
 8: nid005586:68926:69401 [0] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
17: nid005803:180732:181264 [0] NCCL INFO NVLS multicast support is not available on dev 0
 8: nid005586:68927:69451 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,ffffff00,00000000,00000000
17: nid005803:180732:181264 [0] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
17: nid005803:180735:181265 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff,ff000000,00000000,00000000,00000000,00000000,00000000,00000000
 8: nid005586:68927:69451 [1] NCCL INFO NVLS multicast support is not available on dev 1
 8: nid005586:68927:69451 [1] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
17: nid005803:180735:181265 [3] NCCL INFO NVLS multicast support is not available on dev 3
 8: nid005586:68928:69450 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,ffffffff,ffff0000,00000000,00000000,00000000,00000000
17: nid005803:180735:181265 [3] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
 8: nid005586:68928:69450 [2] NCCL INFO NVLS multicast support is not available on dev 2
 8: nid005586:68928:69450 [2] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
 1: nid005576:147558:148070 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,ffffff00,00000000,00000000
 1: nid005576:147558:148070 [1] NCCL INFO NVLS multicast support is not available on dev 1
 1: nid005576:147558:148070 [1] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
26: nid005920:67126:67661 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff,ff000000,00000000,00000000,00000000,00000000,00000000,00000000
 1: nid005576:147560:148100 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff,ff000000,00000000,00000000,00000000,00000000,00000000,00000000
26: nid005920:67126:67661 [3] NCCL INFO NVLS multicast support is not available on dev 3
 1: nid005576:147560:148100 [3] NCCL INFO NVLS multicast support is not available on dev 3
 1: nid005576:147560:148100 [3] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
26: nid005920:67126:67661 [3] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
 1: nid005576:147559:148101 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,ffffffff,ffff0000,00000000,00000000,00000000,00000000
 1: nid005576:147557:148053 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff,ffffffff
 1: nid005576:147559:148101 [2] NCCL INFO NVLS multicast support is not available on dev 2
 1: nid005576:147557:148053 [0] NCCL INFO NVLS multicast support is not available on dev 0
 1: nid005576:147559:148101 [2] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
 1: nid005576:147557:148053 [0] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
26: nid005920:67125:67662 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,ffffffff,ffff0000,00000000,00000000,00000000,00000000
26: nid005920:67125:67662 [2] NCCL INFO NVLS multicast support is not available on dev 2
26: nid005920:67124:67660 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,ffffff00,00000000,00000000
26: nid005920:67125:67662 [2] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
26: nid005920:67124:67660 [1] NCCL INFO NVLS multicast support is not available on dev 1
26: nid005920:67124:67660 [1] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
26: nid005920:67123:67613 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff,ffffffff
26: nid005920:67123:67613 [0] NCCL INFO NVLS multicast support is not available on dev 0
26: nid005920:67123:67613 [0] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
30: nid005936:49908:50465 [0] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
19: nid005912:12438:12958 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff,ff000000,00000000,00000000,00000000,00000000,00000000,00000000
19: nid005912:12438:12958 [3] NCCL INFO NVLS multicast support is not available on dev 3
19: nid005912:12438:12958 [3] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
19: nid005912:12436:12959 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,ffffff00,00000000,00000000
19: nid005912:12437:12976 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,ffffffff,ffff0000,00000000,00000000,00000000,00000000
19: nid005912:12437:12976 [2] NCCL INFO NVLS multicast support is not available on dev 2
19: nid005912:12437:12976 [2] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
19: nid005912:12436:12959 [1] NCCL INFO NVLS multicast support is not available on dev 1
19: nid005912:12436:12959 [1] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
19: nid005912:12435:12909 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff,ffffffff
19: nid005912:12435:12909 [0] NCCL INFO NVLS multicast support is not available on dev 0
19: nid005912:12435:12909 [0] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
 4: nid005581:264524:265064 [1] NCCL INFO NVLS multicast support is not available on dev 1
 4: nid005581:264524:265064 [1] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
11: nid005591:191604:192145 [1] NCCL INFO NVLS multicast support is not available on dev 1
11: nid005591:191604:192145 [1] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
11: nid005591:191606:192116 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff,ff000000,00000000,00000000,00000000,00000000,00000000,00000000
11: nid005591:191606:192116 [3] NCCL INFO NVLS multicast support is not available on dev 3
11: nid005591:191606:192116 [3] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
11: nid005591:191605:192144 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,ffffffff,ffff0000,00000000,00000000,00000000,00000000
11: nid005591:191605:192144 [2] NCCL INFO NVLS multicast support is not available on dev 2
11: nid005591:191605:192144 [2] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
25: nid005919:107465:108002 [3] NCCL INFO NVLS multicast support is not available on dev 3
25: nid005919:107465:108002 [3] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
25: nid005919:107464:108003 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,ffffffff,ffff0000,00000000,00000000,00000000,00000000
25: nid005919:107464:108003 [2] NCCL INFO NVLS multicast support is not available on dev 2
25: nid005919:107464:108003 [2] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
25: nid005919:107463:108001 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,ffffff00,00000000,00000000
25: nid005919:107463:108001 [1] NCCL INFO NVLS multicast support is not available on dev 1
25: nid005919:107463:108001 [1] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
24: nid005918:92507:93078 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff,ff000000,00000000,00000000,00000000,00000000,00000000,00000000
24: nid005918:92507:93078 [3] NCCL INFO NVLS multicast support is not available on dev 3
24: nid005918:92507:93078 [3] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
24: nid005918:92506:93079 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,ffffffff,ffff0000,00000000,00000000,00000000,00000000
24: nid005918:92506:93079 [2] NCCL INFO NVLS multicast support is not available on dev 2
24: nid005918:92506:93079 [2] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
24: nid005918:92505:93080 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,ffffff00,00000000,00000000
24: nid005918:92504:93029 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff,ffffffff
24: nid005918:92505:93080 [1] NCCL INFO NVLS multicast support is not available on dev 1
24: nid005918:92505:93080 [1] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
24: nid005918:92504:93029 [0] NCCL INFO NVLS multicast support is not available on dev 0
24: nid005918:92504:93029 [0] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
29: nid005932:167681:168228 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,ffffff00,00000000,00000000
29: nid005932:167681:168228 [1] NCCL INFO NVLS multicast support is not available on dev 1
29: nid005932:167681:168228 [1] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
29: nid005932:167680:168169 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff,ffffffff
29: nid005932:167683:168230 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff,ff000000,00000000,00000000,00000000,00000000,00000000,00000000
29: nid005932:167680:168169 [0] NCCL INFO NVLS multicast support is not available on dev 0
29: nid005932:167680:168169 [0] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
29: nid005932:167683:168230 [3] NCCL INFO NVLS multicast support is not available on dev 3
29: nid005932:167683:168230 [3] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
29: nid005932:167682:168229 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,ffffffff,ffff0000,00000000,00000000,00000000,00000000
29: nid005932:167682:168229 [2] NCCL INFO NVLS multicast support is not available on dev 2
29: nid005932:167682:168229 [2] NCCL INFO NCCL_CROSS_NIC set by environment to 1.
29: nid005932:167683:168230 [3] NCCL INFO comm 0xaaab0adabbc0 rank 119 nRanks 128 nNodes 32 localRanks 4 localRank 3 MNNVL 0
28: nid005929:16033:16573 [3] NCCL INFO comm 0xaaaade0c3510 rank 115 nRanks 128 nNodes 32 localRanks 4 localRank 3 MNNVL 0
28: nid005929:16032:16570 [2] NCCL INFO comm 0xaaab2fba3240 rank 114 nRanks 128 nNodes 32 localRanks 4 localRank 2 MNNVL 0
29: nid005932:167683:168230 [3] NCCL INFO Trees [0] -1/-1/-1->119->118 [1] -1/-1/-1->119->118 [2] 116/-1/-1->119->118 [3] 116/-1/-1->119->118 [4] -1/-1/-1->119->118 [5] -1/-1/-1->119->118 [6] 116/-1/-1->119->118 [7] 116/-1/-1->119->118
29: nid005932:167683:168230 [3] NCCL INFO P2P Chunksize set to 131072
29: nid005932:167681:168228 [1] NCCL INFO comm 0xaaaac3b4db00 rank 117 nRanks 128 nNodes 32 localRanks 4 localRank 1 MNNVL 0
29: nid005932:167682:168229 [2] NCCL INFO comm 0xaaab2bddcec0 rank 118 nRanks 128 nNodes 32 localRanks 4 localRank 2 MNNVL 0
28: nid005929:16031:16569 [1] NCCL INFO comm 0xaaaaf8401170 rank 113 nRanks 128 nNodes 32 localRanks 4 localRank 1 MNNVL 0
28: nid005929:16033:16573 [3] NCCL INFO Trees [0] -1/-1/-1->115->114 [1] -1/-1/-1->115->114 [2] 112/-1/-1->115->114 [3] 112/-1/-1->115->114 [4] -1/-1/-1->115->114 [5] -1/-1/-1->115->114 [6] 112/-1/-1->115->114 [7] 112/-1/-1->115->114
28: nid005929:16032:16570 [2] NCCL INFO Trees [0] 115/-1/-1->114->113 [1] 115/-1/-1->114->113 [2] 115/106/122->114->98 [3] 115/106/122->114->98 [4] 115/-1/-1->114->113 [5] 115/-1/-1->114->113 [6] 115/-1/-1->114->118 [7] 115/-1/-1->114->118
28: nid005929:16033:16573 [3] NCCL INFO P2P Chunksize set to 131072
28: nid005929:16032:16570 [2] NCCL INFO P2P Chunksize set to 131072
28: nid005929:16030:16526 [0] NCCL INFO comm 0xaaaad57d3fc0 rank 112 nRanks 128 nNodes 32 localRanks 4 localRank 0 MNNVL 0
27: nid005922:80744:81259 [3] NCCL INFO comm 0xaaaabb7ab7a0 rank 111 nRanks 128 nNodes 32 localRanks 4 localRank 3 MNNVL 0
29: nid005932:167680:168169 [0] NCCL INFO comm 0xaaab03ee4fa0 rank 116 nRanks 128 nNodes 32 localRanks 4 localRank 0 MNNVL 0
27: nid005922:80743:81258 [2] NCCL INFO comm 0xaaab0b1de990 rank 110 nRanks 128 nNodes 32 localRanks 4 localRank 2 MNNVL 0
25: nid005919:107463:108001 [1] NCCL INFO comm 0xaaaaf8221890 rank 101 nRanks 128 nNodes 32 localRanks 4 localRank 1 MNNVL 0
28: nid005929:16031:16569 [1] NCCL INFO Trees [0] 114/-1/-1->113->112 [1] 114/-1/-1->113->112 [2] -1/-1/-1->113->112 [3] -1/-1/-1->113->112 [4] 114/-1/-1->113->112 [5] 114/-1/-1->113->112 [6] -1/-1/-1->113->112 [7] -1/-1/-1->113->112
28: nid005929:16031:16569 [1] NCCL INFO P2P Chunksize set to 131072
28: nid005929:16030:16526 [0] NCCL INFO Trees [0] 113/104/120->112->96 [1] 113/104/120->112->96 [2] 113/-1/-1->112->115 [3] 113/-1/-1->112->115 [4] 113/-1/-1->112->116 [5] 113/-1/-1->112->116 [6] 113/-1/-1->112->115 [7] 113/-1/-1->112->115
25: nid005919:107464:108003 [2] NCCL INFO comm 0xaaab1682a750 rank 102 nRanks 128 nNodes 32 localRanks 4 localRank 2 MNNVL 0
25: nid005919:107465:108002 [3] NCCL INFO comm 0xaaaad4543ad0 rank 103 nRanks 128 nNodes 32 localRanks 4 localRank 3 MNNVL 0
29: nid005932:167681:168228 [1] NCCL INFO Trees [0] 118/-1/-1->117->116 [1] 118/-1/-1->117->116 [2] -1/-1/-1->117->116 [3] -1/-1/-1->117->116 [4] 118/-1/-1->117->116 [5] 118/-1/-1->117->116 [6] -1/-1/-1->117->116 [7] -1/-1/-1->117->116
29: nid005932:167681:168228 [1] NCCL INFO P2P Chunksize set to 131072
27: nid005922:80744:81259 [3] NCCL INFO Trees [0] -1/-1/-1->111->110 [1] -1/-1/-1->111->110 [2] 108/-1/-1->111->110 [3] 108/-1/-1->111->110 [4] -1/-1/-1->111->110 [5] -1/-1/-1->111->110 [6] 108/-1/-1->111->110 [7] 108/-1/-1->111->110
27: nid005922:80744:81259 [3] NCCL INFO P2P Chunksize set to 131072
29: nid005932:167682:168229 [2] NCCL INFO Trees [0] 119/-1/-1->118->117 [1] 119/-1/-1->118->117 [2] 119/-1/-1->118->122 [3] 119/-1/-1->118->122 [4] 119/-1/-1->118->117 [5] 119/-1/-1->118->117 [6] 119/122/114->118->110 [7] 119/122/114->118->110
29: nid005932:167682:168229 [2] NCCL INFO P2P Chunksize set to 131072
25: nid005919:107463:108001 [1] NCCL INFO Trees [0] 102/-1/-1->101->100 [1] 102/-1/-1->101->100 [2] -1/-1/-1->101->100 [3] -1/-1/-1->101->100 [4] 102/-1/-1->101->100 [5] 102/-1/-1->101->100 [6] -1/-1/-1->101->100 [7] -1/-1/-1->101->100
25: nid005919:107463:108001 [1] NCCL INFO P2P Chunksize set to 131072
27: nid005922:80743:81258 [2] NCCL INFO Trees [0] 111/-1/-1->110->109 [1] 111/-1/-1->110->109 [2] 111/-1/-1->110->106 [3] 111/-1/-1->110->106 [4] 111/-1/-1->110->109 [5] 111/-1/-1->110->109 [6] 111/118/102->110->94 [7] 111/118/102->110->94
27: nid005922:80743:81258 [2] NCCL INFO P2P Chunksize set to 131072
28: nid005929:16030:16526 [0] NCCL INFO P2P Chunksize set to 131072
26: nid005920:67125:67662 [2] NCCL INFO comm 0xaaaaf841bf30 rank 106 nRanks 128 nNodes 32 localRanks 4 localRank 2 MNNVL 0
26: nid005920:67126:67661 [3] NCCL INFO comm 0xaaab209d4590 rank 107 nRanks 128 nNodes 32 localRanks 4 localRank 3 MNNVL 0
29: nid005932:167680:168169 [0] NCCL INFO Trees [0] 117/-1/-1->116->120 [1] 117/-1/-1->116->120 [2] 117/-1/-1->116->119 [3] 117/-1/-1->116->119 [4] 117/120/112->116->108 [5] 117/120/112->116->108 [6] 117/-1/-1->116->119 [7] 117/-1/-1->116->119
29: nid005932:167680:168169 [0] NCCL INFO P2P Chunksize set to 131072
26: nid005920:67124:67660 [1] NCCL INFO comm 0xaaab0de132b0 rank 105 nRanks 128 nNodes 32 localRanks 4 localRank 1 MNNVL 0
26: nid005920:67123:67613 [0] NCCL INFO comm 0xaaab021f2d20 rank 104 nRanks 128 nNodes 32 localRanks 4 localRank 0 MNNVL 0
27: nid005922:80741:81228 [0] NCCL INFO comm 0xaaab18560ec0 rank 108 nRanks 128 nNodes 32 localRanks 4 localRank 0 MNNVL 0
25: nid005919:107465:108002 [3] NCCL INFO Trees [0] -1/-1/-1->103->102 [1] -1/-1/-1->103->102 [2] 100/-1/-1->103->102 [3] 100/-1/-1->103->102 [4] -1/-1/-1->103->102 [5] -1/-1/-1->103->102 [6] 100/-1/-1->103->102 [7] 100/-1/-1->103->102
25: nid005919:107464:108003 [2] NCCL INFO Trees [0] 103/-1/-1->102->101 [1] 103/-1/-1->102->101 [2] 103/-1/-1->102->106 [3] 103/-1/-1->102->106 [4] 103/-1/-1->102->101 [5] 103/-1/-1->102->101 [6] 103/106/98->102->110 [7] 103/106/98->102->110
25: nid005919:107465:108002 [3] NCCL INFO P2P Chunksize set to 131072
25: nid005919:107464:108003 [2] NCCL INFO P2P Chunksize set to 131072
27: nid005922:80742:81229 [1] NCCL INFO comm 0xaaab00b73210 rank 109 nRanks 128 nNodes 32 localRanks 4 localRank 1 MNNVL 0
26: nid005920:67126:67661 [3] NCCL INFO Trees [0] -1/-1/-1->107->106 [1] -1/-1/-1->107->106 [2] 104/-1/-1->107->106 [3] 104/-1/-1->107->106 [4] -1/-1/-1->107->106 [5] -1/-1/-1->107->106 [6] 104/-1/-1->107->106 [7] 104/-1/-1->107->106
26: nid005920:67125:67662 [2] NCCL INFO Trees [0] 107/-1/-1->106->105 [1] 107/-1/-1->106->105 [2] 107/102/110->106->114 [3] 107/102/110->106->114 [4] 107/-1/-1->106->105 [5] 107/-1/-1->106->105 [6] 107/-1/-1->106->102 [7] 107/-1/-1->106->102
26: nid005920:67126:67661 [3] NCCL INFO P2P Chunksize set to 131072
26: nid005920:67125:67662 [2] NCCL INFO P2P Chunksize set to 131072
26: nid005920:67123:67613 [0] NCCL INFO Trees [0] 105/100/108->104->112 [1] 105/100/108->104->112 [2] 105/-1/-1->104->107 [3] 105/-1/-1->104->107 [4] 105/-1/-1->104->100 [5] 105/-1/-1->104->100 [6] 105/-1/-1->104->107 [7] 105/-1/-1->104->107
25: nid005919:107462:107959 [0] NCCL INFO comm 0xaaab262294f0 rank 100 nRanks 128 nNodes 32 localRanks 4 localRank 0 MNNVL 0
27: nid005922:80741:81228 [0] NCCL INFO Trees [0] 109/-1/-1->108->104 [1] 109/-1/-1->108->104 [2] 109/-1/-1->108->111 [3] 109/-1/-1->108->111 [4] 109/116/100->108->92 [5] 109/116/100->108->92 [6] 109/-1/-1->108->111 [7] 109/-1/-1->108->111
27: nid005922:80741:81228 [0] NCCL INFO P2P Chunksize set to 131072
26: nid005920:67124:67660 [1] NCCL INFO Trees [0] 106/-1/-1->105->104 [1] 106/-1/-1->105->104 [2] -1/-1/-1->105->104 [3] -1/-1/-1->105->104 [4] 106/-1/-1->105->104 [5] 106/-1/-1->105->104 [6] -1/-1/-1->105->104 [7] -1/-1/-1->105->104
27: nid005922:80742:81229 [1] NCCL INFO Trees [0] 110/-1/-1->109->108 [1] 110/-1/-1->109->108 [2] -1/-1/-1->109->108 [3] -1/-1/-1->109->108 [4] 110/-1/-1->109->108 [5] 110/-1/-1->109->108 [6] -1/-1/-1->109->108 [7] -1/-1/-1->109->108
27: nid005922:80742:81229 [1] NCCL INFO P2P Chunksize set to 131072
26: nid005920:67124:67660 [1] NCCL INFO P2P Chunksize set to 131072
26: nid005920:67123:67613 [0] NCCL INFO P2P Chunksize set to 131072
25: nid005919:107462:107959 [0] NCCL INFO Trees [0] 101/-1/-1->100->104 [1] 101/-1/-1->100->104 [2] 101/-1/-1->100->103 [3] 101/-1/-1->100->103 [4] 101/104/96->100->108 [5] 101/104/96->100->108 [6] 101/-1/-1->100->103 [7] 101/-1/-1->100->103
25: nid005919:107462:107959 [0] NCCL INFO P2P Chunksize set to 131072
11: nid005591:191604:192145 [1] NCCL INFO comm 0xaaab196cb950 rank 45 nRanks 128 nNodes 32 localRanks 4 localRank 1 MNNVL 0
10: nid005590:110713:111240 [3] NCCL INFO comm 0xaaab375e3b60 rank 43 nRanks 128 nNodes 32 localRanks 4 localRank 3 MNNVL 0
11: nid005591:191603:192099 [0] NCCL INFO comm 0xaaaaf7916bf0 rank 44 nRanks 128 nNodes 32 localRanks 4 localRank 0 MNNVL 0
10: nid005590:110712:111243 [2] NCCL INFO comm 0xaaab104db470 rank 42 nRanks 128 nNodes 32 localRanks 4 localRank 2 MNNVL 0
10: nid005590:110713:111240 [3] NCCL INFO Trees [0] -1/-1/-1->43->42 [1] -1/-1/-1->43->42 [2] 40/-1/-1->43->42 [3] 40/-1/-1->43->42 [4] -1/-1/-1->43->42 [5] -1/-1/-1->43->42 [6] 40/-1/-1->43->42 [7] 40/-1/-1->43->42
10: nid005590:110710:111197 [0] NCCL INFO comm 0xaaab23d6b530 rank 40 nRanks 128 nNodes 32 localRanks 4 localRank 0 MNNVL 0
10: nid005590:110711:111241 [1] NCCL INFO comm 0xaaab10df3460 rank 41 nRanks 128 nNodes 32 localRanks 4 localRank 1 MNNVL 0
10: nid005590:110713:111240 [3] NCCL INFO P2P Chunksize set to 131072
 9: nid005588:35938:36474 [3] NCCL INFO comm 0xaaaadbd50910 rank 39 nRanks 128 nNodes 32 localRanks 4 localRank 3 MNNVL 0
 9: nid005588:35937:36471 [2] NCCL INFO comm 0xaaaae8a0c3a0 rank 38 nRanks 128 nNodes 32 localRanks 4 localRank 2 MNNVL 0
10: nid005590:110712:111243 [2] NCCL INFO Trees [0] 43/-1/-1->42->41 [1] 43/-1/-1->42->41 [2] 43/38/46->42->50 [3] 43/38/46->42->50 [4] 43/-1/-1->42->41 [5] 43/-1/-1->42->41 [6] 43/-1/-1->42->38 [7] 43/-1/-1->42->38
10: nid005590:110712:111243 [2] NCCL INFO P2P Chunksize set to 131072
 9: nid005588:35936:36472 [1] NCCL INFO comm 0xaaab298ab220 rank 37 nRanks 128 nNodes 32 localRanks 4 localRank 1 MNNVL 0
10: nid005590:110710:111197 [0] NCCL INFO Trees [0] 41/36/44->40->48 [1] 41/36/44->40->48 [2] 41/-1/-1->40->43 [3] 41/-1/-1->40->43 [4] 41/-1/-1->40->36 [5] 41/-1/-1->40->36 [6] 41/-1/-1->40->43 [7] 41/-1/-1->40->43
10: nid005590:110711:111241 [1] NCCL INFO Trees [0] 42/-1/-1->41->40 [1] 42/-1/-1->41->40 [2] -1/-1/-1->41->40 [3] -1/-1/-1->41->40 [4] 42/-1/-1->41->40 [5] 42/-1/-1->41->40 [6] -1/-1/-1->41->40 [7] -1/-1/-1->41->40
10: nid005590:110711:111241 [1] NCCL INFO P2P Chunksize set to 131072
10: nid005590:110710:111197 [0] NCCL INFO P2P Chunksize set to 131072
 9: nid005588:35935:36428 [0] NCCL INFO comm 0xaaab148fdb70 rank 36 nRanks 128 nNodes 32 localRanks 4 localRank 0 MNNVL 0
 9: nid005588:35938:36474 [3] NCCL INFO Trees [0] -1/-1/-1->39->38 [1] -1/-1/-1->39->38 [2] 36/-1/-1->39->38 [3] 36/-1/-1->39->38 [4] -1/-1/-1->39->38 [5] -1/-1/-1->39->38 [6] 36/-1/-1->39->38 [7] 36/-1/-1->39->38
 8: nid005586:68929:69489 [3] NCCL INFO comm 0xaaab0425a760 rank 35 nRanks 128 nNodes 32 localRanks 4 localRank 3 MNNVL 0
 8: nid005586:68928:69450 [2] NCCL INFO comm 0xaaaaf16101a0 rank 34 nRanks 128 nNodes 32 localRanks 4 localRank 2 MNNVL 0
11: nid005591:191604:192145 [1] NCCL INFO Trees [0] 46/-1/-1->45->44 [1] 46/-1/-1->45->44 [2] -1/-1/-1->45->44 [3] -1/-1/-1->45->44 [4] 46/-1/-1->45->44 [5] 46/-1/-1->45->44 [6] -1/-1/-1->45->44 [7] -1/-1/-1->45->44
11: nid005591:191604:192145 [1] NCCL INFO P2P Chunksize set to 131072
 9: nid005588:35938:36474 [3] NCCL INFO P2P Chunksize set to 131072
 9: nid005588:35937:36471 [2] NCCL INFO Trees [0] 39/-1/-1->38->37 [1] 39/-1/-1->38->37 [2] 39/-1/-1->38->42 [3] 39/-1/-1->38->42 [4] 39/-1/-1->38->37 [5] 39/-1/-1->38->37 [6] 39/42/34->38->46 [7] 39/42/34->38->46
 9: nid005588:35937:36471 [2] NCCL INFO P2P Chunksize set to 131072
 9: nid005588:35936:36472 [1] NCCL INFO Trees [0] 38/-1/-1->37->36 [1] 38/-1/-1->37->36 [2] -1/-1/-1->37->36 [3] -1/-1/-1->37->36 [4] 38/-1/-1->37->36 [5] 38/-1/-1->37->36 [6] -1/-1/-1->37->36 [7] -1/-1/-1->37->36
 9: nid005588:35936:36472 [1] NCCL INFO P2P Chunksize set to 131072
 7: nid005585:122005:122496 [0] NCCL INFO comm 0xaaab166fca20 rank 28 nRanks 128 nNodes 32 localRanks 4 localRank 0 MNNVL 0
 7: nid005585:122006:122526 [1] NCCL INFO comm 0xaaab0e87b260 rank 29 nRanks 128 nNodes 32 localRanks 4 localRank 1 MNNVL 0
 7: nid005585:122008:122545 [3] NCCL INFO comm 0xaaaaedf73db0 rank 31 nRanks 128 nNodes 32 localRanks 4 localRank 3 MNNVL 0
 8: nid005586:68927:69451 [1] NCCL INFO comm 0xaaaaec21b350 rank 33 nRanks 128 nNodes 32 localRanks 4 localRank 1 MNNVL 0
 9: nid005588:35935:36428 [0] NCCL INFO Trees [0] 37/-1/-1->36->40 [1] 37/-1/-1->36->40 [2] 37/-1/-1->36->39 [3] 37/-1/-1->36->39 [4] 37/40/32->36->44 [5] 37/40/32->36->44 [6] 37/-1/-1->36->39 [7] 37/-1/-1->36->39
 9: nid005588:35935:36428 [0] NCCL INFO P2P Chunksize set to 131072
 8: nid005586:68926:69401 [0] NCCL INFO comm 0xaaab12790160 rank 32 nRanks 128 nNodes 32 localRanks 4 localRank 0 MNNVL 0
 7: nid005585:122007:122527 [2] NCCL INFO comm 0xaaaadd869ba0 rank 30 nRanks 128 nNodes 32 localRanks 4 localRank 2 MNNVL 0
 8: nid005586:68929:69489 [3] NCCL INFO Trees [0] -1/-1/-1->35->34 [1] -1/-1/-1->35->34 [2] 32/-1/-1->35->34 [3] 32/-1/-1->35->34 [4] -1/-1/-1->35->34 [5] -1/-1/-1->35->34 [6] 32/-1/-1->35->34 [7] 32/-1/-1->35->34
 8: nid005586:68929:69489 [3] NCCL INFO P2P Chunksize set to 131072
 8: nid005586:68927:69451 [1] NCCL INFO Trees [0] 34/-1/-1->33->32 [1] 34/-1/-1->33->32 [2] -1/-1/-1->33->32 [3] -1/-1/-1->33->32 [4] 34/-1/-1->33->32 [5] 34/-1/-1->33->32 [6] -1/-1/-1->33->32 [7] -1/-1/-1->33->32
 7: nid005585:122006:122526 [1] NCCL INFO Trees [0] 30/-1/-1->29->28 [1] 30/-1/-1->29->28 [2] -1/-1/-1->29->28 [3] -1/-1/-1->29->28 [4] 30/-1/-1->29->28 [5] 30/-1/-1->29->28 [6] -1/-1/-1->29->28 [7] -1/-1/-1->29->28
 7: nid005585:122008:122545 [3] NCCL INFO Trees [0] -1/-1/-1->31->30 [1] -1/-1/-1->31->30 [2] 28/-1/-1->31->30 [3] 28/-1/-1->31->30 [4] -1/-1/-1->31->30 [5] -1/-1/-1->31->30 [6] 28/-1/-1->31->30 [7] 28/-1/-1->31->30
 7: nid005585:122006:122526 [1] NCCL INFO P2P Chunksize set to 131072
 7: nid005585:122008:122545 [3] NCCL INFO P2P Chunksize set to 131072
 8: nid005586:68927:69451 [1] NCCL INFO P2P Chunksize set to 131072
 8: nid005586:68928:69450 [2] NCCL INFO Trees [0] 35/-1/-1->34->33 [1] 35/-1/-1->34->33 [2] 35/18/50->34->66 [3] 35/18/50->34->66 [4] 35/-1/-1->34->33 [5] 35/-1/-1->34->33 [6] 35/-1/-1->34->38 [7] 35/-1/-1->34->38
 7: nid005585:122007:122527 [2] NCCL INFO Trees [0] 31/-1/-1->30->29 [1] 31/-1/-1->30->29 [2] 31/-1/-1->30->26 [3] 31/-1/-1->30->26 [4] 31/-1/-1->30->29 [5] 31/-1/-1->30->29 [6] 31/46/14->30->62 [7] 31/46/14->30->62
 8: nid005586:68928:69450 [2] NCCL INFO P2P Chunksize set to 131072
 6: nid005584:28288:28820 [3] NCCL INFO comm 0xaaaaf69fb200 rank 27 nRanks 128 nNodes 32 localRanks 4 localRank 3 MNNVL 0
 6: nid005584:28287:28819 [2] NCCL INFO comm 0xaaab07a0c730 rank 26 nRanks 128 nNodes 32 localRanks 4 localRank 2 MNNVL 0
 7: nid005585:122007:122527 [2] NCCL INFO P2P Chunksize set to 131072
 8: nid005586:68926:69401 [0] NCCL INFO Trees [0] 33/16/48->32->64 [1] 33/16/48->32->64 [2] 33/-1/-1->32->35 [3] 33/-1/-1->32->35 [4] 33/-1/-1->32->36 [5] 33/-1/-1->32->36 [6] 33/-1/-1->32->35 [7] 33/-1/-1->32->35
 8: nid005586:68926:69401 [0] NCCL INFO P2P Chunksize set to 131072
11: nid005591:191603:192099 [0] NCCL INFO Trees [0] 45/-1/-1->44->40 [1] 45/-1/-1->44->40 [2] 45/-1/-1->44->47 [3] 45/-1/-1->44->47 [4] 45/52/36->44->28 [5] 45/52/36->44->28 [6] 45/-1/-1->44->47 [7] 45/-1/-1->44->47
 4: nid005581:264526:265063 [3] NCCL INFO comm 0xaaaae8963db0 rank 19 nRanks 128 nNodes 32 localRanks 4 localRank 3 MNNVL 0
 7: nid005585:122005:122496 [0] NCCL INFO Trees [0] 29/-1/-1->28->24 [1] 29/-1/-1->28->24 [2] 29/-1/-1->28->31 [3] 29/-1/-1->28->31 [4] 29/44/12->28->60 [5] 29/44/12->28->60 [6] 29/-1/-1->28->31 [7] 29/-1/-1->28->31
 7: nid005585:122005:122496 [0] NCCL INFO P2P Chunksize set to 131072
 4: nid005581:264525:265067 [2] NCCL INFO comm 0xaaaaf1142f20 rank 18 nRanks 128 nNodes 32 localRanks 4 localRank 2 MNNVL 0
 6: nid005584:28288:28820 [3] NCCL INFO Trees [0] -1/-1/-1->27->26 [1] -1/-1/-1->27->26 [2] 24/-1/-1->27->26 [3] 24/-1/-1->27->26 [4] -1/-1/-1->27->26 [5] -1/-1/-1->27->26 [6] 24/-1/-1->27->26 [7] 24/-1/-1->27->26
 6: nid005584:28288:28820 [3] NCCL INFO P2P Chunksize set to 131072
 6: nid005584:28287:28819 [2] NCCL INFO Trees [0] 27/-1/-1->26->25 [1] 27/-1/-1->26->25 [2] 27/22/30->26->18 [3] 27/22/30->26->18 [4] 27/-1/-1->26->25 [5] 27/-1/-1->26->25 [6] 27/-1/-1->26->22 [7] 27/-1/-1->26->22
 0: nid005574:69060:69600 [2] NCCL INFO comm 0xaaaaedbf8c70 rank 2 nRanks 128 nNodes 32 localRanks 4 localRank 2 MNNVL 0
 4: nid005581:264526:265063 [3] NCCL INFO Trees [0] -1/-1/-1->19->18 [1] -1/-1/-1->19->18 [2] 16/-1/-1->19->18 [3] 16/-1/-1->19->18 [4] -1/-1/-1->19->18 [5] -1/-1/-1->19->18 [6] 16/-1/-1->19->18 [7] 16/-1/-1->19->18
 4: nid005581:264526:265063 [3] NCCL INFO P2P Chunksize set to 131072
 5: nid005582:196716:197388 [3] NCCL INFO comm 0xaaab1215f930 rank 23 nRanks 128 nNodes 32 localRanks 4 localRank 3 MNNVL 0
 5: nid005582:196713:197389 [0] NCCL INFO comm 0xaaab12118df0 rank 20 nRanks 128 nNodes 32 localRanks 4 localRank 0 MNNVL 0
 5: nid005582:196715:197387 [2] NCCL INFO comm 0xaaaaeab5be10 rank 22 nRanks 128 nNodes 32 localRanks 4 localRank 2 MNNVL 0
 5: nid005582:196714:197386 [1] NCCL INFO comm 0xaaab201019a0 rank 21 nRanks 128 nNodes 32 localRanks 4 localRank 1 MNNVL 0
 6: nid005584:28287:28819 [2] NCCL INFO P2P Chunksize set to 131072
11: nid005591:191603:192099 [0] NCCL INFO P2P Chunksize set to 131072
 6: nid005584:28285:28774 [0] NCCL INFO comm 0xaaaafc6efb40 rank 24 nRanks 128 nNodes 32 localRanks 4 localRank 0 MNNVL 0
 6: nid005584:28286:28818 [1] NCCL INFO comm 0xaaab2173c180 rank 25 nRanks 128 nNodes 32 localRanks 4 localRank 1 MNNVL 0
 4: nid005581:264524:265064 [1] NCCL INFO comm 0xaaaad9b8a440 rank 17 nRanks 128 nNodes 32 localRanks 4 localRank 1 MNNVL 0
 4: nid005581:264525:265067 [2] NCCL INFO Trees [0] 19/-1/-1->18->17 [1] 19/-1/-1->18->17 [2] 19/10/26->18->34 [3] 19/10/26->18->34 [4] 19/-1/-1->18->17 [5] 19/-1/-1->18->17 [6] 19/-1/-1->18->22 [7] 19/-1/-1->18->22
 3: nid005580:71822:72337 [3] NCCL INFO comm 0xaaab06b93260 rank 15 nRanks 128 nNodes 32 localRanks 4 localRank 3 MNNVL 0
 5: nid005582:196715:197387 [2] NCCL INFO Trees [0] 23/-1/-1->22->21 [1] 23/-1/-1->22->21 [2] 23/-1/-1->22->26 [3] 23/-1/-1->22->26 [4] 23/-1/-1->22->21 [5] 23/-1/-1->22->21 [6] 23/26/18->22->14 [7] 23/26/18->22->14
 5: nid005582:196716:197388 [3] NCCL INFO Trees [0] -1/-1/-1->23->22 [1] -1/-1/-1->23->22 [2] 20/-1/-1->23->22 [3] 20/-1/-1->23->22 [4] -1/-1/-1->23->22 [5] -1/-1/-1->23->22 [6] 20/-1/-1->23->22 [7] 20/-1/-1->23->22
 5: nid005582:196714:197386 [1] NCCL INFO Trees [0] 22/-1/-1->21->20 [1] 22/-1/-1->21->20 [2] -1/-1/-1->21->20 [3] -1/-1/-1->21->20 [4] 22/-1/-1->21->20 [5] 22/-1/-1->21->20 [6] -1/-1/-1->21->20 [7] -1/-1/-1->21->20
 5: nid005582:196715:197387 [2] NCCL INFO P2P Chunksize set to 131072
 5: nid005582:196716:197388 [3] NCCL INFO P2P Chunksize set to 131072
 5: nid005582:196713:197389 [0] NCCL INFO Trees [0] 21/-1/-1->20->24 [1] 21/-1/-1->20->24 [2] 21/-1/-1->20->23 [3] 21/-1/-1->20->23 [4] 21/24/16->20->12 [5] 21/24/16->20->12 [6] 21/-1/-1->20->23 [7] 21/-1/-1->20->23
 0: nid005574:69061:69602 [3] NCCL INFO comm 0xaaaad3e5bbc0 rank 3 nRanks 128 nNodes 32 localRanks 4 localRank 3 MNNVL 0
 4: nid005581:264525:265067 [2] NCCL INFO P2P Chunksize set to 131072
 6: nid005584:28285:28774 [0] NCCL INFO Trees [0] 25/20/28->24->16 [1] 25/20/28->24->16 [2] 25/-1/-1->24->27 [3] 25/-1/-1->24->27 [4] 25/-1/-1->24->20 [5] 25/-1/-1->24->20 [6] 25/-1/-1->24->27 [7] 25/-1/-1->24->27
 6: nid005584:28285:28774 [0] NCCL INFO P2P Chunksize set to 131072
 0: nid005574:69060:69600 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/66/-1->2->-1 [3] 3/66/-1->2->-1 [4] 3/-1/-1->2->1 [5] 3/-1/-1->2->1 [6] 3/-1/-1->2->6 [7] 3/-1/-1->2->6
 0: nid005574:69060:69600 [2] NCCL INFO P2P Chunksize set to 131072
 0: nid005574:69058:69552 [0] NCCL INFO comm 0xaaab0113f7d0 rank 0 nRanks 128 nNodes 32 localRanks 4 localRank 0 MNNVL 0
 4: nid005581:264524:265064 [1] NCCL INFO Trees [0] 18/-1/-1->17->16 [1] 18/-1/-1->17->16 [2] -1/-1/-1->17->16 [3] -1/-1/-1->17->16 [4] 18/-1/-1->17->16 [5] 18/-1/-1->17->16 [6] -1/-1/-1->17->16 [7] -1/-1/-1->17->16
 4: nid005581:264524:265064 [1] NCCL INFO P2P Chunksize set to 131072
 3: nid005580:71821:72339 [2] NCCL INFO comm 0xaaaada12b8c0 rank 14 nRanks 128 nNodes 32 localRanks 4 localRank 2 MNNVL 0
31: nid005937:256590:257125 [1] NCCL INFO comm 0xaaab10443c40 rank 125 nRanks 128 nNodes 32 localRanks 4 localRank 1 MNNVL 0
31: nid005937:256592:257124 [3] NCCL INFO comm 0xaaaaedf436d0 rank 127 nRanks 128 nNodes 32 localRanks 4 localRank 3 MNNVL 0
31: nid005937:256591:257123 [2] NCCL INFO comm 0xaaaafcfbaf70 rank 126 nRanks 128 nNodes 32 localRanks 4 localRank 2 MNNVL 0
31: nid005937:256589:256847 [0] NCCL INFO comm 0xaaab2c295d90 rank 124 nRanks 128 nNodes 32 localRanks 4 localRank 0 MNNVL 0
 0: nid005574:69059:69601 [1] NCCL INFO comm 0xaaaad1289f50 rank 1 nRanks 128 nNodes 32 localRanks 4 localRank 1 MNNVL 0
30: nid005936:49908:50465 [0] NCCL INFO comm 0xaaaafc2a9750 rank 120 nRanks 128 nNodes 32 localRanks 4 localRank 0 MNNVL 0
30: nid005936:49910:50467 [2] NCCL INFO comm 0xaaaad8cb00f0 rank 122 nRanks 128 nNodes 32 localRanks 4 localRank 2 MNNVL 0
30: nid005936:49911:50449 [3] NCCL INFO comm 0xaaaad877afc0 rank 123 nRanks 128 nNodes 32 localRanks 4 localRank 3 MNNVL 0
30: nid005936:49909:50450 [1] NCCL INFO comm 0xaaaacaa5c1a0 rank 121 nRanks 128 nNodes 32 localRanks 4 localRank 1 MNNVL 0
 6: nid005584:28286:28818 [1] NCCL INFO Trees [0] 26/-1/-1->25->24 [1] 26/-1/-1->25->24 [2] -1/-1/-1->25->24 [3] -1/-1/-1->25->24 [4] 26/-1/-1->25->24 [5] 26/-1/-1->25->24 [6] -1/-1/-1->25->24 [7] -1/-1/-1->25->24
 6: nid005584:28286:28818 [1] NCCL INFO P2P Chunksize set to 131072
 0: nid005574:69058:69552 [0] NCCL INFO Channel 00/08 :    0   1   2   3   7   6   5   4   8   9  10  11  15  14  13  12  16  17  18  19
 0: nid005574:69058:69552 [0] NCCL INFO Channel 01/08 :    0   4   5   6   7  11  10   9   8  12  13  14  15  19  18  17  16  20  21  22
 3: nid005580:71820:72338 [1] NCCL INFO comm 0xaaaac543b4a0 rank 13 nRanks 128 nNodes 32 localRanks 4 localRank 1 MNNVL 0
 3: nid005580:71822:72337 [3] NCCL INFO Trees [0] -1/-1/-1->15->14 [1] -1/-1/-1->15->14 [2] 12/-1/-1->15->14 [3] 12/-1/-1->15->14 [4] -1/-1/-1->15->14 [5] -1/-1/-1->15->14 [6] 12/-1/-1->15->14 [7] 12/-1/-1->15->14
 3: nid005580:71822:72337 [3] NCCL INFO P2P Chunksize set to 131072
 0: nid005574:69058:69552 [0] NCCL INFO Channel 02/08 :    0   3   1   5   4   7   6  10   8  11   9  13  12  15  14  18  16  19  17  21
 5: nid005582:196714:197386 [1] NCCL INFO P2P Chunksize set to 131072
 0: nid005574:69058:69552 [0] NCCL INFO Channel 03/08 :    0   3   2   6   4   7   5   9   8  11  10  14  12  15  13  17  16  19  18  22
 1: nid005576:147558:148070 [1] NCCL INFO comm 0xaaaaf8e03070 rank 5 nRanks 128 nNodes 32 localRanks 4 localRank 1 MNNVL 0
 1: nid005576:147560:148100 [3] NCCL INFO comm 0xaaaaea94c330 rank 7 nRanks 128 nNodes 32 localRanks 4 localRank 3 MNNVL 0
 1: nid005576:147559:148101 [2] NCCL INFO comm 0xaaab1c4d2400 rank 6 nRanks 128 nNodes 32 localRanks 4 localRank 2 MNNVL 0
 4: nid005581:264523:265016 [0] NCCL INFO comm 0xaaaafba8b880 rank 16 nRanks 128 nNodes 32 localRanks 4 localRank 0 MNNVL 0
 5: nid005582:196713:197389 [0] NCCL INFO P2P Chunksize set to 131072
31: nid005937:256590:257125 [1] NCCL INFO Trees [0] 126/-1/-1->125->124 [1] 126/-1/-1->125->124 [2] -1/-1/-1->125->124 [3] -1/-1/-1->125->124 [4] 126/-1/-1->125->124 [5] 126/-1/-1->125->124 [6] -1/-1/-1->125->124 [7] -1/-1/-1->125->124
31: nid005937:256592:257124 [3] NCCL INFO Trees [0] -1/-1/-1->127->126 [1] -1/-1/-1->127->126 [2] 124/-1/-1->127->126 [3] 124/-1/-1->127->126 [4] -1/-1/-1->127->126 [5] -1/-1/-1->127->126 [6] 124/-1/-1->127->126 [7] 124/-1/-1->127->126
31: nid005937:256590:257125 [1] NCCL INFO P2P Chunksize set to 131072
 0: nid005574:69059:69601 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] -1/-1/-1->1->0 [3] -1/-1/-1->1->0 [4] 2/-1/-1->1->0 [5] 2/-1/-1->1->0 [6] -1/-1/-1->1->0 [7] -1/-1/-1->1->0
 0: nid005574:69058:69552 [0] NCCL INFO Channel 04/08 :    0   1   2   3   7   6   5   4   8   9  10  11  15  14  13  12  16  17  18  19
 0: nid005574:69059:69601 [1] NCCL INFO P2P Chunksize set to 131072
 2: nid005577:17425:17981 [3] NCCL INFO comm 0xaaab1accc2e0 rank 11 nRanks 128 nNodes 32 localRanks 4 localRank 3 MNNVL 0
 2: nid005577:17424:17982 [2] NCCL INFO comm 0xaaaaec29b7f0 rank 10 nRanks 128 nNodes 32 localRanks 4 localRank 2 MNNVL 0
 3: nid005580:71819:72290 [0] NCCL INFO comm 0xaaab065e8c10 rank 12 nRanks 128 nNodes 32 localRanks 4 localRank 0 MNNVL 0
 3: nid005580:71821:72339 [2] NCCL INFO Trees [0] 15/-1/-1->14->13 [1] 15/-1/-1->14->13 [2] 15/-1/-1->14->10 [3] 15/-1/-1->14->10 [4] 15/-1/-1->14->13 [5] 15/-1/-1->14->13 [6] 15/22/6->14->30 [7] 15/22/6->14->30
 3: nid005580:71821:72339 [2] NCCL INFO P2P Chunksize set to 131072
11: nid005591:191605:192144 [2] NCCL INFO comm 0xaaaafb513f80 rank 46 nRanks 128 nNodes 32 localRanks 4 localRank 2 MNNVL 0
31: nid005937:256591:257123 [2] NCCL INFO Trees [0] 127/-1/-1->126->125 [1] 127/-1/-1->126->125 [2] 127/-1/-1->126->122 [3] 127/-1/-1->126->122 [4] 127/-1/-1->126->125 [5] 127/-1/-1->126->125 [6] 127/62/-1->126->-1 [7] 127/62/-1->126->-1
31: nid005937:256589:256847 [0] NCCL INFO Trees [0] 125/-1/-1->124->120 [1] 125/-1/-1->124->120 [2] 125/-1/-1->124->127 [3] 125/-1/-1->124->127 [4] 125/60/-1->124->-1 [5] 125/60/-1->124->-1 [6] 125/-1/-1->124->127 [7] 125/-1/-1->124->127
31: nid005937:256592:257124 [3] NCCL INFO P2P Chunksize set to 131072
 0: nid005574:69061:69602 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] 0/-1/-1->3->2 [3] 0/-1/-1->3->2 [4] -1/-1/-1->3->2 [5] -1/-1/-1->3->2 [6] 0/-1/-1->3->2 [7] 0/-1/-1->3->2
 0: nid005574:69058:69552 [0] NCCL INFO Channel 05/08 :    0   4   5   6   7  11  10   9   8  12  13  14  15  19  18  17  16  20  21  22
 0: nid005574:69061:69602 [3] NCCL INFO P2P Chunksize set to 131072
 2: nid005577:17423:17952 [1] NCCL INFO comm 0xaaaaf479b750 rank 9 nRanks 128 nNodes 32 localRanks 4 localRank 1 MNNVL 0
 3: nid005580:71820:72338 [1] NCCL INFO Trees [0] 14/-1/-1->13->12 [1] 14/-1/-1->13->12 [2] -1/-1/-1->13->12 [3] -1/-1/-1->13->12 [4] 14/-1/-1->13->12 [5] 14/-1/-1->13->12 [6] -1/-1/-1->13->12 [7] -1/-1/-1->13->12
 3: nid005580:71820:72338 [1] NCCL INFO P2P Chunksize set to 131072
30: nid005936:49910:50467 [2] NCCL INFO Trees [0] 123/-1/-1->122->121 [1] 123/-1/-1->122->121 [2] 123/118/126->122->114 [3] 123/118/126->122->114 [4] 123/-1/-1->122->121 [5] 123/-1/-1->122->121 [6] 123/-1/-1->122->118 [7] 123/-1/-1->122->118
30: nid005936:49909:50450 [1] NCCL INFO Trees [0] 122/-1/-1->121->120 [1] 122/-1/-1->121->120 [2] -1/-1/-1->121->120 [3] -1/-1/-1->121->120 [4] 122/-1/-1->121->120 [5] 122/-1/-1->121->120 [6] -1/-1/-1->121->120 [7] -1/-1/-1->121->120
30: nid005936:49911:50449 [3] NCCL INFO Trees [0] -1/-1/-1->123->122 [1] -1/-1/-1->123->122 [2] 120/-1/-1->123->122 [3] 120/-1/-1->123->122 [4] -1/-1/-1->123->122 [5] -1/-1/-1->123->122 [6] 120/-1/-1->123->122 [7] 120/-1/-1->123->122
30: nid005936:49910:50467 [2] NCCL INFO P2P Chunksize set to 131072
30: nid005936:49909:50450 [1] NCCL INFO P2P Chunksize set to 131072
31: nid005937:256589:256847 [0] NCCL INFO P2P Chunksize set to 131072
31: nid005937:256591:257123 [2] NCCL INFO P2P Chunksize set to 131072
 0: nid005574:69058:69552 [0] NCCL INFO Channel 06/08 :    0   3   1   5   4   7   6  10   8  11   9  13  12  15  14  18  16  19  17  21
 0: nid005574:69058:69552 [0] NCCL INFO Channel 07/08 :    0   3   2   6   4   7   5   9   8  11  10  14  12  15  13  17  16  19  18  22
 2: nid005577:17422:17953 [0] NCCL INFO comm 0xaaaaf334fcf0 rank 8 nRanks 128 nNodes 32 localRanks 4 localRank 0 MNNVL 0
 1: nid005576:147558:148070 [1] NCCL INFO Trees [0] 6/-1/-1->5->4 [1] 6/-1/-1->5->4 [2] -1/-1/-1->5->4 [3] -1/-1/-1->5->4 [4] 6/-1/-1->5->4 [5] 6/-1/-1->5->4 [6] -1/-1/-1->5->4 [7] -1/-1/-1->5->4
 1: nid005576:147558:148070 [1] NCCL INFO P2P Chunksize set to 131072
 1: nid005576:147560:148100 [3] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6 [2] 4/-1/-1->7->6 [3] 4/-1/-1->7->6 [4] -1/-1/-1->7->6 [5] -1/-1/-1->7->6 [6] 4/-1/-1->7->6 [7] 4/-1/-1->7->6
 3: nid005580:71819:72290 [0] NCCL INFO Trees [0] 13/-1/-1->12->8 [1] 13/-1/-1->12->8 [2] 13/-1/-1->12->15 [3] 13/-1/-1->12->15 [4] 13/20/4->12->28 [5] 13/20/4->12->28 [6] 13/-1/-1->12->15 [7] 13/-1/-1->12->15
 3: nid005580:71819:72290 [0] NCCL INFO P2P Chunksize set to 131072
30: nid005936:49911:50449 [3] NCCL INFO P2P Chunksize set to 131072
 0: nid005574:69058:69552 [0] NCCL INFO Trees [0] 1/64/-1->0->-1 [1] 1/64/-1->0->-1 [2] 1/-1/-1->0->3 [3] 1/-1/-1->0->3 [4] 1/-1/-1->0->4 [5] 1/-1/-1->0->4 [6] 1/-1/-1->0->3 [7] 1/-1/-1->0->3
 0: nid005574:69058:69552 [0] NCCL INFO P2P Chunksize set to 131072
 2: nid005577:17425:17981 [3] NCCL INFO Trees [0] -1/-1/-1->11->10 [1] -1/-1/-1->11->10 [2] 8/-1/-1->11->10 [3] 8/-1/-1->11->10 [4] -1/-1/-1->11->10 [5] -1/-1/-1->11->10 [6] 8/-1/-1->11->10 [7] 8/-1/-1->11->10
 2: nid005577:17424:17982 [2] NCCL INFO Trees [0] 11/-1/-1->10->9 [1] 11/-1/-1->10->9 [2] 11/6/14->10->18 [3] 11/6/14->10->18 [4] 11/-1/-1->10->9 [5] 11/-1/-1->10->9 [6] 11/-1/-1->10->6 [7] 11/-1/-1->10->6
 2: nid005577:17425:17981 [3] NCCL INFO P2P Chunksize set to 131072
 2: nid005577:17424:17982 [2] NCCL INFO P2P Chunksize set to 131072
 2: nid005577:17423:17952 [1] NCCL INFO Trees [0] 10/-1/-1->9->8 [1] 10/-1/-1->9->8 [2] -1/-1/-1->9->8 [3] -1/-1/-1->9->8 [4] 10/-1/-1->9->8 [5] 10/-1/-1->9->8 [6] -1/-1/-1->9->8 [7] -1/-1/-1->9->8
 1: nid005576:147557:148053 [0] NCCL INFO comm 0xaaab2078f8e0 rank 4 nRanks 128 nNodes 32 localRanks 4 localRank 0 MNNVL 0
 1: nid005576:147559:148101 [2] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5 [2] 7/-1/-1->6->10 [3] 7/-1/-1->6->10 [4] 7/-1/-1->6->5 [5] 7/-1/-1->6->5 [6] 7/10/2->6->14 [7] 7/10/2->6->14
 1: nid005576:147560:148100 [3] NCCL INFO P2P Chunksize set to 131072
 4: nid005581:264523:265016 [0] NCCL INFO Trees [0] 17/8/24->16->32 [1] 17/8/24->16->32 [2] 17/-1/-1->16->19 [3] 17/-1/-1->16->19 [4] 17/-1/-1->16->20 [5] 17/-1/-1->16->20 [6] 17/-1/-1->16->19 [7] 17/-1/-1->16->19
 4: nid005581:264523:265016 [0] NCCL INFO P2P Chunksize set to 131072
30: nid005936:49908:50465 [0] NCCL INFO Trees [0] 121/116/124->120->112 [1] 121/116/124->120->112 [2] 121/-1/-1->120->123 [3] 121/-1/-1->120->123 [4] 121/-1/-1->120->116 [5] 121/-1/-1->120->116 [6] 121/-1/-1->120->123 [7] 121/-1/-1->120->123
30: nid005936:49908:50465 [0] NCCL INFO P2P Chunksize set to 131072
11: nid005591:191605:192144 [2] NCCL INFO Trees [0] 47/-1/-1->46->45 [1] 47/-1/-1->46->45 [2] 47/-1/-1->46->42 [3] 47/-1/-1->46->42 [4] 47/-1/-1->46->45 [5] 47/-1/-1->46->45 [6] 47/54/38->46->30 [7] 47/54/38->46->30
11: nid005591:191605:192144 [2] NCCL INFO P2P Chunksize set to 131072
 2: nid005577:17423:17952 [1] NCCL INFO P2P Chunksize set to 131072
 1: nid005576:147559:148101 [2] NCCL INFO P2P Chunksize set to 131072
 1: nid005576:147557:148053 [0] NCCL INFO Trees [0] 5/-1/-1->4->8 [1] 5/-1/-1->4->8 [2] 5/-1/-1->4->7 [3] 5/-1/-1->4->7 [4] 5/8/0->4->12 [5] 5/8/0->4->12 [6] 5/-1/-1->4->7 [7] 5/-1/-1->4->7
 1: nid005576:147557:148053 [0] NCCL INFO P2P Chunksize set to 131072
 2: nid005577:17422:17953 [0] NCCL INFO Trees [0] 9/4/12->8->16 [1] 9/4/12->8->16 [2] 9/-1/-1->8->11 [3] 9/-1/-1->8->11 [4] 9/-1/-1->8->4 [5] 9/-1/-1->8->4 [6] 9/-1/-1->8->11 [7] 9/-1/-1->8->11
 2: nid005577:17422:17953 [0] NCCL INFO P2P Chunksize set to 131072
11: nid005591:191606:192116 [3] NCCL INFO comm 0xaaaae7d03880 rank 47 nRanks 128 nNodes 32 localRanks 4 localRank 3 MNNVL 0
11: nid005591:191606:192116 [3] NCCL INFO Trees [0] -1/-1/-1->47->46 [1] -1/-1/-1->47->46 [2] 44/-1/-1->47->46 [3] 44/-1/-1->47->46 [4] -1/-1/-1->47->46 [5] -1/-1/-1->47->46 [6] 44/-1/-1->47->46 [7] 44/-1/-1->47->46
11: nid005591:191606:192116 [3] NCCL INFO P2P Chunksize set to 131072
24: nid005918:92507:93078 [3] NCCL INFO comm 0xaaaae09e21b0 rank 99 nRanks 128 nNodes 32 localRanks 4 localRank 3 MNNVL 0
24: nid005918:92506:93079 [2] NCCL INFO comm 0xaaab22641a60 rank 98 nRanks 128 nNodes 32 localRanks 4 localRank 2 MNNVL 0
24: nid005918:92507:93078 [3] NCCL INFO Trees [0] -1/-1/-1->99->98 [1] -1/-1/-1->99->98 [2] 96/-1/-1->99->98 [3] 96/-1/-1->99->98 [4] -1/-1/-1->99->98 [5] -1/-1/-1->99->98 [6] 96/-1/-1->99->98 [7] 96/-1/-1->99->98
24: nid005918:92507:93078 [3] NCCL INFO P2P Chunksize set to 131072
24: nid005918:92506:93079 [2] NCCL INFO Trees [0] 99/-1/-1->98->97 [1] 99/-1/-1->98->97 [2] 99/82/114->98->66 [3] 99/82/114->98->66 [4] 99/-1/-1->98->97 [5] 99/-1/-1->98->97 [6] 99/-1/-1->98->102 [7] 99/-1/-1->98->102
24: nid005918:92506:93079 [2] NCCL INFO P2P Chunksize set to 131072
24: nid005918:92505:93080 [1] NCCL INFO comm 0xaaab23b3bb80 rank 97 nRanks 128 nNodes 32 localRanks 4 localRank 1 MNNVL 0
24: nid005918:92504:93029 [0] NCCL INFO comm 0xaaaaf3895ae0 rank 96 nRanks 128 nNodes 32 localRanks 4 localRank 0 MNNVL 0
24: nid005918:92505:93080 [1] NCCL INFO Trees [0] 98/-1/-1->97->96 [1] 98/-1/-1->97->96 [2] -1/-1/-1->97->96 [3] -1/-1/-1->97->96 [4] 98/-1/-1->97->96 [5] 98/-1/-1->97->96 [6] -1/-1/-1->97->96 [7] -1/-1/-1->97->96
24: nid005918:92505:93080 [1] NCCL INFO P2P Chunksize set to 131072
24: nid005918:92504:93029 [0] NCCL INFO Trees [0] 97/80/112->96->64 [1] 97/80/112->96->64 [2] 97/-1/-1->96->99 [3] 97/-1/-1->96->99 [4] 97/-1/-1->96->100 [5] 97/-1/-1->96->100 [6] 97/-1/-1->96->99 [7] 97/-1/-1->96->99
24: nid005918:92504:93029 [0] NCCL INFO P2P Chunksize set to 131072
23: nid005917:276887:277420 [2] NCCL INFO comm 0xaaaaf1b2b6f0 rank 94 nRanks 128 nNodes 32 localRanks 4 localRank 2 MNNVL 0
23: nid005917:276888:277422 [3] NCCL INFO comm 0xaaaaf34fa080 rank 95 nRanks 128 nNodes 32 localRanks 4 localRank 3 MNNVL 0
23: nid005917:276886:277419 [1] NCCL INFO comm 0xaaab0f582930 rank 93 nRanks 128 nNodes 32 localRanks 4 localRank 1 MNNVL 0
23: nid005917:276887:277420 [2] NCCL INFO Trees [0] 95/-1/-1->94->93 [1] 95/-1/-1->94->93 [2] 95/-1/-1->94->90 [3] 95/-1/-1->94->90 [4] 95/-1/-1->94->93 [5] 95/-1/-1->94->93 [6] 95/110/78->94->62 [7] 95/110/78->94->62
23: nid005917:276888:277422 [3] NCCL INFO Trees [0] -1/-1/-1->95->94 [1] -1/-1/-1->95->94 [2] 92/-1/-1->95->94 [3] 92/-1/-1->95->94 [4] -1/-1/-1->95->94 [5] -1/-1/-1->95->94 [6] 92/-1/-1->95->94 [7] 92/-1/-1->95->94
23: nid005917:276887:277420 [2] NCCL INFO P2P Chunksize set to 131072
23: nid005917:276888:277422 [3] NCCL INFO P2P Chunksize set to 131072
23: nid005917:276886:277419 [1] NCCL INFO Trees [0] 94/-1/-1->93->92 [1] 94/-1/-1->93->92 [2] -1/-1/-1->93->92 [3] -1/-1/-1->93->92 [4] 94/-1/-1->93->92 [5] 94/-1/-1->93->92 [6] -1/-1/-1->93->92 [7] -1/-1/-1->93->92
23: nid005917:276886:277419 [1] NCCL INFO P2P Chunksize set to 131072
22: nid005915:274817:275333 [3] NCCL INFO comm 0xaaab11483950 rank 91 nRanks 128 nNodes 32 localRanks 4 localRank 3 MNNVL 0
22: nid005915:274816:275334 [2] NCCL INFO comm 0xaaaafe3ab720 rank 90 nRanks 128 nNodes 32 localRanks 4 localRank 2 MNNVL 0
23: nid005917:276885:277421 [0] NCCL INFO comm 0xaaaae40fdd90 rank 92 nRanks 128 nNodes 32 localRanks 4 localRank 0 MNNVL 0
22: nid005915:274817:275333 [3] NCCL INFO Trees [0] -1/-1/-1->91->90 [1] -1/-1/-1->91->90 [2] 88/-1/-1->91->90 [3] 88/-1/-1->91->90 [4] -1/-1/-1->91->90 [5] -1/-1/-1->91->90 [6] 88/-1/-1->91->90 [7] 88/-1/-1->91->90
22: nid005915:274817:275333 [3] NCCL INFO P2P Chunksize set to 131072
22: nid005915:274816:275334 [2] NCCL INFO Trees [0] 91/-1/-1->90->89 [1] 91/-1/-1->90->89 [2] 91/86/94->90->82 [3] 91/86/94->90->82 [4] 91/-1/-1->90->89 [5] 91/-1/-1->90->89 [6] 91/-1/-1->90->86 [7] 91/-1/-1->90->86
22: nid005915:274816:275334 [2] NCCL INFO P2P Chunksize set to 131072
22: nid005915:274815:275332 [1] NCCL INFO comm 0xaaab0ea2ac20 rank 89 nRanks 128 nNodes 32 localRanks 4 localRank 1 MNNVL 0
22: nid005915:274814:275290 [0] NCCL INFO comm 0xaaaad1683e90 rank 88 nRanks 128 nNodes 32 localRanks 4 localRank 0 MNNVL 0
23: nid005917:276885:277421 [0] NCCL INFO Trees [0] 93/-1/-1->92->88 [1] 93/-1/-1->92->88 [2] 93/-1/-1->92->95 [3] 93/-1/-1->92->95 [4] 93/108/76->92->60 [5] 93/108/76->92->60 [6] 93/-1/-1->92->95 [7] 93/-1/-1->92->95
23: nid005917:276885:277421 [0] NCCL INFO P2P Chunksize set to 131072
21: nid005914:166787:167300 [3] NCCL INFO comm 0xaaaadea21c50 rank 87 nRanks 128 nNodes 32 localRanks 4 localRank 3 MNNVL 0
21: nid005914:166786:167270 [2] NCCL INFO comm 0xaaab02d82db0 rank 86 nRanks 128 nNodes 32 localRanks 4 localRank 2 MNNVL 0
22: nid005915:274815:275332 [1] NCCL INFO Trees [0] 90/-1/-1->89->88 [1] 90/-1/-1->89->88 [2] -1/-1/-1->89->88 [3] -1/-1/-1->89->88 [4] 90/-1/-1->89->88 [5] 90/-1/-1->89->88 [6] -1/-1/-1->89->88 [7] -1/-1/-1->89->88
22: nid005915:274815:275332 [1] NCCL INFO P2P Chunksize set to 131072
21: nid005914:166787:167300 [3] NCCL INFO Trees [0] -1/-1/-1->87->86 [1] -1/-1/-1->87->86 [2] 84/-1/-1->87->86 [3] 84/-1/-1->87->86 [4] -1/-1/-1->87->86 [5] -1/-1/-1->87->86 [6] 84/-1/-1->87->86 [7] 84/-1/-1->87->86
21: nid005914:166787:167300 [3] NCCL INFO P2P Chunksize set to 131072
21: nid005914:166785:167301 [1] NCCL INFO comm 0xaaaaf1392a50 rank 85 nRanks 128 nNodes 32 localRanks 4 localRank 1 MNNVL 0
21: nid005914:166784:167271 [0] NCCL INFO comm 0xaaab092dcbd0 rank 84 nRanks 128 nNodes 32 localRanks 4 localRank 0 MNNVL 0
21: nid005914:166786:167270 [2] NCCL INFO Trees [0] 87/-1/-1->86->85 [1] 87/-1/-1->86->85 [2] 87/-1/-1->86->90 [3] 87/-1/-1->86->90 [4] 87/-1/-1->86->85 [5] 87/-1/-1->86->85 [6] 87/90/82->86->78 [7] 87/90/82->86->78
21: nid005914:166786:167270 [2] NCCL INFO P2P Chunksize set to 131072
22: nid005915:274814:275290 [0] NCCL INFO Trees [0] 89/84/92->88->80 [1] 89/84/92->88->80 [2] 89/-1/-1->88->91 [3] 89/-1/-1->88->91 [4] 89/-1/-1->88->84 [5] 89/-1/-1->88->84 [6] 89/-1/-1->88->91 [7] 89/-1/-1->88->91
22: nid005915:274814:275290 [0] NCCL INFO P2P Chunksize set to 131072
21: nid005914:166785:167301 [1] NCCL INFO Trees [0] 86/-1/-1->85->84 [1] 86/-1/-1->85->84 [2] -1/-1/-1->85->84 [3] -1/-1/-1->85->84 [4] 86/-1/-1->85->84 [5] 86/-1/-1->85->84 [6] -1/-1/-1->85->84 [7] -1/-1/-1->85->84
21: nid005914:166784:167271 [0] NCCL INFO Trees [0] 85/-1/-1->84->88 [1] 85/-1/-1->84->88 [2] 85/-1/-1->84->87 [3] 85/-1/-1->84->87 [4] 85/88/80->84->76 [5] 85/88/80->84->76 [6] 85/-1/-1->84->87 [7] 85/-1/-1->84->87
21: nid005914:166785:167301 [1] NCCL INFO P2P Chunksize set to 131072
21: nid005914:166784:167271 [0] NCCL INFO P2P Chunksize set to 131072
20: nid005913:292684:293199 [3] NCCL INFO comm 0xaaaae94038c0 rank 83 nRanks 128 nNodes 32 localRanks 4 localRank 3 MNNVL 0
20: nid005913:292684:293199 [3] NCCL INFO Trees [0] -1/-1/-1->83->82 [1] -1/-1/-1->83->82 [2] 80/-1/-1->83->82 [3] 80/-1/-1->83->82 [4] -1/-1/-1->83->82 [5] -1/-1/-1->83->82 [6] 80/-1/-1->83->82 [7] 80/-1/-1->83->82
20: nid005913:292683:293201 [2] NCCL INFO comm 0xaaaaf0f2a8d0 rank 82 nRanks 128 nNodes 32 localRanks 4 localRank 2 MNNVL 0
20: nid005913:292684:293199 [3] NCCL INFO P2P Chunksize set to 131072
20: nid005913:292682:293200 [1] NCCL INFO comm 0xaaaaf6e99730 rank 81 nRanks 128 nNodes 32 localRanks 4 localRank 1 MNNVL 0
20: nid005913:292681:293089 [0] NCCL INFO comm 0xaaab2e755bf0 rank 80 nRanks 128 nNodes 32 localRanks 4 localRank 0 MNNVL 0
19: nid005912:12438:12958 [3] NCCL INFO comm 0xaaaae3c43340 rank 79 nRanks 128 nNodes 32 localRanks 4 localRank 3 MNNVL 0
20: nid005913:292683:293201 [2] NCCL INFO Trees [0] 83/-1/-1->82->81 [1] 83/-1/-1->82->81 [2] 83/74/90->82->98 [3] 83/74/90->82->98 [4] 83/-1/-1->82->81 [5] 83/-1/-1->82->81 [6] 83/-1/-1->82->86 [7] 83/-1/-1->82->86
20: nid005913:292683:293201 [2] NCCL INFO P2P Chunksize set to 131072
19: nid005912:12437:12976 [2] NCCL INFO comm 0xaaaaec4bb890 rank 78 nRanks 128 nNodes 32 localRanks 4 localRank 2 MNNVL 0
19: nid005912:12438:12958 [3] NCCL INFO Trees [0] -1/-1/-1->79->78 [1] -1/-1/-1->79->78 [2] 76/-1/-1->79->78 [3] 76/-1/-1->79->78 [4] -1/-1/-1->79->78 [5] -1/-1/-1->79->78 [6] 76/-1/-1->79->78 [7] 76/-1/-1->79->78
19: nid005912:12438:12958 [3] NCCL INFO P2P Chunksize set to 131072
20: nid005913:292682:293200 [1] NCCL INFO Trees [0] 82/-1/-1->81->80 [1] 82/-1/-1->81->80 [2] -1/-1/-1->81->80 [3] -1/-1/-1->81->80 [4] 82/-1/-1->81->80 [5] 82/-1/-1->81->80 [6] -1/-1/-1->81->80 [7] -1/-1/-1->81->80
20: nid005913:292682:293200 [1] NCCL INFO P2P Chunksize set to 131072
20: nid005913:292681:293089 [0] NCCL INFO Trees [0] 81/72/88->80->96 [1] 81/72/88->80->96 [2] 81/-1/-1->80->83 [3] 81/-1/-1->80->83 [4] 81/-1/-1->80->84 [5] 81/-1/-1->80->84 [6] 81/-1/-1->80->83 [7] 81/-1/-1->80->83
12: nid005594:53085:53561 [0] NCCL INFO comm 0xaaab0e435340 rank 48 nRanks 128 nNodes 32 localRanks 4 localRank 0 MNNVL 0
12: nid005594:53088:53605 [3] NCCL INFO comm 0xaaab14e02fb0 rank 51 nRanks 128 nNodes 32 localRanks 4 localRank 3 MNNVL 0
15: nid005601:210679:211194 [3] NCCL INFO comm 0xaaab0b2c3130 rank 63 nRanks 128 nNodes 32 localRanks 4 localRank 3 MNNVL 0
13: nid005595:197886:198472 [3] NCCL INFO comm 0xaaaaea46b560 rank 55 nRanks 128 nNodes 32 localRanks 4 localRank 3 MNNVL 0
13: nid005595:197885:198470 [2] NCCL INFO comm 0xaaab3c8b15f0 rank 54 nRanks 128 nNodes 32 localRanks 4 localRank 2 MNNVL 0
20: nid005913:292681:293089 [0] NCCL INFO P2P Chunksize set to 131072
12: nid005594:53087:53607 [2] NCCL INFO comm 0xaaab36e31f10 rank 50 nRanks 128 nNodes 32 localRanks 4 localRank 2 MNNVL 0
15: nid005601:210678:211209 [2] NCCL INFO comm 0xaaab22984300 rank 62 nRanks 128 nNodes 32 localRanks 4 localRank 2 MNNVL 0
15: nid005601:210677:211211 [1] NCCL INFO comm 0xaaaaee59b4c0 rank 61 nRanks 128 nNodes 32 localRanks 4 localRank 1 MNNVL 0
13: nid005595:197883:198429 [0] NCCL INFO comm 0xaaab1fa69360 rank 52 nRanks 128 nNodes 32 localRanks 4 localRank 0 MNNVL 0
13: nid005595:197884:198471 [1] NCCL INFO comm 0xaaab0cbd2c40 rank 53 nRanks 128 nNodes 32 localRanks 4 localRank 1 MNNVL 0
19: nid005912:12436:12959 [1] NCCL INFO comm 0xaaaaeb758490 rank 77 nRanks 128 nNodes 32 localRanks 4 localRank 1 MNNVL 0
12: nid005594:53086:53606 [1] NCCL INFO comm 0xaaaadbafb110 rank 49 nRanks 128 nNodes 32 localRanks 4 localRank 1 MNNVL 0
15: nid005601:210676:211210 [0] NCCL INFO comm 0xaaab05fd2fb0 rank 60 nRanks 128 nNodes 32 localRanks 4 localRank 0 MNNVL 0
13: nid005595:197886:198472 [3] NCCL INFO Trees [0] -1/-1/-1->55->54 [1] -1/-1/-1->55->54 [2] 52/-1/-1->55->54 [3] 52/-1/-1->55->54 [4] -1/-1/-1->55->54 [5] -1/-1/-1->55->54 [6] 52/-1/-1->55->54 [7] 52/-1/-1->55->54
13: nid005595:197886:198472 [3] NCCL INFO P2P Chunksize set to 131072
13: nid005595:197885:198470 [2] NCCL INFO Trees [0] 55/-1/-1->54->53 [1] 55/-1/-1->54->53 [2] 55/-1/-1->54->58 [3] 55/-1/-1->54->58 [4] 55/-1/-1->54->53 [5] 55/-1/-1->54->53 [6] 55/58/50->54->46 [7] 55/58/50->54->46
19: nid005912:12435:12909 [0] NCCL INFO comm 0xaaab04d29d70 rank 76 nRanks 128 nNodes 32 localRanks 4 localRank 0 MNNVL 0
19: nid005912:12437:12976 [2] NCCL INFO Trees [0] 79/-1/-1->78->77 [1] 79/-1/-1->78->77 [2] 79/-1/-1->78->74 [3] 79/-1/-1->78->74 [4] 79/-1/-1->78->77 [5] 79/-1/-1->78->77 [6] 79/86/70->78->94 [7] 79/86/70->78->94
19: nid005912:12437:12976 [2] NCCL INFO P2P Chunksize set to 131072
15: nid005601:210679:211194 [3] NCCL INFO Trees [0] -1/-1/-1->63->62 [1] -1/-1/-1->63->62 [2] 60/-1/-1->63->62 [3] 60/-1/-1->63->62 [4] -1/-1/-1->63->62 [5] -1/-1/-1->63->62 [6] 60/-1/-1->63->62 [7] 60/-1/-1->63->62
15: nid005601:210679:211194 [3] NCCL INFO P2P Chunksize set to 131072
13: nid005595:197883:198429 [0] NCCL INFO Trees [0] 53/-1/-1->52->56 [1] 53/-1/-1->52->56 [2] 53/-1/-1->52->55 [3] 53/-1/-1->52->55 [4] 53/56/48->52->44 [5] 53/56/48->52->44 [6] 53/-1/-1->52->55 [7] 53/-1/-1->52->55
13: nid005595:197885:198470 [2] NCCL INFO P2P Chunksize set to 131072
13: nid005595:197883:198429 [0] NCCL INFO P2P Chunksize set to 131072
19: nid005912:12436:12959 [1] NCCL INFO Trees [0] 78/-1/-1->77->76 [1] 78/-1/-1->77->76 [2] -1/-1/-1->77->76 [3] -1/-1/-1->77->76 [4] 78/-1/-1->77->76 [5] 78/-1/-1->77->76 [6] -1/-1/-1->77->76 [7] -1/-1/-1->77->76
19: nid005912:12436:12959 [1] NCCL INFO P2P Chunksize set to 131072
15: nid005601:210678:211209 [2] NCCL INFO Trees [0] 63/-1/-1->62->61 [1] 63/-1/-1->62->61 [2] 63/-1/-1->62->58 [3] 63/-1/-1->62->58 [4] 63/-1/-1->62->61 [5] 63/-1/-1->62->61 [6] 63/94/30->62->126 [7] 63/94/30->62->126
15: nid005601:210678:211209 [2] NCCL INFO P2P Chunksize set to 131072
15: nid005601:210677:211211 [1] NCCL INFO Trees [0] 62/-1/-1->61->60 [1] 62/-1/-1->61->60 [2] -1/-1/-1->61->60 [3] -1/-1/-1->61->60 [4] 62/-1/-1->61->60 [5] 62/-1/-1->61->60 [6] -1/-1/-1->61->60 [7] -1/-1/-1->61->60
15: nid005601:210676:211210 [0] NCCL INFO Trees [0] 61/-1/-1->60->56 [1] 61/-1/-1->60->56 [2] 61/-1/-1->60->63 [3] 61/-1/-1->60->63 [4] 61/92/28->60->124 [5] 61/92/28->60->124 [6] 61/-1/-1->60->63 [7] 61/-1/-1->60->63
13: nid005595:197884:198471 [1] NCCL INFO Trees [0] 54/-1/-1->53->52 [1] 54/-1/-1->53->52 [2] -1/-1/-1->53->52 [3] -1/-1/-1->53->52 [4] 54/-1/-1->53->52 [5] 54/-1/-1->53->52 [6] -1/-1/-1->53->52 [7] -1/-1/-1->53->52
13: nid005595:197884:198471 [1] NCCL INFO P2P Chunksize set to 131072
14: nid005600:217722:218227 [2] NCCL INFO comm 0xaaaada11bcd0 rank 58 nRanks 128 nNodes 32 localRanks 4 localRank 2 MNNVL 0
14: nid005600:217723:218244 [3] NCCL INFO comm 0xaaab2a979520 rank 59 nRanks 128 nNodes 32 localRanks 4 localRank 3 MNNVL 0
12: nid005594:53088:53605 [3] NCCL INFO Trees [0] -1/-1/-1->51->50 [1] -1/-1/-1->51->50 [2] 48/-1/-1->51->50 [3] 48/-1/-1->51->50 [4] -1/-1/-1->51->50 [5] -1/-1/-1->51->50 [6] 48/-1/-1->51->50 [7] 48/-1/-1->51->50
12: nid005594:53087:53607 [2] NCCL INFO Trees [0] 51/-1/-1->50->49 [1] 51/-1/-1->50->49 [2] 51/42/58->50->34 [3] 51/42/58->50->34 [4] 51/-1/-1->50->49 [5] 51/-1/-1->50->49 [6] 51/-1/-1->50->54 [7] 51/-1/-1->50->54
12: nid005594:53086:53606 [1] NCCL INFO Trees [0] 50/-1/-1->49->48 [1] 50/-1/-1->49->48 [2] -1/-1/-1->49->48 [3] -1/-1/-1->49->48 [4] 50/-1/-1->49->48 [5] 50/-1/-1->49->48 [6] -1/-1/-1->49->48 [7] -1/-1/-1->49->48
12: nid005594:53088:53605 [3] NCCL INFO P2P Chunksize set to 131072
12: nid005594:53087:53607 [2] NCCL INFO P2P Chunksize set to 131072
12: nid005594:53086:53606 [1] NCCL INFO P2P Chunksize set to 131072
15: nid005601:210677:211211 [1] NCCL INFO P2P Chunksize set to 131072
15: nid005601:210676:211210 [0] NCCL INFO P2P Chunksize set to 131072
19: nid005912:12435:12909 [0] NCCL INFO Trees [0] 77/-1/-1->76->72 [1] 77/-1/-1->76->72 [2] 77/-1/-1->76->79 [3] 77/-1/-1->76->79 [4] 77/84/68->76->92 [5] 77/84/68->76->92 [6] 77/-1/-1->76->79 [7] 77/-1/-1->76->79
19: nid005912:12435:12909 [0] NCCL INFO P2P Chunksize set to 131072
14: nid005600:217720:218195 [0] NCCL INFO comm 0xaaaadc9bcbc0 rank 56 nRanks 128 nNodes 32 localRanks 4 localRank 0 MNNVL 0
18: nid005911:38864:39357 [0] NCCL INFO comm 0xaaaade95adc0 rank 72 nRanks 128 nNodes 32 localRanks 4 localRank 0 MNNVL 0
18: nid005911:38866:39421 [2] NCCL INFO comm 0xaaaafa2a9ac0 rank 74 nRanks 128 nNodes 32 localRanks 4 localRank 2 MNNVL 0
18: nid005911:38867:39424 [3] NCCL INFO comm 0xaaab31f11170 rank 75 nRanks 128 nNodes 32 localRanks 4 localRank 3 MNNVL 0
18: nid005911:38865:39420 [1] NCCL INFO comm 0xaaaae2c31590 rank 73 nRanks 128 nNodes 32 localRanks 4 localRank 1 MNNVL 0
14: nid005600:217721:218228 [1] NCCL INFO comm 0xaaaacda93d30 rank 57 nRanks 128 nNodes 32 localRanks 4 localRank 1 MNNVL 0
12: nid005594:53085:53561 [0] NCCL INFO Trees [0] 49/40/56->48->32 [1] 49/40/56->48->32 [2] 49/-1/-1->48->51 [3] 49/-1/-1->48->51 [4] 49/-1/-1->48->52 [5] 49/-1/-1->48->52 [6] 49/-1/-1->48->51 [7] 49/-1/-1->48->51
14: nid005600:217722:218227 [2] NCCL INFO Trees [0] 59/-1/-1->58->57 [1] 59/-1/-1->58->57 [2] 59/54/62->58->50 [3] 59/54/62->58->50 [4] 59/-1/-1->58->57 [5] 59/-1/-1->58->57 [6] 59/-1/-1->58->54 [7] 59/-1/-1->58->54
14: nid005600:217722:218227 [2] NCCL INFO P2P Chunksize set to 131072
14: nid005600:217723:218244 [3] NCCL INFO Trees [0] -1/-1/-1->59->58 [1] -1/-1/-1->59->58 [2] 56/-1/-1->59->58 [3] 56/-1/-1->59->58 [4] -1/-1/-1->59->58 [5] -1/-1/-1->59->58 [6] 56/-1/-1->59->58 [7] 56/-1/-1->59->58
12: nid005594:53085:53561 [0] NCCL INFO P2P Chunksize set to 131072
17: nid005803:180733:181262 [1] NCCL INFO comm 0xaaab1f57afc0 rank 69 nRanks 128 nNodes 32 localRanks 4 localRank 1 MNNVL 0
17: nid005803:180734:181263 [2] NCCL INFO comm 0xaaab0a6d9870 rank 70 nRanks 128 nNodes 32 localRanks 4 localRank 2 MNNVL 0
17: nid005803:180735:181265 [3] NCCL INFO comm 0xaaab10aa06b0 rank 71 nRanks 128 nNodes 32 localRanks 4 localRank 3 MNNVL 0
17: nid005803:180732:181264 [0] NCCL INFO comm 0xaaaad12a2680 rank 68 nRanks 128 nNodes 32 localRanks 4 localRank 0 MNNVL 0
18: nid005911:38866:39421 [2] NCCL INFO Trees [0] 75/-1/-1->74->73 [1] 75/-1/-1->74->73 [2] 75/70/78->74->82 [3] 75/70/78->74->82 [4] 75/-1/-1->74->73 [5] 75/-1/-1->74->73 [6] 75/-1/-1->74->70 [7] 75/-1/-1->74->70
18: nid005911:38864:39357 [0] NCCL INFO Trees [0] 73/68/76->72->80 [1] 73/68/76->72->80 [2] 73/-1/-1->72->75 [3] 73/-1/-1->72->75 [4] 73/-1/-1->72->68 [5] 73/-1/-1->72->68 [6] 73/-1/-1->72->75 [7] 73/-1/-1->72->75
18: nid005911:38865:39420 [1] NCCL INFO Trees [0] 74/-1/-1->73->72 [1] 74/-1/-1->73->72 [2] -1/-1/-1->73->72 [3] -1/-1/-1->73->72 [4] 74/-1/-1->73->72 [5] 74/-1/-1->73->72 [6] -1/-1/-1->73->72 [7] -1/-1/-1->73->72
18: nid005911:38867:39424 [3] NCCL INFO Trees [0] -1/-1/-1->75->74 [1] -1/-1/-1->75->74 [2] 72/-1/-1->75->74 [3] 72/-1/-1->75->74 [4] -1/-1/-1->75->74 [5] -1/-1/-1->75->74 [6] 72/-1/-1->75->74 [7] 72/-1/-1->75->74
18: nid005911:38866:39421 [2] NCCL INFO P2P Chunksize set to 131072
18: nid005911:38864:39357 [0] NCCL INFO P2P Chunksize set to 131072
16: nid005802:6299:6898 [2] NCCL INFO comm 0xaaab08f00a50 rank 66 nRanks 128 nNodes 32 localRanks 4 localRank 2 MNNVL 0
16: nid005802:6300:6899 [3] NCCL INFO comm 0xaaaae402b650 rank 67 nRanks 128 nNodes 32 localRanks 4 localRank 3 MNNVL 0
14: nid005600:217723:218244 [3] NCCL INFO P2P Chunksize set to 131072
14: nid005600:217721:218228 [1] NCCL INFO Trees [0] 58/-1/-1->57->56 [1] 58/-1/-1->57->56 [2] -1/-1/-1->57->56 [3] -1/-1/-1->57->56 [4] 58/-1/-1->57->56 [5] 58/-1/-1->57->56 [6] -1/-1/-1->57->56 [7] -1/-1/-1->57->56
18: nid005911:38865:39420 [1] NCCL INFO P2P Chunksize set to 131072
18: nid005911:38867:39424 [3] NCCL INFO P2P Chunksize set to 131072
14: nid005600:217721:218228 [1] NCCL INFO P2P Chunksize set to 131072
16: nid005802:6298:6897 [1] NCCL INFO comm 0xaaab06e0b4f0 rank 65 nRanks 128 nNodes 32 localRanks 4 localRank 1 MNNVL 0
16: nid005802:6299:6898 [2] NCCL INFO Trees [0] 67/-1/-1->66->65 [1] 67/-1/-1->66->65 [2] 67/34/98->66->2 [3] 67/34/98->66->2 [4] 67/-1/-1->66->65 [5] 67/-1/-1->66->65 [6] 67/-1/-1->66->70 [7] 67/-1/-1->66->70
16: nid005802:6300:6899 [3] NCCL INFO Trees [0] -1/-1/-1->67->66 [1] -1/-1/-1->67->66 [2] 64/-1/-1->67->66 [3] 64/-1/-1->67->66 [4] -1/-1/-1->67->66 [5] -1/-1/-1->67->66 [6] 64/-1/-1->67->66 [7] 64/-1/-1->67->66
16: nid005802:6297:6852 [0] NCCL INFO comm 0xaaab18b83d10 rank 64 nRanks 128 nNodes 32 localRanks 4 localRank 0 MNNVL 0
14: nid005600:217720:218195 [0] NCCL INFO Trees [0] 57/52/60->56->48 [1] 57/52/60->56->48 [2] 57/-1/-1->56->59 [3] 57/-1/-1->56->59 [4] 57/-1/-1->56->52 [5] 57/-1/-1->56->52 [6] 57/-1/-1->56->59 [7] 57/-1/-1->56->59
14: nid005600:217720:218195 [0] NCCL INFO P2P Chunksize set to 131072
16: nid005802:6300:6899 [3] NCCL INFO P2P Chunksize set to 131072
16: nid005802:6299:6898 [2] NCCL INFO P2P Chunksize set to 131072
17: nid005803:180733:181262 [1] NCCL INFO Trees [0] 70/-1/-1->69->68 [1] 70/-1/-1->69->68 [2] -1/-1/-1->69->68 [3] -1/-1/-1->69->68 [4] 70/-1/-1->69->68 [5] 70/-1/-1->69->68 [6] -1/-1/-1->69->68 [7] -1/-1/-1->69->68
17: nid005803:180733:181262 [1] NCCL INFO P2P Chunksize set to 131072
16: nid005802:6298:6897 [1] NCCL INFO Trees [0] 66/-1/-1->65->64 [1] 66/-1/-1->65->64 [2] -1/-1/-1->65->64 [3] -1/-1/-1->65->64 [4] 66/-1/-1->65->64 [5] 66/-1/-1->65->64 [6] -1/-1/-1->65->64 [7] -1/-1/-1->65->64
16: nid005802:6298:6897 [1] NCCL INFO P2P Chunksize set to 131072
17: nid005803:180734:181263 [2] NCCL INFO Trees [0] 71/-1/-1->70->69 [1] 71/-1/-1->70->69 [2] 71/-1/-1->70->74 [3] 71/-1/-1->70->74 [4] 71/-1/-1->70->69 [5] 71/-1/-1->70->69 [6] 71/74/66->70->78 [7] 71/74/66->70->78
17: nid005803:180735:181265 [3] NCCL INFO Trees [0] -1/-1/-1->71->70 [1] -1/-1/-1->71->70 [2] 68/-1/-1->71->70 [3] 68/-1/-1->71->70 [4] -1/-1/-1->71->70 [5] -1/-1/-1->71->70 [6] 68/-1/-1->71->70 [7] 68/-1/-1->71->70
17: nid005803:180732:181264 [0] NCCL INFO Trees [0] 69/-1/-1->68->72 [1] 69/-1/-1->68->72 [2] 69/-1/-1->68->71 [3] 69/-1/-1->68->71 [4] 69/72/64->68->76 [5] 69/72/64->68->76 [6] 69/-1/-1->68->71 [7] 69/-1/-1->68->71
17: nid005803:180734:181263 [2] NCCL INFO P2P Chunksize set to 131072
17: nid005803:180732:181264 [0] NCCL INFO P2P Chunksize set to 131072
17: nid005803:180735:181265 [3] NCCL INFO P2P Chunksize set to 131072
16: nid005802:6297:6852 [0] NCCL INFO Trees [0] 65/32/96->64->0 [1] 65/32/96->64->0 [2] 65/-1/-1->64->67 [3] 65/-1/-1->64->67 [4] 65/-1/-1->64->68 [5] 65/-1/-1->64->68 [6] 65/-1/-1->64->67 [7] 65/-1/-1->64->67
16: nid005802:6297:6852 [0] NCCL INFO P2P Chunksize set to 131072
 9: nid005588:35936:36472 [1] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 9: nid005588:35936:36472 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
28: nid005929:16032:16570 [2] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
28: nid005929:16032:16570 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
26: nid005920:67123:67613 [0] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
26: nid005920:67123:67613 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
25: nid005919:107463:108001 [1] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
25: nid005919:107463:108001 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
27: nid005922:80744:81259 [3] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
27: nid005922:80744:81259 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
10: nid005590:110713:111240 [3] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
10: nid005590:110713:111240 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 4: nid005581:264525:265067 [2] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 4: nid005581:264525:265067 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 0: nid005574:69059:69601 [1] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 0: nid005574:69059:69601 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
10: nid005590:110712:111243 [2] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
10: nid005590:110712:111243 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 7: nid005585:122008:122545 [3] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 7: nid005585:122008:122545 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
25: nid005919:107465:108002 [3] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
25: nid005919:107465:108002 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 7: nid005585:122006:122526 [1] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 7: nid005585:122006:122526 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
28: nid005929:16033:16573 [3] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
28: nid005929:16033:16573 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
30: nid005936:49910:50467 [2] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
30: nid005936:49910:50467 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
31: nid005937:256592:257124 [3] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
31: nid005937:256592:257124 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
27: nid005922:80742:81229 [1] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
27: nid005922:80742:81229 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
26: nid005920:67125:67662 [2] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
26: nid005920:67125:67662 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 4: nid005581:264526:265063 [3] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 4: nid005581:264526:265063 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
25: nid005919:107464:108003 [2] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
25: nid005919:107464:108003 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
28: nid005929:16030:16526 [0] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
28: nid005929:16030:16526 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 5: nid005582:196716:197388 [3] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 5: nid005582:196716:197388 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 6: nid005584:28287:28819 [2] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 6: nid005584:28287:28819 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
30: nid005936:49909:50450 [1] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
30: nid005936:49909:50450 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
28: nid005929:16031:16569 [1] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
28: nid005929:16031:16569 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 0: nid005574:69060:69600 [2] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 0: nid005574:69060:69600 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
27: nid005922:80743:81258 [2] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
27: nid005922:80743:81258 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
31: nid005937:256590:257125 [1] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
31: nid005937:256590:257125 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
11: nid005591:191604:192145 [1] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
11: nid005591:191604:192145 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
25: nid005919:107462:107959 [0] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
25: nid005919:107462:107959 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
11: nid005591:191605:192144 [2] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
11: nid005591:191605:192144 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
27: nid005922:80741:81228 [0] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
27: nid005922:80741:81228 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
20: nid005913:292682:293200 [1] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
20: nid005913:292682:293200 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 1: nid005576:147558:148070 [1] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 1: nid005576:147558:148070 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
11: nid005591:191606:192116 [3] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
11: nid005591:191606:192116 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
10: nid005590:110711:111241 [1] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
10: nid005590:110711:111241 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
10: nid005590:110710:111197 [0] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 9: nid005588:35937:36471 [2] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 9: nid005588:35937:36471 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
10: nid005590:110710:111197 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 2: nid005577:17425:17981 [3] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 2: nid005577:17425:17981 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 9: nid005588:35935:36428 [0] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 9: nid005588:35935:36428 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 5: nid005582:196715:197387 [2] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 5: nid005582:196715:197387 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 3: nid005580:71821:72339 [2] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 3: nid005580:71821:72339 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
26: nid005920:67126:67661 [3] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
26: nid005920:67126:67661 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
22: nid005915:274817:275333 [3] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
22: nid005915:274817:275333 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
23: nid005917:276888:277422 [3] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
23: nid005917:276888:277422 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 7: nid005585:122007:122527 [2] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 7: nid005585:122007:122527 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
26: nid005920:67124:67660 [1] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
26: nid005920:67124:67660 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
14: nid005600:217721:218228 [1] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
14: nid005600:217721:218228 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 1: nid005576:147560:148100 [3] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 1: nid005576:147560:148100 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
17: nid005803:180733:181262 [1] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
17: nid005803:180733:181262 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 4: nid005581:264524:265064 [1] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 4: nid005581:264524:265064 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
23: nid005917:276886:277419 [1] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
23: nid005917:276886:277419 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
12: nid005594:53087:53607 [2] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
12: nid005594:53087:53607 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 6: nid005584:28288:28820 [3] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 6: nid005584:28288:28820 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 7: nid005585:122005:122496 [0] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 7: nid005585:122005:122496 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 0: nid005574:69058:69552 [0] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 0: nid005574:69058:69552 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 2: nid005577:17424:17982 [2] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 2: nid005577:17424:17982 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
15: nid005601:210676:211210 [0] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
15: nid005601:210676:211210 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 8: nid005586:68929:69489 [3] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 8: nid005586:68929:69489 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
24: nid005918:92507:93078 [3] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
24: nid005918:92507:93078 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 4: nid005581:264523:265016 [0] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 4: nid005581:264523:265016 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 8: nid005586:68926:69401 [0] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 8: nid005586:68926:69401 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
11: nid005591:191603:192099 [0] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
11: nid005591:191603:192099 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 2: nid005577:17423:17952 [1] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 2: nid005577:17423:17952 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 0: nid005574:69058:69552 [0] NCCL INFO CC Off, Multi-GPU CC Off, workFifoBytes 1048576
 5: nid005582:196713:197389 [0] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 5: nid005582:196714:197386 [1] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 5: nid005582:196713:197389 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 5: nid005582:196714:197386 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 0: nid005574:69061:69602 [3] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 0: nid005574:69061:69602 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 1: nid005576:147559:148101 [2] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 1: nid005576:147559:148101 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
22: nid005915:274816:275334 [2] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
22: nid005915:274816:275334 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
31: nid005937:256591:257123 [2] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
31: nid005937:256591:257123 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
31: nid005937:256589:256847 [0] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 6: nid005584:28285:28774 [0] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 6: nid005584:28285:28774 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
16: nid005802:6299:6898 [2] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
16: nid005802:6299:6898 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
20: nid005913:292684:293199 [3] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
20: nid005913:292684:293199 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
30: nid005936:49911:50449 [3] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
30: nid005936:49911:50449 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
19: nid005912:12438:12958 [3] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
19: nid005912:12438:12958 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 6: nid005584:28286:28818 [1] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 6: nid005584:28286:28818 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
31: nid005937:256589:256847 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
13: nid005595:197885:198470 [2] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
13: nid005595:197885:198470 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
19: nid005912:12437:12976 [2] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
19: nid005912:12437:12976 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 9: nid005588:35938:36474 [3] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 9: nid005588:35938:36474 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 8: nid005586:68927:69451 [1] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 8: nid005586:68927:69451 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 3: nid005580:71822:72337 [3] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 3: nid005580:71822:72337 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
29: nid005932:167680:168169 [0] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
29: nid005932:167680:168169 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
16: nid005802:6298:6897 [1] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
16: nid005802:6298:6897 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 1: nid005576:147557:148053 [0] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 1: nid005576:147557:148053 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
30: nid005936:49908:50465 [0] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
30: nid005936:49908:50465 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 3: nid005580:71819:72290 [0] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 3: nid005580:71819:72290 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
18: nid005911:38866:39421 [2] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
18: nid005911:38866:39421 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
18: nid005911:38864:39357 [0] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
19: nid005912:12436:12959 [1] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
19: nid005912:12436:12959 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
18: nid005911:38864:39357 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
22: nid005915:274815:275332 [1] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
22: nid005915:274815:275332 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
14: nid005600:217722:218227 [2] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
14: nid005600:217722:218227 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 8: nid005586:68928:69450 [2] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 8: nid005586:68928:69450 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
23: nid005917:276887:277420 [2] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
23: nid005917:276887:277420 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 3: nid005580:71820:72338 [1] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 3: nid005580:71820:72338 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
15: nid005601:210677:211211 [1] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
15: nid005601:210677:211211 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
22: nid005915:274814:275290 [0] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
22: nid005915:274814:275290 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
13: nid005595:197883:198429 [0] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
13: nid005595:197883:198429 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
21: nid005914:166785:167301 [1] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
21: nid005914:166785:167301 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 2: nid005577:17422:17953 [0] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 2: nid005577:17422:17953 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
24: nid005918:92506:93079 [2] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
24: nid005918:92506:93079 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
17: nid005803:180734:181263 [2] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
17: nid005803:180734:181263 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
23: nid005917:276885:277421 [0] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
23: nid005917:276885:277421 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
19: nid005912:12435:12909 [0] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
19: nid005912:12435:12909 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
15: nid005601:210679:211194 [3] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
15: nid005601:210679:211194 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
20: nid005913:292681:293089 [0] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
20: nid005913:292681:293089 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
13: nid005595:197884:198471 [1] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
13: nid005595:197884:198471 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
12: nid005594:53088:53605 [3] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
12: nid005594:53088:53605 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
20: nid005913:292683:293201 [2] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
29: nid005932:167681:168228 [1] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
29: nid005932:167681:168228 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
20: nid005913:292683:293201 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
28: nid005929:16032:16570 [2] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
14: nid005600:217723:218244 [3] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
14: nid005600:217723:218244 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
16: nid005802:6300:6899 [3] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
16: nid005802:6300:6899 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
21: nid005914:166784:167271 [0] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
21: nid005914:166784:167271 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
28: nid005929:16032:16570 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
28: nid005929:16032:16570 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
28: nid005929:16032:16570 [2] NCCL INFO ncclCommInitRank comm 0xaaab2fba3240 rank 114 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 commId 0x1958874c5d2a0126 - Init COMPLETE
28: nid005929:16032:16570 [2] NCCL INFO Init timings: rank 114 nranks 128 total 4.61 (kernels 0.06, bootstrap 4.05, allgathers 0.15, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
17: nid005803:180732:181264 [0] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
17: nid005803:180732:181264 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
13: nid005595:197886:198472 [3] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
13: nid005595:197886:198472 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
17: nid005803:180735:181265 [3] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
17: nid005803:180735:181265 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
18: nid005911:38865:39420 [1] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
18: nid005911:38865:39420 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
14: nid005600:217720:218195 [0] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
14: nid005600:217720:218195 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
15: nid005601:210678:211209 [2] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
15: nid005601:210678:211209 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
28: nid005929:16030:16526 [0] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
28: nid005929:16030:16526 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
28: nid005929:16030:16526 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
16: nid005802:6297:6852 [0] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
16: nid005802:6297:6852 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
28: nid005929:16030:16526 [0] NCCL INFO ncclCommInitRank comm 0xaaaad57d3fc0 rank 112 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 commId 0x1958874c5d2a0126 - Init COMPLETE
28: nid005929:16030:16526 [0] NCCL INFO Init timings: rank 112 nranks 128 total 5.39 (kernels 0.06, bootstrap 4.82, allgathers 0.15, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
12: nid005594:53086:53606 [1] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
12: nid005594:53086:53606 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
12: nid005594:53085:53561 [0] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
12: nid005594:53085:53561 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
28: nid005929:16031:16569 [1] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
28: nid005929:16031:16569 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
28: nid005929:16031:16569 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
28: nid005929:16031:16569 [1] NCCL INFO ncclCommInitRank comm 0xaaaaf8401170 rank 113 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 commId 0x1958874c5d2a0126 - Init COMPLETE
28: nid005929:16031:16569 [1] NCCL INFO Init timings: rank 113 nranks 128 total 4.62 (kernels 0.06, bootstrap 4.06, allgathers 0.15, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
28: nid005929:16033:16573 [3] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
29: nid005932:167682:168229 [2] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
29: nid005932:167682:168229 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
28: nid005929:16033:16573 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
28: nid005929:16033:16573 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
29: nid005932:167683:168230 [3] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
29: nid005932:167683:168230 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
28: nid005929:16033:16573 [3] NCCL INFO ncclCommInitRank comm 0xaaaade0c3510 rank 115 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 commId 0x1958874c5d2a0126 - Init COMPLETE
28: nid005929:16033:16573 [3] NCCL INFO Init timings: rank 115 nranks 128 total 3.52 (kernels 0.06, bootstrap 2.95, allgathers 0.15, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
18: nid005911:38867:39424 [3] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
18: nid005911:38867:39424 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
21: nid005914:166786:167270 [2] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
21: nid005914:166786:167270 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
21: nid005914:166787:167300 [3] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
21: nid005914:166787:167300 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
27: nid005922:80743:81258 [2] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
27: nid005922:80743:81258 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
27: nid005922:80743:81258 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
27: nid005922:80743:81258 [2] NCCL INFO ncclCommInitRank comm 0xaaab0b1de990 rank 110 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 commId 0x1958874c5d2a0126 - Init COMPLETE
27: nid005922:80743:81258 [2] NCCL INFO Init timings: rank 110 nranks 128 total 4.62 (kernels 1.05, bootstrap 3.06, allgathers 0.15, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
27: nid005922:80741:81228 [0] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
27: nid005922:80741:81228 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
24: nid005918:92504:93029 [0] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
24: nid005918:92504:93029 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
27: nid005922:80741:81228 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
27: nid005922:80741:81228 [0] NCCL INFO ncclCommInitRank comm 0xaaab18560ec0 rank 108 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 commId 0x1958874c5d2a0126 - Init COMPLETE
27: nid005922:80741:81228 [0] NCCL INFO Init timings: rank 108 nranks 128 total 5.38 (kernels 0.77, bootstrap 4.10, allgathers 0.15, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
24: nid005918:92505:93080 [1] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
27: nid005922:80742:81229 [1] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
24: nid005918:92505:93080 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
27: nid005922:80742:81229 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
27: nid005922:80742:81229 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
27: nid005922:80744:81259 [3] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
27: nid005922:80742:81229 [1] NCCL INFO ncclCommInitRank comm 0xaaab00b73210 rank 109 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 commId 0x1958874c5d2a0126 - Init COMPLETE
27: nid005922:80742:81229 [1] NCCL INFO Init timings: rank 109 nranks 128 total 5.38 (kernels 0.78, bootstrap 4.09, allgathers 0.15, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
27: nid005922:80744:81259 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
27: nid005922:80744:81259 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
27: nid005922:80744:81259 [3] NCCL INFO ncclCommInitRank comm 0xaaaabb7ab7a0 rank 111 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 commId 0x1958874c5d2a0126 - Init COMPLETE
27: nid005922:80744:81259 [3] NCCL INFO Init timings: rank 111 nranks 128 total 4.62 (kernels 1.05, bootstrap 3.06, allgathers 0.15, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
10: nid005590:110710:111197 [0] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
10: nid005590:110712:111243 [2] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
10: nid005590:110710:111197 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
10: nid005590:110710:111197 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
10: nid005590:110710:111197 [0] NCCL INFO ncclCommInitRank comm 0xaaab23d6b530 rank 40 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 commId 0x1958874c5d2a0126 - Init COMPLETE
10: nid005590:110712:111243 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
10: nid005590:110712:111243 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
10: nid005590:110710:111197 [0] NCCL INFO Init timings: rank 40 nranks 128 total 5.39 (kernels 0.60, bootstrap 4.29, allgathers 0.16, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
10: nid005590:110712:111243 [2] NCCL INFO ncclCommInitRank comm 0xaaab104db470 rank 42 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 commId 0x1958874c5d2a0126 - Init COMPLETE
10: nid005590:110712:111243 [2] NCCL INFO Init timings: rank 42 nranks 128 total 4.24 (kernels 1.05, bootstrap 2.69, allgathers 0.16, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
10: nid005590:110713:111240 [3] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
10: nid005590:110713:111240 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
10: nid005590:110713:111240 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
10: nid005590:110711:111241 [1] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
10: nid005590:110713:111240 [3] NCCL INFO ncclCommInitRank comm 0xaaab375e3b60 rank 43 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 commId 0x1958874c5d2a0126 - Init COMPLETE
10: nid005590:110711:111241 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
10: nid005590:110713:111240 [3] NCCL INFO Init timings: rank 43 nranks 128 total 4.81 (kernels 0.57, bootstrap 3.73, allgathers 0.16, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
10: nid005590:110711:111241 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
10: nid005590:110711:111241 [1] NCCL INFO ncclCommInitRank comm 0xaaab10df3460 rank 41 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 commId 0x1958874c5d2a0126 - Init COMPLETE
10: nid005590:110711:111241 [1] NCCL INFO Init timings: rank 41 nranks 128 total 4.81 (kernels 0.57, bootstrap 3.73, allgathers 0.16, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
25: nid005919:107464:108003 [2] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
25: nid005919:107464:108003 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
25: nid005919:107464:108003 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
25: nid005919:107464:108003 [2] NCCL INFO ncclCommInitRank comm 0xaaab1682a750 rank 102 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 commId 0x1958874c5d2a0126 - Init COMPLETE
25: nid005919:107464:108003 [2] NCCL INFO Init timings: rank 102 nranks 128 total 4.83 (kernels 0.55, bootstrap 3.76, allgathers 0.15, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
25: nid005919:107465:108002 [3] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
25: nid005919:107465:108002 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
25: nid005919:107465:108002 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
25: nid005919:107465:108002 [3] NCCL INFO ncclCommInitRank comm 0xaaaad4543ad0 rank 103 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 commId 0x1958874c5d2a0126 - Init COMPLETE
25: nid005919:107465:108002 [3] NCCL INFO Init timings: rank 103 nranks 128 total 4.85 (kernels 0.57, bootstrap 3.78, allgathers 0.15, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
25: nid005919:107463:108001 [1] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
25: nid005919:107462:107959 [0] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
25: nid005919:107463:108001 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
25: nid005919:107463:108001 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
25: nid005919:107463:108001 [1] NCCL INFO ncclCommInitRank comm 0xaaaaf8221890 rank 101 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 commId 0x1958874c5d2a0126 - Init COMPLETE
25: nid005919:107462:107959 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
25: nid005919:107462:107959 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
25: nid005919:107463:108001 [1] NCCL INFO Init timings: rank 101 nranks 128 total 4.85 (kernels 0.57, bootstrap 3.78, allgathers 0.15, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
 4: nid005581:264525:265067 [2] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
25: nid005919:107462:107959 [0] NCCL INFO ncclCommInitRank comm 0xaaab262294f0 rank 100 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 commId 0x1958874c5d2a0126 - Init COMPLETE
25: nid005919:107462:107959 [0] NCCL INFO Init timings: rank 100 nranks 128 total 5.39 (kernels 0.56, bootstrap 4.32, allgathers 0.15, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
 4: nid005581:264525:265067 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
 4: nid005581:264525:265067 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
 7: nid005585:122005:122496 [0] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
 4: nid005581:264525:265067 [2] NCCL INFO ncclCommInitRank comm 0xaaaaf1142f20 rank 18 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 commId 0x1958874c5d2a0126 - Init COMPLETE
 7: nid005585:122005:122496 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
 7: nid005585:122005:122496 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
 7: nid005585:122005:122496 [0] NCCL INFO ncclCommInitRank comm 0xaaab166fca20 rank 28 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 commId 0x1958874c5d2a0126 - Init COMPLETE
 4: nid005581:264525:265067 [2] NCCL INFO Init timings: rank 18 nranks 128 total 2.04 (kernels 0.06, bootstrap 1.48, allgathers 0.15, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
 4: nid005581:264524:265064 [1] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
 7: nid005585:122005:122496 [0] NCCL INFO Init timings: rank 28 nranks 128 total 5.39 (kernels 0.35, bootstrap 4.53, allgathers 0.15, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
 4: nid005581:264524:265064 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
 4: nid005581:264524:265064 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
 4: nid005581:264524:265064 [1] NCCL INFO ncclCommInitRank comm 0xaaaad9b8a440 rank 17 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 commId 0x1958874c5d2a0126 - Init COMPLETE
 4: nid005581:264524:265064 [1] NCCL INFO Init timings: rank 17 nranks 128 total 3.12 (kernels 0.13, bootstrap 2.48, allgathers 0.15, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
 7: nid005585:122008:122545 [3] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
 7: nid005585:122008:122545 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
 7: nid005585:122008:122545 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
 7: nid005585:122008:122545 [3] NCCL INFO ncclCommInitRank comm 0xaaaaedf73db0 rank 31 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 commId 0x1958874c5d2a0126 - Init COMPLETE
 4: nid005581:264523:265016 [0] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
 7: nid005585:122007:122527 [2] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
 7: nid005585:122008:122545 [3] NCCL INFO Init timings: rank 31 nranks 128 total 3.21 (kernels 0.06, bootstrap 2.64, allgathers 0.15, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
 7: nid005585:122007:122527 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
 7: nid005585:122007:122527 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
 4: nid005581:264523:265016 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
 4: nid005581:264523:265016 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
 4: nid005581:264523:265016 [0] NCCL INFO ncclCommInitRank comm 0xaaaafba8b880 rank 16 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 commId 0x1958874c5d2a0126 - Init COMPLETE
 7: nid005585:122006:122526 [1] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
 7: nid005585:122007:122527 [2] NCCL INFO ncclCommInitRank comm 0xaaaadd869ba0 rank 30 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 commId 0x1958874c5d2a0126 - Init COMPLETE
 4: nid005581:264523:265016 [0] NCCL INFO Init timings: rank 16 nranks 128 total 4.30 (kernels 0.11, bootstrap 3.68, allgathers 0.15, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
 7: nid005585:122007:122527 [2] NCCL INFO Init timings: rank 30 nranks 128 total 4.29 (kernels 0.06, bootstrap 3.73, allgathers 0.15, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
 7: nid005585:122006:122526 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
 7: nid005585:122006:122526 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
 7: nid005585:122006:122526 [1] NCCL INFO ncclCommInitRank comm 0xaaab0e87b260 rank 29 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 commId 0x1958874c5d2a0126 - Init COMPLETE
 7: nid005585:122006:122526 [1] NCCL INFO Init timings: rank 29 nranks 128 total 4.31 (kernels 0.06, bootstrap 3.75, allgathers 0.15, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
 4: nid005581:264526:265063 [3] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
 4: nid005581:264526:265063 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
 4: nid005581:264526:265063 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
 4: nid005581:264526:265063 [3] NCCL INFO ncclCommInitRank comm 0xaaaae8963db0 rank 19 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 commId 0x1958874c5d2a0126 - Init COMPLETE
 4: nid005581:264526:265063 [3] NCCL INFO Init timings: rank 19 nranks 128 total 3.14 (kernels 0.06, bootstrap 2.57, allgathers 0.15, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
 2: nid005577:17423:17952 [1] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
 2: nid005577:17423:17952 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
 2: nid005577:17423:17952 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
26: nid005920:67125:67662 [2] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
 2: nid005577:17423:17952 [1] NCCL INFO ncclCommInitRank comm 0xaaaaf479b750 rank 9 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 commId 0x1958874c5d2a0126 - Init COMPLETE
 5: nid005582:196715:197387 [2] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
26: nid005920:67125:67662 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
26: nid005920:67125:67662 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
 2: nid005577:17423:17952 [1] NCCL INFO Init timings: rank 9 nranks 128 total 5.39 (kernels 0.55, bootstrap 4.33, allgathers 0.16, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
 5: nid005582:196715:197387 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
 5: nid005582:196715:197387 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
26: nid005920:67125:67662 [2] NCCL INFO ncclCommInitRank comm 0xaaaaf841bf30 rank 106 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 commId 0x1958874c5d2a0126 - Init COMPLETE
26: nid005920:67125:67662 [2] NCCL INFO Init timings: rank 106 nranks 128 total 3.60 (kernels 0.36, bootstrap 2.73, allgathers 0.15, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
 9: nid005588:35936:36472 [1] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
 5: nid005582:196715:197387 [2] NCCL INFO ncclCommInitRank comm 0xaaaaeab5be10 rank 22 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 commId 0x1958874c5d2a0126 - Init COMPLETE
 2: nid005577:17424:17982 [2] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
 2: nid005577:17424:17982 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
 9: nid005588:35936:36472 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
 9: nid005588:35936:36472 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
 9: nid005588:35936:36472 [1] NCCL INFO ncclCommInitRank comm 0xaaab298ab220 rank 37 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 commId 0x1958874c5d2a0126 - Init COMPLETE
 9: nid005588:35936:36472 [1] NCCL INFO Init timings: rank 37 nranks 128 total 4.90 (kernels 0.57, bootstrap 3.83, allgathers 0.17, topo 0.31, graphs 0.02, connections 0.01, rest 0.01)
 5: nid005582:196715:197387 [2] NCCL INFO Init timings: rank 22 nranks 128 total 5.21 (kernels 0.44, bootstrap 4.26, allgathers 0.17, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
 2: nid005577:17424:17982 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
 2: nid005577:17424:17982 [2] NCCL INFO ncclCommInitRank comm 0xaaaaec29b7f0 rank 10 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 commId 0x1958874c5d2a0126 - Init COMPLETE
 2: nid005577:17425:17981 [3] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
 2: nid005577:17424:17982 [2] NCCL INFO Init timings: rank 10 nranks 128 total 4.85 (kernels 1.56, bootstrap 2.78, allgathers 0.16, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
26: nid005920:67123:67613 [0] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
 2: nid005577:17425:17981 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
 2: nid005577:17425:17981 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
 2: nid005577:17425:17981 [3] NCCL INFO ncclCommInitRank comm 0xaaab1accc2e0 rank 11 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 commId 0x1958874c5d2a0126 - Init COMPLETE
11: nid005591:191604:192145 [1] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
 2: nid005577:17425:17981 [3] NCCL INFO Init timings: rank 11 nranks 128 total 4.87 (kernels 0.88, bootstrap 3.48, allgathers 0.16, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
26: nid005920:67123:67613 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
26: nid005920:67123:67613 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
 2: nid005577:17422:17953 [0] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
 2: nid005577:17422:17953 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
 2: nid005577:17422:17953 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
26: nid005920:67123:67613 [0] NCCL INFO ncclCommInitRank comm 0xaaab021f2d20 rank 104 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 commId 0x1958874c5d2a0126 - Init COMPLETE
11: nid005591:191604:192145 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
11: nid005591:191604:192145 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
 5: nid005582:196714:197386 [1] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
26: nid005920:67123:67613 [0] NCCL INFO Init timings: rank 104 nranks 128 total 5.35 (kernels 0.60, bootstrap 4.24, allgathers 0.15, topo 0.32, graphs 0.02, connections 0.01, rest 0.01)
11: nid005591:191604:192145 [1] NCCL INFO ncclCommInitRank comm 0xaaab196cb950 rank 45 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 commId 0x1958874c5d2a0126 - Init COMPLETE
 2: nid005577:17422:17953 [0] NCCL INFO ncclCommInitRank comm 0xaaaaf334fcf0 rank 8 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 commId 0x1958874c5d2a0126 - Init COMPLETE
 1: nid005576:147558:148070 [1] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
 9: nid005588:35935:36428 [0] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
 5: nid005582:196714:197386 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
26: nid005920:67126:67661 [3] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
11: nid005591:191604:192145 [1] NCCL INFO Init timings: rank 45 nranks 128 total 3.47 (kernels 0.06, bootstrap 2.90, allgathers 0.16, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
 2: nid005577:17422:17953 [0] NCCL INFO Init timings: rank 8 nranks 128 total 5.39 (kernels 0.55, bootstrap 4.33, allgathers 0.16, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
 1: nid005576:147558:148070 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
 1: nid005576:147558:148070 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
 9: nid005588:35935:36428 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
 5: nid005582:196714:197386 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
 5: nid005582:196714:197386 [1] NCCL INFO ncclCommInitRank comm 0xaaab201019a0 rank 21 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 commId 0x1958874c5d2a0126 - Init COMPLETE
26: nid005920:67126:67661 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
26: nid005920:67126:67661 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
 0: nid005574:69059:69601 [1] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
 1: nid005576:147558:148070 [1] NCCL INFO ncclCommInitRank comm 0xaaaaf8e03070 rank 5 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 commId 0x1958874c5d2a0126 - Init COMPLETE
 1: nid005576:147558:148070 [1] NCCL INFO Init timings: rank 5 nranks 128 total 4.25 (kernels 0.06, bootstrap 3.68, allgathers 0.15, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
 9: nid005588:35935:36428 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
 9: nid005588:35935:36428 [0] NCCL INFO ncclCommInitRank comm 0xaaab148fdb70 rank 36 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 commId 0x1958874c5d2a0126 - Init COMPLETE
 9: nid005588:35935:36428 [0] NCCL INFO Init timings: rank 36 nranks 128 total 5.39 (kernels 0.51, bootstrap 4.37, allgathers 0.16, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
 5: nid005582:196714:197386 [1] NCCL INFO Init timings: rank 21 nranks 128 total 5.37 (kernels 0.61, bootstrap 4.26, allgathers 0.17, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
26: nid005920:67126:67661 [3] NCCL INFO ncclCommInitRank comm 0xaaab209d4590 rank 107 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 commId 0x1958874c5d2a0126 - Init COMPLETE
26: nid005920:67124:67660 [1] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
26: nid005920:67126:67661 [3] NCCL INFO Init timings: rank 107 nranks 128 total 3.61 (kernels 0.06, bootstrap 3.04, allgathers 0.15, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
11: nid005591:191606:192116 [3] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
31: nid005937:256592:257124 [3] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
 0: nid005574:69059:69601 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
 9: nid005588:35937:36471 [2] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
 5: nid005582:196716:197388 [3] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
26: nid005920:67124:67660 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
26: nid005920:67124:67660 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
26: nid005920:67124:67660 [1] NCCL INFO ncclCommInitRank comm 0xaaab0de132b0 rank 105 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 commId 0x1958874c5d2a0126 - Init COMPLETE
11: nid005591:191606:192116 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
11: nid005591:191606:192116 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
31: nid005937:256592:257124 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
31: nid005937:256592:257124 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
 0: nid005574:69059:69601 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
 1: nid005576:147560:148100 [3] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
 9: nid005588:35937:36471 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
 9: nid005588:35937:36471 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
 9: nid005588:35937:36471 [2] NCCL INFO ncclCommInitRank comm 0xaaaae8a0c3a0 rank 38 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 commId 0x1958874c5d2a0126 - Init COMPLETE
 5: nid005582:196716:197388 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
 5: nid005582:196716:197388 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
26: nid005920:67124:67660 [1] NCCL INFO Init timings: rank 105 nranks 128 total 3.63 (kernels 0.06, bootstrap 3.06, allgathers 0.15, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
11: nid005591:191606:192116 [3] NCCL INFO ncclCommInitRank comm 0xaaaae7d03880 rank 47 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 commId 0x1958874c5d2a0126 - Init COMPLETE
11: nid005591:191606:192116 [3] NCCL INFO Init timings: rank 47 nranks 128 total 4.08 (kernels 0.06, bootstrap 3.52, allgathers 0.16, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
31: nid005937:256592:257124 [3] NCCL INFO ncclCommInitRank comm 0xaaaaedf436d0 rank 127 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 commId 0x1958874c5d2a0126 - Init COMPLETE
31: nid005937:256592:257124 [3] NCCL INFO Init timings: rank 127 nranks 128 total 3.42 (kernels 0.06, bootstrap 2.85, allgathers 0.16, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
 0: nid005574:69059:69601 [1] NCCL INFO ncclCommInitRank comm 0xaaaad1289f50 rank 1 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 commId 0x1958874c5d2a0126 - Init COMPLETE
 1: nid005576:147560:148100 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
 9: nid005588:35937:36471 [2] NCCL INFO Init timings: rank 38 nranks 128 total 4.90 (kernels 0.57, bootstrap 3.82, allgathers 0.16, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
 5: nid005582:196716:197388 [3] NCCL INFO ncclCommInitRank comm 0xaaab1215f930 rank 23 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 commId 0x1958874c5d2a0126 - Init COMPLETE
 5: nid005582:196716:197388 [3] NCCL INFO Init timings: rank 23 nranks 128 total 5.13 (kernels 0.36, bootstrap 4.26, allgathers 0.17, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
23: nid005917:276888:277422 [3] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
11: nid005591:191605:192144 [2] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
31: nid005937:256590:257125 [1] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
 0: nid005574:69059:69601 [1] NCCL INFO Init timings: rank 1 nranks 128 total 4.22 (kernels 0.06, bootstrap 3.65, allgathers 0.17, topo 0.31, graphs 0.02, connections 0.01, rest 0.01)
 1: nid005576:147560:148100 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
 1: nid005576:147560:148100 [3] NCCL INFO ncclCommInitRank comm 0xaaaaea94c330 rank 7 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 commId 0x1958874c5d2a0126 - Init COMPLETE
 9: nid005588:35938:36474 [3] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
 9: nid005588:35938:36474 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
 5: nid005582:196713:197389 [0] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
23: nid005917:276888:277422 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
23: nid005917:276888:277422 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
11: nid005591:191605:192144 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
11: nid005591:191605:192144 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
31: nid005937:256590:257125 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
31: nid005937:256590:257125 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
 0: nid005574:69061:69602 [3] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
 1: nid005576:147560:148100 [3] NCCL INFO Init timings: rank 7 nranks 128 total 3.65 (kernels 0.06, bootstrap 3.08, allgathers 0.15, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
 9: nid005588:35938:36474 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
17: nid005803:180733:181262 [1] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
 5: nid005582:196713:197389 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
23: nid005917:276888:277422 [3] NCCL INFO ncclCommInitRank comm 0xaaaaf34fa080 rank 95 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 commId 0x1958874c5d2a0126 - Init COMPLETE
23: nid005917:276888:277422 [3] NCCL INFO Init timings: rank 95 nranks 128 total 5.02 (kernels 0.54, bootstrap 3.97, allgathers 0.16, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
11: nid005591:191605:192144 [2] NCCL INFO ncclCommInitRank comm 0xaaaafb513f80 rank 46 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 commId 0x1958874c5d2a0126 - Init COMPLETE
31: nid005937:256590:257125 [1] NCCL INFO ncclCommInitRank comm 0xaaab10443c40 rank 125 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 commId 0x1958874c5d2a0126 - Init COMPLETE
31: nid005937:256590:257125 [1] NCCL INFO Init timings: rank 125 nranks 128 total 3.38 (kernels 1.07, bootstrap 1.80, allgathers 0.16, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
 0: nid005574:69061:69602 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
 0: nid005574:69061:69602 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
 1: nid005576:147559:148101 [2] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
 9: nid005588:35938:36474 [3] NCCL INFO ncclCommInitRank comm 0xaaaadbd50910 rank 39 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 commId 0x1958874c5d2a0126 - Init COMPLETE
 9: nid005588:35938:36474 [3] NCCL INFO Init timings: rank 39 nranks 128 total 4.34 (kernels 1.06, bootstrap 2.77, allgathers 0.16, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
17: nid005803:180733:181262 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
 3: nid005580:71820:72338 [1] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
 3: nid005580:71822:72337 [3] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
 5: nid005582:196713:197389 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
 5: nid005582:196713:197389 [0] NCCL INFO ncclCommInitRank comm 0xaaab12118df0 rank 20 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 commId 0x1958874c5d2a0126 - Init COMPLETE
23: nid005917:276886:277419 [1] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
11: nid005591:191605:192144 [2] NCCL INFO Init timings: rank 46 nranks 128 total 3.47 (kernels 0.06, bootstrap 2.91, allgathers 0.16, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
31: nid005937:256589:256847 [0] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
 0: nid005574:69061:69602 [3] NCCL INFO ncclCommInitRank comm 0xaaaad3e5bbc0 rank 3 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 commId 0x1958874c5d2a0126 - Init COMPLETE
 1: nid005576:147559:148101 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
17: nid005803:180733:181262 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
 3: nid005580:71820:72338 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
 3: nid005580:71822:72337 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
 3: nid005580:71820:72338 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
 3: nid005580:71822:72337 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
 5: nid005582:196713:197389 [0] NCCL INFO Init timings: rank 20 nranks 128 total 5.13 (kernels 0.36, bootstrap 4.26, allgathers 0.17, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
23: nid005917:276886:277419 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
23: nid005917:276886:277419 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
11: nid005591:191603:192099 [0] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
31: nid005937:256589:256847 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
31: nid005937:256589:256847 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
31: nid005937:256589:256847 [0] NCCL INFO ncclCommInitRank comm 0xaaab2c295d90 rank 124 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 commId 0x1958874c5d2a0126 - Init COMPLETE
 0: nid005574:69061:69602 [3] NCCL INFO Init timings: rank 3 nranks 128 total 4.22 (kernels 0.06, bootstrap 3.65, allgathers 0.17, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
 1: nid005576:147557:148053 [0] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
 1: nid005576:147559:148101 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
17: nid005803:180733:181262 [1] NCCL INFO ncclCommInitRank comm 0xaaab1f57afc0 rank 69 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 commId 0x1958874c5d2a0126 - Init COMPLETE
 3: nid005580:71820:72338 [1] NCCL INFO ncclCommInitRank comm 0xaaaac543b4a0 rank 13 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 commId 0x1958874c5d2a0126 - Init COMPLETE
 3: nid005580:71822:72337 [3] NCCL INFO ncclCommInitRank comm 0xaaab06b93260 rank 15 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 commId 0x1958874c5d2a0126 - Init COMPLETE
23: nid005917:276886:277419 [1] NCCL INFO ncclCommInitRank comm 0xaaab0f582930 rank 93 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 commId 0x1958874c5d2a0126 - Init COMPLETE
11: nid005591:191603:192099 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
11: nid005591:191603:192099 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
31: nid005937:256589:256847 [0] NCCL INFO Init timings: rank 124 nranks 128 total 5.17 (kernels 0.48, bootstrap 4.19, allgathers 0.16, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
 0: nid005574:69058:69552 [0] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
 1: nid005576:147559:148101 [2] NCCL INFO ncclCommInitRank comm 0xaaab1c4d2400 rank 6 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 commId 0x1958874c5d2a0126 - Init COMPLETE
 1: nid005576:147557:148053 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
 1: nid005576:147557:148053 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
 1: nid005576:147557:148053 [0] NCCL INFO ncclCommInitRank comm 0xaaab2078f8e0 rank 4 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 commId 0x1958874c5d2a0126 - Init COMPLETE
 1: nid005576:147559:148101 [2] NCCL INFO Init timings: rank 6 nranks 128 total 3.65 (kernels 0.06, bootstrap 3.08, allgathers 0.15, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
17: nid005803:180733:181262 [1] NCCL INFO Init timings: rank 69 nranks 128 total 5.39 (kernels 0.78, bootstrap 4.10, allgathers 0.15, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
 3: nid005580:71820:72338 [1] NCCL INFO Init timings: rank 13 nranks 128 total 3.84 (kernels 0.06, bootstrap 3.27, allgathers 0.16, topo 0.32, graphs 0.02, connections 0.02, rest 0.00)
 3: nid005580:71822:72337 [3] NCCL INFO Init timings: rank 15 nranks 128 total 3.84 (kernels 0.07, bootstrap 3.27, allgathers 0.16, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
23: nid005917:276886:277419 [1] NCCL INFO Init timings: rank 93 nranks 128 total 5.38 (kernels 0.39, bootstrap 4.49, allgathers 0.16, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
11: nid005591:191603:192099 [0] NCCL INFO ncclCommInitRank comm 0xaaaaf7916bf0 rank 44 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 commId 0x1958874c5d2a0126 - Init COMPLETE
11: nid005591:191603:192099 [0] NCCL INFO Init timings: rank 44 nranks 128 total 5.30 (kernels 0.67, bootstrap 4.12, allgathers 0.16, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
31: nid005937:256591:257123 [2] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
 0: nid005574:69058:69552 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
 1: nid005576:147557:148053 [0] NCCL INFO Init timings: rank 4 nranks 128 total 5.39 (kernels 0.61, bootstrap 4.27, allgathers 0.15, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
 3: nid005580:71821:72339 [2] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
23: nid005917:276887:277420 [2] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
30: nid005936:49909:50450 [1] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
31: nid005937:256591:257123 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
31: nid005937:256591:257123 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
 0: nid005574:69058:69552 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
 0: nid005574:69058:69552 [0] NCCL INFO ncclCommInitRank comm 0xaaab0113f7d0 rank 0 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 commId 0x1958874c5d2a0126 - Init COMPLETE
 3: nid005580:71821:72339 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
23: nid005917:276887:277420 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
23: nid005917:276887:277420 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
30: nid005936:49909:50450 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
30: nid005936:49909:50450 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
31: nid005937:256591:257123 [2] NCCL INFO ncclCommInitRank comm 0xaaaafcfbaf70 rank 126 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 commId 0x1958874c5d2a0126 - Init COMPLETE
 0: nid005574:69058:69552 [0] NCCL INFO Init timings: rank 0 nranks 128 total 5.40 (kernels 0.63, bootstrap 4.26, allgathers 0.17, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
17: nid005803:180735:181265 [3] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
 3: nid005580:71821:72339 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
 3: nid005580:71819:72290 [0] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
 3: nid005580:71821:72339 [2] NCCL INFO ncclCommInitRank comm 0xaaaada12b8c0 rank 14 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 commId 0x1958874c5d2a0126 - Init COMPLETE
23: nid005917:276885:277421 [0] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
23: nid005917:276887:277420 [2] NCCL INFO ncclCommInitRank comm 0xaaaaf1b2b6f0 rank 94 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 commId 0x1958874c5d2a0126 - Init COMPLETE
30: nid005936:49909:50450 [1] NCCL INFO ncclCommInitRank comm 0xaaaacaa5c1a0 rank 121 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 commId 0x1958874c5d2a0126 - Init COMPLETE
30: nid005936:49909:50450 [1] NCCL INFO Init timings: rank 121 nranks 128 total 5.37 (kernels 0.58, bootstrap 4.28, allgathers 0.16, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
 0: nid005574:69060:69600 [2] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
17: nid005803:180735:181265 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
17: nid005803:180735:181265 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
 3: nid005580:71821:72339 [2] NCCL INFO Init timings: rank 14 nranks 128 total 3.76 (kernels 1.04, bootstrap 2.22, allgathers 0.16, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
 3: nid005580:71819:72290 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
23: nid005917:276885:277421 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
23: nid005917:276885:277421 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
 0: nid005574:69060:69600 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
 3: nid005580:71819:72290 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
 3: nid005580:71819:72290 [0] NCCL INFO ncclCommInitRank comm 0xaaab065e8c10 rank 12 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 commId 0x1958874c5d2a0126 - Init COMPLETE
 3: nid005580:71819:72290 [0] NCCL INFO Init timings: rank 12 nranks 128 total 4.50 (kernels 0.11, bootstrap 3.88, allgathers 0.16, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
23: nid005917:276887:277420 [2] NCCL INFO Init timings: rank 94 nranks 128 total 5.26 (kernels 0.27, bootstrap 4.49, allgathers 0.16, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
23: nid005917:276885:277421 [0] NCCL INFO ncclCommInitRank comm 0xaaaae40fdd90 rank 92 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 commId 0x1958874c5d2a0126 - Init COMPLETE
30: nid005936:49910:50467 [2] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
 6: nid005584:28286:28818 [1] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
22: nid005915:274817:275333 [3] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
 0: nid005574:69060:69600 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
17: nid005803:180735:181265 [3] NCCL INFO ncclCommInitRank comm 0xaaab10aa06b0 rank 71 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 commId 0x1958874c5d2a0126 - Init COMPLETE
23: nid005917:276885:277421 [0] NCCL INFO Init timings: rank 92 nranks 128 total 5.24 (kernels 0.25, bootstrap 4.49, allgathers 0.16, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
30: nid005936:49910:50467 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
30: nid005936:49910:50467 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
 6: nid005584:28286:28818 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
22: nid005915:274817:275333 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
31: nid005937:256591:257123 [2] NCCL INFO Init timings: rank 126 nranks 128 total 3.42 (kernels 0.06, bootstrap 2.85, allgathers 0.16, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
 0: nid005574:69060:69600 [2] NCCL INFO ncclCommInitRank comm 0xaaaaedbf8c70 rank 2 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 commId 0x1958874c5d2a0126 - Init COMPLETE
17: nid005803:180735:181265 [3] NCCL INFO Init timings: rank 71 nranks 128 total 4.62 (kernels 1.57, bootstrap 2.55, allgathers 0.15, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
30: nid005936:49910:50467 [2] NCCL INFO ncclCommInitRank comm 0xaaaad8cb00f0 rank 122 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 commId 0x1958874c5d2a0126 - Init COMPLETE
30: nid005936:49910:50467 [2] NCCL INFO Init timings: rank 122 nranks 128 total 4.82 (kernels 0.06, bootstrap 4.25, allgathers 0.16, topo 0.31, graphs 0.02, connections 0.01, rest 0.01)
 6: nid005584:28286:28818 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
 6: nid005584:28286:28818 [1] NCCL INFO ncclCommInitRank comm 0xaaab2173c180 rank 25 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 commId 0x1958874c5d2a0126 - Init COMPLETE
 6: nid005584:28286:28818 [1] NCCL INFO Init timings: rank 25 nranks 128 total 3.16 (kernels 0.07, bootstrap 2.58, allgathers 0.16, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
22: nid005915:274817:275333 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
 0: nid005574:69060:69600 [2] NCCL INFO Init timings: rank 2 nranks 128 total 4.22 (kernels 0.06, bootstrap 3.65, allgathers 0.17, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
17: nid005803:180734:181263 [2] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
30: nid005936:49911:50449 [3] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
22: nid005915:274817:275333 [3] NCCL INFO ncclCommInitRank comm 0xaaab11483950 rank 91 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 commId 0x1958874c5d2a0126 - Init COMPLETE
17: nid005803:180734:181263 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
17: nid005803:180734:181263 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
30: nid005936:49911:50449 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
30: nid005936:49911:50449 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
22: nid005915:274817:275333 [3] NCCL INFO Init timings: rank 91 nranks 128 total 4.29 (kernels 0.06, bootstrap 3.73, allgathers 0.17, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
17: nid005803:180734:181263 [2] NCCL INFO ncclCommInitRank comm 0xaaab0a6d9870 rank 70 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 commId 0x1958874c5d2a0126 - Init COMPLETE
17: nid005803:180734:181263 [2] NCCL INFO Init timings: rank 70 nranks 128 total 5.29 (kernels 0.68, bootstrap 4.10, allgathers 0.15, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
30: nid005936:49911:50449 [3] NCCL INFO ncclCommInitRank comm 0xaaaad877afc0 rank 123 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 commId 0x1958874c5d2a0126 - Init COMPLETE
30: nid005936:49911:50449 [3] NCCL INFO Init timings: rank 123 nranks 128 total 5.37 (kernels 0.58, bootstrap 4.28, allgathers 0.16, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
22: nid005915:274815:275332 [1] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
17: nid005803:180732:181264 [0] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
30: nid005936:49908:50465 [0] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
22: nid005915:274815:275332 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
22: nid005915:274815:275332 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
17: nid005803:180732:181264 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
30: nid005936:49908:50465 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
 6: nid005584:28288:28820 [3] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
22: nid005915:274815:275332 [1] NCCL INFO ncclCommInitRank comm 0xaaab0ea2ac20 rank 89 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 commId 0x1958874c5d2a0126 - Init COMPLETE
17: nid005803:180732:181264 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
17: nid005803:180732:181264 [0] NCCL INFO ncclCommInitRank comm 0xaaaad12a2680 rank 68 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 commId 0x1958874c5d2a0126 - Init COMPLETE
30: nid005936:49908:50465 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
30: nid005936:49908:50465 [0] NCCL INFO ncclCommInitRank comm 0xaaaafc2a9750 rank 120 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 commId 0x1958874c5d2a0126 - Init COMPLETE
 6: nid005584:28288:28820 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
22: nid005915:274815:275332 [1] NCCL INFO Init timings: rank 89 nranks 128 total 4.29 (kernels 0.06, bootstrap 3.72, allgathers 0.17, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
17: nid005803:180732:181264 [0] NCCL INFO Init timings: rank 68 nranks 128 total 5.09 (kernels 0.49, bootstrap 4.10, allgathers 0.15, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
30: nid005936:49908:50465 [0] NCCL INFO Init timings: rank 120 nranks 128 total 5.02 (kernels 0.23, bootstrap 4.28, allgathers 0.16, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
 6: nid005584:28288:28820 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
 6: nid005584:28288:28820 [3] NCCL INFO ncclCommInitRank comm 0xaaaaf69fb200 rank 27 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 commId 0x1958874c5d2a0126 - Init COMPLETE
 6: nid005584:28288:28820 [3] NCCL INFO Init timings: rank 27 nranks 128 total 3.11 (kernels 1.06, bootstrap 1.54, allgathers 0.16, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
22: nid005915:274816:275334 [2] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
 6: nid005584:28287:28819 [2] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
 6: nid005584:28287:28819 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
 6: nid005584:28287:28819 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
22: nid005915:274816:275334 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
22: nid005915:274816:275334 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
22: nid005915:274816:275334 [2] NCCL INFO ncclCommInitRank comm 0xaaaafe3ab720 rank 90 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 commId 0x1958874c5d2a0126 - Init COMPLETE
 6: nid005584:28287:28819 [2] NCCL INFO ncclCommInitRank comm 0xaaab07a0c730 rank 26 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 commId 0x1958874c5d2a0126 - Init COMPLETE
 6: nid005584:28287:28819 [2] NCCL INFO Init timings: rank 26 nranks 128 total 3.15 (kernels 0.07, bootstrap 2.58, allgathers 0.16, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
 6: nid005584:28285:28774 [0] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
 6: nid005584:28285:28774 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
 6: nid005584:28285:28774 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
22: nid005915:274816:275334 [2] NCCL INFO Init timings: rank 90 nranks 128 total 4.28 (kernels 0.06, bootstrap 3.72, allgathers 0.17, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
 6: nid005584:28285:28774 [0] NCCL INFO ncclCommInitRank comm 0xaaaafc6efb40 rank 24 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 commId 0x1958874c5d2a0126 - Init COMPLETE
22: nid005915:274814:275290 [0] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
22: nid005915:274814:275290 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
22: nid005915:274814:275290 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
 6: nid005584:28285:28774 [0] NCCL INFO Init timings: rank 24 nranks 128 total 4.09 (kernels 0.11, bootstrap 3.47, allgathers 0.16, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
22: nid005915:274814:275290 [0] NCCL INFO ncclCommInitRank comm 0xaaaad1683e90 rank 88 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 commId 0x1958874c5d2a0126 - Init COMPLETE
22: nid005915:274814:275290 [0] NCCL INFO Init timings: rank 88 nranks 128 total 5.39 (kernels 0.55, bootstrap 4.33, allgathers 0.17, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
19: nid005912:12437:12976 [2] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
19: nid005912:12437:12976 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
19: nid005912:12437:12976 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
19: nid005912:12437:12976 [2] NCCL INFO ncclCommInitRank comm 0xaaaaec4bb890 rank 78 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 commId 0x1958874c5d2a0126 - Init COMPLETE
19: nid005912:12437:12976 [2] NCCL INFO Init timings: rank 78 nranks 128 total 2.98 (kernels 0.06, bootstrap 2.41, allgathers 0.15, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
19: nid005912:12435:12909 [0] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
19: nid005912:12435:12909 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
19: nid005912:12435:12909 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
19: nid005912:12435:12909 [0] NCCL INFO ncclCommInitRank comm 0xaaab04d29d70 rank 76 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 commId 0x1958874c5d2a0126 - Init COMPLETE
19: nid005912:12438:12958 [3] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
21: nid005914:166787:167300 [3] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
19: nid005912:12435:12909 [0] NCCL INFO Init timings: rank 76 nranks 128 total 5.37 (kernels 0.74, bootstrap 4.13, allgathers 0.15, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
19: nid005912:12438:12958 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
19: nid005912:12438:12958 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
19: nid005912:12438:12958 [3] NCCL INFO ncclCommInitRank comm 0xaaaae3c43340 rank 79 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 commId 0x1958874c5d2a0126 - Init COMPLETE
19: nid005912:12438:12958 [3] NCCL INFO Init timings: rank 79 nranks 128 total 4.08 (kernels 0.06, bootstrap 3.52, allgathers 0.15, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
19: nid005912:12436:12959 [1] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
20: nid005913:292682:293200 [1] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
21: nid005914:166787:167300 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
20: nid005913:292682:293200 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
20: nid005913:292682:293200 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
20: nid005913:292682:293200 [1] NCCL INFO ncclCommInitRank comm 0xaaaaf6e99730 rank 81 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 commId 0x1958874c5d2a0126 - Init COMPLETE
19: nid005912:12436:12959 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
19: nid005912:12436:12959 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
19: nid005912:12436:12959 [1] NCCL INFO ncclCommInitRank comm 0xaaaaeb758490 rank 77 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 commId 0x1958874c5d2a0126 - Init COMPLETE
21: nid005914:166787:167300 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
20: nid005913:292682:293200 [1] NCCL INFO Init timings: rank 81 nranks 128 total 3.37 (kernels 0.06, bootstrap 2.80, allgathers 0.16, topo 0.31, graphs 0.02, connections 0.01, rest 0.01)
19: nid005912:12436:12959 [1] NCCL INFO Init timings: rank 77 nranks 128 total 4.08 (kernels 0.06, bootstrap 3.52, allgathers 0.15, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
21: nid005914:166787:167300 [3] NCCL INFO ncclCommInitRank comm 0xaaaadea21c50 rank 87 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 commId 0x1958874c5d2a0126 - Init COMPLETE
21: nid005914:166787:167300 [3] NCCL INFO Init timings: rank 87 nranks 128 total 3.79 (kernels 0.06, bootstrap 3.22, allgathers 0.15, topo 0.32, graphs 0.02, connections 0.02, rest 0.00)
21: nid005914:166785:167301 [1] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
21: nid005914:166785:167301 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
21: nid005914:166785:167301 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
21: nid005914:166785:167301 [1] NCCL INFO ncclCommInitRank comm 0xaaaaf1392a50 rank 85 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 commId 0x1958874c5d2a0126 - Init COMPLETE
21: nid005914:166785:167301 [1] NCCL INFO Init timings: rank 85 nranks 128 total 3.79 (kernels 0.06, bootstrap 3.22, allgathers 0.15, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
 8: nid005586:68926:69401 [0] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
 8: nid005586:68926:69401 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
 8: nid005586:68926:69401 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
14: nid005600:217721:218228 [1] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
21: nid005914:166784:167271 [0] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
 8: nid005586:68926:69401 [0] NCCL INFO ncclCommInitRank comm 0xaaab12790160 rank 32 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 commId 0x1958874c5d2a0126 - Init COMPLETE
 8: nid005586:68926:69401 [0] NCCL INFO Init timings: rank 32 nranks 128 total 5.10 (kernels 0.47, bootstrap 4.13, allgathers 0.15, topo 0.32, graphs 0.02, connections 0.02, rest 0.00)
14: nid005600:217721:218228 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
14: nid005600:217721:218228 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
20: nid005913:292684:293199 [3] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
21: nid005914:166784:167271 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
21: nid005914:166784:167271 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
14: nid005600:217721:218228 [1] NCCL INFO ncclCommInitRank comm 0xaaaacda93d30 rank 57 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 commId 0x1958874c5d2a0126 - Init COMPLETE
20: nid005913:292684:293199 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
20: nid005913:292684:293199 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
20: nid005913:292684:293199 [3] NCCL INFO ncclCommInitRank comm 0xaaaae94038c0 rank 83 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 commId 0x1958874c5d2a0126 - Init COMPLETE
20: nid005913:292681:293089 [0] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
14: nid005600:217721:218228 [1] NCCL INFO Init timings: rank 57 nranks 128 total 3.43 (kernels 0.57, bootstrap 2.36, allgathers 0.16, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
20: nid005913:292684:293199 [3] NCCL INFO Init timings: rank 83 nranks 128 total 3.38 (kernels 0.07, bootstrap 2.80, allgathers 0.16, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
20: nid005913:292681:293089 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
21: nid005914:166784:167271 [0] NCCL INFO ncclCommInitRank comm 0xaaab092dcbd0 rank 84 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 commId 0x1958874c5d2a0126 - Init COMPLETE
21: nid005914:166784:167271 [0] NCCL INFO Init timings: rank 84 nranks 128 total 5.38 (kernels 0.54, bootstrap 4.33, allgathers 0.15, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
21: nid005914:166786:167270 [2] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
20: nid005913:292681:293089 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
21: nid005914:166786:167270 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
21: nid005914:166786:167270 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
21: nid005914:166786:167270 [2] NCCL INFO ncclCommInitRank comm 0xaaab02d82db0 rank 86 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 commId 0x1958874c5d2a0126 - Init COMPLETE
21: nid005914:166786:167270 [2] NCCL INFO Init timings: rank 86 nranks 128 total 5.38 (kernels 0.54, bootstrap 4.33, allgathers 0.15, topo 0.32, graphs 0.02, connections 0.02, rest 0.00)
 8: nid005586:68928:69450 [2] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
16: nid005802:6298:6897 [1] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
20: nid005913:292681:293089 [0] NCCL INFO ncclCommInitRank comm 0xaaab2e755bf0 rank 80 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 commId 0x1958874c5d2a0126 - Init COMPLETE
 8: nid005586:68928:69450 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
14: nid005600:217722:218227 [2] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
16: nid005802:6298:6897 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
16: nid005802:6298:6897 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
16: nid005802:6298:6897 [1] NCCL INFO ncclCommInitRank comm 0xaaab06e0b4f0 rank 65 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 commId 0x1958874c5d2a0126 - Init COMPLETE
20: nid005913:292681:293089 [0] NCCL INFO Init timings: rank 80 nranks 128 total 5.11 (kernels 0.37, bootstrap 4.23, allgathers 0.16, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
20: nid005913:292683:293201 [2] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
14: nid005600:217722:218227 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
14: nid005600:217722:218227 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
20: nid005913:292683:293201 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
20: nid005913:292683:293201 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
 8: nid005586:68928:69450 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
14: nid005600:217722:218227 [2] NCCL INFO ncclCommInitRank comm 0xaaaada11bcd0 rank 58 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 commId 0x1958874c5d2a0126 - Init COMPLETE
14: nid005600:217722:218227 [2] NCCL INFO Init timings: rank 58 nranks 128 total 3.48 (kernels 0.06, bootstrap 2.90, allgathers 0.16, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
16: nid005802:6298:6897 [1] NCCL INFO Init timings: rank 65 nranks 128 total 3.62 (kernels 0.06, bootstrap 3.05, allgathers 0.16, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
20: nid005913:292683:293201 [2] NCCL INFO ncclCommInitRank comm 0xaaaaf0f2a8d0 rank 82 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 commId 0x1958874c5d2a0126 - Init COMPLETE
 8: nid005586:68928:69450 [2] NCCL INFO ncclCommInitRank comm 0xaaaaf16101a0 rank 34 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 commId 0x1958874c5d2a0126 - Init COMPLETE
14: nid005600:217723:218244 [3] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
20: nid005913:292683:293201 [2] NCCL INFO Init timings: rank 82 nranks 128 total 3.32 (kernels 1.05, bootstrap 1.76, allgathers 0.16, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
 8: nid005586:68928:69450 [2] NCCL INFO Init timings: rank 34 nranks 128 total 3.44 (kernels 0.06, bootstrap 2.87, allgathers 0.15, topo 0.32, graphs 0.02, connections 0.02, rest 0.00)
14: nid005600:217723:218244 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
 8: nid005586:68927:69451 [1] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
14: nid005600:217723:218244 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
14: nid005600:217723:218244 [3] NCCL INFO ncclCommInitRank comm 0xaaab2a979520 rank 59 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 commId 0x1958874c5d2a0126 - Init COMPLETE
 8: nid005586:68927:69451 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
 8: nid005586:68927:69451 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
14: nid005600:217723:218244 [3] NCCL INFO Init timings: rank 59 nranks 128 total 2.87 (kernels 0.56, bootstrap 1.81, allgathers 0.16, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
 8: nid005586:68927:69451 [1] NCCL INFO ncclCommInitRank comm 0xaaaaec21b350 rank 33 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 commId 0x1958874c5d2a0126 - Init COMPLETE
 8: nid005586:68927:69451 [1] NCCL INFO Init timings: rank 33 nranks 128 total 3.44 (kernels 0.06, bootstrap 2.87, allgathers 0.15, topo 0.32, graphs 0.02, connections 0.02, rest 0.00)
14: nid005600:217720:218195 [0] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
 8: nid005586:68929:69489 [3] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
14: nid005600:217720:218195 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
14: nid005600:217720:218195 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
14: nid005600:217720:218195 [0] NCCL INFO ncclCommInitRank comm 0xaaaadc9bcbc0 rank 56 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 commId 0x1958874c5d2a0126 - Init COMPLETE
 8: nid005586:68929:69489 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
14: nid005600:217720:218195 [0] NCCL INFO Init timings: rank 56 nranks 128 total 4.86 (kernels 0.23, bootstrap 4.12, allgathers 0.16, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
 8: nid005586:68929:69489 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
16: nid005802:6300:6899 [3] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
16: nid005802:6300:6899 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
 8: nid005586:68929:69489 [3] NCCL INFO ncclCommInitRank comm 0xaaab0425a760 rank 35 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 commId 0x1958874c5d2a0126 - Init COMPLETE
16: nid005802:6300:6899 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
 8: nid005586:68929:69489 [3] NCCL INFO Init timings: rank 35 nranks 128 total 2.35 (kernels 0.06, bootstrap 1.78, allgathers 0.15, topo 0.32, graphs 0.02, connections 0.02, rest 0.00)
16: nid005802:6300:6899 [3] NCCL INFO ncclCommInitRank comm 0xaaaae402b650 rank 67 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 commId 0x1958874c5d2a0126 - Init COMPLETE
16: nid005802:6300:6899 [3] NCCL INFO Init timings: rank 67 nranks 128 total 3.57 (kernels 0.56, bootstrap 2.50, allgathers 0.16, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
16: nid005802:6299:6898 [2] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
16: nid005802:6299:6898 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
16: nid005802:6299:6898 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
16: nid005802:6299:6898 [2] NCCL INFO ncclCommInitRank comm 0xaaab08f00a50 rank 66 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 commId 0x1958874c5d2a0126 - Init COMPLETE
16: nid005802:6299:6898 [2] NCCL INFO Init timings: rank 66 nranks 128 total 3.58 (kernels 0.56, bootstrap 2.52, allgathers 0.16, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
16: nid005802:6297:6852 [0] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
16: nid005802:6297:6852 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
16: nid005802:6297:6852 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
16: nid005802:6297:6852 [0] NCCL INFO ncclCommInitRank comm 0xaaab18b83d10 rank 64 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 commId 0x1958874c5d2a0126 - Init COMPLETE
16: nid005802:6297:6852 [0] NCCL INFO Init timings: rank 64 nranks 128 total 5.13 (kernels 0.50, bootstrap 4.12, allgathers 0.16, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
15: nid005601:210676:211210 [0] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
15: nid005601:210676:211210 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
15: nid005601:210676:211210 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
15: nid005601:210676:211210 [0] NCCL INFO ncclCommInitRank comm 0xaaab05fd2fb0 rank 60 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 commId 0x1958874c5d2a0126 - Init COMPLETE
15: nid005601:210676:211210 [0] NCCL INFO Init timings: rank 60 nranks 128 total 5.12 (kernels 0.39, bootstrap 4.22, allgathers 0.16, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
13: nid005595:197886:198472 [3] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
13: nid005595:197886:198472 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
13: nid005595:197886:198472 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
13: nid005595:197886:198472 [3] NCCL INFO ncclCommInitRank comm 0xaaaaea46b560 rank 55 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 commId 0x1958874c5d2a0126 - Init COMPLETE
13: nid005595:197886:198472 [3] NCCL INFO Init timings: rank 55 nranks 128 total 4.85 (kernels 0.56, bootstrap 3.78, allgathers 0.16, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
12: nid005594:53087:53607 [2] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
15: nid005601:210679:211194 [3] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
12: nid005594:53087:53607 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
15: nid005601:210679:211194 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
15: nid005601:210679:211194 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
12: nid005594:53087:53607 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
12: nid005594:53087:53607 [2] NCCL INFO ncclCommInitRank comm 0xaaab36e31f10 rank 50 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 commId 0x1958874c5d2a0126 - Init COMPLETE
15: nid005601:210677:211211 [1] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
15: nid005601:210679:211194 [3] NCCL INFO ncclCommInitRank comm 0xaaab0b2c3130 rank 63 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 commId 0x1958874c5d2a0126 - Init COMPLETE
18: nid005911:38866:39421 [2] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
12: nid005594:53087:53607 [2] NCCL INFO Init timings: rank 50 nranks 128 total 4.11 (kernels 1.05, bootstrap 2.56, allgathers 0.15, topo 0.32, graphs 0.02, connections 0.01, rest 0.01)
15: nid005601:210677:211211 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
15: nid005601:210677:211211 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
15: nid005601:210679:211194 [3] NCCL INFO Init timings: rank 63 nranks 128 total 5.38 (kernels 0.66, bootstrap 4.22, allgathers 0.16, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
15: nid005601:210677:211211 [1] NCCL INFO ncclCommInitRank comm 0xaaaaee59b4c0 rank 61 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 commId 0x1958874c5d2a0126 - Init COMPLETE
18: nid005911:38866:39421 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
18: nid005911:38866:39421 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
15: nid005601:210677:211211 [1] NCCL INFO Init timings: rank 61 nranks 128 total 4.75 (kernels 0.06, bootstrap 4.18, allgathers 0.16, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
18: nid005911:38866:39421 [2] NCCL INFO ncclCommInitRank comm 0xaaaafa2a9ac0 rank 74 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 commId 0x1958874c5d2a0126 - Init COMPLETE
18: nid005911:38866:39421 [2] NCCL INFO Init timings: rank 74 nranks 128 total 3.07 (kernels 0.23, bootstrap 2.33, allgathers 0.16, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
24: nid005918:92507:93078 [3] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
15: nid005601:210678:211209 [2] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
24: nid005918:92507:93078 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
24: nid005918:92507:93078 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
24: nid005918:92507:93078 [3] NCCL INFO ncclCommInitRank comm 0xaaaae09e21b0 rank 99 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 commId 0x1958874c5d2a0126 - Init COMPLETE
15: nid005601:210678:211209 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
15: nid005601:210678:211209 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
18: nid005911:38865:39420 [1] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
15: nid005601:210678:211209 [2] NCCL INFO ncclCommInitRank comm 0xaaab22984300 rank 62 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 commId 0x1958874c5d2a0126 - Init COMPLETE
15: nid005601:210678:211209 [2] NCCL INFO Init timings: rank 62 nranks 128 total 5.20 (kernels 0.48, bootstrap 4.22, allgathers 0.16, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
18: nid005911:38865:39420 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
18: nid005911:38865:39420 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
24: nid005918:92507:93078 [3] NCCL INFO Init timings: rank 99 nranks 128 total 2.42 (kernels 0.06, bootstrap 1.86, allgathers 0.05, topo 0.42, graphs 0.02, connections 0.01, rest 0.01)
13: nid005595:197885:198470 [2] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
12: nid005594:53086:53606 [1] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
18: nid005911:38865:39420 [1] NCCL INFO ncclCommInitRank comm 0xaaaae2c31590 rank 73 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 commId 0x1958874c5d2a0126 - Init COMPLETE
18: nid005911:38864:39357 [0] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
29: nid005932:167682:168229 [2] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
12: nid005594:53085:53561 [0] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
13: nid005595:197885:198470 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
13: nid005595:197884:198471 [1] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
13: nid005595:197885:198470 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
13: nid005595:197883:198429 [0] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
18: nid005911:38865:39420 [1] NCCL INFO Init timings: rank 73 nranks 128 total 3.09 (kernels 0.06, bootstrap 2.52, allgathers 0.16, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
18: nid005911:38864:39357 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
18: nid005911:38864:39357 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
18: nid005911:38864:39357 [0] NCCL INFO ncclCommInitRank comm 0xaaaade95adc0 rank 72 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 commId 0x1958874c5d2a0126 - Init COMPLETE
18: nid005911:38864:39357 [0] NCCL INFO Init timings: rank 72 nranks 128 total 4.65 (kernels 0.13, bootstrap 4.01, allgathers 0.16, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
29: nid005932:167682:168229 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
29: nid005932:167682:168229 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
12: nid005594:53086:53606 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
12: nid005594:53085:53561 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
13: nid005595:197885:198470 [2] NCCL INFO ncclCommInitRank comm 0xaaab3c8b15f0 rank 54 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 commId 0x1958874c5d2a0126 - Init COMPLETE
13: nid005595:197885:198470 [2] NCCL INFO Init timings: rank 54 nranks 128 total 4.85 (kernels 0.56, bootstrap 3.78, allgathers 0.16, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
13: nid005595:197884:198471 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
13: nid005595:197883:198429 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
29: nid005932:167682:168229 [2] NCCL INFO ncclCommInitRank comm 0xaaab2bddcec0 rank 118 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 commId 0x1958874c5d2a0126 - Init COMPLETE
24: nid005918:92505:93080 [1] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
12: nid005594:53086:53606 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
12: nid005594:53085:53561 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
13: nid005595:197884:198471 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
13: nid005595:197883:198429 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
13: nid005595:197884:198471 [1] NCCL INFO ncclCommInitRank comm 0xaaab0cbd2c40 rank 53 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 commId 0x1958874c5d2a0126 - Init COMPLETE
13: nid005595:197883:198429 [0] NCCL INFO ncclCommInitRank comm 0xaaab1fa69360 rank 52 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 commId 0x1958874c5d2a0126 - Init COMPLETE
18: nid005911:38867:39424 [3] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
29: nid005932:167682:168229 [2] NCCL INFO Init timings: rank 118 nranks 128 total 2.85 (kernels 0.06, bootstrap 2.27, allgathers 0.02, topo 0.45, graphs 0.02, connections 0.02, rest 0.00)
24: nid005918:92504:93029 [0] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
24: nid005918:92505:93080 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
12: nid005594:53086:53606 [1] NCCL INFO ncclCommInitRank comm 0xaaaadbafb110 rank 49 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 commId 0x1958874c5d2a0126 - Init COMPLETE
12: nid005594:53085:53561 [0] NCCL INFO ncclCommInitRank comm 0xaaab0e435340 rank 48 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 commId 0x1958874c5d2a0126 - Init COMPLETE
13: nid005595:197883:198429 [0] NCCL INFO Init timings: rank 52 nranks 128 total 5.39 (kernels 0.56, bootstrap 4.32, allgathers 0.16, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
13: nid005595:197884:198471 [1] NCCL INFO Init timings: rank 53 nranks 128 total 4.85 (kernels 0.56, bootstrap 3.78, allgathers 0.16, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
18: nid005911:38867:39424 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
18: nid005911:38867:39424 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
18: nid005911:38867:39424 [3] NCCL INFO ncclCommInitRank comm 0xaaab31f11170 rank 75 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 commId 0x1958874c5d2a0126 - Init COMPLETE
24: nid005918:92505:93080 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
24: nid005918:92504:93029 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
24: nid005918:92505:93080 [1] NCCL INFO ncclCommInitRank comm 0xaaab23b3bb80 rank 97 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 commId 0x1958874c5d2a0126 - Init COMPLETE
12: nid005594:53085:53561 [0] NCCL INFO Init timings: rank 48 nranks 128 total 5.18 (kernels 0.45, bootstrap 4.22, allgathers 0.15, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
18: nid005911:38867:39424 [3] NCCL INFO Init timings: rank 75 nranks 128 total 1.99 (kernels 0.06, bootstrap 1.42, allgathers 0.16, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
24: nid005918:92504:93029 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
24: nid005918:92506:93079 [2] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
24: nid005918:92504:93029 [0] NCCL INFO ncclCommInitRank comm 0xaaaaf3895ae0 rank 96 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 commId 0x1958874c5d2a0126 - Init COMPLETE
24: nid005918:92505:93080 [1] NCCL INFO Init timings: rank 97 nranks 128 total 2.42 (kernels 0.06, bootstrap 1.85, allgathers 0.05, topo 0.42, graphs 0.02, connections 0.02, rest 0.00)
12: nid005594:53086:53606 [1] NCCL INFO Init timings: rank 49 nranks 128 total 4.17 (kernels 0.07, bootstrap 3.59, allgathers 0.15, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
12: nid005594:53088:53605 [3] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
24: nid005918:92506:93079 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
24: nid005918:92506:93079 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
24: nid005918:92504:93029 [0] NCCL INFO Init timings: rank 96 nranks 128 total 3.23 (kernels 0.11, bootstrap 2.61, allgathers 0.05, topo 0.42, graphs 0.02, connections 0.02, rest 0.00)
24: nid005918:92506:93079 [2] NCCL INFO ncclCommInitRank comm 0xaaab22641a60 rank 98 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 commId 0x1958874c5d2a0126 - Init COMPLETE
12: nid005594:53088:53605 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
24: nid005918:92506:93079 [2] NCCL INFO Init timings: rank 98 nranks 128 total 2.42 (kernels 0.06, bootstrap 1.85, allgathers 0.05, topo 0.42, graphs 0.02, connections 0.02, rest 0.00)
12: nid005594:53088:53605 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
12: nid005594:53088:53605 [3] NCCL INFO ncclCommInitRank comm 0xaaab14e02fb0 rank 51 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 commId 0x1958874c5d2a0126 - Init COMPLETE
12: nid005594:53088:53605 [3] NCCL INFO Init timings: rank 51 nranks 128 total 4.17 (kernels 0.07, bootstrap 3.60, allgathers 0.15, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
29: nid005932:167681:168228 [1] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
29: nid005932:167683:168230 [3] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
29: nid005932:167681:168228 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
29: nid005932:167681:168228 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
29: nid005932:167683:168230 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
29: nid005932:167681:168228 [1] NCCL INFO ncclCommInitRank comm 0xaaaac3b4db00 rank 117 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 commId 0x1958874c5d2a0126 - Init COMPLETE
29: nid005932:167683:168230 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
29: nid005932:167680:168169 [0] NCCL INFO TUNER/Plugin: Plugin name set by env to libnccl-net-ofi.so
29: nid005932:167681:168228 [1] NCCL INFO Init timings: rank 117 nranks 128 total 2.85 (kernels 0.06, bootstrap 2.27, allgathers 0.02, topo 0.45, graphs 0.02, connections 0.02, rest 0.00)
29: nid005932:167683:168230 [3] NCCL INFO ncclCommInitRank comm 0xaaab0adabbc0 rank 119 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 commId 0x1958874c5d2a0126 - Init COMPLETE
29: nid005932:167680:168169 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v3 symbol.
29: nid005932:167680:168169 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2 symbol, using internal tuner instead.
29: nid005932:167683:168230 [3] NCCL INFO Init timings: rank 119 nranks 128 total 2.83 (kernels 0.06, bootstrap 2.25, allgathers 0.02, topo 0.45, graphs 0.02, connections 0.02, rest 0.00)
29: nid005932:167680:168169 [0] NCCL INFO ncclCommInitRank comm 0xaaab03ee4fa0 rank 116 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 commId 0x1958874c5d2a0126 - Init COMPLETE
29: nid005932:167680:168169 [0] NCCL INFO Init timings: rank 116 nranks 128 total 4.71 (kernels 0.14, bootstrap 4.05, allgathers 0.02, topo 0.45, graphs 0.02, connections 0.02, rest 0.00)
 4: nid005581:264523:265078 [0] NCCL INFO Channel 00/0 : 16[0] -> 17[1] via P2P/CUMEM
31: nid005937:256589:257160 [0] NCCL INFO Channel 01/0 : 124[0] -> 125[1] via P2P/CUMEM
 8: nid005586:68926:69499 [0] NCCL INFO Channel 00/0 : 32[0] -> 33[1] via P2P/CUMEM
 4: nid005581:264523:265078 [0] NCCL INFO Channel 04/0 : 16[0] -> 17[1] via P2P/CUMEM
31: nid005937:256589:257160 [0] NCCL INFO Channel 05/0 : 124[0] -> 125[1] via P2P/CUMEM
 8: nid005586:68926:69499 [0] NCCL INFO Channel 04/0 : 32[0] -> 33[1] via P2P/CUMEM
 4: nid005581:264525:265077 [2] NCCL INFO Channel 00/0 : 18[2] -> 19[3] via P2P/CUMEM
26: nid005920:67123:67693 [0] NCCL INFO Channel 00/0 : 104[0] -> 105[1] via P2P/CUMEM
 4: nid005581:264525:265077 [2] NCCL INFO Channel 04/0 : 18[2] -> 19[3] via P2P/CUMEM
 4: nid005581:264524:265080 [1] NCCL INFO Channel 00/0 : 17[1] -> 18[2] via P2P/CUMEM
 4: nid005581:264524:265080 [1] NCCL INFO Channel 04/0 : 17[1] -> 18[2] via P2P/CUMEM
31: nid005937:256590:257161 [1] NCCL INFO Channel 01/0 : 125[1] -> 126[2] via P2P/CUMEM
31: nid005937:256591:257162 [2] NCCL INFO Channel 01/0 : 126[2] -> 127[3] via P2P/CUMEM
26: nid005920:67123:67693 [0] NCCL INFO Channel 04/0 : 104[0] -> 105[1] via P2P/CUMEM
 4: nid005581:264523:265078 [0] NCCL INFO Channel 02/0 : 16[0] -> 19[3] via P2P/CUMEM
31: nid005937:256590:257161 [1] NCCL INFO Channel 05/0 : 125[1] -> 126[2] via P2P/CUMEM
31: nid005937:256591:257162 [2] NCCL INFO Channel 05/0 : 126[2] -> 127[3] via P2P/CUMEM
 4: nid005581:264523:265078 [0] NCCL INFO Channel 03/0 : 16[0] -> 19[3] via P2P/CUMEM
 3: nid005580:71819:72369 [0] NCCL INFO Channel 01/0 : 12[0] -> 13[1] via P2P/CUMEM
 8: nid005586:68928:69502 [2] NCCL INFO Channel 00/0 : 34[2] -> 35[3] via P2P/CUMEM
 8: nid005586:68927:69501 [1] NCCL INFO Channel 00/0 : 33[1] -> 34[2] via P2P/CUMEM
31: nid005937:256589:257160 [0] NCCL INFO Channel 02/0 : 124[0] -> 127[3] via P2P/CUMEM
 4: nid005581:264523:265078 [0] NCCL INFO Channel 06/0 : 16[0] -> 19[3] via P2P/CUMEM
 8: nid005586:68928:69502 [2] NCCL INFO Channel 04/0 : 34[2] -> 35[3] via P2P/CUMEM
31: nid005937:256589:257160 [0] NCCL INFO Channel 03/0 : 124[0] -> 127[3] via P2P/CUMEM
 8: nid005586:68927:69501 [1] NCCL INFO Channel 04/0 : 33[1] -> 34[2] via P2P/CUMEM
 4: nid005581:264523:265078 [0] NCCL INFO Channel 07/0 : 16[0] -> 19[3] via P2P/CUMEM
28: nid005929:16030:16584 [0] NCCL INFO Channel 00/0 : 112[0] -> 113[1] via P2P/CUMEM
 3: nid005580:71819:72369 [0] NCCL INFO Channel 05/0 : 12[0] -> 13[1] via P2P/CUMEM
31: nid005937:256589:257160 [0] NCCL INFO Channel 06/0 : 124[0] -> 127[3] via P2P/CUMEM
 8: nid005586:68926:69499 [0] NCCL INFO Channel 02/0 : 32[0] -> 35[3] via P2P/CUMEM
26: nid005920:67125:67695 [2] NCCL INFO Channel 00/0 : 106[2] -> 107[3] via P2P/CUMEM
31: nid005937:256589:257160 [0] NCCL INFO Channel 07/0 : 124[0] -> 127[3] via P2P/CUMEM
10: nid005590:110710:111255 [0] NCCL INFO Channel 00/0 : 40[0] -> 41[1] via P2P/CUMEM
 8: nid005586:68926:69499 [0] NCCL INFO Channel 03/0 : 32[0] -> 35[3] via P2P/CUMEM
26: nid005920:67125:67695 [2] NCCL INFO Channel 04/0 : 106[2] -> 107[3] via P2P/CUMEM
28: nid005929:16032:16583 [2] NCCL INFO Channel 00/0 : 114[2] -> 115[3] via P2P/CUMEM
28: nid005929:16030:16584 [0] NCCL INFO Channel 04/0 : 112[0] -> 113[1] via P2P/CUMEM
15: nid005601:210676:211245 [0] NCCL INFO Channel 01/0 : 60[0] -> 61[1] via P2P/CUMEM
 8: nid005586:68926:69499 [0] NCCL INFO Channel 06/0 : 32[0] -> 35[3] via P2P/CUMEM
26: nid005920:67124:67696 [1] NCCL INFO Channel 00/0 : 105[1] -> 106[2] via P2P/CUMEM
 8: nid005586:68926:69499 [0] NCCL INFO Channel 07/0 : 32[0] -> 35[3] via P2P/CUMEM
26: nid005920:67124:67696 [1] NCCL INFO Channel 04/0 : 105[1] -> 106[2] via P2P/CUMEM
28: nid005929:16031:16585 [1] NCCL INFO Channel 00/0 : 113[1] -> 114[2] via P2P/CUMEM
15: nid005601:210676:211245 [0] NCCL INFO Channel 05/0 : 60[0] -> 61[1] via P2P/CUMEM
10: nid005590:110710:111255 [0] NCCL INFO Channel 04/0 : 40[0] -> 41[1] via P2P/CUMEM
28: nid005929:16032:16583 [2] NCCL INFO Channel 04/0 : 114[2] -> 115[3] via P2P/CUMEM
 3: nid005580:71821:72370 [2] NCCL INFO Channel 01/0 : 14[2] -> 15[3] via P2P/CUMEM
 3: nid005580:71820:72372 [1] NCCL INFO Channel 01/0 : 13[1] -> 14[2] via P2P/CUMEM
27: nid005922:80741:81298 [0] NCCL INFO Channel 01/0 : 108[0] -> 109[1] via P2P/CUMEM
26: nid005920:67123:67693 [0] NCCL INFO Channel 02/0 : 104[0] -> 107[3] via P2P/CUMEM
28: nid005929:16031:16585 [1] NCCL INFO Channel 04/0 : 113[1] -> 114[2] via P2P/CUMEM
 5: nid005582:196715:197402 [2] NCCL INFO Channel 01/0 : 22[2] -> 23[3] via P2P/CUMEM
11: nid005591:191603:192156 [0] NCCL INFO Channel 01/0 : 44[0] -> 45[1] via P2P/CUMEM
 3: nid005580:71821:72370 [2] NCCL INFO Channel 05/0 : 14[2] -> 15[3] via P2P/CUMEM
26: nid005920:67123:67693 [0] NCCL INFO Channel 03/0 : 104[0] -> 107[3] via P2P/CUMEM
 3: nid005580:71820:72372 [1] NCCL INFO Channel 05/0 : 13[1] -> 14[2] via P2P/CUMEM
28: nid005929:16030:16584 [0] NCCL INFO Channel 02/0 : 112[0] -> 115[3] via P2P/CUMEM
27: nid005922:80741:81298 [0] NCCL INFO Channel 05/0 : 108[0] -> 109[1] via P2P/CUMEM
 0: nid005574:69059:69643 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM
26: nid005920:67123:67693 [0] NCCL INFO Channel 06/0 : 104[0] -> 107[3] via P2P/CUMEM
 7: nid005585:122005:122556 [0] NCCL INFO Channel 01/0 : 28[0] -> 29[1] via P2P/CUMEM
 5: nid005582:196715:197402 [2] NCCL INFO Channel 05/0 : 22[2] -> 23[3] via P2P/CUMEM
 0: nid005574:69059:69643 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM
28: nid005929:16030:16584 [0] NCCL INFO Channel 03/0 : 112[0] -> 115[3] via P2P/CUMEM
 5: nid005582:196714:197403 [1] NCCL INFO Channel 01/0 : 21[1] -> 22[2] via P2P/CUMEM
26: nid005920:67123:67693 [0] NCCL INFO Channel 07/0 : 104[0] -> 107[3] via P2P/CUMEM
20: nid005913:292682:293234 [1] NCCL INFO Channel 00/0 : 81[1] -> 82[2] via P2P/CUMEM
20: nid005913:292681:293237 [0] NCCL INFO Channel 00/0 : 80[0] -> 81[1] via P2P/CUMEM
 3: nid005580:71819:72369 [0] NCCL INFO Channel 02/0 : 12[0] -> 15[3] via P2P/CUMEM
 5: nid005582:196713:197404 [0] NCCL INFO Channel 01/0 : 20[0] -> 21[1] via P2P/CUMEM
 0: nid005574:69058:69646 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM
 6: nid005584:28285:28834 [0] NCCL INFO Channel 00/0 : 24[0] -> 25[1] via P2P/CUMEM
 9: nid005588:35935:36510 [0] NCCL INFO Channel 01/0 : 36[0] -> 37[1] via P2P/CUMEM
 9: nid005588:35936:36508 [1] NCCL INFO Channel 01/0 : 37[1] -> 38[2] via P2P/CUMEM
11: nid005591:191603:192156 [0] NCCL INFO Channel 05/0 : 44[0] -> 45[1] via P2P/CUMEM
 1: nid005576:147557:148113 [0] NCCL INFO Channel 01/0 : 4[0] -> 5[1] via P2P/CUMEM
14: nid005600:217720:218280 [0] NCCL INFO Channel 00/0 : 56[0] -> 57[1] via P2P/CUMEM
28: nid005929:16030:16584 [0] NCCL INFO Channel 06/0 : 112[0] -> 115[3] via P2P/CUMEM
 5: nid005582:196714:197403 [1] NCCL INFO Channel 05/0 : 21[1] -> 22[2] via P2P/CUMEM
 7: nid005585:122005:122556 [0] NCCL INFO Channel 05/0 : 28[0] -> 29[1] via P2P/CUMEM
 3: nid005580:71819:72369 [0] NCCL INFO Channel 03/0 : 12[0] -> 15[3] via P2P/CUMEM
 1: nid005576:147558:148112 [1] NCCL INFO Channel 01/0 : 5[1] -> 6[2] via P2P/CUMEM
20: nid005913:292682:293234 [1] NCCL INFO Channel 04/0 : 81[1] -> 82[2] via P2P/CUMEM
28: nid005929:16030:16584 [0] NCCL INFO Channel 07/0 : 112[0] -> 115[3] via P2P/CUMEM
13: nid005595:197883:198485 [0] NCCL INFO Channel 01/0 : 52[0] -> 53[1] via P2P/CUMEM
23: nid005917:276885:277440 [0] NCCL INFO Channel 01/0 : 92[0] -> 93[1] via P2P/CUMEM
10: nid005590:110712:111257 [2] NCCL INFO Channel 00/0 : 42[2] -> 43[3] via P2P/CUMEM
18: nid005911:38864:39434 [0] NCCL INFO Channel 00/0 : 72[0] -> 73[1] via P2P/CUMEM
 3: nid005580:71819:72369 [0] NCCL INFO Channel 06/0 : 12[0] -> 15[3] via P2P/CUMEM
 0: nid005574:69058:69646 [0] NCCL INFO Channel 04/0 : 0[0] -> 1[1] via P2P/CUMEM
15: nid005601:210677:211246 [1] NCCL INFO Channel 01/0 : 61[1] -> 62[2] via P2P/CUMEM
22: nid005915:274814:275370 [0] NCCL INFO Channel 00/0 : 88[0] -> 89[1] via P2P/CUMEM
27: nid005922:80743:81299 [2] NCCL INFO Channel 01/0 : 110[2] -> 111[3] via P2P/CUMEM
 5: nid005582:196713:197404 [0] NCCL INFO Channel 05/0 : 20[0] -> 21[1] via P2P/CUMEM
 9: nid005588:35936:36508 [1] NCCL INFO Channel 05/0 : 37[1] -> 38[2] via P2P/CUMEM
20: nid005913:292681:293237 [0] NCCL INFO Channel 04/0 : 80[0] -> 81[1] via P2P/CUMEM
15: nid005601:210678:211248 [2] NCCL INFO Channel 01/0 : 62[2] -> 63[3] via P2P/CUMEM
25: nid005919:107462:108038 [0] NCCL INFO Channel 01/0 : 100[0] -> 101[1] via P2P/CUMEM
14: nid005600:217721:218278 [1] NCCL INFO Channel 00/0 : 57[1] -> 58[2] via P2P/CUMEM
22: nid005915:274816:275369 [2] NCCL INFO Channel 00/0 : 90[2] -> 91[3] via P2P/CUMEM
 3: nid005580:71819:72369 [0] NCCL INFO Channel 07/0 : 12[0] -> 15[3] via P2P/CUMEM
15: nid005601:210677:211246 [1] NCCL INFO Channel 05/0 : 61[1] -> 62[2] via P2P/CUMEM
 6: nid005584:28285:28834 [0] NCCL INFO Channel 04/0 : 24[0] -> 25[1] via P2P/CUMEM
30: nid005936:49909:50480 [1] NCCL INFO Channel 00/0 : 121[1] -> 122[2] via P2P/CUMEM
10: nid005590:110711:111258 [1] NCCL INFO Channel 00/0 : 41[1] -> 42[2] via P2P/CUMEM
10: nid005590:110712:111257 [2] NCCL INFO Channel 04/0 : 42[2] -> 43[3] via P2P/CUMEM
14: nid005600:217720:218280 [0] NCCL INFO Channel 04/0 : 56[0] -> 57[1] via P2P/CUMEM
27: nid005922:80743:81299 [2] NCCL INFO Channel 05/0 : 110[2] -> 111[3] via P2P/CUMEM
 1: nid005576:147557:148113 [0] NCCL INFO Channel 05/0 : 4[0] -> 5[1] via P2P/CUMEM
 1: nid005576:147558:148112 [1] NCCL INFO Channel 05/0 : 5[1] -> 6[2] via P2P/CUMEM
13: nid005595:197883:198485 [0] NCCL INFO Channel 05/0 : 52[0] -> 53[1] via P2P/CUMEM
22: nid005915:274816:275369 [2] NCCL INFO Channel 04/0 : 90[2] -> 91[3] via P2P/CUMEM
 0: nid005574:69060:69645 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM
15: nid005601:210678:211248 [2] NCCL INFO Channel 05/0 : 62[2] -> 63[3] via P2P/CUMEM
30: nid005936:49908:50482 [0] NCCL INFO Channel 00/0 : 120[0] -> 121[1] via P2P/CUMEM
 9: nid005588:35935:36510 [0] NCCL INFO Channel 05/0 : 36[0] -> 37[1] via P2P/CUMEM
30: nid005936:49909:50480 [1] NCCL INFO Channel 04/0 : 121[1] -> 122[2] via P2P/CUMEM
20: nid005913:292683:293236 [2] NCCL INFO Channel 00/0 : 82[2] -> 83[3] via P2P/CUMEM
19: nid005912:12435:13009 [0] NCCL INFO Channel 01/0 : 76[0] -> 77[1] via P2P/CUMEM
 5: nid005582:196713:197404 [0] NCCL INFO Channel 02/0 : 20[0] -> 23[3] via P2P/CUMEM
 0: nid005574:69058:69646 [0] NCCL INFO Channel 02/0 : 0[0] -> 3[3] via P2P/CUMEM
 0: nid005574:69060:69645 [2] NCCL INFO Channel 04/0 : 2[2] -> 3[3] via P2P/CUMEM
14: nid005600:217722:218279 [2] NCCL INFO Channel 00/0 : 58[2] -> 59[3] via P2P/CUMEM
15: nid005601:210676:211245 [0] NCCL INFO Channel 02/0 : 60[0] -> 63[3] via P2P/CUMEM
22: nid005915:274814:275370 [0] NCCL INFO Channel 04/0 : 88[0] -> 89[1] via P2P/CUMEM
14: nid005600:217721:218278 [1] NCCL INFO Channel 04/0 : 57[1] -> 58[2] via P2P/CUMEM
 9: nid005588:35937:36509 [2] NCCL INFO Channel 01/0 : 38[2] -> 39[3] via P2P/CUMEM
11: nid005591:191605:192157 [2] NCCL INFO Channel 01/0 : 46[2] -> 47[3] via P2P/CUMEM
20: nid005913:292683:293236 [2] NCCL INFO Channel 04/0 : 82[2] -> 83[3] via P2P/CUMEM
27: nid005922:80742:81301 [1] NCCL INFO Channel 01/0 : 109[1] -> 110[2] via P2P/CUMEM
20: nid005913:292681:293237 [0] NCCL INFO Channel 02/0 : 80[0] -> 83[3] via P2P/CUMEM
 4: nid005581:264525:265077 [2] NCCL INFO Channel 02/0 : 14[2] -> 18[2] [receive] via NET/AWS Libfabric/2
25: nid005919:107462:108038 [0] NCCL INFO Channel 05/0 : 100[0] -> 101[1] via P2P/CUMEM
 5: nid005582:196713:197404 [0] NCCL INFO Channel 03/0 : 20[0] -> 23[3] via P2P/CUMEM
23: nid005917:276885:277440 [0] NCCL INFO Channel 05/0 : 92[0] -> 93[1] via P2P/CUMEM
 2: nid005577:17422:17996 [0] NCCL INFO Channel 00/0 : 8[0] -> 9[1] via P2P/CUMEM
 6: nid005584:28286:28832 [1] NCCL INFO Channel 00/0 : 25[1] -> 26[2] via P2P/CUMEM
 4: nid005581:264525:265077 [2] NCCL INFO Channel 06/0 : 14[2] -> 18[2] [receive] via NET/AWS Libfabric/2
 0: nid005574:69058:69646 [0] NCCL INFO Channel 03/0 : 0[0] -> 3[3] via P2P/CUMEM
27: nid005922:80742:81301 [1] NCCL INFO Channel 05/0 : 109[1] -> 110[2] via P2P/CUMEM
 4: nid005581:264525:265077 [2] NCCL INFO Channel 03/0 : 18[2] -> 22[2] [send] via NET/AWS Libfabric/2
 4: nid005581:264525:265077 [2] NCCL INFO Channel 07/0 : 18[2] -> 22[2] [send] via NET/AWS Libfabric/2
15: nid005601:210676:211245 [0] NCCL INFO Channel 03/0 : 60[0] -> 63[3] via P2P/CUMEM
 4: nid005581:264524:265080 [1] NCCL INFO Channel 03/0 : 13[1] -> 17[1] [receive] via NET/AWS Libfabric/1
 5: nid005582:196713:197404 [0] NCCL INFO Channel 06/0 : 20[0] -> 23[3] via P2P/CUMEM
 0: nid005574:69058:69646 [0] NCCL INFO Channel 06/0 : 0[0] -> 3[3] via P2P/CUMEM
14: nid005600:217722:218279 [2] NCCL INFO Channel 04/0 : 58[2] -> 59[3] via P2P/CUMEM
 9: nid005588:35937:36509 [2] NCCL INFO Channel 05/0 : 38[2] -> 39[3] via P2P/CUMEM
11: nid005591:191604:192159 [1] NCCL INFO Channel 01/0 : 45[1] -> 46[2] via P2P/CUMEM
 4: nid005581:264524:265080 [1] NCCL INFO Channel 07/0 : 13[1] -> 17[1] [receive] via NET/AWS Libfabric/1
 6: nid005584:28287:28835 [2] NCCL INFO Channel 00/0 : 26[2] -> 27[3] via P2P/CUMEM
 1: nid005576:147559:148115 [2] NCCL INFO Channel 01/0 : 6[2] -> 7[3] via P2P/CUMEM
11: nid005591:191605:192157 [2] NCCL INFO Channel 05/0 : 46[2] -> 47[3] via P2P/CUMEM
 6: nid005584:28286:28832 [1] NCCL INFO Channel 04/0 : 25[1] -> 26[2] via P2P/CUMEM
 4: nid005581:264524:265080 [1] NCCL INFO Channel 02/0 : 17[1] -> 21[1] [send] via NET/AWS Libfabric/1
 1: nid005576:147557:148113 [0] NCCL INFO Channel 02/0 : 4[0] -> 7[3] via P2P/CUMEM
 9: nid005588:35935:36510 [0] NCCL INFO Channel 02/0 : 36[0] -> 39[3] via P2P/CUMEM
 0: nid005574:69058:69646 [0] NCCL INFO Channel 07/0 : 0[0] -> 3[3] via P2P/CUMEM
 7: nid005585:122006:122557 [1] NCCL INFO Channel 01/0 : 29[1] -> 30[2] via P2P/CUMEM
14: nid005600:217720:218280 [0] NCCL INFO Channel 02/0 : 56[0] -> 59[3] via P2P/CUMEM
 4: nid005581:264524:265080 [1] NCCL INFO Channel 06/0 : 17[1] -> 21[1] [send] via NET/AWS Libfabric/1
 7: nid005585:122007:122558 [2] NCCL INFO Channel 01/0 : 30[2] -> 31[3] via P2P/CUMEM
 5: nid005582:196713:197404 [0] NCCL INFO Channel 07/0 : 20[0] -> 23[3] via P2P/CUMEM
30: nid005936:49908:50482 [0] NCCL INFO Channel 04/0 : 120[0] -> 121[1] via P2P/CUMEM
23: nid005917:276886:277439 [1] NCCL INFO Channel 01/0 : 93[1] -> 94[2] via P2P/CUMEM
 1: nid005576:147559:148115 [2] NCCL INFO Channel 05/0 : 6[2] -> 7[3] via P2P/CUMEM
15: nid005601:210676:211245 [0] NCCL INFO Channel 06/0 : 60[0] -> 63[3] via P2P/CUMEM
23: nid005917:276887:277438 [2] NCCL INFO Channel 01/0 : 94[2] -> 95[3] via P2P/CUMEM
24: nid005918:92504:93095 [0] NCCL INFO Channel 00/0 : 96[0] -> 97[1] via P2P/CUMEM
27: nid005922:80741:81298 [0] NCCL INFO Channel 02/0 : 108[0] -> 111[3] via P2P/CUMEM
 9: nid005588:35935:36510 [0] NCCL INFO Channel 03/0 : 36[0] -> 39[3] via P2P/CUMEM
22: nid005915:274815:275371 [1] NCCL INFO Channel 00/0 : 89[1] -> 90[2] via P2P/CUMEM
17: nid005803:180733:181299 [1] NCCL INFO Channel 01/0 : 69[1] -> 70[2] via P2P/CUMEM
11: nid005591:191604:192159 [1] NCCL INFO Channel 05/0 : 45[1] -> 46[2] via P2P/CUMEM
19: nid005912:12435:13009 [0] NCCL INFO Channel 05/0 : 76[0] -> 77[1] via P2P/CUMEM
 6: nid005584:28287:28835 [2] NCCL INFO Channel 04/0 : 26[2] -> 27[3] via P2P/CUMEM
 1: nid005576:147557:148113 [0] NCCL INFO Channel 03/0 : 4[0] -> 7[3] via P2P/CUMEM
23: nid005917:276886:277439 [1] NCCL INFO Channel 05/0 : 93[1] -> 94[2] via P2P/CUMEM
31: nid005937:256590:257161 [1] NCCL INFO Channel 02/0 : 121[1] -> 125[1] [receive] via NET/AWS Libfabric/1
 9: nid005588:35935:36510 [0] NCCL INFO Channel 06/0 : 36[0] -> 39[3] via P2P/CUMEM
 7: nid005585:122006:122557 [1] NCCL INFO Channel 05/0 : 29[1] -> 30[2] via P2P/CUMEM
 2: nid005577:17422:17996 [0] NCCL INFO Channel 04/0 : 8[0] -> 9[1] via P2P/CUMEM
15: nid005601:210676:211245 [0] NCCL INFO Channel 07/0 : 60[0] -> 63[3] via P2P/CUMEM
 7: nid005585:122007:122558 [2] NCCL INFO Channel 05/0 : 30[2] -> 31[3] via P2P/CUMEM
14: nid005600:217720:218280 [0] NCCL INFO Channel 03/0 : 56[0] -> 59[3] via P2P/CUMEM
 2: nid005577:17423:17995 [1] NCCL INFO Channel 00/0 : 9[1] -> 10[2] via P2P/CUMEM
19: nid005912:12437:13007 [2] NCCL INFO Channel 01/0 : 78[2] -> 79[3] via P2P/CUMEM
23: nid005917:276887:277438 [2] NCCL INFO Channel 05/0 : 94[2] -> 95[3] via P2P/CUMEM
27: nid005922:80741:81298 [0] NCCL INFO Channel 03/0 : 108[0] -> 111[3] via P2P/CUMEM
31: nid005937:256590:257161 [1] NCCL INFO Channel 06/0 : 121[1] -> 125[1] [receive] via NET/AWS Libfabric/1
 6: nid005584:28285:28834 [0] NCCL INFO Channel 02/0 : 24[0] -> 27[3] via P2P/CUMEM
 1: nid005576:147557:148113 [0] NCCL INFO Channel 06/0 : 4[0] -> 7[3] via P2P/CUMEM
14: nid005600:217720:218280 [0] NCCL INFO Channel 06/0 : 56[0] -> 59[3] via P2P/CUMEM
31: nid005937:256591:257162 [2] NCCL INFO Channel 03/0 : 122[2] -> 126[2] [receive] via NET/AWS Libfabric/2
13: nid005595:197884:198486 [1] NCCL INFO Channel 01/0 : 53[1] -> 54[2] via P2P/CUMEM
30: nid005936:49910:50483 [2] NCCL INFO Channel 00/0 : 122[2] -> 123[3] via P2P/CUMEM
22: nid005915:274815:275371 [1] NCCL INFO Channel 04/0 : 89[1] -> 90[2] via P2P/CUMEM
31: nid005937:256590:257161 [1] NCCL INFO Channel 03/0 : 125[1] -> 1[1] [send] via NET/AWS Libfabric/1
31: nid005937:256590:257161 [1] NCCL INFO Channel 07/0 : 125[1] -> 1[1] [send] via NET/AWS Libfabric/1
 9: nid005588:35935:36510 [0] NCCL INFO Channel 07/0 : 36[0] -> 39[3] via P2P/CUMEM
13: nid005595:197885:198487 [2] NCCL INFO Channel 01/0 : 54[2] -> 55[3] via P2P/CUMEM
11: nid005591:191603:192156 [0] NCCL INFO Channel 02/0 : 44[0] -> 47[3] via P2P/CUMEM
 6: nid005584:28285:28834 [0] NCCL INFO Channel 03/0 : 24[0] -> 27[3] via P2P/CUMEM
 1: nid005576:147557:148113 [0] NCCL INFO Channel 07/0 : 4[0] -> 7[3] via P2P/CUMEM
31: nid005937:256591:257162 [2] NCCL INFO Channel 07/0 : 122[2] -> 126[2] [receive] via NET/AWS Libfabric/2
19: nid005912:12436:13008 [1] NCCL INFO Channel 01/0 : 77[1] -> 78[2] via P2P/CUMEM
 2: nid005577:17423:17995 [1] NCCL INFO Channel 04/0 : 9[1] -> 10[2] via P2P/CUMEM
17: nid005803:180733:181299 [1] NCCL INFO Channel 05/0 : 69[1] -> 70[2] via P2P/CUMEM
30: nid005936:49910:50483 [2] NCCL INFO Channel 04/0 : 122[2] -> 123[3] via P2P/CUMEM
25: nid005919:107464:108040 [2] NCCL INFO Channel 01/0 : 102[2] -> 103[3] via P2P/CUMEM
23: nid005917:276885:277440 [0] NCCL INFO Channel 02/0 : 92[0] -> 95[3] via P2P/CUMEM
27: nid005922:80741:81298 [0] NCCL INFO Channel 06/0 : 108[0] -> 111[3] via P2P/CUMEM
19: nid005912:12437:13007 [2] NCCL INFO Channel 05/0 : 78[2] -> 79[3] via P2P/CUMEM
31: nid005937:256591:257162 [2] NCCL INFO Channel 02/0 : 126[2] -> 2[2] [send] via NET/AWS Libfabric/2
25: nid005919:107463:108041 [1] NCCL INFO Channel 01/0 : 101[1] -> 102[2] via P2P/CUMEM
14: nid005600:217720:218280 [0] NCCL INFO Channel 07/0 : 56[0] -> 59[3] via P2P/CUMEM
31: nid005937:256591:257162 [2] NCCL INFO Channel 06/0 : 126[2] -> 2[2] [send] via NET/AWS Libfabric/2
 7: nid005585:122005:122556 [0] NCCL INFO Channel 02/0 : 28[0] -> 31[3] via P2P/CUMEM
18: nid005911:38865:39435 [1] NCCL INFO Channel 00/0 : 73[1] -> 74[2] via P2P/CUMEM
30: nid005936:49908:50482 [0] NCCL INFO Channel 02/0 : 120[0] -> 123[3] via P2P/CUMEM
11: nid005591:191603:192156 [0] NCCL INFO Channel 03/0 : 44[0] -> 47[3] via P2P/CUMEM
13: nid005595:197884:198486 [1] NCCL INFO Channel 05/0 : 53[1] -> 54[2] via P2P/CUMEM
 6: nid005584:28285:28834 [0] NCCL INFO Channel 06/0 : 24[0] -> 27[3] via P2P/CUMEM
27: nid005922:80741:81298 [0] NCCL INFO Channel 07/0 : 108[0] -> 111[3] via P2P/CUMEM
13: nid005595:197885:198487 [2] NCCL INFO Channel 05/0 : 54[2] -> 55[3] via P2P/CUMEM
23: nid005917:276885:277440 [0] NCCL INFO Channel 03/0 : 92[0] -> 95[3] via P2P/CUMEM
19: nid005912:12436:13008 [1] NCCL INFO Channel 05/0 : 77[1] -> 78[2] via P2P/CUMEM
17: nid005803:180732:181300 [0] NCCL INFO Channel 01/0 : 68[0] -> 69[1] via P2P/CUMEM
 4: nid005581:264526:265079 [3] NCCL INFO Channel 01/0 : 15[3] -> 19[3] [receive] via NET/AWS Libfabric/3
 4: nid005581:264523:265078 [0] NCCL INFO Channel 00/0 : 12[0] -> 16[0] [receive] via NET/AWS Libfabric/0
11: nid005591:191603:192156 [0] NCCL INFO Channel 06/0 : 44[0] -> 47[3] via P2P/CUMEM
21: nid005914:166784:167332 [0] NCCL INFO Channel 01/0 : 84[0] -> 85[1] via P2P/CUMEM
24: nid005918:92504:93095 [0] NCCL INFO Channel 04/0 : 96[0] -> 97[1] via P2P/CUMEM
 7: nid005585:122005:122556 [0] NCCL INFO Channel 03/0 : 28[0] -> 31[3] via P2P/CUMEM
25: nid005919:107464:108040 [2] NCCL INFO Channel 05/0 : 102[2] -> 103[3] via P2P/CUMEM
22: nid005915:274814:275370 [0] NCCL INFO Channel 02/0 : 88[0] -> 91[3] via P2P/CUMEM
25: nid005919:107463:108041 [1] NCCL INFO Channel 05/0 : 101[1] -> 102[2] via P2P/CUMEM
30: nid005936:49908:50482 [0] NCCL INFO Channel 03/0 : 120[0] -> 123[3] via P2P/CUMEM
 6: nid005584:28285:28834 [0] NCCL INFO Channel 07/0 : 24[0] -> 27[3] via P2P/CUMEM
 4: nid005581:264526:265079 [3] NCCL INFO Channel 05/0 : 15[3] -> 19[3] [receive] via NET/AWS Libfabric/3
 4: nid005581:264523:265078 [0] NCCL INFO Channel 04/0 : 12[0] -> 16[0] [receive] via NET/AWS Libfabric/0
18: nid005911:38866:39436 [2] NCCL INFO Channel 00/0 : 74[2] -> 75[3] via P2P/CUMEM
18: nid005911:38865:39435 [1] NCCL INFO Channel 04/0 : 73[1] -> 74[2] via P2P/CUMEM
23: nid005917:276885:277440 [0] NCCL INFO Channel 06/0 : 92[0] -> 95[3] via P2P/CUMEM
19: nid005912:12435:13009 [0] NCCL INFO Channel 02/0 : 76[0] -> 79[3] via P2P/CUMEM
11: nid005591:191603:192156 [0] NCCL INFO Channel 07/0 : 44[0] -> 47[3] via P2P/CUMEM
22: nid005915:274814:275370 [0] NCCL INFO Channel 03/0 : 88[0] -> 91[3] via P2P/CUMEM
 4: nid005581:264526:265079 [3] NCCL INFO Channel 00/0 : 19[3] -> 23[3] [send] via NET/AWS Libfabric/3
 4: nid005581:264523:265078 [0] NCCL INFO Channel 01/0 : 16[0] -> 20[0] [send] via NET/AWS Libfabric/0
13: nid005595:197883:198485 [0] NCCL INFO Channel 02/0 : 52[0] -> 55[3] via P2P/CUMEM
24: nid005918:92506:93093 [2] NCCL INFO Channel 00/0 : 98[2] -> 99[3] via P2P/CUMEM
 7: nid005585:122005:122556 [0] NCCL INFO Channel 06/0 : 28[0] -> 31[3] via P2P/CUMEM
 8: nid005586:68928:69502 [2] NCCL INFO Channel 02/0 : 30[2] -> 34[2] [receive] via NET/AWS Libfabric/2
 2: nid005577:17422:17996 [0] NCCL INFO Channel 02/0 : 8[0] -> 11[3] via P2P/CUMEM
22: nid005915:274814:275370 [0] NCCL INFO Channel 06/0 : 88[0] -> 91[3] via P2P/CUMEM
30: nid005936:49908:50482 [0] NCCL INFO Channel 06/0 : 120[0] -> 123[3] via P2P/CUMEM
24: nid005918:92505:93094 [1] NCCL INFO Channel 00/0 : 97[1] -> 98[2] via P2P/CUMEM
 4: nid005581:264523:265078 [0] NCCL INFO Channel 05/0 : 16[0] -> 20[0] [send] via NET/AWS Libfabric/0
 4: nid005581:264526:265079 [3] NCCL INFO Channel 04/0 : 19[3] -> 23[3] [send] via NET/AWS Libfabric/3
 8: nid005586:68928:69502 [2] NCCL INFO Channel 06/0 : 30[2] -> 34[2] [receive] via NET/AWS Libfabric/2
16: nid005802:6297:6913 [0] NCCL INFO Channel 00/0 : 64[0] -> 65[1] via P2P/CUMEM
19: nid005912:12435:13009 [0] NCCL INFO Channel 03/0 : 76[0] -> 79[3] via P2P/CUMEM
23: nid005917:276885:277440 [0] NCCL INFO Channel 07/0 : 92[0] -> 95[3] via P2P/CUMEM
16: nid005802:6298:6912 [1] NCCL INFO Channel 00/0 : 65[1] -> 66[2] via P2P/CUMEM
21: nid005914:166784:167332 [0] NCCL INFO Channel 05/0 : 84[0] -> 85[1] via P2P/CUMEM
 8: nid005586:68927:69501 [1] NCCL INFO Channel 03/0 : 29[1] -> 33[1] [receive] via NET/AWS Libfabric/1
 8: nid005586:68928:69502 [2] NCCL INFO Channel 03/0 : 34[2] -> 38[2] [send] via NET/AWS Libfabric/2
12: nid005594:53085:53636 [0] NCCL INFO Channel 00/0 : 48[0] -> 49[1] via P2P/CUMEM
25: nid005919:107462:108038 [0] NCCL INFO Channel 02/0 : 100[0] -> 103[3] via P2P/CUMEM
22: nid005915:274814:275370 [0] NCCL INFO Channel 07/0 : 88[0] -> 91[3] via P2P/CUMEM
 7: nid005585:122005:122556 [0] NCCL INFO Channel 07/0 : 28[0] -> 31[3] via P2P/CUMEM
13: nid005595:197883:198485 [0] NCCL INFO Channel 03/0 : 52[0] -> 55[3] via P2P/CUMEM
 8: nid005586:68928:69502 [2] NCCL INFO Channel 07/0 : 34[2] -> 38[2] [send] via NET/AWS Libfabric/2
 8: nid005586:68927:69501 [1] NCCL INFO Channel 07/0 : 29[1] -> 33[1] [receive] via NET/AWS Libfabric/1
16: nid005802:6298:6912 [1] NCCL INFO Channel 04/0 : 65[1] -> 66[2] via P2P/CUMEM
31: nid005937:256589:257160 [0] NCCL INFO Channel 01/0 : 120[0] -> 124[0] [receive] via NET/AWS Libfabric/0
 2: nid005577:17424:17997 [2] NCCL INFO Channel 00/0 : 10[2] -> 11[3] via P2P/CUMEM
29: nid005932:167680:168242 [0] NCCL INFO Channel 01/0 : 116[0] -> 117[1] via P2P/CUMEM
 2: nid005577:17422:17996 [0] NCCL INFO Channel 03/0 : 8[0] -> 11[3] via P2P/CUMEM
30: nid005936:49908:50482 [0] NCCL INFO Channel 07/0 : 120[0] -> 123[3] via P2P/CUMEM
 8: nid005586:68927:69501 [1] NCCL INFO Channel 02/0 : 33[1] -> 37[1] [send] via NET/AWS Libfabric/1
24: nid005918:92506:93093 [2] NCCL INFO Channel 04/0 : 98[2] -> 99[3] via P2P/CUMEM
31: nid005937:256589:257160 [0] NCCL INFO Channel 05/0 : 120[0] -> 124[0] [receive] via NET/AWS Libfabric/0
19: nid005912:12435:13009 [0] NCCL INFO Channel 06/0 : 76[0] -> 79[3] via P2P/CUMEM
24: nid005918:92505:93094 [1] NCCL INFO Channel 04/0 : 97[1] -> 98[2] via P2P/CUMEM
 8: nid005586:68927:69501 [1] NCCL INFO Channel 06/0 : 33[1] -> 37[1] [send] via NET/AWS Libfabric/1
31: nid005937:256589:257160 [0] NCCL INFO Channel 00/0 : 124[0] -> 0[0] [send] via NET/AWS Libfabric/0
25: nid005919:107462:108038 [0] NCCL INFO Channel 03/0 : 100[0] -> 103[3] via P2P/CUMEM
31: nid005937:256589:257160 [0] NCCL INFO Channel 04/0 : 124[0] -> 0[0] [send] via NET/AWS Libfabric/0
 2: nid005577:17424:17997 [2] NCCL INFO Channel 04/0 : 10[2] -> 11[3] via P2P/CUMEM
17: nid005803:180734:181301 [2] NCCL INFO Channel 01/0 : 70[2] -> 71[3] via P2P/CUMEM
20: nid005913:292681:293237 [0] NCCL INFO Channel 03/0 : 80[0] -> 83[3] via P2P/CUMEM
28: nid005929:16032:16583 [2] NCCL INFO Channel 02/0 : 110[2] -> 114[2] [receive] via NET/AWS Libfabric/2
 2: nid005577:17422:17996 [0] NCCL INFO Channel 06/0 : 8[0] -> 11[3] via P2P/CUMEM
13: nid005595:197883:198485 [0] NCCL INFO Channel 06/0 : 52[0] -> 55[3] via P2P/CUMEM
10: nid005590:110711:111258 [1] NCCL INFO Channel 04/0 : 41[1] -> 42[2] via P2P/CUMEM
28: nid005929:16032:16583 [2] NCCL INFO Channel 06/0 : 110[2] -> 114[2] [receive] via NET/AWS Libfabric/2
19: nid005912:12435:13009 [0] NCCL INFO Channel 07/0 : 76[0] -> 79[3] via P2P/CUMEM
31: nid005937:256592:257159 [3] NCCL INFO Channel 00/0 : 123[3] -> 127[3] [receive] via NET/AWS Libfabric/3
26: nid005920:67125:67695 [2] NCCL INFO Channel 02/0 : 102[2] -> 106[2] [receive] via NET/AWS Libfabric/2
28: nid005929:16032:16583 [2] NCCL INFO Channel 03/0 : 114[2] -> 118[2] [send] via NET/AWS Libfabric/2
31: nid005937:256592:257159 [3] NCCL INFO Channel 04/0 : 123[3] -> 127[3] [receive] via NET/AWS Libfabric/3
20: nid005913:292681:293237 [0] NCCL INFO Channel 06/0 : 80[0] -> 83[3] via P2P/CUMEM
26: nid005920:67125:67695 [2] NCCL INFO Channel 06/0 : 102[2] -> 106[2] [receive] via NET/AWS Libfabric/2
25: nid005919:107462:108038 [0] NCCL INFO Channel 06/0 : 100[0] -> 103[3] via P2P/CUMEM
28: nid005929:16032:16583 [2] NCCL INFO Channel 07/0 : 114[2] -> 118[2] [send] via NET/AWS Libfabric/2
 2: nid005577:17422:17996 [0] NCCL INFO Channel 07/0 : 8[0] -> 11[3] via P2P/CUMEM
31: nid005937:256592:257159 [3] NCCL INFO Channel 01/0 : 127[3] -> 3[3] [send] via NET/AWS Libfabric/3
24: nid005918:92504:93095 [0] NCCL INFO Channel 02/0 : 96[0] -> 99[3] via P2P/CUMEM
26: nid005920:67125:67695 [2] NCCL INFO Channel 03/0 : 106[2] -> 110[2] [send] via NET/AWS Libfabric/2
16: nid005802:6297:6913 [0] NCCL INFO Channel 04/0 : 64[0] -> 65[1] via P2P/CUMEM
13: nid005595:197883:198485 [0] NCCL INFO Channel 07/0 : 52[0] -> 55[3] via P2P/CUMEM
 8: nid005586:68929:69500 [3] NCCL INFO Channel 01/0 : 31[3] -> 35[3] [receive] via NET/AWS Libfabric/3
12: nid005594:53085:53636 [0] NCCL INFO Channel 04/0 : 48[0] -> 49[1] via P2P/CUMEM
26: nid005920:67125:67695 [2] NCCL INFO Channel 07/0 : 106[2] -> 110[2] [send] via NET/AWS Libfabric/2
31: nid005937:256592:257159 [3] NCCL INFO Channel 05/0 : 127[3] -> 3[3] [send] via NET/AWS Libfabric/3
20: nid005913:292681:293237 [0] NCCL INFO Channel 07/0 : 80[0] -> 83[3] via P2P/CUMEM
 8: nid005586:68929:69500 [3] NCCL INFO Channel 05/0 : 31[3] -> 35[3] [receive] via NET/AWS Libfabric/3
10: nid005590:110710:111255 [0] NCCL INFO Channel 02/0 : 40[0] -> 43[3] via P2P/CUMEM
21: nid005914:166785:167333 [1] NCCL INFO Channel 01/0 : 85[1] -> 86[2] via P2P/CUMEM
26: nid005920:67124:67696 [1] NCCL INFO Channel 03/0 : 101[1] -> 105[1] [receive] via NET/AWS Libfabric/1
 8: nid005586:68929:69500 [3] NCCL INFO Channel 00/0 : 35[3] -> 39[3] [send] via NET/AWS Libfabric/3
25: nid005919:107462:108038 [0] NCCL INFO Channel 07/0 : 100[0] -> 103[3] via P2P/CUMEM
 8: nid005586:68929:69500 [3] NCCL INFO Channel 04/0 : 35[3] -> 39[3] [send] via NET/AWS Libfabric/3
26: nid005920:67124:67696 [1] NCCL INFO Channel 07/0 : 101[1] -> 105[1] [receive] via NET/AWS Libfabric/1
10: nid005590:110710:111255 [0] NCCL INFO Channel 03/0 : 40[0] -> 43[3] via P2P/CUMEM
24: nid005918:92504:93095 [0] NCCL INFO Channel 03/0 : 96[0] -> 99[3] via P2P/CUMEM
26: nid005920:67124:67696 [1] NCCL INFO Channel 02/0 : 105[1] -> 109[1] [send] via NET/AWS Libfabric/1
12: nid005594:53087:53637 [2] NCCL INFO Channel 00/0 : 50[2] -> 51[3] via P2P/CUMEM
26: nid005920:67124:67696 [1] NCCL INFO Channel 06/0 : 105[1] -> 109[1] [send] via NET/AWS Libfabric/1
29: nid005932:167680:168242 [0] NCCL INFO Channel 05/0 : 116[0] -> 117[1] via P2P/CUMEM
10: nid005590:110710:111255 [0] NCCL INFO Channel 06/0 : 40[0] -> 43[3] via P2P/CUMEM
16: nid005802:6297:6913 [0] NCCL INFO Channel 02/0 : 64[0] -> 67[3] via P2P/CUMEM
28: nid005929:16031:16585 [1] NCCL INFO Channel 03/0 : 109[1] -> 113[1] [receive] via NET/AWS Libfabric/1
16: nid005802:6299:6914 [2] NCCL INFO Channel 00/0 : 66[2] -> 67[3] via P2P/CUMEM
28: nid005929:16031:16585 [1] NCCL INFO Channel 07/0 : 109[1] -> 113[1] [receive] via NET/AWS Libfabric/1
10: nid005590:110710:111255 [0] NCCL INFO Channel 07/0 : 40[0] -> 43[3] via P2P/CUMEM
28: nid005929:16031:16585 [1] NCCL INFO Channel 02/0 : 113[1] -> 117[1] [send] via NET/AWS Libfabric/1
12: nid005594:53086:53638 [1] NCCL INFO Channel 00/0 : 49[1] -> 50[2] via P2P/CUMEM
21: nid005914:166786:167334 [2] NCCL INFO Channel 01/0 : 86[2] -> 87[3] via P2P/CUMEM
12: nid005594:53087:53637 [2] NCCL INFO Channel 04/0 : 50[2] -> 51[3] via P2P/CUMEM
28: nid005929:16031:16585 [1] NCCL INFO Channel 06/0 : 113[1] -> 117[1] [send] via NET/AWS Libfabric/1
21: nid005914:166785:167333 [1] NCCL INFO Channel 05/0 : 85[1] -> 86[2] via P2P/CUMEM
16: nid005802:6297:6913 [0] NCCL INFO Channel 03/0 : 64[0] -> 67[3] via P2P/CUMEM
 8: nid005586:68926:69499 [0] NCCL INFO Channel 00/0 : 28[0] -> 32[0] [receive] via NET/AWS Libfabric/0
16: nid005802:6299:6914 [2] NCCL INFO Channel 04/0 : 66[2] -> 67[3] via P2P/CUMEM
 3: nid005580:71821:72370 [2] NCCL INFO Channel 03/0 : 10[2] -> 14[2] [receive] via NET/AWS Libfabric/2
 8: nid005586:68926:69499 [0] NCCL INFO Channel 04/0 : 28[0] -> 32[0] [receive] via NET/AWS Libfabric/0
 3: nid005580:71820:72372 [1] NCCL INFO Channel 02/0 : 9[1] -> 13[1] [receive] via NET/AWS Libfabric/1
 8: nid005586:68926:69499 [0] NCCL INFO Channel 01/0 : 32[0] -> 36[0] [send] via NET/AWS Libfabric/0
 3: nid005580:71821:72370 [2] NCCL INFO Channel 07/0 : 10[2] -> 14[2] [receive] via NET/AWS Libfabric/2
 8: nid005586:68926:69499 [0] NCCL INFO Channel 05/0 : 32[0] -> 36[0] [send] via NET/AWS Libfabric/0
 3: nid005580:71820:72372 [1] NCCL INFO Channel 06/0 : 9[1] -> 13[1] [receive] via NET/AWS Libfabric/1
16: nid005802:6297:6913 [0] NCCL INFO Channel 06/0 : 64[0] -> 67[3] via P2P/CUMEM
26: nid005920:67126:67694 [3] NCCL INFO Channel 01/0 : 103[3] -> 107[3] [receive] via NET/AWS Libfabric/3
 3: nid005580:71821:72370 [2] NCCL INFO Channel 02/0 : 14[2] -> 18[2] [send] via NET/AWS Libfabric/2
21: nid005914:166786:167334 [2] NCCL INFO Channel 05/0 : 86[2] -> 87[3] via P2P/CUMEM
12: nid005594:53086:53638 [1] NCCL INFO Channel 04/0 : 49[1] -> 50[2] via P2P/CUMEM
 3: nid005580:71820:72372 [1] NCCL INFO Channel 03/0 : 13[1] -> 17[1] [send] via NET/AWS Libfabric/1
26: nid005920:67123:67693 [0] NCCL INFO Channel 00/0 : 100[0] -> 104[0] [receive] via NET/AWS Libfabric/0
 3: nid005580:71821:72370 [2] NCCL INFO Channel 06/0 : 14[2] -> 18[2] [send] via NET/AWS Libfabric/2
26: nid005920:67126:67694 [3] NCCL INFO Channel 05/0 : 103[3] -> 107[3] [receive] via NET/AWS Libfabric/3
 3: nid005580:71820:72372 [1] NCCL INFO Channel 07/0 : 13[1] -> 17[1] [send] via NET/AWS Libfabric/1
26: nid005920:67123:67693 [0] NCCL INFO Channel 04/0 : 100[0] -> 104[0] [receive] via NET/AWS Libfabric/0
26: nid005920:67126:67694 [3] NCCL INFO Channel 00/0 : 107[3] -> 111[3] [send] via NET/AWS Libfabric/3
16: nid005802:6297:6913 [0] NCCL INFO Channel 07/0 : 64[0] -> 67[3] via P2P/CUMEM
21: nid005914:166784:167332 [0] NCCL INFO Channel 02/0 : 84[0] -> 87[3] via P2P/CUMEM
28: nid005929:16030:16584 [0] NCCL INFO Channel 00/0 : 108[0] -> 112[0] [receive] via NET/AWS Libfabric/0
26: nid005920:67123:67693 [0] NCCL INFO Channel 01/0 : 104[0] -> 108[0] [send] via NET/AWS Libfabric/0
26: nid005920:67126:67694 [3] NCCL INFO Channel 04/0 : 107[3] -> 111[3] [send] via NET/AWS Libfabric/3
28: nid005929:16030:16584 [0] NCCL INFO Channel 04/0 : 108[0] -> 112[0] [receive] via NET/AWS Libfabric/0
29: nid005932:167681:168244 [1] NCCL INFO Channel 01/0 : 117[1] -> 118[2] via P2P/CUMEM
26: nid005920:67123:67693 [0] NCCL INFO Channel 05/0 : 104[0] -> 108[0] [send] via NET/AWS Libfabric/0
29: nid005932:167682:168243 [2] NCCL INFO Channel 01/0 : 118[2] -> 119[3] via P2P/CUMEM
21: nid005914:166784:167332 [0] NCCL INFO Channel 03/0 : 84[0] -> 87[3] via P2P/CUMEM
 5: nid005582:196715:197402 [2] NCCL INFO Channel 03/0 : 18[2] -> 22[2] [receive] via NET/AWS Libfabric/2
28: nid005929:16030:16584 [0] NCCL INFO Channel 01/0 : 112[0] -> 116[0] [send] via NET/AWS Libfabric/0
 5: nid005582:196714:197403 [1] NCCL INFO Channel 02/0 : 17[1] -> 21[1] [receive] via NET/AWS Libfabric/1
28: nid005929:16030:16584 [0] NCCL INFO Channel 05/0 : 112[0] -> 116[0] [send] via NET/AWS Libfabric/0
12: nid005594:53085:53636 [0] NCCL INFO Channel 02/0 : 48[0] -> 51[3] via P2P/CUMEM
21: nid005914:166784:167332 [0] NCCL INFO Channel 06/0 : 84[0] -> 87[3] via P2P/CUMEM
 5: nid005582:196715:197402 [2] NCCL INFO Channel 07/0 : 18[2] -> 22[2] [receive] via NET/AWS Libfabric/2
 5: nid005582:196714:197403 [1] NCCL INFO Channel 06/0 : 17[1] -> 21[1] [receive] via NET/AWS Libfabric/1
 5: nid005582:196714:197403 [1] NCCL INFO Channel 03/0 : 21[1] -> 25[1] [send] via NET/AWS Libfabric/1
 5: nid005582:196715:197402 [2] NCCL INFO Channel 02/0 : 22[2] -> 26[2] [send] via NET/AWS Libfabric/2
29: nid005932:167681:168244 [1] NCCL INFO Channel 05/0 : 117[1] -> 118[2] via P2P/CUMEM
12: nid005594:53085:53636 [0] NCCL INFO Channel 03/0 : 48[0] -> 51[3] via P2P/CUMEM
29: nid005932:167682:168243 [2] NCCL INFO Channel 05/0 : 118[2] -> 119[3] via P2P/CUMEM
21: nid005914:166784:167332 [0] NCCL INFO Channel 07/0 : 84[0] -> 87[3] via P2P/CUMEM
 5: nid005582:196714:197403 [1] NCCL INFO Channel 07/0 : 21[1] -> 25[1] [send] via NET/AWS Libfabric/1
 5: nid005582:196715:197402 [2] NCCL INFO Channel 06/0 : 22[2] -> 26[2] [send] via NET/AWS Libfabric/2
20: nid005913:292682:293234 [1] NCCL INFO Channel 03/0 : 77[1] -> 81[1] [receive] via NET/AWS Libfabric/1
10: nid005590:110712:111257 [2] NCCL INFO Channel 02/0 : 38[2] -> 42[2] [receive] via NET/AWS Libfabric/2
 4: nid005581:264525:265077 [2] NCCL INFO Channel 02/0 : 18[2] -> 16[0] via P2P/CUMEM
15: nid005601:210677:211246 [1] NCCL INFO Channel 02/0 : 57[1] -> 61[1] [receive] via NET/AWS Libfabric/1
20: nid005913:292682:293234 [1] NCCL INFO Channel 07/0 : 77[1] -> 81[1] [receive] via NET/AWS Libfabric/1
28: nid005929:16033:16586 [3] NCCL INFO Channel 01/0 : 111[3] -> 115[3] [receive] via NET/AWS Libfabric/3
12: nid005594:53085:53636 [0] NCCL INFO Channel 06/0 : 48[0] -> 51[3] via P2P/CUMEM
10: nid005590:110712:111257 [2] NCCL INFO Channel 06/0 : 38[2] -> 42[2] [receive] via NET/AWS Libfabric/2
20: nid005913:292682:293234 [1] NCCL INFO Channel 02/0 : 81[1] -> 85[1] [send] via NET/AWS Libfabric/1
15: nid005601:210677:211246 [1] NCCL INFO Channel 06/0 : 57[1] -> 61[1] [receive] via NET/AWS Libfabric/1
 3: nid005580:71819:72369 [0] NCCL INFO Channel 01/0 : 8[0] -> 12[0] [receive] via NET/AWS Libfabric/0
28: nid005929:16033:16586 [3] NCCL INFO Channel 05/0 : 111[3] -> 115[3] [receive] via NET/AWS Libfabric/3
 3: nid005580:71822:72371 [3] NCCL INFO Channel 00/0 : 11[3] -> 15[3] [receive] via NET/AWS Libfabric/3
10: nid005590:110712:111257 [2] NCCL INFO Channel 03/0 : 42[2] -> 46[2] [send] via NET/AWS Libfabric/2
28: nid005929:16033:16586 [3] NCCL INFO Channel 00/0 : 115[3] -> 119[3] [send] via NET/AWS Libfabric/3
15: nid005601:210677:211246 [1] NCCL INFO Channel 03/0 : 61[1] -> 65[1] [send] via NET/AWS Libfabric/1
20: nid005913:292682:293234 [1] NCCL INFO Channel 06/0 : 81[1] -> 85[1] [send] via NET/AWS Libfabric/1
29: nid005932:167680:168242 [0] NCCL INFO Channel 02/0 : 116[0] -> 119[3] via P2P/CUMEM
10: nid005590:110712:111257 [2] NCCL INFO Channel 07/0 : 42[2] -> 46[2] [send] via NET/AWS Libfabric/2
15: nid005601:210677:211246 [1] NCCL INFO Channel 07/0 : 61[1] -> 65[1] [send] via NET/AWS Libfabric/1
 3: nid005580:71822:72371 [3] NCCL INFO Channel 04/0 : 11[3] -> 15[3] [receive] via NET/AWS Libfabric/3
 0: nid005574:69059:69643 [1] NCCL INFO Channel 03/0 : 125[1] -> 1[1] [receive] via NET/AWS Libfabric/1
28: nid005929:16033:16586 [3] NCCL INFO Channel 04/0 : 115[3] -> 119[3] [send] via NET/AWS Libfabric/3
 3: nid005580:71819:72369 [0] NCCL INFO Channel 05/0 : 8[0] -> 12[0] [receive] via NET/AWS Libfabric/0
12: nid005594:53085:53636 [0] NCCL INFO Channel 07/0 : 48[0] -> 51[3] via P2P/CUMEM
 3: nid005580:71822:72371 [3] NCCL INFO Channel 01/0 : 15[3] -> 19[3] [send] via NET/AWS Libfabric/3
15: nid005601:210678:211248 [2] NCCL INFO Channel 03/0 : 58[2] -> 62[2] [receive] via NET/AWS Libfabric/2
 0: nid005574:69059:69643 [1] NCCL INFO Channel 07/0 : 125[1] -> 1[1] [receive] via NET/AWS Libfabric/1
14: nid005600:217722:218279 [2] NCCL INFO Channel 02/0 : 54[2] -> 58[2] [receive] via NET/AWS Libfabric/2
 4: nid005581:264525:265077 [2] NCCL INFO Channel 06/0 : 18[2] -> 16[0] via P2P/CUMEM
 5: nid005582:196716:197406 [3] NCCL INFO Channel 00/0 : 19[3] -> 23[3] [receive] via NET/AWS Libfabric/3
 3: nid005580:71822:72371 [3] NCCL INFO Channel 05/0 : 15[3] -> 19[3] [send] via NET/AWS Libfabric/3
 0: nid005574:69059:69643 [1] NCCL INFO Channel 02/0 : 1[1] -> 5[1] [send] via NET/AWS Libfabric/1
15: nid005601:210678:211248 [2] NCCL INFO Channel 07/0 : 58[2] -> 62[2] [receive] via NET/AWS Libfabric/2
 5: nid005582:196716:197406 [3] NCCL INFO Channel 04/0 : 19[3] -> 23[3] [receive] via NET/AWS Libfabric/3
14: nid005600:217722:218279 [2] NCCL INFO Channel 06/0 : 54[2] -> 58[2] [receive] via NET/AWS Libfabric/2
29: nid005932:167680:168242 [0] NCCL INFO Channel 03/0 : 116[0] -> 119[3] via P2P/CUMEM
 0: nid005574:69059:69643 [1] NCCL INFO Channel 06/0 : 1[1] -> 5[1] [send] via NET/AWS Libfabric/1
27: nid005922:80743:81299 [2] NCCL INFO Channel 03/0 : 106[2] -> 110[2] [receive] via NET/AWS Libfabric/2
 5: nid005582:196716:197406 [3] NCCL INFO Channel 01/0 : 23[3] -> 27[3] [send] via NET/AWS Libfabric/3
14: nid005600:217722:218279 [2] NCCL INFO Channel 03/0 : 58[2] -> 62[2] [send] via NET/AWS Libfabric/2
20: nid005913:292683:293236 [2] NCCL INFO Channel 02/0 : 78[2] -> 82[2] [receive] via NET/AWS Libfabric/2
15: nid005601:210678:211248 [2] NCCL INFO Channel 02/0 : 62[2] -> 66[2] [send] via NET/AWS Libfabric/2
15: nid005601:210678:211248 [2] NCCL INFO Channel 06/0 : 62[2] -> 66[2] [send] via NET/AWS Libfabric/2
27: nid005922:80743:81299 [2] NCCL INFO Channel 07/0 : 106[2] -> 110[2] [receive] via NET/AWS Libfabric/2
 5: nid005582:196716:197406 [3] NCCL INFO Channel 05/0 : 23[3] -> 27[3] [send] via NET/AWS Libfabric/3
14: nid005600:217722:218279 [2] NCCL INFO Channel 07/0 : 58[2] -> 62[2] [send] via NET/AWS Libfabric/2
 1: nid005576:147558:148112 [1] NCCL INFO Channel 02/0 : 1[1] -> 5[1] [receive] via NET/AWS Libfabric/1
 3: nid005580:71819:72369 [0] NCCL INFO Channel 00/0 : 12[0] -> 16[0] [send] via NET/AWS Libfabric/0
 0: nid005574:69060:69645 [2] NCCL INFO Channel 02/0 : 126[2] -> 2[2] [receive] via NET/AWS Libfabric/2
20: nid005913:292683:293236 [2] NCCL INFO Channel 06/0 : 78[2] -> 82[2] [receive] via NET/AWS Libfabric/2
27: nid005922:80743:81299 [2] NCCL INFO Channel 02/0 : 110[2] -> 114[2] [send] via NET/AWS Libfabric/2
27: nid005922:80742:81301 [1] NCCL INFO Channel 02/0 : 105[1] -> 109[1] [receive] via NET/AWS Libfabric/1
 1: nid005576:147558:148112 [1] NCCL INFO Channel 06/0 : 1[1] -> 5[1] [receive] via NET/AWS Libfabric/1
20: nid005913:292683:293236 [2] NCCL INFO Channel 03/0 : 82[2] -> 86[2] [send] via NET/AWS Libfabric/2
 4: nid005581:264526:265079 [3] NCCL INFO Channel 02/0 : 19[3] -> 17[1] via P2P/CUMEM
27: nid005922:80743:81299 [2] NCCL INFO Channel 06/0 : 110[2] -> 114[2] [send] via NET/AWS Libfabric/2
 0: nid005574:69060:69645 [2] NCCL INFO Channel 06/0 : 126[2] -> 2[2] [receive] via NET/AWS Libfabric/2
14: nid005600:217721:218278 [1] NCCL INFO Channel 03/0 : 53[1] -> 57[1] [receive] via NET/AWS Libfabric/1
20: nid005913:292683:293236 [2] NCCL INFO Channel 07/0 : 82[2] -> 86[2] [send] via NET/AWS Libfabric/2
27: nid005922:80742:81301 [1] NCCL INFO Channel 06/0 : 105[1] -> 109[1] [receive] via NET/AWS Libfabric/1
 1: nid005576:147558:148112 [1] NCCL INFO Channel 03/0 : 5[1] -> 9[1] [send] via NET/AWS Libfabric/1
 3: nid005580:71819:72369 [0] NCCL INFO Channel 04/0 : 12[0] -> 16[0] [send] via NET/AWS Libfabric/0
 0: nid005574:69060:69645 [2] NCCL INFO Channel 03/0 : 2[2] -> 6[2] [send] via NET/AWS Libfabric/2
14: nid005600:217721:218278 [1] NCCL INFO Channel 07/0 : 53[1] -> 57[1] [receive] via NET/AWS Libfabric/1
29: nid005932:167680:168242 [0] NCCL INFO Channel 06/0 : 116[0] -> 119[3] via P2P/CUMEM
 1: nid005576:147558:148112 [1] NCCL INFO Channel 07/0 : 5[1] -> 9[1] [send] via NET/AWS Libfabric/1
11: nid005591:191605:192157 [2] NCCL INFO Channel 03/0 : 42[2] -> 46[2] [receive] via NET/AWS Libfabric/2
27: nid005922:80742:81301 [1] NCCL INFO Channel 03/0 : 109[1] -> 113[1] [send] via NET/AWS Libfabric/1
 0: nid005574:69060:69645 [2] NCCL INFO Channel 07/0 : 2[2] -> 6[2] [send] via NET/AWS Libfabric/2
14: nid005600:217721:218278 [1] NCCL INFO Channel 02/0 : 57[1] -> 61[1] [send] via NET/AWS Libfabric/1
27: nid005922:80742:81301 [1] NCCL INFO Channel 07/0 : 109[1] -> 113[1] [send] via NET/AWS Libfabric/1
14: nid005600:217721:218278 [1] NCCL INFO Channel 06/0 : 57[1] -> 61[1] [send] via NET/AWS Libfabric/1
11: nid005591:191605:192157 [2] NCCL INFO Channel 07/0 : 42[2] -> 46[2] [receive] via NET/AWS Libfabric/2
27: nid005922:80743:81299 [2] NCCL INFO Channel 03/0 : 110[2] -> 108[0] via P2P/CUMEM
11: nid005591:191605:192157 [2] NCCL INFO Channel 02/0 : 46[2] -> 50[2] [send] via NET/AWS Libfabric/2
 4: nid005581:264526:265079 [3] NCCL INFO Channel 06/0 : 19[3] -> 17[1] via P2P/CUMEM
 1: nid005576:147559:148115 [2] NCCL INFO Channel 03/0 : 2[2] -> 6[2] [receive] via NET/AWS Libfabric/2
 7: nid005585:122007:122558 [2] NCCL INFO Channel 03/0 : 26[2] -> 30[2] [receive] via NET/AWS Libfabric/2
 9: nid005588:35936:36508 [1] NCCL INFO Channel 02/0 : 33[1] -> 37[1] [receive] via NET/AWS Libfabric/1
 6: nid005584:28286:28832 [1] NCCL INFO Channel 03/0 : 21[1] -> 25[1] [receive] via NET/AWS Libfabric/1
 5: nid005582:196713:197404 [0] NCCL INFO Channel 01/0 : 16[0] -> 20[0] [receive] via NET/AWS Libfabric/0
11: nid005591:191605:192157 [2] NCCL INFO Channel 06/0 : 46[2] -> 50[2] [send] via NET/AWS Libfabric/2
29: nid005932:167680:168242 [0] NCCL INFO Channel 07/0 : 116[0] -> 119[3] via P2P/CUMEM
 9: nid005588:35937:36509 [2] NCCL INFO Channel 03/0 : 34[2] -> 38[2] [receive] via NET/AWS Libfabric/2
 5: nid005582:196713:197404 [0] NCCL INFO Channel 05/0 : 16[0] -> 20[0] [receive] via NET/AWS Libfabric/0
 1: nid005576:147559:148115 [2] NCCL INFO Channel 07/0 : 2[2] -> 6[2] [receive] via NET/AWS Libfabric/2
 7: nid005585:122007:122558 [2] NCCL INFO Channel 07/0 : 26[2] -> 30[2] [receive] via NET/AWS Libfabric/2
 9: nid005588:35936:36508 [1] NCCL INFO Channel 06/0 : 33[1] -> 37[1] [receive] via NET/AWS Libfabric/1
 6: nid005584:28286:28832 [1] NCCL INFO Channel 07/0 : 21[1] -> 25[1] [receive] via NET/AWS Libfabric/1
 5: nid005582:196713:197404 [0] NCCL INFO Channel 00/0 : 20[0] -> 24[0] [send] via NET/AWS Libfabric/0
 1: nid005576:147559:148115 [2] NCCL INFO Channel 02/0 : 6[2] -> 10[2] [send] via NET/AWS Libfabric/2
 7: nid005585:122007:122558 [2] NCCL INFO Channel 02/0 : 30[2] -> 34[2] [send] via NET/AWS Libfabric/2
22: nid005915:274816:275369 [2] NCCL INFO Channel 02/0 : 86[2] -> 90[2] [receive] via NET/AWS Libfabric/2
 9: nid005588:35937:36509 [2] NCCL INFO Channel 07/0 : 34[2] -> 38[2] [receive] via NET/AWS Libfabric/2
30: nid005936:49910:50483 [2] NCCL INFO Channel 02/0 : 118[2] -> 122[2] [receive] via NET/AWS Libfabric/2
27: nid005922:80743:81299 [2] NCCL INFO Channel 07/0 : 110[2] -> 108[0] via P2P/CUMEM
 6: nid005584:28286:28832 [1] NCCL INFO Channel 02/0 : 25[1] -> 29[1] [send] via NET/AWS Libfabric/1
 1: nid005576:147559:148115 [2] NCCL INFO Channel 06/0 : 6[2] -> 10[2] [send] via NET/AWS Libfabric/2
 9: nid005588:35936:36508 [1] NCCL INFO Channel 03/0 : 37[1] -> 41[1] [send] via NET/AWS Libfabric/1
 7: nid005585:122007:122558 [2] NCCL INFO Channel 06/0 : 30[2] -> 34[2] [send] via NET/AWS Libfabric/2
 5: nid005582:196713:197404 [0] NCCL INFO Channel 04/0 : 20[0] -> 24[0] [send] via NET/AWS Libfabric/0
23: nid005917:276886:277439 [1] NCCL INFO Channel 02/0 : 89[1] -> 93[1] [receive] via NET/AWS Libfabric/1
 6: nid005584:28286:28832 [1] NCCL INFO Channel 06/0 : 25[1] -> 29[1] [send] via NET/AWS Libfabric/1
11: nid005591:191604:192159 [1] NCCL INFO Channel 02/0 : 41[1] -> 45[1] [receive] via NET/AWS Libfabric/1
 9: nid005588:35937:36509 [2] NCCL INFO Channel 02/0 : 38[2] -> 42[2] [send] via NET/AWS Libfabric/2
15: nid005601:210676:211245 [0] NCCL INFO Channel 01/0 : 56[0] -> 60[0] [receive] via NET/AWS Libfabric/0
30: nid005936:49909:50480 [1] NCCL INFO Channel 03/0 : 117[1] -> 121[1] [receive] via NET/AWS Libfabric/1
30: nid005936:49910:50483 [2] NCCL INFO Channel 06/0 : 118[2] -> 122[2] [receive] via NET/AWS Libfabric/2
22: nid005915:274816:275369 [2] NCCL INFO Channel 06/0 : 86[2] -> 90[2] [receive] via NET/AWS Libfabric/2
 4: nid005581:264526:265079 [3] NCCL INFO Channel 01/0 : 19[3] -> 18[2] via P2P/CUMEM
 9: nid005588:35936:36508 [1] NCCL INFO Channel 07/0 : 37[1] -> 41[1] [send] via NET/AWS Libfabric/1
 6: nid005584:28287:28835 [2] NCCL INFO Channel 02/0 : 22[2] -> 26[2] [receive] via NET/AWS Libfabric/2
23: nid005917:276886:277439 [1] NCCL INFO Channel 06/0 : 89[1] -> 93[1] [receive] via NET/AWS Libfabric/1
11: nid005591:191604:192159 [1] NCCL INFO Channel 06/0 : 41[1] -> 45[1] [receive] via NET/AWS Libfabric/1
22: nid005915:274816:275369 [2] NCCL INFO Channel 03/0 : 90[2] -> 94[2] [send] via NET/AWS Libfabric/2
 9: nid005588:35937:36509 [2] NCCL INFO Channel 06/0 : 38[2] -> 42[2] [send] via NET/AWS Libfabric/2
15: nid005601:210676:211245 [0] NCCL INFO Channel 05/0 : 56[0] -> 60[0] [receive] via NET/AWS Libfabric/0
30: nid005936:49910:50483 [2] NCCL INFO Channel 03/0 : 122[2] -> 126[2] [send] via NET/AWS Libfabric/2
 0: nid005574:69060:69645 [2] NCCL INFO Channel 02/0 : 2[2] -> 0[0] via P2P/CUMEM
23: nid005917:276887:277438 [2] NCCL INFO Channel 03/0 : 90[2] -> 94[2] [receive] via NET/AWS Libfabric/2
30: nid005936:49909:50480 [1] NCCL INFO Channel 07/0 : 117[1] -> 121[1] [receive] via NET/AWS Libfabric/1
22: nid005915:274816:275369 [2] NCCL INFO Channel 07/0 : 90[2] -> 94[2] [send] via NET/AWS Libfabric/2
15: nid005601:210679:211247 [3] NCCL INFO Channel 00/0 : 59[3] -> 63[3] [receive] via NET/AWS Libfabric/3
23: nid005917:276886:277439 [1] NCCL INFO Channel 03/0 : 93[1] -> 97[1] [send] via NET/AWS Libfabric/1
 6: nid005584:28287:28835 [2] NCCL INFO Channel 06/0 : 22[2] -> 26[2] [receive] via NET/AWS Libfabric/2
15: nid005601:210676:211245 [0] NCCL INFO Channel 00/0 : 60[0] -> 64[0] [send] via NET/AWS Libfabric/0
17: nid005803:180734:181301 [2] NCCL INFO Channel 05/0 : 70[2] -> 71[3] via P2P/CUMEM
30: nid005936:49910:50483 [2] NCCL INFO Channel 07/0 : 122[2] -> 126[2] [send] via NET/AWS Libfabric/2
11: nid005591:191604:192159 [1] NCCL INFO Channel 03/0 : 45[1] -> 49[1] [send] via NET/AWS Libfabric/1
30: nid005936:49909:50480 [1] NCCL INFO Channel 02/0 : 121[1] -> 125[1] [send] via NET/AWS Libfabric/1
11: nid005591:191604:192159 [1] NCCL INFO Channel 07/0 : 45[1] -> 49[1] [send] via NET/AWS Libfabric/1
15: nid005601:210679:211247 [3] NCCL INFO Channel 04/0 : 59[3] -> 63[3] [receive] via NET/AWS Libfabric/3
23: nid005917:276886:277439 [1] NCCL INFO Channel 07/0 : 93[1] -> 97[1] [send] via NET/AWS Libfabric/1
23: nid005917:276887:277438 [2] NCCL INFO Channel 07/0 : 90[2] -> 94[2] [receive] via NET/AWS Libfabric/2
 6: nid005584:28287:28835 [2] NCCL INFO Channel 03/0 : 26[2] -> 30[2] [send] via NET/AWS Libfabric/2
15: nid005601:210676:211245 [0] NCCL INFO Channel 04/0 : 60[0] -> 64[0] [send] via NET/AWS Libfabric/0
30: nid005936:49909:50480 [1] NCCL INFO Channel 06/0 : 121[1] -> 125[1] [send] via NET/AWS Libfabric/1
 7: nid005585:122006:122557 [1] NCCL INFO Channel 02/0 : 25[1] -> 29[1] [receive] via NET/AWS Libfabric/1
18: nid005911:38866:39436 [2] NCCL INFO Channel 04/0 : 74[2] -> 75[3] via P2P/CUMEM
18: nid005911:38866:39436 [2] NCCL INFO Channel 02/0 : 70[2] -> 74[2] [receive] via NET/AWS Libfabric/2
 8: nid005586:68928:69502 [2] NCCL INFO Channel 02/0 : 34[2] -> 32[0] via P2P/CUMEM
 6: nid005584:28287:28835 [2] NCCL INFO Channel 07/0 : 26[2] -> 30[2] [send] via NET/AWS Libfabric/2
15: nid005601:210679:211247 [3] NCCL INFO Channel 01/0 : 63[3] -> 67[3] [send] via NET/AWS Libfabric/3
18: nid005911:38866:39436 [2] NCCL INFO Channel 06/0 : 70[2] -> 74[2] [receive] via NET/AWS Libfabric/2
25: nid005919:107463:108041 [1] NCCL INFO Channel 02/0 : 97[1] -> 101[1] [receive] via NET/AWS Libfabric/1
23: nid005917:276887:277438 [2] NCCL INFO Channel 02/0 : 94[2] -> 98[2] [send] via NET/AWS Libfabric/2
18: nid005911:38866:39436 [2] NCCL INFO Channel 03/0 : 74[2] -> 78[2] [send] via NET/AWS Libfabric/2
 0: nid005574:69061:69644 [3] NCCL INFO Channel 01/0 : 127[3] -> 3[3] [receive] via NET/AWS Libfabric/3
18: nid005911:38866:39436 [2] NCCL INFO Channel 07/0 : 74[2] -> 78[2] [send] via NET/AWS Libfabric/2
11: nid005591:191606:192158 [3] NCCL INFO Channel 00/0 : 43[3] -> 47[3] [receive] via NET/AWS Libfabric/3
15: nid005601:210679:211247 [3] NCCL INFO Channel 05/0 : 63[3] -> 67[3] [send] via NET/AWS Libfabric/3
23: nid005917:276887:277438 [2] NCCL INFO Channel 06/0 : 94[2] -> 98[2] [send] via NET/AWS Libfabric/2
10: nid005590:110712:111257 [2] NCCL INFO Channel 02/0 : 42[2] -> 40[0] via P2P/CUMEM
 9: nid005588:35937:36509 [2] NCCL INFO Channel 03/0 : 38[2] -> 36[0] via P2P/CUMEM
 7: nid005585:122006:122557 [1] NCCL INFO Channel 06/0 : 25[1] -> 29[1] [receive] via NET/AWS Libfabric/1
25: nid005919:107463:108041 [1] NCCL INFO Channel 06/0 : 97[1] -> 101[1] [receive] via NET/AWS Libfabric/1
22: nid005915:274815:275371 [1] NCCL INFO Channel 03/0 : 85[1] -> 89[1] [receive] via NET/AWS Libfabric/1
31: nid005937:256591:257162 [2] NCCL INFO Channel 03/0 : 126[2] -> 124[0] via P2P/CUMEM
 0: nid005574:69060:69645 [2] NCCL INFO Channel 06/0 : 2[2] -> 0[0] via P2P/CUMEM
 4: nid005581:264526:265079 [3] NCCL INFO Channel 03/0 : 19[3] -> 18[2] via P2P/CUMEM
 7: nid005585:122006:122557 [1] NCCL INFO Channel 03/0 : 29[1] -> 33[1] [send] via NET/AWS Libfabric/1
 5: nid005582:196715:197402 [2] NCCL INFO Channel 03/0 : 22[2] -> 20[0] via P2P/CUMEM
11: nid005591:191606:192158 [3] NCCL INFO Channel 04/0 : 43[3] -> 47[3] [receive] via NET/AWS Libfabric/3
 0: nid005574:69058:69646 [0] NCCL INFO Channel 00/0 : 124[0] -> 0[0] [receive] via NET/AWS Libfabric/0
19: nid005912:12436:13008 [1] NCCL INFO Channel 02/0 : 73[1] -> 77[1] [receive] via NET/AWS Libfabric/1
25: nid005919:107463:108041 [1] NCCL INFO Channel 03/0 : 101[1] -> 105[1] [send] via NET/AWS Libfabric/1
22: nid005915:274815:275371 [1] NCCL INFO Channel 07/0 : 85[1] -> 89[1] [receive] via NET/AWS Libfabric/1
 0: nid005574:69061:69644 [3] NCCL INFO Channel 05/0 : 127[3] -> 3[3] [receive] via NET/AWS Libfabric/3
11: nid005591:191606:192158 [3] NCCL INFO Channel 01/0 : 47[3] -> 51[3] [send] via NET/AWS Libfabric/3
 9: nid005588:35938:36511 [3] NCCL INFO Channel 00/0 : 35[3] -> 39[3] [receive] via NET/AWS Libfabric/3
 7: nid005585:122006:122557 [1] NCCL INFO Channel 07/0 : 29[1] -> 33[1] [send] via NET/AWS Libfabric/1
27: nid005922:80741:81298 [0] NCCL INFO Channel 01/0 : 104[0] -> 108[0] [receive] via NET/AWS Libfabric/0
 0: nid005574:69058:69646 [0] NCCL INFO Channel 04/0 : 124[0] -> 0[0] [receive] via NET/AWS Libfabric/0
 9: nid005588:35935:36510 [0] NCCL INFO Channel 01/0 : 32[0] -> 36[0] [receive] via NET/AWS Libfabric/0
 7: nid005585:122007:122558 [2] NCCL INFO Channel 03/0 : 30[2] -> 28[0] via P2P/CUMEM
19: nid005912:12436:13008 [1] NCCL INFO Channel 06/0 : 73[1] -> 77[1] [receive] via NET/AWS Libfabric/1
25: nid005919:107463:108041 [1] NCCL INFO Channel 07/0 : 101[1] -> 105[1] [send] via NET/AWS Libfabric/1
22: nid005915:274815:275371 [1] NCCL INFO Channel 02/0 : 89[1] -> 93[1] [send] via NET/AWS Libfabric/1
 0: nid005574:69061:69644 [3] NCCL INFO Channel 00/0 : 3[3] -> 7[3] [send] via NET/AWS Libfabric/3
17: nid005803:180732:181300 [0] NCCL INFO Channel 05/0 : 68[0] -> 69[1] via P2P/CUMEM
 8: nid005586:68928:69502 [2] NCCL INFO Channel 06/0 : 34[2] -> 32[0] via P2P/CUMEM
 6: nid005584:28287:28835 [2] NCCL INFO Channel 02/0 : 26[2] -> 24[0] via P2P/CUMEM
11: nid005591:191606:192158 [3] NCCL INFO Channel 05/0 : 47[3] -> 51[3] [send] via NET/AWS Libfabric/3
 0: nid005574:69058:69646 [0] NCCL INFO Channel 01/0 : 0[0] -> 4[0] [send] via NET/AWS Libfabric/0
 1: nid005576:147560:148114 [3] NCCL INFO Channel 00/0 : 3[3] -> 7[3] [receive] via NET/AWS Libfabric/3
 9: nid005588:35938:36511 [3] NCCL INFO Channel 04/0 : 35[3] -> 39[3] [receive] via NET/AWS Libfabric/3
19: nid005912:12436:13008 [1] NCCL INFO Channel 03/0 : 77[1] -> 81[1] [send] via NET/AWS Libfabric/1
22: nid005915:274815:275371 [1] NCCL INFO Channel 06/0 : 89[1] -> 93[1] [send] via NET/AWS Libfabric/1
 0: nid005574:69061:69644 [3] NCCL INFO Channel 04/0 : 3[3] -> 7[3] [send] via NET/AWS Libfabric/3
10: nid005590:110712:111257 [2] NCCL INFO Channel 06/0 : 42[2] -> 40[0] via P2P/CUMEM
 9: nid005588:35937:36509 [2] NCCL INFO Channel 07/0 : 38[2] -> 36[0] via P2P/CUMEM
27: nid005922:80741:81298 [0] NCCL INFO Channel 05/0 : 104[0] -> 108[0] [receive] via NET/AWS Libfabric/0
 0: nid005574:69058:69646 [0] NCCL INFO Channel 05/0 : 0[0] -> 4[0] [send] via NET/AWS Libfabric/0
 9: nid005588:35938:36511 [3] NCCL INFO Channel 01/0 : 39[3] -> 43[3] [send] via NET/AWS Libfabric/3
19: nid005912:12436:13008 [1] NCCL INFO Channel 07/0 : 77[1] -> 81[1] [send] via NET/AWS Libfabric/1
 1: nid005576:147560:148114 [3] NCCL INFO Channel 04/0 : 3[3] -> 7[3] [receive] via NET/AWS Libfabric/3
27: nid005922:80741:81298 [0] NCCL INFO Channel 00/0 : 108[0] -> 112[0] [send] via NET/AWS Libfabric/0
19: nid005912:12437:13007 [2] NCCL INFO Channel 03/0 : 74[2] -> 78[2] [receive] via NET/AWS Libfabric/2
 9: nid005588:35935:36510 [0] NCCL INFO Channel 05/0 : 32[0] -> 36[0] [receive] via NET/AWS Libfabric/0
11: nid005591:191603:192156 [0] NCCL INFO Channel 01/0 : 40[0] -> 44[0] [receive] via NET/AWS Libfabric/0
 1: nid005576:147560:148114 [3] NCCL INFO Channel 01/0 : 7[3] -> 11[3] [send] via NET/AWS Libfabric/3
 9: nid005588:35938:36511 [3] NCCL INFO Channel 05/0 : 39[3] -> 43[3] [send] via NET/AWS Libfabric/3
27: nid005922:80741:81298 [0] NCCL INFO Channel 04/0 : 108[0] -> 112[0] [send] via NET/AWS Libfabric/0
 4: nid005581:264524:265080 [1] NCCL INFO Channel 01/0 : 17[1] -> 16[0] via P2P/CUMEM
 7: nid005585:122007:122558 [2] NCCL INFO Channel 07/0 : 30[2] -> 28[0] via P2P/CUMEM
19: nid005912:12437:13007 [2] NCCL INFO Channel 07/0 : 74[2] -> 78[2] [receive] via NET/AWS Libfabric/2
 1: nid005576:147560:148114 [3] NCCL INFO Channel 05/0 : 7[3] -> 11[3] [send] via NET/AWS Libfabric/3
 1: nid005576:147557:148113 [0] NCCL INFO Channel 01/0 : 0[0] -> 4[0] [receive] via NET/AWS Libfabric/0
 4: nid005581:264526:265079 [3] NCCL INFO Channel 05/0 : 19[3] -> 18[2] via P2P/CUMEM
27: nid005922:80744:81300 [3] NCCL INFO Channel 00/0 : 107[3] -> 111[3] [receive] via NET/AWS Libfabric/3
11: nid005591:191603:192156 [0] NCCL INFO Channel 05/0 : 40[0] -> 44[0] [receive] via NET/AWS Libfabric/0
 5: nid005582:196715:197402 [2] NCCL INFO Channel 07/0 : 22[2] -> 20[0] via P2P/CUMEM
14: nid005600:217720:218280 [0] NCCL INFO Channel 00/0 : 52[0] -> 56[0] [receive] via NET/AWS Libfabric/0
19: nid005912:12437:13007 [2] NCCL INFO Channel 02/0 : 78[2] -> 82[2] [send] via NET/AWS Libfabric/2
14: nid005600:217723:218281 [3] NCCL INFO Channel 01/0 : 55[3] -> 59[3] [receive] via NET/AWS Libfabric/3
17: nid005803:180734:181301 [2] NCCL INFO Channel 03/0 : 66[2] -> 70[2] [receive] via NET/AWS Libfabric/2
17: nid005803:180732:181300 [0] NCCL INFO Channel 02/0 : 68[0] -> 71[3] via P2P/CUMEM
18: nid005911:38864:39434 [0] NCCL INFO Channel 04/0 : 72[0] -> 73[1] via P2P/CUMEM
27: nid005922:80744:81300 [3] NCCL INFO Channel 04/0 : 107[3] -> 111[3] [receive] via NET/AWS Libfabric/3
13: nid005595:197884:198486 [1] NCCL INFO Channel 02/0 : 49[1] -> 53[1] [receive] via NET/AWS Libfabric/1
 6: nid005584:28287:28835 [2] NCCL INFO Channel 06/0 : 26[2] -> 24[0] via P2P/CUMEM
 9: nid005588:35935:36510 [0] NCCL INFO Channel 00/0 : 36[0] -> 40[0] [send] via NET/AWS Libfabric/0
13: nid005595:197885:198487 [2] NCCL INFO Channel 03/0 : 50[2] -> 54[2] [receive] via NET/AWS Libfabric/2
25: nid005919:107464:108040 [2] NCCL INFO Channel 03/0 : 98[2] -> 102[2] [receive] via NET/AWS Libfabric/2
14: nid005600:217720:218280 [0] NCCL INFO Channel 04/0 : 52[0] -> 56[0] [receive] via NET/AWS Libfabric/0
11: nid005591:191603:192156 [0] NCCL INFO Channel 00/0 : 44[0] -> 48[0] [send] via NET/AWS Libfabric/0
13: nid005595:197884:198486 [1] NCCL INFO Channel 06/0 : 49[1] -> 53[1] [receive] via NET/AWS Libfabric/1
19: nid005912:12437:13007 [2] NCCL INFO Channel 06/0 : 78[2] -> 82[2] [send] via NET/AWS Libfabric/2
14: nid005600:217723:218281 [3] NCCL INFO Channel 05/0 : 55[3] -> 59[3] [receive] via NET/AWS Libfabric/3
31: nid005937:256591:257162 [2] NCCL INFO Channel 07/0 : 126[2] -> 124[0] via P2P/CUMEM
14: nid005600:217720:218280 [0] NCCL INFO Channel 01/0 : 56[0] -> 60[0] [send] via NET/AWS Libfabric/0
 4: nid005581:264524:265080 [1] NCCL INFO Channel 03/0 : 17[1] -> 16[0] via P2P/CUMEM
17: nid005803:180734:181301 [2] NCCL INFO Channel 07/0 : 66[2] -> 70[2] [receive] via NET/AWS Libfabric/2
27: nid005922:80744:81300 [3] NCCL INFO Channel 01/0 : 111[3] -> 115[3] [send] via NET/AWS Libfabric/3
 4: nid005581:264526:265079 [3] NCCL INFO Channel 07/0 : 19[3] -> 18[2] via P2P/CUMEM
 9: nid005588:35935:36510 [0] NCCL INFO Channel 04/0 : 36[0] -> 40[0] [send] via NET/AWS Libfabric/0
17: nid005803:180734:181301 [2] NCCL INFO Channel 02/0 : 70[2] -> 74[2] [send] via NET/AWS Libfabric/2
13: nid005595:197885:198487 [2] NCCL INFO Channel 07/0 : 50[2] -> 54[2] [receive] via NET/AWS Libfabric/2
27: nid005922:80744:81300 [3] NCCL INFO Channel 05/0 : 111[3] -> 115[3] [send] via NET/AWS Libfabric/3
14: nid005600:217723:218281 [3] NCCL INFO Channel 00/0 : 59[3] -> 63[3] [send] via NET/AWS Libfabric/3
11: nid005591:191603:192156 [0] NCCL INFO Channel 04/0 : 44[0] -> 48[0] [send] via NET/AWS Libfabric/0
 7: nid005585:122005:122556 [0] NCCL INFO Channel 01/0 : 24[0] -> 28[0] [receive] via NET/AWS Libfabric/0
13: nid005595:197884:198486 [1] NCCL INFO Channel 03/0 : 53[1] -> 57[1] [send] via NET/AWS Libfabric/1
25: nid005919:107464:108040 [2] NCCL INFO Channel 07/0 : 98[2] -> 102[2] [receive] via NET/AWS Libfabric/2
14: nid005600:217720:218280 [0] NCCL INFO Channel 05/0 : 56[0] -> 60[0] [send] via NET/AWS Libfabric/0
 0: nid005574:69061:69644 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM
 1: nid005576:147557:148113 [0] NCCL INFO Channel 05/0 : 0[0] -> 4[0] [receive] via NET/AWS Libfabric/0
13: nid005595:197885:198487 [2] NCCL INFO Channel 02/0 : 54[2] -> 58[2] [send] via NET/AWS Libfabric/2
25: nid005919:107464:108040 [2] NCCL INFO Channel 02/0 : 102[2] -> 106[2] [send] via NET/AWS Libfabric/2
14: nid005600:217723:218281 [3] NCCL INFO Channel 04/0 : 59[3] -> 63[3] [send] via NET/AWS Libfabric/3
17: nid005803:180732:181300 [0] NCCL INFO Channel 03/0 : 68[0] -> 71[3] via P2P/CUMEM
13: nid005595:197884:198486 [1] NCCL INFO Channel 07/0 : 53[1] -> 57[1] [send] via NET/AWS Libfabric/1
25: nid005919:107464:108040 [2] NCCL INFO Channel 06/0 : 102[2] -> 106[2] [send] via NET/AWS Libfabric/2
17: nid005803:180734:181301 [2] NCCL INFO Channel 06/0 : 70[2] -> 74[2] [send] via NET/AWS Libfabric/2
13: nid005595:197885:198487 [2] NCCL INFO Channel 06/0 : 54[2] -> 58[2] [send] via NET/AWS Libfabric/2
22: nid005915:274814:275370 [0] NCCL INFO Channel 00/0 : 84[0] -> 88[0] [receive] via NET/AWS Libfabric/0
 7: nid005585:122005:122556 [0] NCCL INFO Channel 05/0 : 24[0] -> 28[0] [receive] via NET/AWS Libfabric/0
19: nid005912:12437:13007 [2] NCCL INFO Channel 03/0 : 78[2] -> 76[0] via P2P/CUMEM
22: nid005915:274817:275368 [3] NCCL INFO Channel 01/0 : 87[3] -> 91[3] [receive] via NET/AWS Libfabric/3
 1: nid005576:147557:148113 [0] NCCL INFO Channel 00/0 : 4[0] -> 8[0] [send] via NET/AWS Libfabric/0
 7: nid005585:122005:122556 [0] NCCL INFO Channel 00/0 : 28[0] -> 32[0] [send] via NET/AWS Libfabric/0
30: nid005936:49911:50481 [3] NCCL INFO Channel 01/0 : 119[3] -> 123[3] [receive] via NET/AWS Libfabric/3
24: nid005918:92506:93093 [2] NCCL INFO Channel 02/0 : 94[2] -> 98[2] [receive] via NET/AWS Libfabric/2
 1: nid005576:147557:148113 [0] NCCL INFO Channel 04/0 : 4[0] -> 8[0] [send] via NET/AWS Libfabric/0
18: nid005911:38864:39434 [0] NCCL INFO Channel 02/0 : 72[0] -> 75[3] via P2P/CUMEM
27: nid005922:80744:81300 [3] NCCL INFO Channel 03/0 : 111[3] -> 109[1] via P2P/CUMEM
22: nid005915:274817:275368 [3] NCCL INFO Channel 05/0 : 87[3] -> 91[3] [receive] via NET/AWS Libfabric/3
22: nid005915:274814:275370 [0] NCCL INFO Channel 04/0 : 84[0] -> 88[0] [receive] via NET/AWS Libfabric/0
 6: nid005584:28285:28834 [0] NCCL INFO Channel 00/0 : 20[0] -> 24[0] [receive] via NET/AWS Libfabric/0
 7: nid005585:122005:122556 [0] NCCL INFO Channel 04/0 : 28[0] -> 32[0] [send] via NET/AWS Libfabric/0
22: nid005915:274817:275368 [3] NCCL INFO Channel 00/0 : 91[3] -> 95[3] [send] via NET/AWS Libfabric/3
18: nid005911:38866:39436 [2] NCCL INFO Channel 02/0 : 74[2] -> 72[0] via P2P/CUMEM
30: nid005936:49911:50481 [3] NCCL INFO Channel 05/0 : 119[3] -> 123[3] [receive] via NET/AWS Libfabric/3
 6: nid005584:28288:28833 [3] NCCL INFO Channel 01/0 : 23[3] -> 27[3] [receive] via NET/AWS Libfabric/3
 2: nid005577:17424:17997 [2] NCCL INFO Channel 02/0 : 6[2] -> 10[2] [receive] via NET/AWS Libfabric/2
 2: nid005577:17423:17995 [1] NCCL INFO Channel 03/0 : 5[1] -> 9[1] [receive] via NET/AWS Libfabric/1
 6: nid005584:28285:28834 [0] NCCL INFO Channel 04/0 : 20[0] -> 24[0] [receive] via NET/AWS Libfabric/0
14: nid005600:217722:218279 [2] NCCL INFO Channel 02/0 : 58[2] -> 56[0] via P2P/CUMEM
 0: nid005574:69061:69644 [3] NCCL INFO Channel 06/0 : 3[3] -> 1[1] via P2P/CUMEM
23: nid005917:276885:277440 [0] NCCL INFO Channel 01/0 : 88[0] -> 92[0] [receive] via NET/AWS Libfabric/0
23: nid005917:276888:277437 [3] NCCL INFO Channel 00/0 : 91[3] -> 95[3] [receive] via NET/AWS Libfabric/3
22: nid005915:274814:275370 [0] NCCL INFO Channel 01/0 : 88[0] -> 92[0] [send] via NET/AWS Libfabric/0
17: nid005803:180732:181300 [0] NCCL INFO Channel 06/0 : 68[0] -> 71[3] via P2P/CUMEM
30: nid005936:49911:50481 [3] NCCL INFO Channel 00/0 : 123[3] -> 127[3] [send] via NET/AWS Libfabric/3
 6: nid005584:28288:28833 [3] NCCL INFO Channel 05/0 : 23[3] -> 27[3] [receive] via NET/AWS Libfabric/3
22: nid005915:274817:275368 [3] NCCL INFO Channel 04/0 : 91[3] -> 95[3] [send] via NET/AWS Libfabric/3
19: nid005912:12437:13007 [2] NCCL INFO Channel 07/0 : 78[2] -> 76[0] via P2P/CUMEM
30: nid005936:49911:50481 [3] NCCL INFO Channel 04/0 : 123[3] -> 127[3] [send] via NET/AWS Libfabric/3
 6: nid005584:28285:28834 [0] NCCL INFO Channel 01/0 : 24[0] -> 28[0] [send] via NET/AWS Libfabric/0
10: nid005590:110711:111258 [1] NCCL INFO Channel 03/0 : 37[1] -> 41[1] [receive] via NET/AWS Libfabric/1
 6: nid005584:28288:28833 [3] NCCL INFO Channel 00/0 : 27[3] -> 31[3] [send] via NET/AWS Libfabric/3
 2: nid005577:17424:17997 [2] NCCL INFO Channel 06/0 : 6[2] -> 10[2] [receive] via NET/AWS Libfabric/2
 2: nid005577:17423:17995 [1] NCCL INFO Channel 07/0 : 5[1] -> 9[1] [receive] via NET/AWS Libfabric/1
23: nid005917:276888:277437 [3] NCCL INFO Channel 04/0 : 91[3] -> 95[3] [receive] via NET/AWS Libfabric/3
 6: nid005584:28285:28834 [0] NCCL INFO Channel 05/0 : 24[0] -> 28[0] [send] via NET/AWS Libfabric/0
17: nid005803:180732:181300 [0] NCCL INFO Channel 07/0 : 68[0] -> 71[3] via P2P/CUMEM
 4: nid005581:264524:265080 [1] NCCL INFO Channel 05/0 : 17[1] -> 16[0] via P2P/CUMEM
23: nid005917:276885:277440 [0] NCCL INFO Channel 05/0 : 88[0] -> 92[0] [receive] via NET/AWS Libfabric/0
27: nid005922:80744:81300 [3] NCCL INFO Channel 07/0 : 111[3] -> 109[1] via P2P/CUMEM
22: nid005915:274814:275370 [0] NCCL INFO Channel 05/0 : 88[0] -> 92[0] [send] via NET/AWS Libfabric/0
10: nid005590:110711:111258 [1] NCCL INFO Channel 07/0 : 37[1] -> 41[1] [receive] via NET/AWS Libfabric/1
 2: nid005577:17424:17997 [2] NCCL INFO Channel 03/0 : 10[2] -> 14[2] [send] via NET/AWS Libfabric/2
23: nid005917:276885:277440 [0] NCCL INFO Channel 00/0 : 92[0] -> 96[0] [send] via NET/AWS Libfabric/0
30: nid005936:49908:50482 [0] NCCL INFO Channel 00/0 : 116[0] -> 120[0] [receive] via NET/AWS Libfabric/0
 6: nid005584:28288:28833 [3] NCCL INFO Channel 04/0 : 27[3] -> 31[3] [send] via NET/AWS Libfabric/3
10: nid005590:110711:111258 [1] NCCL INFO Channel 02/0 : 41[1] -> 45[1] [send] via NET/AWS Libfabric/1
 2: nid005577:17423:17995 [1] NCCL INFO Channel 02/0 : 9[1] -> 13[1] [send] via NET/AWS Libfabric/1
 2: nid005577:17424:17997 [2] NCCL INFO Channel 07/0 : 10[2] -> 14[2] [send] via NET/AWS Libfabric/2
23: nid005917:276888:277437 [3] NCCL INFO Channel 01/0 : 95[3] -> 99[3] [send] via NET/AWS Libfabric/3
 2: nid005577:17423:17995 [1] NCCL INFO Channel 06/0 : 9[1] -> 13[1] [send] via NET/AWS Libfabric/1
18: nid005911:38866:39436 [2] NCCL INFO Channel 06/0 : 74[2] -> 72[0] via P2P/CUMEM
18: nid005911:38864:39434 [0] NCCL INFO Channel 03/0 : 72[0] -> 75[3] via P2P/CUMEM
23: nid005917:276885:277440 [0] NCCL INFO Channel 04/0 : 92[0] -> 96[0] [send] via NET/AWS Libfabric/0
10: nid005590:110711:111258 [1] NCCL INFO Channel 06/0 : 41[1] -> 45[1] [send] via NET/AWS Libfabric/1
23: nid005917:276888:277437 [3] NCCL INFO Channel 05/0 : 95[3] -> 99[3] [send] via NET/AWS Libfabric/3
19: nid005912:12438:13006 [3] NCCL INFO Channel 00/0 : 75[3] -> 79[3] [receive] via NET/AWS Libfabric/3
31: nid005937:256592:257159 [3] NCCL INFO Channel 03/0 : 127[3] -> 125[1] via P2P/CUMEM
 5: nid005582:196716:197406 [3] NCCL INFO Channel 03/0 : 23[3] -> 21[1] via P2P/CUMEM
 0: nid005574:69061:69644 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM
 1: nid005576:147559:148115 [2] NCCL INFO Channel 03/0 : 6[2] -> 4[0] via P2P/CUMEM
14: nid005600:217722:218279 [2] NCCL INFO Channel 06/0 : 58[2] -> 56[0] via P2P/CUMEM
24: nid005918:92506:93093 [2] NCCL INFO Channel 06/0 : 94[2] -> 98[2] [receive] via NET/AWS Libfabric/2
19: nid005912:12435:13009 [0] NCCL INFO Channel 01/0 : 72[0] -> 76[0] [receive] via NET/AWS Libfabric/0
19: nid005912:12438:13006 [3] NCCL INFO Channel 04/0 : 75[3] -> 79[3] [receive] via NET/AWS Libfabric/3
24: nid005918:92506:93093 [2] NCCL INFO Channel 03/0 : 98[2] -> 102[2] [send] via NET/AWS Libfabric/2
30: nid005936:49908:50482 [0] NCCL INFO Channel 04/0 : 116[0] -> 120[0] [receive] via NET/AWS Libfabric/0
24: nid005918:92506:93093 [2] NCCL INFO Channel 07/0 : 98[2] -> 102[2] [send] via NET/AWS Libfabric/2
 2: nid005577:17425:17998 [3] NCCL INFO Channel 01/0 : 7[3] -> 11[3] [receive] via NET/AWS Libfabric/3
24: nid005918:92505:93094 [1] NCCL INFO Channel 03/0 : 93[1] -> 97[1] [receive] via NET/AWS Libfabric/1
 2: nid005577:17424:17997 [2] NCCL INFO Channel 02/0 : 10[2] -> 8[0] via P2P/CUMEM
24: nid005918:92505:93094 [1] NCCL INFO Channel 07/0 : 93[1] -> 97[1] [receive] via NET/AWS Libfabric/1
30: nid005936:49908:50482 [0] NCCL INFO Channel 01/0 : 120[0] -> 124[0] [send] via NET/AWS Libfabric/0
24: nid005918:92505:93094 [1] NCCL INFO Channel 02/0 : 97[1] -> 101[1] [send] via NET/AWS Libfabric/1
24: nid005918:92505:93094 [1] NCCL INFO Channel 06/0 : 97[1] -> 101[1] [send] via NET/AWS Libfabric/1
16: nid005802:6298:6912 [1] NCCL INFO Channel 03/0 : 61[1] -> 65[1] [receive] via NET/AWS Libfabric/1
 3: nid005580:71821:72370 [2] NCCL INFO Channel 03/0 : 14[2] -> 12[0] via P2P/CUMEM
 2: nid005577:17425:17998 [3] NCCL INFO Channel 05/0 : 7[3] -> 11[3] [receive] via NET/AWS Libfabric/3
19: nid005912:12438:13006 [3] NCCL INFO Channel 01/0 : 79[3] -> 83[3] [send] via NET/AWS Libfabric/3
18: nid005911:38864:39434 [0] NCCL INFO Channel 06/0 : 72[0] -> 75[3] via P2P/CUMEM
19: nid005912:12435:13009 [0] NCCL INFO Channel 05/0 : 72[0] -> 76[0] [receive] via NET/AWS Libfabric/0
 4: nid005581:264524:265080 [1] NCCL INFO Channel 07/0 : 17[1] -> 16[0] via P2P/CUMEM
16: nid005802:6298:6912 [1] NCCL INFO Channel 07/0 : 61[1] -> 65[1] [receive] via NET/AWS Libfabric/1
31: nid005937:256592:257159 [3] NCCL INFO Channel 07/0 : 127[3] -> 125[1] via P2P/CUMEM
20: nid005913:292684:293235 [3] NCCL INFO Channel 01/0 : 79[3] -> 83[3] [receive] via NET/AWS Libfabric/3
19: nid005912:12438:13006 [3] NCCL INFO Channel 05/0 : 79[3] -> 83[3] [send] via NET/AWS Libfabric/3
 2: nid005577:17425:17998 [3] NCCL INFO Channel 00/0 : 11[3] -> 15[3] [send] via NET/AWS Libfabric/3
30: nid005936:49908:50482 [0] NCCL INFO Channel 05/0 : 120[0] -> 124[0] [send] via NET/AWS Libfabric/0
23: nid005917:276887:277438 [2] NCCL INFO Channel 03/0 : 94[2] -> 92[0] via P2P/CUMEM
16: nid005802:6298:6912 [1] NCCL INFO Channel 02/0 : 65[1] -> 69[1] [send] via NET/AWS Libfabric/1
 5: nid005582:196716:197406 [3] NCCL INFO Channel 07/0 : 23[3] -> 21[1] via P2P/CUMEM
19: nid005912:12435:13009 [0] NCCL INFO Channel 00/0 : 76[0] -> 80[0] [send] via NET/AWS Libfabric/0
 2: nid005577:17425:17998 [3] NCCL INFO Channel 04/0 : 11[3] -> 15[3] [send] via NET/AWS Libfabric/3
20: nid005913:292684:293235 [3] NCCL INFO Channel 05/0 : 79[3] -> 83[3] [receive] via NET/AWS Libfabric/3
18: nid005911:38864:39434 [0] NCCL INFO Channel 07/0 : 72[0] -> 75[3] via P2P/CUMEM
27: nid005922:80744:81300 [3] NCCL INFO Channel 00/0 : 111[3] -> 110[2] via P2P/CUMEM
16: nid005802:6298:6912 [1] NCCL INFO Channel 06/0 : 65[1] -> 69[1] [send] via NET/AWS Libfabric/1
19: nid005912:12435:13009 [0] NCCL INFO Channel 04/0 : 76[0] -> 80[0] [send] via NET/AWS Libfabric/0
20: nid005913:292681:293237 [0] NCCL INFO Channel 00/0 : 76[0] -> 80[0] [receive] via NET/AWS Libfabric/0
24: nid005918:92506:93093 [2] NCCL INFO Channel 02/0 : 98[2] -> 96[0] via P2P/CUMEM
20: nid005913:292684:293235 [3] NCCL INFO Channel 00/0 : 83[3] -> 87[3] [send] via NET/AWS Libfabric/3
25: nid005919:107465:108039 [3] NCCL INFO Channel 00/0 : 99[3] -> 103[3] [receive] via NET/AWS Libfabric/3
 0: nid005574:69061:69644 [3] NCCL INFO Channel 03/0 : 3[3] -> 2[2] via P2P/CUMEM
16: nid005802:6299:6914 [2] NCCL INFO Channel 02/0 : 62[2] -> 66[2] [receive] via NET/AWS Libfabric/2
13: nid005595:197886:198488 [3] NCCL INFO Channel 00/0 : 51[3] -> 55[3] [receive] via NET/AWS Libfabric/3
 1: nid005576:147559:148115 [2] NCCL INFO Channel 07/0 : 6[2] -> 4[0] via P2P/CUMEM
 1: nid005576:147560:148114 [3] NCCL INFO Channel 03/0 : 7[3] -> 5[1] via P2P/CUMEM
13: nid005595:197883:198485 [0] NCCL INFO Channel 01/0 : 48[0] -> 52[0] [receive] via NET/AWS Libfabric/0
20: nid005913:292684:293235 [3] NCCL INFO Channel 04/0 : 83[3] -> 87[3] [send] via NET/AWS Libfabric/3
25: nid005919:107465:108039 [3] NCCL INFO Channel 04/0 : 99[3] -> 103[3] [receive] via NET/AWS Libfabric/3
25: nid005919:107464:108040 [2] NCCL INFO Channel 03/0 : 102[2] -> 100[0] via P2P/CUMEM
 7: nid005585:122008:122559 [3] NCCL INFO Channel 00/0 : 27[3] -> 31[3] [receive] via NET/AWS Libfabric/3
31: nid005937:256592:257159 [3] NCCL INFO Channel 00/0 : 127[3] -> 126[2] via P2P/CUMEM
26: nid005920:67125:67695 [2] NCCL INFO Channel 02/0 : 106[2] -> 104[0] via P2P/CUMEM
10: nid005590:110713:111256 [3] NCCL INFO Channel 01/0 : 39[3] -> 43[3] [receive] via NET/AWS Libfabric/3
 2: nid005577:17425:17998 [3] NCCL INFO Channel 02/0 : 11[3] -> 9[1] via P2P/CUMEM
 2: nid005577:17424:17997 [2] NCCL INFO Channel 06/0 : 10[2] -> 8[0] via P2P/CUMEM
16: nid005802:6299:6914 [2] NCCL INFO Channel 06/0 : 62[2] -> 66[2] [receive] via NET/AWS Libfabric/2
13: nid005595:197886:198488 [3] NCCL INFO Channel 04/0 : 51[3] -> 55[3] [receive] via NET/AWS Libfabric/3
 3: nid005580:71822:72371 [3] NCCL INFO Channel 03/0 : 15[3] -> 13[1] via P2P/CUMEM
24: nid005918:92504:93095 [0] NCCL INFO Channel 06/0 : 96[0] -> 99[3] via P2P/CUMEM
 3: nid005580:71821:72370 [2] NCCL INFO Channel 07/0 : 14[2] -> 12[0] via P2P/CUMEM
25: nid005919:107465:108039 [3] NCCL INFO Channel 01/0 : 103[3] -> 107[3] [send] via NET/AWS Libfabric/3
 7: nid005585:122008:122559 [3] NCCL INFO Channel 04/0 : 27[3] -> 31[3] [receive] via NET/AWS Libfabric/3
13: nid005595:197886:198488 [3] NCCL INFO Channel 01/0 : 55[3] -> 59[3] [send] via NET/AWS Libfabric/3
16: nid005802:6299:6914 [2] NCCL INFO Channel 03/0 : 66[2] -> 70[2] [send] via NET/AWS Libfabric/2
21: nid005914:166785:167333 [1] NCCL INFO Channel 02/0 : 81[1] -> 85[1] [receive] via NET/AWS Libfabric/1
10: nid005590:110713:111256 [3] NCCL INFO Channel 05/0 : 39[3] -> 43[3] [receive] via NET/AWS Libfabric/3
13: nid005595:197883:198485 [0] NCCL INFO Channel 05/0 : 48[0] -> 52[0] [receive] via NET/AWS Libfabric/0
25: nid005919:107465:108039 [3] NCCL INFO Channel 05/0 : 103[3] -> 107[3] [send] via NET/AWS Libfabric/3
10: nid005590:110710:111255 [0] NCCL INFO Channel 00/0 : 36[0] -> 40[0] [receive] via NET/AWS Libfabric/0
16: nid005802:6299:6914 [2] NCCL INFO Channel 07/0 : 66[2] -> 70[2] [send] via NET/AWS Libfabric/2
 7: nid005585:122008:122559 [3] NCCL INFO Channel 01/0 : 31[3] -> 35[3] [send] via NET/AWS Libfabric/3
10: nid005590:110713:111256 [3] NCCL INFO Channel 00/0 : 43[3] -> 47[3] [send] via NET/AWS Libfabric/3
13: nid005595:197886:198488 [3] NCCL INFO Channel 05/0 : 55[3] -> 59[3] [send] via NET/AWS Libfabric/3
 5: nid005582:196716:197406 [3] NCCL INFO Channel 00/0 : 23[3] -> 22[2] via P2P/CUMEM
21: nid005914:166785:167333 [1] NCCL INFO Channel 06/0 : 81[1] -> 85[1] [receive] via NET/AWS Libfabric/1
23: nid005917:276887:277438 [2] NCCL INFO Channel 07/0 : 94[2] -> 92[0] via P2P/CUMEM
10: nid005590:110713:111256 [3] NCCL INFO Channel 04/0 : 43[3] -> 47[3] [send] via NET/AWS Libfabric/3
 7: nid005585:122008:122559 [3] NCCL INFO Channel 05/0 : 31[3] -> 35[3] [send] via NET/AWS Libfabric/3
 2: nid005577:17422:17996 [0] NCCL INFO Channel 00/0 : 4[0] -> 8[0] [receive] via NET/AWS Libfabric/0
20: nid005913:292681:293237 [0] NCCL INFO Channel 04/0 : 76[0] -> 80[0] [receive] via NET/AWS Libfabric/0
21: nid005914:166785:167333 [1] NCCL INFO Channel 03/0 : 85[1] -> 89[1] [send] via NET/AWS Libfabric/1
10: nid005590:110710:111255 [0] NCCL INFO Channel 04/0 : 36[0] -> 40[0] [receive] via NET/AWS Libfabric/0
15: nid005601:210678:211248 [2] NCCL INFO Channel 03/0 : 62[2] -> 60[0] via P2P/CUMEM
12: nid005594:53087:53637 [2] NCCL INFO Channel 02/0 : 46[2] -> 50[2] [receive] via NET/AWS Libfabric/2
21: nid005914:166785:167333 [1] NCCL INFO Channel 07/0 : 85[1] -> 89[1] [send] via NET/AWS Libfabric/1
27: nid005922:80744:81300 [3] NCCL INFO Channel 02/0 : 111[3] -> 110[2] via P2P/CUMEM
 2: nid005577:17422:17996 [0] NCCL INFO Channel 04/0 : 4[0] -> 8[0] [receive] via NET/AWS Libfabric/0
 4: nid005581:264525:265077 [2] NCCL INFO Channel 01/0 : 18[2] -> 17[1] via P2P/CUMEM
21: nid005914:166786:167334 [2] NCCL INFO Channel 03/0 : 82[2] -> 86[2] [receive] via NET/AWS Libfabric/2
20: nid005913:292681:293237 [0] NCCL INFO Channel 01/0 : 80[0] -> 84[0] [send] via NET/AWS Libfabric/0
26: nid005920:67126:67694 [3] NCCL INFO Channel 02/0 : 107[3] -> 105[1] via P2P/CUMEM
24: nid005918:92506:93093 [2] NCCL INFO Channel 06/0 : 98[2] -> 96[0] via P2P/CUMEM
 9: nid005588:35938:36511 [3] NCCL INFO Channel 03/0 : 39[3] -> 37[1] via P2P/CUMEM
 6: nid005584:28288:28833 [3] NCCL INFO Channel 02/0 : 27[3] -> 25[1] via P2P/CUMEM
12: nid005594:53087:53637 [2] NCCL INFO Channel 06/0 : 46[2] -> 50[2] [receive] via NET/AWS Libfabric/2
 2: nid005577:17422:17996 [0] NCCL INFO Channel 01/0 : 8[0] -> 12[0] [send] via NET/AWS Libfabric/0
16: nid005802:6299:6914 [2] NCCL INFO Channel 02/0 : 66[2] -> 64[0] via P2P/CUMEM
17: nid005803:180734:181301 [2] NCCL INFO Channel 03/0 : 70[2] -> 68[0] via P2P/CUMEM
26: nid005920:67125:67695 [2] NCCL INFO Channel 06/0 : 106[2] -> 104[0] via P2P/CUMEM
14: nid005600:217723:218281 [3] NCCL INFO Channel 02/0 : 59[3] -> 57[1] via P2P/CUMEM
 0: nid005574:69059:69643 [1] NCCL INFO Channel 01/0 : 1[1] -> 0[0] via P2P/CUMEM
12: nid005594:53087:53637 [2] NCCL INFO Channel 03/0 : 50[2] -> 54[2] [send] via NET/AWS Libfabric/2
 2: nid005577:17422:17996 [0] NCCL INFO Channel 05/0 : 8[0] -> 12[0] [send] via NET/AWS Libfabric/0
 7: nid005585:122008:122559 [3] NCCL INFO Channel 03/0 : 31[3] -> 29[1] via P2P/CUMEM
21: nid005914:166786:167334 [2] NCCL INFO Channel 07/0 : 82[2] -> 86[2] [receive] via NET/AWS Libfabric/2
25: nid005919:107464:108040 [2] NCCL INFO Channel 07/0 : 102[2] -> 100[0] via P2P/CUMEM
 8: nid005586:68929:69500 [3] NCCL INFO Channel 02/0 : 35[3] -> 33[1] via P2P/CUMEM
31: nid005937:256592:257159 [3] NCCL INFO Channel 02/0 : 127[3] -> 126[2] via P2P/CUMEM
 0: nid005574:69061:69644 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM
10: nid005590:110713:111256 [3] NCCL INFO Channel 02/0 : 43[3] -> 41[1] via P2P/CUMEM
 1: nid005576:147560:148114 [3] NCCL INFO Channel 07/0 : 7[3] -> 5[1] via P2P/CUMEM
 4: nid005581:264525:265077 [2] NCCL INFO Channel 05/0 : 18[2] -> 17[1] via P2P/CUMEM
13: nid005595:197883:198485 [0] NCCL INFO Channel 00/0 : 52[0] -> 56[0] [send] via NET/AWS Libfabric/0
21: nid005914:166786:167334 [2] NCCL INFO Channel 02/0 : 86[2] -> 90[2] [send] via NET/AWS Libfabric/2
12: nid005594:53087:53637 [2] NCCL INFO Channel 07/0 : 50[2] -> 54[2] [send] via NET/AWS Libfabric/2
10: nid005590:110710:111255 [0] NCCL INFO Channel 01/0 : 40[0] -> 44[0] [send] via NET/AWS Libfabric/0
 2: nid005577:17425:17998 [3] NCCL INFO Channel 06/0 : 11[3] -> 9[1] via P2P/CUMEM
13: nid005595:197883:198485 [0] NCCL INFO Channel 04/0 : 52[0] -> 56[0] [send] via NET/AWS Libfabric/0
20: nid005913:292681:293237 [0] NCCL INFO Channel 05/0 : 80[0] -> 84[0] [send] via NET/AWS Libfabric/0
 3: nid005580:71822:72371 [3] NCCL INFO Channel 07/0 : 15[3] -> 13[1] via P2P/CUMEM
21: nid005914:166786:167334 [2] NCCL INFO Channel 06/0 : 86[2] -> 90[2] [send] via NET/AWS Libfabric/2
15: nid005601:210678:211248 [2] NCCL INFO Channel 07/0 : 62[2] -> 60[0] via P2P/CUMEM
10: nid005590:110710:111255 [0] NCCL INFO Channel 05/0 : 40[0] -> 44[0] [send] via NET/AWS Libfabric/0
14: nid005600:217723:218281 [3] NCCL INFO Channel 06/0 : 59[3] -> 57[1] via P2P/CUMEM
17: nid005803:180734:181301 [2] NCCL INFO Channel 07/0 : 70[2] -> 68[0] via P2P/CUMEM
21: nid005914:166784:167332 [0] NCCL INFO Channel 01/0 : 80[0] -> 84[0] [receive] via NET/AWS Libfabric/0
16: nid005802:6299:6914 [2] NCCL INFO Channel 06/0 : 66[2] -> 64[0] via P2P/CUMEM
 9: nid005588:35938:36511 [3] NCCL INFO Channel 07/0 : 39[3] -> 37[1] via P2P/CUMEM
11: nid005591:191605:192157 [2] NCCL INFO Channel 03/0 : 46[2] -> 44[0] via P2P/CUMEM
24: nid005918:92504:93095 [0] NCCL INFO Channel 07/0 : 96[0] -> 99[3] via P2P/CUMEM
31: nid005937:256592:257159 [3] NCCL INFO Channel 04/0 : 127[3] -> 126[2] via P2P/CUMEM
21: nid005914:166784:167332 [0] NCCL INFO Channel 05/0 : 80[0] -> 84[0] [receive] via NET/AWS Libfabric/0
20: nid005913:292683:293236 [2] NCCL INFO Channel 02/0 : 82[2] -> 80[0] via P2P/CUMEM
27: nid005922:80744:81300 [3] NCCL INFO Channel 04/0 : 111[3] -> 110[2] via P2P/CUMEM
12: nid005594:53087:53637 [2] NCCL INFO Channel 02/0 : 50[2] -> 48[0] via P2P/CUMEM
10: nid005590:110713:111256 [3] NCCL INFO Channel 06/0 : 43[3] -> 41[1] via P2P/CUMEM
 1: nid005576:147560:148114 [3] NCCL INFO Channel 00/0 : 7[3] -> 6[2] via P2P/CUMEM
 5: nid005582:196716:197406 [3] NCCL INFO Channel 02/0 : 23[3] -> 22[2] via P2P/CUMEM
13: nid005595:197885:198487 [2] NCCL INFO Channel 03/0 : 54[2] -> 52[0] via P2P/CUMEM
21: nid005914:166784:167332 [0] NCCL INFO Channel 00/0 : 84[0] -> 88[0] [send] via NET/AWS Libfabric/0
 6: nid005584:28288:28833 [3] NCCL INFO Channel 06/0 : 27[3] -> 25[1] via P2P/CUMEM
25: nid005919:107462:108038 [0] NCCL INFO Channel 01/0 : 96[0] -> 100[0] [receive] via NET/AWS Libfabric/0
22: nid005915:274816:275369 [2] NCCL INFO Channel 02/0 : 90[2] -> 88[0] via P2P/CUMEM
31: nid005937:256590:257161 [1] NCCL INFO Channel 00/0 : 125[1] -> 124[0] via P2P/CUMEM
21: nid005914:166786:167334 [2] NCCL INFO Channel 03/0 : 86[2] -> 84[0] via P2P/CUMEM
 3: nid005580:71822:72371 [3] NCCL INFO Channel 00/0 : 15[3] -> 14[2] via P2P/CUMEM
21: nid005914:166784:167332 [0] NCCL INFO Channel 04/0 : 84[0] -> 88[0] [send] via NET/AWS Libfabric/0
21: nid005914:166787:167335 [3] NCCL INFO Channel 00/0 : 83[3] -> 87[3] [receive] via NET/AWS Libfabric/3
12: nid005594:53086:53638 [1] NCCL INFO Channel 03/0 : 45[1] -> 49[1] [receive] via NET/AWS Libfabric/1
26: nid005920:67126:67694 [3] NCCL INFO Channel 06/0 : 107[3] -> 105[1] via P2P/CUMEM
 2: nid005577:17425:17998 [3] NCCL INFO Channel 01/0 : 11[3] -> 10[2] via P2P/CUMEM
 8: nid005586:68929:69500 [3] NCCL INFO Channel 06/0 : 35[3] -> 33[1] via P2P/CUMEM
14: nid005600:217723:218281 [3] NCCL INFO Channel 01/0 : 59[3] -> 58[2] via P2P/CUMEM
11: nid005591:191605:192157 [2] NCCL INFO Channel 07/0 : 46[2] -> 44[0] via P2P/CUMEM
 9: nid005588:35938:36511 [3] NCCL INFO Channel 00/0 : 39[3] -> 38[2] via P2P/CUMEM
 7: nid005585:122008:122559 [3] NCCL INFO Channel 07/0 : 31[3] -> 29[1] via P2P/CUMEM
21: nid005914:166787:167335 [3] NCCL INFO Channel 04/0 : 83[3] -> 87[3] [receive] via NET/AWS Libfabric/3
 0: nid005574:69059:69643 [1] NCCL INFO Channel 03/0 : 1[1] -> 0[0] via P2P/CUMEM
25: nid005919:107462:108038 [0] NCCL INFO Channel 05/0 : 96[0] -> 100[0] [receive] via NET/AWS Libfabric/0
12: nid005594:53086:53638 [1] NCCL INFO Channel 07/0 : 45[1] -> 49[1] [receive] via NET/AWS Libfabric/1
16: nid005802:6297:6913 [0] NCCL INFO Channel 00/0 : 60[0] -> 64[0] [receive] via NET/AWS Libfabric/0
21: nid005914:166787:167335 [3] NCCL INFO Channel 01/0 : 87[3] -> 91[3] [send] via NET/AWS Libfabric/3
 0: nid005574:69061:69644 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM
12: nid005594:53087:53637 [2] NCCL INFO Channel 06/0 : 50[2] -> 48[0] via P2P/CUMEM
27: nid005922:80743:81299 [2] NCCL INFO Channel 00/0 : 110[2] -> 109[1] via P2P/CUMEM
25: nid005919:107462:108038 [0] NCCL INFO Channel 00/0 : 100[0] -> 104[0] [send] via NET/AWS Libfabric/0
31: nid005937:256592:257159 [3] NCCL INFO Channel 06/0 : 127[3] -> 126[2] via P2P/CUMEM
13: nid005595:197885:198487 [2] NCCL INFO Channel 07/0 : 54[2] -> 52[0] via P2P/CUMEM
21: nid005914:166787:167335 [3] NCCL INFO Channel 05/0 : 87[3] -> 91[3] [send] via NET/AWS Libfabric/3
31: nid005937:256590:257161 [1] NCCL INFO Channel 02/0 : 125[1] -> 124[0] via P2P/CUMEM
12: nid005594:53086:53638 [1] NCCL INFO Channel 02/0 : 49[1] -> 53[1] [send] via NET/AWS Libfabric/1
10: nid005590:110713:111256 [3] NCCL INFO Channel 01/0 : 43[3] -> 42[2] via P2P/CUMEM
16: nid005802:6297:6913 [0] NCCL INFO Channel 04/0 : 60[0] -> 64[0] [receive] via NET/AWS Libfabric/0
20: nid005913:292683:293236 [2] NCCL INFO Channel 06/0 : 82[2] -> 80[0] via P2P/CUMEM
27: nid005922:80744:81300 [3] NCCL INFO Channel 06/0 : 111[3] -> 110[2] via P2P/CUMEM
 8: nid005586:68928:69502 [2] NCCL INFO Channel 01/0 : 34[2] -> 33[1] via P2P/CUMEM
12: nid005594:53086:53638 [1] NCCL INFO Channel 06/0 : 49[1] -> 53[1] [send] via NET/AWS Libfabric/1
16: nid005802:6300:6915 [3] NCCL INFO Channel 01/0 : 63[3] -> 67[3] [receive] via NET/AWS Libfabric/3
 1: nid005576:147560:148114 [3] NCCL INFO Channel 02/0 : 7[3] -> 6[2] via P2P/CUMEM
16: nid005802:6297:6913 [0] NCCL INFO Channel 01/0 : 64[0] -> 68[0] [send] via NET/AWS Libfabric/0
25: nid005919:107462:108038 [0] NCCL INFO Channel 04/0 : 100[0] -> 104[0] [send] via NET/AWS Libfabric/0
21: nid005914:166786:167334 [2] NCCL INFO Channel 07/0 : 86[2] -> 84[0] via P2P/CUMEM
16: nid005802:6300:6915 [3] NCCL INFO Channel 05/0 : 63[3] -> 67[3] [receive] via NET/AWS Libfabric/3
26: nid005920:67126:67694 [3] NCCL INFO Channel 01/0 : 107[3] -> 106[2] via P2P/CUMEM
20: nid005913:292684:293235 [3] NCCL INFO Channel 02/0 : 83[3] -> 81[1] via P2P/CUMEM
16: nid005802:6300:6915 [3] NCCL INFO Channel 00/0 : 67[3] -> 71[3] [send] via NET/AWS Libfabric/3
 5: nid005582:196714:197403 [1] NCCL INFO Channel 00/0 : 21[1] -> 20[0] via P2P/CUMEM
 8: nid005586:68928:69502 [2] NCCL INFO Channel 05/0 : 34[2] -> 33[1] via P2P/CUMEM
 6: nid005584:28288:28833 [3] NCCL INFO Channel 01/0 : 27[3] -> 26[2] via P2P/CUMEM
 3: nid005580:71822:72371 [3] NCCL INFO Channel 02/0 : 15[3] -> 14[2] via P2P/CUMEM
 5: nid005582:196716:197406 [3] NCCL INFO Channel 04/0 : 23[3] -> 22[2] via P2P/CUMEM
14: nid005600:217723:218281 [3] NCCL INFO Channel 03/0 : 59[3] -> 58[2] via P2P/CUMEM
 2: nid005577:17425:17998 [3] NCCL INFO Channel 03/0 : 11[3] -> 10[2] via P2P/CUMEM
16: nid005802:6297:6913 [0] NCCL INFO Channel 05/0 : 64[0] -> 68[0] [send] via NET/AWS Libfabric/0
22: nid005915:274817:275368 [3] NCCL INFO Channel 02/0 : 91[3] -> 89[1] via P2P/CUMEM
21: nid005914:166787:167335 [3] NCCL INFO Channel 03/0 : 87[3] -> 85[1] via P2P/CUMEM
27: nid005922:80742:81301 [1] NCCL INFO Channel 00/0 : 109[1] -> 108[0] via P2P/CUMEM
22: nid005915:274816:275369 [2] NCCL INFO Channel 06/0 : 90[2] -> 88[0] via P2P/CUMEM
 9: nid005588:35938:36511 [3] NCCL INFO Channel 02/0 : 39[3] -> 38[2] via P2P/CUMEM
16: nid005802:6300:6915 [3] NCCL INFO Channel 04/0 : 67[3] -> 71[3] [send] via NET/AWS Libfabric/3
 6: nid005584:28287:28835 [2] NCCL INFO Channel 01/0 : 26[2] -> 25[1] via P2P/CUMEM
 8: nid005586:68929:69500 [3] NCCL INFO Channel 01/0 : 35[3] -> 34[2] via P2P/CUMEM
 7: nid005585:122007:122558 [2] NCCL INFO Channel 00/0 : 30[2] -> 29[1] via P2P/CUMEM
27: nid005922:80743:81299 [2] NCCL INFO Channel 04/0 : 110[2] -> 109[1] via P2P/CUMEM
 2: nid005577:17423:17995 [1] NCCL INFO Channel 01/0 : 9[1] -> 8[0] via P2P/CUMEM
 0: nid005574:69059:69643 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM
 7: nid005585:122008:122559 [3] NCCL INFO Channel 00/0 : 31[3] -> 30[2] via P2P/CUMEM
31: nid005937:256590:257161 [1] NCCL INFO Channel 04/0 : 125[1] -> 124[0] via P2P/CUMEM
10: nid005590:110713:111256 [3] NCCL INFO Channel 03/0 : 43[3] -> 42[2] via P2P/CUMEM
 1: nid005576:147558:148112 [1] NCCL INFO Channel 00/0 : 5[1] -> 4[0] via P2P/CUMEM
15: nid005601:210679:211247 [3] NCCL INFO Channel 03/0 : 63[3] -> 61[1] via P2P/CUMEM
 3: nid005580:71820:72372 [1] NCCL INFO Channel 00/0 : 13[1] -> 12[0] via P2P/CUMEM
12: nid005594:53085:53636 [0] NCCL INFO Channel 00/0 : 44[0] -> 48[0] [receive] via NET/AWS Libfabric/0
 1: nid005576:147560:148114 [3] NCCL INFO Channel 04/0 : 7[3] -> 6[2] via P2P/CUMEM
29: nid005932:167682:168243 [2] NCCL INFO Channel 03/0 : 114[2] -> 118[2] [receive] via NET/AWS Libfabric/2
26: nid005920:67126:67694 [3] NCCL INFO Channel 03/0 : 107[3] -> 106[2] via P2P/CUMEM
12: nid005594:53085:53636 [0] NCCL INFO Channel 04/0 : 44[0] -> 48[0] [receive] via NET/AWS Libfabric/0
14: nid005600:217721:218278 [1] NCCL INFO Channel 01/0 : 57[1] -> 56[0] via P2P/CUMEM
 9: nid005588:35936:36508 [1] NCCL INFO Channel 00/0 : 37[1] -> 36[0] via P2P/CUMEM
 3: nid005580:71822:72371 [3] NCCL INFO Channel 04/0 : 15[3] -> 14[2] via P2P/CUMEM
21: nid005914:166787:167335 [3] NCCL INFO Channel 07/0 : 87[3] -> 85[1] via P2P/CUMEM
14: nid005600:217723:218281 [3] NCCL INFO Channel 05/0 : 59[3] -> 58[2] via P2P/CUMEM
 9: nid005588:35938:36511 [3] NCCL INFO Channel 04/0 : 39[3] -> 38[2] via P2P/CUMEM
20: nid005913:292684:293235 [3] NCCL INFO Channel 06/0 : 83[3] -> 81[1] via P2P/CUMEM
 8: nid005586:68929:69500 [3] NCCL INFO Channel 03/0 : 35[3] -> 34[2] via P2P/CUMEM
 6: nid005584:28288:28833 [3] NCCL INFO Channel 03/0 : 27[3] -> 26[2] via P2P/CUMEM
12: nid005594:53085:53636 [0] NCCL INFO Channel 01/0 : 48[0] -> 52[0] [send] via NET/AWS Libfabric/0
27: nid005922:80742:81301 [1] NCCL INFO Channel 02/0 : 109[1] -> 108[0] via P2P/CUMEM
29: nid005932:167682:168243 [2] NCCL INFO Channel 07/0 : 114[2] -> 118[2] [receive] via NET/AWS Libfabric/2
10: nid005590:110711:111258 [1] NCCL INFO Channel 01/0 : 41[1] -> 40[0] via P2P/CUMEM
22: nid005915:274817:275368 [3] NCCL INFO Channel 06/0 : 91[3] -> 89[1] via P2P/CUMEM
31: nid005937:256590:257161 [1] NCCL INFO Channel 06/0 : 125[1] -> 124[0] via P2P/CUMEM
 2: nid005577:17425:17998 [3] NCCL INFO Channel 05/0 : 11[3] -> 10[2] via P2P/CUMEM
 6: nid005584:28287:28835 [2] NCCL INFO Channel 05/0 : 26[2] -> 25[1] via P2P/CUMEM
12: nid005594:53088:53639 [3] NCCL INFO Channel 01/0 : 47[3] -> 51[3] [receive] via NET/AWS Libfabric/3
10: nid005590:110713:111256 [3] NCCL INFO Channel 05/0 : 43[3] -> 42[2] via P2P/CUMEM
 5: nid005582:196714:197403 [1] NCCL INFO Channel 02/0 : 21[1] -> 20[0] via P2P/CUMEM
29: nid005932:167682:168243 [2] NCCL INFO Channel 02/0 : 118[2] -> 122[2] [send] via NET/AWS Libfabric/2
 0: nid005574:69060:69645 [2] NCCL INFO Channel 01/0 : 2[2] -> 1[1] via P2P/CUMEM
12: nid005594:53085:53636 [0] NCCL INFO Channel 05/0 : 48[0] -> 52[0] [send] via NET/AWS Libfabric/0
15: nid005601:210679:211247 [3] NCCL INFO Channel 07/0 : 63[3] -> 61[1] via P2P/CUMEM
 7: nid005585:122007:122558 [2] NCCL INFO Channel 04/0 : 30[2] -> 29[1] via P2P/CUMEM
 5: nid005582:196716:197406 [3] NCCL INFO Channel 06/0 : 23[3] -> 22[2] via P2P/CUMEM
29: nid005932:167682:168243 [2] NCCL INFO Channel 06/0 : 118[2] -> 122[2] [send] via NET/AWS Libfabric/2
 0: nid005574:69059:69643 [1] NCCL INFO Channel 07/0 : 1[1] -> 0[0] via P2P/CUMEM
12: nid005594:53088:53639 [3] NCCL INFO Channel 05/0 : 47[3] -> 51[3] [receive] via NET/AWS Libfabric/3
27: nid005922:80742:81301 [1] NCCL INFO Channel 04/0 : 109[1] -> 108[0] via P2P/CUMEM
21: nid005914:166787:167335 [3] NCCL INFO Channel 00/0 : 87[3] -> 86[2] via P2P/CUMEM
 7: nid005585:122008:122559 [3] NCCL INFO Channel 02/0 : 31[3] -> 30[2] via P2P/CUMEM
12: nid005594:53088:53639 [3] NCCL INFO Channel 00/0 : 51[3] -> 55[3] [send] via NET/AWS Libfabric/3
 1: nid005576:147558:148112 [1] NCCL INFO Channel 02/0 : 5[1] -> 4[0] via P2P/CUMEM
20: nid005913:292684:293235 [3] NCCL INFO Channel 01/0 : 83[3] -> 82[2] via P2P/CUMEM
26: nid005920:67124:67696 [1] NCCL INFO Channel 01/0 : 105[1] -> 104[0] via P2P/CUMEM
 2: nid005577:17423:17995 [1] NCCL INFO Channel 03/0 : 9[1] -> 8[0] via P2P/CUMEM
 1: nid005576:147560:148114 [3] NCCL INFO Channel 06/0 : 7[3] -> 6[2] via P2P/CUMEM
28: nid005929:16032:16583 [2] NCCL INFO Channel 02/0 : 114[2] -> 112[0] via P2P/CUMEM
 8: nid005586:68927:69501 [1] NCCL INFO Channel 01/0 : 33[1] -> 32[0] via P2P/CUMEM
 6: nid005584:28288:28833 [3] NCCL INFO Channel 05/0 : 27[3] -> 26[2] via P2P/CUMEM
12: nid005594:53088:53639 [3] NCCL INFO Channel 04/0 : 51[3] -> 55[3] [send] via NET/AWS Libfabric/3
 3: nid005580:71820:72372 [1] NCCL INFO Channel 02/0 : 13[1] -> 12[0] via P2P/CUMEM
26: nid005920:67126:67694 [3] NCCL INFO Channel 05/0 : 107[3] -> 106[2] via P2P/CUMEM
22: nid005915:274817:275368 [3] NCCL INFO Channel 01/0 : 91[3] -> 90[2] via P2P/CUMEM
 0: nid005574:69060:69645 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM
 3: nid005580:71822:72371 [3] NCCL INFO Channel 06/0 : 15[3] -> 14[2] via P2P/CUMEM
 8: nid005586:68929:69500 [3] NCCL INFO Channel 05/0 : 35[3] -> 34[2] via P2P/CUMEM
30: nid005936:49910:50483 [2] NCCL INFO Channel 02/0 : 122[2] -> 120[0] via P2P/CUMEM
29: nid005932:167681:168244 [1] NCCL INFO Channel 02/0 : 113[1] -> 117[1] [receive] via NET/AWS Libfabric/1
29: nid005932:167682:168243 [2] NCCL INFO Channel 03/0 : 118[2] -> 116[0] via P2P/CUMEM
14: nid005600:217721:218278 [1] NCCL INFO Channel 03/0 : 57[1] -> 56[0] via P2P/CUMEM
10: nid005590:110711:111258 [1] NCCL INFO Channel 03/0 : 41[1] -> 40[0] via P2P/CUMEM
27: nid005922:80742:81301 [1] NCCL INFO Channel 06/0 : 109[1] -> 108[0] via P2P/CUMEM
 6: nid005584:28286:28832 [1] NCCL INFO Channel 01/0 : 25[1] -> 24[0] via P2P/CUMEM
11: nid005591:191606:192158 [3] NCCL INFO Channel 03/0 : 47[3] -> 45[1] via P2P/CUMEM
 9: nid005588:35936:36508 [1] NCCL INFO Channel 02/0 : 37[1] -> 36[0] via P2P/CUMEM
29: nid005932:167681:168244 [1] NCCL INFO Channel 06/0 : 113[1] -> 117[1] [receive] via NET/AWS Libfabric/1
26: nid005920:67124:67696 [1] NCCL INFO Channel 03/0 : 105[1] -> 104[0] via P2P/CUMEM
 9: nid005588:35938:36511 [3] NCCL INFO Channel 06/0 : 39[3] -> 38[2] via P2P/CUMEM
15: nid005601:210679:211247 [3] NCCL INFO Channel 00/0 : 63[3] -> 62[2] via P2P/CUMEM
14: nid005600:217723:218281 [3] NCCL INFO Channel 07/0 : 59[3] -> 58[2] via P2P/CUMEM
29: nid005932:167681:168244 [1] NCCL INFO Channel 03/0 : 117[1] -> 121[1] [send] via NET/AWS Libfabric/1
13: nid005595:197886:198488 [3] NCCL INFO Channel 03/0 : 55[3] -> 53[1] via P2P/CUMEM
12: nid005594:53088:53639 [3] NCCL INFO Channel 02/0 : 51[3] -> 49[1] via P2P/CUMEM
10: nid005590:110713:111256 [3] NCCL INFO Channel 07/0 : 43[3] -> 42[2] via P2P/CUMEM
 2: nid005577:17425:17998 [3] NCCL INFO Channel 07/0 : 11[3] -> 10[2] via P2P/CUMEM
28: nid005929:16032:16583 [2] NCCL INFO Channel 06/0 : 114[2] -> 112[0] via P2P/CUMEM
 7: nid005585:122006:122557 [1] NCCL INFO Channel 00/0 : 29[1] -> 28[0] via P2P/CUMEM
29: nid005932:167681:168244 [1] NCCL INFO Channel 07/0 : 117[1] -> 121[1] [send] via NET/AWS Libfabric/1
 5: nid005582:196714:197403 [1] NCCL INFO Channel 04/0 : 21[1] -> 20[0] via P2P/CUMEM
30: nid005936:49910:50483 [2] NCCL INFO Channel 06/0 : 122[2] -> 120[0] via P2P/CUMEM
 7: nid005585:122008:122559 [3] NCCL INFO Channel 04/0 : 31[3] -> 30[2] via P2P/CUMEM
 5: nid005582:196715:197402 [2] NCCL INFO Channel 00/0 : 22[2] -> 21[1] via P2P/CUMEM
 8: nid005586:68927:69501 [1] NCCL INFO Channel 03/0 : 33[1] -> 32[0] via P2P/CUMEM
 8: nid005586:68929:69500 [3] NCCL INFO Channel 07/0 : 35[3] -> 34[2] via P2P/CUMEM
 6: nid005584:28288:28833 [3] NCCL INFO Channel 07/0 : 27[3] -> 26[2] via P2P/CUMEM
29: nid005932:167682:168243 [2] NCCL INFO Channel 07/0 : 118[2] -> 116[0] via P2P/CUMEM
29: nid005932:167683:168245 [3] NCCL INFO Channel 00/0 : 115[3] -> 119[3] [receive] via NET/AWS Libfabric/3
 6: nid005584:28286:28832 [1] NCCL INFO Channel 03/0 : 25[1] -> 24[0] via P2P/CUMEM
26: nid005920:67126:67694 [3] NCCL INFO Channel 07/0 : 107[3] -> 106[2] via P2P/CUMEM
20: nid005913:292684:293235 [3] NCCL INFO Channel 03/0 : 83[3] -> 82[2] via P2P/CUMEM
 1: nid005576:147558:148112 [1] NCCL INFO Channel 04/0 : 5[1] -> 4[0] via P2P/CUMEM
 2: nid005577:17423:17995 [1] NCCL INFO Channel 05/0 : 9[1] -> 8[0] via P2P/CUMEM
11: nid005591:191606:192158 [3] NCCL INFO Channel 07/0 : 47[3] -> 45[1] via P2P/CUMEM
29: nid005932:167683:168245 [3] NCCL INFO Channel 04/0 : 115[3] -> 119[3] [receive] via NET/AWS Libfabric/3
21: nid005914:166787:167335 [3] NCCL INFO Channel 02/0 : 87[3] -> 86[2] via P2P/CUMEM
 3: nid005580:71820:72372 [1] NCCL INFO Channel 04/0 : 13[1] -> 12[0] via P2P/CUMEM
 5: nid005582:196714:197403 [1] NCCL INFO Channel 06/0 : 21[1] -> 20[0] via P2P/CUMEM
 5: nid005582:196715:197402 [2] NCCL INFO Channel 04/0 : 22[2] -> 21[1] via P2P/CUMEM
14: nid005600:217721:218278 [1] NCCL INFO Channel 05/0 : 57[1] -> 56[0] via P2P/CUMEM
29: nid005932:167683:168245 [3] NCCL INFO Channel 01/0 : 119[3] -> 123[3] [send] via NET/AWS Libfabric/3
13: nid005595:197886:198488 [3] NCCL INFO Channel 07/0 : 55[3] -> 53[1] via P2P/CUMEM
12: nid005594:53088:53639 [3] NCCL INFO Channel 06/0 : 51[3] -> 49[1] via P2P/CUMEM
 7: nid005585:122006:122557 [1] NCCL INFO Channel 02/0 : 29[1] -> 28[0] via P2P/CUMEM
22: nid005915:274817:275368 [3] NCCL INFO Channel 03/0 : 91[3] -> 90[2] via P2P/CUMEM
 7: nid005585:122008:122559 [3] NCCL INFO Channel 06/0 : 31[3] -> 30[2] via P2P/CUMEM
29: nid005932:167683:168245 [3] NCCL INFO Channel 05/0 : 119[3] -> 123[3] [send] via NET/AWS Libfabric/3
10: nid005590:110711:111258 [1] NCCL INFO Channel 05/0 : 41[1] -> 40[0] via P2P/CUMEM
 8: nid005586:68927:69501 [1] NCCL INFO Channel 05/0 : 33[1] -> 32[0] via P2P/CUMEM
 6: nid005584:28286:28832 [1] NCCL INFO Channel 05/0 : 25[1] -> 24[0] via P2P/CUMEM
 9: nid005588:35936:36508 [1] NCCL INFO Channel 04/0 : 37[1] -> 36[0] via P2P/CUMEM
15: nid005601:210679:211247 [3] NCCL INFO Channel 02/0 : 63[3] -> 62[2] via P2P/CUMEM
31: nid005937:256591:257162 [2] NCCL INFO Channel 00/0 : 126[2] -> 125[1] via P2P/CUMEM
28: nid005929:16033:16586 [3] NCCL INFO Channel 02/0 : 115[3] -> 113[1] via P2P/CUMEM
26: nid005920:67124:67696 [1] NCCL INFO Channel 05/0 : 105[1] -> 104[0] via P2P/CUMEM
 6: nid005584:28286:28832 [1] NCCL INFO Channel 07/0 : 25[1] -> 24[0] via P2P/CUMEM
 8: nid005586:68927:69501 [1] NCCL INFO Channel 07/0 : 33[1] -> 32[0] via P2P/CUMEM
17: nid005803:180733:181299 [1] NCCL INFO Channel 02/0 : 65[1] -> 69[1] [receive] via NET/AWS Libfabric/1
30: nid005936:49911:50481 [3] NCCL INFO Channel 02/0 : 123[3] -> 121[1] via P2P/CUMEM
29: nid005932:167683:168245 [3] NCCL INFO Channel 03/0 : 119[3] -> 117[1] via P2P/CUMEM
 1: nid005576:147558:148112 [1] NCCL INFO Channel 06/0 : 5[1] -> 4[0] via P2P/CUMEM
11: nid005591:191606:192158 [3] NCCL INFO Channel 00/0 : 47[3] -> 46[2] via P2P/CUMEM
13: nid005595:197886:198488 [3] NCCL INFO Channel 00/0 : 55[3] -> 54[2] via P2P/CUMEM
21: nid005914:166785:167333 [1] NCCL INFO Channel 00/0 : 85[1] -> 84[0] via P2P/CUMEM
17: nid005803:180733:181299 [1] NCCL INFO Channel 06/0 : 65[1] -> 69[1] [receive] via NET/AWS Libfabric/1
10: nid005590:110711:111258 [1] NCCL INFO Channel 07/0 : 41[1] -> 40[0] via P2P/CUMEM
 7: nid005585:122006:122557 [1] NCCL INFO Channel 04/0 : 29[1] -> 28[0] via P2P/CUMEM
12: nid005594:53088:53639 [3] NCCL INFO Channel 01/0 : 51[3] -> 50[2] via P2P/CUMEM
 2: nid005577:17423:17995 [1] NCCL INFO Channel 07/0 : 9[1] -> 8[0] via P2P/CUMEM
14: nid005600:217721:218278 [1] NCCL INFO Channel 07/0 : 57[1] -> 56[0] via P2P/CUMEM
 3: nid005580:71820:72372 [1] NCCL INFO Channel 06/0 : 13[1] -> 12[0] via P2P/CUMEM
20: nid005913:292682:293234 [1] NCCL INFO Channel 01/0 : 81[1] -> 80[0] via P2P/CUMEM
17: nid005803:180733:181299 [1] NCCL INFO Channel 03/0 : 69[1] -> 73[1] [send] via NET/AWS Libfabric/1
22: nid005915:274815:275371 [1] NCCL INFO Channel 01/0 : 89[1] -> 88[0] via P2P/CUMEM
17: nid005803:180733:181299 [1] NCCL INFO Channel 07/0 : 69[1] -> 73[1] [send] via NET/AWS Libfabric/1
20: nid005913:292684:293235 [3] NCCL INFO Channel 05/0 : 83[3] -> 82[2] via P2P/CUMEM
 7: nid005585:122006:122557 [1] NCCL INFO Channel 06/0 : 29[1] -> 28[0] via P2P/CUMEM
22: nid005915:274817:275368 [3] NCCL INFO Channel 05/0 : 91[3] -> 90[2] via P2P/CUMEM
 9: nid005588:35936:36508 [1] NCCL INFO Channel 06/0 : 37[1] -> 36[0] via P2P/CUMEM
28: nid005929:16033:16586 [3] NCCL INFO Channel 06/0 : 115[3] -> 113[1] via P2P/CUMEM
29: nid005932:167680:168242 [0] NCCL INFO Channel 01/0 : 112[0] -> 116[0] [receive] via NET/AWS Libfabric/0
21: nid005914:166787:167335 [3] NCCL INFO Channel 04/0 : 87[3] -> 86[2] via P2P/CUMEM
30: nid005936:49911:50481 [3] NCCL INFO Channel 06/0 : 123[3] -> 121[1] via P2P/CUMEM
18: nid005911:38865:39435 [1] NCCL INFO Channel 03/0 : 69[1] -> 73[1] [receive] via NET/AWS Libfabric/1
26: nid005920:67124:67696 [1] NCCL INFO Channel 07/0 : 105[1] -> 104[0] via P2P/CUMEM
29: nid005932:167680:168242 [0] NCCL INFO Channel 05/0 : 112[0] -> 116[0] [receive] via NET/AWS Libfabric/0
29: nid005932:167683:168245 [3] NCCL INFO Channel 07/0 : 119[3] -> 117[1] via P2P/CUMEM
29: nid005932:167680:168242 [0] NCCL INFO Channel 00/0 : 116[0] -> 120[0] [send] via NET/AWS Libfabric/0
 2: nid005577:17424:17997 [2] NCCL INFO Channel 01/0 : 10[2] -> 9[1] via P2P/CUMEM
15: nid005601:210679:211247 [3] NCCL INFO Channel 04/0 : 63[3] -> 62[2] via P2P/CUMEM
18: nid005911:38865:39435 [1] NCCL INFO Channel 07/0 : 69[1] -> 73[1] [receive] via NET/AWS Libfabric/1
15: nid005601:210677:211246 [1] NCCL INFO Channel 00/0 : 61[1] -> 60[0] via P2P/CUMEM
 3: nid005580:71821:72370 [2] NCCL INFO Channel 00/0 : 14[2] -> 13[1] via P2P/CUMEM
 1: nid005576:147559:148115 [2] NCCL INFO Channel 00/0 : 6[2] -> 5[1] via P2P/CUMEM
29: nid005932:167680:168242 [0] NCCL INFO Channel 04/0 : 116[0] -> 120[0] [send] via NET/AWS Libfabric/0
18: nid005911:38865:39435 [1] NCCL INFO Channel 02/0 : 73[1] -> 77[1] [send] via NET/AWS Libfabric/1
21: nid005914:166785:167333 [1] NCCL INFO Channel 02/0 : 85[1] -> 84[0] via P2P/CUMEM
28: nid005929:16033:16586 [3] NCCL INFO Channel 01/0 : 115[3] -> 114[2] via P2P/CUMEM
13: nid005595:197886:198488 [3] NCCL INFO Channel 02/0 : 55[3] -> 54[2] via P2P/CUMEM
18: nid005911:38865:39435 [1] NCCL INFO Channel 06/0 : 73[1] -> 77[1] [send] via NET/AWS Libfabric/1
30: nid005936:49911:50481 [3] NCCL INFO Channel 01/0 : 123[3] -> 122[2] via P2P/CUMEM
10: nid005590:110712:111257 [2] NCCL INFO Channel 01/0 : 42[2] -> 41[1] via P2P/CUMEM
 2: nid005577:17424:17997 [2] NCCL INFO Channel 05/0 : 10[2] -> 9[1] via P2P/CUMEM
 9: nid005588:35937:36509 [2] NCCL INFO Channel 00/0 : 38[2] -> 37[1] via P2P/CUMEM
20: nid005913:292682:293234 [1] NCCL INFO Channel 03/0 : 81[1] -> 80[0] via P2P/CUMEM
12: nid005594:53088:53639 [3] NCCL INFO Channel 03/0 : 51[3] -> 50[2] via P2P/CUMEM
 1: nid005576:147559:148115 [2] NCCL INFO Channel 04/0 : 6[2] -> 5[1] via P2P/CUMEM
 3: nid005580:71821:72370 [2] NCCL INFO Channel 04/0 : 14[2] -> 13[1] via P2P/CUMEM
11: nid005591:191606:192158 [3] NCCL INFO Channel 02/0 : 47[3] -> 46[2] via P2P/CUMEM
29: nid005932:167683:168245 [3] NCCL INFO Channel 00/0 : 119[3] -> 118[2] via P2P/CUMEM
14: nid005600:217722:218279 [2] NCCL INFO Channel 01/0 : 58[2] -> 57[1] via P2P/CUMEM
22: nid005915:274815:275371 [1] NCCL INFO Channel 03/0 : 89[1] -> 88[0] via P2P/CUMEM
20: nid005913:292684:293235 [3] NCCL INFO Channel 07/0 : 83[3] -> 82[2] via P2P/CUMEM
22: nid005915:274817:275368 [3] NCCL INFO Channel 07/0 : 91[3] -> 90[2] via P2P/CUMEM
10: nid005590:110712:111257 [2] NCCL INFO Channel 05/0 : 42[2] -> 41[1] via P2P/CUMEM
 9: nid005588:35937:36509 [2] NCCL INFO Channel 04/0 : 38[2] -> 37[1] via P2P/CUMEM
14: nid005600:217722:218279 [2] NCCL INFO Channel 05/0 : 58[2] -> 57[1] via P2P/CUMEM
21: nid005914:166787:167335 [3] NCCL INFO Channel 06/0 : 87[3] -> 86[2] via P2P/CUMEM
17: nid005803:180735:181302 [3] NCCL INFO Channel 00/0 : 67[3] -> 71[3] [receive] via NET/AWS Libfabric/3
21: nid005914:166786:167334 [2] NCCL INFO Channel 00/0 : 86[2] -> 85[1] via P2P/CUMEM
15: nid005601:210679:211247 [3] NCCL INFO Channel 06/0 : 63[3] -> 62[2] via P2P/CUMEM
30: nid005936:49911:50481 [3] NCCL INFO Channel 03/0 : 123[3] -> 122[2] via P2P/CUMEM
17: nid005803:180735:181302 [3] NCCL INFO Channel 04/0 : 67[3] -> 71[3] [receive] via NET/AWS Libfabric/3
26: nid005920:67125:67695 [2] NCCL INFO Channel 01/0 : 106[2] -> 105[1] via P2P/CUMEM
15: nid005601:210677:211246 [1] NCCL INFO Channel 02/0 : 61[1] -> 60[0] via P2P/CUMEM
28: nid005929:16033:16586 [3] NCCL INFO Channel 03/0 : 115[3] -> 114[2] via P2P/CUMEM
17: nid005803:180735:181302 [3] NCCL INFO Channel 01/0 : 71[3] -> 75[3] [send] via NET/AWS Libfabric/3
20: nid005913:292683:293236 [2] NCCL INFO Channel 01/0 : 82[2] -> 81[1] via P2P/CUMEM
11: nid005591:191604:192159 [1] NCCL INFO Channel 00/0 : 45[1] -> 44[0] via P2P/CUMEM
22: nid005915:274816:275369 [2] NCCL INFO Channel 01/0 : 90[2] -> 89[1] via P2P/CUMEM
21: nid005914:166785:167333 [1] NCCL INFO Channel 04/0 : 85[1] -> 84[0] via P2P/CUMEM
11: nid005591:191606:192158 [3] NCCL INFO Channel 04/0 : 47[3] -> 46[2] via P2P/CUMEM
17: nid005803:180735:181302 [3] NCCL INFO Channel 05/0 : 71[3] -> 75[3] [send] via NET/AWS Libfabric/3
26: nid005920:67125:67695 [2] NCCL INFO Channel 05/0 : 106[2] -> 105[1] via P2P/CUMEM
12: nid005594:53086:53638 [1] NCCL INFO Channel 01/0 : 49[1] -> 48[0] via P2P/CUMEM
13: nid005595:197886:198488 [3] NCCL INFO Channel 04/0 : 55[3] -> 54[2] via P2P/CUMEM
20: nid005913:292682:293234 [1] NCCL INFO Channel 05/0 : 81[1] -> 80[0] via P2P/CUMEM
13: nid005595:197884:198486 [1] NCCL INFO Channel 00/0 : 53[1] -> 52[0] via P2P/CUMEM
22: nid005915:274815:275371 [1] NCCL INFO Channel 05/0 : 89[1] -> 88[0] via P2P/CUMEM
29: nid005932:167683:168245 [3] NCCL INFO Channel 02/0 : 119[3] -> 118[2] via P2P/CUMEM
12: nid005594:53088:53639 [3] NCCL INFO Channel 05/0 : 51[3] -> 50[2] via P2P/CUMEM
16: nid005802:6300:6915 [3] NCCL INFO Channel 02/0 : 67[3] -> 65[1] via P2P/CUMEM
17: nid005803:180732:181300 [0] NCCL INFO Channel 01/0 : 64[0] -> 68[0] [receive] via NET/AWS Libfabric/0
28: nid005929:16031:16585 [1] NCCL INFO Channel 01/0 : 113[1] -> 112[0] via P2P/CUMEM
20: nid005913:292683:293236 [2] NCCL INFO Channel 05/0 : 82[2] -> 81[1] via P2P/CUMEM
30: nid005936:49909:50480 [1] NCCL INFO Channel 01/0 : 121[1] -> 120[0] via P2P/CUMEM
20: nid005913:292682:293234 [1] NCCL INFO Channel 07/0 : 81[1] -> 80[0] via P2P/CUMEM
28: nid005929:16033:16586 [3] NCCL INFO Channel 05/0 : 115[3] -> 114[2] via P2P/CUMEM
21: nid005914:166786:167334 [2] NCCL INFO Channel 04/0 : 86[2] -> 85[1] via P2P/CUMEM
30: nid005936:49911:50481 [3] NCCL INFO Channel 05/0 : 123[3] -> 122[2] via P2P/CUMEM
22: nid005915:274816:275369 [2] NCCL INFO Channel 05/0 : 90[2] -> 89[1] via P2P/CUMEM
17: nid005803:180732:181300 [0] NCCL INFO Channel 05/0 : 64[0] -> 68[0] [receive] via NET/AWS Libfabric/0
21: nid005914:166785:167333 [1] NCCL INFO Channel 06/0 : 85[1] -> 84[0] via P2P/CUMEM
22: nid005915:274815:275371 [1] NCCL INFO Channel 07/0 : 89[1] -> 88[0] via P2P/CUMEM
17: nid005803:180732:181300 [0] NCCL INFO Channel 00/0 : 68[0] -> 72[0] [send] via NET/AWS Libfabric/0
15: nid005601:210678:211248 [2] NCCL INFO Channel 00/0 : 62[2] -> 61[1] via P2P/CUMEM
11: nid005591:191604:192159 [1] NCCL INFO Channel 02/0 : 45[1] -> 44[0] via P2P/CUMEM
15: nid005601:210677:211246 [1] NCCL INFO Channel 04/0 : 61[1] -> 60[0] via P2P/CUMEM
11: nid005591:191606:192158 [3] NCCL INFO Channel 06/0 : 47[3] -> 46[2] via P2P/CUMEM
29: nid005932:167681:168244 [1] NCCL INFO Channel 00/0 : 117[1] -> 116[0] via P2P/CUMEM
16: nid005802:6300:6915 [3] NCCL INFO Channel 06/0 : 67[3] -> 65[1] via P2P/CUMEM
17: nid005803:180732:181300 [0] NCCL INFO Channel 04/0 : 68[0] -> 72[0] [send] via NET/AWS Libfabric/0
29: nid005932:167683:168245 [3] NCCL INFO Channel 04/0 : 119[3] -> 118[2] via P2P/CUMEM
28: nid005929:16031:16585 [1] NCCL INFO Channel 03/0 : 113[1] -> 112[0] via P2P/CUMEM
13: nid005595:197886:198488 [3] NCCL INFO Channel 06/0 : 55[3] -> 54[2] via P2P/CUMEM
12: nid005594:53086:53638 [1] NCCL INFO Channel 03/0 : 49[1] -> 48[0] via P2P/CUMEM
28: nid005929:16033:16586 [3] NCCL INFO Channel 07/0 : 115[3] -> 114[2] via P2P/CUMEM
12: nid005594:53088:53639 [3] NCCL INFO Channel 07/0 : 51[3] -> 50[2] via P2P/CUMEM
13: nid005595:197884:198486 [1] NCCL INFO Channel 02/0 : 53[1] -> 52[0] via P2P/CUMEM
13: nid005595:197885:198487 [2] NCCL INFO Channel 00/0 : 54[2] -> 53[1] via P2P/CUMEM
12: nid005594:53087:53637 [2] NCCL INFO Channel 01/0 : 50[2] -> 49[1] via P2P/CUMEM
15: nid005601:210678:211248 [2] NCCL INFO Channel 04/0 : 62[2] -> 61[1] via P2P/CUMEM
30: nid005936:49909:50480 [1] NCCL INFO Channel 03/0 : 121[1] -> 120[0] via P2P/CUMEM
15: nid005601:210677:211246 [1] NCCL INFO Channel 06/0 : 61[1] -> 60[0] via P2P/CUMEM
30: nid005936:49911:50481 [3] NCCL INFO Channel 07/0 : 123[3] -> 122[2] via P2P/CUMEM
29: nid005932:167681:168244 [1] NCCL INFO Channel 02/0 : 117[1] -> 116[0] via P2P/CUMEM
16: nid005802:6300:6915 [3] NCCL INFO Channel 01/0 : 67[3] -> 66[2] via P2P/CUMEM
11: nid005591:191605:192157 [2] NCCL INFO Channel 00/0 : 46[2] -> 45[1] via P2P/CUMEM
11: nid005591:191604:192159 [1] NCCL INFO Channel 04/0 : 45[1] -> 44[0] via P2P/CUMEM
18: nid005911:38864:39434 [0] NCCL INFO Channel 00/0 : 68[0] -> 72[0] [receive] via NET/AWS Libfabric/0
29: nid005932:167683:168245 [3] NCCL INFO Channel 06/0 : 119[3] -> 118[2] via P2P/CUMEM
12: nid005594:53086:53638 [1] NCCL INFO Channel 05/0 : 49[1] -> 48[0] via P2P/CUMEM
18: nid005911:38864:39434 [0] NCCL INFO Channel 04/0 : 68[0] -> 72[0] [receive] via NET/AWS Libfabric/0
13: nid005595:197884:198486 [1] NCCL INFO Channel 04/0 : 53[1] -> 52[0] via P2P/CUMEM
13: nid005595:197885:198487 [2] NCCL INFO Channel 04/0 : 54[2] -> 53[1] via P2P/CUMEM
12: nid005594:53087:53637 [2] NCCL INFO Channel 05/0 : 50[2] -> 49[1] via P2P/CUMEM
28: nid005929:16031:16585 [1] NCCL INFO Channel 05/0 : 113[1] -> 112[0] via P2P/CUMEM
18: nid005911:38864:39434 [0] NCCL INFO Channel 01/0 : 72[0] -> 76[0] [send] via NET/AWS Libfabric/0
11: nid005591:191605:192157 [2] NCCL INFO Channel 04/0 : 46[2] -> 45[1] via P2P/CUMEM
16: nid005802:6300:6915 [3] NCCL INFO Channel 03/0 : 67[3] -> 66[2] via P2P/CUMEM
30: nid005936:49909:50480 [1] NCCL INFO Channel 05/0 : 121[1] -> 120[0] via P2P/CUMEM
18: nid005911:38864:39434 [0] NCCL INFO Channel 05/0 : 72[0] -> 76[0] [send] via NET/AWS Libfabric/0
12: nid005594:53086:53638 [1] NCCL INFO Channel 07/0 : 49[1] -> 48[0] via P2P/CUMEM
18: nid005911:38867:39437 [3] NCCL INFO Channel 01/0 : 71[3] -> 75[3] [receive] via NET/AWS Libfabric/3
11: nid005591:191604:192159 [1] NCCL INFO Channel 06/0 : 45[1] -> 44[0] via P2P/CUMEM
29: nid005932:167681:168244 [1] NCCL INFO Channel 04/0 : 117[1] -> 116[0] via P2P/CUMEM
18: nid005911:38867:39437 [3] NCCL INFO Channel 05/0 : 71[3] -> 75[3] [receive] via NET/AWS Libfabric/3
13: nid005595:197884:198486 [1] NCCL INFO Channel 06/0 : 53[1] -> 52[0] via P2P/CUMEM
18: nid005911:38867:39437 [3] NCCL INFO Channel 00/0 : 75[3] -> 79[3] [send] via NET/AWS Libfabric/3
16: nid005802:6298:6912 [1] NCCL INFO Channel 01/0 : 65[1] -> 64[0] via P2P/CUMEM
30: nid005936:49909:50480 [1] NCCL INFO Channel 07/0 : 121[1] -> 120[0] via P2P/CUMEM
18: nid005911:38867:39437 [3] NCCL INFO Channel 04/0 : 75[3] -> 79[3] [send] via NET/AWS Libfabric/3
28: nid005929:16031:16585 [1] NCCL INFO Channel 07/0 : 113[1] -> 112[0] via P2P/CUMEM
24: nid005918:92507:93092 [3] NCCL INFO Channel 01/0 : 95[3] -> 99[3] [receive] via NET/AWS Libfabric/3
24: nid005918:92507:93092 [3] NCCL INFO Channel 05/0 : 95[3] -> 99[3] [receive] via NET/AWS Libfabric/3
17: nid005803:180735:181302 [3] NCCL INFO Channel 03/0 : 71[3] -> 69[1] via P2P/CUMEM
24: nid005918:92507:93092 [3] NCCL INFO Channel 00/0 : 99[3] -> 103[3] [send] via NET/AWS Libfabric/3
16: nid005802:6300:6915 [3] NCCL INFO Channel 05/0 : 67[3] -> 66[2] via P2P/CUMEM
19: nid005912:12438:13006 [3] NCCL INFO Channel 03/0 : 79[3] -> 77[1] via P2P/CUMEM
24: nid005918:92507:93092 [3] NCCL INFO Channel 04/0 : 99[3] -> 103[3] [send] via NET/AWS Libfabric/3
18: nid005911:38867:39437 [3] NCCL INFO Channel 02/0 : 75[3] -> 73[1] via P2P/CUMEM
29: nid005932:167681:168244 [1] NCCL INFO Channel 06/0 : 117[1] -> 116[0] via P2P/CUMEM
16: nid005802:6298:6912 [1] NCCL INFO Channel 03/0 : 65[1] -> 64[0] via P2P/CUMEM
23: nid005917:276888:277437 [3] NCCL INFO Channel 03/0 : 95[3] -> 93[1] via P2P/CUMEM
24: nid005918:92507:93092 [3] NCCL INFO Channel 02/0 : 99[3] -> 97[1] via P2P/CUMEM
17: nid005803:180735:181302 [3] NCCL INFO Channel 07/0 : 71[3] -> 69[1] via P2P/CUMEM
25: nid005919:107465:108039 [3] NCCL INFO Channel 03/0 : 103[3] -> 101[1] via P2P/CUMEM
24: nid005918:92504:93095 [0] NCCL INFO Channel 00/0 : 92[0] -> 96[0] [receive] via NET/AWS Libfabric/0
18: nid005911:38867:39437 [3] NCCL INFO Channel 06/0 : 75[3] -> 73[1] via P2P/CUMEM
19: nid005912:12438:13006 [3] NCCL INFO Channel 07/0 : 79[3] -> 77[1] via P2P/CUMEM
28: nid005929:16032:16583 [2] NCCL INFO Channel 01/0 : 114[2] -> 113[1] via P2P/CUMEM
23: nid005917:276888:277437 [3] NCCL INFO Channel 07/0 : 95[3] -> 93[1] via P2P/CUMEM
24: nid005918:92504:93095 [0] NCCL INFO Channel 04/0 : 92[0] -> 96[0] [receive] via NET/AWS Libfabric/0
24: nid005918:92507:93092 [3] NCCL INFO Channel 06/0 : 99[3] -> 97[1] via P2P/CUMEM
30: nid005936:49910:50483 [2] NCCL INFO Channel 01/0 : 122[2] -> 121[1] via P2P/CUMEM
17: nid005803:180735:181302 [3] NCCL INFO Channel 00/0 : 71[3] -> 70[2] via P2P/CUMEM
24: nid005918:92504:93095 [0] NCCL INFO Channel 01/0 : 96[0] -> 100[0] [send] via NET/AWS Libfabric/0
25: nid005919:107465:108039 [3] NCCL INFO Channel 07/0 : 103[3] -> 101[1] via P2P/CUMEM
28: nid005929:16032:16583 [2] NCCL INFO Channel 05/0 : 114[2] -> 113[1] via P2P/CUMEM
16: nid005802:6300:6915 [3] NCCL INFO Channel 07/0 : 67[3] -> 66[2] via P2P/CUMEM
31: nid005937:256591:257162 [2] NCCL INFO Channel 04/0 : 126[2] -> 125[1] via P2P/CUMEM
16: nid005802:6298:6912 [1] NCCL INFO Channel 05/0 : 65[1] -> 64[0] via P2P/CUMEM
24: nid005918:92504:93095 [0] NCCL INFO Channel 05/0 : 96[0] -> 100[0] [send] via NET/AWS Libfabric/0
19: nid005912:12438:13006 [3] NCCL INFO Channel 00/0 : 79[3] -> 78[2] via P2P/CUMEM
23: nid005917:276888:277437 [3] NCCL INFO Channel 00/0 : 95[3] -> 94[2] via P2P/CUMEM
30: nid005936:49910:50483 [2] NCCL INFO Channel 05/0 : 122[2] -> 121[1] via P2P/CUMEM
24: nid005918:92507:93092 [3] NCCL INFO Channel 01/0 : 99[3] -> 98[2] via P2P/CUMEM
18: nid005911:38867:39437 [3] NCCL INFO Channel 01/0 : 75[3] -> 74[2] via P2P/CUMEM
29: nid005932:167682:168243 [2] NCCL INFO Channel 00/0 : 118[2] -> 117[1] via P2P/CUMEM
25: nid005919:107465:108039 [3] NCCL INFO Channel 00/0 : 103[3] -> 102[2] via P2P/CUMEM
29: nid005932:167682:168243 [2] NCCL INFO Channel 04/0 : 118[2] -> 117[1] via P2P/CUMEM
17: nid005803:180735:181302 [3] NCCL INFO Channel 02/0 : 71[3] -> 70[2] via P2P/CUMEM
16: nid005802:6298:6912 [1] NCCL INFO Channel 07/0 : 65[1] -> 64[0] via P2P/CUMEM
23: nid005917:276888:277437 [3] NCCL INFO Channel 02/0 : 95[3] -> 94[2] via P2P/CUMEM
19: nid005912:12438:13006 [3] NCCL INFO Channel 02/0 : 79[3] -> 78[2] via P2P/CUMEM
25: nid005919:107465:108039 [3] NCCL INFO Channel 02/0 : 103[3] -> 102[2] via P2P/CUMEM
24: nid005918:92507:93092 [3] NCCL INFO Channel 03/0 : 99[3] -> 98[2] via P2P/CUMEM
18: nid005911:38867:39437 [3] NCCL INFO Channel 03/0 : 75[3] -> 74[2] via P2P/CUMEM
23: nid005917:276886:277439 [1] NCCL INFO Channel 00/0 : 93[1] -> 92[0] via P2P/CUMEM
25: nid005919:107465:108039 [3] NCCL INFO Channel 04/0 : 103[3] -> 102[2] via P2P/CUMEM
23: nid005917:276888:277437 [3] NCCL INFO Channel 04/0 : 95[3] -> 94[2] via P2P/CUMEM
17: nid005803:180733:181299 [1] NCCL INFO Channel 00/0 : 69[1] -> 68[0] via P2P/CUMEM
17: nid005803:180735:181302 [3] NCCL INFO Channel 04/0 : 71[3] -> 70[2] via P2P/CUMEM
16: nid005802:6299:6914 [2] NCCL INFO Channel 01/0 : 66[2] -> 65[1] via P2P/CUMEM
24: nid005918:92507:93092 [3] NCCL INFO Channel 05/0 : 99[3] -> 98[2] via P2P/CUMEM
25: nid005919:107463:108041 [1] NCCL INFO Channel 00/0 : 101[1] -> 100[0] via P2P/CUMEM
24: nid005918:92505:93094 [1] NCCL INFO Channel 01/0 : 97[1] -> 96[0] via P2P/CUMEM
19: nid005912:12436:13008 [1] NCCL INFO Channel 00/0 : 77[1] -> 76[0] via P2P/CUMEM
23: nid005917:276886:277439 [1] NCCL INFO Channel 02/0 : 93[1] -> 92[0] via P2P/CUMEM
19: nid005912:12438:13006 [3] NCCL INFO Channel 04/0 : 79[3] -> 78[2] via P2P/CUMEM
23: nid005917:276888:277437 [3] NCCL INFO Channel 06/0 : 95[3] -> 94[2] via P2P/CUMEM
16: nid005802:6299:6914 [2] NCCL INFO Channel 05/0 : 66[2] -> 65[1] via P2P/CUMEM
25: nid005919:107465:108039 [3] NCCL INFO Channel 06/0 : 103[3] -> 102[2] via P2P/CUMEM
18: nid005911:38865:39435 [1] NCCL INFO Channel 01/0 : 73[1] -> 72[0] via P2P/CUMEM
25: nid005919:107463:108041 [1] NCCL INFO Channel 02/0 : 101[1] -> 100[0] via P2P/CUMEM
18: nid005911:38867:39437 [3] NCCL INFO Channel 05/0 : 75[3] -> 74[2] via P2P/CUMEM
24: nid005918:92507:93092 [3] NCCL INFO Channel 07/0 : 99[3] -> 98[2] via P2P/CUMEM
17: nid005803:180733:181299 [1] NCCL INFO Channel 02/0 : 69[1] -> 68[0] via P2P/CUMEM
17: nid005803:180735:181302 [3] NCCL INFO Channel 06/0 : 71[3] -> 70[2] via P2P/CUMEM
24: nid005918:92505:93094 [1] NCCL INFO Channel 03/0 : 97[1] -> 96[0] via P2P/CUMEM
19: nid005912:12436:13008 [1] NCCL INFO Channel 02/0 : 77[1] -> 76[0] via P2P/CUMEM
23: nid005917:276886:277439 [1] NCCL INFO Channel 04/0 : 93[1] -> 92[0] via P2P/CUMEM
19: nid005912:12438:13006 [3] NCCL INFO Channel 06/0 : 79[3] -> 78[2] via P2P/CUMEM
17: nid005803:180734:181301 [2] NCCL INFO Channel 00/0 : 70[2] -> 69[1] via P2P/CUMEM
19: nid005912:12437:13007 [2] NCCL INFO Channel 00/0 : 78[2] -> 77[1] via P2P/CUMEM
18: nid005911:38866:39436 [2] NCCL INFO Channel 01/0 : 74[2] -> 73[1] via P2P/CUMEM
18: nid005911:38865:39435 [1] NCCL INFO Channel 03/0 : 73[1] -> 72[0] via P2P/CUMEM
17: nid005803:180733:181299 [1] NCCL INFO Channel 04/0 : 69[1] -> 68[0] via P2P/CUMEM
18: nid005911:38867:39437 [3] NCCL INFO Channel 07/0 : 75[3] -> 74[2] via P2P/CUMEM
25: nid005919:107463:108041 [1] NCCL INFO Channel 04/0 : 101[1] -> 100[0] via P2P/CUMEM
24: nid005918:92505:93094 [1] NCCL INFO Channel 05/0 : 97[1] -> 96[0] via P2P/CUMEM
19: nid005912:12436:13008 [1] NCCL INFO Channel 04/0 : 77[1] -> 76[0] via P2P/CUMEM
17: nid005803:180734:181301 [2] NCCL INFO Channel 04/0 : 70[2] -> 69[1] via P2P/CUMEM
19: nid005912:12437:13007 [2] NCCL INFO Channel 04/0 : 78[2] -> 77[1] via P2P/CUMEM
23: nid005917:276886:277439 [1] NCCL INFO Channel 06/0 : 93[1] -> 92[0] via P2P/CUMEM
17: nid005803:180733:181299 [1] NCCL INFO Channel 06/0 : 69[1] -> 68[0] via P2P/CUMEM
18: nid005911:38866:39436 [2] NCCL INFO Channel 05/0 : 74[2] -> 73[1] via P2P/CUMEM
19: nid005912:12436:13008 [1] NCCL INFO Channel 06/0 : 77[1] -> 76[0] via P2P/CUMEM
18: nid005911:38865:39435 [1] NCCL INFO Channel 05/0 : 73[1] -> 72[0] via P2P/CUMEM
25: nid005919:107463:108041 [1] NCCL INFO Channel 06/0 : 101[1] -> 100[0] via P2P/CUMEM
24: nid005918:92505:93094 [1] NCCL INFO Channel 07/0 : 97[1] -> 96[0] via P2P/CUMEM
18: nid005911:38865:39435 [1] NCCL INFO Channel 07/0 : 73[1] -> 72[0] via P2P/CUMEM
23: nid005917:276887:277438 [2] NCCL INFO Channel 00/0 : 94[2] -> 93[1] via P2P/CUMEM
23: nid005917:276887:277438 [2] NCCL INFO Channel 04/0 : 94[2] -> 93[1] via P2P/CUMEM
25: nid005919:107464:108040 [2] NCCL INFO Channel 00/0 : 102[2] -> 101[1] via P2P/CUMEM
25: nid005919:107464:108040 [2] NCCL INFO Channel 04/0 : 102[2] -> 101[1] via P2P/CUMEM
24: nid005918:92506:93093 [2] NCCL INFO Channel 01/0 : 98[2] -> 97[1] via P2P/CUMEM
24: nid005918:92506:93093 [2] NCCL INFO Channel 05/0 : 98[2] -> 97[1] via P2P/CUMEM
17: nid005803:180732:181300 [0] NCCL INFO Connected all rings
17: nid005803:180735:181302 [3] NCCL INFO Connected all rings
17: nid005803:180733:181299 [1] NCCL INFO Connected all rings
17: nid005803:180734:181301 [2] NCCL INFO Connected all rings
31: nid005937:256592:257159 [3] NCCL INFO Connected all rings
31: nid005937:256589:257160 [0] NCCL INFO Connected all rings
31: nid005937:256591:257162 [2] NCCL INFO Connected all rings
31: nid005937:256590:257161 [1] NCCL INFO Connected all rings
 0: nid005574:69061:69644 [3] NCCL INFO Connected all rings
 0: nid005574:69058:69646 [0] NCCL INFO Connected all rings
 8: nid005586:68926:69499 [0] NCCL INFO Connected all rings
 8: nid005586:68929:69500 [3] NCCL INFO Connected all rings
 0: nid005574:69059:69643 [1] NCCL INFO Connected all rings
 0: nid005574:69060:69645 [2] NCCL INFO Connected all rings
 8: nid005586:68927:69501 [1] NCCL INFO Connected all rings
 7: nid005585:122005:122556 [0] NCCL INFO Connected all rings
 8: nid005586:68928:69502 [2] NCCL INFO Connected all rings
 7: nid005585:122008:122559 [3] NCCL INFO Connected all rings
 6: nid005584:28285:28834 [0] NCCL INFO Connected all rings
 6: nid005584:28288:28833 [3] NCCL INFO Connected all rings
 7: nid005585:122007:122558 [2] NCCL INFO Connected all rings
 6: nid005584:28287:28835 [2] NCCL INFO Connected all rings
 7: nid005585:122006:122557 [1] NCCL INFO Connected all rings
 6: nid005584:28286:28832 [1] NCCL INFO Connected all rings
 9: nid005588:35935:36510 [0] NCCL INFO Connected all rings
 9: nid005588:35938:36511 [3] NCCL INFO Connected all rings
 9: nid005588:35936:36508 [1] NCCL INFO Connected all rings
 9: nid005588:35937:36509 [2] NCCL INFO Connected all rings
 1: nid005576:147560:148114 [3] NCCL INFO Connected all rings
 1: nid005576:147557:148113 [0] NCCL INFO Connected all rings
 1: nid005576:147559:148115 [2] NCCL INFO Connected all rings
 1: nid005576:147558:148112 [1] NCCL INFO Connected all rings
 5: nid005582:196716:197406 [3] NCCL INFO Connected all rings
 5: nid005582:196713:197404 [0] NCCL INFO Connected all rings
 5: nid005582:196715:197402 [2] NCCL INFO Connected all rings
 5: nid005582:196714:197403 [1] NCCL INFO Connected all rings
27: nid005922:80741:81298 [0] NCCL INFO Connected all rings
27: nid005922:80744:81300 [3] NCCL INFO Connected all rings
27: nid005922:80742:81301 [1] NCCL INFO Connected all rings
27: nid005922:80743:81299 [2] NCCL INFO Connected all rings
 4: nid005581:264523:265078 [0] NCCL INFO Connected all rings
 4: nid005581:264526:265079 [3] NCCL INFO Connected all rings
 4: nid005581:264524:265080 [1] NCCL INFO Connected all rings
 4: nid005581:264525:265077 [2] NCCL INFO Connected all rings
 3: nid005580:71822:72371 [3] NCCL INFO Connected all rings
 2: nid005577:17425:17998 [3] NCCL INFO Connected all rings
 2: nid005577:17422:17996 [0] NCCL INFO Connected all rings
 3: nid005580:71819:72369 [0] NCCL INFO Connected all rings
 3: nid005580:71821:72370 [2] NCCL INFO Connected all rings
 3: nid005580:71820:72372 [1] NCCL INFO Connected all rings
 2: nid005577:17424:17997 [2] NCCL INFO Connected all rings
 2: nid005577:17423:17995 [1] NCCL INFO Connected all rings
12: nid005594:53085:53636 [0] NCCL INFO Connected all rings
11: nid005591:191606:192158 [3] NCCL INFO Connected all rings
11: nid005591:191603:192156 [0] NCCL INFO Connected all rings
12: nid005594:53088:53639 [3] NCCL INFO Connected all rings
10: nid005590:110713:111256 [3] NCCL INFO Connected all rings
10: nid005590:110710:111255 [0] NCCL INFO Connected all rings
12: nid005594:53087:53637 [2] NCCL INFO Connected all rings
12: nid005594:53086:53638 [1] NCCL INFO Connected all rings
11: nid005591:191605:192157 [2] NCCL INFO Connected all rings
10: nid005590:110712:111257 [2] NCCL INFO Connected all rings
11: nid005591:191604:192159 [1] NCCL INFO Connected all rings
10: nid005590:110711:111258 [1] NCCL INFO Connected all rings
19: nid005912:12435:13009 [0] NCCL INFO Connected all rings
19: nid005912:12438:13006 [3] NCCL INFO Connected all rings
18: nid005911:38867:39437 [3] NCCL INFO Connected all rings
18: nid005911:38864:39434 [0] NCCL INFO Connected all rings
19: nid005912:12437:13007 [2] NCCL INFO Connected all rings
19: nid005912:12436:13008 [1] NCCL INFO Connected all rings
18: nid005911:38866:39436 [2] NCCL INFO Connected all rings
18: nid005911:38865:39435 [1] NCCL INFO Connected all rings
22: nid005915:274817:275368 [3] NCCL INFO Connected all rings
22: nid005915:274814:275370 [0] NCCL INFO Connected all rings
22: nid005915:274816:275369 [2] NCCL INFO Connected all rings
21: nid005914:166784:167332 [0] NCCL INFO Connected all rings
20: nid005913:292681:293237 [0] NCCL INFO Connected all rings
21: nid005914:166787:167335 [3] NCCL INFO Connected all rings
22: nid005915:274815:275371 [1] NCCL INFO Connected all rings
20: nid005913:292684:293235 [3] NCCL INFO Connected all rings
21: nid005914:166786:167334 [2] NCCL INFO Connected all rings
21: nid005914:166785:167333 [1] NCCL INFO Connected all rings
20: nid005913:292682:293234 [1] NCCL INFO Connected all rings
20: nid005913:292683:293236 [2] NCCL INFO Connected all rings
16: nid005802:6297:6913 [0] NCCL INFO Connected all rings
16: nid005802:6300:6915 [3] NCCL INFO Connected all rings
16: nid005802:6299:6914 [2] NCCL INFO Connected all rings
16: nid005802:6298:6912 [1] NCCL INFO Connected all rings
26: nid005920:67123:67693 [0] NCCL INFO Connected all rings
26: nid005920:67124:67696 [1] NCCL INFO Connected all rings
26: nid005920:67126:67694 [3] NCCL INFO Connected all rings
26: nid005920:67125:67695 [2] NCCL INFO Connected all rings
15: nid005601:210676:211245 [0] NCCL INFO Connected all rings
15: nid005601:210677:211246 [1] NCCL INFO Connected all rings
14: nid005600:217720:218280 [0] NCCL INFO Connected all rings
13: nid005595:197883:198485 [0] NCCL INFO Connected all rings
14: nid005600:217721:218278 [1] NCCL INFO Connected all rings
15: nid005601:210679:211247 [3] NCCL INFO Connected all rings
15: nid005601:210678:211248 [2] NCCL INFO Connected all rings
13: nid005595:197884:198486 [1] NCCL INFO Connected all rings
14: nid005600:217723:218281 [3] NCCL INFO Connected all rings
13: nid005595:197886:198488 [3] NCCL INFO Connected all rings
14: nid005600:217722:218279 [2] NCCL INFO Connected all rings
13: nid005595:197885:198487 [2] NCCL INFO Connected all rings
30: nid005936:49908:50482 [0] NCCL INFO Connected all rings
30: nid005936:49909:50480 [1] NCCL INFO Connected all rings
30: nid005936:49911:50481 [3] NCCL INFO Connected all rings
29: nid005932:167680:168242 [0] NCCL INFO Connected all rings
30: nid005936:49910:50483 [2] NCCL INFO Connected all rings
29: nid005932:167681:168244 [1] NCCL INFO Connected all rings
28: nid005929:16031:16585 [1] NCCL INFO Connected all rings
28: nid005929:16030:16584 [0] NCCL INFO Connected all rings
28: nid005929:16033:16586 [3] NCCL INFO Connected all rings
29: nid005932:167683:168245 [3] NCCL INFO Connected all rings
28: nid005929:16032:16583 [2] NCCL INFO Connected all rings
29: nid005932:167682:168243 [2] NCCL INFO Connected all rings
25: nid005919:107462:108038 [0] NCCL INFO Connected all rings
25: nid005919:107465:108039 [3] NCCL INFO Connected all rings
25: nid005919:107463:108041 [1] NCCL INFO Connected all rings
25: nid005919:107464:108040 [2] NCCL INFO Connected all rings
24: nid005918:92504:93095 [0] NCCL INFO Connected all rings
24: nid005918:92507:93092 [3] NCCL INFO Connected all rings
24: nid005918:92506:93093 [2] NCCL INFO Connected all rings
23: nid005917:276885:277440 [0] NCCL INFO Connected all rings
23: nid005917:276888:277437 [3] NCCL INFO Connected all rings
24: nid005918:92505:93094 [1] NCCL INFO Connected all rings
23: nid005917:276887:277438 [2] NCCL INFO Connected all rings
23: nid005917:276886:277439 [1] NCCL INFO Connected all rings
 0: [2025-06-27 21:03:01,877] [INFO] [partition_parameters.py:348:__exit__] finished initializing model - num_params = 729, num_elems = 8.29B
27: Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.80s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.80s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.80s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.78s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.62s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|████
19: Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.81s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.80s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.80s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.79s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.62s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|████
23: Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.79s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.80s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.80s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.78s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.62s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|████
 9: Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.81s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.80s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.80s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.79s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|████
26: Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.80s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.80s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.80s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.76s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.61s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|████
25: Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.80s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.80s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.80s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.79s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|████
 2: Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.81s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.80s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.81s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.79s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.11s/it]Loading checkpoint shards:  60%|████
 1: Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.81s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.81s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.81s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.80s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.64s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.11s/it]Loading checkpoint shards:  60%|████
21: Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.79s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.79s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.80s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.80s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|████
17: Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.80s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.79s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.79s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.78s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.62s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|████
14: Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.80s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.80s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.80s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.79s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|████
30: Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.79s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.80s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.80s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.78s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.62s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|████
13: Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.81s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.79s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.79s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:22,  5.74s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.62s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.61s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|████
 3: Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.77s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.79s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.78s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.81s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.62s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.62s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|████
31: Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.80s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.79s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.78s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.78s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.62s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.62s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|████
11: Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.81s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.80s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.80s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.80s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|████
22: Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.80s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.79s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.78s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.80s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.62s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|████
28: Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.80s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.79s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.78s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.79s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.62s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.62s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.62s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|████
15: Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.80s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.79s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.79s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.78s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.62s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|████
 5: Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.81s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.79s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.75s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.79s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.61s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.62s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.62s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|████
24: Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.80s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.78s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.79s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.78s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.62s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.62s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|████
12: Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.80s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.79s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.78s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.79s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.62s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.62s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|████
 7: Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.81s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.80s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.80s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.80s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|████
 6: Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.79s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.79s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.79s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:22,  5.74s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.61s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|████
 8: Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.79s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.79s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.79s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.79s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|████
29: Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.80s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.79s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.79s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:22,  5.74s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.61s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|████
18: Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.80s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.80s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.78s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:22,  5.75s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.62s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.61s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|████
16: Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.79s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.79s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.80s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.78s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.62s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|████
10: Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.80s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.79s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.79s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.78s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.62s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|████
 0: Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.80s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.78s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.78s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.84s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.62s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.62s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.66s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|████
20: Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.78s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.78s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.80s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.80s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.62s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.62s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|████
 4: Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.80s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.80s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.79s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:05<00:23,  5.78s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.63s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:09<00:13,  4.62s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|████
19: █    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
19: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
19: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it][INFO|modeling_utils.py:4930] 2025-06-27 21:03:20,453 >> All model checkpoint weights were used when initializing Qwen2_5_VLForConditionalGeneration.
19: 
19: 
27: █    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
19: [INFO|modeling_utils.py:4938] 2025-06-27 21:03:20,453 >> All the weights of Qwen2_5_VLForConditionalGeneration were initialized from the model checkpoint at Qwen/Qwen2.5-VL-7B-Instruct.
19: If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2_5_VLForConditionalGeneration for predictions without further training.
25: █    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
27: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
27: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
19: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
 7: █    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
29: █    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.09s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
27: [INFO|modeling_utils.py:4930] 2025-06-27 21:03:20,454 >> All model checkpoint weights were used when initializing Qwen2_5_VLForConditionalGeneration.
27: 
29: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
 7: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
25: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
23: █    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
27: [INFO|modeling_utils.py:4938] 2025-06-27 21:03:20,454 >> All the weights of Qwen2_5_VLForConditionalGeneration were initialized from the model checkpoint at Qwen/Qwen2.5-VL-7B-Instruct.
27: If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2_5_VLForConditionalGeneration for predictions without further training.
26: █    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.09s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
28: █    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
13: █    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.09s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
25: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
23: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
26: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
26: [INFO|modeling_utils.py:4930] 2025-06-27 21:03:20,454 >> All model checkpoint weights were used when initializing Qwen2_5_VLForConditionalGeneration.
26: 
 5: █    | 3/5 [00:13<00:08,  4.09s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
28: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
22: █    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
26: [INFO|modeling_utils.py:4938] 2025-06-27 21:03:20,454 >> All the weights of Qwen2_5_VLForConditionalGeneration were initialized from the model checkpoint at Qwen/Qwen2.5-VL-7B-Instruct.
26: If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2_5_VLForConditionalGeneration for predictions without further training.
29: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
 9: █    | 3/5 [00:13<00:08,  4.11s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
 7: [INFO|modeling_utils.py:4930] 2025-06-27 21:03:20,454 >> All model checkpoint weights were used when initializing Qwen2_5_VLForConditionalGeneration.
 7: 
23: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
28: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
 9: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
 9: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
 7: [INFO|modeling_utils.py:4938] 2025-06-27 21:03:20,454 >> All the weights of Qwen2_5_VLForConditionalGeneration were initialized from the model checkpoint at Qwen/Qwen2.5-VL-7B-Instruct.
 7: If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2_5_VLForConditionalGeneration for predictions without further training.
13: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
 3: █    | 3/5 [00:13<00:08,  4.11s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.70s/it]
30: █    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
30: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
 7: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
13: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
28: [INFO|modeling_utils.py:4930] 2025-06-27 21:03:20,454 >> All model checkpoint weights were used when initializing Qwen2_5_VLForConditionalGeneration.
28: 
 9: [INFO|modeling_utils.py:4930] 2025-06-27 21:03:20,454 >> All model checkpoint weights were used when initializing Qwen2_5_VLForConditionalGeneration.
 9: 
 5: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.70s/it]
28: [INFO|modeling_utils.py:4938] 2025-06-27 21:03:20,454 >> All the weights of Qwen2_5_VLForConditionalGeneration were initialized from the model checkpoint at Qwen/Qwen2.5-VL-7B-Instruct.
28: If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2_5_VLForConditionalGeneration for predictions without further training.
11: █    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
 9: [INFO|modeling_utils.py:4938] 2025-06-27 21:03:20,454 >> All the weights of Qwen2_5_VLForConditionalGeneration were initialized from the model checkpoint at Qwen/Qwen2.5-VL-7B-Instruct.
 9: If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2_5_VLForConditionalGeneration for predictions without further training.
25: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
29: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.70s/it]
 9: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
23: [INFO|modeling_utils.py:4930] 2025-06-27 21:03:20,454 >> All model checkpoint weights were used when initializing Qwen2_5_VLForConditionalGeneration.
23: 
13: [INFO|modeling_utils.py:4930] 2025-06-27 21:03:20,454 >> All model checkpoint weights were used when initializing Qwen2_5_VLForConditionalGeneration.
13: 
30: [INFO|modeling_utils.py:4930] 2025-06-27 21:03:20,454 >> All model checkpoint weights were used when initializing Qwen2_5_VLForConditionalGeneration.
30: 
 0: █    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.13s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
26: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
13: [INFO|modeling_utils.py:4938] 2025-06-27 21:03:20,454 >> All the weights of Qwen2_5_VLForConditionalGeneration were initialized from the model checkpoint at Qwen/Qwen2.5-VL-7B-Instruct.
13: If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2_5_VLForConditionalGeneration for predictions without further training.
25: [INFO|modeling_utils.py:4930] 2025-06-27 21:03:20,454 >> All model checkpoint weights were used when initializing Qwen2_5_VLForConditionalGeneration.
25: 
25: [INFO|modeling_utils.py:4938] 2025-06-27 21:03:20,454 >> All the weights of Qwen2_5_VLForConditionalGeneration were initialized from the model checkpoint at Qwen/Qwen2.5-VL-7B-Instruct.
25: If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2_5_VLForConditionalGeneration for predictions without further training.
23: [INFO|modeling_utils.py:4938] 2025-06-27 21:03:20,454 >> All the weights of Qwen2_5_VLForConditionalGeneration were initialized from the model checkpoint at Qwen/Qwen2.5-VL-7B-Instruct.
23: If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2_5_VLForConditionalGeneration for predictions without further training.
23: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
30: [INFO|modeling_utils.py:4938] 2025-06-27 21:03:20,454 >> All the weights of Qwen2_5_VLForConditionalGeneration were initialized from the model checkpoint at Qwen/Qwen2.5-VL-7B-Instruct.
30: If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2_5_VLForConditionalGeneration for predictions without further training.
27: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
22: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
30: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
11: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
22: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
 2: █    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
 2: 
 5: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
 0: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
 1: █    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.64s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
 7: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
29: [INFO|modeling_utils.py:4930] 2025-06-27 21:03:20,454 >> All model checkpoint weights were used when initializing Qwen2_5_VLForConditionalGeneration.
29: 
 1: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
11: [INFO|modeling_utils.py:4930] 2025-06-27 21:03:20,454 >> All model checkpoint weights were used when initializing Qwen2_5_VLForConditionalGeneration.
11: 
 1: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
17: █    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
29: [INFO|modeling_utils.py:4938] 2025-06-27 21:03:20,454 >> All the weights of Qwen2_5_VLForConditionalGeneration were initialized from the model checkpoint at Qwen/Qwen2.5-VL-7B-Instruct.
29: If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2_5_VLForConditionalGeneration for predictions without further training.
 2: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
28: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
11: [INFO|modeling_utils.py:4938] 2025-06-27 21:03:20,454 >> All the weights of Qwen2_5_VLForConditionalGeneration were initialized from the model checkpoint at Qwen/Qwen2.5-VL-7B-Instruct.
11: If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2_5_VLForConditionalGeneration for predictions without further training.
 2: [INFO|modeling_utils.py:4930] 2025-06-27 21:03:20,454 >> All model checkpoint weights were used when initializing Qwen2_5_VLForConditionalGeneration.
 2: 
 1: [INFO|modeling_utils.py:4930] 2025-06-27 21:03:20,454 >> All model checkpoint weights were used when initializing Qwen2_5_VLForConditionalGeneration.
 1: 
30: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
 2: [INFO|modeling_utils.py:4938] 2025-06-27 21:03:20,455 >> All the weights of Qwen2_5_VLForConditionalGeneration were initialized from the model checkpoint at Qwen/Qwen2.5-VL-7B-Instruct.
 2: If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2_5_VLForConditionalGeneration for predictions without further training.
15: █    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
10: █    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
 1: [INFO|modeling_utils.py:4938] 2025-06-27 21:03:20,455 >> All the weights of Qwen2_5_VLForConditionalGeneration were initialized from the model checkpoint at Qwen/Qwen2.5-VL-7B-Instruct.
 1: If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2_5_VLForConditionalGeneration for predictions without further training.
 3: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
11: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
31: █    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
31: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
10: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
 5: [INFO|modeling_utils.py:4930] 2025-06-27 21:03:20,454 >> All model checkpoint weights were used when initializing Qwen2_5_VLForConditionalGeneration.
 5: 
15: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
31: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
15: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
 5: [INFO|modeling_utils.py:4938] 2025-06-27 21:03:20,455 >> All the weights of Qwen2_5_VLForConditionalGeneration were initialized from the model checkpoint at Qwen/Qwen2.5-VL-7B-Instruct.
 5: If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2_5_VLForConditionalGeneration for predictions without further training.
12: █    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
 3: [INFO|modeling_utils.py:4930] 2025-06-27 21:03:20,455 >> All model checkpoint weights were used when initializing Qwen2_5_VLForConditionalGeneration.
 3: 
31: [INFO|modeling_utils.py:4930] 2025-06-27 21:03:20,455 >> All model checkpoint weights were used when initializing Qwen2_5_VLForConditionalGeneration.
31: 
 2: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
21: █    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
31: [INFO|modeling_utils.py:4938] 2025-06-27 21:03:20,455 >> All the weights of Qwen2_5_VLForConditionalGeneration were initialized from the model checkpoint at Qwen/Qwen2.5-VL-7B-Instruct.
31: If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2_5_VLForConditionalGeneration for predictions without further training.
21: 
26: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.70s/it]
 3: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
 5: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
 4: █    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
 3: [INFO|modeling_utils.py:4938] 2025-06-27 21:03:20,455 >> All the weights of Qwen2_5_VLForConditionalGeneration were initialized from the model checkpoint at Qwen/Qwen2.5-VL-7B-Instruct.
 3: If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2_5_VLForConditionalGeneration for predictions without further training.
22: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
10: [INFO|modeling_utils.py:4930] 2025-06-27 21:03:20,455 >> All model checkpoint weights were used when initializing Qwen2_5_VLForConditionalGeneration.
10: 
10: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it][INFO|modeling_utils.py:4938] 2025-06-27 21:03:20,455 >> All the weights of Qwen2_5_VLForConditionalGeneration were initialized from the model checkpoint at Qwen/Qwen2.5-VL-7B-Instruct.
10: If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2_5_VLForConditionalGeneration for predictions without further training.
 4: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
21: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
10: 
 4: [INFO|modeling_utils.py:4930] 2025-06-27 21:03:20,455 >> All model checkpoint weights were used when initializing Qwen2_5_VLForConditionalGeneration.
 4: 
 4: [INFO|modeling_utils.py:4938] 2025-06-27 21:03:20,455 >> All the weights of Qwen2_5_VLForConditionalGeneration were initialized from the model checkpoint at Qwen/Qwen2.5-VL-7B-Instruct.
 4: If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2_5_VLForConditionalGeneration for predictions without further training.
14: █    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
21: [INFO|modeling_utils.py:4930] 2025-06-27 21:03:20,455 >> All model checkpoint weights were used when initializing Qwen2_5_VLForConditionalGeneration.
21: 
18: █    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.09s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
18: 
24: █    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
12: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
16: █    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
12: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
 4: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
21: [INFO|modeling_utils.py:4938] 2025-06-27 21:03:20,455 >> All the weights of Qwen2_5_VLForConditionalGeneration were initialized from the model checkpoint at Qwen/Qwen2.5-VL-7B-Instruct.
21: If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2_5_VLForConditionalGeneration for predictions without further training.
24: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
20: █    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
18: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
24: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
13: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.70s/it]
18: [INFO|modeling_utils.py:4930] 2025-06-27 21:03:20,455 >> All model checkpoint weights were used when initializing Qwen2_5_VLForConditionalGeneration.
18: 
11: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
22: [INFO|modeling_utils.py:4930] 2025-06-27 21:03:20,455 >> All model checkpoint weights were used when initializing Qwen2_5_VLForConditionalGeneration.
22: 
 1: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
17: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
20: 
18: [INFO|modeling_utils.py:4938] 2025-06-27 21:03:20,455 >> All the weights of Qwen2_5_VLForConditionalGeneration were initialized from the model checkpoint at Qwen/Qwen2.5-VL-7B-Instruct.
18: If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2_5_VLForConditionalGeneration for predictions without further training.
22: [INFO|modeling_utils.py:4938] 2025-06-27 21:03:20,455 >> All the weights of Qwen2_5_VLForConditionalGeneration were initialized from the model checkpoint at Qwen/Qwen2.5-VL-7B-Instruct.
22: If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2_5_VLForConditionalGeneration for predictions without further training.
17: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
20: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
31: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
16: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
 4: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
16: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
 3: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
14: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
24: [INFO|modeling_utils.py:4930] 2025-06-27 21:03:20,455 >> All model checkpoint weights were used when initializing Qwen2_5_VLForConditionalGeneration.
24: 
12: [INFO|modeling_utils.py:4930] 2025-06-27 21:03:20,455 >> All model checkpoint weights were used when initializing Qwen2_5_VLForConditionalGeneration.
12: 
24: [INFO|modeling_utils.py:4938] 2025-06-27 21:03:20,455 >> All the weights of Qwen2_5_VLForConditionalGeneration were initialized from the model checkpoint at Qwen/Qwen2.5-VL-7B-Instruct.
24: If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2_5_VLForConditionalGeneration for predictions without further training.
12: [INFO|modeling_utils.py:4938] 2025-06-27 21:03:20,455 >> All the weights of Qwen2_5_VLForConditionalGeneration were initialized from the model checkpoint at Qwen/Qwen2.5-VL-7B-Instruct.
12: If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2_5_VLForConditionalGeneration for predictions without further training.
21: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
16: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
12: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
14: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
15: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
17: [INFO|modeling_utils.py:4930] 2025-06-27 21:03:20,455 >> All model checkpoint weights were used when initializing Qwen2_5_VLForConditionalGeneration.
17: 
18: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.70s/it]
17: [INFO|modeling_utils.py:4938] 2025-06-27 21:03:20,455 >> All the weights of Qwen2_5_VLForConditionalGeneration were initialized from the model checkpoint at Qwen/Qwen2.5-VL-7B-Instruct.
17: If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2_5_VLForConditionalGeneration for predictions without further training.
24: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
16: [INFO|modeling_utils.py:4930] 2025-06-27 21:03:20,455 >> All model checkpoint weights were used when initializing Qwen2_5_VLForConditionalGeneration.
16: 
 8: █    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
10: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
16: [INFO|modeling_utils.py:4938] 2025-06-27 21:03:20,455 >> All the weights of Qwen2_5_VLForConditionalGeneration were initialized from the model checkpoint at Qwen/Qwen2.5-VL-7B-Instruct.
16: If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2_5_VLForConditionalGeneration for predictions without further training.
14: [INFO|modeling_utils.py:4930] 2025-06-27 21:03:20,455 >> All model checkpoint weights were used when initializing Qwen2_5_VLForConditionalGeneration.
14: 
14: [INFO|modeling_utils.py:4938] 2025-06-27 21:03:20,455 >> All the weights of Qwen2_5_VLForConditionalGeneration were initialized from the model checkpoint at Qwen/Qwen2.5-VL-7B-Instruct.
14: If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2_5_VLForConditionalGeneration for predictions without further training.
 8: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
20: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
 6: █    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.10s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:13<00:08,  4.09s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.63s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
 8: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
 6: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
 6: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
15: [INFO|modeling_utils.py:4930] 2025-06-27 21:03:20,455 >> All model checkpoint weights were used when initializing Qwen2_5_VLForConditionalGeneration.
15: 
15: [INFO|modeling_utils.py:4938] 2025-06-27 21:03:20,456 >> All the weights of Qwen2_5_VLForConditionalGeneration were initialized from the model checkpoint at Qwen/Qwen2.5-VL-7B-Instruct.
15: If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2_5_VLForConditionalGeneration for predictions without further training.
 6: [INFO|modeling_utils.py:4930] 2025-06-27 21:03:20,456 >> All model checkpoint weights were used when initializing Qwen2_5_VLForConditionalGeneration.
 6: 
17: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
 6: [INFO|modeling_utils.py:4938] 2025-06-27 21:03:20,456 >> All the weights of Qwen2_5_VLForConditionalGeneration were initialized from the model checkpoint at Qwen/Qwen2.5-VL-7B-Instruct.
 6: If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2_5_VLForConditionalGeneration for predictions without further training.
20: [INFO|modeling_utils.py:4930] 2025-06-27 21:03:20,456 >> All model checkpoint weights were used when initializing Qwen2_5_VLForConditionalGeneration.
20: 
20: [INFO|modeling_utils.py:4938] 2025-06-27 21:03:20,456 >> All the weights of Qwen2_5_VLForConditionalGeneration were initialized from the model checkpoint at Qwen/Qwen2.5-VL-7B-Instruct.
20: If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2_5_VLForConditionalGeneration for predictions without further training.
14: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
 6: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.70s/it]
 8: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
 8: [INFO|modeling_utils.py:4930] 2025-06-27 21:03:20,456 >> All model checkpoint weights were used when initializing Qwen2_5_VLForConditionalGeneration.
 8: 
 8: [INFO|modeling_utils.py:4938] 2025-06-27 21:03:20,456 >> All the weights of Qwen2_5_VLForConditionalGeneration were initialized from the model checkpoint at Qwen/Qwen2.5-VL-7B-Instruct.
 8: If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2_5_VLForConditionalGeneration for predictions without further training.
 0: Loading checkpoint shards: 100%|██████████| 5/5 [00:18<00:00,  3.71s/it]
20: [INFO|configuration_utils.py:1097] 2025-06-27 21:03:20,599 >> loading configuration file generation_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/generation_config.json
20: [INFO|configuration_utils.py:1142] 2025-06-27 21:03:20,599 >> Generate config GenerationConfig {
20:   "bos_token_id": 151643,
20:   "do_sample": true,
20:   "eos_token_id": [
20:     151645,
20:     151643
20:   ],
20:   "pad_token_id": 151643,
20:   "repetition_penalty": 1.05,
20:   "temperature": 1e-06
20: }
20: 
10: [INFO|configuration_utils.py:1097] 2025-06-27 21:03:20,600 >> loading configuration file generation_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/generation_config.json
30: [INFO|configuration_utils.py:1097] 2025-06-27 21:03:20,600 >> loading configuration file generation_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/generation_config.json
11: [INFO|configuration_utils.py:1097] 2025-06-27 21:03:20,600 >> loading configuration file generation_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/generation_config.json
 8: [INFO|configuration_utils.py:1097] 2025-06-27 21:03:20,600 >> loading configuration file generation_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/generation_config.json
 3: [INFO|configuration_utils.py:1097] 2025-06-27 21:03:20,600 >> loading configuration file generation_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/generation_config.json
27: [INFO|configuration_utils.py:1097] 2025-06-27 21:03:20,600 >> loading configuration file generation_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/generation_config.json
23: [INFO|configuration_utils.py:1097] 2025-06-27 21:03:20,600 >> loading configuration file generation_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/generation_config.json
 4: [INFO|configuration_utils.py:1097] 2025-06-27 21:03:20,600 >> loading configuration file generation_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/generation_config.json
26: [INFO|configuration_utils.py:1097] 2025-06-27 21:03:20,600 >> loading configuration file generation_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/generation_config.json
 6: [INFO|configuration_utils.py:1097] 2025-06-27 21:03:20,600 >> loading configuration file generation_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/generation_config.json
 7: [INFO|configuration_utils.py:1097] 2025-06-27 21:03:20,600 >> loading configuration file generation_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/generation_config.json
 5: [INFO|configuration_utils.py:1097] 2025-06-27 21:03:20,600 >> loading configuration file generation_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/generation_config.json
14: [INFO|configuration_utils.py:1097] 2025-06-27 21:03:20,600 >> loading configuration file generation_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/generation_config.json
25: [INFO|configuration_utils.py:1097] 2025-06-27 21:03:20,600 >> loading configuration file generation_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/generation_config.json
31: [INFO|configuration_utils.py:1097] 2025-06-27 21:03:20,600 >> loading configuration file generation_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/generation_config.json
17: [INFO|configuration_utils.py:1097] 2025-06-27 21:03:20,600 >> loading configuration file generation_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/generation_config.json
10: [INFO|configuration_utils.py:1142] 2025-06-27 21:03:20,600 >> Generate config GenerationConfig {
10:   "bos_token_id": 151643,
10:   "do_sample": true,
10:   "eos_token_id": [
10:     151645,
10:     151643
10:   ],
10:   "pad_token_id": 151643,
10:   "repetition_penalty": 1.05,
10:   "temperature": 1e-06
10: }
10: 
11: [INFO|configuration_utils.py:1142] 2025-06-27 21:03:20,600 >> Generate config GenerationConfig {
11:   "bos_token_id": 151643,
11:   "do_sample": true,
11:   "eos_token_id": [
11:     151645,
11:     151643
11:   ],
11:   "pad_token_id": 151643,
11:   "repetition_penalty": 1.05,
11:   "temperature": 1e-06
11: }
11: 
 1: [INFO|configuration_utils.py:1097] 2025-06-27 21:03:20,600 >> loading configuration file generation_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/generation_config.json
18: [INFO|configuration_utils.py:1097] 2025-06-27 21:03:20,600 >> loading configuration file generation_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/generation_config.json
19: [INFO|configuration_utils.py:1097] 2025-06-27 21:03:20,600 >> loading configuration file generation_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/generation_config.json
30: [INFO|configuration_utils.py:1142] 2025-06-27 21:03:20,600 >> Generate config GenerationConfig {
30:   "bos_token_id": 151643,
30:   "do_sample": true,
30:   "eos_token_id": [
30:     151645,
30:     151643
30:   ],
30:   "pad_token_id": 151643,
30:   "repetition_penalty": 1.05,
30:   "temperature": 1e-06
30: }
30: 
24: [INFO|configuration_utils.py:1097] 2025-06-27 21:03:20,600 >> loading configuration file generation_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/generation_config.json
 2: [INFO|configuration_utils.py:1097] 2025-06-27 21:03:20,600 >> loading configuration file generation_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/generation_config.json
 3: [INFO|configuration_utils.py:1142] 2025-06-27 21:03:20,600 >> Generate config GenerationConfig {
 3:   "bos_token_id": 151643,
 3:   "do_sample": true,
 3:   "eos_token_id": [
 3:     151645,
 3:     151643
 3:   ],
 3:   "pad_token_id": 151643,
 3:   "repetition_penalty": 1.05,
 3:   "temperature": 1e-06
 3: }
 3: 
21: [INFO|configuration_utils.py:1097] 2025-06-27 21:03:20,600 >> loading configuration file generation_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/generation_config.json
27: [INFO|configuration_utils.py:1142] 2025-06-27 21:03:20,600 >> Generate config GenerationConfig {
27:   "bos_token_id": 151643,
27:   "do_sample": true,
27:   "eos_token_id": [
27:     151645,
27:     151643
27:   ],
27:   "pad_token_id": 151643,
27:   "repetition_penalty": 1.05,
27:   "temperature": 1e-06
27: }
27: 
 8: [INFO|configuration_utils.py:1142] 2025-06-27 21:03:20,600 >> Generate config GenerationConfig {
 8:   "bos_token_id": 151643,
 8:   "do_sample": true,
 8:   "eos_token_id": [
 8:     151645,
 8:     151643
 8:   ],
 8:   "pad_token_id": 151643,
 8:   "repetition_penalty": 1.05,
 8:   "temperature": 1e-06
 8: }
 8: 
22: [INFO|configuration_utils.py:1097] 2025-06-27 21:03:20,600 >> loading configuration file generation_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/generation_config.json
 4: [INFO|configuration_utils.py:1142] 2025-06-27 21:03:20,600 >> Generate config GenerationConfig {
 4:   "bos_token_id": 151643,
 4:   "do_sample": true,
 4:   "eos_token_id": [
 4:     151645,
 4:     151643
 4:   ],
 4:   "pad_token_id": 151643,
 4:   "repetition_penalty": 1.05,
 4:   "temperature": 1e-06
 4: }
 4: 
26: [INFO|configuration_utils.py:1142] 2025-06-27 21:03:20,600 >> Generate config GenerationConfig {
26:   "bos_token_id": 151643,
26:   "do_sample": true,
26:   "eos_token_id": [
26:     151645,
26:     151643
26:   ],
26:   "pad_token_id": 151643,
26:   "repetition_penalty": 1.05,
26:   "temperature": 1e-06
26: }
26: 
14: [INFO|configuration_utils.py:1142] 2025-06-27 21:03:20,600 >> Generate config GenerationConfig {
14:   "bos_token_id": 151643,
14:   "do_sample": true,
14:   "eos_token_id": [
14:     151645,
14:     151643
14:   ],
14:   "pad_token_id": 151643,
14:   "repetition_penalty": 1.05,
14:   "temperature": 1e-06
14: }
14: 
 6: [INFO|configuration_utils.py:1142] 2025-06-27 21:03:20,600 >> Generate config GenerationConfig {
 6:   "bos_token_id": 151643,
 6:   "do_sample": true,
 6:   "eos_token_id": [
 6:     151645,
 6:     151643
 6:   ],
 6:   "pad_token_id": 151643,
 6:   "repetition_penalty": 1.05,
 6:   "temperature": 1e-06
 6: }
 6: 
25: [INFO|configuration_utils.py:1142] 2025-06-27 21:03:20,600 >> Generate config GenerationConfig {
25:   "bos_token_id": 151643,
25:   "do_sample": true,
25:   "eos_token_id": [
25:     151645,
25:     151643
25:   ],
25:   "pad_token_id": 151643,
25:   "repetition_penalty": 1.05,
25:   "temperature": 1e-06
25: }
25: 
28: [INFO|configuration_utils.py:1097] 2025-06-27 21:03:20,600 >> loading configuration file generation_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/generation_config.json
15: [INFO|configuration_utils.py:1097] 2025-06-27 21:03:20,600 >> loading configuration file generation_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/generation_config.json
31: [INFO|configuration_utils.py:1142] 2025-06-27 21:03:20,600 >> Generate config GenerationConfig {
31:   "bos_token_id": 151643,
31:   "do_sample": true,
31:   "eos_token_id": [
31:     151645,
31:     151643
31:   ],
31:   "pad_token_id": 151643,
31:   "repetition_penalty": 1.05,
31:   "temperature": 1e-06
31: }
31: 
 9: [INFO|configuration_utils.py:1097] 2025-06-27 21:03:20,600 >> loading configuration file generation_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/generation_config.json
17: [INFO|configuration_utils.py:1142] 2025-06-27 21:03:20,600 >> Generate config GenerationConfig {
17:   "bos_token_id": 151643,
17:   "do_sample": true,
17:   "eos_token_id": [
17:     151645,
17:     151643
17:   ],
17:   "pad_token_id": 151643,
17:   "repetition_penalty": 1.05,
17:   "temperature": 1e-06
17: }
17: 
 7: [INFO|configuration_utils.py:1142] 2025-06-27 21:03:20,600 >> Generate config GenerationConfig {
 7:   "bos_token_id": 151643,
 7:   "do_sample": true,
 7:   "eos_token_id": [
 7:     151645,
 7:     151643
 7:   ],
 7:   "pad_token_id": 151643,
 7:   "repetition_penalty": 1.05,
 7:   "temperature": 1e-06
 7: }
 7: 
20: [INFO|2025-06-27 21:03:20] llamafactory.model.model_utils.checkpointing:143 >> Gradient checkpointing enabled.
13: [INFO|configuration_utils.py:1097] 2025-06-27 21:03:20,600 >> loading configuration file generation_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/generation_config.json
 5: [INFO|configuration_utils.py:1142] 2025-06-27 21:03:20,600 >> Generate config GenerationConfig {
 5:   "bos_token_id": 151643,
 5:   "do_sample": true,
 5:   "eos_token_id": [
 5:     151645,
 5:     151643
 5:   ],
 5:   "pad_token_id": 151643,
 5:   "repetition_penalty": 1.05,
 5:   "temperature": 1e-06
 5: }
 5: 
20: [INFO|2025-06-27 21:03:20] llamafactory.model.model_utils.attention:143 >> Using torch SDPA for faster training and inference.
23: [INFO|configuration_utils.py:1142] 2025-06-27 21:03:20,600 >> Generate config GenerationConfig {
23:   "bos_token_id": 151643,
23:   "do_sample": true,
23:   "eos_token_id": [
23:     151645,
23:     151643
23:   ],
23:   "pad_token_id": 151643,
23:   "repetition_penalty": 1.05,
23:   "temperature": 1e-06
23: }
23: 
20: [INFO|2025-06-27 21:03:20] llamafactory.model.adapter:143 >> DeepSpeed ZeRO3 detected, remaining trainable params in float32.
 2: [INFO|configuration_utils.py:1142] 2025-06-27 21:03:20,600 >> Generate config GenerationConfig {
 2:   "bos_token_id": 151643,
 2:   "do_sample": true,
 2:   "eos_token_id": [
 2:     151645,
 2:     151643
 2:   ],
 2:   "pad_token_id": 151643,
 2:   "repetition_penalty": 1.05,
 2:   "temperature": 1e-06
 2: }
 2: 
20: [INFO|2025-06-27 21:03:20] llamafactory.model.adapter:143 >> Fine-tuning method: Full
 1: [INFO|configuration_utils.py:1142] 2025-06-27 21:03:20,600 >> Generate config GenerationConfig {
 1:   "bos_token_id": 151643,
 1:   "do_sample": true,
 1:   "eos_token_id": [
 1:     151645,
 1:     151643
 1:   ],
 1:   "pad_token_id": 151643,
 1:   "repetition_penalty": 1.05,
 1:   "temperature": 1e-06
 1: }
 1: 
18: [INFO|configuration_utils.py:1142] 2025-06-27 21:03:20,600 >> Generate config GenerationConfig {
18:   "bos_token_id": 151643,
18:   "do_sample": true,
18:   "eos_token_id": [
18:     151645,
18:     151643
18:   ],
18:   "pad_token_id": 151643,
18:   "repetition_penalty": 1.05,
18:   "temperature": 1e-06
18: }
18: 
24: [INFO|configuration_utils.py:1142] 2025-06-27 21:03:20,600 >> Generate config GenerationConfig {
24:   "bos_token_id": 151643,
24:   "do_sample": true,
24:   "eos_token_id": [
24:     151645,
24:     151643
24:   ],
24:   "pad_token_id": 151643,
24:   "repetition_penalty": 1.05,
24:   "temperature": 1e-06
24: }
24: 
19: [INFO|configuration_utils.py:1142] 2025-06-27 21:03:20,600 >> Generate config GenerationConfig {
19:   "bos_token_id": 151643,
19:   "do_sample": true,
19:   "eos_token_id": [
19:     151645,
19:     151643
19:   ],
19:   "pad_token_id": 151643,
19:   "repetition_penalty": 1.05,
19:   "temperature": 1e-06
19: }
19: 
16: [INFO|configuration_utils.py:1097] 2025-06-27 21:03:20,600 >> loading configuration file generation_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/generation_config.json
21: [INFO|configuration_utils.py:1142] 2025-06-27 21:03:20,601 >> Generate config GenerationConfig {
21:   "bos_token_id": 151643,
21:   "do_sample": true,
21:   "eos_token_id": [
21:     151645,
21:     151643
21:   ],
21:   "pad_token_id": 151643,
21:   "repetition_penalty": 1.05,
21:   "temperature": 1e-06
21: }
21: 
28: [INFO|configuration_utils.py:1142] 2025-06-27 21:03:20,601 >> Generate config GenerationConfig {
28:   "bos_token_id": 151643,
28:   "do_sample": true,
28:   "eos_token_id": [
28:     151645,
28:     151643
28:   ],
28:   "pad_token_id": 151643,
28:   "repetition_penalty": 1.05,
28:   "temperature": 1e-06
28: }
28: 
13: [INFO|configuration_utils.py:1142] 2025-06-27 21:03:20,601 >> Generate config GenerationConfig {
13:   "bos_token_id": 151643,
13:   "do_sample": true,
13:   "eos_token_id": [
13:     151645,
13:     151643
13:   ],
13:   "pad_token_id": 151643,
13:   "repetition_penalty": 1.05,
13:   "temperature": 1e-06
13: }
13: 
22: [INFO|configuration_utils.py:1142] 2025-06-27 21:03:20,601 >> Generate config GenerationConfig {
22:   "bos_token_id": 151643,
22:   "do_sample": true,
22:   "eos_token_id": [
22:     151645,
22:     151643
22:   ],
22:   "pad_token_id": 151643,
22:   "repetition_penalty": 1.05,
22:   "temperature": 1e-06
22: }
22: 
15: [INFO|configuration_utils.py:1142] 2025-06-27 21:03:20,601 >> Generate config GenerationConfig {
15:   "bos_token_id": 151643,
15:   "do_sample": true,
15:   "eos_token_id": [
15:     151645,
15:     151643
15:   ],
15:   "pad_token_id": 151643,
15:   "repetition_penalty": 1.05,
15:   "temperature": 1e-06
15: }
15: 
 9: [INFO|configuration_utils.py:1142] 2025-06-27 21:03:20,601 >> Generate config GenerationConfig {
 9:   "bos_token_id": 151643,
 9:   "do_sample": true,
 9:   "eos_token_id": [
 9:     151645,
 9:     151643
 9:   ],
 9:   "pad_token_id": 151643,
 9:   "repetition_penalty": 1.05,
 9:   "temperature": 1e-06
 9: }
 9: 
16: [INFO|configuration_utils.py:1142] 2025-06-27 21:03:20,601 >> Generate config GenerationConfig {
16:   "bos_token_id": 151643,
16:   "do_sample": true,
16:   "eos_token_id": [
16:     151645,
16:     151643
16:   ],
16:   "pad_token_id": 151643,
16:   "repetition_penalty": 1.05,
16:   "temperature": 1e-06
16: }
16: 
10: [INFO|2025-06-27 21:03:20] llamafactory.model.model_utils.checkpointing:143 >> Gradient checkpointing enabled.
10: [INFO|2025-06-27 21:03:20] llamafactory.model.model_utils.attention:143 >> Using torch SDPA for faster training and inference.
11: [INFO|2025-06-27 21:03:20] llamafactory.model.model_utils.checkpointing:143 >> Gradient checkpointing enabled.
 3: [INFO|2025-06-27 21:03:20] llamafactory.model.model_utils.checkpointing:143 >> Gradient checkpointing enabled.
30: [INFO|2025-06-27 21:03:20] llamafactory.model.model_utils.checkpointing:143 >> Gradient checkpointing enabled.
27: [INFO|2025-06-27 21:03:20] llamafactory.model.model_utils.checkpointing:143 >> Gradient checkpointing enabled.
11: [INFO|2025-06-27 21:03:20] llamafactory.model.model_utils.attention:143 >> Using torch SDPA for faster training and inference.
10: [INFO|2025-06-27 21:03:20] llamafactory.model.adapter:143 >> DeepSpeed ZeRO3 detected, remaining trainable params in float32.
 3: [INFO|2025-06-27 21:03:20] llamafactory.model.model_utils.attention:143 >> Using torch SDPA for faster training and inference.
10: [INFO|2025-06-27 21:03:20] llamafactory.model.adapter:143 >> Fine-tuning method: Full
 4: [INFO|2025-06-27 21:03:20] llamafactory.model.model_utils.checkpointing:143 >> Gradient checkpointing enabled.
30: [INFO|2025-06-27 21:03:20] llamafactory.model.model_utils.attention:143 >> Using torch SDPA for faster training and inference.
26: [INFO|2025-06-27 21:03:20] llamafactory.model.model_utils.checkpointing:143 >> Gradient checkpointing enabled.
27: [INFO|2025-06-27 21:03:20] llamafactory.model.model_utils.attention:143 >> Using torch SDPA for faster training and inference.
 6: [INFO|2025-06-27 21:03:20] llamafactory.model.model_utils.checkpointing:143 >> Gradient checkpointing enabled.
 3: [INFO|2025-06-27 21:03:20] llamafactory.model.adapter:143 >> DeepSpeed ZeRO3 detected, remaining trainable params in float32.
11: [INFO|2025-06-27 21:03:20] llamafactory.model.adapter:143 >> DeepSpeed ZeRO3 detected, remaining trainable params in float32.
 4: [INFO|2025-06-27 21:03:20] llamafactory.model.model_utils.attention:143 >> Using torch SDPA for faster training and inference.
26: [INFO|2025-06-27 21:03:20] llamafactory.model.model_utils.attention:143 >> Using torch SDPA for faster training and inference.
30: [INFO|2025-06-27 21:03:20] llamafactory.model.adapter:143 >> DeepSpeed ZeRO3 detected, remaining trainable params in float32.
27: [INFO|2025-06-27 21:03:20] llamafactory.model.adapter:143 >> DeepSpeed ZeRO3 detected, remaining trainable params in float32.
 4: [INFO|2025-06-27 21:03:20] llamafactory.model.adapter:143 >> DeepSpeed ZeRO3 detected, remaining trainable params in float32.
27: [INFO|2025-06-27 21:03:20] llamafactory.model.adapter:143 >> Fine-tuning method: Full
 6: [INFO|2025-06-27 21:03:20] llamafactory.model.model_utils.attention:143 >> Using torch SDPA for faster training and inference.
 3: [INFO|2025-06-27 21:03:20] llamafactory.model.adapter:143 >> Fine-tuning method: Full
14: [INFO|2025-06-27 21:03:20] llamafactory.model.model_utils.checkpointing:143 >> Gradient checkpointing enabled.
11: [INFO|2025-06-27 21:03:20] llamafactory.model.adapter:143 >> Fine-tuning method: Full
 4: [INFO|2025-06-27 21:03:20] llamafactory.model.adapter:143 >> Fine-tuning method: Full
25: [INFO|2025-06-27 21:03:20] llamafactory.model.model_utils.checkpointing:143 >> Gradient checkpointing enabled.
31: [INFO|2025-06-27 21:03:20] llamafactory.model.model_utils.checkpointing:143 >> Gradient checkpointing enabled.
26: [INFO|2025-06-27 21:03:20] llamafactory.model.adapter:143 >> DeepSpeed ZeRO3 detected, remaining trainable params in float32.
25: [INFO|2025-06-27 21:03:20] llamafactory.model.model_utils.attention:143 >> Using torch SDPA for faster training and inference.
30: [INFO|2025-06-27 21:03:20] llamafactory.model.adapter:143 >> Fine-tuning method: Full
26: [INFO|2025-06-27 21:03:20] llamafactory.model.adapter:143 >> Fine-tuning method: Full
 6: [INFO|2025-06-27 21:03:20] llamafactory.model.adapter:143 >> DeepSpeed ZeRO3 detected, remaining trainable params in float32.
 2: [INFO|2025-06-27 21:03:20] llamafactory.model.model_utils.checkpointing:143 >> Gradient checkpointing enabled.
14: [INFO|2025-06-27 21:03:20] llamafactory.model.model_utils.attention:143 >> Using torch SDPA for faster training and inference.
 6: [INFO|2025-06-27 21:03:20] llamafactory.model.adapter:143 >> Fine-tuning method: Full
25: [INFO|2025-06-27 21:03:20] llamafactory.model.adapter:143 >> DeepSpeed ZeRO3 detected, remaining trainable params in float32.
14: [INFO|2025-06-27 21:03:20] llamafactory.model.adapter:143 >> DeepSpeed ZeRO3 detected, remaining trainable params in float32.
 1: [INFO|2025-06-27 21:03:20] llamafactory.model.model_utils.checkpointing:143 >> Gradient checkpointing enabled.
 7: [INFO|2025-06-27 21:03:20] llamafactory.model.model_utils.checkpointing:143 >> Gradient checkpointing enabled.
25: [INFO|2025-06-27 21:03:20] llamafactory.model.adapter:143 >> Fine-tuning method: Full
14: [INFO|2025-06-27 21:03:20] llamafactory.model.adapter:143 >> Fine-tuning method: Full
31: [INFO|2025-06-27 21:03:20] llamafactory.model.model_utils.attention:143 >> Using torch SDPA for faster training and inference.
31: [INFO|2025-06-27 21:03:20] llamafactory.model.adapter:143 >> DeepSpeed ZeRO3 detected, remaining trainable params in float32.
 1: [INFO|2025-06-27 21:03:20] llamafactory.model.model_utils.attention:143 >> Using torch SDPA for faster training and inference.
31: [INFO|2025-06-27 21:03:20] llamafactory.model.adapter:143 >> Fine-tuning method: Full
 2: [INFO|2025-06-27 21:03:20] llamafactory.model.model_utils.attention:143 >> Using torch SDPA for faster training and inference.
 8: [INFO|2025-06-27 21:03:20] llamafactory.model.model_utils.checkpointing:143 >> Gradient checkpointing enabled.
 7: [INFO|2025-06-27 21:03:20] llamafactory.model.model_utils.attention:143 >> Using torch SDPA for faster training and inference.
 5: [INFO|2025-06-27 21:03:20] llamafactory.model.model_utils.checkpointing:143 >> Gradient checkpointing enabled.
 1: [INFO|2025-06-27 21:03:20] llamafactory.model.adapter:143 >> DeepSpeed ZeRO3 detected, remaining trainable params in float32.
 1: [INFO|2025-06-27 21:03:20] llamafactory.model.adapter:143 >> Fine-tuning method: Full
18: [INFO|2025-06-27 21:03:20] llamafactory.model.model_utils.checkpointing:143 >> Gradient checkpointing enabled.
 2: [INFO|2025-06-27 21:03:20] llamafactory.model.adapter:143 >> DeepSpeed ZeRO3 detected, remaining trainable params in float32.
 7: [INFO|2025-06-27 21:03:20] llamafactory.model.adapter:143 >> DeepSpeed ZeRO3 detected, remaining trainable params in float32.
 8: [INFO|2025-06-27 21:03:20] llamafactory.model.model_utils.attention:143 >> Using torch SDPA for faster training and inference.
 2: [INFO|2025-06-27 21:03:20] llamafactory.model.adapter:143 >> Fine-tuning method: Full
 7: [INFO|2025-06-27 21:03:20] llamafactory.model.adapter:143 >> Fine-tuning method: Full
23: [INFO|2025-06-27 21:03:20] llamafactory.model.model_utils.checkpointing:143 >> Gradient checkpointing enabled.
28: [INFO|2025-06-27 21:03:20] llamafactory.model.model_utils.checkpointing:143 >> Gradient checkpointing enabled.
17: [INFO|2025-06-27 21:03:20] llamafactory.model.model_utils.checkpointing:143 >> Gradient checkpointing enabled.
 5: [INFO|2025-06-27 21:03:20] llamafactory.model.model_utils.attention:143 >> Using torch SDPA for faster training and inference.
18: [INFO|2025-06-27 21:03:20] llamafactory.model.model_utils.attention:143 >> Using torch SDPA for faster training and inference.
18: [INFO|2025-06-27 21:03:20] llamafactory.model.adapter:143 >> DeepSpeed ZeRO3 detected, remaining trainable params in float32.
24: [INFO|2025-06-27 21:03:20] llamafactory.model.model_utils.checkpointing:143 >> Gradient checkpointing enabled.
17: [INFO|2025-06-27 21:03:20] llamafactory.model.model_utils.attention:143 >> Using torch SDPA for faster training and inference.
13: [INFO|2025-06-27 21:03:20] llamafactory.model.model_utils.checkpointing:143 >> Gradient checkpointing enabled.
 5: [INFO|2025-06-27 21:03:20] llamafactory.model.adapter:143 >> DeepSpeed ZeRO3 detected, remaining trainable params in float32.
 8: [INFO|2025-06-27 21:03:20] llamafactory.model.adapter:143 >> DeepSpeed ZeRO3 detected, remaining trainable params in float32.
 5: [INFO|2025-06-27 21:03:20] llamafactory.model.adapter:143 >> Fine-tuning method: Full
23: [INFO|2025-06-27 21:03:20] llamafactory.model.model_utils.attention:143 >> Using torch SDPA for faster training and inference.
 8: [INFO|2025-06-27 21:03:20] llamafactory.model.adapter:143 >> Fine-tuning method: Full
23: [INFO|2025-06-27 21:03:20] llamafactory.model.adapter:143 >> DeepSpeed ZeRO3 detected, remaining trainable params in float32.
28: [INFO|2025-06-27 21:03:20] llamafactory.model.model_utils.attention:143 >> Using torch SDPA for faster training and inference.
19: [INFO|2025-06-27 21:03:20] llamafactory.model.model_utils.checkpointing:143 >> Gradient checkpointing enabled.
28: [INFO|2025-06-27 21:03:20] llamafactory.model.adapter:143 >> DeepSpeed ZeRO3 detected, remaining trainable params in float32.
18: [INFO|2025-06-27 21:03:20] llamafactory.model.adapter:143 >> Fine-tuning method: Full
28: [INFO|2025-06-27 21:03:20] llamafactory.model.adapter:143 >> Fine-tuning method: Full
21: [INFO|2025-06-27 21:03:20] llamafactory.model.model_utils.checkpointing:143 >> Gradient checkpointing enabled.
21: [INFO|2025-06-27 21:03:20] llamafactory.model.model_utils.attention:143 >> Using torch SDPA for faster training and inference.
24: [INFO|2025-06-27 21:03:20] llamafactory.model.model_utils.attention:143 >> Using torch SDPA for faster training and inference.
17: [INFO|2025-06-27 21:03:20] llamafactory.model.adapter:143 >> DeepSpeed ZeRO3 detected, remaining trainable params in float32.
24: [INFO|2025-06-27 21:03:20] llamafactory.model.adapter:143 >> DeepSpeed ZeRO3 detected, remaining trainable params in float32.
17: [INFO|2025-06-27 21:03:20] llamafactory.model.adapter:143 >> Fine-tuning method: Full
13: [INFO|2025-06-27 21:03:20] llamafactory.model.model_utils.attention:143 >> Using torch SDPA for faster training and inference.
13: [INFO|2025-06-27 21:03:20] llamafactory.model.adapter:143 >> DeepSpeed ZeRO3 detected, remaining trainable params in float32.
23: [INFO|2025-06-27 21:03:20] llamafactory.model.adapter:143 >> Fine-tuning method: Full
13: [INFO|2025-06-27 21:03:20] llamafactory.model.adapter:143 >> Fine-tuning method: Full
19: [INFO|2025-06-27 21:03:20] llamafactory.model.model_utils.attention:143 >> Using torch SDPA for faster training and inference.
21: [INFO|2025-06-27 21:03:20] llamafactory.model.adapter:143 >> DeepSpeed ZeRO3 detected, remaining trainable params in float32.
21: [INFO|2025-06-27 21:03:20] llamafactory.model.adapter:143 >> Fine-tuning method: Full
24: [INFO|2025-06-27 21:03:20] llamafactory.model.adapter:143 >> Fine-tuning method: Full
19: [INFO|2025-06-27 21:03:20] llamafactory.model.adapter:143 >> DeepSpeed ZeRO3 detected, remaining trainable params in float32.
19: [INFO|2025-06-27 21:03:20] llamafactory.model.adapter:143 >> Fine-tuning method: Full
 9: [INFO|2025-06-27 21:03:20] llamafactory.model.model_utils.checkpointing:143 >> Gradient checkpointing enabled.
15: [INFO|2025-06-27 21:03:20] llamafactory.model.model_utils.checkpointing:143 >> Gradient checkpointing enabled.
16: [INFO|2025-06-27 21:03:20] llamafactory.model.model_utils.checkpointing:143 >> Gradient checkpointing enabled.
 9: [INFO|2025-06-27 21:03:20] llamafactory.model.model_utils.attention:143 >> Using torch SDPA for faster training and inference.
22: [INFO|2025-06-27 21:03:20] llamafactory.model.model_utils.checkpointing:143 >> Gradient checkpointing enabled.
16: [INFO|2025-06-27 21:03:20] llamafactory.model.model_utils.attention:143 >> Using torch SDPA for faster training and inference.
 9: [INFO|2025-06-27 21:03:20] llamafactory.model.adapter:143 >> DeepSpeed ZeRO3 detected, remaining trainable params in float32.
15: [INFO|2025-06-27 21:03:20] llamafactory.model.model_utils.attention:143 >> Using torch SDPA for faster training and inference.
 9: [INFO|2025-06-27 21:03:20] llamafactory.model.adapter:143 >> Fine-tuning method: Full
16: [INFO|2025-06-27 21:03:20] llamafactory.model.adapter:143 >> DeepSpeed ZeRO3 detected, remaining trainable params in float32.
22: [INFO|2025-06-27 21:03:20] llamafactory.model.model_utils.attention:143 >> Using torch SDPA for faster training and inference.
16: [INFO|2025-06-27 21:03:20] llamafactory.model.adapter:143 >> Fine-tuning method: Full
15: [INFO|2025-06-27 21:03:20] llamafactory.model.adapter:143 >> DeepSpeed ZeRO3 detected, remaining trainable params in float32.
15: [INFO|2025-06-27 21:03:20] llamafactory.model.adapter:143 >> Fine-tuning method: Full
22: [INFO|2025-06-27 21:03:20] llamafactory.model.adapter:143 >> DeepSpeed ZeRO3 detected, remaining trainable params in float32.
22: [INFO|2025-06-27 21:03:20] llamafactory.model.adapter:143 >> Fine-tuning method: Full
20: [INFO|2025-06-27 21:03:20] llamafactory.model.loader:143 >> trainable params: 8,292,166,656 || all params: 8,292,166,656 || trainable%: 100.0000
10: [INFO|2025-06-27 21:03:20] llamafactory.model.loader:143 >> trainable params: 8,292,166,656 || all params: 8,292,166,656 || trainable%: 100.0000
30: [INFO|2025-06-27 21:03:20] llamafactory.model.loader:143 >> trainable params: 8,292,166,656 || all params: 8,292,166,656 || trainable%: 100.0000
11: [INFO|2025-06-27 21:03:20] llamafactory.model.loader:143 >> trainable params: 8,292,166,656 || all params: 8,292,166,656 || trainable%: 100.0000
 4: [INFO|2025-06-27 21:03:20] llamafactory.model.loader:143 >> trainable params: 8,292,166,656 || all params: 8,292,166,656 || trainable%: 100.0000
27: [INFO|2025-06-27 21:03:20] llamafactory.model.loader:143 >> trainable params: 8,292,166,656 || all params: 8,292,166,656 || trainable%: 100.0000
 3: [INFO|2025-06-27 21:03:20] llamafactory.model.loader:143 >> trainable params: 8,292,166,656 || all params: 8,292,166,656 || trainable%: 100.0000
 6: [INFO|2025-06-27 21:03:20] llamafactory.model.loader:143 >> trainable params: 8,292,166,656 || all params: 8,292,166,656 || trainable%: 100.0000
26: [INFO|2025-06-27 21:03:20] llamafactory.model.loader:143 >> trainable params: 8,292,166,656 || all params: 8,292,166,656 || trainable%: 100.0000
25: [INFO|2025-06-27 21:03:20] llamafactory.model.loader:143 >> trainable params: 8,292,166,656 || all params: 8,292,166,656 || trainable%: 100.0000
 7: [INFO|2025-06-27 21:03:20] llamafactory.model.loader:143 >> trainable params: 8,292,166,656 || all params: 8,292,166,656 || trainable%: 100.0000
14: [INFO|2025-06-27 21:03:20] llamafactory.model.loader:143 >> trainable params: 8,292,166,656 || all params: 8,292,166,656 || trainable%: 100.0000
31: [INFO|2025-06-27 21:03:20] llamafactory.model.loader:143 >> trainable params: 8,292,166,656 || all params: 8,292,166,656 || trainable%: 100.0000
 2: [INFO|2025-06-27 21:03:20] llamafactory.model.loader:143 >> trainable params: 8,292,166,656 || all params: 8,292,166,656 || trainable%: 100.0000
 1: [INFO|2025-06-27 21:03:20] llamafactory.model.loader:143 >> trainable params: 8,292,166,656 || all params: 8,292,166,656 || trainable%: 100.0000
18: [INFO|2025-06-27 21:03:20] llamafactory.model.loader:143 >> trainable params: 8,292,166,656 || all params: 8,292,166,656 || trainable%: 100.0000
28: [INFO|2025-06-27 21:03:20] llamafactory.model.loader:143 >> trainable params: 8,292,166,656 || all params: 8,292,166,656 || trainable%: 100.0000
21: [INFO|2025-06-27 21:03:20] llamafactory.model.loader:143 >> trainable params: 8,292,166,656 || all params: 8,292,166,656 || trainable%: 100.0000
24: [INFO|2025-06-27 21:03:20] llamafactory.model.loader:143 >> trainable params: 8,292,166,656 || all params: 8,292,166,656 || trainable%: 100.0000
23: [INFO|2025-06-27 21:03:20] llamafactory.model.loader:143 >> trainable params: 8,292,166,656 || all params: 8,292,166,656 || trainable%: 100.0000
 5: [INFO|2025-06-27 21:03:20] llamafactory.model.loader:143 >> trainable params: 8,292,166,656 || all params: 8,292,166,656 || trainable%: 100.0000
13: [INFO|2025-06-27 21:03:20] llamafactory.model.loader:143 >> trainable params: 8,292,166,656 || all params: 8,292,166,656 || trainable%: 100.0000
17: [INFO|2025-06-27 21:03:20] llamafactory.model.loader:143 >> trainable params: 8,292,166,656 || all params: 8,292,166,656 || trainable%: 100.0000
19: [INFO|2025-06-27 21:03:20] llamafactory.model.loader:143 >> trainable params: 8,292,166,656 || all params: 8,292,166,656 || trainable%: 100.0000
 9: [INFO|2025-06-27 21:03:20] llamafactory.model.loader:143 >> trainable params: 8,292,166,656 || all params: 8,292,166,656 || trainable%: 100.0000
16: [INFO|2025-06-27 21:03:20] llamafactory.model.loader:143 >> trainable params: 8,292,166,656 || all params: 8,292,166,656 || trainable%: 100.0000
 8: [INFO|2025-06-27 21:03:20] llamafactory.model.loader:143 >> trainable params: 8,292,166,656 || all params: 8,292,166,656 || trainable%: 100.0000
15: [INFO|2025-06-27 21:03:20] llamafactory.model.loader:143 >> trainable params: 8,292,166,656 || all params: 8,292,166,656 || trainable%: 100.0000
22: [INFO|2025-06-27 21:03:20] llamafactory.model.loader:143 >> trainable params: 8,292,166,656 || all params: 8,292,166,656 || trainable%: 100.0000
 2: [INFO|trainer.py:748] 2025-06-27 21:03:20,619 >> Using auto half precision backend
27: [INFO|trainer.py:748] 2025-06-27 21:03:20,619 >> Using auto half precision backend
10: [INFO|trainer.py:748] 2025-06-27 21:03:20,619 >> Using auto half precision backend
 3: [INFO|trainer.py:748] 2025-06-27 21:03:20,620 >> Using auto half precision backend
28: [INFO|trainer.py:748] 2025-06-27 21:03:20,620 >> Using auto half precision backend
 4: [INFO|trainer.py:748] 2025-06-27 21:03:20,620 >> Using auto half precision backend
 1: [INFO|trainer.py:748] 2025-06-27 21:03:20,620 >> Using auto half precision backend
26: [INFO|trainer.py:748] 2025-06-27 21:03:20,620 >> Using auto half precision backend
14: [INFO|trainer.py:748] 2025-06-27 21:03:20,621 >> Using auto half precision backend
25: [INFO|trainer.py:748] 2025-06-27 21:03:20,621 >> Using auto half precision backend
11: [INFO|trainer.py:748] 2025-06-27 21:03:20,621 >> Using auto half precision backend
 6: [INFO|trainer.py:748] 2025-06-27 21:03:20,621 >> Using auto half precision backend
13: [INFO|trainer.py:748] 2025-06-27 21:03:20,621 >> Using auto half precision backend
18: [INFO|trainer.py:748] 2025-06-27 21:03:20,621 >> Using auto half precision backend
21: [INFO|trainer.py:748] 2025-06-27 21:03:20,621 >> Using auto half precision backend
 7: [INFO|trainer.py:748] 2025-06-27 21:03:20,621 >> Using auto half precision backend
31: [INFO|trainer.py:748] 2025-06-27 21:03:20,621 >> Using auto half precision backend
19: [INFO|trainer.py:748] 2025-06-27 21:03:20,622 >> Using auto half precision backend
24: [INFO|trainer.py:748] 2025-06-27 21:03:20,622 >> Using auto half precision backend
30: [INFO|trainer.py:748] 2025-06-27 21:03:20,622 >> Using auto half precision backend
20: [INFO|trainer.py:748] 2025-06-27 21:03:20,622 >> Using auto half precision backend
 9: [INFO|trainer.py:748] 2025-06-27 21:03:20,622 >> Using auto half precision backend
17: [INFO|trainer.py:748] 2025-06-27 21:03:20,622 >> Using auto half precision backend
 8: [INFO|trainer.py:748] 2025-06-27 21:03:20,622 >> Using auto half precision backend
16: [INFO|trainer.py:748] 2025-06-27 21:03:20,622 >> Using auto half precision backend
 5: [INFO|trainer.py:748] 2025-06-27 21:03:20,622 >> Using auto half precision backend
23: [INFO|trainer.py:748] 2025-06-27 21:03:20,622 >> Using auto half precision backend
22: [INFO|trainer.py:748] 2025-06-27 21:03:20,623 >> Using auto half precision backend
15: [INFO|trainer.py:748] 2025-06-27 21:03:20,623 >> Using auto half precision backend
12: [INFO|configuration_utils.py:1097] 2025-06-27 21:03:20,760 >> loading configuration file generation_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/generation_config.json
12: [INFO|configuration_utils.py:1142] 2025-06-27 21:03:20,761 >> Generate config GenerationConfig {
12:   "bos_token_id": 151643,
12:   "do_sample": true,
12:   "eos_token_id": [
12:     151645,
12:     151643
12:   ],
12:   "pad_token_id": 151643,
12:   "repetition_penalty": 1.05,
12:   "temperature": 1e-06
12: }
12: 
12: [INFO|2025-06-27 21:03:20] llamafactory.model.model_utils.checkpointing:143 >> Gradient checkpointing enabled.
12: [INFO|2025-06-27 21:03:20] llamafactory.model.model_utils.attention:143 >> Using torch SDPA for faster training and inference.
12: [INFO|2025-06-27 21:03:20] llamafactory.model.adapter:143 >> DeepSpeed ZeRO3 detected, remaining trainable params in float32.
12: [INFO|2025-06-27 21:03:20] llamafactory.model.adapter:143 >> Fine-tuning method: Full
29: [INFO|configuration_utils.py:1097] 2025-06-27 21:03:20,764 >> loading configuration file generation_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/generation_config.json
29: [INFO|configuration_utils.py:1142] 2025-06-27 21:03:20,764 >> Generate config GenerationConfig {
29:   "bos_token_id": 151643,
29:   "do_sample": true,
29:   "eos_token_id": [
29:     151645,
29:     151643
29:   ],
29:   "pad_token_id": 151643,
29:   "repetition_penalty": 1.05,
29:   "temperature": 1e-06
29: }
29: 
29: [INFO|2025-06-27 21:03:20] llamafactory.model.model_utils.checkpointing:143 >> Gradient checkpointing enabled.
29: [INFO|2025-06-27 21:03:20] llamafactory.model.model_utils.attention:143 >> Using torch SDPA for faster training and inference.
29: [INFO|2025-06-27 21:03:20] llamafactory.model.adapter:143 >> DeepSpeed ZeRO3 detected, remaining trainable params in float32.
29: [INFO|2025-06-27 21:03:20] llamafactory.model.adapter:143 >> Fine-tuning method: Full
12: [INFO|2025-06-27 21:03:20] llamafactory.model.loader:143 >> trainable params: 8,292,166,656 || all params: 8,292,166,656 || trainable%: 100.0000
29: [INFO|2025-06-27 21:03:20] llamafactory.model.loader:143 >> trainable params: 8,292,166,656 || all params: 8,292,166,656 || trainable%: 100.0000
12: [INFO|trainer.py:748] 2025-06-27 21:03:20,783 >> Using auto half precision backend
29: [INFO|trainer.py:748] 2025-06-27 21:03:20,784 >> Using auto half precision backend
 0: Loading checkpoint shards:  80%|████████  | 4/5 [00:18<00:04,  4.69s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:19<00:00,  3.18s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:19<00:00,  3.84s/it]
 0: [INFO|modeling_utils.py:4930] 2025-06-27 21:03:21,118 >> All model checkpoint weights were used when initializing Qwen2_5_VLForConditionalGeneration.
 0: 
 0: [INFO|modeling_utils.py:4938] 2025-06-27 21:03:21,119 >> All the weights of Qwen2_5_VLForConditionalGeneration were initialized from the model checkpoint at Qwen/Qwen2.5-VL-7B-Instruct.
 0: If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2_5_VLForConditionalGeneration for predictions without further training.
 8: [2025-06-27 21:03:21,177] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
24: [2025-06-27 21:03:21,183] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
31: [2025-06-27 21:03:21,185] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
26: [2025-06-27 21:03:21,194] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
 6: [2025-06-27 21:03:21,194] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
 7: [2025-06-27 21:03:21,195] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
15: [2025-06-27 21:03:21,195] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
29: [2025-06-27 21:03:21,196] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
10: [2025-06-27 21:03:21,196] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
 9: [2025-06-27 21:03:21,197] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
11: [2025-06-27 21:03:21,197] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
13: [2025-06-27 21:03:21,197] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
18: [2025-06-27 21:03:21,199] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
 3: [2025-06-27 21:03:21,199] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
 2: [2025-06-27 21:03:21,200] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
 1: [2025-06-27 21:03:21,200] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
 5: [2025-06-27 21:03:21,201] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
23: [2025-06-27 21:03:21,202] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
20: [2025-06-27 21:03:21,202] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
28: [2025-06-27 21:03:21,203] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
14: [2025-06-27 21:03:21,203] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
19: [2025-06-27 21:03:21,204] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
30: [2025-06-27 21:03:21,204] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
 4: [2025-06-27 21:03:21,206] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
16: [2025-06-27 21:03:21,206] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
27: [2025-06-27 21:03:21,207] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
22: [2025-06-27 21:03:21,207] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
25: [2025-06-27 21:03:21,207] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
21: [2025-06-27 21:03:21,208] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
12: [2025-06-27 21:03:21,213] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
17: [2025-06-27 21:03:21,214] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
 0: [INFO|configuration_utils.py:1097] 2025-06-27 21:03:21,253 >> loading configuration file generation_config.json from cache at /capstor/scratch/cscs/ndeperr/.cache/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/generation_config.json
 0: [INFO|configuration_utils.py:1142] 2025-06-27 21:03:21,253 >> Generate config GenerationConfig {
 0:   "bos_token_id": 151643,
 0:   "do_sample": true,
 0:   "eos_token_id": [
 0:     151645,
 0:     151643
 0:   ],
 0:   "pad_token_id": 151643,
 0:   "repetition_penalty": 1.05,
 0:   "temperature": 1e-06
 0: }
 0: 
 0: [INFO|2025-06-27 21:03:21] llamafactory.model.model_utils.checkpointing:143 >> Gradient checkpointing enabled.
 0: [INFO|2025-06-27 21:03:21] llamafactory.model.model_utils.attention:143 >> Using torch SDPA for faster training and inference.
 0: [INFO|2025-06-27 21:03:21] llamafactory.model.adapter:143 >> DeepSpeed ZeRO3 detected, remaining trainable params in float32.
 0: [INFO|2025-06-27 21:03:21] llamafactory.model.adapter:143 >> Fine-tuning method: Full
 0: [INFO|2025-06-27 21:03:21] llamafactory.model.loader:143 >> trainable params: 8,292,166,656 || all params: 8,292,166,656 || trainable%: 100.0000
 0: [INFO|trainer.py:748] 2025-06-27 21:03:21,274 >> Using auto half precision backend
 8: nid005586:68928:69565 [2] NCCL INFO Channel 01/0 : 34[2] -> 35[3] via P2P/CUMEM
 8: nid005586:68928:69565 [2] NCCL INFO Channel 02/0 : 34[2] -> 35[3] via P2P/CUMEM
 8: nid005586:68928:69565 [2] NCCL INFO Channel 03/0 : 34[2] -> 35[3] via P2P/CUMEM
 8: nid005586:68928:69565 [2] NCCL INFO Channel 05/0 : 34[2] -> 35[3] via P2P/CUMEM
 8: nid005586:68928:69565 [2] NCCL INFO Channel 06/0 : 34[2] -> 35[3] via P2P/CUMEM
 8: nid005586:68928:69565 [2] NCCL INFO Channel 07/0 : 34[2] -> 35[3] via P2P/CUMEM
 8: nid005586:68927:69566 [1] NCCL INFO Channel 01/0 : 33[1] -> 34[2] via P2P/CUMEM
 8: nid005586:68927:69566 [1] NCCL INFO Channel 05/0 : 33[1] -> 34[2] via P2P/CUMEM
 8: nid005586:68929:69567 [3] NCCL INFO Channel 02/0 : 35[3] -> 32[0] via P2P/CUMEM
 8: nid005586:68929:69567 [3] NCCL INFO Channel 03/0 : 35[3] -> 32[0] via P2P/CUMEM
 8: nid005586:68928:69565 [2] NCCL INFO Channel 06/0 : 34[2] -> 38[2] [send] via NET/AWS Libfabric/2
 8: nid005586:68929:69567 [3] NCCL INFO Channel 06/0 : 35[3] -> 32[0] via P2P/CUMEM
 8: nid005586:68929:69567 [3] NCCL INFO Channel 07/0 : 35[3] -> 32[0] via P2P/CUMEM
 8: nid005586:68926:69568 [0] NCCL INFO Channel 01/0 : 32[0] -> 33[1] via P2P/CUMEM
 8: nid005586:68926:69568 [0] NCCL INFO Channel 02/0 : 32[0] -> 33[1] via P2P/CUMEM
 8: nid005586:68926:69568 [0] NCCL INFO Channel 03/0 : 32[0] -> 33[1] via P2P/CUMEM
 8: nid005586:68926:69568 [0] NCCL INFO Channel 05/0 : 32[0] -> 33[1] via P2P/CUMEM
 8: nid005586:68926:69568 [0] NCCL INFO Channel 06/0 : 32[0] -> 33[1] via P2P/CUMEM
 8: nid005586:68926:69568 [0] NCCL INFO Channel 07/0 : 32[0] -> 33[1] via P2P/CUMEM
24: nid005918:92504:93175 [0] NCCL INFO Channel 01/0 : 96[0] -> 97[1] via P2P/CUMEM
 8: nid005586:68926:69568 [0] NCCL INFO Channel 04/0 : 32[0] -> 36[0] [send] via NET/AWS Libfabric/0
 8: nid005586:68927:69566 [1] NCCL INFO Channel 00/0 : 33[1] -> 32[0] via P2P/CUMEM
 8: nid005586:68927:69566 [1] NCCL INFO Channel 02/0 : 33[1] -> 32[0] via P2P/CUMEM
 8: nid005586:68927:69566 [1] NCCL INFO Channel 04/0 : 33[1] -> 32[0] via P2P/CUMEM
 8: nid005586:68927:69566 [1] NCCL INFO Channel 06/0 : 33[1] -> 32[0] via P2P/CUMEM
31: nid005937:256589:257239 [0] NCCL INFO Channel 00/0 : 124[0] -> 125[1] via P2P/CUMEM
24: nid005918:92504:93175 [0] NCCL INFO Channel 02/0 : 96[0] -> 97[1] via P2P/CUMEM
31: nid005937:256589:257239 [0] NCCL INFO Channel 02/0 : 124[0] -> 125[1] via P2P/CUMEM
24: nid005918:92504:93175 [0] NCCL INFO Channel 03/0 : 96[0] -> 97[1] via P2P/CUMEM
24: nid005918:92506:93176 [2] NCCL INFO Channel 01/0 : 98[2] -> 99[3] via P2P/CUMEM
31: nid005937:256589:257239 [0] NCCL INFO Channel 03/0 : 124[0] -> 125[1] via P2P/CUMEM
24: nid005918:92504:93175 [0] NCCL INFO Channel 05/0 : 96[0] -> 97[1] via P2P/CUMEM
24: nid005918:92506:93176 [2] NCCL INFO Channel 02/0 : 98[2] -> 99[3] via P2P/CUMEM
31: nid005937:256589:257239 [0] NCCL INFO Channel 04/0 : 124[0] -> 125[1] via P2P/CUMEM
24: nid005918:92504:93175 [0] NCCL INFO Channel 06/0 : 96[0] -> 97[1] via P2P/CUMEM
24: nid005918:92506:93176 [2] NCCL INFO Channel 03/0 : 98[2] -> 99[3] via P2P/CUMEM
24: nid005918:92504:93175 [0] NCCL INFO Channel 07/0 : 96[0] -> 97[1] via P2P/CUMEM
24: nid005918:92506:93176 [2] NCCL INFO Channel 05/0 : 98[2] -> 99[3] via P2P/CUMEM
31: nid005937:256589:257239 [0] NCCL INFO Channel 06/0 : 124[0] -> 125[1] via P2P/CUMEM
24: nid005918:92506:93176 [2] NCCL INFO Channel 06/0 : 98[2] -> 99[3] via P2P/CUMEM
31: nid005937:256591:257241 [2] NCCL INFO Channel 00/0 : 126[2] -> 127[3] via P2P/CUMEM
31: nid005937:256589:257239 [0] NCCL INFO Channel 07/0 : 124[0] -> 125[1] via P2P/CUMEM
24: nid005918:92506:93176 [2] NCCL INFO Channel 07/0 : 98[2] -> 99[3] via P2P/CUMEM
31: nid005937:256591:257241 [2] NCCL INFO Channel 02/0 : 126[2] -> 127[3] via P2P/CUMEM
24: nid005918:92507:93177 [3] NCCL INFO Channel 02/0 : 99[3] -> 96[0] via P2P/CUMEM
31: nid005937:256591:257241 [2] NCCL INFO Channel 03/0 : 126[2] -> 127[3] via P2P/CUMEM
24: nid005918:92507:93177 [3] NCCL INFO Channel 03/0 : 99[3] -> 96[0] via P2P/CUMEM
24: nid005918:92507:93177 [3] NCCL INFO Channel 06/0 : 99[3] -> 96[0] via P2P/CUMEM
31: nid005937:256591:257241 [2] NCCL INFO Channel 04/0 : 126[2] -> 127[3] via P2P/CUMEM
24: nid005918:92507:93177 [3] NCCL INFO Channel 07/0 : 99[3] -> 96[0] via P2P/CUMEM
31: nid005937:256590:257240 [1] NCCL INFO Channel 00/0 : 125[1] -> 126[2] via P2P/CUMEM
31: nid005937:256591:257241 [2] NCCL INFO Channel 06/0 : 126[2] -> 127[3] via P2P/CUMEM
31: nid005937:256590:257240 [1] NCCL INFO Channel 04/0 : 125[1] -> 126[2] via P2P/CUMEM
31: nid005937:256591:257241 [2] NCCL INFO Channel 07/0 : 126[2] -> 127[3] via P2P/CUMEM
31: nid005937:256592:257238 [3] NCCL INFO Channel 02/0 : 127[3] -> 124[0] via P2P/CUMEM
31: nid005937:256589:257239 [0] NCCL INFO Channel 00/0 : 120[0] -> 124[0] [receive] via NET/AWS Libfabric/0
31: nid005937:256591:257241 [2] NCCL INFO Channel 02/0 : 122[2] -> 126[2] [receive] via NET/AWS Libfabric/2
31: nid005937:256592:257238 [3] NCCL INFO Channel 03/0 : 127[3] -> 124[0] via P2P/CUMEM
31: nid005937:256592:257238 [3] NCCL INFO Channel 06/0 : 127[3] -> 124[0] via P2P/CUMEM
31: nid005937:256590:257240 [1] NCCL INFO Channel 01/0 : 125[1] -> 124[0] via P2P/CUMEM
31: nid005937:256592:257238 [3] NCCL INFO Channel 07/0 : 127[3] -> 124[0] via P2P/CUMEM
31: nid005937:256590:257240 [1] NCCL INFO Channel 03/0 : 125[1] -> 124[0] via P2P/CUMEM
26: nid005920:67123:67775 [0] NCCL INFO Channel 01/0 : 104[0] -> 105[1] via P2P/CUMEM
31: nid005937:256590:257240 [1] NCCL INFO Channel 05/0 : 125[1] -> 124[0] via P2P/CUMEM
31: nid005937:256590:257240 [1] NCCL INFO Channel 07/0 : 125[1] -> 124[0] via P2P/CUMEM
26: nid005920:67123:67775 [0] NCCL INFO Channel 02/0 : 104[0] -> 105[1] via P2P/CUMEM
26: nid005920:67123:67775 [0] NCCL INFO Channel 03/0 : 104[0] -> 105[1] via P2P/CUMEM
26: nid005920:67123:67775 [0] NCCL INFO Channel 05/0 : 104[0] -> 105[1] via P2P/CUMEM
26: nid005920:67123:67775 [0] NCCL INFO Channel 06/0 : 104[0] -> 105[1] via P2P/CUMEM
 0: nid005574:69060:69729 [2] NCCL INFO Channel 01/0 : 2[2] -> 3[3] via P2P/CUMEM
26: nid005920:67123:67775 [0] NCCL INFO Channel 07/0 : 104[0] -> 105[1] via P2P/CUMEM
 0: nid005574:69060:69729 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM
 0: nid005574:69059:69728 [1] NCCL INFO Channel 01/0 : 1[1] -> 2[2] via P2P/CUMEM
 0: nid005574:69060:69729 [2] NCCL INFO Channel 03/0 : 2[2] -> 3[3] via P2P/CUMEM
 0: nid005574:69059:69728 [1] NCCL INFO Channel 05/0 : 1[1] -> 2[2] via P2P/CUMEM
 0: nid005574:69060:69729 [2] NCCL INFO Channel 05/0 : 2[2] -> 3[3] via P2P/CUMEM
 6: nid005584:28285:28917 [0] NCCL INFO Channel 01/0 : 24[0] -> 25[1] via P2P/CUMEM
 0: nid005574:69060:69729 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM
 0: nid005574:69060:69729 [2] NCCL INFO Channel 07/0 : 2[2] -> 3[3] via P2P/CUMEM
 7: nid005585:122005:122641 [0] NCCL INFO Channel 00/0 : 28[0] -> 29[1] via P2P/CUMEM
26: nid005920:67125:67776 [2] NCCL INFO Channel 01/0 : 106[2] -> 107[3] via P2P/CUMEM
26: nid005920:67125:67776 [2] NCCL INFO Channel 02/0 : 106[2] -> 107[3] via P2P/CUMEM
15: nid005601:210678:211329 [2] NCCL INFO Channel 00/0 : 62[2] -> 63[3] via P2P/CUMEM
26: nid005920:67125:67776 [2] NCCL INFO Channel 03/0 : 106[2] -> 107[3] via P2P/CUMEM
 7: nid005585:122005:122641 [0] NCCL INFO Channel 02/0 : 28[0] -> 29[1] via P2P/CUMEM
26: nid005920:67125:67776 [2] NCCL INFO Channel 05/0 : 106[2] -> 107[3] via P2P/CUMEM
26: nid005920:67125:67776 [2] NCCL INFO Channel 06/0 : 106[2] -> 107[3] via P2P/CUMEM
 7: nid005585:122005:122641 [0] NCCL INFO Channel 03/0 : 28[0] -> 29[1] via P2P/CUMEM
15: nid005601:210678:211329 [2] NCCL INFO Channel 02/0 : 62[2] -> 63[3] via P2P/CUMEM
26: nid005920:67125:67776 [2] NCCL INFO Channel 07/0 : 106[2] -> 107[3] via P2P/CUMEM
 7: nid005585:122005:122641 [0] NCCL INFO Channel 04/0 : 28[0] -> 29[1] via P2P/CUMEM
 7: nid005585:122005:122641 [0] NCCL INFO Channel 06/0 : 28[0] -> 29[1] via P2P/CUMEM
15: nid005601:210678:211329 [2] NCCL INFO Channel 03/0 : 62[2] -> 63[3] via P2P/CUMEM
 7: nid005585:122005:122641 [0] NCCL INFO Channel 07/0 : 28[0] -> 29[1] via P2P/CUMEM
15: nid005601:210678:211329 [2] NCCL INFO Channel 04/0 : 62[2] -> 63[3] via P2P/CUMEM
10: nid005590:110710:111344 [0] NCCL INFO Channel 01/0 : 40[0] -> 41[1] via P2P/CUMEM
15: nid005601:210678:211329 [2] NCCL INFO Channel 06/0 : 62[2] -> 63[3] via P2P/CUMEM
 6: nid005584:28286:28918 [1] NCCL INFO Channel 01/0 : 25[1] -> 26[2] via P2P/CUMEM
 6: nid005584:28286:28918 [1] NCCL INFO Channel 05/0 : 25[1] -> 26[2] via P2P/CUMEM
15: nid005601:210678:211329 [2] NCCL INFO Channel 07/0 : 62[2] -> 63[3] via P2P/CUMEM
15: nid005601:210679:211330 [3] NCCL INFO Channel 02/0 : 63[3] -> 60[0] via P2P/CUMEM
15: nid005601:210679:211330 [3] NCCL INFO Channel 03/0 : 63[3] -> 60[0] via P2P/CUMEM
15: nid005601:210679:211330 [3] NCCL INFO Channel 06/0 : 63[3] -> 60[0] via P2P/CUMEM
15: nid005601:210679:211330 [3] NCCL INFO Channel 07/0 : 63[3] -> 60[0] via P2P/CUMEM
29: nid005932:167682:168331 [2] NCCL INFO Channel 00/0 : 118[2] -> 119[3] via P2P/CUMEM
29: nid005932:167682:168331 [2] NCCL INFO Channel 02/0 : 118[2] -> 119[3] via P2P/CUMEM
29: nid005932:167682:168331 [2] NCCL INFO Channel 03/0 : 118[2] -> 119[3] via P2P/CUMEM
29: nid005932:167682:168331 [2] NCCL INFO Channel 04/0 : 118[2] -> 119[3] via P2P/CUMEM
 7: nid005585:122007:122642 [2] NCCL INFO Channel 00/0 : 30[2] -> 31[3] via P2P/CUMEM
29: nid005932:167682:168331 [2] NCCL INFO Channel 06/0 : 118[2] -> 119[3] via P2P/CUMEM
29: nid005932:167682:168331 [2] NCCL INFO Channel 07/0 : 118[2] -> 119[3] via P2P/CUMEM
 7: nid005585:122007:122642 [2] NCCL INFO Channel 02/0 : 30[2] -> 31[3] via P2P/CUMEM
 9: nid005588:35937:36596 [2] NCCL INFO Channel 00/0 : 38[2] -> 39[3] via P2P/CUMEM
 6: nid005584:28285:28917 [0] NCCL INFO Channel 02/0 : 24[0] -> 25[1] via P2P/CUMEM
 6: nid005584:28285:28917 [0] NCCL INFO Channel 03/0 : 24[0] -> 25[1] via P2P/CUMEM
 7: nid005585:122007:122642 [2] NCCL INFO Channel 03/0 : 30[2] -> 31[3] via P2P/CUMEM
 9: nid005588:35937:36596 [2] NCCL INFO Channel 02/0 : 38[2] -> 39[3] via P2P/CUMEM
26: nid005920:67126:67777 [3] NCCL INFO Channel 02/0 : 107[3] -> 104[0] via P2P/CUMEM
 6: nid005584:28285:28917 [0] NCCL INFO Channel 05/0 : 24[0] -> 25[1] via P2P/CUMEM
26: nid005920:67126:67777 [3] NCCL INFO Channel 03/0 : 107[3] -> 104[0] via P2P/CUMEM
15: nid005601:210676:211332 [0] NCCL INFO Channel 00/0 : 60[0] -> 61[1] via P2P/CUMEM
26: nid005920:67126:67777 [3] NCCL INFO Channel 06/0 : 107[3] -> 104[0] via P2P/CUMEM
 6: nid005584:28285:28917 [0] NCCL INFO Channel 06/0 : 24[0] -> 25[1] via P2P/CUMEM
 7: nid005585:122007:122642 [2] NCCL INFO Channel 04/0 : 30[2] -> 31[3] via P2P/CUMEM
 9: nid005588:35937:36596 [2] NCCL INFO Channel 03/0 : 38[2] -> 39[3] via P2P/CUMEM
26: nid005920:67126:67777 [3] NCCL INFO Channel 07/0 : 107[3] -> 104[0] via P2P/CUMEM
 6: nid005584:28285:28917 [0] NCCL INFO Channel 07/0 : 24[0] -> 25[1] via P2P/CUMEM
 9: nid005588:35936:36597 [1] NCCL INFO Channel 00/0 : 37[1] -> 38[2] via P2P/CUMEM
 7: nid005585:122007:122642 [2] NCCL INFO Channel 06/0 : 30[2] -> 31[3] via P2P/CUMEM
 9: nid005588:35937:36596 [2] NCCL INFO Channel 04/0 : 38[2] -> 39[3] via P2P/CUMEM
15: nid005601:210676:211332 [0] NCCL INFO Channel 02/0 : 60[0] -> 61[1] via P2P/CUMEM
11: nid005591:191603:192243 [0] NCCL INFO Channel 00/0 : 44[0] -> 45[1] via P2P/CUMEM
 9: nid005588:35937:36596 [2] NCCL INFO Channel 06/0 : 38[2] -> 39[3] via P2P/CUMEM
 9: nid005588:35936:36597 [1] NCCL INFO Channel 04/0 : 37[1] -> 38[2] via P2P/CUMEM
15: nid005601:210676:211332 [0] NCCL INFO Channel 03/0 : 60[0] -> 61[1] via P2P/CUMEM
 7: nid005585:122007:122642 [2] NCCL INFO Channel 07/0 : 30[2] -> 31[3] via P2P/CUMEM
18: nid005911:38864:39519 [0] NCCL INFO Channel 01/0 : 72[0] -> 73[1] via P2P/CUMEM
 6: nid005584:28285:28917 [0] NCCL INFO Channel 01/0 : 20[0] -> 24[0] [receive] via NET/AWS Libfabric/0
29: nid005932:167680:168334 [0] NCCL INFO Channel 00/0 : 116[0] -> 117[1] via P2P/CUMEM
 9: nid005588:35937:36596 [2] NCCL INFO Channel 07/0 : 38[2] -> 39[3] via P2P/CUMEM
 6: nid005584:28285:28917 [0] NCCL INFO Channel 05/0 : 20[0] -> 24[0] [receive] via NET/AWS Libfabric/0
10: nid005590:110711:111345 [1] NCCL INFO Channel 01/0 : 41[1] -> 42[2] via P2P/CUMEM
15: nid005601:210676:211332 [0] NCCL INFO Channel 04/0 : 60[0] -> 61[1] via P2P/CUMEM
 6: nid005584:28285:28917 [0] NCCL INFO Channel 00/0 : 24[0] -> 28[0] [send] via NET/AWS Libfabric/0
 7: nid005585:122006:122643 [1] NCCL INFO Channel 00/0 : 29[1] -> 30[2] via P2P/CUMEM
10: nid005590:110711:111345 [1] NCCL INFO Channel 05/0 : 41[1] -> 42[2] via P2P/CUMEM
15: nid005601:210677:211331 [1] NCCL INFO Channel 00/0 : 61[1] -> 62[2] via P2P/CUMEM
11: nid005591:191603:192243 [0] NCCL INFO Channel 02/0 : 44[0] -> 45[1] via P2P/CUMEM
 7: nid005585:122006:122643 [1] NCCL INFO Channel 04/0 : 29[1] -> 30[2] via P2P/CUMEM
15: nid005601:210676:211332 [0] NCCL INFO Channel 06/0 : 60[0] -> 61[1] via P2P/CUMEM
18: nid005911:38864:39519 [0] NCCL INFO Channel 02/0 : 72[0] -> 73[1] via P2P/CUMEM
 9: nid005588:35935:36599 [0] NCCL INFO Channel 00/0 : 36[0] -> 37[1] via P2P/CUMEM
15: nid005601:210677:211331 [1] NCCL INFO Channel 04/0 : 61[1] -> 62[2] via P2P/CUMEM
15: nid005601:210676:211332 [0] NCCL INFO Channel 07/0 : 60[0] -> 61[1] via P2P/CUMEM
11: nid005591:191605:192244 [2] NCCL INFO Channel 00/0 : 46[2] -> 47[3] via P2P/CUMEM
10: nid005590:110710:111344 [0] NCCL INFO Channel 02/0 : 40[0] -> 41[1] via P2P/CUMEM
11: nid005591:191603:192243 [0] NCCL INFO Channel 03/0 : 44[0] -> 45[1] via P2P/CUMEM
 3: nid005580:71819:72468 [0] NCCL INFO Channel 00/0 : 12[0] -> 13[1] via P2P/CUMEM
18: nid005911:38864:39519 [0] NCCL INFO Channel 03/0 : 72[0] -> 73[1] via P2P/CUMEM
10: nid005590:110710:111344 [0] NCCL INFO Channel 03/0 : 40[0] -> 41[1] via P2P/CUMEM
18: nid005911:38866:39520 [2] NCCL INFO Channel 01/0 : 74[2] -> 75[3] via P2P/CUMEM
18: nid005911:38864:39519 [0] NCCL INFO Channel 05/0 : 72[0] -> 73[1] via P2P/CUMEM
10: nid005590:110710:111344 [0] NCCL INFO Channel 05/0 : 40[0] -> 41[1] via P2P/CUMEM
29: nid005932:167680:168334 [0] NCCL INFO Channel 02/0 : 116[0] -> 117[1] via P2P/CUMEM
 7: nid005585:122005:122641 [0] NCCL INFO Channel 00/0 : 24[0] -> 28[0] [receive] via NET/AWS Libfabric/0
 9: nid005588:35935:36599 [0] NCCL INFO Channel 02/0 : 36[0] -> 37[1] via P2P/CUMEM
 2: nid005577:17422:18081 [0] NCCL INFO Channel 01/0 : 8[0] -> 9[1] via P2P/CUMEM
11: nid005591:191605:192244 [2] NCCL INFO Channel 02/0 : 46[2] -> 47[3] via P2P/CUMEM
11: nid005591:191603:192243 [0] NCCL INFO Channel 04/0 : 44[0] -> 45[1] via P2P/CUMEM
10: nid005590:110710:111344 [0] NCCL INFO Channel 06/0 : 40[0] -> 41[1] via P2P/CUMEM
18: nid005911:38866:39520 [2] NCCL INFO Channel 02/0 : 74[2] -> 75[3] via P2P/CUMEM
15: nid005601:210676:211332 [0] NCCL INFO Channel 00/0 : 56[0] -> 60[0] [receive] via NET/AWS Libfabric/0
 7: nid005585:122005:122641 [0] NCCL INFO Channel 04/0 : 12[0] -> 28[0] [receive] via NET/AWS Libfabric/0
18: nid005911:38864:39519 [0] NCCL INFO Channel 06/0 : 72[0] -> 73[1] via P2P/CUMEM
 9: nid005588:35935:36599 [0] NCCL INFO Channel 03/0 : 36[0] -> 37[1] via P2P/CUMEM
 7: nid005585:122005:122641 [0] NCCL INFO Channel 05/0 : 12[0] -> 28[0] [receive] via NET/AWS Libfabric/0
15: nid005601:210678:211329 [2] NCCL INFO Channel 02/0 : 58[2] -> 62[2] [receive] via NET/AWS Libfabric/2
10: nid005590:110710:111344 [0] NCCL INFO Channel 07/0 : 40[0] -> 41[1] via P2P/CUMEM
 7: nid005585:122005:122641 [0] NCCL INFO Channel 04/0 : 28[0] -> 44[0] [send] via NET/AWS Libfabric/0
 7: nid005585:122005:122641 [0] NCCL INFO Channel 05/0 : 28[0] -> 44[0] [send] via NET/AWS Libfabric/0
13: nid005595:197885:198571 [2] NCCL INFO Channel 00/0 : 54[2] -> 55[3] via P2P/CUMEM
18: nid005911:38866:39520 [2] NCCL INFO Channel 03/0 : 74[2] -> 75[3] via P2P/CUMEM
18: nid005911:38864:39519 [0] NCCL INFO Channel 07/0 : 72[0] -> 73[1] via P2P/CUMEM
 9: nid005588:35935:36599 [0] NCCL INFO Channel 04/0 : 36[0] -> 37[1] via P2P/CUMEM
11: nid005591:191605:192244 [2] NCCL INFO Channel 03/0 : 46[2] -> 47[3] via P2P/CUMEM
15: nid005601:210677:211331 [1] NCCL INFO Channel 01/0 : 61[1] -> 60[0] via P2P/CUMEM
11: nid005591:191603:192243 [0] NCCL INFO Channel 06/0 : 44[0] -> 45[1] via P2P/CUMEM
29: nid005932:167680:168334 [0] NCCL INFO Channel 03/0 : 116[0] -> 117[1] via P2P/CUMEM
15: nid005601:210677:211331 [1] NCCL INFO Channel 03/0 : 61[1] -> 60[0] via P2P/CUMEM
18: nid005911:38866:39520 [2] NCCL INFO Channel 05/0 : 74[2] -> 75[3] via P2P/CUMEM
 9: nid005588:35935:36599 [0] NCCL INFO Channel 06/0 : 36[0] -> 37[1] via P2P/CUMEM
 7: nid005585:122006:122643 [1] NCCL INFO Channel 01/0 : 29[1] -> 28[0] via P2P/CUMEM
13: nid005595:197885:198571 [2] NCCL INFO Channel 02/0 : 54[2] -> 55[3] via P2P/CUMEM
15: nid005601:210677:211331 [1] NCCL INFO Channel 05/0 : 61[1] -> 60[0] via P2P/CUMEM
18: nid005911:38866:39520 [2] NCCL INFO Channel 06/0 : 74[2] -> 75[3] via P2P/CUMEM
 9: nid005588:35935:36599 [0] NCCL INFO Channel 07/0 : 36[0] -> 37[1] via P2P/CUMEM
15: nid005601:210677:211331 [1] NCCL INFO Channel 07/0 : 61[1] -> 60[0] via P2P/CUMEM
11: nid005591:191605:192244 [2] NCCL INFO Channel 04/0 : 46[2] -> 47[3] via P2P/CUMEM
11: nid005591:191603:192243 [0] NCCL INFO Channel 07/0 : 44[0] -> 45[1] via P2P/CUMEM
10: nid005590:110710:111344 [0] NCCL INFO Channel 01/0 : 36[0] -> 40[0] [receive] via NET/AWS Libfabric/0
 1: nid005576:147559:148197 [2] NCCL INFO Channel 00/0 : 6[2] -> 7[3] via P2P/CUMEM
10: nid005590:110710:111344 [0] NCCL INFO Channel 05/0 : 36[0] -> 40[0] [receive] via NET/AWS Libfabric/0
 7: nid005585:122006:122643 [1] NCCL INFO Channel 03/0 : 29[1] -> 28[0] via P2P/CUMEM
13: nid005595:197883:198573 [0] NCCL INFO Channel 00/0 : 52[0] -> 53[1] via P2P/CUMEM
13: nid005595:197885:198571 [2] NCCL INFO Channel 03/0 : 54[2] -> 55[3] via P2P/CUMEM
29: nid005932:167680:168334 [0] NCCL INFO Channel 04/0 : 116[0] -> 117[1] via P2P/CUMEM
10: nid005590:110710:111344 [0] NCCL INFO Channel 00/0 : 40[0] -> 44[0] [send] via NET/AWS Libfabric/0
18: nid005911:38866:39520 [2] NCCL INFO Channel 07/0 : 74[2] -> 75[3] via P2P/CUMEM
 1: nid005576:147557:148198 [0] NCCL INFO Channel 00/0 : 4[0] -> 5[1] via P2P/CUMEM
 2: nid005577:17423:18082 [1] NCCL INFO Channel 01/0 : 9[1] -> 10[2] via P2P/CUMEM
11: nid005591:191605:192244 [2] NCCL INFO Channel 06/0 : 46[2] -> 47[3] via P2P/CUMEM
 7: nid005585:122006:122643 [1] NCCL INFO Channel 05/0 : 29[1] -> 28[0] via P2P/CUMEM
11: nid005591:191605:192244 [2] NCCL INFO Channel 07/0 : 46[2] -> 47[3] via P2P/CUMEM
 9: nid005588:35935:36599 [0] NCCL INFO Channel 04/0 : 32[0] -> 36[0] [receive] via NET/AWS Libfabric/0
13: nid005595:197885:198571 [2] NCCL INFO Channel 04/0 : 54[2] -> 55[3] via P2P/CUMEM
 7: nid005585:122006:122643 [1] NCCL INFO Channel 07/0 : 29[1] -> 28[0] via P2P/CUMEM
 9: nid005588:35935:36599 [0] NCCL INFO Channel 01/0 : 36[0] -> 40[0] [send] via NET/AWS Libfabric/0
29: nid005932:167680:168334 [0] NCCL INFO Channel 06/0 : 116[0] -> 117[1] via P2P/CUMEM
 9: nid005588:35936:36597 [1] NCCL INFO Channel 01/0 : 37[1] -> 36[0] via P2P/CUMEM
 7: nid005585:122008:122644 [3] NCCL INFO Channel 02/0 : 31[3] -> 28[0] via P2P/CUMEM
28: nid005929:16030:16665 [0] NCCL INFO Channel 01/0 : 112[0] -> 113[1] via P2P/CUMEM
 1: nid005576:147559:148197 [2] NCCL INFO Channel 02/0 : 6[2] -> 7[3] via P2P/CUMEM
 1: nid005576:147559:148197 [2] NCCL INFO Channel 03/0 : 6[2] -> 7[3] via P2P/CUMEM
 9: nid005588:35935:36599 [0] NCCL INFO Channel 05/0 : 36[0] -> 40[0] [send] via NET/AWS Libfabric/0
23: nid005917:276887:277521 [2] NCCL INFO Channel 00/0 : 94[2] -> 95[3] via P2P/CUMEM
 7: nid005585:122007:122642 [2] NCCL INFO Channel 02/0 : 26[2] -> 30[2] [receive] via NET/AWS Libfabric/2
20: nid005913:292682:293317 [1] NCCL INFO Channel 01/0 : 81[1] -> 82[2] via P2P/CUMEM
 7: nid005585:122008:122644 [3] NCCL INFO Channel 03/0 : 31[3] -> 28[0] via P2P/CUMEM
13: nid005595:197885:198571 [2] NCCL INFO Channel 06/0 : 54[2] -> 55[3] via P2P/CUMEM
 9: nid005588:35936:36597 [1] NCCL INFO Channel 03/0 : 37[1] -> 36[0] via P2P/CUMEM
13: nid005595:197883:198573 [0] NCCL INFO Channel 02/0 : 52[0] -> 53[1] via P2P/CUMEM
 8: nid005586:68926:69568 [0] NCCL INFO Channel 00/0 : 16[0] -> 32[0] [receive] via NET/AWS Libfabric/0
 7: nid005585:122008:122644 [3] NCCL INFO Channel 06/0 : 31[3] -> 28[0] via P2P/CUMEM
20: nid005913:292682:293317 [1] NCCL INFO Channel 05/0 : 81[1] -> 82[2] via P2P/CUMEM
13: nid005595:197884:198572 [1] NCCL INFO Channel 00/0 : 53[1] -> 54[2] via P2P/CUMEM
 8: nid005586:68926:69568 [0] NCCL INFO Channel 01/0 : 16[0] -> 32[0] [receive] via NET/AWS Libfabric/0
 7: nid005585:122008:122644 [3] NCCL INFO Channel 07/0 : 31[3] -> 28[0] via P2P/CUMEM
 8: nid005586:68926:69568 [0] NCCL INFO Channel 00/0 : 32[0] -> 48[0] [send] via NET/AWS Libfabric/0
 9: nid005588:35935:36599 [0] NCCL INFO Channel 04/0 : 36[0] -> 44[0] [send] via NET/AWS Libfabric/0
29: nid005932:167681:168332 [1] NCCL INFO Channel 00/0 : 117[1] -> 118[2] via P2P/CUMEM
11: nid005591:191606:192245 [3] NCCL INFO Channel 02/0 : 47[3] -> 44[0] via P2P/CUMEM
 8: nid005586:68926:69568 [0] NCCL INFO Channel 01/0 : 32[0] -> 48[0] [send] via NET/AWS Libfabric/0
29: nid005932:167680:168334 [0] NCCL INFO Channel 07/0 : 116[0] -> 117[1] via P2P/CUMEM
 9: nid005588:35935:36599 [0] NCCL INFO Channel 05/0 : 36[0] -> 44[0] [send] via NET/AWS Libfabric/0
28: nid005929:16032:16664 [2] NCCL INFO Channel 01/0 : 114[2] -> 115[3] via P2P/CUMEM
13: nid005595:197885:198571 [2] NCCL INFO Channel 07/0 : 54[2] -> 55[3] via P2P/CUMEM
23: nid005917:276887:277521 [2] NCCL INFO Channel 02/0 : 94[2] -> 95[3] via P2P/CUMEM
 9: nid005588:35936:36597 [1] NCCL INFO Channel 05/0 : 37[1] -> 36[0] via P2P/CUMEM
13: nid005595:197883:198573 [0] NCCL INFO Channel 03/0 : 52[0] -> 53[1] via P2P/CUMEM
18: nid005911:38865:39521 [1] NCCL INFO Channel 01/0 : 73[1] -> 74[2] via P2P/CUMEM
29: nid005932:167683:168333 [3] NCCL INFO Channel 02/0 : 119[3] -> 116[0] via P2P/CUMEM
13: nid005595:197884:198572 [1] NCCL INFO Channel 04/0 : 53[1] -> 54[2] via P2P/CUMEM
29: nid005932:167681:168332 [1] NCCL INFO Channel 04/0 : 117[1] -> 118[2] via P2P/CUMEM
28: nid005929:16032:16664 [2] NCCL INFO Channel 02/0 : 114[2] -> 115[3] via P2P/CUMEM
28: nid005929:16032:16664 [2] NCCL INFO Channel 03/0 : 114[2] -> 115[3] via P2P/CUMEM
11: nid005591:191606:192245 [3] NCCL INFO Channel 03/0 : 47[3] -> 44[0] via P2P/CUMEM
18: nid005911:38865:39521 [1] NCCL INFO Channel 05/0 : 73[1] -> 74[2] via P2P/CUMEM
 1: nid005576:147559:148197 [2] NCCL INFO Channel 04/0 : 6[2] -> 7[3] via P2P/CUMEM
 1: nid005576:147559:148197 [2] NCCL INFO Channel 06/0 : 6[2] -> 7[3] via P2P/CUMEM
 9: nid005588:35936:36597 [1] NCCL INFO Channel 07/0 : 37[1] -> 36[0] via P2P/CUMEM
 5: nid005582:196715:197503 [2] NCCL INFO Channel 00/0 : 22[2] -> 23[3] via P2P/CUMEM
 1: nid005576:147558:148199 [1] NCCL INFO Channel 00/0 : 5[1] -> 6[2] via P2P/CUMEM
23: nid005917:276887:277521 [2] NCCL INFO Channel 03/0 : 94[2] -> 95[3] via P2P/CUMEM
13: nid005595:197883:198573 [0] NCCL INFO Channel 04/0 : 52[0] -> 53[1] via P2P/CUMEM
29: nid005932:167683:168333 [3] NCCL INFO Channel 03/0 : 119[3] -> 116[0] via P2P/CUMEM
 1: nid005576:147559:148197 [2] NCCL INFO Channel 07/0 : 6[2] -> 7[3] via P2P/CUMEM
14: nid005600:217720:218385 [0] NCCL INFO Channel 01/0 : 56[0] -> 57[1] via P2P/CUMEM
11: nid005591:191606:192245 [3] NCCL INFO Channel 06/0 : 47[3] -> 44[0] via P2P/CUMEM
13: nid005595:197883:198573 [0] NCCL INFO Channel 06/0 : 52[0] -> 53[1] via P2P/CUMEM
29: nid005932:167683:168333 [3] NCCL INFO Channel 06/0 : 119[3] -> 116[0] via P2P/CUMEM
13: nid005595:197883:198573 [0] NCCL INFO Channel 07/0 : 52[0] -> 53[1] via P2P/CUMEM
29: nid005932:167683:168333 [3] NCCL INFO Channel 07/0 : 119[3] -> 116[0] via P2P/CUMEM
18: nid005911:38864:39519 [0] NCCL INFO Channel 01/0 : 68[0] -> 72[0] [receive] via NET/AWS Libfabric/0
29: nid005932:167680:168334 [0] NCCL INFO Channel 04/0 : 112[0] -> 116[0] [receive] via NET/AWS Libfabric/0
 1: nid005576:147558:148199 [1] NCCL INFO Channel 04/0 : 5[1] -> 6[2] via P2P/CUMEM
18: nid005911:38864:39519 [0] NCCL INFO Channel 05/0 : 68[0] -> 72[0] [receive] via NET/AWS Libfabric/0
26: nid005920:67124:67778 [1] NCCL INFO Channel 01/0 : 105[1] -> 106[2] via P2P/CUMEM
 5: nid005582:196715:197503 [2] NCCL INFO Channel 02/0 : 22[2] -> 23[3] via P2P/CUMEM
23: nid005917:276887:277521 [2] NCCL INFO Channel 04/0 : 94[2] -> 95[3] via P2P/CUMEM
11: nid005591:191606:192245 [3] NCCL INFO Channel 07/0 : 47[3] -> 44[0] via P2P/CUMEM
29: nid005932:167680:168334 [0] NCCL INFO Channel 01/0 : 116[0] -> 120[0] [send] via NET/AWS Libfabric/0
18: nid005911:38864:39519 [0] NCCL INFO Channel 00/0 : 72[0] -> 76[0] [send] via NET/AWS Libfabric/0
29: nid005932:167682:168331 [2] NCCL INFO Channel 06/0 : 114[2] -> 118[2] [receive] via NET/AWS Libfabric/2
10: nid005590:110712:111346 [2] NCCL INFO Channel 01/0 : 42[2] -> 43[3] via P2P/CUMEM
26: nid005920:67124:67778 [1] NCCL INFO Channel 05/0 : 105[1] -> 106[2] via P2P/CUMEM
29: nid005932:167680:168334 [0] NCCL INFO Channel 05/0 : 116[0] -> 120[0] [send] via NET/AWS Libfabric/0
28: nid005929:16032:16664 [2] NCCL INFO Channel 05/0 : 114[2] -> 115[3] via P2P/CUMEM
28: nid005929:16032:16664 [2] NCCL INFO Channel 06/0 : 114[2] -> 115[3] via P2P/CUMEM
 1: nid005576:147557:148198 [0] NCCL INFO Channel 02/0 : 4[0] -> 5[1] via P2P/CUMEM
28: nid005929:16032:16664 [2] NCCL INFO Channel 07/0 : 114[2] -> 115[3] via P2P/CUMEM
29: nid005932:167682:168331 [2] NCCL INFO Channel 03/0 : 118[2] -> 122[2] [send] via NET/AWS Libfabric/2
29: nid005932:167682:168331 [2] NCCL INFO Channel 07/0 : 118[2] -> 122[2] [send] via NET/AWS Libfabric/2
30: nid005936:49908:50567 [0] NCCL INFO Channel 01/0 : 120[0] -> 121[1] via P2P/CUMEM
10: nid005590:110712:111346 [2] NCCL INFO Channel 02/0 : 42[2] -> 43[3] via P2P/CUMEM
14: nid005600:217720:218385 [0] NCCL INFO Channel 02/0 : 56[0] -> 57[1] via P2P/CUMEM
18: nid005911:38865:39521 [1] NCCL INFO Channel 00/0 : 73[1] -> 72[0] via P2P/CUMEM
 0: nid005574:69061:69730 [3] NCCL INFO Channel 02/0 : 3[3] -> 0[0] via P2P/CUMEM
10: nid005590:110712:111346 [2] NCCL INFO Channel 03/0 : 42[2] -> 43[3] via P2P/CUMEM
13: nid005595:197883:198573 [0] NCCL INFO Channel 04/0 : 48[0] -> 52[0] [receive] via NET/AWS Libfabric/0
 1: nid005576:147557:148198 [0] NCCL INFO Channel 03/0 : 4[0] -> 5[1] via P2P/CUMEM
 5: nid005582:196715:197503 [2] NCCL INFO Channel 03/0 : 22[2] -> 23[3] via P2P/CUMEM
23: nid005917:276887:277521 [2] NCCL INFO Channel 06/0 : 94[2] -> 95[3] via P2P/CUMEM
14: nid005600:217720:218385 [0] NCCL INFO Channel 03/0 : 56[0] -> 57[1] via P2P/CUMEM
29: nid005932:167681:168332 [1] NCCL INFO Channel 01/0 : 117[1] -> 116[0] via P2P/CUMEM
 9: nid005588:35938:36600 [3] NCCL INFO Channel 02/0 : 39[3] -> 36[0] via P2P/CUMEM
18: nid005911:38865:39521 [1] NCCL INFO Channel 02/0 : 73[1] -> 72[0] via P2P/CUMEM
13: nid005595:197883:198573 [0] NCCL INFO Channel 01/0 : 52[0] -> 56[0] [send] via NET/AWS Libfabric/0
 0: nid005574:69061:69730 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM
13: nid005595:197884:198572 [1] NCCL INFO Channel 01/0 : 53[1] -> 52[0] via P2P/CUMEM
 0: nid005574:69060:69729 [2] NCCL INFO Channel 06/0 : 2[2] -> 6[2] [send] via NET/AWS Libfabric/2
10: nid005590:110712:111346 [2] NCCL INFO Channel 05/0 : 42[2] -> 43[3] via P2P/CUMEM
13: nid005595:197883:198573 [0] NCCL INFO Channel 05/0 : 52[0] -> 56[0] [send] via NET/AWS Libfabric/0
18: nid005911:38865:39521 [1] NCCL INFO Channel 04/0 : 73[1] -> 72[0] via P2P/CUMEM
 9: nid005588:35938:36600 [3] NCCL INFO Channel 03/0 : 39[3] -> 36[0] via P2P/CUMEM
 9: nid005588:35937:36596 [2] NCCL INFO Channel 06/0 : 34[2] -> 38[2] [receive] via NET/AWS Libfabric/2
 0: nid005574:69061:69730 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM
 1: nid005576:147557:148198 [0] NCCL INFO Channel 04/0 : 4[0] -> 5[1] via P2P/CUMEM
20: nid005913:292681:293318 [0] NCCL INFO Channel 01/0 : 80[0] -> 81[1] via P2P/CUMEM
26: nid005920:67123:67775 [0] NCCL INFO Channel 01/0 : 100[0] -> 104[0] [receive] via NET/AWS Libfabric/0
29: nid005932:167681:168332 [1] NCCL INFO Channel 03/0 : 117[1] -> 116[0] via P2P/CUMEM
10: nid005590:110712:111346 [2] NCCL INFO Channel 06/0 : 42[2] -> 43[3] via P2P/CUMEM
 5: nid005582:196713:197505 [0] NCCL INFO Channel 00/0 : 20[0] -> 21[1] via P2P/CUMEM
14: nid005600:217720:218385 [0] NCCL INFO Channel 05/0 : 56[0] -> 57[1] via P2P/CUMEM
 9: nid005588:35937:36596 [2] NCCL INFO Channel 03/0 : 38[2] -> 42[2] [send] via NET/AWS Libfabric/2
 6: nid005584:28287:28919 [2] NCCL INFO Channel 01/0 : 26[2] -> 27[3] via P2P/CUMEM
18: nid005911:38865:39521 [1] NCCL INFO Channel 06/0 : 73[1] -> 72[0] via P2P/CUMEM
26: nid005920:67123:67775 [0] NCCL INFO Channel 05/0 : 100[0] -> 104[0] [receive] via NET/AWS Libfabric/0
23: nid005917:276887:277521 [2] NCCL INFO Channel 07/0 : 94[2] -> 95[3] via P2P/CUMEM
 0: nid005574:69061:69730 [3] NCCL INFO Channel 07/0 : 3[3] -> 0[0] via P2P/CUMEM
 9: nid005588:35938:36600 [3] NCCL INFO Channel 06/0 : 39[3] -> 36[0] via P2P/CUMEM
13: nid005595:197884:198572 [1] NCCL INFO Channel 03/0 : 53[1] -> 52[0] via P2P/CUMEM
 9: nid005588:35937:36596 [2] NCCL INFO Channel 07/0 : 38[2] -> 42[2] [send] via NET/AWS Libfabric/2
26: nid005920:67125:67776 [2] NCCL INFO Channel 03/0 : 102[2] -> 106[2] [receive] via NET/AWS Libfabric/2
29: nid005932:167681:168332 [1] NCCL INFO Channel 05/0 : 117[1] -> 116[0] via P2P/CUMEM
10: nid005590:110712:111346 [2] NCCL INFO Channel 07/0 : 42[2] -> 43[3] via P2P/CUMEM
23: nid005917:276886:277522 [1] NCCL INFO Channel 00/0 : 93[1] -> 94[2] via P2P/CUMEM
26: nid005920:67123:67775 [0] NCCL INFO Channel 00/0 : 104[0] -> 108[0] [send] via NET/AWS Libfabric/0
 1: nid005576:147557:148198 [0] NCCL INFO Channel 06/0 : 4[0] -> 5[1] via P2P/CUMEM
26: nid005920:67125:67776 [2] NCCL INFO Channel 07/0 : 102[2] -> 106[2] [receive] via NET/AWS Libfabric/2
 6: nid005584:28287:28919 [2] NCCL INFO Channel 02/0 : 26[2] -> 27[3] via P2P/CUMEM
 5: nid005582:196715:197503 [2] NCCL INFO Channel 04/0 : 22[2] -> 23[3] via P2P/CUMEM
11: nid005591:191604:192246 [1] NCCL INFO Channel 00/0 : 45[1] -> 46[2] via P2P/CUMEM
30: nid005936:49908:50567 [0] NCCL INFO Channel 02/0 : 120[0] -> 121[1] via P2P/CUMEM
 9: nid005588:35938:36600 [3] NCCL INFO Channel 07/0 : 39[3] -> 36[0] via P2P/CUMEM
13: nid005595:197884:198572 [1] NCCL INFO Channel 05/0 : 53[1] -> 52[0] via P2P/CUMEM
26: nid005920:67125:67776 [2] NCCL INFO Channel 02/0 : 106[2] -> 110[2] [send] via NET/AWS Libfabric/2
29: nid005932:167681:168332 [1] NCCL INFO Channel 07/0 : 117[1] -> 116[0] via P2P/CUMEM
26: nid005920:67124:67778 [1] NCCL INFO Channel 00/0 : 105[1] -> 104[0] via P2P/CUMEM
19: nid005912:12435:13072 [0] NCCL INFO Channel 00/0 : 76[0] -> 77[1] via P2P/CUMEM
11: nid005591:191604:192246 [1] NCCL INFO Channel 04/0 : 45[1] -> 46[2] via P2P/CUMEM
 1: nid005576:147557:148198 [0] NCCL INFO Channel 07/0 : 4[0] -> 5[1] via P2P/CUMEM
 6: nid005584:28287:28919 [2] NCCL INFO Channel 03/0 : 26[2] -> 27[3] via P2P/CUMEM
13: nid005595:197884:198572 [1] NCCL INFO Channel 07/0 : 53[1] -> 52[0] via P2P/CUMEM
30: nid005936:49908:50567 [0] NCCL INFO Channel 03/0 : 120[0] -> 121[1] via P2P/CUMEM
 8: nid005586:68928:69565 [2] NCCL INFO Channel 02/0 : 18[2] -> 34[2] [receive] via NET/AWS Libfabric/2
23: nid005917:276886:277522 [1] NCCL INFO Channel 04/0 : 93[1] -> 94[2] via P2P/CUMEM
14: nid005600:217720:218385 [0] NCCL INFO Channel 06/0 : 56[0] -> 57[1] via P2P/CUMEM
26: nid005920:67124:67778 [1] NCCL INFO Channel 02/0 : 105[1] -> 104[0] via P2P/CUMEM
28: nid005929:16030:16665 [0] NCCL INFO Channel 02/0 : 112[0] -> 113[1] via P2P/CUMEM
 8: nid005586:68928:69565 [2] NCCL INFO Channel 03/0 : 18[2] -> 34[2] [receive] via NET/AWS Libfabric/2
 6: nid005584:28287:28919 [2] NCCL INFO Channel 05/0 : 26[2] -> 27[3] via P2P/CUMEM
30: nid005936:49908:50567 [0] NCCL INFO Channel 05/0 : 120[0] -> 121[1] via P2P/CUMEM
 8: nid005586:68928:69565 [2] NCCL INFO Channel 02/0 : 34[2] -> 50[2] [send] via NET/AWS Libfabric/2
10: nid005590:110713:111343 [3] NCCL INFO Channel 02/0 : 43[3] -> 40[0] via P2P/CUMEM
26: nid005920:67124:67778 [1] NCCL INFO Channel 04/0 : 105[1] -> 104[0] via P2P/CUMEM
23: nid005917:276888:277520 [3] NCCL INFO Channel 02/0 : 95[3] -> 92[0] via P2P/CUMEM
 8: nid005586:68928:69565 [2] NCCL INFO Channel 03/0 : 34[2] -> 50[2] [send] via NET/AWS Libfabric/2
14: nid005600:217720:218385 [0] NCCL INFO Channel 07/0 : 56[0] -> 57[1] via P2P/CUMEM
 6: nid005584:28287:28919 [2] NCCL INFO Channel 06/0 : 26[2] -> 27[3] via P2P/CUMEM
20: nid005913:292681:293318 [0] NCCL INFO Channel 02/0 : 80[0] -> 81[1] via P2P/CUMEM
30: nid005936:49908:50567 [0] NCCL INFO Channel 06/0 : 120[0] -> 121[1] via P2P/CUMEM
26: nid005920:67124:67778 [1] NCCL INFO Channel 06/0 : 105[1] -> 104[0] via P2P/CUMEM
28: nid005929:16030:16665 [0] NCCL INFO Channel 03/0 : 112[0] -> 113[1] via P2P/CUMEM
 6: nid005584:28287:28919 [2] NCCL INFO Channel 07/0 : 26[2] -> 27[3] via P2P/CUMEM
23: nid005917:276888:277520 [3] NCCL INFO Channel 03/0 : 95[3] -> 92[0] via P2P/CUMEM
10: nid005590:110712:111346 [2] NCCL INFO Channel 03/0 : 38[2] -> 42[2] [receive] via NET/AWS Libfabric/2
30: nid005936:49908:50567 [0] NCCL INFO Channel 07/0 : 120[0] -> 121[1] via P2P/CUMEM
10: nid005590:110712:111346 [2] NCCL INFO Channel 07/0 : 38[2] -> 42[2] [receive] via NET/AWS Libfabric/2
20: nid005913:292681:293318 [0] NCCL INFO Channel 03/0 : 80[0] -> 81[1] via P2P/CUMEM
11: nid005591:191603:192243 [0] NCCL INFO Channel 00/0 : 40[0] -> 44[0] [receive] via NET/AWS Libfabric/0
 5: nid005582:196715:197503 [2] NCCL INFO Channel 06/0 : 22[2] -> 23[3] via P2P/CUMEM
23: nid005917:276888:277520 [3] NCCL INFO Channel 06/0 : 95[3] -> 92[0] via P2P/CUMEM
10: nid005590:110712:111346 [2] NCCL INFO Channel 02/0 : 42[2] -> 46[2] [send] via NET/AWS Libfabric/2
10: nid005590:110713:111343 [3] NCCL INFO Channel 03/0 : 43[3] -> 40[0] via P2P/CUMEM
 1: nid005576:147557:148198 [0] NCCL INFO Channel 04/0 : 0[0] -> 4[0] [receive] via NET/AWS Libfabric/0
11: nid005591:191605:192244 [2] NCCL INFO Channel 02/0 : 42[2] -> 46[2] [receive] via NET/AWS Libfabric/2
10: nid005590:110711:111345 [1] NCCL INFO Channel 00/0 : 41[1] -> 40[0] via P2P/CUMEM
 5: nid005582:196713:197505 [0] NCCL INFO Channel 02/0 : 20[0] -> 21[1] via P2P/CUMEM
23: nid005917:276887:277521 [2] NCCL INFO Channel 02/0 : 90[2] -> 94[2] [receive] via NET/AWS Libfabric/2
28: nid005929:16030:16665 [0] NCCL INFO Channel 05/0 : 112[0] -> 113[1] via P2P/CUMEM
 1: nid005576:147558:148199 [1] NCCL INFO Channel 01/0 : 5[1] -> 4[0] via P2P/CUMEM
23: nid005917:276888:277520 [3] NCCL INFO Channel 07/0 : 95[3] -> 92[0] via P2P/CUMEM
 5: nid005582:196714:197502 [1] NCCL INFO Channel 00/0 : 21[1] -> 22[2] via P2P/CUMEM
11: nid005591:191603:192243 [0] NCCL INFO Channel 04/0 : 36[0] -> 44[0] [receive] via NET/AWS Libfabric/0
 1: nid005576:147557:148198 [0] NCCL INFO Channel 01/0 : 4[0] -> 8[0] [send] via NET/AWS Libfabric/0
20: nid005913:292681:293318 [0] NCCL INFO Channel 05/0 : 80[0] -> 81[1] via P2P/CUMEM
10: nid005590:110710:111344 [0] NCCL INFO Channel 00/0 : 40[0] -> 48[0] [send] via NET/AWS Libfabric/0
11: nid005591:191603:192243 [0] NCCL INFO Channel 05/0 : 36[0] -> 44[0] [receive] via NET/AWS Libfabric/0
 1: nid005576:147558:148199 [1] NCCL INFO Channel 03/0 : 5[1] -> 4[0] via P2P/CUMEM
10: nid005590:110710:111344 [0] NCCL INFO Channel 01/0 : 40[0] -> 48[0] [send] via NET/AWS Libfabric/0
 1: nid005576:147557:148198 [0] NCCL INFO Channel 05/0 : 4[0] -> 8[0] [send] via NET/AWS Libfabric/0
 9: nid005588:35937:36596 [2] NCCL INFO Channel 06/0 : 38[2] -> 46[2] [send] via NET/AWS Libfabric/2
11: nid005591:191604:192246 [1] NCCL INFO Channel 01/0 : 45[1] -> 44[0] via P2P/CUMEM
11: nid005591:191603:192243 [0] NCCL INFO Channel 04/0 : 44[0] -> 52[0] [send] via NET/AWS Libfabric/0
 9: nid005588:35937:36596 [2] NCCL INFO Channel 07/0 : 38[2] -> 46[2] [send] via NET/AWS Libfabric/2
 1: nid005576:147558:148199 [1] NCCL INFO Channel 05/0 : 5[1] -> 4[0] via P2P/CUMEM
 6: nid005584:28288:28916 [3] NCCL INFO Channel 02/0 : 27[3] -> 24[0] via P2P/CUMEM
10: nid005590:110711:111345 [1] NCCL INFO Channel 02/0 : 41[1] -> 40[0] via P2P/CUMEM
20: nid005913:292681:293318 [0] NCCL INFO Channel 06/0 : 80[0] -> 81[1] via P2P/CUMEM
11: nid005591:191603:192243 [0] NCCL INFO Channel 05/0 : 44[0] -> 52[0] [send] via NET/AWS Libfabric/0
10: nid005590:110713:111343 [3] NCCL INFO Channel 06/0 : 43[3] -> 40[0] via P2P/CUMEM
11: nid005591:191604:192246 [1] NCCL INFO Channel 03/0 : 45[1] -> 44[0] via P2P/CUMEM
28: nid005929:16030:16665 [0] NCCL INFO Channel 06/0 : 112[0] -> 113[1] via P2P/CUMEM
11: nid005591:191605:192244 [2] NCCL INFO Channel 06/0 : 38[2] -> 46[2] [receive] via NET/AWS Libfabric/2
10: nid005590:110712:111346 [2] NCCL INFO Channel 02/0 : 42[2] -> 50[2] [send] via NET/AWS Libfabric/2
 2: nid005577:17423:18082 [1] NCCL INFO Channel 05/0 : 9[1] -> 10[2] via P2P/CUMEM
 2: nid005577:17424:18083 [2] NCCL INFO Channel 01/0 : 10[2] -> 11[3] via P2P/CUMEM
 2: nid005577:17424:18083 [2] NCCL INFO Channel 02/0 : 10[2] -> 11[3] via P2P/CUMEM
 2: nid005577:17424:18083 [2] NCCL INFO Channel 03/0 : 10[2] -> 11[3] via P2P/CUMEM
 1: nid005576:147558:148199 [1] NCCL INFO Channel 07/0 : 5[1] -> 4[0] via P2P/CUMEM
11: nid005591:191605:192244 [2] NCCL INFO Channel 07/0 : 38[2] -> 46[2] [receive] via NET/AWS Libfabric/2
 2: nid005577:17424:18083 [2] NCCL INFO Channel 05/0 : 10[2] -> 11[3] via P2P/CUMEM
 5: nid005582:196715:197503 [2] NCCL INFO Channel 07/0 : 22[2] -> 23[3] via P2P/CUMEM
 2: nid005577:17424:18083 [2] NCCL INFO Channel 06/0 : 10[2] -> 11[3] via P2P/CUMEM
 2: nid005577:17424:18083 [2] NCCL INFO Channel 07/0 : 10[2] -> 11[3] via P2P/CUMEM
 6: nid005584:28287:28919 [2] NCCL INFO Channel 03/0 : 22[2] -> 26[2] [receive] via NET/AWS Libfabric/2
10: nid005590:110712:111346 [2] NCCL INFO Channel 03/0 : 42[2] -> 50[2] [send] via NET/AWS Libfabric/2
 2: nid005577:17425:18084 [3] NCCL INFO Channel 02/0 : 11[3] -> 8[0] via P2P/CUMEM
11: nid005591:191604:192246 [1] NCCL INFO Channel 05/0 : 45[1] -> 44[0] via P2P/CUMEM
 9: nid005588:35935:36599 [0] NCCL INFO Channel 04/0 : 44[0] -> 36[0] [receive] via NET/AWS Libfabric/0
20: nid005913:292681:293318 [0] NCCL INFO Channel 07/0 : 80[0] -> 81[1] via P2P/CUMEM
19: nid005912:12435:13072 [0] NCCL INFO Channel 02/0 : 76[0] -> 77[1] via P2P/CUMEM
 5: nid005582:196713:197505 [0] NCCL INFO Channel 03/0 : 20[0] -> 21[1] via P2P/CUMEM
11: nid005591:191605:192244 [2] NCCL INFO Channel 06/0 : 46[2] -> 54[2] [send] via NET/AWS Libfabric/2
14: nid005600:217721:218386 [1] NCCL INFO Channel 01/0 : 57[1] -> 58[2] via P2P/CUMEM
 6: nid005584:28288:28916 [3] NCCL INFO Channel 03/0 : 27[3] -> 24[0] via P2P/CUMEM
10: nid005590:110711:111345 [1] NCCL INFO Channel 04/0 : 41[1] -> 40[0] via P2P/CUMEM
 9: nid005588:35935:36599 [0] NCCL INFO Channel 05/0 : 44[0] -> 36[0] [receive] via NET/AWS Libfabric/0
23: nid005917:276885:277523 [0] NCCL INFO Channel 00/0 : 92[0] -> 93[1] via P2P/CUMEM
 6: nid005584:28287:28919 [2] NCCL INFO Channel 07/0 : 22[2] -> 26[2] [receive] via NET/AWS Libfabric/2
11: nid005591:191605:192244 [2] NCCL INFO Channel 07/0 : 46[2] -> 54[2] [send] via NET/AWS Libfabric/2
 2: nid005577:17425:18084 [3] NCCL INFO Channel 03/0 : 11[3] -> 8[0] via P2P/CUMEM
 2: nid005577:17424:18083 [2] NCCL INFO Channel 03/0 : 6[2] -> 10[2] [receive] via NET/AWS Libfabric/2
27: nid005922:80741:81383 [0] NCCL INFO Channel 00/0 : 108[0] -> 109[1] via P2P/CUMEM
 6: nid005584:28286:28918 [1] NCCL INFO Channel 00/0 : 25[1] -> 24[0] via P2P/CUMEM
10: nid005590:110713:111343 [3] NCCL INFO Channel 07/0 : 43[3] -> 40[0] via P2P/CUMEM
 5: nid005582:196714:197502 [1] NCCL INFO Channel 04/0 : 21[1] -> 22[2] via P2P/CUMEM
 3: nid005580:71820:72470 [1] NCCL INFO Channel 00/0 : 13[1] -> 14[2] via P2P/CUMEM
 6: nid005584:28287:28919 [2] NCCL INFO Channel 02/0 : 26[2] -> 30[2] [send] via NET/AWS Libfabric/2
11: nid005591:191604:192246 [1] NCCL INFO Channel 07/0 : 45[1] -> 44[0] via P2P/CUMEM
 2: nid005577:17424:18083 [2] NCCL INFO Channel 07/0 : 6[2] -> 10[2] [receive] via NET/AWS Libfabric/2
30: nid005936:49910:50568 [2] NCCL INFO Channel 01/0 : 122[2] -> 123[3] via P2P/CUMEM
14: nid005600:217721:218386 [1] NCCL INFO Channel 05/0 : 57[1] -> 58[2] via P2P/CUMEM
 2: nid005577:17424:18083 [2] NCCL INFO Channel 02/0 : 10[2] -> 14[2] [send] via NET/AWS Libfabric/2
 6: nid005584:28288:28916 [3] NCCL INFO Channel 06/0 : 27[3] -> 24[0] via P2P/CUMEM
 2: nid005577:17425:18084 [3] NCCL INFO Channel 06/0 : 11[3] -> 8[0] via P2P/CUMEM
 9: nid005588:35937:36596 [2] NCCL INFO Channel 06/0 : 46[2] -> 38[2] [receive] via NET/AWS Libfabric/2
30: nid005936:49910:50568 [2] NCCL INFO Channel 02/0 : 122[2] -> 123[3] via P2P/CUMEM
28: nid005929:16030:16665 [0] NCCL INFO Channel 07/0 : 112[0] -> 113[1] via P2P/CUMEM
 4: nid005581:264525:265164 [2] NCCL INFO Channel 01/0 : 18[2] -> 19[3] via P2P/CUMEM
 6: nid005584:28286:28918 [1] NCCL INFO Channel 02/0 : 25[1] -> 24[0] via P2P/CUMEM
 9: nid005588:35937:36596 [2] NCCL INFO Channel 07/0 : 46[2] -> 38[2] [receive] via NET/AWS Libfabric/2
 3: nid005580:71820:72470 [1] NCCL INFO Channel 04/0 : 13[1] -> 14[2] via P2P/CUMEM
10: nid005590:110711:111345 [1] NCCL INFO Channel 06/0 : 41[1] -> 40[0] via P2P/CUMEM
30: nid005936:49910:50568 [2] NCCL INFO Channel 03/0 : 122[2] -> 123[3] via P2P/CUMEM
 6: nid005584:28288:28916 [3] NCCL INFO Channel 07/0 : 27[3] -> 24[0] via P2P/CUMEM
 2: nid005577:17422:18081 [0] NCCL INFO Channel 02/0 : 8[0] -> 9[1] via P2P/CUMEM
 7: nid005585:122007:122642 [2] NCCL INFO Channel 06/0 : 14[2] -> 30[2] [receive] via NET/AWS Libfabric/2
 2: nid005577:17425:18084 [3] NCCL INFO Channel 07/0 : 11[3] -> 8[0] via P2P/CUMEM
23: nid005917:276885:277523 [0] NCCL INFO Channel 02/0 : 92[0] -> 93[1] via P2P/CUMEM
 4: nid005581:264525:265164 [2] NCCL INFO Channel 02/0 : 18[2] -> 19[3] via P2P/CUMEM
 7: nid005585:122007:122642 [2] NCCL INFO Channel 07/0 : 14[2] -> 30[2] [receive] via NET/AWS Libfabric/2
20: nid005913:292681:293318 [0] NCCL INFO Channel 04/0 : 80[0] -> 84[0] [send] via NET/AWS Libfabric/0
 5: nid005582:196713:197505 [0] NCCL INFO Channel 04/0 : 20[0] -> 21[1] via P2P/CUMEM
27: nid005922:80741:81383 [0] NCCL INFO Channel 02/0 : 108[0] -> 109[1] via P2P/CUMEM
 6: nid005584:28286:28918 [1] NCCL INFO Channel 04/0 : 25[1] -> 24[0] via P2P/CUMEM
 4: nid005581:264525:265164 [2] NCCL INFO Channel 03/0 : 18[2] -> 19[3] via P2P/CUMEM
 7: nid005585:122007:122642 [2] NCCL INFO Channel 06/0 : 30[2] -> 46[2] [send] via NET/AWS Libfabric/2
23: nid005917:276885:277523 [0] NCCL INFO Channel 03/0 : 92[0] -> 93[1] via P2P/CUMEM
14: nid005600:217720:218385 [0] NCCL INFO Channel 01/0 : 52[0] -> 56[0] [receive] via NET/AWS Libfabric/0
 7: nid005585:122007:122642 [2] NCCL INFO Channel 07/0 : 30[2] -> 46[2] [send] via NET/AWS Libfabric/2
30: nid005936:49910:50568 [2] NCCL INFO Channel 05/0 : 122[2] -> 123[3] via P2P/CUMEM
28: nid005929:16031:16666 [1] NCCL INFO Channel 01/0 : 113[1] -> 114[2] via P2P/CUMEM
 4: nid005581:264525:265164 [2] NCCL INFO Channel 05/0 : 18[2] -> 19[3] via P2P/CUMEM
 5: nid005582:196713:197505 [0] NCCL INFO Channel 06/0 : 20[0] -> 21[1] via P2P/CUMEM
19: nid005912:12435:13072 [0] NCCL INFO Channel 03/0 : 76[0] -> 77[1] via P2P/CUMEM
27: nid005922:80741:81383 [0] NCCL INFO Channel 03/0 : 108[0] -> 109[1] via P2P/CUMEM
 6: nid005584:28286:28918 [1] NCCL INFO Channel 06/0 : 25[1] -> 24[0] via P2P/CUMEM
 2: nid005577:17422:18081 [0] NCCL INFO Channel 03/0 : 8[0] -> 9[1] via P2P/CUMEM
14: nid005600:217720:218385 [0] NCCL INFO Channel 05/0 : 52[0] -> 56[0] [receive] via NET/AWS Libfabric/0
 5: nid005582:196716:197504 [3] NCCL INFO Channel 02/0 : 23[3] -> 20[0] via P2P/CUMEM
23: nid005917:276885:277523 [0] NCCL INFO Channel 04/0 : 92[0] -> 93[1] via P2P/CUMEM
19: nid005912:12437:13073 [2] NCCL INFO Channel 00/0 : 78[2] -> 79[3] via P2P/CUMEM
14: nid005600:217720:218385 [0] NCCL INFO Channel 00/0 : 56[0] -> 60[0] [send] via NET/AWS Libfabric/0
 4: nid005581:264525:265164 [2] NCCL INFO Channel 06/0 : 18[2] -> 19[3] via P2P/CUMEM
27: nid005922:80741:81383 [0] NCCL INFO Channel 04/0 : 108[0] -> 109[1] via P2P/CUMEM
23: nid005917:276885:277523 [0] NCCL INFO Channel 06/0 : 92[0] -> 93[1] via P2P/CUMEM
30: nid005936:49910:50568 [2] NCCL INFO Channel 06/0 : 122[2] -> 123[3] via P2P/CUMEM
 2: nid005577:17422:18081 [0] NCCL INFO Channel 05/0 : 8[0] -> 9[1] via P2P/CUMEM
 5: nid005582:196713:197505 [0] NCCL INFO Channel 07/0 : 20[0] -> 21[1] via P2P/CUMEM
 4: nid005581:264525:265164 [2] NCCL INFO Channel 07/0 : 18[2] -> 19[3] via P2P/CUMEM
28: nid005929:16031:16666 [1] NCCL INFO Channel 05/0 : 113[1] -> 114[2] via P2P/CUMEM
 5: nid005582:196716:197504 [3] NCCL INFO Channel 03/0 : 23[3] -> 20[0] via P2P/CUMEM
 5: nid005582:196715:197503 [2] NCCL INFO Channel 06/0 : 18[2] -> 22[2] [receive] via NET/AWS Libfabric/2
 3: nid005580:71819:72468 [0] NCCL INFO Channel 02/0 : 12[0] -> 13[1] via P2P/CUMEM
16: nid005802:6297:7000 [0] NCCL INFO Channel 01/0 : 64[0] -> 65[1] via P2P/CUMEM
23: nid005917:276885:277523 [0] NCCL INFO Channel 07/0 : 92[0] -> 93[1] via P2P/CUMEM
 2: nid005577:17422:18081 [0] NCCL INFO Channel 06/0 : 8[0] -> 9[1] via P2P/CUMEM
27: nid005922:80741:81383 [0] NCCL INFO Channel 06/0 : 108[0] -> 109[1] via P2P/CUMEM
 5: nid005582:196715:197503 [2] NCCL INFO Channel 03/0 : 22[2] -> 26[2] [send] via NET/AWS Libfabric/2
 5: nid005582:196715:197503 [2] NCCL INFO Channel 07/0 : 22[2] -> 26[2] [send] via NET/AWS Libfabric/2
27: nid005922:80741:81383 [0] NCCL INFO Channel 07/0 : 108[0] -> 109[1] via P2P/CUMEM
 5: nid005582:196716:197504 [3] NCCL INFO Channel 06/0 : 23[3] -> 20[0] via P2P/CUMEM
15: nid005601:210676:211332 [0] NCCL INFO Channel 04/0 : 28[0] -> 60[0] [receive] via NET/AWS Libfabric/0
 3: nid005580:71819:72468 [0] NCCL INFO Channel 03/0 : 12[0] -> 13[1] via P2P/CUMEM
 2: nid005577:17422:18081 [0] NCCL INFO Channel 07/0 : 8[0] -> 9[1] via P2P/CUMEM
30: nid005936:49910:50568 [2] NCCL INFO Channel 07/0 : 122[2] -> 123[3] via P2P/CUMEM
15: nid005601:210676:211332 [0] NCCL INFO Channel 05/0 : 28[0] -> 60[0] [receive] via NET/AWS Libfabric/0
25: nid005919:107462:108105 [0] NCCL INFO Channel 00/0 : 100[0] -> 101[1] via P2P/CUMEM
14: nid005600:217720:218385 [0] NCCL INFO Channel 00/0 : 48[0] -> 56[0] [receive] via NET/AWS Libfabric/0
 5: nid005582:196716:197504 [3] NCCL INFO Channel 07/0 : 23[3] -> 20[0] via P2P/CUMEM
14: nid005600:217720:218385 [0] NCCL INFO Channel 01/0 : 48[0] -> 56[0] [receive] via NET/AWS Libfabric/0
15: nid005601:210676:211332 [0] NCCL INFO Channel 04/0 : 60[0] -> 92[0] [send] via NET/AWS Libfabric/0
19: nid005912:12435:13072 [0] NCCL INFO Channel 04/0 : 76[0] -> 77[1] via P2P/CUMEM
 6: nid005584:28287:28919 [2] NCCL INFO Channel 02/0 : 18[2] -> 26[2] [receive] via NET/AWS Libfabric/2
 3: nid005580:71819:72468 [0] NCCL INFO Channel 04/0 : 12[0] -> 13[1] via P2P/CUMEM
15: nid005601:210676:211332 [0] NCCL INFO Channel 05/0 : 60[0] -> 92[0] [send] via NET/AWS Libfabric/0
22: nid005915:274816:275451 [2] NCCL INFO Channel 01/0 : 90[2] -> 91[3] via P2P/CUMEM
23: nid005917:276885:277523 [0] NCCL INFO Channel 00/0 : 88[0] -> 92[0] [receive] via NET/AWS Libfabric/0
19: nid005912:12437:13073 [2] NCCL INFO Channel 02/0 : 78[2] -> 79[3] via P2P/CUMEM
 6: nid005584:28287:28919 [2] NCCL INFO Channel 03/0 : 18[2] -> 26[2] [receive] via NET/AWS Libfabric/2
 5: nid005582:196713:197505 [0] NCCL INFO Channel 04/0 : 16[0] -> 20[0] [receive] via NET/AWS Libfabric/0
16: nid005802:6297:7000 [0] NCCL INFO Channel 02/0 : 64[0] -> 65[1] via P2P/CUMEM
 3: nid005580:71819:72468 [0] NCCL INFO Channel 06/0 : 12[0] -> 13[1] via P2P/CUMEM
 5: nid005582:196713:197505 [0] NCCL INFO Channel 01/0 : 20[0] -> 24[0] [send] via NET/AWS Libfabric/0
28: nid005929:16030:16665 [0] NCCL INFO Channel 04/0 : 112[0] -> 116[0] [send] via NET/AWS Libfabric/0
22: nid005915:274816:275451 [2] NCCL INFO Channel 02/0 : 90[2] -> 91[3] via P2P/CUMEM
23: nid005917:276886:277522 [1] NCCL INFO Channel 01/0 : 93[1] -> 92[0] via P2P/CUMEM
 5: nid005582:196713:197505 [0] NCCL INFO Channel 05/0 : 20[0] -> 24[0] [send] via NET/AWS Libfabric/0
22: nid005915:274816:275451 [2] NCCL INFO Channel 03/0 : 90[2] -> 91[3] via P2P/CUMEM
 3: nid005580:71819:72468 [0] NCCL INFO Channel 07/0 : 12[0] -> 13[1] via P2P/CUMEM
23: nid005917:276886:277522 [1] NCCL INFO Channel 03/0 : 93[1] -> 92[0] via P2P/CUMEM
 2: nid005577:17422:18081 [0] NCCL INFO Channel 01/0 : 4[0] -> 8[0] [receive] via NET/AWS Libfabric/0
 5: nid005582:196714:197502 [1] NCCL INFO Channel 01/0 : 21[1] -> 20[0] via P2P/CUMEM
28: nid005929:16030:16665 [0] NCCL INFO Channel 00/0 : 104[0] -> 112[0] [receive] via NET/AWS Libfabric/0
16: nid005802:6297:7000 [0] NCCL INFO Channel 03/0 : 64[0] -> 65[1] via P2P/CUMEM
28: nid005929:16033:16667 [3] NCCL INFO Channel 02/0 : 115[3] -> 112[0] via P2P/CUMEM
28: nid005929:16030:16665 [0] NCCL INFO Channel 01/0 : 104[0] -> 112[0] [receive] via NET/AWS Libfabric/0
22: nid005915:274816:275451 [2] NCCL INFO Channel 05/0 : 90[2] -> 91[3] via P2P/CUMEM
 2: nid005577:17422:18081 [0] NCCL INFO Channel 05/0 : 4[0] -> 8[0] [receive] via NET/AWS Libfabric/0
 2: nid005577:17423:18082 [1] NCCL INFO Channel 00/0 : 9[1] -> 8[0] via P2P/CUMEM
24: nid005918:92505:93178 [1] NCCL INFO Channel 01/0 : 97[1] -> 98[2] via P2P/CUMEM
13: nid005595:197886:198574 [3] NCCL INFO Channel 02/0 : 55[3] -> 52[0] via P2P/CUMEM
23: nid005917:276886:277522 [1] NCCL INFO Channel 05/0 : 93[1] -> 92[0] via P2P/CUMEM
 5: nid005582:196714:197502 [1] NCCL INFO Channel 03/0 : 21[1] -> 20[0] via P2P/CUMEM
25: nid005919:107462:108105 [0] NCCL INFO Channel 02/0 : 100[0] -> 101[1] via P2P/CUMEM
28: nid005929:16031:16666 [1] NCCL INFO Channel 00/0 : 113[1] -> 112[0] via P2P/CUMEM
28: nid005929:16030:16665 [0] NCCL INFO Channel 00/0 : 112[0] -> 120[0] [send] via NET/AWS Libfabric/0
 2: nid005577:17422:18081 [0] NCCL INFO Channel 00/0 : 8[0] -> 12[0] [send] via NET/AWS Libfabric/0
28: nid005929:16032:16664 [2] NCCL INFO Channel 06/0 : 114[2] -> 118[2] [send] via NET/AWS Libfabric/2
22: nid005915:274816:275451 [2] NCCL INFO Channel 06/0 : 90[2] -> 91[3] via P2P/CUMEM
19: nid005912:12435:13072 [0] NCCL INFO Channel 06/0 : 76[0] -> 77[1] via P2P/CUMEM
23: nid005917:276886:277522 [1] NCCL INFO Channel 07/0 : 93[1] -> 92[0] via P2P/CUMEM
 6: nid005584:28285:28917 [0] NCCL INFO Channel 00/0 : 16[0] -> 24[0] [receive] via NET/AWS Libfabric/0
 2: nid005577:17423:18082 [1] NCCL INFO Channel 02/0 : 9[1] -> 8[0] via P2P/CUMEM
 5: nid005582:196714:197502 [1] NCCL INFO Channel 05/0 : 21[1] -> 20[0] via P2P/CUMEM
24: nid005918:92505:93178 [1] NCCL INFO Channel 05/0 : 97[1] -> 98[2] via P2P/CUMEM
19: nid005912:12437:13073 [2] NCCL INFO Channel 03/0 : 78[2] -> 79[3] via P2P/CUMEM
28: nid005929:16030:16665 [0] NCCL INFO Channel 01/0 : 112[0] -> 120[0] [send] via NET/AWS Libfabric/0
28: nid005929:16033:16667 [3] NCCL INFO Channel 03/0 : 115[3] -> 112[0] via P2P/CUMEM
13: nid005595:197886:198574 [3] NCCL INFO Channel 03/0 : 55[3] -> 52[0] via P2P/CUMEM
 6: nid005584:28285:28917 [0] NCCL INFO Channel 01/0 : 16[0] -> 24[0] [receive] via NET/AWS Libfabric/0
13: nid005595:197885:198571 [2] NCCL INFO Channel 06/0 : 50[2] -> 54[2] [receive] via NET/AWS Libfabric/2
22: nid005915:274816:275451 [2] NCCL INFO Channel 07/0 : 90[2] -> 91[3] via P2P/CUMEM
16: nid005802:6297:7000 [0] NCCL INFO Channel 05/0 : 64[0] -> 65[1] via P2P/CUMEM
13: nid005595:197885:198571 [2] NCCL INFO Channel 03/0 : 54[2] -> 58[2] [send] via NET/AWS Libfabric/2
 2: nid005577:17423:18082 [1] NCCL INFO Channel 04/0 : 9[1] -> 8[0] via P2P/CUMEM
 5: nid005582:196714:197502 [1] NCCL INFO Channel 07/0 : 21[1] -> 20[0] via P2P/CUMEM
25: nid005919:107462:108105 [0] NCCL INFO Channel 03/0 : 100[0] -> 101[1] via P2P/CUMEM
28: nid005929:16032:16664 [2] NCCL INFO Channel 02/0 : 106[2] -> 114[2] [receive] via NET/AWS Libfabric/2
13: nid005595:197886:198574 [3] NCCL INFO Channel 06/0 : 55[3] -> 52[0] via P2P/CUMEM
13: nid005595:197885:198571 [2] NCCL INFO Channel 07/0 : 54[2] -> 58[2] [send] via NET/AWS Libfabric/2
28: nid005929:16032:16664 [2] NCCL INFO Channel 03/0 : 106[2] -> 114[2] [receive] via NET/AWS Libfabric/2
28: nid005929:16031:16666 [1] NCCL INFO Channel 02/0 : 113[1] -> 112[0] via P2P/CUMEM
18: nid005911:38867:39522 [3] NCCL INFO Channel 02/0 : 75[3] -> 72[0] via P2P/CUMEM
 2: nid005577:17423:18082 [1] NCCL INFO Channel 06/0 : 9[1] -> 8[0] via P2P/CUMEM
28: nid005929:16033:16667 [3] NCCL INFO Channel 06/0 : 115[3] -> 112[0] via P2P/CUMEM
28: nid005929:16032:16664 [2] NCCL INFO Channel 02/0 : 114[2] -> 122[2] [send] via NET/AWS Libfabric/2
13: nid005595:197886:198574 [3] NCCL INFO Channel 07/0 : 55[3] -> 52[0] via P2P/CUMEM
28: nid005929:16032:16664 [2] NCCL INFO Channel 03/0 : 114[2] -> 122[2] [send] via NET/AWS Libfabric/2
25: nid005919:107462:108105 [0] NCCL INFO Channel 04/0 : 100[0] -> 101[1] via P2P/CUMEM
16: nid005802:6297:7000 [0] NCCL INFO Channel 06/0 : 64[0] -> 65[1] via P2P/CUMEM
18: nid005911:38866:39520 [2] NCCL INFO Channel 03/0 : 70[2] -> 74[2] [receive] via NET/AWS Libfabric/2
18: nid005911:38867:39522 [3] NCCL INFO Channel 03/0 : 75[3] -> 72[0] via P2P/CUMEM
 3: nid005580:71821:72471 [2] NCCL INFO Channel 00/0 : 14[2] -> 15[3] via P2P/CUMEM
 3: nid005580:71819:72468 [0] NCCL INFO Channel 00/0 : 8[0] -> 12[0] [receive] via NET/AWS Libfabric/0
 4: nid005581:264523:265165 [0] NCCL INFO Channel 01/0 : 16[0] -> 17[1] via P2P/CUMEM
22: nid005915:274817:275450 [3] NCCL INFO Channel 02/0 : 91[3] -> 88[0] via P2P/CUMEM
18: nid005911:38866:39520 [2] NCCL INFO Channel 07/0 : 70[2] -> 74[2] [receive] via NET/AWS Libfabric/2
24: nid005918:92504:93175 [0] NCCL INFO Channel 04/0 : 96[0] -> 100[0] [send] via NET/AWS Libfabric/0
19: nid005912:12437:13073 [2] NCCL INFO Channel 04/0 : 78[2] -> 79[3] via P2P/CUMEM
28: nid005929:16031:16666 [1] NCCL INFO Channel 04/0 : 113[1] -> 112[0] via P2P/CUMEM
18: nid005911:38866:39520 [2] NCCL INFO Channel 02/0 : 74[2] -> 78[2] [send] via NET/AWS Libfabric/2
19: nid005912:12436:13071 [1] NCCL INFO Channel 00/0 : 77[1] -> 78[2] via P2P/CUMEM
28: nid005929:16033:16667 [3] NCCL INFO Channel 07/0 : 115[3] -> 112[0] via P2P/CUMEM
18: nid005911:38867:39522 [3] NCCL INFO Channel 06/0 : 75[3] -> 72[0] via P2P/CUMEM
19: nid005912:12435:13072 [0] NCCL INFO Channel 07/0 : 76[0] -> 77[1] via P2P/CUMEM
24: nid005918:92506:93176 [2] NCCL INFO Channel 06/0 : 98[2] -> 102[2] [send] via NET/AWS Libfabric/2
 3: nid005580:71821:72471 [2] NCCL INFO Channel 02/0 : 14[2] -> 15[3] via P2P/CUMEM
25: nid005919:107462:108105 [0] NCCL INFO Channel 06/0 : 100[0] -> 101[1] via P2P/CUMEM
22: nid005915:274817:275450 [3] NCCL INFO Channel 03/0 : 91[3] -> 88[0] via P2P/CUMEM
16: nid005802:6297:7000 [0] NCCL INFO Channel 07/0 : 64[0] -> 65[1] via P2P/CUMEM
16: nid005802:6298:6998 [1] NCCL INFO Channel 01/0 : 65[1] -> 66[2] via P2P/CUMEM
 3: nid005580:71819:72468 [0] NCCL INFO Channel 04/0 : 4[0] -> 12[0] [receive] via NET/AWS Libfabric/0
 2: nid005577:17422:18081 [0] NCCL INFO Channel 00/0 : 8[0] -> 16[0] [send] via NET/AWS Libfabric/0
18: nid005911:38867:39522 [3] NCCL INFO Channel 07/0 : 75[3] -> 72[0] via P2P/CUMEM
 3: nid005580:71819:72468 [0] NCCL INFO Channel 05/0 : 4[0] -> 12[0] [receive] via NET/AWS Libfabric/0
19: nid005912:12437:13073 [2] NCCL INFO Channel 06/0 : 78[2] -> 79[3] via P2P/CUMEM
 2: nid005577:17422:18081 [0] NCCL INFO Channel 01/0 : 8[0] -> 16[0] [send] via NET/AWS Libfabric/0
 3: nid005580:71821:72471 [2] NCCL INFO Channel 03/0 : 14[2] -> 15[3] via P2P/CUMEM
28: nid005929:16031:16666 [1] NCCL INFO Channel 06/0 : 113[1] -> 112[0] via P2P/CUMEM
22: nid005915:274817:275450 [3] NCCL INFO Channel 06/0 : 91[3] -> 88[0] via P2P/CUMEM
 3: nid005580:71819:72468 [0] NCCL INFO Channel 04/0 : 12[0] -> 20[0] [send] via NET/AWS Libfabric/0
19: nid005912:12436:13071 [1] NCCL INFO Channel 04/0 : 77[1] -> 78[2] via P2P/CUMEM
30: nid005936:49911:50569 [3] NCCL INFO Channel 02/0 : 123[3] -> 120[0] via P2P/CUMEM
30: nid005936:49909:50570 [1] NCCL INFO Channel 01/0 : 121[1] -> 122[2] via P2P/CUMEM
24: nid005918:92505:93178 [1] NCCL INFO Channel 00/0 : 97[1] -> 96[0] via P2P/CUMEM
 3: nid005580:71819:72468 [0] NCCL INFO Channel 05/0 : 12[0] -> 20[0] [send] via NET/AWS Libfabric/0
25: nid005919:107462:108105 [0] NCCL INFO Channel 07/0 : 100[0] -> 101[1] via P2P/CUMEM
22: nid005915:274817:275450 [3] NCCL INFO Channel 07/0 : 91[3] -> 88[0] via P2P/CUMEM
14: nid005600:217722:218387 [2] NCCL INFO Channel 01/0 : 58[2] -> 59[3] via P2P/CUMEM
 3: nid005580:71821:72471 [2] NCCL INFO Channel 04/0 : 14[2] -> 15[3] via P2P/CUMEM
24: nid005918:92505:93178 [1] NCCL INFO Channel 02/0 : 97[1] -> 96[0] via P2P/CUMEM
 4: nid005581:264523:265165 [0] NCCL INFO Channel 02/0 : 16[0] -> 17[1] via P2P/CUMEM
19: nid005912:12437:13073 [2] NCCL INFO Channel 07/0 : 78[2] -> 79[3] via P2P/CUMEM
14: nid005600:217722:218387 [2] NCCL INFO Channel 02/0 : 58[2] -> 59[3] via P2P/CUMEM
 3: nid005580:71821:72471 [2] NCCL INFO Channel 06/0 : 14[2] -> 15[3] via P2P/CUMEM
16: nid005802:6298:6998 [1] NCCL INFO Channel 05/0 : 65[1] -> 66[2] via P2P/CUMEM
24: nid005918:92505:93178 [1] NCCL INFO Channel 04/0 : 97[1] -> 96[0] via P2P/CUMEM
30: nid005936:49911:50569 [3] NCCL INFO Channel 03/0 : 123[3] -> 120[0] via P2P/CUMEM
 3: nid005580:71821:72471 [2] NCCL INFO Channel 07/0 : 14[2] -> 15[3] via P2P/CUMEM
21: nid005914:166784:167414 [0] NCCL INFO Channel 00/0 : 84[0] -> 85[1] via P2P/CUMEM
30: nid005936:49909:50570 [1] NCCL INFO Channel 05/0 : 121[1] -> 122[2] via P2P/CUMEM
14: nid005600:217722:218387 [2] NCCL INFO Channel 03/0 : 58[2] -> 59[3] via P2P/CUMEM
 4: nid005581:264523:265165 [0] NCCL INFO Channel 03/0 : 16[0] -> 17[1] via P2P/CUMEM
24: nid005918:92505:93178 [1] NCCL INFO Channel 06/0 : 97[1] -> 96[0] via P2P/CUMEM
14: nid005600:217722:218387 [2] NCCL INFO Channel 05/0 : 58[2] -> 59[3] via P2P/CUMEM
 4: nid005581:264523:265165 [0] NCCL INFO Channel 05/0 : 16[0] -> 17[1] via P2P/CUMEM
16: nid005802:6299:7001 [2] NCCL INFO Channel 01/0 : 66[2] -> 67[3] via P2P/CUMEM
19: nid005912:12435:13072 [0] NCCL INFO Channel 00/0 : 72[0] -> 76[0] [receive] via NET/AWS Libfabric/0
25: nid005919:107463:108106 [1] NCCL INFO Channel 00/0 : 101[1] -> 102[2] via P2P/CUMEM
30: nid005936:49911:50569 [3] NCCL INFO Channel 06/0 : 123[3] -> 120[0] via P2P/CUMEM
19: nid005912:12438:13070 [3] NCCL INFO Channel 02/0 : 79[3] -> 76[0] via P2P/CUMEM
 1: nid005576:147560:148200 [3] NCCL INFO Channel 02/0 : 7[3] -> 4[0] via P2P/CUMEM
 4: nid005581:264523:265165 [0] NCCL INFO Channel 06/0 : 16[0] -> 17[1] via P2P/CUMEM
16: nid005802:6297:7000 [0] NCCL INFO Channel 04/0 : 64[0] -> 68[0] [send] via NET/AWS Libfabric/0
 3: nid005580:71822:72469 [3] NCCL INFO Channel 02/0 : 15[3] -> 12[0] via P2P/CUMEM
25: nid005919:107463:108106 [1] NCCL INFO Channel 04/0 : 101[1] -> 102[2] via P2P/CUMEM
30: nid005936:49911:50569 [3] NCCL INFO Channel 07/0 : 123[3] -> 120[0] via P2P/CUMEM
21: nid005914:166784:167414 [0] NCCL INFO Channel 02/0 : 84[0] -> 85[1] via P2P/CUMEM
 1: nid005576:147560:148200 [3] NCCL INFO Channel 03/0 : 7[3] -> 4[0] via P2P/CUMEM
16: nid005802:6299:7001 [2] NCCL INFO Channel 02/0 : 66[2] -> 67[3] via P2P/CUMEM
 1: nid005576:147559:148197 [2] NCCL INFO Channel 06/0 : 2[2] -> 6[2] [receive] via NET/AWS Libfabric/2
14: nid005600:217722:218387 [2] NCCL INFO Channel 06/0 : 58[2] -> 59[3] via P2P/CUMEM
19: nid005912:12435:13072 [0] NCCL INFO Channel 04/0 : 68[0] -> 76[0] [receive] via NET/AWS Libfabric/0
 4: nid005581:264523:265165 [0] NCCL INFO Channel 07/0 : 16[0] -> 17[1] via P2P/CUMEM
19: nid005912:12437:13073 [2] NCCL INFO Channel 02/0 : 74[2] -> 78[2] [receive] via NET/AWS Libfabric/2
19: nid005912:12438:13070 [3] NCCL INFO Channel 03/0 : 79[3] -> 76[0] via P2P/CUMEM
 1: nid005576:147559:148197 [2] NCCL INFO Channel 03/0 : 6[2] -> 10[2] [send] via NET/AWS Libfabric/2
19: nid005912:12436:13071 [1] NCCL INFO Channel 01/0 : 77[1] -> 76[0] via P2P/CUMEM
19: nid005912:12435:13072 [0] NCCL INFO Channel 05/0 : 68[0] -> 76[0] [receive] via NET/AWS Libfabric/0
 1: nid005576:147560:148200 [3] NCCL INFO Channel 06/0 : 7[3] -> 4[0] via P2P/CUMEM
21: nid005914:166784:167414 [0] NCCL INFO Channel 03/0 : 84[0] -> 85[1] via P2P/CUMEM
 3: nid005580:71821:72471 [2] NCCL INFO Channel 02/0 : 10[2] -> 14[2] [receive] via NET/AWS Libfabric/2
 1: nid005576:147559:148197 [2] NCCL INFO Channel 07/0 : 6[2] -> 10[2] [send] via NET/AWS Libfabric/2
30: nid005936:49908:50567 [0] NCCL INFO Channel 01/0 : 116[0] -> 120[0] [receive] via NET/AWS Libfabric/0
 3: nid005580:71822:72469 [3] NCCL INFO Channel 03/0 : 15[3] -> 12[0] via P2P/CUMEM
19: nid005912:12435:13072 [0] NCCL INFO Channel 04/0 : 76[0] -> 84[0] [send] via NET/AWS Libfabric/0
16: nid005802:6299:7001 [2] NCCL INFO Channel 03/0 : 66[2] -> 67[3] via P2P/CUMEM
19: nid005912:12438:13070 [3] NCCL INFO Channel 06/0 : 79[3] -> 76[0] via P2P/CUMEM
19: nid005912:12437:13073 [2] NCCL INFO Channel 06/0 : 70[2] -> 78[2] [receive] via NET/AWS Libfabric/2
19: nid005912:12435:13072 [0] NCCL INFO Channel 05/0 : 76[0] -> 84[0] [send] via NET/AWS Libfabric/0
 1: nid005576:147560:148200 [3] NCCL INFO Channel 07/0 : 7[3] -> 4[0] via P2P/CUMEM
21: nid005914:166784:167414 [0] NCCL INFO Channel 04/0 : 84[0] -> 85[1] via P2P/CUMEM
30: nid005936:49908:50567 [0] NCCL INFO Channel 05/0 : 116[0] -> 120[0] [receive] via NET/AWS Libfabric/0
30: nid005936:49910:50568 [2] NCCL INFO Channel 03/0 : 118[2] -> 122[2] [receive] via NET/AWS Libfabric/2
 3: nid005580:71821:72471 [2] NCCL INFO Channel 06/0 : 6[2] -> 14[2] [receive] via NET/AWS Libfabric/2
14: nid005600:217722:218387 [2] NCCL INFO Channel 07/0 : 58[2] -> 59[3] via P2P/CUMEM
19: nid005912:12437:13073 [2] NCCL INFO Channel 07/0 : 70[2] -> 78[2] [receive] via NET/AWS Libfabric/2
30: nid005936:49908:50567 [0] NCCL INFO Channel 00/0 : 120[0] -> 124[0] [send] via NET/AWS Libfabric/0
30: nid005936:49910:50568 [2] NCCL INFO Channel 07/0 : 118[2] -> 122[2] [receive] via NET/AWS Libfabric/2
 3: nid005580:71820:72470 [1] NCCL INFO Channel 01/0 : 13[1] -> 12[0] via P2P/CUMEM
 3: nid005580:71821:72471 [2] NCCL INFO Channel 07/0 : 6[2] -> 14[2] [receive] via NET/AWS Libfabric/2
25: nid005919:107462:108105 [0] NCCL INFO Channel 04/0 : 96[0] -> 100[0] [receive] via NET/AWS Libfabric/0
19: nid005912:12437:13073 [2] NCCL INFO Channel 06/0 : 78[2] -> 86[2] [send] via NET/AWS Libfabric/2
19: nid005912:12436:13071 [1] NCCL INFO Channel 03/0 : 77[1] -> 76[0] via P2P/CUMEM
19: nid005912:12437:13073 [2] NCCL INFO Channel 07/0 : 78[2] -> 86[2] [send] via NET/AWS Libfabric/2
19: nid005912:12438:13070 [3] NCCL INFO Channel 07/0 : 79[3] -> 76[0] via P2P/CUMEM
21: nid005914:166784:167414 [0] NCCL INFO Channel 06/0 : 84[0] -> 85[1] via P2P/CUMEM
30: nid005936:49910:50568 [2] NCCL INFO Channel 02/0 : 122[2] -> 126[2] [send] via NET/AWS Libfabric/2
 3: nid005580:71822:72469 [3] NCCL INFO Channel 06/0 : 15[3] -> 12[0] via P2P/CUMEM
30: nid005936:49909:50570 [1] NCCL INFO Channel 00/0 : 121[1] -> 120[0] via P2P/CUMEM
 0: nid005574:69060:69729 [2] NCCL INFO Channel 02/0 : 66[2] -> 2[2] [receive] via NET/AWS Libfabric/2
 3: nid005580:71821:72471 [2] NCCL INFO Channel 06/0 : 14[2] -> 22[2] [send] via NET/AWS Libfabric/2
25: nid005919:107462:108105 [0] NCCL INFO Channel 01/0 : 100[0] -> 104[0] [send] via NET/AWS Libfabric/0
22: nid005915:274814:275452 [0] NCCL INFO Channel 01/0 : 88[0] -> 89[1] via P2P/CUMEM
 2: nid005577:17424:18083 [2] NCCL INFO Channel 02/0 : 10[2] -> 18[2] [send] via NET/AWS Libfabric/2
 1: nid005576:147559:148197 [2] NCCL INFO Channel 06/0 : 6[2] -> 14[2] [send] via NET/AWS Libfabric/2
 3: nid005580:71821:72471 [2] NCCL INFO Channel 07/0 : 14[2] -> 22[2] [send] via NET/AWS Libfabric/2
 0: nid005574:69060:69729 [2] NCCL INFO Channel 03/0 : 66[2] -> 2[2] [receive] via NET/AWS Libfabric/2
25: nid005919:107462:108105 [0] NCCL INFO Channel 05/0 : 100[0] -> 104[0] [send] via NET/AWS Libfabric/0
29: nid005932:167680:168334 [0] NCCL INFO Channel 04/0 : 108[0] -> 116[0] [receive] via NET/AWS Libfabric/0
 2: nid005577:17424:18083 [2] NCCL INFO Channel 03/0 : 10[2] -> 18[2] [send] via NET/AWS Libfabric/2
 1: nid005576:147559:148197 [2] NCCL INFO Channel 07/0 : 6[2] -> 14[2] [send] via NET/AWS Libfabric/2
16: nid005802:6299:7001 [2] NCCL INFO Channel 05/0 : 66[2] -> 67[3] via P2P/CUMEM
30: nid005936:49909:50570 [1] NCCL INFO Channel 02/0 : 121[1] -> 120[0] via P2P/CUMEM
29: nid005932:167680:168334 [0] NCCL INFO Channel 05/0 : 108[0] -> 116[0] [receive] via NET/AWS Libfabric/0
 0: nid005574:69060:69729 [2] NCCL INFO Channel 02/0 : 2[2] -> 66[2] [send] via NET/AWS Libfabric/2
30: nid005936:49908:50567 [0] NCCL INFO Channel 00/0 : 112[0] -> 120[0] [receive] via NET/AWS Libfabric/0
31: nid005937:256589:257239 [0] NCCL INFO Channel 04/0 : 60[0] -> 124[0] [receive] via NET/AWS Libfabric/0
 0: nid005574:69060:69729 [2] NCCL INFO Channel 03/0 : 2[2] -> 66[2] [send] via NET/AWS Libfabric/2
 3: nid005580:71820:72470 [1] NCCL INFO Channel 03/0 : 13[1] -> 12[0] via P2P/CUMEM
30: nid005936:49908:50567 [0] NCCL INFO Channel 01/0 : 112[0] -> 120[0] [receive] via NET/AWS Libfabric/0
 3: nid005580:71822:72469 [3] NCCL INFO Channel 07/0 : 15[3] -> 12[0] via P2P/CUMEM
21: nid005914:166784:167414 [0] NCCL INFO Channel 07/0 : 84[0] -> 85[1] via P2P/CUMEM
19: nid005912:12436:13071 [1] NCCL INFO Channel 05/0 : 77[1] -> 76[0] via P2P/CUMEM
31: nid005937:256589:257239 [0] NCCL INFO Channel 05/0 : 60[0] -> 124[0] [receive] via NET/AWS Libfabric/0
 1: nid005576:147559:148197 [2] NCCL INFO Channel 06/0 : 14[2] -> 6[2] [receive] via NET/AWS Libfabric/2
30: nid005936:49909:50570 [1] NCCL INFO Channel 04/0 : 121[1] -> 120[0] via P2P/CUMEM
20: nid005913:292683:293319 [2] NCCL INFO Channel 01/0 : 82[2] -> 83[3] via P2P/CUMEM
30: nid005936:49910:50568 [2] NCCL INFO Channel 02/0 : 114[2] -> 122[2] [receive] via NET/AWS Libfabric/2
29: nid005932:167682:168331 [2] NCCL INFO Channel 06/0 : 110[2] -> 118[2] [receive] via NET/AWS Libfabric/2
24: nid005918:92504:93175 [0] NCCL INFO Channel 00/0 : 80[0] -> 96[0] [receive] via NET/AWS Libfabric/0
25: nid005919:107462:108105 [0] NCCL INFO Channel 04/0 : 100[0] -> 108[0] [send] via NET/AWS Libfabric/0
31: nid005937:256589:257239 [0] NCCL INFO Channel 04/0 : 124[0] -> 60[0] [send] via NET/AWS Libfabric/0
 1: nid005576:147559:148197 [2] NCCL INFO Channel 07/0 : 14[2] -> 6[2] [receive] via NET/AWS Libfabric/2
30: nid005936:49910:50568 [2] NCCL INFO Channel 03/0 : 114[2] -> 122[2] [receive] via NET/AWS Libfabric/2
25: nid005919:107462:108105 [0] NCCL INFO Channel 05/0 : 100[0] -> 108[0] [send] via NET/AWS Libfabric/0
29: nid005932:167682:168331 [2] NCCL INFO Channel 07/0 : 110[2] -> 118[2] [receive] via NET/AWS Libfabric/2
24: nid005918:92504:93175 [0] NCCL INFO Channel 01/0 : 80[0] -> 96[0] [receive] via NET/AWS Libfabric/0
19: nid005912:12436:13071 [1] NCCL INFO Channel 07/0 : 77[1] -> 76[0] via P2P/CUMEM
30: nid005936:49909:50570 [1] NCCL INFO Channel 06/0 : 121[1] -> 120[0] via P2P/CUMEM
31: nid005937:256591:257241 [2] NCCL INFO Channel 06/0 : 62[2] -> 126[2] [receive] via NET/AWS Libfabric/2
31: nid005937:256589:257239 [0] NCCL INFO Channel 05/0 : 124[0] -> 60[0] [send] via NET/AWS Libfabric/0
20: nid005913:292683:293319 [2] NCCL INFO Channel 02/0 : 82[2] -> 83[3] via P2P/CUMEM
30: nid005936:49908:50567 [0] NCCL INFO Channel 00/0 : 120[0] -> 112[0] [send] via NET/AWS Libfabric/0
16: nid005802:6299:7001 [2] NCCL INFO Channel 06/0 : 66[2] -> 67[3] via P2P/CUMEM
 3: nid005580:71820:72470 [1] NCCL INFO Channel 05/0 : 13[1] -> 12[0] via P2P/CUMEM
30: nid005936:49908:50567 [0] NCCL INFO Channel 01/0 : 120[0] -> 112[0] [send] via NET/AWS Libfabric/0
24: nid005918:92504:93175 [0] NCCL INFO Channel 00/0 : 96[0] -> 112[0] [send] via NET/AWS Libfabric/0
31: nid005937:256591:257241 [2] NCCL INFO Channel 07/0 : 62[2] -> 126[2] [receive] via NET/AWS Libfabric/2
24: nid005918:92504:93175 [0] NCCL INFO Channel 01/0 : 96[0] -> 112[0] [send] via NET/AWS Libfabric/0
30: nid005936:49910:50568 [2] NCCL INFO Channel 02/0 : 122[2] -> 114[2] [send] via NET/AWS Libfabric/2
22: nid005915:274814:275452 [0] NCCL INFO Channel 02/0 : 88[0] -> 89[1] via P2P/CUMEM
31: nid005937:256591:257241 [2] NCCL INFO Channel 06/0 : 126[2] -> 62[2] [send] via NET/AWS Libfabric/2
20: nid005913:292683:293319 [2] NCCL INFO Channel 03/0 : 82[2] -> 83[3] via P2P/CUMEM
30: nid005936:49910:50568 [2] NCCL INFO Channel 03/0 : 122[2] -> 114[2] [send] via NET/AWS Libfabric/2
 3: nid005580:71820:72470 [1] NCCL INFO Channel 07/0 : 13[1] -> 12[0] via P2P/CUMEM
31: nid005937:256591:257241 [2] NCCL INFO Channel 07/0 : 126[2] -> 62[2] [send] via NET/AWS Libfabric/2
20: nid005913:292683:293319 [2] NCCL INFO Channel 05/0 : 82[2] -> 83[3] via P2P/CUMEM
22: nid005915:274814:275452 [0] NCCL INFO Channel 03/0 : 88[0] -> 89[1] via P2P/CUMEM
16: nid005802:6299:7001 [2] NCCL INFO Channel 07/0 : 66[2] -> 67[3] via P2P/CUMEM
20: nid005913:292683:293319 [2] NCCL INFO Channel 06/0 : 82[2] -> 83[3] via P2P/CUMEM
22: nid005915:274814:275452 [0] NCCL INFO Channel 05/0 : 88[0] -> 89[1] via P2P/CUMEM
14: nid005600:217721:218386 [1] NCCL INFO Channel 00/0 : 57[1] -> 56[0] via P2P/CUMEM
20: nid005913:292683:293319 [2] NCCL INFO Channel 07/0 : 82[2] -> 83[3] via P2P/CUMEM
22: nid005915:274814:275452 [0] NCCL INFO Channel 06/0 : 88[0] -> 89[1] via P2P/CUMEM
22: nid005915:274814:275452 [0] NCCL INFO Channel 07/0 : 88[0] -> 89[1] via P2P/CUMEM
14: nid005600:217721:218386 [1] NCCL INFO Channel 02/0 : 57[1] -> 56[0] via P2P/CUMEM
14: nid005600:217721:218386 [1] NCCL INFO Channel 04/0 : 57[1] -> 56[0] via P2P/CUMEM
20: nid005913:292684:293316 [3] NCCL INFO Channel 02/0 : 83[3] -> 80[0] via P2P/CUMEM
16: nid005802:6300:7002 [3] NCCL INFO Channel 02/0 : 67[3] -> 64[0] via P2P/CUMEM
21: nid005914:166786:167416 [2] NCCL INFO Channel 00/0 : 86[2] -> 87[3] via P2P/CUMEM
14: nid005600:217723:218388 [3] NCCL INFO Channel 02/0 : 59[3] -> 56[0] via P2P/CUMEM
14: nid005600:217721:218386 [1] NCCL INFO Channel 06/0 : 57[1] -> 56[0] via P2P/CUMEM
16: nid005802:6299:7001 [2] NCCL INFO Channel 06/0 : 66[2] -> 70[2] [send] via NET/AWS Libfabric/2
20: nid005913:292683:293319 [2] NCCL INFO Channel 06/0 : 82[2] -> 86[2] [send] via NET/AWS Libfabric/2
20: nid005913:292684:293316 [3] NCCL INFO Channel 03/0 : 83[3] -> 80[0] via P2P/CUMEM
14: nid005600:217722:218387 [2] NCCL INFO Channel 03/0 : 54[2] -> 58[2] [receive] via NET/AWS Libfabric/2
14: nid005600:217722:218387 [2] NCCL INFO Channel 07/0 : 54[2] -> 58[2] [receive] via NET/AWS Libfabric/2
16: nid005802:6300:7002 [3] NCCL INFO Channel 03/0 : 67[3] -> 64[0] via P2P/CUMEM
16: nid005802:6298:6998 [1] NCCL INFO Channel 00/0 : 65[1] -> 64[0] via P2P/CUMEM
14: nid005600:217722:218387 [2] NCCL INFO Channel 02/0 : 58[2] -> 62[2] [send] via NET/AWS Libfabric/2
21: nid005914:166785:167415 [1] NCCL INFO Channel 00/0 : 85[1] -> 86[2] via P2P/CUMEM
14: nid005600:217723:218388 [3] NCCL INFO Channel 03/0 : 59[3] -> 56[0] via P2P/CUMEM
21: nid005914:166786:167416 [2] NCCL INFO Channel 02/0 : 86[2] -> 87[3] via P2P/CUMEM
20: nid005913:292682:293317 [1] NCCL INFO Channel 00/0 : 81[1] -> 80[0] via P2P/CUMEM
20: nid005913:292684:293316 [3] NCCL INFO Channel 06/0 : 83[3] -> 80[0] via P2P/CUMEM
14: nid005600:217723:218388 [3] NCCL INFO Channel 06/0 : 59[3] -> 56[0] via P2P/CUMEM
16: nid005802:6300:7002 [3] NCCL INFO Channel 06/0 : 67[3] -> 64[0] via P2P/CUMEM
16: nid005802:6298:6998 [1] NCCL INFO Channel 02/0 : 65[1] -> 64[0] via P2P/CUMEM
14: nid005600:217723:218388 [3] NCCL INFO Channel 07/0 : 59[3] -> 56[0] via P2P/CUMEM
14: nid005600:217722:218387 [2] NCCL INFO Channel 02/0 : 50[2] -> 58[2] [receive] via NET/AWS Libfabric/2
15: nid005601:210678:211329 [2] NCCL INFO Channel 06/0 : 30[2] -> 62[2] [receive] via NET/AWS Libfabric/2
25: nid005919:107464:108107 [2] NCCL INFO Channel 00/0 : 102[2] -> 103[3] via P2P/CUMEM
21: nid005914:166785:167415 [1] NCCL INFO Channel 04/0 : 85[1] -> 86[2] via P2P/CUMEM
21: nid005914:166786:167416 [2] NCCL INFO Channel 03/0 : 86[2] -> 87[3] via P2P/CUMEM
20: nid005913:292682:293317 [1] NCCL INFO Channel 02/0 : 81[1] -> 80[0] via P2P/CUMEM
20: nid005913:292684:293316 [3] NCCL INFO Channel 07/0 : 83[3] -> 80[0] via P2P/CUMEM
14: nid005600:217722:218387 [2] NCCL INFO Channel 03/0 : 50[2] -> 58[2] [receive] via NET/AWS Libfabric/2
15: nid005601:210678:211329 [2] NCCL INFO Channel 07/0 : 30[2] -> 62[2] [receive] via NET/AWS Libfabric/2
17: nid005803:180733:181386 [1] NCCL INFO Channel 00/0 : 69[1] -> 70[2] via P2P/CUMEM
25: nid005919:107464:108107 [2] NCCL INFO Channel 02/0 : 102[2] -> 103[3] via P2P/CUMEM
15: nid005601:210678:211329 [2] NCCL INFO Channel 06/0 : 62[2] -> 94[2] [send] via NET/AWS Libfabric/2
16: nid005802:6300:7002 [3] NCCL INFO Channel 07/0 : 67[3] -> 64[0] via P2P/CUMEM
16: nid005802:6298:6998 [1] NCCL INFO Channel 04/0 : 65[1] -> 64[0] via P2P/CUMEM
15: nid005601:210678:211329 [2] NCCL INFO Channel 07/0 : 62[2] -> 94[2] [send] via NET/AWS Libfabric/2
17: nid005803:180733:181386 [1] NCCL INFO Channel 04/0 : 69[1] -> 70[2] via P2P/CUMEM
20: nid005913:292682:293317 [1] NCCL INFO Channel 04/0 : 81[1] -> 80[0] via P2P/CUMEM
21: nid005914:166786:167416 [2] NCCL INFO Channel 04/0 : 86[2] -> 87[3] via P2P/CUMEM
25: nid005919:107464:108107 [2] NCCL INFO Channel 03/0 : 102[2] -> 103[3] via P2P/CUMEM
25: nid005919:107464:108107 [2] NCCL INFO Channel 04/0 : 102[2] -> 103[3] via P2P/CUMEM
20: nid005913:292682:293317 [1] NCCL INFO Channel 06/0 : 81[1] -> 80[0] via P2P/CUMEM
27: nid005922:80743:81385 [2] NCCL INFO Channel 00/0 : 110[2] -> 111[3] via P2P/CUMEM
21: nid005914:166786:167416 [2] NCCL INFO Channel 06/0 : 86[2] -> 87[3] via P2P/CUMEM
16: nid005802:6298:6998 [1] NCCL INFO Channel 06/0 : 65[1] -> 64[0] via P2P/CUMEM
25: nid005919:107464:108107 [2] NCCL INFO Channel 06/0 : 102[2] -> 103[3] via P2P/CUMEM
27: nid005922:80743:81385 [2] NCCL INFO Channel 02/0 : 110[2] -> 111[3] via P2P/CUMEM
21: nid005914:166786:167416 [2] NCCL INFO Channel 07/0 : 86[2] -> 87[3] via P2P/CUMEM
21: nid005914:166784:167414 [0] NCCL INFO Channel 04/0 : 80[0] -> 84[0] [receive] via NET/AWS Libfabric/0
21: nid005914:166784:167414 [0] NCCL INFO Channel 01/0 : 84[0] -> 88[0] [send] via NET/AWS Libfabric/0
25: nid005919:107464:108107 [2] NCCL INFO Channel 07/0 : 102[2] -> 103[3] via P2P/CUMEM
27: nid005922:80743:81385 [2] NCCL INFO Channel 03/0 : 110[2] -> 111[3] via P2P/CUMEM
21: nid005914:166784:167414 [0] NCCL INFO Channel 05/0 : 84[0] -> 88[0] [send] via NET/AWS Libfabric/0
22: nid005915:274815:275453 [1] NCCL INFO Channel 01/0 : 89[1] -> 90[2] via P2P/CUMEM
27: nid005922:80743:81385 [2] NCCL INFO Channel 04/0 : 110[2] -> 111[3] via P2P/CUMEM
22: nid005915:274815:275453 [1] NCCL INFO Channel 05/0 : 89[1] -> 90[2] via P2P/CUMEM
20: nid005913:292681:293318 [0] NCCL INFO Channel 00/0 : 72[0] -> 80[0] [receive] via NET/AWS Libfabric/0
27: nid005922:80743:81385 [2] NCCL INFO Channel 06/0 : 110[2] -> 111[3] via P2P/CUMEM
20: nid005913:292681:293318 [0] NCCL INFO Channel 01/0 : 72[0] -> 80[0] [receive] via NET/AWS Libfabric/0
20: nid005913:292681:293318 [0] NCCL INFO Channel 00/0 : 80[0] -> 88[0] [send] via NET/AWS Libfabric/0
27: nid005922:80743:81385 [2] NCCL INFO Channel 07/0 : 110[2] -> 111[3] via P2P/CUMEM
20: nid005913:292681:293318 [0] NCCL INFO Channel 01/0 : 80[0] -> 88[0] [send] via NET/AWS Libfabric/0
21: nid005914:166787:167413 [3] NCCL INFO Channel 02/0 : 87[3] -> 84[0] via P2P/CUMEM
25: nid005919:107465:108104 [3] NCCL INFO Channel 02/0 : 103[3] -> 100[0] via P2P/CUMEM
25: nid005919:107464:108107 [2] NCCL INFO Channel 06/0 : 98[2] -> 102[2] [receive] via NET/AWS Libfabric/2
21: nid005914:166786:167416 [2] NCCL INFO Channel 06/0 : 82[2] -> 86[2] [receive] via NET/AWS Libfabric/2
22: nid005915:274814:275452 [0] NCCL INFO Channel 01/0 : 84[0] -> 88[0] [receive] via NET/AWS Libfabric/0
25: nid005919:107465:108104 [3] NCCL INFO Channel 03/0 : 103[3] -> 100[0] via P2P/CUMEM
25: nid005919:107464:108107 [2] NCCL INFO Channel 03/0 : 102[2] -> 106[2] [send] via NET/AWS Libfabric/2
21: nid005914:166786:167416 [2] NCCL INFO Channel 03/0 : 86[2] -> 90[2] [send] via NET/AWS Libfabric/2
27: nid005922:80744:81384 [3] NCCL INFO Channel 02/0 : 111[3] -> 108[0] via P2P/CUMEM
21: nid005914:166787:167413 [3] NCCL INFO Channel 03/0 : 87[3] -> 84[0] via P2P/CUMEM
25: nid005919:107463:108106 [1] NCCL INFO Channel 01/0 : 101[1] -> 100[0] via P2P/CUMEM
21: nid005914:166785:167415 [1] NCCL INFO Channel 01/0 : 85[1] -> 84[0] via P2P/CUMEM
21: nid005914:166786:167416 [2] NCCL INFO Channel 07/0 : 86[2] -> 90[2] [send] via NET/AWS Libfabric/2
25: nid005919:107464:108107 [2] NCCL INFO Channel 07/0 : 102[2] -> 106[2] [send] via NET/AWS Libfabric/2
22: nid005915:274814:275452 [0] NCCL INFO Channel 05/0 : 84[0] -> 88[0] [receive] via NET/AWS Libfabric/0
22: nid005915:274816:275451 [2] NCCL INFO Channel 03/0 : 86[2] -> 90[2] [receive] via NET/AWS Libfabric/2
22: nid005915:274814:275452 [0] NCCL INFO Channel 00/0 : 88[0] -> 92[0] [send] via NET/AWS Libfabric/0
27: nid005922:80744:81384 [3] NCCL INFO Channel 03/0 : 111[3] -> 108[0] via P2P/CUMEM
22: nid005915:274816:275451 [2] NCCL INFO Channel 07/0 : 86[2] -> 90[2] [receive] via NET/AWS Libfabric/2
22: nid005915:274815:275453 [1] NCCL INFO Channel 00/0 : 89[1] -> 88[0] via P2P/CUMEM
22: nid005915:274816:275451 [2] NCCL INFO Channel 02/0 : 90[2] -> 94[2] [send] via NET/AWS Libfabric/2
20: nid005913:292683:293319 [2] NCCL INFO Channel 02/0 : 74[2] -> 82[2] [receive] via NET/AWS Libfabric/2
25: nid005919:107465:108104 [3] NCCL INFO Channel 06/0 : 103[3] -> 100[0] via P2P/CUMEM
27: nid005922:80744:81384 [3] NCCL INFO Channel 06/0 : 111[3] -> 108[0] via P2P/CUMEM
24: nid005918:92506:93176 [2] NCCL INFO Channel 02/0 : 82[2] -> 98[2] [receive] via NET/AWS Libfabric/2
21: nid005914:166787:167413 [3] NCCL INFO Channel 06/0 : 87[3] -> 84[0] via P2P/CUMEM
25: nid005919:107463:108106 [1] NCCL INFO Channel 03/0 : 101[1] -> 100[0] via P2P/CUMEM
20: nid005913:292683:293319 [2] NCCL INFO Channel 03/0 : 74[2] -> 82[2] [receive] via NET/AWS Libfabric/2
25: nid005919:107464:108107 [2] NCCL INFO Channel 06/0 : 102[2] -> 110[2] [send] via NET/AWS Libfabric/2
22: nid005915:274815:275453 [1] NCCL INFO Channel 02/0 : 89[1] -> 88[0] via P2P/CUMEM
24: nid005918:92506:93176 [2] NCCL INFO Channel 03/0 : 82[2] -> 98[2] [receive] via NET/AWS Libfabric/2
21: nid005914:166785:167415 [1] NCCL INFO Channel 03/0 : 85[1] -> 84[0] via P2P/CUMEM
20: nid005913:292683:293319 [2] NCCL INFO Channel 02/0 : 82[2] -> 90[2] [send] via NET/AWS Libfabric/2
27: nid005922:80744:81384 [3] NCCL INFO Channel 07/0 : 111[3] -> 108[0] via P2P/CUMEM
21: nid005914:166784:167414 [0] NCCL INFO Channel 04/0 : 76[0] -> 84[0] [receive] via NET/AWS Libfabric/0
25: nid005919:107464:108107 [2] NCCL INFO Channel 07/0 : 102[2] -> 110[2] [send] via NET/AWS Libfabric/2
24: nid005918:92506:93176 [2] NCCL INFO Channel 02/0 : 98[2] -> 114[2] [send] via NET/AWS Libfabric/2
22: nid005915:274815:275453 [1] NCCL INFO Channel 04/0 : 89[1] -> 88[0] via P2P/CUMEM
21: nid005914:166784:167414 [0] NCCL INFO Channel 05/0 : 76[0] -> 84[0] [receive] via NET/AWS Libfabric/0
24: nid005918:92506:93176 [2] NCCL INFO Channel 03/0 : 98[2] -> 114[2] [send] via NET/AWS Libfabric/2
20: nid005913:292683:293319 [2] NCCL INFO Channel 03/0 : 82[2] -> 90[2] [send] via NET/AWS Libfabric/2
23: nid005917:276885:277523 [0] NCCL INFO Channel 04/0 : 76[0] -> 92[0] [receive] via NET/AWS Libfabric/0
21: nid005914:166786:167416 [2] NCCL INFO Channel 06/0 : 78[2] -> 86[2] [receive] via NET/AWS Libfabric/2
22: nid005915:274814:275452 [0] NCCL INFO Channel 00/0 : 80[0] -> 88[0] [receive] via NET/AWS Libfabric/0
25: nid005919:107465:108104 [3] NCCL INFO Channel 07/0 : 103[3] -> 100[0] via P2P/CUMEM
22: nid005915:274815:275453 [1] NCCL INFO Channel 06/0 : 89[1] -> 88[0] via P2P/CUMEM
21: nid005914:166786:167416 [2] NCCL INFO Channel 07/0 : 78[2] -> 86[2] [receive] via NET/AWS Libfabric/2
25: nid005919:107463:108106 [1] NCCL INFO Channel 05/0 : 101[1] -> 100[0] via P2P/CUMEM
23: nid005917:276885:277523 [0] NCCL INFO Channel 05/0 : 76[0] -> 92[0] [receive] via NET/AWS Libfabric/0
21: nid005914:166787:167413 [3] NCCL INFO Channel 07/0 : 87[3] -> 84[0] via P2P/CUMEM
23: nid005917:276887:277521 [2] NCCL INFO Channel 06/0 : 78[2] -> 94[2] [receive] via NET/AWS Libfabric/2
22: nid005915:274816:275451 [2] NCCL INFO Channel 02/0 : 82[2] -> 90[2] [receive] via NET/AWS Libfabric/2
22: nid005915:274814:275452 [0] NCCL INFO Channel 01/0 : 80[0] -> 88[0] [receive] via NET/AWS Libfabric/0
21: nid005914:166785:167415 [1] NCCL INFO Channel 05/0 : 85[1] -> 84[0] via P2P/CUMEM
22: nid005915:274816:275451 [2] NCCL INFO Channel 03/0 : 82[2] -> 90[2] [receive] via NET/AWS Libfabric/2
21: nid005914:166784:167414 [0] NCCL INFO Channel 04/0 : 84[0] -> 76[0] [send] via NET/AWS Libfabric/0
23: nid005917:276885:277523 [0] NCCL INFO Channel 04/0 : 92[0] -> 108[0] [send] via NET/AWS Libfabric/0
23: nid005917:276887:277521 [2] NCCL INFO Channel 07/0 : 78[2] -> 94[2] [receive] via NET/AWS Libfabric/2
21: nid005914:166784:167414 [0] NCCL INFO Channel 05/0 : 84[0] -> 76[0] [send] via NET/AWS Libfabric/0
23: nid005917:276885:277523 [0] NCCL INFO Channel 05/0 : 92[0] -> 108[0] [send] via NET/AWS Libfabric/0
22: nid005915:274814:275452 [0] NCCL INFO Channel 00/0 : 88[0] -> 80[0] [send] via NET/AWS Libfabric/0
21: nid005914:166786:167416 [2] NCCL INFO Channel 06/0 : 86[2] -> 78[2] [send] via NET/AWS Libfabric/2
23: nid005917:276887:277521 [2] NCCL INFO Channel 06/0 : 94[2] -> 110[2] [send] via NET/AWS Libfabric/2
21: nid005914:166786:167416 [2] NCCL INFO Channel 07/0 : 86[2] -> 78[2] [send] via NET/AWS Libfabric/2
23: nid005917:276887:277521 [2] NCCL INFO Channel 07/0 : 94[2] -> 110[2] [send] via NET/AWS Libfabric/2
22: nid005915:274814:275452 [0] NCCL INFO Channel 01/0 : 88[0] -> 80[0] [send] via NET/AWS Libfabric/0
22: nid005915:274816:275451 [2] NCCL INFO Channel 02/0 : 90[2] -> 82[2] [send] via NET/AWS Libfabric/2
25: nid005919:107463:108106 [1] NCCL INFO Channel 07/0 : 101[1] -> 100[0] via P2P/CUMEM
21: nid005914:166785:167415 [1] NCCL INFO Channel 07/0 : 85[1] -> 84[0] via P2P/CUMEM
22: nid005915:274816:275451 [2] NCCL INFO Channel 03/0 : 90[2] -> 82[2] [send] via NET/AWS Libfabric/2
12: nid005594:53085:53720 [0] NCCL INFO Channel 01/0 : 48[0] -> 49[1] via P2P/CUMEM
12: nid005594:53085:53720 [0] NCCL INFO Channel 02/0 : 48[0] -> 49[1] via P2P/CUMEM
12: nid005594:53085:53720 [0] NCCL INFO Channel 03/0 : 48[0] -> 49[1] via P2P/CUMEM
12: nid005594:53085:53720 [0] NCCL INFO Channel 05/0 : 48[0] -> 49[1] via P2P/CUMEM
 4: nid005581:264524:265167 [1] NCCL INFO Channel 01/0 : 17[1] -> 18[2] via P2P/CUMEM
12: nid005594:53085:53720 [0] NCCL INFO Channel 06/0 : 48[0] -> 49[1] via P2P/CUMEM
 4: nid005581:264524:265167 [1] NCCL INFO Channel 05/0 : 17[1] -> 18[2] via P2P/CUMEM
 4: nid005581:264526:265166 [3] NCCL INFO Channel 02/0 : 19[3] -> 16[0] via P2P/CUMEM
12: nid005594:53085:53720 [0] NCCL INFO Channel 07/0 : 48[0] -> 49[1] via P2P/CUMEM
 4: nid005581:264526:265166 [3] NCCL INFO Channel 03/0 : 19[3] -> 16[0] via P2P/CUMEM
 4: nid005581:264526:265166 [3] NCCL INFO Channel 06/0 : 19[3] -> 16[0] via P2P/CUMEM
 4: nid005581:264526:265166 [3] NCCL INFO Channel 07/0 : 19[3] -> 16[0] via P2P/CUMEM
 4: nid005581:264523:265165 [0] NCCL INFO Channel 04/0 : 16[0] -> 20[0] [send] via NET/AWS Libfabric/0
 4: nid005581:264525:265164 [2] NCCL INFO Channel 06/0 : 18[2] -> 22[2] [send] via NET/AWS Libfabric/2
 4: nid005581:264525:265164 [2] NCCL INFO Channel 02/0 : 10[2] -> 18[2] [receive] via NET/AWS Libfabric/2
 5: nid005582:196715:197503 [2] NCCL INFO Channel 06/0 : 14[2] -> 22[2] [receive] via NET/AWS Libfabric/2
 4: nid005581:264523:265165 [0] NCCL INFO Channel 00/0 : 8[0] -> 16[0] [receive] via NET/AWS Libfabric/0
 4: nid005581:264524:265167 [1] NCCL INFO Channel 00/0 : 17[1] -> 16[0] via P2P/CUMEM
 4: nid005581:264525:265164 [2] NCCL INFO Channel 03/0 : 10[2] -> 18[2] [receive] via NET/AWS Libfabric/2
 5: nid005582:196713:197505 [0] NCCL INFO Channel 04/0 : 12[0] -> 20[0] [receive] via NET/AWS Libfabric/0
 4: nid005581:264523:265165 [0] NCCL INFO Channel 01/0 : 8[0] -> 16[0] [receive] via NET/AWS Libfabric/0
 5: nid005582:196715:197503 [2] NCCL INFO Channel 07/0 : 14[2] -> 22[2] [receive] via NET/AWS Libfabric/2
 4: nid005581:264525:265164 [2] NCCL INFO Channel 02/0 : 18[2] -> 26[2] [send] via NET/AWS Libfabric/2
27: nid005922:80742:81386 [1] NCCL INFO Channel 00/0 : 109[1] -> 110[2] via P2P/CUMEM
 5: nid005582:196713:197505 [0] NCCL INFO Channel 05/0 : 12[0] -> 20[0] [receive] via NET/AWS Libfabric/0
 4: nid005581:264523:265165 [0] NCCL INFO Channel 00/0 : 16[0] -> 24[0] [send] via NET/AWS Libfabric/0
 4: nid005581:264524:265167 [1] NCCL INFO Channel 02/0 : 17[1] -> 16[0] via P2P/CUMEM
 4: nid005581:264525:265164 [2] NCCL INFO Channel 03/0 : 18[2] -> 26[2] [send] via NET/AWS Libfabric/2
27: nid005922:80742:81386 [1] NCCL INFO Channel 04/0 : 109[1] -> 110[2] via P2P/CUMEM
 4: nid005581:264523:265165 [0] NCCL INFO Channel 01/0 : 16[0] -> 24[0] [send] via NET/AWS Libfabric/0
 5: nid005582:196715:197503 [2] NCCL INFO Channel 06/0 : 22[2] -> 14[2] [send] via NET/AWS Libfabric/2
12: nid005594:53087:53721 [2] NCCL INFO Channel 01/0 : 50[2] -> 51[3] via P2P/CUMEM
 5: nid005582:196713:197505 [0] NCCL INFO Channel 04/0 : 20[0] -> 12[0] [send] via NET/AWS Libfabric/0
 4: nid005581:264524:265167 [1] NCCL INFO Channel 04/0 : 17[1] -> 16[0] via P2P/CUMEM
 3: nid005580:71821:72471 [2] NCCL INFO Channel 06/0 : 14[2] -> 30[2] [send] via NET/AWS Libfabric/2
 2: nid005577:17424:18083 [2] NCCL INFO Channel 02/0 : 18[2] -> 10[2] [receive] via NET/AWS Libfabric/2
 3: nid005580:71821:72471 [2] NCCL INFO Channel 07/0 : 14[2] -> 30[2] [send] via NET/AWS Libfabric/2
 5: nid005582:196715:197503 [2] NCCL INFO Channel 07/0 : 22[2] -> 14[2] [send] via NET/AWS Libfabric/2
12: nid005594:53087:53721 [2] NCCL INFO Channel 02/0 : 50[2] -> 51[3] via P2P/CUMEM
 2: nid005577:17424:18083 [2] NCCL INFO Channel 03/0 : 18[2] -> 10[2] [receive] via NET/AWS Libfabric/2
 4: nid005581:264525:265164 [2] NCCL INFO Channel 02/0 : 18[2] -> 34[2] [send] via NET/AWS Libfabric/2
 5: nid005582:196713:197505 [0] NCCL INFO Channel 05/0 : 20[0] -> 12[0] [send] via NET/AWS Libfabric/0
 6: nid005584:28287:28919 [2] NCCL INFO Channel 02/0 : 26[2] -> 18[2] [send] via NET/AWS Libfabric/2
 4: nid005581:264524:265167 [1] NCCL INFO Channel 06/0 : 17[1] -> 16[0] via P2P/CUMEM
 2: nid005577:17422:18081 [0] NCCL INFO Channel 00/0 : 16[0] -> 8[0] [receive] via NET/AWS Libfabric/0
 4: nid005581:264525:265164 [2] NCCL INFO Channel 03/0 : 18[2] -> 34[2] [send] via NET/AWS Libfabric/2
 6: nid005584:28287:28919 [2] NCCL INFO Channel 03/0 : 26[2] -> 18[2] [send] via NET/AWS Libfabric/2
 4: nid005581:264523:265165 [0] NCCL INFO Channel 00/0 : 16[0] -> 32[0] [send] via NET/AWS Libfabric/0
 6: nid005584:28285:28917 [0] NCCL INFO Channel 00/0 : 24[0] -> 16[0] [send] via NET/AWS Libfabric/0
12: nid005594:53087:53721 [2] NCCL INFO Channel 03/0 : 50[2] -> 51[3] via P2P/CUMEM
 3: nid005580:71821:72471 [2] NCCL INFO Channel 06/0 : 30[2] -> 14[2] [receive] via NET/AWS Libfabric/2
 2: nid005577:17422:18081 [0] NCCL INFO Channel 01/0 : 16[0] -> 8[0] [receive] via NET/AWS Libfabric/0
 4: nid005581:264523:265165 [0] NCCL INFO Channel 01/0 : 16[0] -> 32[0] [send] via NET/AWS Libfabric/0
 3: nid005580:71821:72471 [2] NCCL INFO Channel 07/0 : 30[2] -> 14[2] [receive] via NET/AWS Libfabric/2
 6: nid005584:28285:28917 [0] NCCL INFO Channel 01/0 : 24[0] -> 16[0] [send] via NET/AWS Libfabric/0
27: nid005922:80741:81383 [0] NCCL INFO Channel 00/0 : 104[0] -> 108[0] [receive] via NET/AWS Libfabric/0
12: nid005594:53087:53721 [2] NCCL INFO Channel 05/0 : 50[2] -> 51[3] via P2P/CUMEM
 4: nid005581:264525:265164 [2] NCCL INFO Channel 02/0 : 34[2] -> 18[2] [receive] via NET/AWS Libfabric/2
 4: nid005581:264525:265164 [2] NCCL INFO Channel 03/0 : 34[2] -> 18[2] [receive] via NET/AWS Libfabric/2
27: nid005922:80743:81385 [2] NCCL INFO Channel 02/0 : 106[2] -> 110[2] [receive] via NET/AWS Libfabric/2
 4: nid005581:264523:265165 [0] NCCL INFO Channel 00/0 : 32[0] -> 16[0] [receive] via NET/AWS Libfabric/0
 4: nid005581:264523:265165 [0] NCCL INFO Channel 01/0 : 32[0] -> 16[0] [receive] via NET/AWS Libfabric/0
27: nid005922:80741:81383 [0] NCCL INFO Channel 04/0 : 100[0] -> 108[0] [receive] via NET/AWS Libfabric/0
27: nid005922:80741:81383 [0] NCCL INFO Channel 05/0 : 100[0] -> 108[0] [receive] via NET/AWS Libfabric/0
27: nid005922:80742:81386 [1] NCCL INFO Channel 01/0 : 109[1] -> 108[0] via P2P/CUMEM
27: nid005922:80743:81385 [2] NCCL INFO Channel 06/0 : 102[2] -> 110[2] [receive] via NET/AWS Libfabric/2
27: nid005922:80741:81383 [0] NCCL INFO Channel 04/0 : 108[0] -> 116[0] [send] via NET/AWS Libfabric/0
26: nid005920:67125:67776 [2] NCCL INFO Channel 02/0 : 106[2] -> 114[2] [send] via NET/AWS Libfabric/2
26: nid005920:67123:67775 [0] NCCL INFO Channel 00/0 : 104[0] -> 112[0] [send] via NET/AWS Libfabric/0
27: nid005922:80743:81385 [2] NCCL INFO Channel 07/0 : 102[2] -> 110[2] [receive] via NET/AWS Libfabric/2
12: nid005594:53087:53721 [2] NCCL INFO Channel 06/0 : 50[2] -> 51[3] via P2P/CUMEM
27: nid005922:80741:81383 [0] NCCL INFO Channel 05/0 : 108[0] -> 116[0] [send] via NET/AWS Libfabric/0
26: nid005920:67125:67776 [2] NCCL INFO Channel 03/0 : 106[2] -> 114[2] [send] via NET/AWS Libfabric/2
27: nid005922:80743:81385 [2] NCCL INFO Channel 06/0 : 110[2] -> 118[2] [send] via NET/AWS Libfabric/2
26: nid005920:67123:67775 [0] NCCL INFO Channel 01/0 : 104[0] -> 112[0] [send] via NET/AWS Libfabric/0
27: nid005922:80742:81386 [1] NCCL INFO Channel 03/0 : 109[1] -> 108[0] via P2P/CUMEM
27: nid005922:80743:81385 [2] NCCL INFO Channel 07/0 : 110[2] -> 118[2] [send] via NET/AWS Libfabric/2
25: nid005919:107462:108105 [0] NCCL INFO Channel 04/0 : 108[0] -> 100[0] [receive] via NET/AWS Libfabric/0
26: nid005920:67125:67776 [2] NCCL INFO Channel 02/0 : 114[2] -> 106[2] [receive] via NET/AWS Libfabric/2
27: nid005922:80742:81386 [1] NCCL INFO Channel 05/0 : 109[1] -> 108[0] via P2P/CUMEM
27: nid005922:80741:81383 [0] NCCL INFO Channel 04/0 : 92[0] -> 108[0] [receive] via NET/AWS Libfabric/0
12: nid005594:53087:53721 [2] NCCL INFO Channel 07/0 : 50[2] -> 51[3] via P2P/CUMEM
28: nid005929:16032:16664 [2] NCCL INFO Channel 02/0 : 98[2] -> 114[2] [receive] via NET/AWS Libfabric/2
26: nid005920:67123:67775 [0] NCCL INFO Channel 00/0 : 112[0] -> 104[0] [receive] via NET/AWS Libfabric/0
25: nid005919:107462:108105 [0] NCCL INFO Channel 05/0 : 108[0] -> 100[0] [receive] via NET/AWS Libfabric/0
28: nid005929:16030:16665 [0] NCCL INFO Channel 00/0 : 96[0] -> 112[0] [receive] via NET/AWS Libfabric/0
26: nid005920:67125:67776 [2] NCCL INFO Channel 03/0 : 114[2] -> 106[2] [receive] via NET/AWS Libfabric/2
29: nid005932:167680:168334 [0] NCCL INFO Channel 04/0 : 116[0] -> 108[0] [send] via NET/AWS Libfabric/0
27: nid005922:80741:81383 [0] NCCL INFO Channel 05/0 : 92[0] -> 108[0] [receive] via NET/AWS Libfabric/0
28: nid005929:16032:16664 [2] NCCL INFO Channel 03/0 : 98[2] -> 114[2] [receive] via NET/AWS Libfabric/2
27: nid005922:80742:81386 [1] NCCL INFO Channel 07/0 : 109[1] -> 108[0] via P2P/CUMEM
25: nid005919:107464:108107 [2] NCCL INFO Channel 06/0 : 110[2] -> 102[2] [receive] via NET/AWS Libfabric/2
26: nid005920:67123:67775 [0] NCCL INFO Channel 01/0 : 112[0] -> 104[0] [receive] via NET/AWS Libfabric/0
29: nid005932:167680:168334 [0] NCCL INFO Channel 05/0 : 116[0] -> 108[0] [send] via NET/AWS Libfabric/0
28: nid005929:16030:16665 [0] NCCL INFO Channel 01/0 : 96[0] -> 112[0] [receive] via NET/AWS Libfabric/0
27: nid005922:80743:81385 [2] NCCL INFO Channel 06/0 : 94[2] -> 110[2] [receive] via NET/AWS Libfabric/2
29: nid005932:167682:168331 [2] NCCL INFO Channel 06/0 : 118[2] -> 110[2] [send] via NET/AWS Libfabric/2
25: nid005919:107464:108107 [2] NCCL INFO Channel 07/0 : 110[2] -> 102[2] [receive] via NET/AWS Libfabric/2
27: nid005922:80741:81383 [0] NCCL INFO Channel 04/0 : 108[0] -> 92[0] [send] via NET/AWS Libfabric/0
17: nid005803:180732:181388 [0] NCCL INFO Channel 00/0 : 68[0] -> 69[1] via P2P/CUMEM
27: nid005922:80743:81385 [2] NCCL INFO Channel 07/0 : 94[2] -> 110[2] [receive] via NET/AWS Libfabric/2
28: nid005929:16032:16664 [2] NCCL INFO Channel 02/0 : 114[2] -> 98[2] [send] via NET/AWS Libfabric/2
29: nid005932:167682:168331 [2] NCCL INFO Channel 07/0 : 118[2] -> 110[2] [send] via NET/AWS Libfabric/2
27: nid005922:80741:81383 [0] NCCL INFO Channel 05/0 : 108[0] -> 92[0] [send] via NET/AWS Libfabric/0
28: nid005929:16032:16664 [2] NCCL INFO Channel 03/0 : 114[2] -> 98[2] [send] via NET/AWS Libfabric/2
28: nid005929:16030:16665 [0] NCCL INFO Channel 00/0 : 112[0] -> 96[0] [send] via NET/AWS Libfabric/0
28: nid005929:16030:16665 [0] NCCL INFO Channel 01/0 : 112[0] -> 96[0] [send] via NET/AWS Libfabric/0
27: nid005922:80743:81385 [2] NCCL INFO Channel 06/0 : 110[2] -> 94[2] [send] via NET/AWS Libfabric/2
27: nid005922:80743:81385 [2] NCCL INFO Channel 07/0 : 110[2] -> 94[2] [send] via NET/AWS Libfabric/2
17: nid005803:180732:181388 [0] NCCL INFO Channel 02/0 : 68[0] -> 69[1] via P2P/CUMEM
17: nid005803:180732:181388 [0] NCCL INFO Channel 03/0 : 68[0] -> 69[1] via P2P/CUMEM
17: nid005803:180732:181388 [0] NCCL INFO Channel 04/0 : 68[0] -> 69[1] via P2P/CUMEM
17: nid005803:180734:181389 [2] NCCL INFO Channel 00/0 : 70[2] -> 71[3] via P2P/CUMEM
17: nid005803:180732:181388 [0] NCCL INFO Channel 06/0 : 68[0] -> 69[1] via P2P/CUMEM
12: nid005594:53086:53722 [1] NCCL INFO Channel 01/0 : 49[1] -> 50[2] via P2P/CUMEM
17: nid005803:180734:181389 [2] NCCL INFO Channel 02/0 : 70[2] -> 71[3] via P2P/CUMEM
17: nid005803:180732:181388 [0] NCCL INFO Channel 07/0 : 68[0] -> 69[1] via P2P/CUMEM
17: nid005803:180734:181389 [2] NCCL INFO Channel 03/0 : 70[2] -> 71[3] via P2P/CUMEM
12: nid005594:53086:53722 [1] NCCL INFO Channel 05/0 : 49[1] -> 50[2] via P2P/CUMEM
17: nid005803:180734:181389 [2] NCCL INFO Channel 04/0 : 70[2] -> 71[3] via P2P/CUMEM
17: nid005803:180734:181389 [2] NCCL INFO Channel 06/0 : 70[2] -> 71[3] via P2P/CUMEM
17: nid005803:180734:181389 [2] NCCL INFO Channel 07/0 : 70[2] -> 71[3] via P2P/CUMEM
17: nid005803:180732:181388 [0] NCCL INFO Channel 04/0 : 64[0] -> 68[0] [receive] via NET/AWS Libfabric/0
17: nid005803:180732:181388 [0] NCCL INFO Channel 01/0 : 68[0] -> 72[0] [send] via NET/AWS Libfabric/0
12: nid005594:53085:53720 [0] NCCL INFO Channel 04/0 : 48[0] -> 52[0] [send] via NET/AWS Libfabric/0
12: nid005594:53088:53723 [3] NCCL INFO Channel 02/0 : 51[3] -> 48[0] via P2P/CUMEM
17: nid005803:180732:181388 [0] NCCL INFO Channel 05/0 : 68[0] -> 72[0] [send] via NET/AWS Libfabric/0
12: nid005594:53085:53720 [0] NCCL INFO Channel 00/0 : 40[0] -> 48[0] [receive] via NET/AWS Libfabric/0
13: nid005595:197883:198573 [0] NCCL INFO Channel 04/0 : 44[0] -> 52[0] [receive] via NET/AWS Libfabric/0
12: nid005594:53087:53721 [2] NCCL INFO Channel 06/0 : 50[2] -> 54[2] [send] via NET/AWS Libfabric/2
16: nid005802:6297:7000 [0] NCCL INFO Channel 00/0 : 32[0] -> 64[0] [receive] via NET/AWS Libfabric/0
12: nid005594:53085:53720 [0] NCCL INFO Channel 01/0 : 40[0] -> 48[0] [receive] via NET/AWS Libfabric/0
13: nid005595:197883:198573 [0] NCCL INFO Channel 05/0 : 44[0] -> 52[0] [receive] via NET/AWS Libfabric/0
17: nid005803:180735:181387 [3] NCCL INFO Channel 02/0 : 71[3] -> 68[0] via P2P/CUMEM
17: nid005803:180732:181388 [0] NCCL INFO Channel 04/0 : 68[0] -> 76[0] [send] via NET/AWS Libfabric/0
16: nid005802:6297:7000 [0] NCCL INFO Channel 01/0 : 32[0] -> 64[0] [receive] via NET/AWS Libfabric/0
18: nid005911:38864:39519 [0] NCCL INFO Channel 00/0 : 72[0] -> 80[0] [send] via NET/AWS Libfabric/0
12: nid005594:53085:53720 [0] NCCL INFO Channel 00/0 : 48[0] -> 56[0] [send] via NET/AWS Libfabric/0
12: nid005594:53088:53723 [3] NCCL INFO Channel 03/0 : 51[3] -> 48[0] via P2P/CUMEM
17: nid005803:180732:181388 [0] NCCL INFO Channel 05/0 : 68[0] -> 76[0] [send] via NET/AWS Libfabric/0
18: nid005911:38864:39519 [0] NCCL INFO Channel 01/0 : 72[0] -> 80[0] [send] via NET/AWS Libfabric/0
12: nid005594:53085:53720 [0] NCCL INFO Channel 01/0 : 48[0] -> 56[0] [send] via NET/AWS Libfabric/0
16: nid005802:6297:7000 [0] NCCL INFO Channel 00/0 : 64[0] -> 96[0] [send] via NET/AWS Libfabric/0
12: nid005594:53087:53721 [2] NCCL INFO Channel 02/0 : 42[2] -> 50[2] [receive] via NET/AWS Libfabric/2
16: nid005802:6297:7000 [0] NCCL INFO Channel 01/0 : 64[0] -> 96[0] [send] via NET/AWS Libfabric/0
13: nid005595:197885:198571 [2] NCCL INFO Channel 06/0 : 46[2] -> 54[2] [receive] via NET/AWS Libfabric/2
12: nid005594:53087:53721 [2] NCCL INFO Channel 03/0 : 42[2] -> 50[2] [receive] via NET/AWS Libfabric/2
13: nid005595:197883:198573 [0] NCCL INFO Channel 04/0 : 52[0] -> 44[0] [send] via NET/AWS Libfabric/0
13: nid005595:197885:198571 [2] NCCL INFO Channel 07/0 : 46[2] -> 54[2] [receive] via NET/AWS Libfabric/2
18: nid005911:38864:39519 [0] NCCL INFO Channel 00/0 : 80[0] -> 72[0] [receive] via NET/AWS Libfabric/0
12: nid005594:53087:53721 [2] NCCL INFO Channel 02/0 : 50[2] -> 58[2] [send] via NET/AWS Libfabric/2
10: nid005590:110710:111344 [0] NCCL INFO Channel 00/0 : 48[0] -> 40[0] [receive] via NET/AWS Libfabric/0
13: nid005595:197883:198573 [0] NCCL INFO Channel 05/0 : 52[0] -> 44[0] [send] via NET/AWS Libfabric/0
12: nid005594:53085:53720 [0] NCCL INFO Channel 00/0 : 32[0] -> 48[0] [receive] via NET/AWS Libfabric/0
17: nid005803:180732:181388 [0] NCCL INFO Channel 04/0 : 76[0] -> 68[0] [receive] via NET/AWS Libfabric/0
20: nid005913:292681:293318 [0] NCCL INFO Channel 00/0 : 80[0] -> 96[0] [send] via NET/AWS Libfabric/0
18: nid005911:38864:39519 [0] NCCL INFO Channel 01/0 : 80[0] -> 72[0] [receive] via NET/AWS Libfabric/0
19: nid005912:12435:13072 [0] NCCL INFO Channel 04/0 : 76[0] -> 92[0] [send] via NET/AWS Libfabric/0
17: nid005803:180735:181387 [3] NCCL INFO Channel 03/0 : 71[3] -> 68[0] via P2P/CUMEM
12: nid005594:53087:53721 [2] NCCL INFO Channel 03/0 : 50[2] -> 58[2] [send] via NET/AWS Libfabric/2
17: nid005803:180734:181389 [2] NCCL INFO Channel 06/0 : 66[2] -> 70[2] [receive] via NET/AWS Libfabric/2
17: nid005803:180733:181386 [1] NCCL INFO Channel 01/0 : 69[1] -> 68[0] via P2P/CUMEM
12: nid005594:53086:53722 [1] NCCL INFO Channel 00/0 : 49[1] -> 48[0] via P2P/CUMEM
20: nid005913:292681:293318 [0] NCCL INFO Channel 01/0 : 80[0] -> 96[0] [send] via NET/AWS Libfabric/0
12: nid005594:53085:53720 [0] NCCL INFO Channel 01/0 : 32[0] -> 48[0] [receive] via NET/AWS Libfabric/0
10: nid005590:110710:111344 [0] NCCL INFO Channel 01/0 : 48[0] -> 40[0] [receive] via NET/AWS Libfabric/0
12: nid005594:53088:53723 [3] NCCL INFO Channel 06/0 : 51[3] -> 48[0] via P2P/CUMEM
19: nid005912:12435:13072 [0] NCCL INFO Channel 05/0 : 76[0] -> 92[0] [send] via NET/AWS Libfabric/0
17: nid005803:180732:181388 [0] NCCL INFO Channel 05/0 : 76[0] -> 68[0] [receive] via NET/AWS Libfabric/0
11: nid005591:191603:192243 [0] NCCL INFO Channel 04/0 : 28[0] -> 44[0] [receive] via NET/AWS Libfabric/0
17: nid005803:180734:181389 [2] NCCL INFO Channel 03/0 : 70[2] -> 74[2] [send] via NET/AWS Libfabric/2
14: nid005600:217720:218385 [0] NCCL INFO Channel 00/0 : 56[0] -> 48[0] [send] via NET/AWS Libfabric/0
13: nid005595:197885:198571 [2] NCCL INFO Channel 06/0 : 54[2] -> 46[2] [send] via NET/AWS Libfabric/2
17: nid005803:180734:181389 [2] NCCL INFO Channel 07/0 : 70[2] -> 74[2] [send] via NET/AWS Libfabric/2
14: nid005600:217720:218385 [0] NCCL INFO Channel 01/0 : 56[0] -> 48[0] [send] via NET/AWS Libfabric/0
11: nid005591:191605:192244 [2] NCCL INFO Channel 06/0 : 30[2] -> 46[2] [receive] via NET/AWS Libfabric/2
12: nid005594:53085:53720 [0] NCCL INFO Channel 00/0 : 48[0] -> 32[0] [send] via NET/AWS Libfabric/0
20: nid005913:292681:293318 [0] NCCL INFO Channel 00/0 : 96[0] -> 80[0] [receive] via NET/AWS Libfabric/0
 8: nid005586:68926:69568 [0] NCCL INFO Channel 00/0 : 32[0] -> 64[0] [send] via NET/AWS Libfabric/0
13: nid005595:197885:198571 [2] NCCL INFO Channel 07/0 : 54[2] -> 46[2] [send] via NET/AWS Libfabric/2
12: nid005594:53085:53720 [0] NCCL INFO Channel 01/0 : 48[0] -> 32[0] [send] via NET/AWS Libfabric/0
19: nid005912:12435:13072 [0] NCCL INFO Channel 04/0 : 92[0] -> 76[0] [receive] via NET/AWS Libfabric/0
17: nid005803:180735:181387 [3] NCCL INFO Channel 06/0 : 71[3] -> 68[0] via P2P/CUMEM
20: nid005913:292681:293318 [0] NCCL INFO Channel 01/0 : 96[0] -> 80[0] [receive] via NET/AWS Libfabric/0
24: nid005918:92504:93175 [0] NCCL INFO Channel 00/0 : 64[0] -> 96[0] [receive] via NET/AWS Libfabric/0
12: nid005594:53088:53723 [3] NCCL INFO Channel 07/0 : 51[3] -> 48[0] via P2P/CUMEM
10: nid005590:110712:111346 [2] NCCL INFO Channel 02/0 : 50[2] -> 42[2] [receive] via NET/AWS Libfabric/2
 8: nid005586:68926:69568 [0] NCCL INFO Channel 01/0 : 32[0] -> 64[0] [send] via NET/AWS Libfabric/0
12: nid005594:53087:53721 [2] NCCL INFO Channel 02/0 : 34[2] -> 50[2] [receive] via NET/AWS Libfabric/2
17: nid005803:180733:181386 [1] NCCL INFO Channel 03/0 : 69[1] -> 68[0] via P2P/CUMEM
19: nid005912:12435:13072 [0] NCCL INFO Channel 05/0 : 92[0] -> 76[0] [receive] via NET/AWS Libfabric/0
23: nid005917:276885:277523 [0] NCCL INFO Channel 04/0 : 60[0] -> 92[0] [receive] via NET/AWS Libfabric/0
24: nid005918:92504:93175 [0] NCCL INFO Channel 01/0 : 64[0] -> 96[0] [receive] via NET/AWS Libfabric/0
12: nid005594:53086:53722 [1] NCCL INFO Channel 02/0 : 49[1] -> 48[0] via P2P/CUMEM
10: nid005590:110712:111346 [2] NCCL INFO Channel 03/0 : 50[2] -> 42[2] [receive] via NET/AWS Libfabric/2
23: nid005917:276885:277523 [0] NCCL INFO Channel 05/0 : 60[0] -> 92[0] [receive] via NET/AWS Libfabric/0
11: nid005591:191603:192243 [0] NCCL INFO Channel 05/0 : 28[0] -> 44[0] [receive] via NET/AWS Libfabric/0
11: nid005591:191605:192244 [2] NCCL INFO Channel 07/0 : 30[2] -> 46[2] [receive] via NET/AWS Libfabric/2
12: nid005594:53087:53721 [2] NCCL INFO Channel 03/0 : 34[2] -> 50[2] [receive] via NET/AWS Libfabric/2
14: nid005600:217722:218387 [2] NCCL INFO Channel 02/0 : 58[2] -> 50[2] [send] via NET/AWS Libfabric/2
16: nid005802:6299:7001 [2] NCCL INFO Channel 02/0 : 34[2] -> 66[2] [receive] via NET/AWS Libfabric/2
 8: nid005586:68926:69568 [0] NCCL INFO Channel 00/0 : 64[0] -> 32[0] [receive] via NET/AWS Libfabric/0
14: nid005600:217722:218387 [2] NCCL INFO Channel 03/0 : 58[2] -> 50[2] [send] via NET/AWS Libfabric/2
16: nid005802:6299:7001 [2] NCCL INFO Channel 03/0 : 34[2] -> 66[2] [receive] via NET/AWS Libfabric/2
 8: nid005586:68926:69568 [0] NCCL INFO Channel 01/0 : 64[0] -> 32[0] [receive] via NET/AWS Libfabric/0
24: nid005918:92504:93175 [0] NCCL INFO Channel 00/0 : 96[0] -> 64[0] [send] via NET/AWS Libfabric/0
18: nid005911:38866:39520 [2] NCCL INFO Channel 02/0 : 74[2] -> 82[2] [send] via NET/AWS Libfabric/2
17: nid005803:180734:181389 [2] NCCL INFO Channel 06/0 : 70[2] -> 78[2] [send] via NET/AWS Libfabric/2
23: nid005917:276885:277523 [0] NCCL INFO Channel 04/0 : 92[0] -> 60[0] [send] via NET/AWS Libfabric/0
12: nid005594:53087:53721 [2] NCCL INFO Channel 02/0 : 50[2] -> 34[2] [send] via NET/AWS Libfabric/2
16: nid005802:6297:7000 [0] NCCL INFO Channel 00/0 : 0[0] -> 64[0] [receive] via NET/AWS Libfabric/0
11: nid005591:191603:192243 [0] NCCL INFO Channel 04/0 : 44[0] -> 28[0] [send] via NET/AWS Libfabric/0
12: nid005594:53086:53722 [1] NCCL INFO Channel 04/0 : 49[1] -> 48[0] via P2P/CUMEM
11: nid005591:191605:192244 [2] NCCL INFO Channel 06/0 : 46[2] -> 30[2] [send] via NET/AWS Libfabric/2
24: nid005918:92504:93175 [0] NCCL INFO Channel 01/0 : 96[0] -> 64[0] [send] via NET/AWS Libfabric/0
12: nid005594:53087:53721 [2] NCCL INFO Channel 03/0 : 50[2] -> 34[2] [send] via NET/AWS Libfabric/2
17: nid005803:180735:181387 [3] NCCL INFO Channel 07/0 : 71[3] -> 68[0] via P2P/CUMEM
 7: nid005585:122007:122642 [2] NCCL INFO Channel 06/0 : 30[2] -> 62[2] [send] via NET/AWS Libfabric/2
18: nid005911:38866:39520 [2] NCCL INFO Channel 03/0 : 74[2] -> 82[2] [send] via NET/AWS Libfabric/2
 8: nid005586:68928:69565 [2] NCCL INFO Channel 02/0 : 34[2] -> 66[2] [send] via NET/AWS Libfabric/2
16: nid005802:6299:7001 [2] NCCL INFO Channel 02/0 : 66[2] -> 98[2] [send] via NET/AWS Libfabric/2
17: nid005803:180734:181389 [2] NCCL INFO Channel 07/0 : 70[2] -> 78[2] [send] via NET/AWS Libfabric/2
17: nid005803:180733:181386 [1] NCCL INFO Channel 05/0 : 69[1] -> 68[0] via P2P/CUMEM
23: nid005917:276885:277523 [0] NCCL INFO Channel 05/0 : 92[0] -> 60[0] [send] via NET/AWS Libfabric/0
11: nid005591:191603:192243 [0] NCCL INFO Channel 05/0 : 44[0] -> 28[0] [send] via NET/AWS Libfabric/0
16: nid005802:6297:7000 [0] NCCL INFO Channel 01/0 : 0[0] -> 64[0] [receive] via NET/AWS Libfabric/0
16: nid005802:6299:7001 [2] NCCL INFO Channel 03/0 : 66[2] -> 98[2] [send] via NET/AWS Libfabric/2
 7: nid005585:122007:122642 [2] NCCL INFO Channel 07/0 : 30[2] -> 62[2] [send] via NET/AWS Libfabric/2
 8: nid005586:68928:69565 [2] NCCL INFO Channel 03/0 : 34[2] -> 66[2] [send] via NET/AWS Libfabric/2
12: nid005594:53086:53722 [1] NCCL INFO Channel 06/0 : 49[1] -> 48[0] via P2P/CUMEM
11: nid005591:191605:192244 [2] NCCL INFO Channel 07/0 : 46[2] -> 30[2] [send] via NET/AWS Libfabric/2
16: nid005802:6297:7000 [0] NCCL INFO Channel 00/0 : 64[0] -> 0[0] [send] via NET/AWS Libfabric/0
18: nid005911:38866:39520 [2] NCCL INFO Channel 02/0 : 82[2] -> 74[2] [receive] via NET/AWS Libfabric/2
16: nid005802:6297:7000 [0] NCCL INFO Channel 01/0 : 64[0] -> 0[0] [send] via NET/AWS Libfabric/0
 7: nid005585:122007:122642 [2] NCCL INFO Channel 06/0 : 62[2] -> 30[2] [receive] via NET/AWS Libfabric/2
17: nid005803:180734:181389 [2] NCCL INFO Channel 06/0 : 78[2] -> 70[2] [receive] via NET/AWS Libfabric/2
20: nid005913:292683:293319 [2] NCCL INFO Channel 02/0 : 82[2] -> 98[2] [send] via NET/AWS Libfabric/2
18: nid005911:38866:39520 [2] NCCL INFO Channel 03/0 : 82[2] -> 74[2] [receive] via NET/AWS Libfabric/2
 7: nid005585:122007:122642 [2] NCCL INFO Channel 07/0 : 62[2] -> 30[2] [receive] via NET/AWS Libfabric/2
19: nid005912:12437:13073 [2] NCCL INFO Channel 06/0 : 78[2] -> 94[2] [send] via NET/AWS Libfabric/2
19: nid005912:12437:13073 [2] NCCL INFO Channel 07/0 : 78[2] -> 94[2] [send] via NET/AWS Libfabric/2
17: nid005803:180734:181389 [2] NCCL INFO Channel 07/0 : 78[2] -> 70[2] [receive] via NET/AWS Libfabric/2
17: nid005803:180733:181386 [1] NCCL INFO Channel 07/0 : 69[1] -> 68[0] via P2P/CUMEM
20: nid005913:292683:293319 [2] NCCL INFO Channel 03/0 : 82[2] -> 98[2] [send] via NET/AWS Libfabric/2
 8: nid005586:68928:69565 [2] NCCL INFO Channel 02/0 : 66[2] -> 34[2] [receive] via NET/AWS Libfabric/2
 8: nid005586:68928:69565 [2] NCCL INFO Channel 03/0 : 66[2] -> 34[2] [receive] via NET/AWS Libfabric/2
19: nid005912:12437:13073 [2] NCCL INFO Channel 06/0 : 94[2] -> 78[2] [receive] via NET/AWS Libfabric/2
20: nid005913:292683:293319 [2] NCCL INFO Channel 02/0 : 98[2] -> 82[2] [receive] via NET/AWS Libfabric/2
24: nid005918:92506:93176 [2] NCCL INFO Channel 02/0 : 66[2] -> 98[2] [receive] via NET/AWS Libfabric/2
19: nid005912:12437:13073 [2] NCCL INFO Channel 07/0 : 94[2] -> 78[2] [receive] via NET/AWS Libfabric/2
23: nid005917:276887:277521 [2] NCCL INFO Channel 06/0 : 62[2] -> 94[2] [receive] via NET/AWS Libfabric/2
20: nid005913:292683:293319 [2] NCCL INFO Channel 03/0 : 98[2] -> 82[2] [receive] via NET/AWS Libfabric/2
24: nid005918:92506:93176 [2] NCCL INFO Channel 03/0 : 66[2] -> 98[2] [receive] via NET/AWS Libfabric/2
23: nid005917:276887:277521 [2] NCCL INFO Channel 07/0 : 62[2] -> 94[2] [receive] via NET/AWS Libfabric/2
23: nid005917:276887:277521 [2] NCCL INFO Channel 06/0 : 94[2] -> 62[2] [send] via NET/AWS Libfabric/2
24: nid005918:92506:93176 [2] NCCL INFO Channel 02/0 : 98[2] -> 66[2] [send] via NET/AWS Libfabric/2
15: nid005601:210678:211329 [2] NCCL INFO Channel 06/0 : 126[2] -> 62[2] [receive] via NET/AWS Libfabric/2
16: nid005802:6299:7001 [2] NCCL INFO Channel 02/0 : 2[2] -> 66[2] [receive] via NET/AWS Libfabric/2
23: nid005917:276887:277521 [2] NCCL INFO Channel 07/0 : 94[2] -> 62[2] [send] via NET/AWS Libfabric/2
24: nid005918:92506:93176 [2] NCCL INFO Channel 03/0 : 98[2] -> 66[2] [send] via NET/AWS Libfabric/2
16: nid005802:6299:7001 [2] NCCL INFO Channel 03/0 : 2[2] -> 66[2] [receive] via NET/AWS Libfabric/2
15: nid005601:210678:211329 [2] NCCL INFO Channel 07/0 : 126[2] -> 62[2] [receive] via NET/AWS Libfabric/2
16: nid005802:6299:7001 [2] NCCL INFO Channel 02/0 : 66[2] -> 2[2] [send] via NET/AWS Libfabric/2
15: nid005601:210678:211329 [2] NCCL INFO Channel 06/0 : 62[2] -> 126[2] [send] via NET/AWS Libfabric/2
16: nid005802:6299:7001 [2] NCCL INFO Channel 03/0 : 66[2] -> 2[2] [send] via NET/AWS Libfabric/2
15: nid005601:210678:211329 [2] NCCL INFO Channel 07/0 : 62[2] -> 126[2] [send] via NET/AWS Libfabric/2
16: nid005802:6299:7001 [2] NCCL INFO Channel 02/0 : 98[2] -> 66[2] [receive] via NET/AWS Libfabric/2
15: nid005601:210678:211329 [2] NCCL INFO Channel 06/0 : 94[2] -> 62[2] [receive] via NET/AWS Libfabric/2
 0: nid005574:69060:69729 [2] NCCL INFO Channel 06/0 : 6[2] -> 2[2] [receive] via NET/AWS Libfabric/2
16: nid005802:6299:7001 [2] NCCL INFO Channel 03/0 : 98[2] -> 66[2] [receive] via NET/AWS Libfabric/2
15: nid005601:210678:211329 [2] NCCL INFO Channel 07/0 : 94[2] -> 62[2] [receive] via NET/AWS Libfabric/2
31: nid005937:256591:257241 [2] NCCL INFO Channel 02/0 : 126[2] -> 122[2] [send] via NET/AWS Libfabric/2
16: nid005802:6299:7001 [2] NCCL INFO Channel 02/0 : 66[2] -> 34[2] [send] via NET/AWS Libfabric/2
 0: nid005574:69060:69729 [2] NCCL INFO Channel 07/0 : 6[2] -> 2[2] [receive] via NET/AWS Libfabric/2
15: nid005601:210678:211329 [2] NCCL INFO Channel 06/0 : 62[2] -> 30[2] [send] via NET/AWS Libfabric/2
31: nid005937:256591:257241 [2] NCCL INFO Channel 03/0 : 126[2] -> 122[2] [send] via NET/AWS Libfabric/2
16: nid005802:6299:7001 [2] NCCL INFO Channel 03/0 : 66[2] -> 34[2] [send] via NET/AWS Libfabric/2
15: nid005601:210678:211329 [2] NCCL INFO Channel 07/0 : 62[2] -> 30[2] [send] via NET/AWS Libfabric/2
24: nid005918:92506:93176 [2] NCCL INFO Channel 02/0 : 114[2] -> 98[2] [receive] via NET/AWS Libfabric/2
23: nid005917:276887:277521 [2] NCCL INFO Channel 06/0 : 110[2] -> 94[2] [receive] via NET/AWS Libfabric/2
24: nid005918:92506:93176 [2] NCCL INFO Channel 03/0 : 114[2] -> 98[2] [receive] via NET/AWS Libfabric/2
16: nid005802:6299:7001 [2] NCCL INFO Channel 06/0 : 70[2] -> 66[2] [receive] via NET/AWS Libfabric/2
 8: nid005586:68928:69565 [2] NCCL INFO Channel 02/0 : 50[2] -> 34[2] [receive] via NET/AWS Libfabric/2
23: nid005917:276887:277521 [2] NCCL INFO Channel 07/0 : 110[2] -> 94[2] [receive] via NET/AWS Libfabric/2
16: nid005802:6299:7001 [2] NCCL INFO Channel 07/0 : 70[2] -> 66[2] [receive] via NET/AWS Libfabric/2
15: nid005601:210678:211329 [2] NCCL INFO Channel 02/0 : 62[2] -> 58[2] [send] via NET/AWS Libfabric/2
 7: nid005585:122007:122642 [2] NCCL INFO Channel 06/0 : 46[2] -> 30[2] [receive] via NET/AWS Libfabric/2
23: nid005917:276887:277521 [2] NCCL INFO Channel 06/0 : 94[2] -> 78[2] [send] via NET/AWS Libfabric/2
24: nid005918:92506:93176 [2] NCCL INFO Channel 02/0 : 98[2] -> 82[2] [send] via NET/AWS Libfabric/2
15: nid005601:210678:211329 [2] NCCL INFO Channel 03/0 : 62[2] -> 58[2] [send] via NET/AWS Libfabric/2
 7: nid005585:122007:122642 [2] NCCL INFO Channel 07/0 : 46[2] -> 30[2] [receive] via NET/AWS Libfabric/2
 8: nid005586:68928:69565 [2] NCCL INFO Channel 03/0 : 50[2] -> 34[2] [receive] via NET/AWS Libfabric/2
24: nid005918:92506:93176 [2] NCCL INFO Channel 03/0 : 98[2] -> 82[2] [send] via NET/AWS Libfabric/2
 8: nid005586:68928:69565 [2] NCCL INFO Channel 02/0 : 34[2] -> 18[2] [send] via NET/AWS Libfabric/2
 7: nid005585:122007:122642 [2] NCCL INFO Channel 06/0 : 30[2] -> 14[2] [send] via NET/AWS Libfabric/2
23: nid005917:276887:277521 [2] NCCL INFO Channel 07/0 : 94[2] -> 78[2] [send] via NET/AWS Libfabric/2
 8: nid005586:68928:69565 [2] NCCL INFO Channel 03/0 : 34[2] -> 18[2] [send] via NET/AWS Libfabric/2
 7: nid005585:122007:122642 [2] NCCL INFO Channel 07/0 : 30[2] -> 14[2] [send] via NET/AWS Libfabric/2
28: nid005929:16032:16664 [2] NCCL INFO Channel 02/0 : 122[2] -> 114[2] [receive] via NET/AWS Libfabric/2
27: nid005922:80743:81385 [2] NCCL INFO Channel 06/0 : 118[2] -> 110[2] [receive] via NET/AWS Libfabric/2
20: nid005913:292683:293319 [2] NCCL INFO Channel 02/0 : 90[2] -> 82[2] [receive] via NET/AWS Libfabric/2
24: nid005918:92506:93176 [2] NCCL INFO Channel 06/0 : 102[2] -> 98[2] [receive] via NET/AWS Libfabric/2
28: nid005929:16032:16664 [2] NCCL INFO Channel 03/0 : 122[2] -> 114[2] [receive] via NET/AWS Libfabric/2
19: nid005912:12437:13073 [2] NCCL INFO Channel 06/0 : 86[2] -> 78[2] [receive] via NET/AWS Libfabric/2
12: nid005594:53087:53721 [2] NCCL INFO Channel 02/0 : 58[2] -> 50[2] [receive] via NET/AWS Libfabric/2
11: nid005591:191605:192244 [2] NCCL INFO Channel 06/0 : 54[2] -> 46[2] [receive] via NET/AWS Libfabric/2
20: nid005913:292683:293319 [2] NCCL INFO Channel 03/0 : 90[2] -> 82[2] [receive] via NET/AWS Libfabric/2
23: nid005917:276887:277521 [2] NCCL INFO Channel 02/0 : 94[2] -> 90[2] [send] via NET/AWS Libfabric/2
28: nid005929:16032:16664 [2] NCCL INFO Channel 02/0 : 114[2] -> 106[2] [send] via NET/AWS Libfabric/2
24: nid005918:92506:93176 [2] NCCL INFO Channel 07/0 : 102[2] -> 98[2] [receive] via NET/AWS Libfabric/2
12: nid005594:53087:53721 [2] NCCL INFO Channel 03/0 : 58[2] -> 50[2] [receive] via NET/AWS Libfabric/2
23: nid005917:276887:277521 [2] NCCL INFO Channel 03/0 : 94[2] -> 90[2] [send] via NET/AWS Libfabric/2
27: nid005922:80743:81385 [2] NCCL INFO Channel 07/0 : 118[2] -> 110[2] [receive] via NET/AWS Libfabric/2
 4: nid005581:264525:265164 [2] NCCL INFO Channel 02/0 : 26[2] -> 18[2] [receive] via NET/AWS Libfabric/2
 7: nid005585:122007:122642 [2] NCCL INFO Channel 02/0 : 30[2] -> 26[2] [send] via NET/AWS Libfabric/2
19: nid005912:12437:13073 [2] NCCL INFO Channel 07/0 : 86[2] -> 78[2] [receive] via NET/AWS Libfabric/2
27: nid005922:80743:81385 [2] NCCL INFO Channel 06/0 : 110[2] -> 102[2] [send] via NET/AWS Libfabric/2
12: nid005594:53087:53721 [2] NCCL INFO Channel 02/0 : 50[2] -> 42[2] [send] via NET/AWS Libfabric/2
 3: nid005580:71821:72471 [2] NCCL INFO Channel 06/0 : 22[2] -> 14[2] [receive] via NET/AWS Libfabric/2
20: nid005913:292683:293319 [2] NCCL INFO Channel 02/0 : 82[2] -> 74[2] [send] via NET/AWS Libfabric/2
28: nid005929:16032:16664 [2] NCCL INFO Channel 03/0 : 114[2] -> 106[2] [send] via NET/AWS Libfabric/2
 8: nid005586:68928:69565 [2] NCCL INFO Channel 06/0 : 38[2] -> 34[2] [receive] via NET/AWS Libfabric/2
11: nid005591:191605:192244 [2] NCCL INFO Channel 07/0 : 54[2] -> 46[2] [receive] via NET/AWS Libfabric/2
12: nid005594:53087:53721 [2] NCCL INFO Channel 03/0 : 50[2] -> 42[2] [send] via NET/AWS Libfabric/2
 4: nid005581:264525:265164 [2] NCCL INFO Channel 03/0 : 26[2] -> 18[2] [receive] via NET/AWS Libfabric/2
 7: nid005585:122007:122642 [2] NCCL INFO Channel 03/0 : 30[2] -> 26[2] [send] via NET/AWS Libfabric/2
20: nid005913:292683:293319 [2] NCCL INFO Channel 03/0 : 82[2] -> 74[2] [send] via NET/AWS Libfabric/2
19: nid005912:12437:13073 [2] NCCL INFO Channel 06/0 : 78[2] -> 70[2] [send] via NET/AWS Libfabric/2
27: nid005922:80743:81385 [2] NCCL INFO Channel 07/0 : 110[2] -> 102[2] [send] via NET/AWS Libfabric/2
 8: nid005586:68928:69565 [2] NCCL INFO Channel 07/0 : 38[2] -> 34[2] [receive] via NET/AWS Libfabric/2
11: nid005591:191605:192244 [2] NCCL INFO Channel 06/0 : 46[2] -> 38[2] [send] via NET/AWS Libfabric/2
 4: nid005581:264525:265164 [2] NCCL INFO Channel 02/0 : 18[2] -> 10[2] [send] via NET/AWS Libfabric/2
 3: nid005580:71821:72471 [2] NCCL INFO Channel 07/0 : 22[2] -> 14[2] [receive] via NET/AWS Libfabric/2
19: nid005912:12437:13073 [2] NCCL INFO Channel 07/0 : 78[2] -> 70[2] [send] via NET/AWS Libfabric/2
11: nid005591:191605:192244 [2] NCCL INFO Channel 07/0 : 46[2] -> 38[2] [send] via NET/AWS Libfabric/2
 3: nid005580:71821:72471 [2] NCCL INFO Channel 06/0 : 14[2] -> 6[2] [send] via NET/AWS Libfabric/2
 4: nid005581:264525:265164 [2] NCCL INFO Channel 03/0 : 18[2] -> 10[2] [send] via NET/AWS Libfabric/2
30: nid005936:49910:50568 [2] NCCL INFO Channel 02/0 : 126[2] -> 122[2] [receive] via NET/AWS Libfabric/2
29: nid005932:167682:168331 [2] NCCL INFO Channel 02/0 : 122[2] -> 118[2] [receive] via NET/AWS Libfabric/2
 3: nid005580:71821:72471 [2] NCCL INFO Channel 07/0 : 14[2] -> 6[2] [send] via NET/AWS Libfabric/2
28: nid005929:16032:16664 [2] NCCL INFO Channel 06/0 : 118[2] -> 114[2] [receive] via NET/AWS Libfabric/2
30: nid005936:49910:50568 [2] NCCL INFO Channel 03/0 : 126[2] -> 122[2] [receive] via NET/AWS Libfabric/2
26: nid005920:67125:67776 [2] NCCL INFO Channel 02/0 : 110[2] -> 106[2] [receive] via NET/AWS Libfabric/2
29: nid005932:167682:168331 [2] NCCL INFO Channel 03/0 : 122[2] -> 118[2] [receive] via NET/AWS Libfabric/2
25: nid005919:107464:108107 [2] NCCL INFO Channel 02/0 : 106[2] -> 102[2] [receive] via NET/AWS Libfabric/2
28: nid005929:16032:16664 [2] NCCL INFO Channel 07/0 : 118[2] -> 114[2] [receive] via NET/AWS Libfabric/2
13: nid005595:197885:198571 [2] NCCL INFO Channel 02/0 : 58[2] -> 54[2] [receive] via NET/AWS Libfabric/2
14: nid005600:217722:218387 [2] NCCL INFO Channel 02/0 : 62[2] -> 58[2] [receive] via NET/AWS Libfabric/2
22: nid005915:274816:275451 [2] NCCL INFO Channel 02/0 : 94[2] -> 90[2] [receive] via NET/AWS Libfabric/2
12: nid005594:53087:53721 [2] NCCL INFO Channel 06/0 : 54[2] -> 50[2] [receive] via NET/AWS Libfabric/2
21: nid005914:166786:167416 [2] NCCL INFO Channel 02/0 : 90[2] -> 86[2] [receive] via NET/AWS Libfabric/2
30: nid005936:49910:50568 [2] NCCL INFO Channel 02/0 : 122[2] -> 118[2] [send] via NET/AWS Libfabric/2
14: nid005600:217722:218387 [2] NCCL INFO Channel 03/0 : 62[2] -> 58[2] [receive] via NET/AWS Libfabric/2
29: nid005932:167682:168331 [2] NCCL INFO Channel 06/0 : 122[2] -> 118[2] [receive] via NET/AWS Libfabric/2
 9: nid005588:35937:36596 [2] NCCL INFO Channel 02/0 : 42[2] -> 38[2] [receive] via NET/AWS Libfabric/2
17: nid005803:180734:181389 [2] NCCL INFO Channel 02/0 : 74[2] -> 70[2] [receive] via NET/AWS Libfabric/2
20: nid005913:292683:293319 [2] NCCL INFO Channel 06/0 : 86[2] -> 82[2] [receive] via NET/AWS Libfabric/2
18: nid005911:38866:39520 [2] NCCL INFO Channel 02/0 : 78[2] -> 74[2] [receive] via NET/AWS Libfabric/2
19: nid005912:12437:13073 [2] NCCL INFO Channel 02/0 : 78[2] -> 74[2] [send] via NET/AWS Libfabric/2
26: nid005920:67125:67776 [2] NCCL INFO Channel 03/0 : 110[2] -> 106[2] [receive] via NET/AWS Libfabric/2
25: nid005919:107464:108107 [2] NCCL INFO Channel 03/0 : 106[2] -> 102[2] [receive] via NET/AWS Libfabric/2
27: nid005922:80743:81385 [2] NCCL INFO Channel 02/0 : 110[2] -> 106[2] [send] via NET/AWS Libfabric/2
22: nid005915:274816:275451 [2] NCCL INFO Channel 03/0 : 94[2] -> 90[2] [receive] via NET/AWS Libfabric/2
12: nid005594:53087:53721 [2] NCCL INFO Channel 07/0 : 54[2] -> 50[2] [receive] via NET/AWS Libfabric/2
10: nid005590:110712:111346 [2] NCCL INFO Channel 02/0 : 46[2] -> 42[2] [receive] via NET/AWS Libfabric/2
 9: nid005588:35937:36596 [2] NCCL INFO Channel 03/0 : 42[2] -> 38[2] [receive] via NET/AWS Libfabric/2
13: nid005595:197885:198571 [2] NCCL INFO Channel 03/0 : 58[2] -> 54[2] [receive] via NET/AWS Libfabric/2
 5: nid005582:196715:197503 [2] NCCL INFO Channel 02/0 : 26[2] -> 22[2] [receive] via NET/AWS Libfabric/2
19: nid005912:12437:13073 [2] NCCL INFO Channel 03/0 : 78[2] -> 74[2] [send] via NET/AWS Libfabric/2
21: nid005914:166786:167416 [2] NCCL INFO Channel 03/0 : 90[2] -> 86[2] [receive] via NET/AWS Libfabric/2
30: nid005936:49910:50568 [2] NCCL INFO Channel 03/0 : 122[2] -> 118[2] [send] via NET/AWS Libfabric/2
27: nid005922:80743:81385 [2] NCCL INFO Channel 03/0 : 110[2] -> 106[2] [send] via NET/AWS Libfabric/2
14: nid005600:217722:218387 [2] NCCL INFO Channel 02/0 : 58[2] -> 54[2] [send] via NET/AWS Libfabric/2
11: nid005591:191605:192244 [2] NCCL INFO Channel 02/0 : 46[2] -> 42[2] [send] via NET/AWS Libfabric/2
29: nid005932:167682:168331 [2] NCCL INFO Channel 07/0 : 122[2] -> 118[2] [receive] via NET/AWS Libfabric/2
10: nid005590:110712:111346 [2] NCCL INFO Channel 03/0 : 46[2] -> 42[2] [receive] via NET/AWS Libfabric/2
 2: nid005577:17424:18083 [2] NCCL INFO Channel 02/0 : 14[2] -> 10[2] [receive] via NET/AWS Libfabric/2
 4: nid005581:264525:265164 [2] NCCL INFO Channel 06/0 : 22[2] -> 18[2] [receive] via NET/AWS Libfabric/2
 9: nid005588:35937:36596 [2] NCCL INFO Channel 06/0 : 42[2] -> 38[2] [receive] via NET/AWS Libfabric/2
17: nid005803:180734:181389 [2] NCCL INFO Channel 03/0 : 74[2] -> 70[2] [receive] via NET/AWS Libfabric/2
13: nid005595:197885:198571 [2] NCCL INFO Channel 06/0 : 58[2] -> 54[2] [receive] via NET/AWS Libfabric/2
 5: nid005582:196715:197503 [2] NCCL INFO Channel 03/0 : 26[2] -> 22[2] [receive] via NET/AWS Libfabric/2
20: nid005913:292683:293319 [2] NCCL INFO Channel 07/0 : 86[2] -> 82[2] [receive] via NET/AWS Libfabric/2
18: nid005911:38866:39520 [2] NCCL INFO Channel 03/0 : 78[2] -> 74[2] [receive] via NET/AWS Libfabric/2
21: nid005914:166786:167416 [2] NCCL INFO Channel 06/0 : 90[2] -> 86[2] [receive] via NET/AWS Libfabric/2
26: nid005920:67125:67776 [2] NCCL INFO Channel 02/0 : 106[2] -> 102[2] [send] via NET/AWS Libfabric/2
25: nid005919:107464:108107 [2] NCCL INFO Channel 06/0 : 106[2] -> 102[2] [receive] via NET/AWS Libfabric/2
30: nid005936:49910:50568 [2] NCCL INFO Channel 06/0 : 122[2] -> 118[2] [send] via NET/AWS Libfabric/2
14: nid005600:217722:218387 [2] NCCL INFO Channel 03/0 : 58[2] -> 54[2] [send] via NET/AWS Libfabric/2
 6: nid005584:28287:28919 [2] NCCL INFO Channel 02/0 : 30[2] -> 26[2] [receive] via NET/AWS Libfabric/2
11: nid005591:191605:192244 [2] NCCL INFO Channel 03/0 : 46[2] -> 42[2] [send] via NET/AWS Libfabric/2
22: nid005915:274816:275451 [2] NCCL INFO Channel 02/0 : 90[2] -> 86[2] [send] via NET/AWS Libfabric/2
29: nid005932:167682:168331 [2] NCCL INFO Channel 06/0 : 118[2] -> 114[2] [send] via NET/AWS Libfabric/2
10: nid005590:110712:111346 [2] NCCL INFO Channel 02/0 : 42[2] -> 38[2] [send] via NET/AWS Libfabric/2
 2: nid005577:17424:18083 [2] NCCL INFO Channel 03/0 : 14[2] -> 10[2] [receive] via NET/AWS Libfabric/2
 1: nid005576:147559:148197 [2] NCCL INFO Channel 02/0 : 10[2] -> 6[2] [receive] via NET/AWS Libfabric/2
 4: nid005581:264525:265164 [2] NCCL INFO Channel 07/0 : 22[2] -> 18[2] [receive] via NET/AWS Libfabric/2
 9: nid005588:35937:36596 [2] NCCL INFO Channel 07/0 : 42[2] -> 38[2] [receive] via NET/AWS Libfabric/2
17: nid005803:180734:181389 [2] NCCL INFO Channel 06/0 : 74[2] -> 70[2] [receive] via NET/AWS Libfabric/2
 3: nid005580:71821:72471 [2] NCCL INFO Channel 02/0 : 14[2] -> 10[2] [send] via NET/AWS Libfabric/2
13: nid005595:197885:198571 [2] NCCL INFO Channel 07/0 : 58[2] -> 54[2] [receive] via NET/AWS Libfabric/2
 5: nid005582:196715:197503 [2] NCCL INFO Channel 06/0 : 26[2] -> 22[2] [receive] via NET/AWS Libfabric/2
18: nid005911:38866:39520 [2] NCCL INFO Channel 02/0 : 74[2] -> 70[2] [send] via NET/AWS Libfabric/2
21: nid005914:166786:167416 [2] NCCL INFO Channel 07/0 : 90[2] -> 86[2] [receive] via NET/AWS Libfabric/2
26: nid005920:67125:67776 [2] NCCL INFO Channel 03/0 : 106[2] -> 102[2] [send] via NET/AWS Libfabric/2
25: nid005919:107464:108107 [2] NCCL INFO Channel 07/0 : 106[2] -> 102[2] [receive] via NET/AWS Libfabric/2
30: nid005936:49910:50568 [2] NCCL INFO Channel 07/0 : 122[2] -> 118[2] [send] via NET/AWS Libfabric/2
14: nid005600:217722:218387 [2] NCCL INFO Channel 06/0 : 58[2] -> 54[2] [send] via NET/AWS Libfabric/2
 6: nid005584:28287:28919 [2] NCCL INFO Channel 03/0 : 30[2] -> 26[2] [receive] via NET/AWS Libfabric/2
22: nid005915:274816:275451 [2] NCCL INFO Channel 03/0 : 90[2] -> 86[2] [send] via NET/AWS Libfabric/2
29: nid005932:167682:168331 [2] NCCL INFO Channel 07/0 : 118[2] -> 114[2] [send] via NET/AWS Libfabric/2
10: nid005590:110712:111346 [2] NCCL INFO Channel 03/0 : 42[2] -> 38[2] [send] via NET/AWS Libfabric/2
 2: nid005577:17424:18083 [2] NCCL INFO Channel 02/0 : 10[2] -> 6[2] [send] via NET/AWS Libfabric/2
 1: nid005576:147559:148197 [2] NCCL INFO Channel 03/0 : 10[2] -> 6[2] [receive] via NET/AWS Libfabric/2
 9: nid005588:35937:36596 [2] NCCL INFO Channel 06/0 : 38[2] -> 34[2] [send] via NET/AWS Libfabric/2
17: nid005803:180734:181389 [2] NCCL INFO Channel 07/0 : 74[2] -> 70[2] [receive] via NET/AWS Libfabric/2
 3: nid005580:71821:72471 [2] NCCL INFO Channel 03/0 : 14[2] -> 10[2] [send] via NET/AWS Libfabric/2
13: nid005595:197885:198571 [2] NCCL INFO Channel 06/0 : 54[2] -> 50[2] [send] via NET/AWS Libfabric/2
 5: nid005582:196715:197503 [2] NCCL INFO Channel 07/0 : 26[2] -> 22[2] [receive] via NET/AWS Libfabric/2
18: nid005911:38866:39520 [2] NCCL INFO Channel 03/0 : 74[2] -> 70[2] [send] via NET/AWS Libfabric/2
21: nid005914:166786:167416 [2] NCCL INFO Channel 06/0 : 86[2] -> 82[2] [send] via NET/AWS Libfabric/2
26: nid005920:67125:67776 [2] NCCL INFO Channel 06/0 : 106[2] -> 102[2] [send] via NET/AWS Libfabric/2
25: nid005919:107464:108107 [2] NCCL INFO Channel 06/0 : 102[2] -> 98[2] [send] via NET/AWS Libfabric/2
14: nid005600:217722:218387 [2] NCCL INFO Channel 07/0 : 58[2] -> 54[2] [send] via NET/AWS Libfabric/2
 6: nid005584:28287:28919 [2] NCCL INFO Channel 02/0 : 26[2] -> 22[2] [send] via NET/AWS Libfabric/2
22: nid005915:274816:275451 [2] NCCL INFO Channel 06/0 : 90[2] -> 86[2] [send] via NET/AWS Libfabric/2
10: nid005590:110712:111346 [2] NCCL INFO Channel 06/0 : 42[2] -> 38[2] [send] via NET/AWS Libfabric/2
 2: nid005577:17424:18083 [2] NCCL INFO Channel 03/0 : 10[2] -> 6[2] [send] via NET/AWS Libfabric/2
 1: nid005576:147559:148197 [2] NCCL INFO Channel 06/0 : 10[2] -> 6[2] [receive] via NET/AWS Libfabric/2
 9: nid005588:35937:36596 [2] NCCL INFO Channel 07/0 : 38[2] -> 34[2] [send] via NET/AWS Libfabric/2
17: nid005803:180734:181389 [2] NCCL INFO Channel 06/0 : 70[2] -> 66[2] [send] via NET/AWS Libfabric/2
13: nid005595:197885:198571 [2] NCCL INFO Channel 07/0 : 54[2] -> 50[2] [send] via NET/AWS Libfabric/2
 5: nid005582:196715:197503 [2] NCCL INFO Channel 06/0 : 22[2] -> 18[2] [send] via NET/AWS Libfabric/2
18: nid005911:38866:39520 [2] NCCL INFO Channel 06/0 : 74[2] -> 70[2] [send] via NET/AWS Libfabric/2
21: nid005914:166786:167416 [2] NCCL INFO Channel 07/0 : 86[2] -> 82[2] [send] via NET/AWS Libfabric/2
26: nid005920:67125:67776 [2] NCCL INFO Channel 07/0 : 106[2] -> 102[2] [send] via NET/AWS Libfabric/2
25: nid005919:107464:108107 [2] NCCL INFO Channel 07/0 : 102[2] -> 98[2] [send] via NET/AWS Libfabric/2
 6: nid005584:28287:28919 [2] NCCL INFO Channel 03/0 : 26[2] -> 22[2] [send] via NET/AWS Libfabric/2
22: nid005915:274816:275451 [2] NCCL INFO Channel 07/0 : 90[2] -> 86[2] [send] via NET/AWS Libfabric/2
10: nid005590:110712:111346 [2] NCCL INFO Channel 07/0 : 42[2] -> 38[2] [send] via NET/AWS Libfabric/2
 2: nid005577:17424:18083 [2] NCCL INFO Channel 06/0 : 10[2] -> 6[2] [send] via NET/AWS Libfabric/2
 1: nid005576:147559:148197 [2] NCCL INFO Channel 07/0 : 10[2] -> 6[2] [receive] via NET/AWS Libfabric/2
17: nid005803:180734:181389 [2] NCCL INFO Channel 07/0 : 70[2] -> 66[2] [send] via NET/AWS Libfabric/2
 5: nid005582:196715:197503 [2] NCCL INFO Channel 07/0 : 22[2] -> 18[2] [send] via NET/AWS Libfabric/2
18: nid005911:38866:39520 [2] NCCL INFO Channel 07/0 : 74[2] -> 70[2] [send] via NET/AWS Libfabric/2
 6: nid005584:28287:28919 [2] NCCL INFO Channel 06/0 : 26[2] -> 22[2] [send] via NET/AWS Libfabric/2
 1: nid005576:147559:148197 [2] NCCL INFO Channel 06/0 : 6[2] -> 2[2] [send] via NET/AWS Libfabric/2
 6: nid005584:28287:28919 [2] NCCL INFO Channel 07/0 : 26[2] -> 22[2] [send] via NET/AWS Libfabric/2
 2: nid005577:17424:18083 [2] NCCL INFO Channel 07/0 : 10[2] -> 6[2] [send] via NET/AWS Libfabric/2
 1: nid005576:147559:148197 [2] NCCL INFO Channel 07/0 : 6[2] -> 2[2] [send] via NET/AWS Libfabric/2
30: nid005936:49910:50568 [2] NCCL INFO Channel 00/0 : 122[2] -> 121[1] via P2P/CUMEM
31: nid005937:256591:257241 [2] NCCL INFO Channel 01/0 : 126[2] -> 125[1] via P2P/CUMEM
28: nid005929:16032:16664 [2] NCCL INFO Channel 00/0 : 114[2] -> 113[1] via P2P/CUMEM
23: nid005917:276887:277521 [2] NCCL INFO Channel 01/0 : 94[2] -> 93[1] via P2P/CUMEM
27: nid005922:80743:81385 [2] NCCL INFO Channel 01/0 : 110[2] -> 109[1] via P2P/CUMEM
19: nid005912:12437:13073 [2] NCCL INFO Channel 01/0 : 78[2] -> 77[1] via P2P/CUMEM
15: nid005601:210678:211329 [2] NCCL INFO Channel 01/0 : 62[2] -> 61[1] via P2P/CUMEM
22: nid005915:274816:275451 [2] NCCL INFO Channel 00/0 : 90[2] -> 89[1] via P2P/CUMEM
30: nid005936:49910:50568 [2] NCCL INFO Channel 04/0 : 122[2] -> 121[1] via P2P/CUMEM
 7: nid005585:122007:122642 [2] NCCL INFO Channel 01/0 : 30[2] -> 29[1] via P2P/CUMEM
25: nid005919:107464:108107 [2] NCCL INFO Channel 01/0 : 102[2] -> 101[1] via P2P/CUMEM
28: nid005929:16032:16664 [2] NCCL INFO Channel 04/0 : 114[2] -> 113[1] via P2P/CUMEM
31: nid005937:256591:257241 [2] NCCL INFO Channel 05/0 : 126[2] -> 125[1] via P2P/CUMEM
20: nid005913:292683:293319 [2] NCCL INFO Channel 00/0 : 82[2] -> 81[1] via P2P/CUMEM
26: nid005920:67125:67776 [2] NCCL INFO Channel 00/0 : 106[2] -> 105[1] via P2P/CUMEM
16: nid005802:6299:7001 [2] NCCL INFO Channel 00/0 : 66[2] -> 65[1] via P2P/CUMEM
15: nid005601:210678:211329 [2] NCCL INFO Channel 05/0 : 62[2] -> 61[1] via P2P/CUMEM
13: nid005595:197885:198571 [2] NCCL INFO Channel 01/0 : 54[2] -> 53[1] via P2P/CUMEM
27: nid005922:80743:81385 [2] NCCL INFO Channel 05/0 : 110[2] -> 109[1] via P2P/CUMEM
14: nid005600:217722:218387 [2] NCCL INFO Channel 00/0 : 58[2] -> 57[1] via P2P/CUMEM
11: nid005591:191605:192244 [2] NCCL INFO Channel 01/0 : 46[2] -> 45[1] via P2P/CUMEM
12: nid005594:53087:53721 [2] NCCL INFO Channel 00/0 : 50[2] -> 49[1] via P2P/CUMEM
 4: nid005581:264525:265164 [2] NCCL INFO Channel 00/0 : 18[2] -> 17[1] via P2P/CUMEM
 9: nid005588:35937:36596 [2] NCCL INFO Channel 01/0 : 38[2] -> 37[1] via P2P/CUMEM
 3: nid005580:71821:72471 [2] NCCL INFO Channel 01/0 : 14[2] -> 13[1] via P2P/CUMEM
19: nid005912:12437:13073 [2] NCCL INFO Channel 05/0 : 78[2] -> 77[1] via P2P/CUMEM
21: nid005914:166786:167416 [2] NCCL INFO Channel 01/0 : 86[2] -> 85[1] via P2P/CUMEM
23: nid005917:276887:277521 [2] NCCL INFO Channel 05/0 : 94[2] -> 93[1] via P2P/CUMEM
22: nid005915:274816:275451 [2] NCCL INFO Channel 04/0 : 90[2] -> 89[1] via P2P/CUMEM
29: nid005932:167682:168331 [2] NCCL INFO Channel 01/0 : 118[2] -> 117[1] via P2P/CUMEM
24: nid005918:92506:93176 [2] NCCL INFO Channel 00/0 : 98[2] -> 97[1] via P2P/CUMEM
17: nid005803:180734:181389 [2] NCCL INFO Channel 01/0 : 70[2] -> 69[1] via P2P/CUMEM
 7: nid005585:122007:122642 [2] NCCL INFO Channel 05/0 : 30[2] -> 29[1] via P2P/CUMEM
18: nid005911:38866:39520 [2] NCCL INFO Channel 00/0 : 74[2] -> 73[1] via P2P/CUMEM
25: nid005919:107464:108107 [2] NCCL INFO Channel 05/0 : 102[2] -> 101[1] via P2P/CUMEM
 8: nid005586:68928:69565 [2] NCCL INFO Channel 00/0 : 34[2] -> 33[1] via P2P/CUMEM
14: nid005600:217722:218387 [2] NCCL INFO Channel 04/0 : 58[2] -> 57[1] via P2P/CUMEM
12: nid005594:53087:53721 [2] NCCL INFO Channel 04/0 : 50[2] -> 49[1] via P2P/CUMEM
 2: nid005577:17424:18083 [2] NCCL INFO Channel 00/0 : 10[2] -> 9[1] via P2P/CUMEM
 4: nid005581:264525:265164 [2] NCCL INFO Channel 04/0 : 18[2] -> 17[1] via P2P/CUMEM
16: nid005802:6299:7001 [2] NCCL INFO Channel 04/0 : 66[2] -> 65[1] via P2P/CUMEM
13: nid005595:197885:198571 [2] NCCL INFO Channel 05/0 : 54[2] -> 53[1] via P2P/CUMEM
20: nid005913:292683:293319 [2] NCCL INFO Channel 04/0 : 82[2] -> 81[1] via P2P/CUMEM
26: nid005920:67125:67776 [2] NCCL INFO Channel 04/0 : 106[2] -> 105[1] via P2P/CUMEM
 6: nid005584:28287:28919 [2] NCCL INFO Channel 00/0 : 26[2] -> 25[1] via P2P/CUMEM
11: nid005591:191605:192244 [2] NCCL INFO Channel 05/0 : 46[2] -> 45[1] via P2P/CUMEM
24: nid005918:92506:93176 [2] NCCL INFO Channel 04/0 : 98[2] -> 97[1] via P2P/CUMEM
10: nid005590:110712:111346 [2] NCCL INFO Channel 00/0 : 42[2] -> 41[1] via P2P/CUMEM
 2: nid005577:17424:18083 [2] NCCL INFO Channel 04/0 : 10[2] -> 9[1] via P2P/CUMEM
 9: nid005588:35937:36596 [2] NCCL INFO Channel 05/0 : 38[2] -> 37[1] via P2P/CUMEM
17: nid005803:180734:181389 [2] NCCL INFO Channel 05/0 : 70[2] -> 69[1] via P2P/CUMEM
 3: nid005580:71821:72471 [2] NCCL INFO Channel 05/0 : 14[2] -> 13[1] via P2P/CUMEM
 5: nid005582:196715:197503 [2] NCCL INFO Channel 01/0 : 22[2] -> 21[1] via P2P/CUMEM
18: nid005911:38866:39520 [2] NCCL INFO Channel 04/0 : 74[2] -> 73[1] via P2P/CUMEM
21: nid005914:166786:167416 [2] NCCL INFO Channel 05/0 : 86[2] -> 85[1] via P2P/CUMEM
 8: nid005586:68928:69565 [2] NCCL INFO Channel 04/0 : 34[2] -> 33[1] via P2P/CUMEM
29: nid005932:167682:168331 [2] NCCL INFO Channel 05/0 : 118[2] -> 117[1] via P2P/CUMEM
 0: nid005574:69060:69729 [2] NCCL INFO Channel 00/0 : 2[2] -> 1[1] via P2P/CUMEM
 1: nid005576:147559:148197 [2] NCCL INFO Channel 01/0 : 6[2] -> 5[1] via P2P/CUMEM
 6: nid005584:28287:28919 [2] NCCL INFO Channel 04/0 : 26[2] -> 25[1] via P2P/CUMEM
10: nid005590:110712:111346 [2] NCCL INFO Channel 04/0 : 42[2] -> 41[1] via P2P/CUMEM
 5: nid005582:196715:197503 [2] NCCL INFO Channel 05/0 : 22[2] -> 21[1] via P2P/CUMEM
 0: nid005574:69060:69729 [2] NCCL INFO Channel 04/0 : 2[2] -> 1[1] via P2P/CUMEM
 1: nid005576:147559:148197 [2] NCCL INFO Channel 05/0 : 6[2] -> 5[1] via P2P/CUMEM
 0: [2025-06-27 21:03:21,527] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed info: version=0.16.9, git-hash=unknown, git-branch=unknown
 0: [2025-06-27 21:03:21,527] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 128
 0: [2025-06-27 21:03:21,539] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
 0: [2025-06-27 21:03:21,540] [INFO] [logging.py:107:log_dist] [Rank 0] Using client Optimizer as basic optimizer
 0: [2025-06-27 21:03:21,540] [INFO] [logging.py:107:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
 0: [2025-06-27 21:03:21,575] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed Basic Optimizer = AdamW
 0: [2025-06-27 21:03:21,575] [INFO] [utils.py:59:is_zero_supported_optimizer] Checking ZeRO support for optimizer=AdamW type=<class 'torch.optim.adamw.AdamW'>
 0: [2025-06-27 21:03:21,575] [INFO] [logging.py:107:log_dist] [Rank 0] Creating fp16 ZeRO stage 3 optimizer, MiCS is enabled False, Hierarchical params gather False
 0: [2025-06-27 21:03:21,575] [INFO] [logging.py:107:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 3 optimizer
 0: [2025-06-27 21:03:21,782] [INFO] [utils.py:781:see_memory_usage] Stage 3 initialize beginning
 0: [2025-06-27 21:03:21,783] [INFO] [utils.py:782:see_memory_usage] MA 0.12 GB         Max_MA 3.16 GB         CA 0.14 GB         Max_CA 3 GB 
 0: [2025-06-27 21:03:21,784] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 104.04 GB, percent = 12.2%
 0: [2025-06-27 21:03:21,786] [INFO] [stage3.py:170:__init__] Reduce bucket size 12845056
 0: [2025-06-27 21:03:21,786] [INFO] [stage3.py:171:__init__] Prefetch bucket size 11560550
 0: [2025-06-27 21:03:21,985] [INFO] [utils.py:781:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]
 0: [2025-06-27 21:03:21,986] [INFO] [utils.py:782:see_memory_usage] MA 0.12 GB         Max_MA 0.12 GB         CA 0.14 GB         Max_CA 0 GB 
 0: [2025-06-27 21:03:21,986] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 104.04 GB, percent = 12.2%
 0: Parameter Offload: Total persistent parameters: 848896 in 368 params
 0: [2025-06-27 21:03:22,259] [INFO] [utils.py:781:see_memory_usage] DeepSpeedZeRoOffload initialize [end]
 0: [2025-06-27 21:03:22,260] [INFO] [utils.py:782:see_memory_usage] MA 0.12 GB         Max_MA 0.12 GB         CA 0.14 GB         Max_CA 0 GB 
 0: [2025-06-27 21:03:22,260] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 104.04 GB, percent = 12.2%
 0: [2025-06-27 21:03:22,472] [INFO] [utils.py:781:see_memory_usage] Before creating fp16 partitions
 0: [2025-06-27 21:03:22,473] [INFO] [utils.py:782:see_memory_usage] MA 0.12 GB         Max_MA 0.12 GB         CA 0.14 GB         Max_CA 0 GB 
 0: [2025-06-27 21:03:22,473] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 104.04 GB, percent = 12.2%
 0: nid005574:69058:69733 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM
 0: nid005574:69058:69733 [0] NCCL INFO Channel 02/0 : 0[0] -> 1[1] via P2P/CUMEM
 0: nid005574:69058:69733 [0] NCCL INFO Channel 03/0 : 0[0] -> 1[1] via P2P/CUMEM
 0: nid005574:69058:69733 [0] NCCL INFO Channel 05/0 : 0[0] -> 1[1] via P2P/CUMEM
 0: nid005574:69058:69733 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM
 0: nid005574:69058:69733 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM
 0: nid005574:69058:69733 [0] NCCL INFO Channel 04/0 : 0[0] -> 4[0] [send] via NET/AWS Libfabric/0
 0: nid005574:69058:69733 [0] NCCL INFO Channel 00/0 : 64[0] -> 0[0] [receive] via NET/AWS Libfabric/0
 0: nid005574:69059:69728 [1] NCCL INFO Channel 00/0 : 1[1] -> 0[0] via P2P/CUMEM
 0: nid005574:69058:69733 [0] NCCL INFO Channel 01/0 : 64[0] -> 0[0] [receive] via NET/AWS Libfabric/0
 1: nid005576:147557:148198 [0] NCCL INFO Channel 04/0 : 4[0] -> 12[0] [send] via NET/AWS Libfabric/0
 0: nid005574:69058:69733 [0] NCCL INFO Channel 00/0 : 0[0] -> 64[0] [send] via NET/AWS Libfabric/0
 1: nid005576:147557:148198 [0] NCCL INFO Channel 05/0 : 4[0] -> 12[0] [send] via NET/AWS Libfabric/0
 0: nid005574:69059:69728 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM
 0: nid005574:69058:69733 [0] NCCL INFO Channel 01/0 : 0[0] -> 64[0] [send] via NET/AWS Libfabric/0
 0: nid005574:69059:69728 [1] NCCL INFO Channel 04/0 : 1[1] -> 0[0] via P2P/CUMEM
 1: nid005576:147557:148198 [0] NCCL INFO Channel 04/0 : 12[0] -> 4[0] [receive] via NET/AWS Libfabric/0
 0: nid005574:69058:69733 [0] NCCL INFO Channel 04/0 : 4[0] -> 0[0] [receive] via NET/AWS Libfabric/0
 1: nid005576:147557:148198 [0] NCCL INFO Channel 05/0 : 12[0] -> 4[0] [receive] via NET/AWS Libfabric/0
 0: nid005574:69059:69728 [1] NCCL INFO Channel 06/0 : 1[1] -> 0[0] via P2P/CUMEM
 0: nid005574:69058:69733 [0] NCCL INFO Channel 05/0 : 4[0] -> 0[0] [receive] via NET/AWS Libfabric/0
 3: nid005580:71819:72468 [0] NCCL INFO Channel 04/0 : 12[0] -> 28[0] [send] via NET/AWS Libfabric/0
16: nid005802:6297:7000 [0] NCCL INFO Channel 00/0 : 96[0] -> 64[0] [receive] via NET/AWS Libfabric/0
16: nid005802:6297:7000 [0] NCCL INFO Channel 01/0 : 96[0] -> 64[0] [receive] via NET/AWS Libfabric/0
 3: nid005580:71819:72468 [0] NCCL INFO Channel 05/0 : 12[0] -> 28[0] [send] via NET/AWS Libfabric/0
16: nid005802:6297:7000 [0] NCCL INFO Channel 00/0 : 64[0] -> 32[0] [send] via NET/AWS Libfabric/0
16: nid005802:6297:7000 [0] NCCL INFO Channel 01/0 : 64[0] -> 32[0] [send] via NET/AWS Libfabric/0
 3: nid005580:71819:72468 [0] NCCL INFO Channel 04/0 : 28[0] -> 12[0] [receive] via NET/AWS Libfabric/0
 3: nid005580:71819:72468 [0] NCCL INFO Channel 05/0 : 28[0] -> 12[0] [receive] via NET/AWS Libfabric/0
 7: nid005585:122005:122641 [0] NCCL INFO Channel 04/0 : 28[0] -> 60[0] [send] via NET/AWS Libfabric/0
 7: nid005585:122005:122641 [0] NCCL INFO Channel 05/0 : 28[0] -> 60[0] [send] via NET/AWS Libfabric/0
24: nid005918:92504:93175 [0] NCCL INFO Channel 00/0 : 112[0] -> 96[0] [receive] via NET/AWS Libfabric/0
16: nid005802:6297:7000 [0] NCCL INFO Channel 04/0 : 68[0] -> 64[0] [receive] via NET/AWS Libfabric/0
24: nid005918:92504:93175 [0] NCCL INFO Channel 01/0 : 112[0] -> 96[0] [receive] via NET/AWS Libfabric/0
16: nid005802:6297:7000 [0] NCCL INFO Channel 05/0 : 68[0] -> 64[0] [receive] via NET/AWS Libfabric/0
 7: nid005585:122005:122641 [0] NCCL INFO Channel 04/0 : 60[0] -> 28[0] [receive] via NET/AWS Libfabric/0
 8: nid005586:68926:69568 [0] NCCL INFO Channel 00/0 : 48[0] -> 32[0] [receive] via NET/AWS Libfabric/0
24: nid005918:92504:93175 [0] NCCL INFO Channel 00/0 : 96[0] -> 80[0] [send] via NET/AWS Libfabric/0
15: nid005601:210676:211332 [0] NCCL INFO Channel 04/0 : 124[0] -> 60[0] [receive] via NET/AWS Libfabric/0
 7: nid005585:122005:122641 [0] NCCL INFO Channel 05/0 : 60[0] -> 28[0] [receive] via NET/AWS Libfabric/0
 8: nid005586:68926:69568 [0] NCCL INFO Channel 01/0 : 48[0] -> 32[0] [receive] via NET/AWS Libfabric/0
24: nid005918:92504:93175 [0] NCCL INFO Channel 01/0 : 96[0] -> 80[0] [send] via NET/AWS Libfabric/0
15: nid005601:210676:211332 [0] NCCL INFO Channel 05/0 : 124[0] -> 60[0] [receive] via NET/AWS Libfabric/0
 8: nid005586:68926:69568 [0] NCCL INFO Channel 00/0 : 32[0] -> 16[0] [send] via NET/AWS Libfabric/0
15: nid005601:210676:211332 [0] NCCL INFO Channel 04/0 : 60[0] -> 124[0] [send] via NET/AWS Libfabric/0
 8: nid005586:68926:69568 [0] NCCL INFO Channel 01/0 : 32[0] -> 16[0] [send] via NET/AWS Libfabric/0
15: nid005601:210676:211332 [0] NCCL INFO Channel 05/0 : 60[0] -> 124[0] [send] via NET/AWS Libfabric/0
24: nid005918:92504:93175 [0] NCCL INFO Channel 04/0 : 100[0] -> 96[0] [receive] via NET/AWS Libfabric/0
28: nid005929:16030:16665 [0] NCCL INFO Channel 00/0 : 120[0] -> 112[0] [receive] via NET/AWS Libfabric/0
15: nid005601:210676:211332 [0] NCCL INFO Channel 04/0 : 92[0] -> 60[0] [receive] via NET/AWS Libfabric/0
24: nid005918:92504:93175 [0] NCCL INFO Channel 05/0 : 100[0] -> 96[0] [receive] via NET/AWS Libfabric/0
28: nid005929:16030:16665 [0] NCCL INFO Channel 01/0 : 120[0] -> 112[0] [receive] via NET/AWS Libfabric/0
20: nid005913:292681:293318 [0] NCCL INFO Channel 00/0 : 88[0] -> 80[0] [receive] via NET/AWS Libfabric/0
15: nid005601:210676:211332 [0] NCCL INFO Channel 05/0 : 92[0] -> 60[0] [receive] via NET/AWS Libfabric/0
20: nid005913:292681:293318 [0] NCCL INFO Channel 01/0 : 88[0] -> 80[0] [receive] via NET/AWS Libfabric/0
 8: nid005586:68926:69568 [0] NCCL INFO Channel 04/0 : 36[0] -> 32[0] [receive] via NET/AWS Libfabric/0
12: nid005594:53085:53720 [0] NCCL INFO Channel 00/0 : 56[0] -> 48[0] [receive] via NET/AWS Libfabric/0
15: nid005601:210676:211332 [0] NCCL INFO Channel 04/0 : 60[0] -> 28[0] [send] via NET/AWS Libfabric/0
28: nid005929:16030:16665 [0] NCCL INFO Channel 00/0 : 112[0] -> 104[0] [send] via NET/AWS Libfabric/0
31: nid005937:256589:257239 [0] NCCL INFO Channel 00/0 : 124[0] -> 120[0] [send] via NET/AWS Libfabric/0
12: nid005594:53085:53720 [0] NCCL INFO Channel 01/0 : 56[0] -> 48[0] [receive] via NET/AWS Libfabric/0
20: nid005913:292681:293318 [0] NCCL INFO Channel 00/0 : 80[0] -> 72[0] [send] via NET/AWS Libfabric/0
31: nid005937:256589:257239 [0] NCCL INFO Channel 01/0 : 124[0] -> 120[0] [send] via NET/AWS Libfabric/0
 8: nid005586:68926:69568 [0] NCCL INFO Channel 05/0 : 36[0] -> 32[0] [receive] via NET/AWS Libfabric/0
12: nid005594:53085:53720 [0] NCCL INFO Channel 00/0 : 48[0] -> 40[0] [send] via NET/AWS Libfabric/0
15: nid005601:210676:211332 [0] NCCL INFO Channel 05/0 : 60[0] -> 28[0] [send] via NET/AWS Libfabric/0
28: nid005929:16030:16665 [0] NCCL INFO Channel 01/0 : 112[0] -> 104[0] [send] via NET/AWS Libfabric/0
20: nid005913:292681:293318 [0] NCCL INFO Channel 01/0 : 80[0] -> 72[0] [send] via NET/AWS Libfabric/0
 4: nid005581:264523:265165 [0] NCCL INFO Channel 00/0 : 24[0] -> 16[0] [receive] via NET/AWS Libfabric/0
12: nid005594:53085:53720 [0] NCCL INFO Channel 01/0 : 48[0] -> 40[0] [send] via NET/AWS Libfabric/0
 4: nid005581:264523:265165 [0] NCCL INFO Channel 01/0 : 24[0] -> 16[0] [receive] via NET/AWS Libfabric/0
 4: nid005581:264523:265165 [0] NCCL INFO Channel 00/0 : 16[0] -> 8[0] [send] via NET/AWS Libfabric/0
30: nid005936:49908:50567 [0] NCCL INFO Channel 00/0 : 124[0] -> 120[0] [receive] via NET/AWS Libfabric/0
15: nid005601:210676:211332 [0] NCCL INFO Channel 00/0 : 60[0] -> 56[0] [send] via NET/AWS Libfabric/0
23: nid005917:276885:277523 [0] NCCL INFO Channel 04/0 : 108[0] -> 92[0] [receive] via NET/AWS Libfabric/0
 4: nid005581:264523:265165 [0] NCCL INFO Channel 01/0 : 16[0] -> 8[0] [send] via NET/AWS Libfabric/0
30: nid005936:49908:50567 [0] NCCL INFO Channel 01/0 : 124[0] -> 120[0] [receive] via NET/AWS Libfabric/0
 7: nid005585:122005:122641 [0] NCCL INFO Channel 04/0 : 44[0] -> 28[0] [receive] via NET/AWS Libfabric/0
28: nid005929:16030:16665 [0] NCCL INFO Channel 04/0 : 116[0] -> 112[0] [receive] via NET/AWS Libfabric/0
23: nid005917:276885:277523 [0] NCCL INFO Channel 05/0 : 108[0] -> 92[0] [receive] via NET/AWS Libfabric/0
22: nid005915:274814:275452 [0] NCCL INFO Channel 00/0 : 92[0] -> 88[0] [receive] via NET/AWS Libfabric/0
15: nid005601:210676:211332 [0] NCCL INFO Channel 01/0 : 60[0] -> 56[0] [send] via NET/AWS Libfabric/0
 7: nid005585:122005:122641 [0] NCCL INFO Channel 05/0 : 44[0] -> 28[0] [receive] via NET/AWS Libfabric/0
30: nid005936:49908:50567 [0] NCCL INFO Channel 00/0 : 120[0] -> 116[0] [send] via NET/AWS Libfabric/0
20: nid005913:292681:293318 [0] NCCL INFO Channel 04/0 : 84[0] -> 80[0] [receive] via NET/AWS Libfabric/0
28: nid005929:16030:16665 [0] NCCL INFO Channel 05/0 : 116[0] -> 112[0] [receive] via NET/AWS Libfabric/0
23: nid005917:276885:277523 [0] NCCL INFO Channel 04/0 : 92[0] -> 76[0] [send] via NET/AWS Libfabric/0
22: nid005915:274814:275452 [0] NCCL INFO Channel 01/0 : 92[0] -> 88[0] [receive] via NET/AWS Libfabric/0
12: nid005594:53085:53720 [0] NCCL INFO Channel 04/0 : 52[0] -> 48[0] [receive] via NET/AWS Libfabric/0
 7: nid005585:122005:122641 [0] NCCL INFO Channel 04/0 : 28[0] -> 12[0] [send] via NET/AWS Libfabric/0
26: nid005920:67123:67775 [0] NCCL INFO Channel 00/0 : 108[0] -> 104[0] [receive] via NET/AWS Libfabric/0
20: nid005913:292681:293318 [0] NCCL INFO Channel 05/0 : 84[0] -> 80[0] [receive] via NET/AWS Libfabric/0
18: nid005911:38864:39519 [0] NCCL INFO Channel 00/0 : 76[0] -> 72[0] [receive] via NET/AWS Libfabric/0
23: nid005917:276885:277523 [0] NCCL INFO Channel 05/0 : 92[0] -> 76[0] [send] via NET/AWS Libfabric/0
22: nid005915:274814:275452 [0] NCCL INFO Channel 00/0 : 88[0] -> 84[0] [send] via NET/AWS Libfabric/0
10: nid005590:110710:111344 [0] NCCL INFO Channel 00/0 : 44[0] -> 40[0] [receive] via NET/AWS Libfabric/0
14: nid005600:217720:218385 [0] NCCL INFO Channel 00/0 : 60[0] -> 56[0] [receive] via NET/AWS Libfabric/0
12: nid005594:53085:53720 [0] NCCL INFO Channel 05/0 : 52[0] -> 48[0] [receive] via NET/AWS Libfabric/0
 7: nid005585:122005:122641 [0] NCCL INFO Channel 05/0 : 28[0] -> 12[0] [send] via NET/AWS Libfabric/0
30: nid005936:49908:50567 [0] NCCL INFO Channel 01/0 : 120[0] -> 116[0] [send] via NET/AWS Libfabric/0
14: nid005600:217720:218385 [0] NCCL INFO Channel 01/0 : 60[0] -> 56[0] [receive] via NET/AWS Libfabric/0
26: nid005920:67123:67775 [0] NCCL INFO Channel 01/0 : 108[0] -> 104[0] [receive] via NET/AWS Libfabric/0
30: nid005936:49908:50567 [0] NCCL INFO Channel 04/0 : 120[0] -> 116[0] [send] via NET/AWS Libfabric/0
18: nid005911:38864:39519 [0] NCCL INFO Channel 01/0 : 76[0] -> 72[0] [receive] via NET/AWS Libfabric/0
26: nid005920:67123:67775 [0] NCCL INFO Channel 00/0 : 104[0] -> 100[0] [send] via NET/AWS Libfabric/0
10: nid005590:110710:111344 [0] NCCL INFO Channel 01/0 : 44[0] -> 40[0] [receive] via NET/AWS Libfabric/0
22: nid005915:274814:275452 [0] NCCL INFO Channel 01/0 : 88[0] -> 84[0] [send] via NET/AWS Libfabric/0
30: nid005936:49908:50567 [0] NCCL INFO Channel 05/0 : 120[0] -> 116[0] [send] via NET/AWS Libfabric/0
26: nid005920:67123:67775 [0] NCCL INFO Channel 01/0 : 104[0] -> 100[0] [send] via NET/AWS Libfabric/0
 4: nid005581:264523:265165 [0] NCCL INFO Channel 04/0 : 20[0] -> 16[0] [receive] via NET/AWS Libfabric/0
18: nid005911:38864:39519 [0] NCCL INFO Channel 00/0 : 72[0] -> 68[0] [send] via NET/AWS Libfabric/0
18: nid005911:38864:39519 [0] NCCL INFO Channel 01/0 : 72[0] -> 68[0] [send] via NET/AWS Libfabric/0
 6: nid005584:28285:28917 [0] NCCL INFO Channel 00/0 : 28[0] -> 24[0] [receive] via NET/AWS Libfabric/0
10: nid005590:110710:111344 [0] NCCL INFO Channel 00/0 : 40[0] -> 36[0] [send] via NET/AWS Libfabric/0
 2: nid005577:17422:18081 [0] NCCL INFO Channel 00/0 : 12[0] -> 8[0] [receive] via NET/AWS Libfabric/0
14: nid005600:217720:218385 [0] NCCL INFO Channel 00/0 : 56[0] -> 52[0] [send] via NET/AWS Libfabric/0
14: nid005600:217720:218385 [0] NCCL INFO Channel 01/0 : 56[0] -> 52[0] [send] via NET/AWS Libfabric/0
22: nid005915:274814:275452 [0] NCCL INFO Channel 04/0 : 88[0] -> 84[0] [send] via NET/AWS Libfabric/0
 4: nid005581:264523:265165 [0] NCCL INFO Channel 05/0 : 20[0] -> 16[0] [receive] via NET/AWS Libfabric/0
18: nid005911:38864:39519 [0] NCCL INFO Channel 04/0 : 72[0] -> 68[0] [send] via NET/AWS Libfabric/0
26: nid005920:67123:67775 [0] NCCL INFO Channel 04/0 : 104[0] -> 100[0] [send] via NET/AWS Libfabric/0
 6: nid005584:28285:28917 [0] NCCL INFO Channel 01/0 : 28[0] -> 24[0] [receive] via NET/AWS Libfabric/0
10: nid005590:110710:111344 [0] NCCL INFO Channel 01/0 : 40[0] -> 36[0] [send] via NET/AWS Libfabric/0
 2: nid005577:17422:18081 [0] NCCL INFO Channel 01/0 : 12[0] -> 8[0] [receive] via NET/AWS Libfabric/0
14: nid005600:217720:218385 [0] NCCL INFO Channel 04/0 : 56[0] -> 52[0] [send] via NET/AWS Libfabric/0
22: nid005915:274814:275452 [0] NCCL INFO Channel 05/0 : 88[0] -> 84[0] [send] via NET/AWS Libfabric/0
26: nid005920:67123:67775 [0] NCCL INFO Channel 05/0 : 104[0] -> 100[0] [send] via NET/AWS Libfabric/0
 7: nid005585:122005:122641 [0] NCCL INFO Channel 00/0 : 28[0] -> 24[0] [send] via NET/AWS Libfabric/0
18: nid005911:38864:39519 [0] NCCL INFO Channel 05/0 : 72[0] -> 68[0] [send] via NET/AWS Libfabric/0
27: nid005922:80741:81383 [0] NCCL INFO Channel 04/0 : 116[0] -> 108[0] [receive] via NET/AWS Libfabric/0
 6: nid005584:28285:28917 [0] NCCL INFO Channel 00/0 : 24[0] -> 20[0] [send] via NET/AWS Libfabric/0
10: nid005590:110710:111344 [0] NCCL INFO Channel 04/0 : 40[0] -> 36[0] [send] via NET/AWS Libfabric/0
 2: nid005577:17422:18081 [0] NCCL INFO Channel 00/0 : 8[0] -> 4[0] [send] via NET/AWS Libfabric/0
14: nid005600:217720:218385 [0] NCCL INFO Channel 05/0 : 56[0] -> 52[0] [send] via NET/AWS Libfabric/0
23: nid005917:276885:277523 [0] NCCL INFO Channel 00/0 : 92[0] -> 88[0] [send] via NET/AWS Libfabric/0
23: nid005917:276885:277523 [0] NCCL INFO Channel 01/0 : 92[0] -> 88[0] [send] via NET/AWS Libfabric/0
 7: nid005585:122005:122641 [0] NCCL INFO Channel 01/0 : 28[0] -> 24[0] [send] via NET/AWS Libfabric/0
27: nid005922:80741:81383 [0] NCCL INFO Channel 05/0 : 116[0] -> 108[0] [receive] via NET/AWS Libfabric/0
 6: nid005584:28285:28917 [0] NCCL INFO Channel 01/0 : 24[0] -> 20[0] [send] via NET/AWS Libfabric/0
10: nid005590:110710:111344 [0] NCCL INFO Channel 05/0 : 40[0] -> 36[0] [send] via NET/AWS Libfabric/0
 2: nid005577:17422:18081 [0] NCCL INFO Channel 01/0 : 8[0] -> 4[0] [send] via NET/AWS Libfabric/0
11: nid005591:191603:192243 [0] NCCL INFO Channel 04/0 : 52[0] -> 44[0] [receive] via NET/AWS Libfabric/0
 3: nid005580:71819:72468 [0] NCCL INFO Channel 04/0 : 20[0] -> 12[0] [receive] via NET/AWS Libfabric/0
27: nid005922:80741:81383 [0] NCCL INFO Channel 04/0 : 108[0] -> 100[0] [send] via NET/AWS Libfabric/0
 3: nid005580:71819:72468 [0] NCCL INFO Channel 05/0 : 20[0] -> 12[0] [receive] via NET/AWS Libfabric/0
19: nid005912:12435:13072 [0] NCCL INFO Channel 04/0 : 84[0] -> 76[0] [receive] via NET/AWS Libfabric/0
 6: nid005584:28285:28917 [0] NCCL INFO Channel 04/0 : 24[0] -> 20[0] [send] via NET/AWS Libfabric/0
 2: nid005577:17422:18081 [0] NCCL INFO Channel 04/0 : 8[0] -> 4[0] [send] via NET/AWS Libfabric/0
 3: nid005580:71819:72468 [0] NCCL INFO Channel 04/0 : 12[0] -> 4[0] [send] via NET/AWS Libfabric/0
11: nid005591:191603:192243 [0] NCCL INFO Channel 05/0 : 52[0] -> 44[0] [receive] via NET/AWS Libfabric/0
19: nid005912:12435:13072 [0] NCCL INFO Channel 05/0 : 84[0] -> 76[0] [receive] via NET/AWS Libfabric/0
27: nid005922:80741:81383 [0] NCCL INFO Channel 05/0 : 108[0] -> 100[0] [send] via NET/AWS Libfabric/0
 6: nid005584:28285:28917 [0] NCCL INFO Channel 05/0 : 24[0] -> 20[0] [send] via NET/AWS Libfabric/0
11: nid005591:191603:192243 [0] NCCL INFO Channel 04/0 : 44[0] -> 36[0] [send] via NET/AWS Libfabric/0
 2: nid005577:17422:18081 [0] NCCL INFO Channel 05/0 : 8[0] -> 4[0] [send] via NET/AWS Libfabric/0
19: nid005912:12435:13072 [0] NCCL INFO Channel 04/0 : 76[0] -> 68[0] [send] via NET/AWS Libfabric/0
 3: nid005580:71819:72468 [0] NCCL INFO Channel 05/0 : 12[0] -> 4[0] [send] via NET/AWS Libfabric/0
11: nid005591:191603:192243 [0] NCCL INFO Channel 05/0 : 44[0] -> 36[0] [send] via NET/AWS Libfabric/0
19: nid005912:12435:13072 [0] NCCL INFO Channel 05/0 : 76[0] -> 68[0] [send] via NET/AWS Libfabric/0
29: nid005932:167680:168334 [0] NCCL INFO Channel 00/0 : 120[0] -> 116[0] [receive] via NET/AWS Libfabric/0
27: nid005922:80741:81383 [0] NCCL INFO Channel 00/0 : 108[0] -> 104[0] [send] via NET/AWS Libfabric/0
29: nid005932:167680:168334 [0] NCCL INFO Channel 01/0 : 120[0] -> 116[0] [receive] via NET/AWS Libfabric/0
 1: nid005576:147557:148198 [0] NCCL INFO Channel 00/0 : 8[0] -> 4[0] [receive] via NET/AWS Libfabric/0
27: nid005922:80741:81383 [0] NCCL INFO Channel 01/0 : 108[0] -> 104[0] [send] via NET/AWS Libfabric/0
29: nid005932:167680:168334 [0] NCCL INFO Channel 04/0 : 120[0] -> 116[0] [receive] via NET/AWS Libfabric/0
13: nid005595:197883:198573 [0] NCCL INFO Channel 00/0 : 56[0] -> 52[0] [receive] via NET/AWS Libfabric/0
 3: nid005580:71819:72468 [0] NCCL INFO Channel 00/0 : 12[0] -> 8[0] [send] via NET/AWS Libfabric/0
 1: nid005576:147557:148198 [0] NCCL INFO Channel 01/0 : 8[0] -> 4[0] [receive] via NET/AWS Libfabric/0
21: nid005914:166784:167414 [0] NCCL INFO Channel 00/0 : 88[0] -> 84[0] [receive] via NET/AWS Libfabric/0
29: nid005932:167680:168334 [0] NCCL INFO Channel 05/0 : 120[0] -> 116[0] [receive] via NET/AWS Libfabric/0
19: nid005912:12435:13072 [0] NCCL INFO Channel 00/0 : 76[0] -> 72[0] [send] via NET/AWS Libfabric/0
13: nid005595:197883:198573 [0] NCCL INFO Channel 01/0 : 56[0] -> 52[0] [receive] via NET/AWS Libfabric/0
11: nid005591:191603:192243 [0] NCCL INFO Channel 00/0 : 44[0] -> 40[0] [send] via NET/AWS Libfabric/0
 1: nid005576:147557:148198 [0] NCCL INFO Channel 04/0 : 8[0] -> 4[0] [receive] via NET/AWS Libfabric/0
 3: nid005580:71819:72468 [0] NCCL INFO Channel 01/0 : 12[0] -> 8[0] [send] via NET/AWS Libfabric/0
 9: nid005588:35935:36599 [0] NCCL INFO Channel 00/0 : 40[0] -> 36[0] [receive] via NET/AWS Libfabric/0
21: nid005914:166784:167414 [0] NCCL INFO Channel 01/0 : 88[0] -> 84[0] [receive] via NET/AWS Libfabric/0
29: nid005932:167680:168334 [0] NCCL INFO Channel 04/0 : 116[0] -> 112[0] [send] via NET/AWS Libfabric/0
17: nid005803:180732:181388 [0] NCCL INFO Channel 00/0 : 72[0] -> 68[0] [receive] via NET/AWS Libfabric/0
19: nid005912:12435:13072 [0] NCCL INFO Channel 01/0 : 76[0] -> 72[0] [send] via NET/AWS Libfabric/0
13: nid005595:197883:198573 [0] NCCL INFO Channel 04/0 : 56[0] -> 52[0] [receive] via NET/AWS Libfabric/0
11: nid005591:191603:192243 [0] NCCL INFO Channel 01/0 : 44[0] -> 40[0] [send] via NET/AWS Libfabric/0
29: nid005932:167680:168334 [0] NCCL INFO Channel 05/0 : 116[0] -> 112[0] [send] via NET/AWS Libfabric/0
 1: nid005576:147557:148198 [0] NCCL INFO Channel 05/0 : 8[0] -> 4[0] [receive] via NET/AWS Libfabric/0
17: nid005803:180732:181388 [0] NCCL INFO Channel 01/0 : 72[0] -> 68[0] [receive] via NET/AWS Libfabric/0
 9: nid005588:35935:36599 [0] NCCL INFO Channel 01/0 : 40[0] -> 36[0] [receive] via NET/AWS Libfabric/0
21: nid005914:166784:167414 [0] NCCL INFO Channel 04/0 : 88[0] -> 84[0] [receive] via NET/AWS Libfabric/0
13: nid005595:197883:198573 [0] NCCL INFO Channel 05/0 : 56[0] -> 52[0] [receive] via NET/AWS Libfabric/0
 1: nid005576:147557:148198 [0] NCCL INFO Channel 04/0 : 4[0] -> 0[0] [send] via NET/AWS Libfabric/0
21: nid005914:166784:167414 [0] NCCL INFO Channel 05/0 : 88[0] -> 84[0] [receive] via NET/AWS Libfabric/0
17: nid005803:180732:181388 [0] NCCL INFO Channel 04/0 : 72[0] -> 68[0] [receive] via NET/AWS Libfabric/0
 9: nid005588:35935:36599 [0] NCCL INFO Channel 04/0 : 40[0] -> 36[0] [receive] via NET/AWS Libfabric/0
13: nid005595:197883:198573 [0] NCCL INFO Channel 04/0 : 52[0] -> 48[0] [send] via NET/AWS Libfabric/0
21: nid005914:166784:167414 [0] NCCL INFO Channel 04/0 : 84[0] -> 80[0] [send] via NET/AWS Libfabric/0
 1: nid005576:147557:148198 [0] NCCL INFO Channel 05/0 : 4[0] -> 0[0] [send] via NET/AWS Libfabric/0
17: nid005803:180732:181388 [0] NCCL INFO Channel 05/0 : 72[0] -> 68[0] [receive] via NET/AWS Libfabric/0
 9: nid005588:35935:36599 [0] NCCL INFO Channel 05/0 : 40[0] -> 36[0] [receive] via NET/AWS Libfabric/0
31: nid005937:256592:257238 [3] NCCL INFO Channel 01/0 : 127[3] -> 126[2] via P2P/CUMEM
13: nid005595:197883:198573 [0] NCCL INFO Channel 05/0 : 52[0] -> 48[0] [send] via NET/AWS Libfabric/0
17: nid005803:180732:181388 [0] NCCL INFO Channel 04/0 : 68[0] -> 64[0] [send] via NET/AWS Libfabric/0
21: nid005914:166784:167414 [0] NCCL INFO Channel 05/0 : 84[0] -> 80[0] [send] via NET/AWS Libfabric/0
 9: nid005588:35935:36599 [0] NCCL INFO Channel 04/0 : 36[0] -> 32[0] [send] via NET/AWS Libfabric/0
15: nid005601:210679:211330 [3] NCCL INFO Channel 01/0 : 63[3] -> 62[2] via P2P/CUMEM
17: nid005803:180732:181388 [0] NCCL INFO Channel 05/0 : 68[0] -> 64[0] [send] via NET/AWS Libfabric/0
 9: nid005588:35935:36599 [0] NCCL INFO Channel 05/0 : 36[0] -> 32[0] [send] via NET/AWS Libfabric/0
23: nid005917:276888:277520 [3] NCCL INFO Channel 01/0 : 95[3] -> 94[2] via P2P/CUMEM
 5: nid005582:196713:197505 [0] NCCL INFO Channel 00/0 : 24[0] -> 20[0] [receive] via NET/AWS Libfabric/0
 5: nid005582:196713:197505 [0] NCCL INFO Channel 01/0 : 24[0] -> 20[0] [receive] via NET/AWS Libfabric/0
 7: nid005585:122008:122644 [3] NCCL INFO Channel 01/0 : 31[3] -> 30[2] via P2P/CUMEM
31: nid005937:256592:257238 [3] NCCL INFO Channel 03/0 : 127[3] -> 126[2] via P2P/CUMEM
 5: nid005582:196713:197505 [0] NCCL INFO Channel 04/0 : 24[0] -> 20[0] [receive] via NET/AWS Libfabric/0
15: nid005601:210679:211330 [3] NCCL INFO Channel 03/0 : 63[3] -> 62[2] via P2P/CUMEM
 5: nid005582:196713:197505 [0] NCCL INFO Channel 05/0 : 24[0] -> 20[0] [receive] via NET/AWS Libfabric/0
23: nid005917:276888:277520 [3] NCCL INFO Channel 03/0 : 95[3] -> 94[2] via P2P/CUMEM
 5: nid005582:196713:197505 [0] NCCL INFO Channel 04/0 : 20[0] -> 16[0] [send] via NET/AWS Libfabric/0
 5: nid005582:196713:197505 [0] NCCL INFO Channel 05/0 : 20[0] -> 16[0] [send] via NET/AWS Libfabric/0
27: nid005922:80744:81384 [3] NCCL INFO Channel 01/0 : 111[3] -> 110[2] via P2P/CUMEM
31: nid005937:256592:257238 [3] NCCL INFO Channel 05/0 : 127[3] -> 126[2] via P2P/CUMEM
15: nid005601:210679:211330 [3] NCCL INFO Channel 05/0 : 63[3] -> 62[2] via P2P/CUMEM
19: nid005912:12438:13070 [3] NCCL INFO Channel 01/0 : 79[3] -> 78[2] via P2P/CUMEM
 3: nid005580:71822:72469 [3] NCCL INFO Channel 01/0 : 15[3] -> 14[2] via P2P/CUMEM
23: nid005917:276888:277520 [3] NCCL INFO Channel 05/0 : 95[3] -> 94[2] via P2P/CUMEM
11: nid005591:191606:192245 [3] NCCL INFO Channel 01/0 : 47[3] -> 46[2] via P2P/CUMEM
 7: nid005585:122008:122644 [3] NCCL INFO Channel 03/0 : 31[3] -> 30[2] via P2P/CUMEM
30: nid005936:49911:50569 [3] NCCL INFO Channel 00/0 : 123[3] -> 122[2] via P2P/CUMEM
31: nid005937:256592:257238 [3] NCCL INFO Channel 07/0 : 127[3] -> 126[2] via P2P/CUMEM
28: nid005929:16033:16667 [3] NCCL INFO Channel 00/0 : 115[3] -> 114[2] via P2P/CUMEM
27: nid005922:80744:81384 [3] NCCL INFO Channel 03/0 : 111[3] -> 110[2] via P2P/CUMEM
15: nid005601:210679:211330 [3] NCCL INFO Channel 07/0 : 63[3] -> 62[2] via P2P/CUMEM
 2: nid005577:17425:18084 [3] NCCL INFO Channel 00/0 : 11[3] -> 10[2] via P2P/CUMEM
 3: nid005580:71822:72469 [3] NCCL INFO Channel 03/0 : 15[3] -> 14[2] via P2P/CUMEM
29: nid005932:167683:168333 [3] NCCL INFO Channel 01/0 : 119[3] -> 118[2] via P2P/CUMEM
19: nid005912:12438:13070 [3] NCCL INFO Channel 03/0 : 79[3] -> 78[2] via P2P/CUMEM
23: nid005917:276888:277520 [3] NCCL INFO Channel 07/0 : 95[3] -> 94[2] via P2P/CUMEM
 0: nid005574:69061:69730 [3] NCCL INFO Channel 00/0 : 3[3] -> 2[2] via P2P/CUMEM
 1: nid005576:147560:148200 [3] NCCL INFO Channel 01/0 : 7[3] -> 6[2] via P2P/CUMEM
14: nid005600:217723:218388 [3] NCCL INFO Channel 00/0 : 59[3] -> 58[2] via P2P/CUMEM
11: nid005591:191606:192245 [3] NCCL INFO Channel 03/0 : 47[3] -> 46[2] via P2P/CUMEM
21: nid005914:166787:167413 [3] NCCL INFO Channel 01/0 : 87[3] -> 86[2] via P2P/CUMEM
22: nid005915:274817:275450 [3] NCCL INFO Channel 00/0 : 91[3] -> 90[2] via P2P/CUMEM
17: nid005803:180735:181387 [3] NCCL INFO Channel 01/0 : 71[3] -> 70[2] via P2P/CUMEM
 7: nid005585:122008:122644 [3] NCCL INFO Channel 05/0 : 31[3] -> 30[2] via P2P/CUMEM
18: nid005911:38867:39522 [3] NCCL INFO Channel 00/0 : 75[3] -> 74[2] via P2P/CUMEM
10: nid005590:110713:111343 [3] NCCL INFO Channel 00/0 : 43[3] -> 42[2] via P2P/CUMEM
13: nid005595:197886:198574 [3] NCCL INFO Channel 01/0 : 55[3] -> 54[2] via P2P/CUMEM
12: nid005594:53088:53723 [3] NCCL INFO Channel 00/0 : 51[3] -> 50[2] via P2P/CUMEM
 9: nid005588:35938:36600 [3] NCCL INFO Channel 01/0 : 39[3] -> 38[2] via P2P/CUMEM
20: nid005913:292684:293316 [3] NCCL INFO Channel 00/0 : 83[3] -> 82[2] via P2P/CUMEM
28: nid005929:16033:16667 [3] NCCL INFO Channel 02/0 : 115[3] -> 114[2] via P2P/CUMEM
27: nid005922:80744:81384 [3] NCCL INFO Channel 05/0 : 111[3] -> 110[2] via P2P/CUMEM
16: nid005802:6300:7002 [3] NCCL INFO Channel 00/0 : 67[3] -> 66[2] via P2P/CUMEM
 8: nid005586:68929:69567 [3] NCCL INFO Channel 00/0 : 35[3] -> 34[2] via P2P/CUMEM
30: nid005936:49911:50569 [3] NCCL INFO Channel 02/0 : 123[3] -> 122[2] via P2P/CUMEM
 3: nid005580:71822:72469 [3] NCCL INFO Channel 05/0 : 15[3] -> 14[2] via P2P/CUMEM
 7: nid005585:122008:122644 [3] NCCL INFO Channel 07/0 : 31[3] -> 30[2] via P2P/CUMEM
19: nid005912:12438:13070 [3] NCCL INFO Channel 05/0 : 79[3] -> 78[2] via P2P/CUMEM
11: nid005591:191606:192245 [3] NCCL INFO Channel 05/0 : 47[3] -> 46[2] via P2P/CUMEM
29: nid005932:167683:168333 [3] NCCL INFO Channel 03/0 : 119[3] -> 118[2] via P2P/CUMEM
 1: nid005576:147560:148200 [3] NCCL INFO Channel 03/0 : 7[3] -> 6[2] via P2P/CUMEM
22: nid005915:274817:275450 [3] NCCL INFO Channel 02/0 : 91[3] -> 90[2] via P2P/CUMEM
 2: nid005577:17425:18084 [3] NCCL INFO Channel 02/0 : 11[3] -> 10[2] via P2P/CUMEM
10: nid005590:110713:111343 [3] NCCL INFO Channel 02/0 : 43[3] -> 42[2] via P2P/CUMEM
28: nid005929:16033:16667 [3] NCCL INFO Channel 04/0 : 115[3] -> 114[2] via P2P/CUMEM
13: nid005595:197886:198574 [3] NCCL INFO Channel 03/0 : 55[3] -> 54[2] via P2P/CUMEM
27: nid005922:80744:81384 [3] NCCL INFO Channel 07/0 : 111[3] -> 110[2] via P2P/CUMEM
 9: nid005588:35938:36600 [3] NCCL INFO Channel 03/0 : 39[3] -> 38[2] via P2P/CUMEM
21: nid005914:166787:167413 [3] NCCL INFO Channel 03/0 : 87[3] -> 86[2] via P2P/CUMEM
17: nid005803:180735:181387 [3] NCCL INFO Channel 03/0 : 71[3] -> 70[2] via P2P/CUMEM
12: nid005594:53088:53723 [3] NCCL INFO Channel 02/0 : 51[3] -> 50[2] via P2P/CUMEM
 0: nid005574:69061:69730 [3] NCCL INFO Channel 02/0 : 3[3] -> 2[2] via P2P/CUMEM
 3: nid005580:71822:72469 [3] NCCL INFO Channel 07/0 : 15[3] -> 14[2] via P2P/CUMEM
19: nid005912:12438:13070 [3] NCCL INFO Channel 07/0 : 79[3] -> 78[2] via P2P/CUMEM
 6: nid005584:28288:28916 [3] NCCL INFO Channel 00/0 : 27[3] -> 26[2] via P2P/CUMEM
30: nid005936:49911:50569 [3] NCCL INFO Channel 04/0 : 123[3] -> 122[2] via P2P/CUMEM
 1: nid005576:147560:148200 [3] NCCL INFO Channel 05/0 : 7[3] -> 6[2] via P2P/CUMEM
29: nid005932:167683:168333 [3] NCCL INFO Channel 05/0 : 119[3] -> 118[2] via P2P/CUMEM
18: nid005911:38867:39522 [3] NCCL INFO Channel 02/0 : 75[3] -> 74[2] via P2P/CUMEM
16: nid005802:6300:7002 [3] NCCL INFO Channel 02/0 : 67[3] -> 66[2] via P2P/CUMEM
11: nid005591:191606:192245 [3] NCCL INFO Channel 07/0 : 47[3] -> 46[2] via P2P/CUMEM
 5: nid005582:196716:197504 [3] NCCL INFO Channel 01/0 : 23[3] -> 22[2] via P2P/CUMEM
20: nid005913:292684:293316 [3] NCCL INFO Channel 02/0 : 83[3] -> 82[2] via P2P/CUMEM
10: nid005590:110713:111343 [3] NCCL INFO Channel 04/0 : 43[3] -> 42[2] via P2P/CUMEM
 2: nid005577:17425:18084 [3] NCCL INFO Channel 04/0 : 11[3] -> 10[2] via P2P/CUMEM
 4: nid005581:264526:265166 [3] NCCL INFO Channel 00/0 : 19[3] -> 18[2] via P2P/CUMEM
28: nid005929:16033:16667 [3] NCCL INFO Channel 06/0 : 115[3] -> 114[2] via P2P/CUMEM
22: nid005915:274817:275450 [3] NCCL INFO Channel 04/0 : 91[3] -> 90[2] via P2P/CUMEM
13: nid005595:197886:198574 [3] NCCL INFO Channel 05/0 : 55[3] -> 54[2] via P2P/CUMEM
 8: nid005586:68929:69567 [3] NCCL INFO Channel 02/0 : 35[3] -> 34[2] via P2P/CUMEM
12: nid005594:53088:53723 [3] NCCL INFO Channel 04/0 : 51[3] -> 50[2] via P2P/CUMEM
21: nid005914:166787:167413 [3] NCCL INFO Channel 05/0 : 87[3] -> 86[2] via P2P/CUMEM
 9: nid005588:35938:36600 [3] NCCL INFO Channel 05/0 : 39[3] -> 38[2] via P2P/CUMEM
17: nid005803:180735:181387 [3] NCCL INFO Channel 05/0 : 71[3] -> 70[2] via P2P/CUMEM
 0: nid005574:69061:69730 [3] NCCL INFO Channel 04/0 : 3[3] -> 2[2] via P2P/CUMEM
10: nid005590:110713:111343 [3] NCCL INFO Channel 06/0 : 43[3] -> 42[2] via P2P/CUMEM
 1: nid005576:147560:148200 [3] NCCL INFO Channel 07/0 : 7[3] -> 6[2] via P2P/CUMEM
 6: nid005584:28288:28916 [3] NCCL INFO Channel 02/0 : 27[3] -> 26[2] via P2P/CUMEM
29: nid005932:167683:168333 [3] NCCL INFO Channel 07/0 : 119[3] -> 118[2] via P2P/CUMEM
18: nid005911:38867:39522 [3] NCCL INFO Channel 04/0 : 75[3] -> 74[2] via P2P/CUMEM
16: nid005802:6300:7002 [3] NCCL INFO Channel 04/0 : 67[3] -> 66[2] via P2P/CUMEM
 2: nid005577:17425:18084 [3] NCCL INFO Channel 06/0 : 11[3] -> 10[2] via P2P/CUMEM
 5: nid005582:196716:197504 [3] NCCL INFO Channel 03/0 : 23[3] -> 22[2] via P2P/CUMEM
12: nid005594:53088:53723 [3] NCCL INFO Channel 06/0 : 51[3] -> 50[2] via P2P/CUMEM
30: nid005936:49911:50569 [3] NCCL INFO Channel 06/0 : 123[3] -> 122[2] via P2P/CUMEM
25: nid005919:107462:108105 [0] NCCL INFO Channel 00/0 : 104[0] -> 100[0] [receive] via NET/AWS Libfabric/0
22: nid005915:274817:275450 [3] NCCL INFO Channel 06/0 : 91[3] -> 90[2] via P2P/CUMEM
 8: nid005586:68929:69567 [3] NCCL INFO Channel 04/0 : 35[3] -> 34[2] via P2P/CUMEM
 4: nid005581:264526:265166 [3] NCCL INFO Channel 02/0 : 19[3] -> 18[2] via P2P/CUMEM
25: nid005919:107462:108105 [0] NCCL INFO Channel 01/0 : 104[0] -> 100[0] [receive] via NET/AWS Libfabric/0
13: nid005595:197886:198574 [3] NCCL INFO Channel 07/0 : 55[3] -> 54[2] via P2P/CUMEM
20: nid005913:292684:293316 [3] NCCL INFO Channel 04/0 : 83[3] -> 82[2] via P2P/CUMEM
 0: nid005574:69061:69730 [3] NCCL INFO Channel 06/0 : 3[3] -> 2[2] via P2P/CUMEM
21: nid005914:166787:167413 [3] NCCL INFO Channel 07/0 : 87[3] -> 86[2] via P2P/CUMEM
25: nid005919:107462:108105 [0] NCCL INFO Channel 04/0 : 104[0] -> 100[0] [receive] via NET/AWS Libfabric/0
 9: nid005588:35938:36600 [3] NCCL INFO Channel 07/0 : 39[3] -> 38[2] via P2P/CUMEM
17: nid005803:180735:181387 [3] NCCL INFO Channel 07/0 : 71[3] -> 70[2] via P2P/CUMEM
 6: nid005584:28288:28916 [3] NCCL INFO Channel 04/0 : 27[3] -> 26[2] via P2P/CUMEM
25: nid005919:107462:108105 [0] NCCL INFO Channel 05/0 : 104[0] -> 100[0] [receive] via NET/AWS Libfabric/0
18: nid005911:38867:39522 [3] NCCL INFO Channel 06/0 : 75[3] -> 74[2] via P2P/CUMEM
16: nid005802:6300:7002 [3] NCCL INFO Channel 06/0 : 67[3] -> 66[2] via P2P/CUMEM
25: nid005919:107462:108105 [0] NCCL INFO Channel 04/0 : 100[0] -> 96[0] [send] via NET/AWS Libfabric/0
 5: nid005582:196716:197504 [3] NCCL INFO Channel 05/0 : 23[3] -> 22[2] via P2P/CUMEM
25: nid005919:107462:108105 [0] NCCL INFO Channel 05/0 : 100[0] -> 96[0] [send] via NET/AWS Libfabric/0
 4: nid005581:264526:265166 [3] NCCL INFO Channel 04/0 : 19[3] -> 18[2] via P2P/CUMEM
 6: nid005584:28288:28916 [3] NCCL INFO Channel 06/0 : 27[3] -> 26[2] via P2P/CUMEM
20: nid005913:292684:293316 [3] NCCL INFO Channel 06/0 : 83[3] -> 82[2] via P2P/CUMEM
 5: nid005582:196716:197504 [3] NCCL INFO Channel 07/0 : 23[3] -> 22[2] via P2P/CUMEM
 4: nid005581:264526:265166 [3] NCCL INFO Channel 06/0 : 19[3] -> 18[2] via P2P/CUMEM
26: nid005920:67126:67777 [3] NCCL INFO Channel 00/0 : 107[3] -> 106[2] via P2P/CUMEM
25: nid005919:107465:108104 [3] NCCL INFO Channel 01/0 : 103[3] -> 102[2] via P2P/CUMEM
24: nid005918:92507:93177 [3] NCCL INFO Channel 00/0 : 99[3] -> 98[2] via P2P/CUMEM
26: nid005920:67126:67777 [3] NCCL INFO Channel 02/0 : 107[3] -> 106[2] via P2P/CUMEM
25: nid005919:107465:108104 [3] NCCL INFO Channel 03/0 : 103[3] -> 102[2] via P2P/CUMEM
26: nid005920:67126:67777 [3] NCCL INFO Channel 04/0 : 107[3] -> 106[2] via P2P/CUMEM
25: nid005919:107465:108104 [3] NCCL INFO Channel 05/0 : 103[3] -> 102[2] via P2P/CUMEM
14: nid005600:217723:218388 [3] NCCL INFO Channel 02/0 : 59[3] -> 58[2] via P2P/CUMEM
24: nid005918:92507:93177 [3] NCCL INFO Channel 02/0 : 99[3] -> 98[2] via P2P/CUMEM
25: nid005919:107465:108104 [3] NCCL INFO Channel 07/0 : 103[3] -> 102[2] via P2P/CUMEM
26: nid005920:67126:67777 [3] NCCL INFO Channel 06/0 : 107[3] -> 106[2] via P2P/CUMEM
24: nid005918:92507:93177 [3] NCCL INFO Channel 04/0 : 99[3] -> 98[2] via P2P/CUMEM
24: nid005918:92507:93177 [3] NCCL INFO Channel 06/0 : 99[3] -> 98[2] via P2P/CUMEM
 8: nid005586:68929:69567 [3] NCCL INFO Channel 06/0 : 35[3] -> 34[2] via P2P/CUMEM
14: nid005600:217723:218388 [3] NCCL INFO Channel 04/0 : 59[3] -> 58[2] via P2P/CUMEM
14: nid005600:217723:218388 [3] NCCL INFO Channel 06/0 : 59[3] -> 58[2] via P2P/CUMEM
31: nid005937:256589:257239 [0] NCCL INFO Connected all trees
15: nid005601:210676:211332 [0] NCCL INFO Connected all trees
 7: nid005585:122005:122641 [0] NCCL INFO Connected all trees
 0: nid005574:69058:69733 [0] NCCL INFO Connected all trees
23: nid005917:276885:277523 [0] NCCL INFO Connected all trees
 3: nid005580:71819:72468 [0] NCCL INFO Connected all trees
 8: nid005586:68926:69568 [0] NCCL INFO Connected all trees
 2: nid005577:17422:18081 [0] NCCL INFO Connected all trees
 1: nid005576:147557:148198 [0] NCCL INFO Connected all trees
11: nid005591:191603:192243 [0] NCCL INFO Connected all trees
19: nid005912:12435:13072 [0] NCCL INFO Connected all trees
10: nid005590:110710:111344 [0] NCCL INFO Connected all trees
 4: nid005581:264523:265165 [0] NCCL INFO Connected all trees
12: nid005594:53085:53720 [0] NCCL INFO Connected all trees
 9: nid005588:35935:36599 [0] NCCL INFO Connected all trees
20: nid005913:292681:293318 [0] NCCL INFO Connected all trees
27: nid005922:80741:81383 [0] NCCL INFO Connected all trees
 5: nid005582:196713:197505 [0] NCCL INFO Connected all trees
25: nid005919:107462:108105 [0] NCCL INFO Connected all trees
28: nid005929:16030:16665 [0] NCCL INFO Connected all trees
13: nid005595:197883:198573 [0] NCCL INFO Connected all trees
21: nid005914:166784:167414 [0] NCCL INFO Connected all trees
26: nid005920:67123:67775 [0] NCCL INFO Connected all trees
22: nid005915:274814:275452 [0] NCCL INFO Connected all trees
30: nid005936:49908:50567 [0] NCCL INFO Connected all trees
 6: nid005584:28285:28917 [0] NCCL INFO Connected all trees
14: nid005600:217720:218385 [0] NCCL INFO Connected all trees
17: nid005803:180732:181388 [0] NCCL INFO Connected all trees
16: nid005802:6297:7000 [0] NCCL INFO Connected all trees
18: nid005911:38864:39519 [0] NCCL INFO Connected all trees
29: nid005932:167680:168334 [0] NCCL INFO Connected all trees
24: nid005918:92504:93175 [0] NCCL INFO Connected all trees
31: nid005937:256590:257240 [1] NCCL INFO Connected all trees
31: nid005937:256592:257238 [3] NCCL INFO Connected all trees
31: nid005937:256591:257241 [2] NCCL INFO Connected all trees
15: nid005601:210677:211331 [1] NCCL INFO Connected all trees
15: nid005601:210679:211330 [3] NCCL INFO Connected all trees
 7: nid005585:122006:122643 [1] NCCL INFO Connected all trees
 0: nid005574:69059:69728 [1] NCCL INFO Connected all trees
15: nid005601:210678:211329 [2] NCCL INFO Connected all trees
 7: nid005585:122008:122644 [3] NCCL INFO Connected all trees
 3: nid005580:71820:72470 [1] NCCL INFO Connected all trees
 1: nid005576:147558:148199 [1] NCCL INFO Connected all trees
 7: nid005585:122007:122642 [2] NCCL INFO Connected all trees
 4: nid005581:264524:265167 [1] NCCL INFO Connected all trees
 8: nid005586:68927:69566 [1] NCCL INFO Connected all trees
11: nid005591:191604:192246 [1] NCCL INFO Connected all trees
 0: nid005574:69060:69729 [2] NCCL INFO Connected all trees
 0: nid005574:69061:69730 [3] NCCL INFO Connected all trees
 5: nid005582:196714:197502 [1] NCCL INFO Connected all trees
 3: nid005580:71822:72469 [3] NCCL INFO Connected all trees
12: nid005594:53086:53722 [1] NCCL INFO Connected all trees
16: nid005802:6298:6998 [1] NCCL INFO Connected all trees
 1: nid005576:147560:148200 [3] NCCL INFO Connected all trees
 4: nid005581:264526:265166 [3] NCCL INFO Connected all trees
 9: nid005588:35936:36597 [1] NCCL INFO Connected all trees
 6: nid005584:28286:28918 [1] NCCL INFO Connected all trees
 8: nid005586:68929:69567 [3] NCCL INFO Connected all trees
11: nid005591:191606:192245 [3] NCCL INFO Connected all trees
 4: nid005581:264525:265164 [2] NCCL INFO Connected all trees
 3: nid005580:71821:72471 [2] NCCL INFO Connected all trees
24: nid005918:92505:93178 [1] NCCL INFO Connected all trees
 1: nid005576:147559:148197 [2] NCCL INFO Connected all trees
10: nid005590:110711:111345 [1] NCCL INFO Connected all trees
11: nid005591:191605:192244 [2] NCCL INFO Connected all trees
 5: nid005582:196716:197504 [3] NCCL INFO Connected all trees
12: nid005594:53088:53723 [3] NCCL INFO Connected all trees
 5: nid005582:196715:197503 [2] NCCL INFO Connected all trees
13: nid005595:197884:198572 [1] NCCL INFO Connected all trees
 6: nid005584:28288:28916 [3] NCCL INFO Connected all trees
 9: nid005588:35938:36600 [3] NCCL INFO Connected all trees
24: nid005918:92507:93177 [3] NCCL INFO Connected all trees
17: nid005803:180733:181386 [1] NCCL INFO Connected all trees
20: nid005913:292682:293317 [1] NCCL INFO Connected all trees
27: nid005922:80742:81386 [1] NCCL INFO Connected all trees
16: nid005802:6300:7002 [3] NCCL INFO Connected all trees
 8: nid005586:68928:69565 [2] NCCL INFO Connected all trees
10: nid005590:110713:111343 [3] NCCL INFO Connected all trees
 9: nid005588:35937:36596 [2] NCCL INFO Connected all trees
16: nid005802:6299:7001 [2] NCCL INFO Connected all trees
25: nid005919:107463:108106 [1] NCCL INFO Connected all trees
23: nid005917:276886:277522 [1] NCCL INFO Connected all trees
28: nid005929:16031:16666 [1] NCCL INFO Connected all trees
19: nid005912:12436:13071 [1] NCCL INFO Connected all trees
22: nid005915:274815:275453 [1] NCCL INFO Connected all trees
12: nid005594:53087:53721 [2] NCCL INFO Connected all trees
19: nid005912:12438:13070 [3] NCCL INFO Connected all trees
30: nid005936:49909:50570 [1] NCCL INFO Connected all trees
13: nid005595:197886:198574 [3] NCCL INFO Connected all trees
21: nid005914:166785:167415 [1] NCCL INFO Connected all trees
 6: nid005584:28287:28919 [2] NCCL INFO Connected all trees
13: nid005595:197885:198571 [2] NCCL INFO Connected all trees
29: nid005932:167681:168332 [1] NCCL INFO Connected all trees
24: nid005918:92506:93176 [2] NCCL INFO Connected all trees
26: nid005920:67124:67778 [1] NCCL INFO Connected all trees
29: nid005932:167683:168333 [3] NCCL INFO Connected all trees
17: nid005803:180735:181387 [3] NCCL INFO Connected all trees
20: nid005913:292684:293316 [3] NCCL INFO Connected all trees
26: nid005920:67126:67777 [3] NCCL INFO Connected all trees
17: nid005803:180734:181389 [2] NCCL INFO Connected all trees
20: nid005913:292683:293319 [2] NCCL INFO Connected all trees
18: nid005911:38865:39521 [1] NCCL INFO Connected all trees
10: nid005590:110712:111346 [2] NCCL INFO Connected all trees
 2: nid005577:17424:18083 [2] NCCL INFO Connected all trees
18: nid005911:38867:39522 [3] NCCL INFO Connected all trees
27: nid005922:80744:81384 [3] NCCL INFO Connected all trees
18: nid005911:38866:39520 [2] NCCL INFO Connected all trees
23: nid005917:276888:277520 [3] NCCL INFO Connected all trees
27: nid005922:80743:81385 [2] NCCL INFO Connected all trees
28: nid005929:16033:16667 [3] NCCL INFO Connected all trees
19: nid005912:12437:13073 [2] NCCL INFO Connected all trees
25: nid005919:107465:108104 [3] NCCL INFO Connected all trees
23: nid005917:276887:277521 [2] NCCL INFO Connected all trees
28: nid005929:16032:16664 [2] NCCL INFO Connected all trees
22: nid005915:274817:275450 [3] NCCL INFO Connected all trees
21: nid005914:166787:167413 [3] NCCL INFO Connected all trees
25: nid005919:107464:108107 [2] NCCL INFO Connected all trees
30: nid005936:49911:50569 [3] NCCL INFO Connected all trees
22: nid005915:274816:275451 [2] NCCL INFO Connected all trees
29: nid005932:167682:168331 [2] NCCL INFO Connected all trees
21: nid005914:166786:167416 [2] NCCL INFO Connected all trees
26: nid005920:67125:67776 [2] NCCL INFO Connected all trees
30: nid005936:49910:50568 [2] NCCL INFO Connected all trees
 2: nid005577:17423:18082 [1] NCCL INFO Connected all trees
 2: nid005577:17425:18084 [3] NCCL INFO Connected all trees
14: nid005600:217721:218386 [1] NCCL INFO Connected all trees
14: nid005600:217723:218388 [3] NCCL INFO Connected all trees
14: nid005600:217722:218387 [2] NCCL INFO Connected all trees
 0: [2025-06-27 21:03:24,713] [INFO] [utils.py:781:see_memory_usage] After creating fp16 partitions: 2
 0: [2025-06-27 21:03:24,714] [INFO] [utils.py:782:see_memory_usage] MA 0.12 GB         Max_MA 0.12 GB         CA 0.15 GB         Max_CA 0 GB 
 0: [2025-06-27 21:03:24,714] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 105.77 GB, percent = 12.4%
 0: [2025-06-27 21:03:24,919] [INFO] [utils.py:781:see_memory_usage] Before creating fp32 partitions
 0: [2025-06-27 21:03:24,920] [INFO] [utils.py:782:see_memory_usage] MA 0.12 GB         Max_MA 0.12 GB         CA 0.15 GB         Max_CA 0 GB 
 0: [2025-06-27 21:03:24,920] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 105.77 GB, percent = 12.4%
 0: [2025-06-27 21:03:25,129] [INFO] [utils.py:781:see_memory_usage] After creating fp32 partitions
 0: [2025-06-27 21:03:25,130] [INFO] [utils.py:782:see_memory_usage] MA 0.36 GB         Max_MA 0.48 GB         CA 0.5 GB         Max_CA 1 GB 
 0: [2025-06-27 21:03:25,130] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 106.12 GB, percent = 12.4%
 0: [2025-06-27 21:03:25,337] [INFO] [utils.py:781:see_memory_usage] Before initializing optimizer states
 0: [2025-06-27 21:03:25,337] [INFO] [utils.py:782:see_memory_usage] MA 0.36 GB         Max_MA 0.36 GB         CA 0.5 GB         Max_CA 1 GB 
 0: [2025-06-27 21:03:25,338] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 106.89 GB, percent = 12.5%
 0: [2025-06-27 21:03:25,548] [INFO] [utils.py:781:see_memory_usage] After initializing optimizer states
 0: [2025-06-27 21:03:25,548] [INFO] [utils.py:782:see_memory_usage] MA 0.36 GB         Max_MA 0.6 GB         CA 0.76 GB         Max_CA 1 GB 
 0: [2025-06-27 21:03:25,549] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 107.15 GB, percent = 12.5%
 0: [2025-06-27 21:03:25,549] [INFO] [stage3.py:534:_setup_for_real_optimizer] optimizer state initialized
27: [INFO|trainer.py:2414] 2025-06-27 21:03:27,709 >> ***** Running training *****
27: [INFO|trainer.py:2415] 2025-06-27 21:03:27,709 >>   Num examples = 1,126,096
27: [INFO|trainer.py:2416] 2025-06-27 21:03:27,709 >>   Num Epochs = 1
27: [INFO|trainer.py:2417] 2025-06-27 21:03:27,709 >>   Instantaneous batch size per device = 1
27: [INFO|trainer.py:2420] 2025-06-27 21:03:27,709 >>   Total train batch size (w. parallel, distributed & accumulation) = 256
10: [INFO|trainer.py:2414] 2025-06-27 21:03:27,709 >> ***** Running training *****
10: [INFO|trainer.py:2415] 2025-06-27 21:03:27,709 >>   Num examples = 1,126,096
27: [INFO|trainer.py:2421] 2025-06-27 21:03:27,709 >>   Gradient Accumulation steps = 2
10: [INFO|trainer.py:2416] 2025-06-27 21:03:27,709 >>   Num Epochs = 1
 2: [INFO|trainer.py:2414] 2025-06-27 21:03:27,709 >> ***** Running training *****
 1: [INFO|trainer.py:2414] 2025-06-27 21:03:27,709 >> ***** Running training *****
 4: [INFO|trainer.py:2414] 2025-06-27 21:03:27,709 >> ***** Running training *****
27: [INFO|trainer.py:2422] 2025-06-27 21:03:27,709 >>   Total optimization steps = 4,399
11: [INFO|trainer.py:2414] 2025-06-27 21:03:27,709 >> ***** Running training *****
10: [INFO|trainer.py:2417] 2025-06-27 21:03:27,709 >>   Instantaneous batch size per device = 1
 2: [INFO|trainer.py:2415] 2025-06-27 21:03:27,709 >>   Num examples = 1,126,096
 1: [INFO|trainer.py:2415] 2025-06-27 21:03:27,709 >>   Num examples = 1,126,096
 4: [INFO|trainer.py:2415] 2025-06-27 21:03:27,709 >>   Num examples = 1,126,096
10: [INFO|trainer.py:2420] 2025-06-27 21:03:27,709 >>   Total train batch size (w. parallel, distributed & accumulation) = 256
 2: [INFO|trainer.py:2416] 2025-06-27 21:03:27,709 >>   Num Epochs = 1
 1: [INFO|trainer.py:2416] 2025-06-27 21:03:27,709 >>   Num Epochs = 1
 4: [INFO|trainer.py:2416] 2025-06-27 21:03:27,709 >>   Num Epochs = 1
11: [INFO|trainer.py:2415] 2025-06-27 21:03:27,709 >>   Num examples = 1,126,096
10: [INFO|trainer.py:2421] 2025-06-27 21:03:27,709 >>   Gradient Accumulation steps = 2
 2: [INFO|trainer.py:2417] 2025-06-27 21:03:27,709 >>   Instantaneous batch size per device = 1
 1: [INFO|trainer.py:2417] 2025-06-27 21:03:27,709 >>   Instantaneous batch size per device = 1
 4: [INFO|trainer.py:2417] 2025-06-27 21:03:27,709 >>   Instantaneous batch size per device = 1
14: [INFO|trainer.py:2414] 2025-06-27 21:03:27,709 >> ***** Running training *****
11: [INFO|trainer.py:2416] 2025-06-27 21:03:27,709 >>   Num Epochs = 1
10: [INFO|trainer.py:2422] 2025-06-27 21:03:27,709 >>   Total optimization steps = 4,399
 1: [INFO|trainer.py:2420] 2025-06-27 21:03:27,709 >>   Total train batch size (w. parallel, distributed & accumulation) = 256
 4: [INFO|trainer.py:2420] 2025-06-27 21:03:27,709 >>   Total train batch size (w. parallel, distributed & accumulation) = 256
 1: [INFO|trainer.py:2421] 2025-06-27 21:03:27,709 >>   Gradient Accumulation steps = 2
 1: [INFO|trainer.py:2422] 2025-06-27 21:03:27,709 >>   Total optimization steps = 4,399
 4: [INFO|trainer.py:2421] 2025-06-27 21:03:27,709 >>   Gradient Accumulation steps = 2
28: [INFO|trainer.py:2414] 2025-06-27 21:03:27,709 >> ***** Running training *****
 4: [INFO|trainer.py:2422] 2025-06-27 21:03:27,709 >>   Total optimization steps = 4,399
13: [INFO|trainer.py:2414] 2025-06-27 21:03:27,709 >> ***** Running training *****
28: [INFO|trainer.py:2415] 2025-06-27 21:03:27,709 >>   Num examples = 1,126,096
31: [INFO|trainer.py:2414] 2025-06-27 21:03:27,709 >> ***** Running training *****
 2: [INFO|trainer.py:2420] 2025-06-27 21:03:27,709 >>   Total train batch size (w. parallel, distributed & accumulation) = 256
13: [INFO|trainer.py:2415] 2025-06-27 21:03:27,709 >>   Num examples = 1,126,096
28: [INFO|trainer.py:2416] 2025-06-27 21:03:27,709 >>   Num Epochs = 1
31: [INFO|trainer.py:2415] 2025-06-27 21:03:27,709 >>   Num examples = 1,126,096
31: [INFO|trainer.py:2416] 2025-06-27 21:03:27,709 >>   Num Epochs = 1
 2: [INFO|trainer.py:2421] 2025-06-27 21:03:27,709 >>   Gradient Accumulation steps = 2
13: [INFO|trainer.py:2416] 2025-06-27 21:03:27,709 >>   Num Epochs = 1
14: [INFO|trainer.py:2415] 2025-06-27 21:03:27,709 >>   Num examples = 1,126,096
14: [INFO|trainer.py:2416] 2025-06-27 21:03:27,709 >>   Num Epochs = 1
11: [INFO|trainer.py:2417] 2025-06-27 21:03:27,709 >>   Instantaneous batch size per device = 1
 2: [INFO|trainer.py:2422] 2025-06-27 21:03:27,709 >>   Total optimization steps = 4,399
 3: [INFO|trainer.py:2414] 2025-06-27 21:03:27,709 >> ***** Running training *****
13: [INFO|trainer.py:2417] 2025-06-27 21:03:27,709 >>   Instantaneous batch size per device = 1
14: [INFO|trainer.py:2417] 2025-06-27 21:03:27,709 >>   Instantaneous batch size per device = 1
14: [INFO|trainer.py:2420] 2025-06-27 21:03:27,709 >>   Total train batch size (w. parallel, distributed & accumulation) = 256
11: [INFO|trainer.py:2420] 2025-06-27 21:03:27,709 >>   Total train batch size (w. parallel, distributed & accumulation) = 256
 3: [INFO|trainer.py:2415] 2025-06-27 21:03:27,709 >>   Num examples = 1,126,096
28: [INFO|trainer.py:2417] 2025-06-27 21:03:27,709 >>   Instantaneous batch size per device = 1
14: [INFO|trainer.py:2421] 2025-06-27 21:03:27,709 >>   Gradient Accumulation steps = 2
11: [INFO|trainer.py:2421] 2025-06-27 21:03:27,709 >>   Gradient Accumulation steps = 2
28: [INFO|trainer.py:2420] 2025-06-27 21:03:27,709 >>   Total train batch size (w. parallel, distributed & accumulation) = 256
14: [INFO|trainer.py:2422] 2025-06-27 21:03:27,709 >>   Total optimization steps = 4,399
11: [INFO|trainer.py:2422] 2025-06-27 21:03:27,709 >>   Total optimization steps = 4,399
31: [INFO|trainer.py:2417] 2025-06-27 21:03:27,709 >>   Instantaneous batch size per device = 1
13: [INFO|trainer.py:2420] 2025-06-27 21:03:27,709 >>   Total train batch size (w. parallel, distributed & accumulation) = 256
28: [INFO|trainer.py:2421] 2025-06-27 21:03:27,709 >>   Gradient Accumulation steps = 2
31: [INFO|trainer.py:2420] 2025-06-27 21:03:27,709 >>   Total train batch size (w. parallel, distributed & accumulation) = 256
13: [INFO|trainer.py:2421] 2025-06-27 21:03:27,709 >>   Gradient Accumulation steps = 2
26: [INFO|trainer.py:2414] 2025-06-27 21:03:27,709 >> ***** Running training *****
28: [INFO|trainer.py:2422] 2025-06-27 21:03:27,709 >>   Total optimization steps = 4,399
31: [INFO|trainer.py:2421] 2025-06-27 21:03:27,709 >>   Gradient Accumulation steps = 2
13: [INFO|trainer.py:2422] 2025-06-27 21:03:27,709 >>   Total optimization steps = 4,399
18: [INFO|trainer.py:2414] 2025-06-27 21:03:27,709 >> ***** Running training *****
26: [INFO|trainer.py:2415] 2025-06-27 21:03:27,709 >>   Num examples = 1,126,096
31: [INFO|trainer.py:2422] 2025-06-27 21:03:27,709 >>   Total optimization steps = 4,399
 3: [INFO|trainer.py:2416] 2025-06-27 21:03:27,709 >>   Num Epochs = 1
18: [INFO|trainer.py:2415] 2025-06-27 21:03:27,709 >>   Num examples = 1,126,096
18: [INFO|trainer.py:2416] 2025-06-27 21:03:27,709 >>   Num Epochs = 1
26: [INFO|trainer.py:2416] 2025-06-27 21:03:27,709 >>   Num Epochs = 1
26: [INFO|trainer.py:2417] 2025-06-27 21:03:27,709 >>   Instantaneous batch size per device = 1
 3: [INFO|trainer.py:2417] 2025-06-27 21:03:27,709 >>   Instantaneous batch size per device = 1
18: [INFO|trainer.py:2417] 2025-06-27 21:03:27,709 >>   Instantaneous batch size per device = 1
26: [INFO|trainer.py:2420] 2025-06-27 21:03:27,709 >>   Total train batch size (w. parallel, distributed & accumulation) = 256
 3: [INFO|trainer.py:2420] 2025-06-27 21:03:27,709 >>   Total train batch size (w. parallel, distributed & accumulation) = 256
 3: [INFO|trainer.py:2421] 2025-06-27 21:03:27,709 >>   Gradient Accumulation steps = 2
26: [INFO|trainer.py:2421] 2025-06-27 21:03:27,709 >>   Gradient Accumulation steps = 2
 6: [INFO|trainer.py:2414] 2025-06-27 21:03:27,709 >> ***** Running training *****
 3: [INFO|trainer.py:2422] 2025-06-27 21:03:27,709 >>   Total optimization steps = 4,399
26: [INFO|trainer.py:2422] 2025-06-27 21:03:27,709 >>   Total optimization steps = 4,399
 6: [INFO|trainer.py:2415] 2025-06-27 21:03:27,709 >>   Num examples = 1,126,096
 6: [INFO|trainer.py:2416] 2025-06-27 21:03:27,709 >>   Num Epochs = 1
18: [INFO|trainer.py:2420] 2025-06-27 21:03:27,709 >>   Total train batch size (w. parallel, distributed & accumulation) = 256
 6: [INFO|trainer.py:2417] 2025-06-27 21:03:27,709 >>   Instantaneous batch size per device = 1
18: [INFO|trainer.py:2421] 2025-06-27 21:03:27,709 >>   Gradient Accumulation steps = 2
 8: [INFO|trainer.py:2414] 2025-06-27 21:03:27,709 >> ***** Running training *****
 6: [INFO|trainer.py:2420] 2025-06-27 21:03:27,709 >>   Total train batch size (w. parallel, distributed & accumulation) = 256
18: [INFO|trainer.py:2422] 2025-06-27 21:03:27,709 >>   Total optimization steps = 4,399
25: [INFO|trainer.py:2414] 2025-06-27 21:03:27,709 >> ***** Running training *****
 8: [INFO|trainer.py:2415] 2025-06-27 21:03:27,709 >>   Num examples = 1,126,096
 6: [INFO|trainer.py:2421] 2025-06-27 21:03:27,709 >>   Gradient Accumulation steps = 2
25: [INFO|trainer.py:2415] 2025-06-27 21:03:27,710 >>   Num examples = 1,126,096
25: [INFO|trainer.py:2416] 2025-06-27 21:03:27,710 >>   Num Epochs = 1
 6: [INFO|trainer.py:2422] 2025-06-27 21:03:27,709 >>   Total optimization steps = 4,399
25: [INFO|trainer.py:2417] 2025-06-27 21:03:27,710 >>   Instantaneous batch size per device = 1
 8: [INFO|trainer.py:2416] 2025-06-27 21:03:27,710 >>   Num Epochs = 1
25: [INFO|trainer.py:2420] 2025-06-27 21:03:27,710 >>   Total train batch size (w. parallel, distributed & accumulation) = 256
 8: [INFO|trainer.py:2417] 2025-06-27 21:03:27,710 >>   Instantaneous batch size per device = 1
25: [INFO|trainer.py:2421] 2025-06-27 21:03:27,710 >>   Gradient Accumulation steps = 2
21: [INFO|trainer.py:2414] 2025-06-27 21:03:27,709 >> ***** Running training *****
25: [INFO|trainer.py:2422] 2025-06-27 21:03:27,710 >>   Total optimization steps = 4,399
21: [INFO|trainer.py:2415] 2025-06-27 21:03:27,710 >>   Num examples = 1,126,096
 9: [INFO|trainer.py:2414] 2025-06-27 21:03:27,709 >> ***** Running training *****
19: [INFO|trainer.py:2414] 2025-06-27 21:03:27,709 >> ***** Running training *****
 8: [INFO|trainer.py:2420] 2025-06-27 21:03:27,710 >>   Total train batch size (w. parallel, distributed & accumulation) = 256
 9: [INFO|trainer.py:2415] 2025-06-27 21:03:27,710 >>   Num examples = 1,126,096
30: [INFO|trainer.py:2414] 2025-06-27 21:03:27,709 >> ***** Running training *****
 8: [INFO|trainer.py:2421] 2025-06-27 21:03:27,710 >>   Gradient Accumulation steps = 2
21: [INFO|trainer.py:2416] 2025-06-27 21:03:27,710 >>   Num Epochs = 1
30: [INFO|trainer.py:2415] 2025-06-27 21:03:27,710 >>   Num examples = 1,126,096
30: [INFO|trainer.py:2416] 2025-06-27 21:03:27,710 >>   Num Epochs = 1
 8: [INFO|trainer.py:2422] 2025-06-27 21:03:27,710 >>   Total optimization steps = 4,399
24: [INFO|trainer.py:2414] 2025-06-27 21:03:27,710 >> ***** Running training *****
 9: [INFO|trainer.py:2416] 2025-06-27 21:03:27,710 >>   Num Epochs = 1
21: [INFO|trainer.py:2417] 2025-06-27 21:03:27,710 >>   Instantaneous batch size per device = 1
21: [INFO|trainer.py:2420] 2025-06-27 21:03:27,710 >>   Total train batch size (w. parallel, distributed & accumulation) = 256
21: [INFO|trainer.py:2421] 2025-06-27 21:03:27,710 >>   Gradient Accumulation steps = 2
30: [INFO|trainer.py:2417] 2025-06-27 21:03:27,710 >>   Instantaneous batch size per device = 1
30: [INFO|trainer.py:2420] 2025-06-27 21:03:27,710 >>   Total train batch size (w. parallel, distributed & accumulation) = 256
30: [INFO|trainer.py:2421] 2025-06-27 21:03:27,710 >>   Gradient Accumulation steps = 2
24: [INFO|trainer.py:2415] 2025-06-27 21:03:27,710 >>   Num examples = 1,126,096
 9: [INFO|trainer.py:2417] 2025-06-27 21:03:27,710 >>   Instantaneous batch size per device = 1
19: [INFO|trainer.py:2415] 2025-06-27 21:03:27,710 >>   Num examples = 1,126,096
30: [INFO|trainer.py:2422] 2025-06-27 21:03:27,710 >>   Total optimization steps = 4,399
19: [INFO|trainer.py:2416] 2025-06-27 21:03:27,710 >>   Num Epochs = 1
 9: [INFO|trainer.py:2420] 2025-06-27 21:03:27,710 >>   Total train batch size (w. parallel, distributed & accumulation) = 256
 9: [INFO|trainer.py:2421] 2025-06-27 21:03:27,710 >>   Gradient Accumulation steps = 2
19: [INFO|trainer.py:2417] 2025-06-27 21:03:27,710 >>   Instantaneous batch size per device = 1
21: [INFO|trainer.py:2422] 2025-06-27 21:03:27,710 >>   Total optimization steps = 4,399
 9: [INFO|trainer.py:2422] 2025-06-27 21:03:27,710 >>   Total optimization steps = 4,399
16: [INFO|trainer.py:2414] 2025-06-27 21:03:27,710 >> ***** Running training *****
 5: [INFO|trainer.py:2414] 2025-06-27 21:03:27,710 >> ***** Running training *****
19: [INFO|trainer.py:2420] 2025-06-27 21:03:27,710 >>   Total train batch size (w. parallel, distributed & accumulation) = 256
16: [INFO|trainer.py:2415] 2025-06-27 21:03:27,710 >>   Num examples = 1,126,096
29: [INFO|trainer.py:2414] 2025-06-27 21:03:27,710 >> ***** Running training *****
24: [INFO|trainer.py:2416] 2025-06-27 21:03:27,710 >>   Num Epochs = 1
16: [INFO|trainer.py:2416] 2025-06-27 21:03:27,710 >>   Num Epochs = 1
19: [INFO|trainer.py:2421] 2025-06-27 21:03:27,710 >>   Gradient Accumulation steps = 2
24: [INFO|trainer.py:2417] 2025-06-27 21:03:27,710 >>   Instantaneous batch size per device = 1
16: [INFO|trainer.py:2417] 2025-06-27 21:03:27,710 >>   Instantaneous batch size per device = 1
 5: [INFO|trainer.py:2415] 2025-06-27 21:03:27,710 >>   Num examples = 1,126,096
19: [INFO|trainer.py:2422] 2025-06-27 21:03:27,710 >>   Total optimization steps = 4,399
24: [INFO|trainer.py:2420] 2025-06-27 21:03:27,710 >>   Total train batch size (w. parallel, distributed & accumulation) = 256
24: [INFO|trainer.py:2421] 2025-06-27 21:03:27,710 >>   Gradient Accumulation steps = 2
24: [INFO|trainer.py:2422] 2025-06-27 21:03:27,710 >>   Total optimization steps = 4,399
16: [INFO|trainer.py:2420] 2025-06-27 21:03:27,710 >>   Total train batch size (w. parallel, distributed & accumulation) = 256
 5: [INFO|trainer.py:2416] 2025-06-27 21:03:27,710 >>   Num Epochs = 1
29: [INFO|trainer.py:2415] 2025-06-27 21:03:27,710 >>   Num examples = 1,126,096
29: [INFO|trainer.py:2416] 2025-06-27 21:03:27,710 >>   Num Epochs = 1
16: [INFO|trainer.py:2421] 2025-06-27 21:03:27,710 >>   Gradient Accumulation steps = 2
16: [INFO|trainer.py:2422] 2025-06-27 21:03:27,710 >>   Total optimization steps = 4,399
 5: [INFO|trainer.py:2417] 2025-06-27 21:03:27,710 >>   Instantaneous batch size per device = 1
29: [INFO|trainer.py:2417] 2025-06-27 21:03:27,710 >>   Instantaneous batch size per device = 1
17: [INFO|trainer.py:2414] 2025-06-27 21:03:27,710 >> ***** Running training *****
29: [INFO|trainer.py:2420] 2025-06-27 21:03:27,710 >>   Total train batch size (w. parallel, distributed & accumulation) = 256
 5: [INFO|trainer.py:2420] 2025-06-27 21:03:27,710 >>   Total train batch size (w. parallel, distributed & accumulation) = 256
 5: [INFO|trainer.py:2421] 2025-06-27 21:03:27,710 >>   Gradient Accumulation steps = 2
29: [INFO|trainer.py:2421] 2025-06-27 21:03:27,710 >>   Gradient Accumulation steps = 2
 5: [INFO|trainer.py:2422] 2025-06-27 21:03:27,710 >>   Total optimization steps = 4,399
29: [INFO|trainer.py:2422] 2025-06-27 21:03:27,710 >>   Total optimization steps = 4,399
22: [INFO|trainer.py:2414] 2025-06-27 21:03:27,710 >> ***** Running training *****
17: [INFO|trainer.py:2415] 2025-06-27 21:03:27,710 >>   Num examples = 1,126,096
22: [INFO|trainer.py:2415] 2025-06-27 21:03:27,710 >>   Num examples = 1,126,096
15: [INFO|trainer.py:2414] 2025-06-27 21:03:27,710 >> ***** Running training *****
17: [INFO|trainer.py:2416] 2025-06-27 21:03:27,710 >>   Num Epochs = 1
17: [INFO|trainer.py:2417] 2025-06-27 21:03:27,710 >>   Instantaneous batch size per device = 1
12: [INFO|trainer.py:2414] 2025-06-27 21:03:27,710 >> ***** Running training *****
12: [INFO|trainer.py:2415] 2025-06-27 21:03:27,710 >>   Num examples = 1,126,096
12: [INFO|trainer.py:2416] 2025-06-27 21:03:27,710 >>   Num Epochs = 1
17: [INFO|trainer.py:2420] 2025-06-27 21:03:27,710 >>   Total train batch size (w. parallel, distributed & accumulation) = 256
12: [INFO|trainer.py:2417] 2025-06-27 21:03:27,710 >>   Instantaneous batch size per device = 1
17: [INFO|trainer.py:2421] 2025-06-27 21:03:27,710 >>   Gradient Accumulation steps = 2
15: [INFO|trainer.py:2415] 2025-06-27 21:03:27,710 >>   Num examples = 1,126,096
17: [INFO|trainer.py:2422] 2025-06-27 21:03:27,710 >>   Total optimization steps = 4,399
15: [INFO|trainer.py:2416] 2025-06-27 21:03:27,710 >>   Num Epochs = 1
 7: [INFO|trainer.py:2414] 2025-06-27 21:03:27,710 >> ***** Running training *****
22: [INFO|trainer.py:2416] 2025-06-27 21:03:27,710 >>   Num Epochs = 1
12: [INFO|trainer.py:2420] 2025-06-27 21:03:27,710 >>   Total train batch size (w. parallel, distributed & accumulation) = 256
22: [INFO|trainer.py:2417] 2025-06-27 21:03:27,710 >>   Instantaneous batch size per device = 1
12: [INFO|trainer.py:2421] 2025-06-27 21:03:27,710 >>   Gradient Accumulation steps = 2
15: [INFO|trainer.py:2417] 2025-06-27 21:03:27,710 >>   Instantaneous batch size per device = 1
15: [INFO|trainer.py:2420] 2025-06-27 21:03:27,710 >>   Total train batch size (w. parallel, distributed & accumulation) = 256
20: [INFO|trainer.py:2414] 2025-06-27 21:03:27,710 >> ***** Running training *****
22: [INFO|trainer.py:2420] 2025-06-27 21:03:27,710 >>   Total train batch size (w. parallel, distributed & accumulation) = 256
22: [INFO|trainer.py:2421] 2025-06-27 21:03:27,710 >>   Gradient Accumulation steps = 2
22: [INFO|trainer.py:2422] 2025-06-27 21:03:27,710 >>   Total optimization steps = 4,399
12: [INFO|trainer.py:2422] 2025-06-27 21:03:27,710 >>   Total optimization steps = 4,399
 7: [INFO|trainer.py:2415] 2025-06-27 21:03:27,710 >>   Num examples = 1,126,096
20: [INFO|trainer.py:2415] 2025-06-27 21:03:27,710 >>   Num examples = 1,126,096
15: [INFO|trainer.py:2421] 2025-06-27 21:03:27,710 >>   Gradient Accumulation steps = 2
 7: [INFO|trainer.py:2416] 2025-06-27 21:03:27,710 >>   Num Epochs = 1
20: [INFO|trainer.py:2416] 2025-06-27 21:03:27,710 >>   Num Epochs = 1
20: [INFO|trainer.py:2417] 2025-06-27 21:03:27,710 >>   Instantaneous batch size per device = 1
15: [INFO|trainer.py:2422] 2025-06-27 21:03:27,710 >>   Total optimization steps = 4,399
 7: [INFO|trainer.py:2417] 2025-06-27 21:03:27,710 >>   Instantaneous batch size per device = 1
 7: [INFO|trainer.py:2420] 2025-06-27 21:03:27,710 >>   Total train batch size (w. parallel, distributed & accumulation) = 256
20: [INFO|trainer.py:2420] 2025-06-27 21:03:27,710 >>   Total train batch size (w. parallel, distributed & accumulation) = 256
20: [INFO|trainer.py:2421] 2025-06-27 21:03:27,710 >>   Gradient Accumulation steps = 2
 7: [INFO|trainer.py:2421] 2025-06-27 21:03:27,710 >>   Gradient Accumulation steps = 2
 7: [INFO|trainer.py:2422] 2025-06-27 21:03:27,710 >>   Total optimization steps = 4,399
23: [INFO|trainer.py:2414] 2025-06-27 21:03:27,710 >> ***** Running training *****
20: [INFO|trainer.py:2422] 2025-06-27 21:03:27,710 >>   Total optimization steps = 4,399
23: [INFO|trainer.py:2415] 2025-06-27 21:03:27,710 >>   Num examples = 1,126,096
23: [INFO|trainer.py:2416] 2025-06-27 21:03:27,710 >>   Num Epochs = 1
23: [INFO|trainer.py:2417] 2025-06-27 21:03:27,710 >>   Instantaneous batch size per device = 1
23: [INFO|trainer.py:2420] 2025-06-27 21:03:27,710 >>   Total train batch size (w. parallel, distributed & accumulation) = 256
23: [INFO|trainer.py:2421] 2025-06-27 21:03:27,710 >>   Gradient Accumulation steps = 2
23: [INFO|trainer.py:2422] 2025-06-27 21:03:27,710 >>   Total optimization steps = 4,399
27: [INFO|trainer.py:2423] 2025-06-27 21:03:27,710 >>   Number of trainable parameters = 8,292,166,656
10: [INFO|trainer.py:2423] 2025-06-27 21:03:27,710 >>   Number of trainable parameters = 8,292,166,656
 2: [INFO|trainer.py:2423] 2025-06-27 21:03:27,710 >>   Number of trainable parameters = 8,292,166,656
 1: [INFO|trainer.py:2423] 2025-06-27 21:03:27,710 >>   Number of trainable parameters = 8,292,166,656
 4: [INFO|trainer.py:2423] 2025-06-27 21:03:27,710 >>   Number of trainable parameters = 8,292,166,656
14: [INFO|trainer.py:2423] 2025-06-27 21:03:27,710 >>   Number of trainable parameters = 8,292,166,656
11: [INFO|trainer.py:2423] 2025-06-27 21:03:27,710 >>   Number of trainable parameters = 8,292,166,656
28: [INFO|trainer.py:2423] 2025-06-27 21:03:27,711 >>   Number of trainable parameters = 8,292,166,656
31: [INFO|trainer.py:2423] 2025-06-27 21:03:27,711 >>   Number of trainable parameters = 8,292,166,656
26: [INFO|trainer.py:2423] 2025-06-27 21:03:27,711 >>   Number of trainable parameters = 8,292,166,656
13: [INFO|trainer.py:2423] 2025-06-27 21:03:27,711 >>   Number of trainable parameters = 8,292,166,656
 3: [INFO|trainer.py:2423] 2025-06-27 21:03:27,711 >>   Number of trainable parameters = 8,292,166,656
18: [INFO|trainer.py:2423] 2025-06-27 21:03:27,711 >>   Number of trainable parameters = 8,292,166,656
 6: [INFO|trainer.py:2423] 2025-06-27 21:03:27,711 >>   Number of trainable parameters = 8,292,166,656
25: [INFO|trainer.py:2423] 2025-06-27 21:03:27,711 >>   Number of trainable parameters = 8,292,166,656
30: [INFO|trainer.py:2423] 2025-06-27 21:03:27,711 >>   Number of trainable parameters = 8,292,166,656
21: [INFO|trainer.py:2423] 2025-06-27 21:03:27,711 >>   Number of trainable parameters = 8,292,166,656
24: [INFO|trainer.py:2423] 2025-06-27 21:03:27,711 >>   Number of trainable parameters = 8,292,166,656
 9: [INFO|trainer.py:2423] 2025-06-27 21:03:27,711 >>   Number of trainable parameters = 8,292,166,656
19: [INFO|trainer.py:2423] 2025-06-27 21:03:27,711 >>   Number of trainable parameters = 8,292,166,656
16: [INFO|trainer.py:2423] 2025-06-27 21:03:27,711 >>   Number of trainable parameters = 8,292,166,656
29: [INFO|trainer.py:2423] 2025-06-27 21:03:27,711 >>   Number of trainable parameters = 8,292,166,656
 8: [INFO|trainer.py:2423] 2025-06-27 21:03:27,711 >>   Number of trainable parameters = 8,292,166,656
 5: [INFO|trainer.py:2423] 2025-06-27 21:03:27,711 >>   Number of trainable parameters = 8,292,166,656
17: [INFO|trainer.py:2423] 2025-06-27 21:03:27,711 >>   Number of trainable parameters = 8,292,166,656
12: [INFO|trainer.py:2423] 2025-06-27 21:03:27,711 >>   Number of trainable parameters = 8,292,166,656
22: [INFO|trainer.py:2423] 2025-06-27 21:03:27,711 >>   Number of trainable parameters = 8,292,166,656
15: [INFO|trainer.py:2423] 2025-06-27 21:03:27,711 >>   Number of trainable parameters = 8,292,166,656
 7: [INFO|trainer.py:2423] 2025-06-27 21:03:27,711 >>   Number of trainable parameters = 8,292,166,656
20: [INFO|trainer.py:2423] 2025-06-27 21:03:27,711 >>   Number of trainable parameters = 8,292,166,656
23: [INFO|trainer.py:2423] 2025-06-27 21:03:27,712 >>   Number of trainable parameters = 8,292,166,656
 0: [2025-06-27 21:03:27,934] [INFO] [utils.py:781:see_memory_usage] After initializing ZeRO optimizer
 0: [2025-06-27 21:03:27,934] [INFO] [utils.py:782:see_memory_usage] MA 0.51 GB         Max_MA 2.54 GB         CA 2.65 GB         Max_CA 3 GB 
 0: [2025-06-27 21:03:27,935] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 116.46 GB, percent = 13.6%
 0: [2025-06-27 21:03:27,935] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedZeroOptimizer_Stage3
 0: [2025-06-27 21:03:27,935] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed using configured LR scheduler = None
 0: [2025-06-27 21:03:27,935] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
 0: [2025-06-27 21:03:27,935] [INFO] [logging.py:107:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0, 0.0], mom=[(0.9, 0.999), (0.9, 0.999)]
 0: [2025-06-27 21:03:27,937] [INFO] [config.py:1003:print] DeepSpeedEngine configuration:
 0: [2025-06-27 21:03:27,937] [INFO] [config.py:1007:print]   activation_checkpointing_config  {
 0:     "partition_activations": false, 
 0:     "contiguous_memory_optimization": false, 
 0:     "cpu_checkpointing": false, 
 0:     "number_checkpoints": null, 
 0:     "synchronize_checkpoint_boundary": false, 
 0:     "profile": false
 0: }
 0: [2025-06-27 21:03:27,937] [INFO] [config.py:1007:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'intra_op_parallelism': 1, 'single_submit': False, 'overlap_events': True, 'use_gds': False}
 0: [2025-06-27 21:03:27,937] [INFO] [config.py:1007:print]   amp_enabled .................. False
 0: [2025-06-27 21:03:27,937] [INFO] [config.py:1007:print]   amp_params ................... False
 0: [2025-06-27 21:03:27,937] [INFO] [config.py:1007:print]   autotuning_config ............ {
 0:     "enabled": false, 
 0:     "start_step": null, 
 0:     "end_step": null, 
 0:     "metric_path": null, 
 0:     "arg_mappings": null, 
 0:     "metric": "throughput", 
 0:     "model_info": null, 
 0:     "results_dir": "autotuning_results", 
 0:     "exps_dir": "autotuning_exps", 
 0:     "overwrite": true, 
 0:     "fast": true, 
 0:     "start_profile_step": 3, 
 0:     "end_profile_step": 5, 
 0:     "tuner_type": "gridsearch", 
 0:     "tuner_early_stopping": 5, 
 0:     "tuner_num_trials": 50, 
 0:     "model_info_path": null, 
 0:     "mp_size": 1, 
 0:     "max_train_batch_size": null, 
 0:     "min_train_batch_size": 1, 
 0:     "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
 0:     "min_train_micro_batch_size_per_gpu": 1, 
 0:     "num_tuning_micro_batch_sizes": 3
 0: }
 0: [2025-06-27 21:03:27,937] [INFO] [config.py:1007:print]   bfloat16_enabled ............. True
 0: [2025-06-27 21:03:27,937] [INFO] [config.py:1007:print]   bfloat16_immediate_grad_update  True
 0: [2025-06-27 21:03:27,938] [INFO] [config.py:1007:print]   checkpoint_parallel_write_pipeline  False
 0: [2025-06-27 21:03:27,938] [INFO] [config.py:1007:print]   checkpoint_tag_validation_enabled  True
 0: [2025-06-27 21:03:27,938] [INFO] [config.py:1007:print]   checkpoint_tag_validation_fail  False
 0: [2025-06-27 21:03:27,938] [INFO] [config.py:1007:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x40037eddcc40>
 0: [2025-06-27 21:03:27,938] [INFO] [config.py:1007:print]   communication_data_type ...... None
 0: [2025-06-27 21:03:27,938] [INFO] [config.py:1007:print]   compile_config ............... deepcompile=False free_activation=False offload_activation=False offload_opt_states=False double_buffer=True symmetric_memory=False debug_log=False offload_parameters=False sync_before_reduce=False sync_after_reduce=False sync_before_allgather=False sync_after_allgather=False
 0: [2025-06-27 21:03:27,938] [INFO] [config.py:1007:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_pa
 0: rameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
 0: [2025-06-27 21:03:27,938] [INFO] [config.py:1007:print]   curriculum_enabled_legacy .... False
 0: [2025-06-27 21:03:27,938] [INFO] [config.py:1007:print]   curriculum_params_legacy ..... False
 0: [2025-06-27 21:03:27,938] [INFO] [config.py:1007:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'pin_memory': False, 'curriculum_learning': {'enabled': False}, 'dynamic_batching': {'enabled': False, 'lr_scaling_method': 'linear', 'min_batch_size': 1, 'max_batch_size': None, 'sequence_picking_order': 'dataloader', 'verbose': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
 0: [2025-06-27 21:03:27,938] [INFO] [config.py:1007:print]   data_efficiency_enabled ...... False
 0: [2025-06-27 21:03:27,938] [INFO] [config.py:1007:print]   dataloader_drop_last ......... False
 0: [2025-06-27 21:03:27,938] [INFO] [config.py:1007:print]   disable_allgather ............ False
 0: [2025-06-27 21:03:27,938] [INFO] [config.py:1007:print]   dump_state ................... False
 0: [2025-06-27 21:03:27,938] [INFO] [config.py:1007:print]   dynamic_loss_scale_args ...... None
 0: [2025-06-27 21:03:27,938] [INFO] [config.py:1007:print]   eigenvalue_enabled ........... False
 0: [2025-06-27 21:03:27,938] [INFO] [config.py:1007:print]   eigenvalue_gas_boundary_resolution  1
 0: [2025-06-27 21:03:27,938] [INFO] [config.py:1007:print]   eigenvalue_layer_name ........ bert.encoder.layer
 0: [2025-06-27 21:03:27,938] [INFO] [config.py:1007:print]   eigenvalue_layer_num ......... 0
 0: [2025-06-27 21:03:27,938] [INFO] [config.py:1007:print]   eigenvalue_max_iter .......... 100
 0: [2025-06-27 21:03:27,938] [INFO] [config.py:1007:print]   eigenvalue_stability ......... 1e-06
 0: [2025-06-27 21:03:27,938] [INFO] [config.py:1007:print]   eigenvalue_tol ............... 0.01
 0: [2025-06-27 21:03:27,938] [INFO] [config.py:1007:print]   eigenvalue_verbose ........... False
 0: [2025-06-27 21:03:27,938] [INFO] [config.py:1007:print]   elasticity_enabled ........... False
 0: [2025-06-27 21:03:27,938] [INFO] [config.py:1007:print]   flops_profiler_config ........ {
 0:     "enabled": false, 
 0:     "recompute_fwd_factor": 0.0, 
 0:     "profile_step": 1, 
 0:     "module_depth": -1, 
 0:     "top_modules": 1, 
 0:     "detailed": true, 
 0:     "output_file": null
 0: }
 0: [2025-06-27 21:03:27,938] [INFO] [config.py:1007:print]   fp16_auto_cast ............... None
 0: [2025-06-27 21:03:27,938] [INFO] [config.py:1007:print]   fp16_enabled ................. False
 0: [2025-06-27 21:03:27,938] [INFO] [config.py:1007:print]   fp16_master_weights_and_gradients  False
 0: [2025-06-27 21:03:27,938] [INFO] [config.py:1007:print]   global_rank .................. 0
 0: [2025-06-27 21:03:27,938] [INFO] [config.py:1007:print]   grad_accum_dtype ............. None
 0: [2025-06-27 21:03:27,938] [INFO] [config.py:1007:print]   gradient_accumulation_steps .. 2
 0: [2025-06-27 21:03:27,938] [INFO] [config.py:1007:print]   gradient_clipping ............ 1.0
 0: [2025-06-27 21:03:27,938] [INFO] [config.py:1007:print]   gradient_predivide_factor .... 1.0
 0: [2025-06-27 21:03:27,938] [INFO] [config.py:1007:print]   graph_harvesting ............. False
 0: [2025-06-27 21:03:27,938] [INFO] [config.py:1007:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
 0: [2025-06-27 21:03:27,939] [INFO] [config.py:1007:print]   initial_dynamic_scale ........ 1
 0: [2025-06-27 21:03:27,939] [INFO] [config.py:1007:print]   load_universal_checkpoint .... False
 0: [2025-06-27 21:03:27,939] [INFO] [config.py:1007:print]   loss_scale ................... 1.0
 0: [2025-06-27 21:03:27,939] [INFO] [config.py:1007:print]   memory_breakdown ............. False
 0: [2025-06-27 21:03:27,939] [INFO] [config.py:1007:print]   mics_hierarchial_params_gather  False
 0: [2025-06-27 21:03:27,939] [INFO] [config.py:1007:print]   mics_shard_size .............. -1
 0: [2025-06-27 21:03:27,939] [INFO] [config.py:1007:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName')
 0: [2025-06-27 21:03:27,939] [INFO] [config.py:1007:print]   nebula_config ................ {
 0:     "enabled": false, 
 0:     "persistent_storage_path": null, 
 0:     "persistent_time_interval": 100, 
 0:     "num_of_version_in_retention": 2, 
 0:     "enable_nebula_load": true, 
 0:     "load_path": null
 0: }
 0: [2025-06-27 21:03:27,939] [INFO] [config.py:1007:print]   optimizer_legacy_fusion ...... False
 0: [2025-06-27 21:03:27,939] [INFO] [config.py:1007:print]   optimizer_name ............... None
 0: [2025-06-27 21:03:27,939] [INFO] [config.py:1007:print]   optimizer_params ............. None
 0: [2025-06-27 21:03:27,939] [INFO] [config.py:1007:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
 0: [2025-06-27 21:03:27,939] [INFO] [config.py:1007:print]   pld_enabled .................. False
 0: [2025-06-27 21:03:27,939] [INFO] [config.py:1007:print]   pld_params ................... False
 0: [2025-06-27 21:03:27,939] [INFO] [config.py:1007:print]   prescale_gradients ........... False
 0: [2025-06-27 21:03:27,939] [INFO] [config.py:1007:print]   scheduler_name ............... None
 0: [2025-06-27 21:03:27,939] [INFO] [config.py:1007:print]   scheduler_params ............. None
 0: [2025-06-27 21:03:27,939] [INFO] [config.py:1007:print]   seq_parallel_communication_data_type  torch.float32
 0: [2025-06-27 21:03:27,939] [INFO] [config.py:1007:print]   sparse_attention ............. None
 0: [2025-06-27 21:03:27,939] [INFO] [config.py:1007:print]   sparse_gradients_enabled ..... False
 0: [2025-06-27 21:03:27,939] [INFO] [config.py:1007:print]   steps_per_print .............. inf
 0: [2025-06-27 21:03:27,939] [INFO] [config.py:1007:print]   tensor_parallel_config ....... dtype=torch.float16 autotp_size=0 tp_overlap_comm=False tensor_parallel=TPConfig(tp_size=1, tp_grain_size=1, mpu=None, tp_group=None) injection_policy_tuple=None keep_module_on_host=False replace_with_kernel_inject=False
 0: [2025-06-27 21:03:27,939] [INFO] [config.py:1007:print]   timers_config ................ enabled=True synchronized=True
 0: [2025-06-27 21:03:27,939] [INFO] [config.py:1007:print]   train_batch_size ............. 256
 0: [2025-06-27 21:03:27,939] [INFO] [config.py:1007:print]   train_micro_batch_size_per_gpu  1
 0: [2025-06-27 21:03:27,939] [INFO] [config.py:1007:print]   use_data_before_expert_parallel_  False
 0: [2025-06-27 21:03:27,939] [INFO] [config.py:1007:print]   use_node_local_storage ....... False
 0: [2025-06-27 21:03:27,939] [INFO] [config.py:1007:print]   wall_clock_breakdown ......... False
 0: [2025-06-27 21:03:27,939] [INFO] [config.py:1007:print]   weight_quantization_config ... None
 0: [2025-06-27 21:03:27,939] [INFO] [config.py:1007:print]   world_size ................... 128
 0: [2025-06-27 21:03:27,939] [INFO] [config.py:1007:print]   zero_allow_untested_optimizer  True
 0: [2025-06-27 21:03:27,939] [INFO] [config.py:1007:print]   zero_config .................. stage=3 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=12845056 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=11560550 param_persistence_threshold=35840 model_persistence_threshold=9223372036854775807 max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=True module_granularity_threshold=0 use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False zeropp_loco
 0: _param=None mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True log_trace_cache_warnings=False
 0: [2025-06-27 21:03:27,940] [INFO] [config.py:1007:print]   zero_enabled ................. True
 0: [2025-06-27 21:03:27,940] [INFO] [config.py:1007:print]   zero_force_ds_cpu_optimizer .. True
 0: [2025-06-27 21:03:27,940] [INFO] [config.py:1007:print]   zero_optimization_stage ...... 3
 0: [2025-06-27 21:03:27,940] [INFO] [config.py:993:print_user_config]   json = {
 0:     "train_batch_size": 256, 
 0:     "train_micro_batch_size_per_gpu": 1, 
 0:     "gradient_accumulation_steps": 2, 
 0:     "gradient_clipping": 1.0, 
 0:     "zero_allow_untested_optimizer": true, 
 0:     "fp16": {
 0:         "enabled": false, 
 0:         "loss_scale": 0, 
 0:         "loss_scale_window": 1000, 
 0:         "initial_scale_power": 16, 
 0:         "hysteresis": 2, 
 0:         "min_loss_scale": 1
 0:     }, 
 0:     "bf16": {
 0:         "enabled": true
 0:     }, 
 0:     "zero_optimization": {
 0:         "stage": 3, 
 0:         "overlap_comm": false, 
 0:         "contiguous_gradients": true, 
 0:         "sub_group_size": 1.000000e+09, 
 0:         "reduce_bucket_size": 1.284506e+07, 
 0:         "stage3_prefetch_bucket_size": 1.156055e+07, 
 0:         "stage3_param_persistence_threshold": 3.584000e+04, 
 0:         "stage3_max_live_parameters": 1.000000e+09, 
 0:         "stage3_max_reuse_distance": 1.000000e+09, 
 0:         "stage3_gather_16bit_weights_on_model_save": true
 0:     }, 
 0:     "steps_per_print": inf
 0: }
 0: [INFO|trainer.py:2414] 2025-06-27 21:03:27,941 >> ***** Running training *****
 0: [INFO|trainer.py:2415] 2025-06-27 21:03:27,941 >>   Num examples = 1,126,096
 0: [INFO|trainer.py:2416] 2025-06-27 21:03:27,942 >>   Num Epochs = 1
 0: [INFO|trainer.py:2417] 2025-06-27 21:03:27,942 >>   Instantaneous batch size per device = 1
 0: [INFO|trainer.py:2420] 2025-06-27 21:03:27,942 >>   Total train batch size (w. parallel, distributed & accumulation) = 256
 0: [INFO|trainer.py:2421] 2025-06-27 21:03:27,942 >>   Gradient Accumulation steps = 2
 0: [INFO|trainer.py:2422] 2025-06-27 21:03:27,942 >>   Total optimization steps = 4,399
 0: [INFO|trainer.py:2423] 2025-06-27 21:03:27,943 >>   Number of trainable parameters = 8,292,166,656
 0: [INFO|integration_utils.py:831] 2025-06-27 21:03:27,945 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
 0: wandb: WARNING The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.
 0: wandb: Currently logged in as: nicolas-deperrois (krauthammerlab) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
 0: wandb: Tracking run with wandb version 0.20.1
 0: wandb: Run data is saved locally in /capstor/scratch/cscs/ndeperr/code/LLaMA-Factory/wandb/run-20250627_210328-heonkcdn
 0: wandb: Run `wandb offline` to turn off syncing.
 0: wandb: Syncing run /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/
 0: wandb: ⭐️ View project at https://wandb.ai/krauthammerlab/llamafactory
 0: wandb: 🚀 View run at https://wandb.ai/krauthammerlab/llamafactory/runs/heonkcdn
15: nid005601:210679:220215 [3] NCCL INFO Using network AWS Libfabric
15: nid005601:210678:220212 [2] NCCL INFO Using network AWS Libfabric
15: nid005601:210677:220213 [1] NCCL INFO Using network AWS Libfabric
15: nid005601:210676:220214 [0] NCCL INFO Using network AWS Libfabric
22: nid005915:274817:284251 [3] NCCL INFO Using network AWS Libfabric
22: nid005915:274816:284254 [2] NCCL INFO Using network AWS Libfabric
16: nid005802:6299:15922 [2] NCCL INFO Using network AWS Libfabric
15: nid005601:210679:220215 [3] NCCL INFO DMA-BUF is available on GPU device 3
15: nid005601:210678:220212 [2] NCCL INFO DMA-BUF is available on GPU device 2
15: nid005601:210677:220213 [1] NCCL INFO DMA-BUF is available on GPU device 1
15: nid005601:210676:220214 [0] NCCL INFO DMA-BUF is available on GPU device 0
13: nid005595:197886:207693 [3] NCCL INFO Using network AWS Libfabric
13: nid005595:197884:207691 [1] NCCL INFO Using network AWS Libfabric
13: nid005595:197883:207694 [0] NCCL INFO Using network AWS Libfabric
13: nid005595:197885:207692 [2] NCCL INFO Using network AWS Libfabric
14: nid005600:217723:227284 [3] NCCL INFO Using network AWS Libfabric
14: nid005600:217720:227285 [0] NCCL INFO Using network AWS Libfabric
14: nid005600:217721:227286 [1] NCCL INFO Using network AWS Libfabric
 6: nid005584:28288:37690 [3] NCCL INFO Using network AWS Libfabric
22: nid005915:274817:284251 [3] NCCL INFO DMA-BUF is available on GPU device 3
 9: nid005588:35938:45404 [3] NCCL INFO Using network AWS Libfabric
 9: nid005588:35936:45406 [1] NCCL INFO Using network AWS Libfabric
 9: nid005588:35937:45405 [2] NCCL INFO Using network AWS Libfabric
16: nid005802:6299:15922 [2] NCCL INFO DMA-BUF is available on GPU device 2
17: nid005803:180733:190220 [1] NCCL INFO Using network AWS Libfabric
 7: nid005585:122008:131402 [3] NCCL INFO Using network AWS Libfabric
13: nid005595:197886:207693 [3] NCCL INFO DMA-BUF is available on GPU device 3
13: nid005595:197883:207694 [0] NCCL INFO DMA-BUF is available on GPU device 0
13: nid005595:197884:207691 [1] NCCL INFO DMA-BUF is available on GPU device 1
13: nid005595:197885:207692 [2] NCCL INFO DMA-BUF is available on GPU device 2
20: nid005913:292682:9578 [1] NCCL INFO Using network AWS Libfabric
18: nid005911:38867:48329 [3] NCCL INFO Using network AWS Libfabric
19: nid005912:12436:21867 [1] NCCL INFO Using network AWS Libfabric
19: nid005912:12438:21868 [3] NCCL INFO Using network AWS Libfabric
21: nid005914:166784:176212 [0] NCCL INFO Using network AWS Libfabric
14: nid005600:217722:227283 [2] NCCL INFO Using network AWS Libfabric
14: nid005600:217723:227284 [3] NCCL INFO DMA-BUF is available on GPU device 3
14: nid005600:217721:227286 [1] NCCL INFO DMA-BUF is available on GPU device 1
 6: nid005584:28288:37690 [3] NCCL INFO DMA-BUF is available on GPU device 3
11: nid005591:191606:202312 [3] NCCL INFO Using network AWS Libfabric
22: nid005915:274816:284254 [2] NCCL INFO DMA-BUF is available on GPU device 2
12: nid005594:53088:62557 [3] NCCL INFO Using network AWS Libfabric
12: nid005594:53086:62556 [1] NCCL INFO Using network AWS Libfabric
12: nid005594:53085:62558 [0] NCCL INFO Using network AWS Libfabric
12: nid005594:53087:62559 [2] NCCL INFO Using network AWS Libfabric
 9: nid005588:35935:45407 [0] NCCL INFO Using network AWS Libfabric
 9: nid005588:35938:45404 [3] NCCL INFO DMA-BUF is available on GPU device 3
 9: nid005588:35937:45405 [2] NCCL INFO DMA-BUF is available on GPU device 2
 9: nid005588:35936:45406 [1] NCCL INFO DMA-BUF is available on GPU device 1
16: nid005802:6297:15923 [0] NCCL INFO Using network AWS Libfabric
17: nid005803:180735:190221 [3] NCCL INFO Using network AWS Libfabric
17: nid005803:180732:190218 [0] NCCL INFO Using network AWS Libfabric
17: nid005803:180734:190219 [2] NCCL INFO Using network AWS Libfabric
17: nid005803:180733:190220 [1] NCCL INFO DMA-BUF is available on GPU device 1
 7: nid005585:122007:131403 [2] NCCL INFO Using network AWS Libfabric
20: nid005913:292681:9580 [0] NCCL INFO Using network AWS Libfabric
20: nid005913:292682:9578 [1] NCCL INFO DMA-BUF is available on GPU device 1
18: nid005911:38866:48328 [2] NCCL INFO Using network AWS Libfabric
18: nid005911:38864:48326 [0] NCCL INFO Using network AWS Libfabric
18: nid005911:38867:48329 [3] NCCL INFO DMA-BUF is available on GPU device 3
21: nid005914:166785:176214 [1] NCCL INFO Using network AWS Libfabric
21: nid005914:166784:176212 [0] NCCL INFO DMA-BUF is available on GPU device 0
 8: nid005586:68927:78410 [1] NCCL INFO Using network AWS Libfabric
14: nid005600:217720:227285 [0] NCCL INFO DMA-BUF is available on GPU device 0
14: nid005600:217722:227283 [2] NCCL INFO DMA-BUF is available on GPU device 2
 6: nid005584:28287:37693 [2] NCCL INFO Using network AWS Libfabric
11: nid005591:191606:202312 [3] NCCL INFO DMA-BUF is available on GPU device 3
22: nid005915:274814:284253 [0] NCCL INFO Using network AWS Libfabric
22: nid005915:274815:284252 [1] NCCL INFO Using network AWS Libfabric
 0: nid005574:69059:78862 [1] NCCL INFO Using network AWS Libfabric
12: nid005594:53085:62558 [0] NCCL INFO DMA-BUF is available on GPU device 0
12: nid005594:53086:62556 [1] NCCL INFO DMA-BUF is available on GPU device 1
12: nid005594:53087:62559 [2] NCCL INFO DMA-BUF is available on GPU device 2
12: nid005594:53088:62557 [3] NCCL INFO DMA-BUF is available on GPU device 3
 1: nid005576:147558:156960 [1] NCCL INFO Using network AWS Libfabric
 1: nid005576:147559:156961 [2] NCCL INFO Using network AWS Libfabric
 1: nid005576:147557:156962 [0] NCCL INFO Using network AWS Libfabric
 1: nid005576:147560:156959 [3] NCCL INFO Using network AWS Libfabric
 4: nid005581:264525:273956 [2] NCCL INFO Using network AWS Libfabric
 4: nid005581:264523:273959 [0] NCCL INFO Using network AWS Libfabric
 9: nid005588:35935:45407 [0] NCCL INFO DMA-BUF is available on GPU device 0
16: nid005802:6298:15921 [1] NCCL INFO Using network AWS Libfabric
17: nid005803:180735:190221 [3] NCCL INFO DMA-BUF is available on GPU device 3
 7: nid005585:122005:131405 [0] NCCL INFO Using network AWS Libfabric
 7: nid005585:122008:131402 [3] NCCL INFO DMA-BUF is available on GPU device 3
 7: nid005585:122006:131404 [1] NCCL INFO Using network AWS Libfabric
18: nid005911:38865:48327 [1] NCCL INFO Using network AWS Libfabric
19: nid005912:12435:21865 [0] NCCL INFO Using network AWS Libfabric
19: nid005912:12437:21866 [2] NCCL INFO Using network AWS Libfabric
19: nid005912:12438:21868 [3] NCCL INFO DMA-BUF is available on GPU device 3
19: nid005912:12436:21867 [1] NCCL INFO DMA-BUF is available on GPU device 1
21: nid005914:166787:176211 [3] NCCL INFO Using network AWS Libfabric
21: nid005914:166786:176213 [2] NCCL INFO Using network AWS Libfabric
25: nid005919:107465:116955 [3] NCCL INFO Using network AWS Libfabric
23: nid005917:276887:286344 [2] NCCL INFO Using network AWS Libfabric
23: nid005917:276885:286342 [0] NCCL INFO Using network AWS Libfabric
23: nid005917:276886:286341 [1] NCCL INFO Using network AWS Libfabric
23: nid005917:276888:286343 [3] NCCL INFO Using network AWS Libfabric
 8: nid005586:68928:78413 [2] NCCL INFO Using network AWS Libfabric
 8: nid005586:68926:78412 [0] NCCL INFO Using network AWS Libfabric
 8: nid005586:68927:78410 [1] NCCL INFO DMA-BUF is available on GPU device 1
 8: nid005586:68929:78411 [3] NCCL INFO Using network AWS Libfabric
 6: nid005584:28285:37691 [0] NCCL INFO Using network AWS Libfabric
 6: nid005584:28286:37692 [1] NCCL INFO Using network AWS Libfabric
11: nid005591:191605:202311 [2] NCCL INFO Using network AWS Libfabric
11: nid005591:191603:202313 [0] NCCL INFO Using network AWS Libfabric
22: nid005915:274815:284252 [1] NCCL INFO DMA-BUF is available on GPU device 1
22: nid005915:274814:284253 [0] NCCL INFO DMA-BUF is available on GPU device 0
 0: nid005574:69060:78861 [2] NCCL INFO Using network AWS Libfabric
 0: nid005574:69061:78860 [3] NCCL INFO Using network AWS Libfabric
 0: nid005574:69058:78859 [0] NCCL INFO Using network AWS Libfabric
 0: nid005574:69059:78862 [1] NCCL INFO DMA-BUF is available on GPU device 1
 1: nid005576:147558:156960 [1] NCCL INFO DMA-BUF is available on GPU device 1
 1: nid005576:147557:156962 [0] NCCL INFO DMA-BUF is available on GPU device 0
 1: nid005576:147559:156961 [2] NCCL INFO DMA-BUF is available on GPU device 2
 4: nid005581:264526:273958 [3] NCCL INFO Using network AWS Libfabric
 4: nid005581:264524:273957 [1] NCCL INFO Using network AWS Libfabric
 4: nid005581:264525:273956 [2] NCCL INFO DMA-BUF is available on GPU device 2
 4: nid005581:264523:273959 [0] NCCL INFO DMA-BUF is available on GPU device 0
16: nid005802:6300:15924 [3] NCCL INFO Using network AWS Libfabric
17: nid005803:180734:190219 [2] NCCL INFO DMA-BUF is available on GPU device 2
17: nid005803:180732:190218 [0] NCCL INFO DMA-BUF is available on GPU device 0
 7: nid005585:122007:131403 [2] NCCL INFO DMA-BUF is available on GPU device 2
20: nid005913:292684:9581 [3] NCCL INFO Using network AWS Libfabric
20: nid005913:292683:9579 [2] NCCL INFO Using network AWS Libfabric
18: nid005911:38866:48328 [2] NCCL INFO DMA-BUF is available on GPU device 2
18: nid005911:38864:48326 [0] NCCL INFO DMA-BUF is available on GPU device 0
19: nid005912:12437:21866 [2] NCCL INFO DMA-BUF is available on GPU device 2
21: nid005914:166785:176214 [1] NCCL INFO DMA-BUF is available on GPU device 1
21: nid005914:166787:176211 [3] NCCL INFO DMA-BUF is available on GPU device 3
21: nid005914:166786:176213 [2] NCCL INFO DMA-BUF is available on GPU device 2
25: nid005919:107462:116957 [0] NCCL INFO Using network AWS Libfabric
25: nid005919:107465:116955 [3] NCCL INFO DMA-BUF is available on GPU device 3
23: nid005917:276887:286344 [2] NCCL INFO DMA-BUF is available on GPU device 2
23: nid005917:276886:286341 [1] NCCL INFO DMA-BUF is available on GPU device 1
23: nid005917:276888:286343 [3] NCCL INFO DMA-BUF is available on GPU device 3
23: nid005917:276885:286342 [0] NCCL INFO DMA-BUF is available on GPU device 0
30: nid005936:49909:59369 [1] NCCL INFO Using network AWS Libfabric
30: nid005936:49910:59367 [2] NCCL INFO Using network AWS Libfabric
30: nid005936:49908:59370 [0] NCCL INFO Using network AWS Libfabric
30: nid005936:49911:59368 [3] NCCL INFO Using network AWS Libfabric
 8: nid005586:68926:78412 [0] NCCL INFO DMA-BUF is available on GPU device 0
 6: nid005584:28285:37691 [0] NCCL INFO DMA-BUF is available on GPU device 0
11: nid005591:191604:202310 [1] NCCL INFO Using network AWS Libfabric
29: nid005932:167681:177111 [1] NCCL INFO Using network AWS Libfabric
24: nid005918:92506:101973 [2] NCCL INFO Using network AWS Libfabric
24: nid005918:92507:101970 [3] NCCL INFO Using network AWS Libfabric
24: nid005918:92504:101971 [0] NCCL INFO Using network AWS Libfabric
24: nid005918:92505:101972 [1] NCCL INFO Using network AWS Libfabric
 0: nid005574:69060:78861 [2] NCCL INFO DMA-BUF is available on GPU device 2
 0: nid005574:69058:78859 [0] NCCL INFO DMA-BUF is available on GPU device 0
 0: nid005574:69061:78860 [3] NCCL INFO DMA-BUF is available on GPU device 3
10: nid005590:110710:120118 [0] NCCL INFO Using network AWS Libfabric
10: nid005590:110711:120117 [1] NCCL INFO Using network AWS Libfabric
10: nid005590:110713:120120 [3] NCCL INFO Using network AWS Libfabric
10: nid005590:110712:120119 [2] NCCL INFO Using network AWS Libfabric
 2: nid005577:17424:26951 [2] NCCL INFO Using network AWS Libfabric
 2: nid005577:17425:26950 [3] NCCL INFO Using network AWS Libfabric
 2: nid005577:17423:26949 [1] NCCL INFO Using network AWS Libfabric
 2: nid005577:17422:26952 [0] NCCL INFO Using network AWS Libfabric
 1: nid005576:147560:156959 [3] NCCL INFO DMA-BUF is available on GPU device 3
 4: nid005581:264526:273958 [3] NCCL INFO DMA-BUF is available on GPU device 3
 4: nid005581:264524:273957 [1] NCCL INFO DMA-BUF is available on GPU device 1
16: nid005802:6297:15923 [0] NCCL INFO DMA-BUF is available on GPU device 0
16: nid005802:6298:15921 [1] NCCL INFO DMA-BUF is available on GPU device 1
 7: nid005585:122005:131405 [0] NCCL INFO DMA-BUF is available on GPU device 0
 7: nid005585:122006:131404 [1] NCCL INFO DMA-BUF is available on GPU device 1
 5: nid005582:196715:206689 [2] NCCL INFO Using network AWS Libfabric
20: nid005913:292684:9581 [3] NCCL INFO DMA-BUF is available on GPU device 3
20: nid005913:292681:9580 [0] NCCL INFO DMA-BUF is available on GPU device 0
18: nid005911:38865:48327 [1] NCCL INFO DMA-BUF is available on GPU device 1
19: nid005912:12435:21865 [0] NCCL INFO DMA-BUF is available on GPU device 0
26: nid005920:67125:76589 [2] NCCL INFO Using network AWS Libfabric
26: nid005920:67123:76588 [0] NCCL INFO Using network AWS Libfabric
25: nid005919:107462:116957 [0] NCCL INFO DMA-BUF is available on GPU device 0
25: nid005919:107464:116954 [2] NCCL INFO Using network AWS Libfabric
25: nid005919:107463:116956 [1] NCCL INFO Using network AWS Libfabric
27: nid005922:80744:90167 [3] NCCL INFO Using network AWS Libfabric
 8: nid005586:68928:78413 [2] NCCL INFO DMA-BUF is available on GPU device 2
 8: nid005586:68929:78411 [3] NCCL INFO DMA-BUF is available on GPU device 3
 6: nid005584:28287:37693 [2] NCCL INFO DMA-BUF is available on GPU device 2
 6: nid005584:28286:37692 [1] NCCL INFO DMA-BUF is available on GPU device 1
11: nid005591:191605:202311 [2] NCCL INFO DMA-BUF is available on GPU device 2
11: nid005591:191603:202313 [0] NCCL INFO DMA-BUF is available on GPU device 0
29: nid005932:167681:177111 [1] NCCL INFO DMA-BUF is available on GPU device 1
29: nid005932:167683:177110 [3] NCCL INFO Using network AWS Libfabric
29: nid005932:167682:177113 [2] NCCL INFO Using network AWS Libfabric
29: nid005932:167680:177112 [0] NCCL INFO Using network AWS Libfabric
24: nid005918:92506:101973 [2] NCCL INFO DMA-BUF is available on GPU device 2
24: nid005918:92507:101970 [3] NCCL INFO DMA-BUF is available on GPU device 3
10: nid005590:110710:120118 [0] NCCL INFO DMA-BUF is available on GPU device 0
10: nid005590:110713:120120 [3] NCCL INFO DMA-BUF is available on GPU device 3
 2: nid005577:17425:26950 [3] NCCL INFO DMA-BUF is available on GPU device 3
 2: nid005577:17424:26951 [2] NCCL INFO DMA-BUF is available on GPU device 2
 2: nid005577:17423:26949 [1] NCCL INFO DMA-BUF is available on GPU device 1
 2: nid005577:17422:26952 [0] NCCL INFO DMA-BUF is available on GPU device 0
16: nid005802:6300:15924 [3] NCCL INFO DMA-BUF is available on GPU device 3
 3: nid005580:71822:81295 [3] NCCL INFO Using network AWS Libfabric
 3: nid005580:71821:81296 [2] NCCL INFO Using network AWS Libfabric
 3: nid005580:71820:81294 [1] NCCL INFO Using network AWS Libfabric
 3: nid005580:71819:81293 [0] NCCL INFO Using network AWS Libfabric
 5: nid005582:196714:206691 [1] NCCL INFO Using network AWS Libfabric
 5: nid005582:196715:206689 [2] NCCL INFO DMA-BUF is available on GPU device 2
 5: nid005582:196716:206688 [3] NCCL INFO Using network AWS Libfabric
20: nid005913:292683:9579 [2] NCCL INFO DMA-BUF is available on GPU device 2
26: nid005920:67123:76588 [0] NCCL INFO DMA-BUF is available on GPU device 0
26: nid005920:67125:76589 [2] NCCL INFO DMA-BUF is available on GPU device 2
26: nid005920:67126:76590 [3] NCCL INFO Using network AWS Libfabric
26: nid005920:67124:76591 [1] NCCL INFO Using network AWS Libfabric
25: nid005919:107463:116956 [1] NCCL INFO DMA-BUF is available on GPU device 1
25: nid005919:107464:116954 [2] NCCL INFO DMA-BUF is available on GPU device 2
27: nid005922:80744:90167 [3] NCCL INFO DMA-BUF is available on GPU device 3
27: nid005922:80741:90164 [0] NCCL INFO Using network AWS Libfabric
27: nid005922:80742:90165 [1] NCCL INFO Using network AWS Libfabric
27: nid005922:80743:90166 [2] NCCL INFO Using network AWS Libfabric
28: nid005929:16033:25498 [3] NCCL INFO Using network AWS Libfabric
28: nid005929:16030:25495 [0] NCCL INFO Using network AWS Libfabric
28: nid005929:16031:25497 [1] NCCL INFO Using network AWS Libfabric
28: nid005929:16032:25496 [2] NCCL INFO Using network AWS Libfabric
11: nid005591:191604:202310 [1] NCCL INFO DMA-BUF is available on GPU device 1
31: nid005937:256592:266031 [3] NCCL INFO Using network AWS Libfabric
31: nid005937:256589:266029 [0] NCCL INFO Using network AWS Libfabric
31: nid005937:256590:266030 [1] NCCL INFO Using network AWS Libfabric
31: nid005937:256591:266028 [2] NCCL INFO Using network AWS Libfabric
24: nid005918:92504:101971 [0] NCCL INFO DMA-BUF is available on GPU device 0
24: nid005918:92505:101972 [1] NCCL INFO DMA-BUF is available on GPU device 1
10: nid005590:110711:120117 [1] NCCL INFO DMA-BUF is available on GPU device 1
10: nid005590:110712:120119 [2] NCCL INFO DMA-BUF is available on GPU device 2
 3: nid005580:71822:81295 [3] NCCL INFO DMA-BUF is available on GPU device 3
 3: nid005580:71820:81294 [1] NCCL INFO DMA-BUF is available on GPU device 1
 3: nid005580:71819:81293 [0] NCCL INFO DMA-BUF is available on GPU device 0
 3: nid005580:71821:81296 [2] NCCL INFO DMA-BUF is available on GPU device 2
 5: nid005582:196713:206690 [0] NCCL INFO Using network AWS Libfabric
 5: nid005582:196714:206691 [1] NCCL INFO DMA-BUF is available on GPU device 1
26: nid005920:67124:76591 [1] NCCL INFO DMA-BUF is available on GPU device 1
26: nid005920:67126:76590 [3] NCCL INFO DMA-BUF is available on GPU device 3
30: nid005936:49910:59367 [2] NCCL INFO DMA-BUF is available on GPU device 2
30: nid005936:49909:59369 [1] NCCL INFO DMA-BUF is available on GPU device 1
27: nid005922:80741:90164 [0] NCCL INFO DMA-BUF is available on GPU device 0
28: nid005929:16033:25498 [3] NCCL INFO DMA-BUF is available on GPU device 3
28: nid005929:16030:25495 [0] NCCL INFO DMA-BUF is available on GPU device 0
28: nid005929:16031:25497 [1] NCCL INFO DMA-BUF is available on GPU device 1
31: nid005937:256589:266029 [0] NCCL INFO DMA-BUF is available on GPU device 0
31: nid005937:256592:266031 [3] NCCL INFO DMA-BUF is available on GPU device 3
31: nid005937:256591:266028 [2] NCCL INFO DMA-BUF is available on GPU device 2
31: nid005937:256590:266030 [1] NCCL INFO DMA-BUF is available on GPU device 1
29: nid005932:167682:177113 [2] NCCL INFO DMA-BUF is available on GPU device 2
 5: nid005582:196716:206688 [3] NCCL INFO DMA-BUF is available on GPU device 3
 5: nid005582:196713:206690 [0] NCCL INFO DMA-BUF is available on GPU device 0
30: nid005936:49911:59368 [3] NCCL INFO DMA-BUF is available on GPU device 3
30: nid005936:49908:59370 [0] NCCL INFO DMA-BUF is available on GPU device 0
27: nid005922:80743:90166 [2] NCCL INFO DMA-BUF is available on GPU device 2
27: nid005922:80742:90165 [1] NCCL INFO DMA-BUF is available on GPU device 1
28: nid005929:16032:25496 [2] NCCL INFO DMA-BUF is available on GPU device 2
29: nid005932:167683:177110 [3] NCCL INFO DMA-BUF is available on GPU device 3
29: nid005932:167680:177112 [0] NCCL INFO DMA-BUF is available on GPU device 0
15: nid005601:210679:220215 [3] NCCL INFO bootstrapSplit: comm 0x4006ad64fdf0 parent 0xaaab0b2c3130 rank 63 nranks 128 color 315732477 key 63 prev 62 next 64 - DONE
15: nid005601:210678:220212 [2] NCCL INFO bootstrapSplit: comm 0x40068d6528c0 parent 0xaaab22984300 rank 62 nranks 128 color 315732477 key 62 prev 61 next 63 - DONE
15: nid005601:210679:220215 [3] NCCL INFO ncclCommSplit comm 0x4006ad64fdf0 rank 63 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 parent 0xaaab0b2c3130 color 315732477 key 63 commId 0xf264858106496629 - Init START
15: nid005601:210678:220212 [2] NCCL INFO ncclCommSplit comm 0x40068d6528c0 rank 62 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 parent 0xaaab22984300 color 315732477 key 62 commId 0xf264858106496629 - Init START
15: nid005601:210677:220213 [1] NCCL INFO bootstrapSplit: comm 0x40068d64fdf0 parent 0xaaaaee59b4c0 rank 61 nranks 128 color 315732477 key 61 prev 60 next 62 - DONE
17: nid005803:180734:190219 [2] NCCL INFO bootstrapSplit: comm 0x40068564fe00 parent 0xaaab0a6d9870 rank 70 nranks 128 color 315732477 key 70 prev 69 next 71 - DONE
17: nid005803:180735:190221 [3] NCCL INFO bootstrapSplit: comm 0x4006896513a0 parent 0xaaab10aa06b0 rank 71 nranks 128 color 315732477 key 71 prev 70 next 72 - DONE
17: nid005803:180732:190218 [0] NCCL INFO bootstrapSplit: comm 0x400681651260 parent 0xaaaad12a2680 rank 68 nranks 128 color 315732477 key 68 prev 67 next 69 - DONE
17: nid005803:180733:190220 [1] NCCL INFO bootstrapSplit: comm 0x40069164fa60 parent 0xaaab1f57afc0 rank 69 nranks 128 color 315732477 key 69 prev 68 next 70 - DONE
17: nid005803:180734:190219 [2] NCCL INFO ncclCommSplit comm 0x40068564fe00 rank 70 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 parent 0xaaab0a6d9870 color 315732477 key 70 commId 0xf264858106496629 - Init START
 9: nid005588:35937:45405 [2] NCCL INFO bootstrapSplit: comm 0x40068d64fe00 parent 0xaaaae8a0c3a0 rank 38 nranks 128 color 315732477 key 38 prev 37 next 39 - DONE
 9: nid005588:35938:45404 [3] NCCL INFO bootstrapSplit: comm 0x40069164fe00 parent 0xaaaadbd50910 rank 39 nranks 128 color 315732477 key 39 prev 38 next 40 - DONE
 9: nid005588:35937:45405 [2] NCCL INFO ncclCommSplit comm 0x40068d64fe00 rank 38 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 parent 0xaaaae8a0c3a0 color 315732477 key 38 commId 0xf264858106496629 - Init START
 9: nid005588:35938:45404 [3] NCCL INFO ncclCommSplit comm 0x40069164fe00 rank 39 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 parent 0xaaaadbd50910 color 315732477 key 39 commId 0xf264858106496629 - Init START
15: nid005601:210677:220213 [1] NCCL INFO ncclCommSplit comm 0x40068d64fdf0 rank 61 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 parent 0xaaaaee59b4c0 color 315732477 key 61 commId 0xf264858106496629 - Init START
13: nid005595:197885:207692 [2] NCCL INFO bootstrapSplit: comm 0x4006a96528c0 parent 0xaaab3c8b15f0 rank 54 nranks 128 color 315732477 key 54 prev 53 next 55 - DONE
13: nid005595:197885:207692 [2] NCCL INFO ncclCommSplit comm 0x4006a96528c0 rank 54 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 parent 0xaaab3c8b15f0 color 315732477 key 54 commId 0xf264858106496629 - Init START
18: nid005911:38864:48326 [0] NCCL INFO bootstrapSplit: comm 0x40068964fdf0 parent 0xaaaade95adc0 rank 72 nranks 128 color 315732477 key 72 prev 71 next 73 - DONE
18: nid005911:38864:48326 [0] NCCL INFO ncclCommSplit comm 0x40068964fdf0 rank 72 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 parent 0xaaaade95adc0 color 315732477 key 72 commId 0xf264858106496629 - Init START
 1: nid005576:147559:156961 [2] NCCL INFO bootstrapSplit: comm 0x40069d652920 parent 0xaaab1c4d2400 rank 6 nranks 128 color 315732477 key 6 prev 5 next 7 - DONE
 1: nid005576:147559:156961 [2] NCCL INFO ncclCommSplit comm 0x40069d652920 rank 6 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 parent 0xaaab1c4d2400 color 315732477 key 6 commId 0xf264858106496629 - Init START
 1: nid005576:147558:156960 [1] NCCL INFO bootstrapSplit: comm 0x40069964fd70 parent 0xaaaaf8e03070 rank 5 nranks 128 color 315732477 key 5 prev 4 next 6 - DONE
 9: nid005588:35936:45406 [1] NCCL INFO bootstrapSplit: comm 0x400698a89620 parent 0xaaab298ab220 rank 37 nranks 128 color 315732477 key 37 prev 36 next 38 - DONE
 9: nid005588:35936:45406 [1] NCCL INFO ncclCommSplit comm 0x400698a89620 rank 37 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 parent 0xaaab298ab220 color 315732477 key 37 commId 0xf264858106496629 - Init START
 9: nid005588:35935:45407 [0] NCCL INFO bootstrapSplit: comm 0x40065964fd80 parent 0xaaab148fdb70 rank 36 nranks 128 color 315732477 key 36 prev 35 next 37 - DONE
16: nid005802:6299:15922 [2] NCCL INFO bootstrapSplit: comm 0x4006ad650f90 parent 0xaaab08f00a50 rank 66 nranks 128 color 315732477 key 66 prev 65 next 67 - DONE
16: nid005802:6298:15921 [1] NCCL INFO bootstrapSplit: comm 0x40069964e900 parent 0xaaab06e0b4f0 rank 65 nranks 128 color 315732477 key 65 prev 64 next 66 - DONE
16: nid005802:6297:15923 [0] NCCL INFO bootstrapSplit: comm 0x400669651260 parent 0xaaab18b83d10 rank 64 nranks 128 color 315732477 key 64 prev 63 next 65 - DONE
16: nid005802:6299:15922 [2] NCCL INFO ncclCommSplit comm 0x4006ad650f90 rank 66 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 parent 0xaaab08f00a50 color 315732477 key 66 commId 0xf264858106496629 - Init START
16: nid005802:6298:15921 [1] NCCL INFO ncclCommSplit comm 0x40069964e900 rank 65 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 parent 0xaaab06e0b4f0 color 315732477 key 65 commId 0xf264858106496629 - Init START
15: nid005601:210676:220214 [0] NCCL INFO bootstrapSplit: comm 0x40068164fe00 parent 0xaaab05fd2fb0 rank 60 nranks 128 color 315732477 key 60 prev 59 next 61 - DONE
 7: nid005585:122008:131402 [3] NCCL INFO bootstrapSplit: comm 0x4006956513a0 parent 0xaaaaedf73db0 rank 31 nranks 128 color 315732477 key 31 prev 30 next 32 - DONE
 7: nid005585:122007:131403 [2] NCCL INFO bootstrapSplit: comm 0x4006b564fe00 parent 0xaaaadd869ba0 rank 30 nranks 128 color 315732477 key 30 prev 29 next 31 - DONE
 7: nid005585:122008:131402 [3] NCCL INFO ncclCommSplit comm 0x4006956513a0 rank 31 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 parent 0xaaaaedf73db0 color 315732477 key 31 commId 0xf264858106496629 - Init START
 7: nid005585:122007:131403 [2] NCCL INFO ncclCommSplit comm 0x4006b564fe00 rank 30 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 parent 0xaaaadd869ba0 color 315732477 key 30 commId 0xf264858106496629 - Init START
 7: nid005585:122006:131404 [1] NCCL INFO bootstrapSplit: comm 0x4006716513b0 parent 0xaaab0e87b260 rank 29 nranks 128 color 315732477 key 29 prev 28 next 30 - DONE
13: nid005595:197886:207693 [3] NCCL INFO bootstrapSplit: comm 0x40069164e840 parent 0xaaaaea46b560 rank 55 nranks 128 color 315732477 key 55 prev 54 next 56 - DONE
13: nid005595:197886:207693 [3] NCCL INFO ncclCommSplit comm 0x40069164e840 rank 55 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 parent 0xaaaaea46b560 color 315732477 key 55 commId 0xf264858106496629 - Init START
18: nid005911:38865:48327 [1] NCCL INFO bootstrapSplit: comm 0x40068564e900 parent 0xaaaae2c31590 rank 73 nranks 128 color 315732477 key 73 prev 72 next 74 - DONE
18: nid005911:38867:48329 [3] NCCL INFO bootstrapSplit: comm 0x40068964e420 parent 0xaaab31f11170 rank 75 nranks 128 color 315732477 key 75 prev 74 next 76 - DONE
18: nid005911:38866:48328 [2] NCCL INFO bootstrapSplit: comm 0x4006ad64e900 parent 0xaaaafa2a9ac0 rank 74 nranks 128 color 315732477 key 74 prev 73 next 75 - DONE
18: nid005911:38865:48327 [1] NCCL INFO ncclCommSplit comm 0x40068564e900 rank 73 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 parent 0xaaaae2c31590 color 315732477 key 73 commId 0xf264858106496629 - Init START
18: nid005911:38867:48329 [3] NCCL INFO ncclCommSplit comm 0x40068964e420 rank 75 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 parent 0xaaab31f11170 color 315732477 key 75 commId 0xf264858106496629 - Init START
 0: nid005574:69061:78860 [3] NCCL INFO bootstrapSplit: comm 0x40069964e880 parent 0xaaaad3e5bbc0 rank 3 nranks 128 color 315732477 key 3 prev 2 next 4 - DONE
 0: nid005574:69060:78861 [2] NCCL INFO bootstrapSplit: comm 0x4006b164e420 parent 0xaaaaedbf8c70 rank 2 nranks 128 color 315732477 key 2 prev 1 next 3 - DONE
 0: nid005574:69061:78860 [3] NCCL INFO ncclCommSplit comm 0x40069964e880 rank 3 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 parent 0xaaaad3e5bbc0 color 315732477 key 3 commId 0xf264858106496629 - Init START
 0: nid005574:69060:78861 [2] NCCL INFO ncclCommSplit comm 0x4006b164e420 rank 2 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 parent 0xaaaaedbf8c70 color 315732477 key 2 commId 0xf264858106496629 - Init START
10: nid005590:110712:120119 [2] NCCL INFO bootstrapSplit: comm 0x40069d64e3d0 parent 0xaaab104db470 rank 42 nranks 128 color 315732477 key 42 prev 41 next 43 - DONE
10: nid005590:110713:120120 [3] NCCL INFO bootstrapSplit: comm 0x4006a9653dc0 parent 0xaaab375e3b60 rank 43 nranks 128 color 315732477 key 43 prev 42 next 44 - DONE
10: nid005590:110712:120119 [2] NCCL INFO ncclCommSplit comm 0x40069d64e3d0 rank 42 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 parent 0xaaab104db470 color 315732477 key 42 commId 0xf264858106496629 - Init START
10: nid005590:110713:120120 [3] NCCL INFO ncclCommSplit comm 0x4006a9653dc0 rank 43 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 parent 0xaaab375e3b60 color 315732477 key 43 commId 0xf264858106496629 - Init START
10: nid005590:110711:120117 [1] NCCL INFO bootstrapSplit: comm 0x4006896528c0 parent 0xaaab10df3460 rank 41 nranks 128 color 315732477 key 41 prev 40 next 42 - DONE
 2: nid005577:17425:26950 [3] NCCL INFO bootstrapSplit: comm 0x40068164e900 parent 0xaaab1accc2e0 rank 11 nranks 128 color 315732477 key 11 prev 10 next 12 - DONE
 2: nid005577:17424:26951 [2] NCCL INFO bootstrapSplit: comm 0x4006b5648640 parent 0xaaaaec29b7f0 rank 10 nranks 128 color 315732477 key 10 prev 9 next 11 - DONE
 2: nid005577:17423:26949 [1] NCCL INFO bootstrapSplit: comm 0x40069164fd80 parent 0xaaaaf479b750 rank 9 nranks 128 color 315732477 key 9 prev 8 next 10 - DONE
 2: nid005577:17422:26952 [0] NCCL INFO bootstrapSplit: comm 0x40069964fe00 parent 0xaaaaf334fcf0 rank 8 nranks 128 color 315732477 key 8 prev 7 next 9 - DONE
 2: nid005577:17425:26950 [3] NCCL INFO ncclCommSplit comm 0x40068164e900 rank 11 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 parent 0xaaab1accc2e0 color 315732477 key 11 commId 0xf264858106496629 - Init START
 1: nid005576:147558:156960 [1] NCCL INFO ncclCommSplit comm 0x40069964fd70 rank 5 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 parent 0xaaaaf8e03070 color 315732477 key 5 commId 0xf264858106496629 - Init START
 1: nid005576:147560:156959 [3] NCCL INFO bootstrapSplit: comm 0x400699651260 parent 0xaaaaea94c330 rank 7 nranks 128 color 315732477 key 7 prev 6 next 8 - DONE
 1: nid005576:147560:156959 [3] NCCL INFO ncclCommSplit comm 0x400699651260 rank 7 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 parent 0xaaaaea94c330 color 315732477 key 7 commId 0xf264858106496629 - Init START
 1: nid005576:147557:156962 [0] NCCL INFO bootstrapSplit: comm 0x40066d64e900 parent 0xaaab2078f8e0 rank 4 nranks 128 color 315732477 key 4 prev 3 next 5 - DONE
 4: nid005581:264526:273958 [3] NCCL INFO bootstrapSplit: comm 0x40069d64e840 parent 0xaaaae8963db0 rank 19 nranks 128 color 315732477 key 19 prev 18 next 20 - DONE
 4: nid005581:264525:273956 [2] NCCL INFO bootstrapSplit: comm 0x40069564fe00 parent 0xaaaaf1142f20 rank 18 nranks 128 color 315732477 key 18 prev 17 next 19 - DONE
 4: nid005581:264524:273957 [1] NCCL INFO bootstrapSplit: comm 0x4006aca88070 parent 0xaaaad9b8a440 rank 17 nranks 128 color 315732477 key 17 prev 16 next 18 - DONE
 4: nid005581:264526:273958 [3] NCCL INFO ncclCommSplit comm 0x40069d64e840 rank 19 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 parent 0xaaaae8963db0 color 315732477 key 19 commId 0xf264858106496629 - Init START
 4: nid005581:264525:273956 [2] NCCL INFO ncclCommSplit comm 0x40069564fe00 rank 18 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 parent 0xaaaaf1142f20 color 315732477 key 18 commId 0xf264858106496629 - Init START
 9: nid005588:35935:45407 [0] NCCL INFO ncclCommSplit comm 0x40065964fd80 rank 36 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 parent 0xaaab148fdb70 color 315732477 key 36 commId 0xf264858106496629 - Init START
16: nid005802:6297:15923 [0] NCCL INFO ncclCommSplit comm 0x400669651260 rank 64 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 parent 0xaaab18b83d10 color 315732477 key 64 commId 0xf264858106496629 - Init START
16: nid005802:6300:15924 [3] NCCL INFO bootstrapSplit: comm 0x40069164fe00 parent 0xaaaae402b650 rank 67 nranks 128 color 315732477 key 67 prev 66 next 68 - DONE
15: nid005601:210676:220214 [0] NCCL INFO ncclCommSplit comm 0x40068164fe00 rank 60 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 parent 0xaaab05fd2fb0 color 315732477 key 60 commId 0xf264858106496629 - Init START
 7: nid005585:122006:131404 [1] NCCL INFO ncclCommSplit comm 0x4006716513b0 rank 29 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 parent 0xaaab0e87b260 color 315732477 key 29 commId 0xf264858106496629 - Init START
 7: nid005585:122005:131405 [0] NCCL INFO bootstrapSplit: comm 0x40067964fe00 parent 0xaaab166fca20 rank 28 nranks 128 color 315732477 key 28 prev 27 next 29 - DONE
13: nid005595:197884:207691 [1] NCCL INFO bootstrapSplit: comm 0x40068d64e840 parent 0xaaab0cbd2c40 rank 53 nranks 128 color 315732477 key 53 prev 52 next 54 - DONE
13: nid005595:197883:207694 [0] NCCL INFO bootstrapSplit: comm 0x40068164e880 parent 0xaaab1fa69360 rank 52 nranks 128 color 315732477 key 52 prev 51 next 53 - DONE
13: nid005595:197884:207691 [1] NCCL INFO ncclCommSplit comm 0x40068d64e840 rank 53 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 parent 0xaaab0cbd2c40 color 315732477 key 53 commId 0xf264858106496629 - Init START
 5: nid005582:196715:206689 [2] NCCL INFO bootstrapSplit: comm 0x4006bd651260 parent 0xaaaaeab5be10 rank 22 nranks 128 color 315732477 key 22 prev 21 next 23 - DONE
 5: nid005582:196716:206688 [3] NCCL INFO bootstrapSplit: comm 0x40067d64fe00 parent 0xaaab1215f930 rank 23 nranks 128 color 315732477 key 23 prev 22 next 24 - DONE
 5: nid005582:196715:206689 [2] NCCL INFO ncclCommSplit comm 0x4006bd651260 rank 22 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 parent 0xaaaaeab5be10 color 315732477 key 22 commId 0xf264858106496629 - Init START
 8: nid005586:68926:78412 [0] NCCL INFO bootstrapSplit: comm 0x400665651220 parent 0xaaab12790160 rank 32 nranks 128 color 315732477 key 32 prev 31 next 33 - DONE
 8: nid005586:68927:78410 [1] NCCL INFO bootstrapSplit: comm 0x40066ca89660 parent 0xaaaaec21b350 rank 33 nranks 128 color 315732477 key 33 prev 32 next 34 - DONE
 8: nid005586:68927:78410 [1] NCCL INFO ncclCommSplit comm 0x40066ca89660 rank 33 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 parent 0xaaaaec21b350 color 315732477 key 33 commId 0xf264858106496629 - Init START
 8: nid005586:68926:78412 [0] NCCL INFO ncclCommSplit comm 0x400665651220 rank 32 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 parent 0xaaab12790160 color 315732477 key 32 commId 0xf264858106496629 - Init START
14: nid005600:217723:227284 [3] NCCL INFO bootstrapSplit: comm 0x4006bd64e900 parent 0xaaab2a979520 rank 59 nranks 128 color 315732477 key 59 prev 58 next 60 - DONE
14: nid005600:217722:227283 [2] NCCL INFO bootstrapSplit: comm 0x40068d6513b0 parent 0xaaaada11bcd0 rank 58 nranks 128 color 315732477 key 58 prev 57 next 59 - DONE
14: nid005600:217721:227286 [1] NCCL INFO bootstrapSplit: comm 0x400679651260 parent 0xaaaacda93d30 rank 57 nranks 128 color 315732477 key 57 prev 56 next 58 - DONE
14: nid005600:217723:227284 [3] NCCL INFO ncclCommSplit comm 0x4006bd64e900 rank 59 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 parent 0xaaab2a979520 color 315732477 key 59 commId 0xf264858106496629 - Init START
14: nid005600:217722:227283 [2] NCCL INFO ncclCommSplit comm 0x40068d6513b0 rank 58 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 parent 0xaaaada11bcd0 color 315732477 key 58 commId 0xf264858106496629 - Init START
11: nid005591:191604:202310 [1] NCCL INFO bootstrapSplit: comm 0x4006a564fd80 parent 0xaaab196cb950 rank 45 nranks 128 color 315732477 key 45 prev 44 next 46 - DONE
11: nid005591:191605:202311 [2] NCCL INFO bootstrapSplit: comm 0x4006b56513b0 parent 0xaaaafb513f80 rank 46 nranks 128 color 315732477 key 46 prev 45 next 47 - DONE
11: nid005591:191604:202310 [1] NCCL INFO ncclCommSplit comm 0x4006a564fd80 rank 45 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 parent 0xaaab196cb950 color 315732477 key 45 commId 0xf264858106496629 - Init START
11: nid005591:191606:202312 [3] NCCL INFO bootstrapSplit: comm 0x40069164fb20 parent 0xaaaae7d03880 rank 47 nranks 128 color 315732477 key 47 prev 46 next 48 - DONE
11: nid005591:191603:202313 [0] NCCL INFO bootstrapSplit: comm 0x400681651260 parent 0xaaaaf7916bf0 rank 44 nranks 128 color 315732477 key 44 prev 43 next 45 - DONE
 0: nid005574:69059:78862 [1] NCCL INFO bootstrapSplit: comm 0x4006b964e900 parent 0xaaaad1289f50 rank 1 nranks 128 color 315732477 key 1 prev 0 next 2 - DONE
12: nid005594:53085:62558 [0] NCCL INFO bootstrapSplit: comm 0x40068d64fb30 parent 0xaaab0e435340 rank 48 nranks 128 color 315732477 key 48 prev 47 next 49 - DONE
12: nid005594:53086:62556 [1] NCCL INFO bootstrapSplit: comm 0x40067164fdf0 parent 0xaaaadbafb110 rank 49 nranks 128 color 315732477 key 49 prev 48 next 50 - DONE
12: nid005594:53086:62556 [1] NCCL INFO ncclCommSplit comm 0x40067164fdf0 rank 49 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 parent 0xaaaadbafb110 color 315732477 key 49 commId 0xf264858106496629 - Init START
12: nid005594:53085:62558 [0] NCCL INFO ncclCommSplit comm 0x40068d64fb30 rank 48 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 parent 0xaaab0e435340 color 315732477 key 48 commId 0xf264858106496629 - Init START
12: nid005594:53087:62559 [2] NCCL INFO bootstrapSplit: comm 0x40068164e880 parent 0xaaab36e31f10 rank 50 nranks 128 color 315732477 key 50 prev 49 next 51 - DONE
10: nid005590:110710:120118 [0] NCCL INFO bootstrapSplit: comm 0x40066964e420 parent 0xaaab23d6b530 rank 40 nranks 128 color 315732477 key 40 prev 39 next 41 - DONE
10: nid005590:110711:120117 [1] NCCL INFO ncclCommSplit comm 0x4006896528c0 rank 41 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 parent 0xaaab10df3460 color 315732477 key 41 commId 0xf264858106496629 - Init START
10: nid005590:110710:120118 [0] NCCL INFO ncclCommSplit comm 0x40066964e420 rank 40 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 parent 0xaaab23d6b530 color 315732477 key 40 commId 0xf264858106496629 - Init START
 1: nid005576:147557:156962 [0] NCCL INFO ncclCommSplit comm 0x40066d64e900 rank 4 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 parent 0xaaab2078f8e0 color 315732477 key 4 commId 0xf264858106496629 - Init START
 4: nid005581:264524:273957 [1] NCCL INFO ncclCommSplit comm 0x4006aca88070 rank 17 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 parent 0xaaaad9b8a440 color 315732477 key 17 commId 0xf264858106496629 - Init START
16: nid005802:6300:15924 [3] NCCL INFO ncclCommSplit comm 0x40069164fe00 rank 67 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 parent 0xaaaae402b650 color 315732477 key 67 commId 0xf264858106496629 - Init START
 7: nid005585:122005:131405 [0] NCCL INFO ncclCommSplit comm 0x40067964fe00 rank 28 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 parent 0xaaab166fca20 color 315732477 key 28 commId 0xf264858106496629 - Init START
 3: nid005580:71821:81296 [2] NCCL INFO bootstrapSplit: comm 0x40068564fe00 parent 0xaaaada12b8c0 rank 14 nranks 128 color 315732477 key 14 prev 13 next 15 - DONE
 3: nid005580:71822:81295 [3] NCCL INFO bootstrapSplit: comm 0x4006a164fde0 parent 0xaaab06b93260 rank 15 nranks 128 color 315732477 key 15 prev 14 next 16 - DONE
 3: nid005580:71820:81294 [1] NCCL INFO bootstrapSplit: comm 0x4006b564e160 parent 0xaaaac543b4a0 rank 13 nranks 128 color 315732477 key 13 prev 12 next 14 - DONE
 3: nid005580:71819:81293 [0] NCCL INFO bootstrapSplit: comm 0x40067564e840 parent 0xaaab065e8c10 rank 12 nranks 128 color 315732477 key 12 prev 11 next 13 - DONE
 3: nid005580:71821:81296 [2] NCCL INFO ncclCommSplit comm 0x40068564fe00 rank 14 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 parent 0xaaaada12b8c0 color 315732477 key 14 commId 0xf264858106496629 - Init START
 5: nid005582:196716:206688 [3] NCCL INFO ncclCommSplit comm 0x40067d64fe00 rank 23 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 parent 0xaaab1215f930 color 315732477 key 23 commId 0xf264858106496629 - Init START
 5: nid005582:196713:206690 [0] NCCL INFO bootstrapSplit: comm 0x40068564fdf0 parent 0xaaab12118df0 rank 20 nranks 128 color 315732477 key 20 prev 19 next 21 - DONE
 5: nid005582:196714:206691 [1] NCCL INFO bootstrapSplit: comm 0x400689651260 parent 0xaaab201019a0 rank 21 nranks 128 color 315732477 key 21 prev 20 next 22 - DONE
21: nid005914:166786:176213 [2] NCCL INFO bootstrapSplit: comm 0x40068564fdf0 parent 0xaaab02d82db0 rank 86 nranks 128 color 315732477 key 86 prev 85 next 87 - DONE
21: nid005914:166787:176211 [3] NCCL INFO bootstrapSplit: comm 0x40069964fe00 parent 0xaaaadea21c50 rank 87 nranks 128 color 315732477 key 87 prev 86 next 88 - DONE
21: nid005914:166786:176213 [2] NCCL INFO ncclCommSplit comm 0x40068564fdf0 rank 86 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 parent 0xaaab02d82db0 color 315732477 key 86 commId 0xf264858106496629 - Init START
21: nid005914:166787:176211 [3] NCCL INFO ncclCommSplit comm 0x40069964fe00 rank 87 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 parent 0xaaaadea21c50 color 315732477 key 87 commId 0xf264858106496629 - Init START
30: nid005936:49910:59367 [2] NCCL INFO bootstrapSplit: comm 0x4006b964f9d0 parent 0xaaaad8cb00f0 rank 122 nranks 128 color 315732477 key 122 prev 121 next 123 - DONE
30: nid005936:49910:59367 [2] NCCL INFO ncclCommSplit comm 0x4006b964f9d0 rank 122 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 parent 0xaaaad8cb00f0 color 315732477 key 122 commId 0xf264858106496629 - Init START
30: nid005936:49911:59368 [3] NCCL INFO bootstrapSplit: comm 0x40067564fd80 parent 0xaaaad877afc0 rank 123 nranks 128 color 315732477 key 123 prev 122 next 124 - DONE
 8: nid005586:68928:78413 [2] NCCL INFO bootstrapSplit: comm 0x4006a964f980 parent 0xaaaaf16101a0 rank 34 nranks 128 color 315732477 key 34 prev 33 next 35 - DONE
14: nid005600:217721:227286 [1] NCCL INFO ncclCommSplit comm 0x400679651260 rank 57 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 parent 0xaaaacda93d30 color 315732477 key 57 commId 0xf264858106496629 - Init START
14: nid005600:217720:227285 [0] NCCL INFO bootstrapSplit: comm 0x40066964fdc0 parent 0xaaaadc9bcbc0 rank 56 nranks 128 color 315732477 key 56 prev 55 next 57 - DONE
11: nid005591:191605:202311 [2] NCCL INFO ncclCommSplit comm 0x4006b56513b0 rank 46 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 parent 0xaaaafb513f80 color 315732477 key 46 commId 0xf264858106496629 - Init START
29: nid005932:167681:177111 [1] NCCL INFO bootstrapSplit: comm 0x4006a164fdf0 parent 0xaaaac3b4db00 rank 117 nranks 128 color 315732477 key 117 prev 116 next 118 - DONE
29: nid005932:167682:177113 [2] NCCL INFO bootstrapSplit: comm 0x400678a86760 parent 0xaaab2bddcec0 rank 118 nranks 128 color 315732477 key 118 prev 117 next 119 - DONE
29: nid005932:167682:177113 [2] NCCL INFO ncclCommSplit comm 0x400678a86760 rank 118 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 parent 0xaaab2bddcec0 color 315732477 key 118 commId 0xf264858106496629 - Init START
29: nid005932:167681:177111 [1] NCCL INFO ncclCommSplit comm 0x4006a164fdf0 rank 117 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 parent 0xaaaac3b4db00 color 315732477 key 117 commId 0xf264858106496629 - Init START
24: nid005918:92506:101973 [2] NCCL INFO bootstrapSplit: comm 0x40067d6513b0 parent 0xaaab22641a60 rank 98 nranks 128 color 315732477 key 98 prev 97 next 99 - DONE
24: nid005918:92507:101970 [3] NCCL INFO bootstrapSplit: comm 0x40069164fe00 parent 0xaaaae09e21b0 rank 99 nranks 128 color 315732477 key 99 prev 98 next 100 - DONE
24: nid005918:92507:101970 [3] NCCL INFO ncclCommSplit comm 0x40069164fe00 rank 99 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 parent 0xaaaae09e21b0 color 315732477 key 99 commId 0xf264858106496629 - Init START
24: nid005918:92506:101973 [2] NCCL INFO ncclCommSplit comm 0x40067d6513b0 rank 98 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 parent 0xaaab22641a60 color 315732477 key 98 commId 0xf264858106496629 - Init START
 0: nid005574:69059:78862 [1] NCCL INFO ncclCommSplit comm 0x4006b964e900 rank 1 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 parent 0xaaaad1289f50 color 315732477 key 1 commId 0xf264858106496629 - Init START
12: nid005594:53088:62557 [3] NCCL INFO bootstrapSplit: comm 0x40068164fe00 parent 0xaaab14e02fb0 rank 51 nranks 128 color 315732477 key 51 prev 50 next 52 - DONE
 4: nid005581:264523:273959 [0] NCCL INFO bootstrapSplit: comm 0x40068964fe00 parent 0xaaaafba8b880 rank 16 nranks 128 color 315732477 key 16 prev 15 next 17 - DONE
 4: nid005581:264523:273959 [0] NCCL INFO ncclCommSplit comm 0x40068964fe00 rank 16 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 parent 0xaaaafba8b880 color 315732477 key 16 commId 0xf264858106496629 - Init START
17: nid005803:180735:190221 [3] NCCL INFO ncclCommSplit comm 0x4006896513a0 rank 71 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 parent 0xaaab10aa06b0 color 315732477 key 71 commId 0xf264858106496629 - Init START
17: nid005803:180732:190218 [0] NCCL INFO ncclCommSplit comm 0x400681651260 rank 68 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 parent 0xaaaad12a2680 color 315732477 key 68 commId 0xf264858106496629 - Init START
17: nid005803:180733:190220 [1] NCCL INFO ncclCommSplit comm 0x40069164fa60 rank 69 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 parent 0xaaab1f57afc0 color 315732477 key 69 commId 0xf264858106496629 - Init START
 5: nid005582:196713:206690 [0] NCCL INFO ncclCommSplit comm 0x40068564fdf0 rank 20 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 parent 0xaaab12118df0 color 315732477 key 20 commId 0xf264858106496629 - Init START
 5: nid005582:196714:206691 [1] NCCL INFO ncclCommSplit comm 0x400689651260 rank 21 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 parent 0xaaab201019a0 color 315732477 key 21 commId 0xf264858106496629 - Init START
20: nid005913:292684:9581 [3] NCCL INFO bootstrapSplit: comm 0x40069164e900 parent 0xaaaae94038c0 rank 83 nranks 128 color 315732477 key 83 prev 82 next 84 - DONE
20: nid005913:292684:9581 [3] NCCL INFO ncclCommSplit comm 0x40069164e900 rank 83 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 parent 0xaaaae94038c0 color 315732477 key 83 commId 0xf264858106496629 - Init START
20: nid005913:292683:9579 [2] NCCL INFO bootstrapSplit: comm 0x40069564fdf0 parent 0xaaaaf0f2a8d0 rank 82 nranks 128 color 315732477 key 82 prev 81 next 83 - DONE
20: nid005913:292681:9580 [0] NCCL INFO bootstrapSplit: comm 0x40069564fe00 parent 0xaaab2e755bf0 rank 80 nranks 128 color 315732477 key 80 prev 79 next 81 - DONE
20: nid005913:292682:9578 [1] NCCL INFO bootstrapSplit: comm 0x40066964fdf0 parent 0xaaaaf6e99730 rank 81 nranks 128 color 315732477 key 81 prev 80 next 82 - DONE
18: nid005911:38866:48328 [2] NCCL INFO ncclCommSplit comm 0x4006ad64e900 rank 74 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 parent 0xaaaafa2a9ac0 color 315732477 key 74 commId 0xf264858106496629 - Init START
21: nid005914:166785:176214 [1] NCCL INFO bootstrapSplit: comm 0x400689651260 parent 0xaaaaf1392a50 rank 85 nranks 128 color 315732477 key 85 prev 84 next 86 - DONE
21: nid005914:166784:176212 [0] NCCL INFO bootstrapSplit: comm 0x4006a164fe00 parent 0xaaab092dcbd0 rank 84 nranks 128 color 315732477 key 84 prev 83 next 85 - DONE
21: nid005914:166785:176214 [1] NCCL INFO ncclCommSplit comm 0x400689651260 rank 85 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 parent 0xaaaaf1392a50 color 315732477 key 85 commId 0xf264858106496629 - Init START
21: nid005914:166784:176212 [0] NCCL INFO ncclCommSplit comm 0x4006a164fe00 rank 84 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 parent 0xaaab092dcbd0 color 315732477 key 84 commId 0xf264858106496629 - Init START
26: nid005920:67126:76590 [3] NCCL INFO bootstrapSplit: comm 0x40067964fd80 parent 0xaaab209d4590 rank 107 nranks 128 color 315732477 key 107 prev 106 next 108 - DONE
26: nid005920:67123:76588 [0] NCCL INFO bootstrapSplit: comm 0x40069964fe00 parent 0xaaab021f2d20 rank 104 nranks 128 color 315732477 key 104 prev 103 next 105 - DONE
26: nid005920:67125:76589 [2] NCCL INFO bootstrapSplit: comm 0x400669651220 parent 0xaaaaf841bf30 rank 106 nranks 128 color 315732477 key 106 prev 105 next 107 - DONE
26: nid005920:67124:76591 [1] NCCL INFO bootstrapSplit: comm 0x400689651260 parent 0xaaab0de132b0 rank 105 nranks 128 color 315732477 key 105 prev 104 next 106 - DONE
26: nid005920:67126:76590 [3] NCCL INFO ncclCommSplit comm 0x40067964fd80 rank 107 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 parent 0xaaab209d4590 color 315732477 key 107 commId 0xf264858106496629 - Init START
23: nid005917:276888:286343 [3] NCCL INFO bootstrapSplit: comm 0x40069d6513b0 parent 0xaaaaf34fa080 rank 95 nranks 128 color 315732477 key 95 prev 94 next 96 - DONE
23: nid005917:276885:286342 [0] NCCL INFO bootstrapSplit: comm 0x400668a73790 parent 0xaaaae40fdd90 rank 92 nranks 128 color 315732477 key 92 prev 91 next 93 - DONE
23: nid005917:276888:286343 [3] NCCL INFO ncclCommSplit comm 0x40069d6513b0 rank 95 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 parent 0xaaaaf34fa080 color 315732477 key 95 commId 0xf264858106496629 - Init START
23: nid005917:276885:286342 [0] NCCL INFO ncclCommSplit comm 0x400668a73790 rank 92 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 parent 0xaaaae40fdd90 color 315732477 key 92 commId 0xf264858106496629 - Init START
23: nid005917:276886:286341 [1] NCCL INFO bootstrapSplit: comm 0x40068164fb30 parent 0xaaab0f582930 rank 93 nranks 128 color 315732477 key 93 prev 92 next 94 - DONE
30: nid005936:49911:59368 [3] NCCL INFO ncclCommSplit comm 0x40067564fd80 rank 123 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 parent 0xaaaad877afc0 color 315732477 key 123 commId 0xf264858106496629 - Init START
30: nid005936:49909:59369 [1] NCCL INFO bootstrapSplit: comm 0x4006b964fdc0 parent 0xaaaacaa5c1a0 rank 121 nranks 128 color 315732477 key 121 prev 120 next 122 - DONE
30: nid005936:49909:59369 [1] NCCL INFO ncclCommSplit comm 0x4006b964fdc0 rank 121 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 parent 0xaaaacaa5c1a0 color 315732477 key 121 commId 0xf264858106496629 - Init START
27: nid005922:80743:90166 [2] NCCL INFO bootstrapSplit: comm 0x4006b96513a0 parent 0xaaab0b1de990 rank 110 nranks 128 color 315732477 key 110 prev 109 next 111 - DONE
27: nid005922:80744:90167 [3] NCCL INFO bootstrapSplit: comm 0x40068964fe00 parent 0xaaaabb7ab7a0 rank 111 nranks 128 color 315732477 key 111 prev 110 next 112 - DONE
27: nid005922:80742:90165 [1] NCCL INFO bootstrapSplit: comm 0x4006996513b0 parent 0xaaab00b73210 rank 109 nranks 128 color 315732477 key 109 prev 108 next 110 - DONE
27: nid005922:80743:90166 [2] NCCL INFO ncclCommSplit comm 0x4006b96513a0 rank 110 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 parent 0xaaab0b1de990 color 315732477 key 110 commId 0xf264858106496629 - Init START
27: nid005922:80744:90167 [3] NCCL INFO ncclCommSplit comm 0x40068964fe00 rank 111 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 parent 0xaaaabb7ab7a0 color 315732477 key 111 commId 0xf264858106496629 - Init START
 8: nid005586:68929:78411 [3] NCCL INFO bootstrapSplit: comm 0x4006b8a880b0 parent 0xaaab0425a760 rank 35 nranks 128 color 315732477 key 35 prev 34 next 36 - DONE
 8: nid005586:68928:78413 [2] NCCL INFO ncclCommSplit comm 0x4006a964f980 rank 34 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 parent 0xaaaaf16101a0 color 315732477 key 34 commId 0xf264858106496629 - Init START
 8: nid005586:68929:78411 [3] NCCL INFO ncclCommSplit comm 0x4006b8a880b0 rank 35 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 parent 0xaaab0425a760 color 315732477 key 35 commId 0xf264858106496629 - Init START
14: nid005600:217720:227285 [0] NCCL INFO ncclCommSplit comm 0x40066964fdc0 rank 56 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 parent 0xaaaadc9bcbc0 color 315732477 key 56 commId 0xf264858106496629 - Init START
11: nid005591:191606:202312 [3] NCCL INFO ncclCommSplit comm 0x40069164fb20 rank 47 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 parent 0xaaaae7d03880 color 315732477 key 47 commId 0xf264858106496629 - Init START
11: nid005591:191603:202313 [0] NCCL INFO ncclCommSplit comm 0x400681651260 rank 44 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 parent 0xaaaaf7916bf0 color 315732477 key 44 commId 0xf264858106496629 - Init START
29: nid005932:167683:177110 [3] NCCL INFO bootstrapSplit: comm 0x4006a1651260 parent 0xaaab0adabbc0 rank 119 nranks 128 color 315732477 key 119 prev 118 next 120 - DONE
29: nid005932:167680:177112 [0] NCCL INFO bootstrapSplit: comm 0x40069d64fa60 parent 0xaaab03ee4fa0 rank 116 nranks 128 color 315732477 key 116 prev 115 next 117 - DONE
29: nid005932:167683:177110 [3] NCCL INFO ncclCommSplit comm 0x4006a1651260 rank 119 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 parent 0xaaab0adabbc0 color 315732477 key 119 commId 0xf264858106496629 - Init START
24: nid005918:92505:101972 [1] NCCL INFO bootstrapSplit: comm 0x4006a564fdf0 parent 0xaaab23b3bb80 rank 97 nranks 128 color 315732477 key 97 prev 96 next 98 - DONE
24: nid005918:92505:101972 [1] NCCL INFO ncclCommSplit comm 0x4006a564fdf0 rank 97 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 parent 0xaaab23b3bb80 color 315732477 key 97 commId 0xf264858106496629 - Init START
24: nid005918:92504:101971 [0] NCCL INFO bootstrapSplit: comm 0x40066d64fe00 parent 0xaaaaf3895ae0 rank 96 nranks 128 color 315732477 key 96 prev 95 next 97 - DONE
 0: nid005574:69058:78859 [0] NCCL INFO bootstrapSplit: comm 0x400691650620 parent 0xaaab0113f7d0 rank 0 nranks 128 color 315732477 key 0 prev 127 next 1 - DONE
 0: nid005574:69058:78859 [0] NCCL INFO ncclCommSplit comm 0x400691650620 rank 0 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 parent 0xaaab0113f7d0 color 315732477 key 0 commId 0xf264858106496629 - Init START
12: nid005594:53087:62559 [2] NCCL INFO ncclCommSplit comm 0x40068164e880 rank 50 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 parent 0xaaab36e31f10 color 315732477 key 50 commId 0xf264858106496629 - Init START
12: nid005594:53088:62557 [3] NCCL INFO ncclCommSplit comm 0x40068164fe00 rank 51 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 parent 0xaaab14e02fb0 color 315732477 key 51 commId 0xf264858106496629 - Init START
13: nid005595:197883:207694 [0] NCCL INFO ncclCommSplit comm 0x40068164e880 rank 52 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 parent 0xaaab1fa69360 color 315732477 key 52 commId 0xf264858106496629 - Init START
20: nid005913:292683:9579 [2] NCCL INFO ncclCommSplit comm 0x40069564fdf0 rank 82 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 parent 0xaaaaf0f2a8d0 color 315732477 key 82 commId 0xf264858106496629 - Init START
20: nid005913:292681:9580 [0] NCCL INFO ncclCommSplit comm 0x40069564fe00 rank 80 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 parent 0xaaab2e755bf0 color 315732477 key 80 commId 0xf264858106496629 - Init START
20: nid005913:292682:9578 [1] NCCL INFO ncclCommSplit comm 0x40066964fdf0 rank 81 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 parent 0xaaaaf6e99730 color 315732477 key 81 commId 0xf264858106496629 - Init START
19: nid005912:12435:21865 [0] NCCL INFO bootstrapSplit: comm 0x40066d64e900 parent 0xaaab04d29d70 rank 76 nranks 128 color 315732477 key 76 prev 75 next 77 - DONE
19: nid005912:12435:21865 [0] NCCL INFO ncclCommSplit comm 0x40066d64e900 rank 76 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 parent 0xaaab04d29d70 color 315732477 key 76 commId 0xf264858106496629 - Init START
26: nid005920:67123:76588 [0] NCCL INFO ncclCommSplit comm 0x40069964fe00 rank 104 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 parent 0xaaab021f2d20 color 315732477 key 104 commId 0xf264858106496629 - Init START
26: nid005920:67124:76591 [1] NCCL INFO ncclCommSplit comm 0x400689651260 rank 105 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 parent 0xaaab0de132b0 color 315732477 key 105 commId 0xf264858106496629 - Init START
26: nid005920:67125:76589 [2] NCCL INFO ncclCommSplit comm 0x400669651220 rank 106 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 parent 0xaaaaf841bf30 color 315732477 key 106 commId 0xf264858106496629 - Init START
25: nid005919:107462:116957 [0] NCCL INFO bootstrapSplit: comm 0x40067964fe00 parent 0xaaab262294f0 rank 100 nranks 128 color 315732477 key 100 prev 99 next 101 - DONE
25: nid005919:107465:116955 [3] NCCL INFO bootstrapSplit: comm 0x40069964fe00 parent 0xaaaad4543ad0 rank 103 nranks 128 color 315732477 key 103 prev 102 next 104 - DONE
25: nid005919:107464:116954 [2] NCCL INFO bootstrapSplit: comm 0x4006b564e420 parent 0xaaab1682a750 rank 102 nranks 128 color 315732477 key 102 prev 101 next 103 - DONE
25: nid005919:107465:116955 [3] NCCL INFO ncclCommSplit comm 0x40069964fe00 rank 103 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 parent 0xaaaad4543ad0 color 315732477 key 103 commId 0xf264858106496629 - Init START
25: nid005919:107462:116957 [0] NCCL INFO ncclCommSplit comm 0x40067964fe00 rank 100 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 parent 0xaaab262294f0 color 315732477 key 100 commId 0xf264858106496629 - Init START
23: nid005917:276887:286344 [2] NCCL INFO bootstrapSplit: comm 0x40068d64e900 parent 0xaaaaf1b2b6f0 rank 94 nranks 128 color 315732477 key 94 prev 93 next 95 - DONE
23: nid005917:276886:286341 [1] NCCL INFO ncclCommSplit comm 0x40068164fb30 rank 93 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 parent 0xaaab0f582930 color 315732477 key 93 commId 0xf264858106496629 - Init START
23: nid005917:276887:286344 [2] NCCL INFO ncclCommSplit comm 0x40068d64e900 rank 94 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 parent 0xaaaaf1b2b6f0 color 315732477 key 94 commId 0xf264858106496629 - Init START
27: nid005922:80742:90165 [1] NCCL INFO ncclCommSplit comm 0x4006996513b0 rank 109 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 parent 0xaaab00b73210 color 315732477 key 109 commId 0xf264858106496629 - Init START
27: nid005922:80741:90164 [0] NCCL INFO bootstrapSplit: comm 0x40067964fde0 parent 0xaaab18560ec0 rank 108 nranks 128 color 315732477 key 108 prev 107 next 109 - DONE
28: nid005929:16033:25498 [3] NCCL INFO bootstrapSplit: comm 0x4006b164fdc0 parent 0xaaaade0c3510 rank 115 nranks 128 color 315732477 key 115 prev 114 next 116 - DONE
28: nid005929:16032:25496 [2] NCCL INFO bootstrapSplit: comm 0x40069564e840 parent 0xaaab2fba3240 rank 114 nranks 128 color 315732477 key 114 prev 113 next 115 - DONE
28: nid005929:16033:25498 [3] NCCL INFO ncclCommSplit comm 0x4006b164fdc0 rank 115 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 parent 0xaaaade0c3510 color 315732477 key 115 commId 0xf264858106496629 - Init START
28: nid005929:16032:25496 [2] NCCL INFO ncclCommSplit comm 0x40069564e840 rank 114 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 parent 0xaaab2fba3240 color 315732477 key 114 commId 0xf264858106496629 - Init START
 6: nid005584:28288:37690 [3] NCCL INFO bootstrapSplit: comm 0x400698a880b0 parent 0xaaaaf69fb200 rank 27 nranks 128 color 315732477 key 27 prev 26 next 28 - DONE
 6: nid005584:28288:37690 [3] NCCL INFO ncclCommSplit comm 0x400698a880b0 rank 27 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 parent 0xaaaaf69fb200 color 315732477 key 27 commId 0xf264858106496629 - Init START
22: nid005915:274817:284251 [3] NCCL INFO bootstrapSplit: comm 0x4006ad651330 parent 0xaaab11483950 rank 91 nranks 128 color 315732477 key 91 prev 90 next 92 - DONE
22: nid005915:274817:284251 [3] NCCL INFO ncclCommSplit comm 0x4006ad651330 rank 91 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 parent 0xaaab11483950 color 315732477 key 91 commId 0xf264858106496629 - Init START
22: nid005915:274816:284254 [2] NCCL INFO bootstrapSplit: comm 0x4006a96513b0 parent 0xaaaafe3ab720 rank 90 nranks 128 color 315732477 key 90 prev 89 next 91 - DONE
22: nid005915:274816:284254 [2] NCCL INFO ncclCommSplit comm 0x4006a96513b0 rank 90 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 parent 0xaaaafe3ab720 color 315732477 key 90 commId 0xf264858106496629 - Init START
31: nid005937:256591:266028 [2] NCCL INFO bootstrapSplit: comm 0x40068964fe00 parent 0xaaaafcfbaf70 rank 126 nranks 128 color 315732477 key 126 prev 125 next 127 - DONE
31: nid005937:256590:266030 [1] NCCL INFO bootstrapSplit: comm 0x400691651360 parent 0xaaab10443c40 rank 125 nranks 128 color 315732477 key 125 prev 124 next 126 - DONE
31: nid005937:256589:266029 [0] NCCL INFO bootstrapSplit: comm 0x400699652800 parent 0xaaab2c295d90 rank 124 nranks 128 color 315732477 key 124 prev 123 next 125 - DONE
31: nid005937:256592:266031 [3] NCCL INFO bootstrapSplit: comm 0x400674a86b00 parent 0xaaaaedf436d0 rank 127 nranks 128 color 315732477 key 127 prev 126 next 0 - DONE
31: nid005937:256590:266030 [1] NCCL INFO ncclCommSplit comm 0x400691651360 rank 125 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 parent 0xaaab10443c40 color 315732477 key 125 commId 0xf264858106496629 - Init START
29: nid005932:167680:177112 [0] NCCL INFO ncclCommSplit comm 0x40069d64fa60 rank 116 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 parent 0xaaab03ee4fa0 color 315732477 key 116 commId 0xf264858106496629 - Init START
24: nid005918:92504:101971 [0] NCCL INFO ncclCommSplit comm 0x40066d64fe00 rank 96 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 parent 0xaaaaf3895ae0 color 315732477 key 96 commId 0xf264858106496629 - Init START
 2: nid005577:17424:26951 [2] NCCL INFO ncclCommSplit comm 0x4006b5648640 rank 10 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 parent 0xaaaaec29b7f0 color 315732477 key 10 commId 0xf264858106496629 - Init START
 2: nid005577:17423:26949 [1] NCCL INFO ncclCommSplit comm 0x40069164fd80 rank 9 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 parent 0xaaaaf479b750 color 315732477 key 9 commId 0xf264858106496629 - Init START
 2: nid005577:17422:26952 [0] NCCL INFO ncclCommSplit comm 0x40069964fe00 rank 8 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 parent 0xaaaaf334fcf0 color 315732477 key 8 commId 0xf264858106496629 - Init START
 3: nid005580:71822:81295 [3] NCCL INFO ncclCommSplit comm 0x4006a164fde0 rank 15 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 parent 0xaaab06b93260 color 315732477 key 15 commId 0xf264858106496629 - Init START
 3: nid005580:71820:81294 [1] NCCL INFO ncclCommSplit comm 0x4006b564e160 rank 13 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 parent 0xaaaac543b4a0 color 315732477 key 13 commId 0xf264858106496629 - Init START
 3: nid005580:71819:81293 [0] NCCL INFO ncclCommSplit comm 0x40067564e840 rank 12 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 parent 0xaaab065e8c10 color 315732477 key 12 commId 0xf264858106496629 - Init START
19: nid005912:12436:21867 [1] NCCL INFO bootstrapSplit: comm 0x40067964fe00 parent 0xaaaaeb758490 rank 77 nranks 128 color 315732477 key 77 prev 76 next 78 - DONE
19: nid005912:12436:21867 [1] NCCL INFO ncclCommSplit comm 0x40067964fe00 rank 77 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 parent 0xaaaaeb758490 color 315732477 key 77 commId 0xf264858106496629 - Init START
19: nid005912:12437:21866 [2] NCCL INFO bootstrapSplit: comm 0x4006a964fe00 parent 0xaaaaec4bb890 rank 78 nranks 128 color 315732477 key 78 prev 77 next 79 - DONE
25: nid005919:107464:116954 [2] NCCL INFO ncclCommSplit comm 0x4006b564e420 rank 102 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 parent 0xaaab1682a750 color 315732477 key 102 commId 0xf264858106496629 - Init START
25: nid005919:107463:116956 [1] NCCL INFO bootstrapSplit: comm 0x40067d64fe00 parent 0xaaaaf8221890 rank 101 nranks 128 color 315732477 key 101 prev 100 next 102 - DONE
30: nid005936:49908:59370 [0] NCCL INFO bootstrapSplit: comm 0x40057d64fe00 parent 0xaaaafc2a9750 rank 120 nranks 128 color 315732477 key 120 prev 119 next 121 - DONE
30: nid005936:49908:59370 [0] NCCL INFO ncclCommSplit comm 0x40057d64fe00 rank 120 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 parent 0xaaaafc2a9750 color 315732477 key 120 commId 0xf264858106496629 - Init START
27: nid005922:80741:90164 [0] NCCL INFO ncclCommSplit comm 0x40067964fde0 rank 108 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 parent 0xaaab18560ec0 color 315732477 key 108 commId 0xf264858106496629 - Init START
28: nid005929:16031:25497 [1] NCCL INFO bootstrapSplit: comm 0x400699647100 parent 0xaaaaf8401170 rank 113 nranks 128 color 315732477 key 113 prev 112 next 114 - DONE
28: nid005929:16030:25495 [0] NCCL INFO bootstrapSplit: comm 0x40066164fe00 parent 0xaaaad57d3fc0 rank 112 nranks 128 color 315732477 key 112 prev 111 next 113 - DONE
28: nid005929:16031:25497 [1] NCCL INFO ncclCommSplit comm 0x400699647100 rank 113 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 parent 0xaaaaf8401170 color 315732477 key 113 commId 0xf264858106496629 - Init START
28: nid005929:16030:25495 [0] NCCL INFO ncclCommSplit comm 0x40066164fe00 rank 112 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 parent 0xaaaad57d3fc0 color 315732477 key 112 commId 0xf264858106496629 - Init START
 6: nid005584:28287:37693 [2] NCCL INFO bootstrapSplit: comm 0x40068964fb50 parent 0xaaab07a0c730 rank 26 nranks 128 color 315732477 key 26 prev 25 next 27 - DONE
 6: nid005584:28287:37693 [2] NCCL INFO ncclCommSplit comm 0x40068964fb50 rank 26 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 parent 0xaaab07a0c730 color 315732477 key 26 commId 0xf264858106496629 - Init START
22: nid005915:274814:284253 [0] NCCL INFO bootstrapSplit: comm 0x40067d64fe00 parent 0xaaaad1683e90 rank 88 nranks 128 color 315732477 key 88 prev 87 next 89 - DONE
22: nid005915:274815:284252 [1] NCCL INFO bootstrapSplit: comm 0x40069d64f9d0 parent 0xaaab0ea2ac20 rank 89 nranks 128 color 315732477 key 89 prev 88 next 90 - DONE
22: nid005915:274814:284253 [0] NCCL INFO ncclCommSplit comm 0x40067d64fe00 rank 88 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 parent 0xaaaad1683e90 color 315732477 key 88 commId 0xf264858106496629 - Init START
31: nid005937:256591:266028 [2] NCCL INFO ncclCommSplit comm 0x40068964fe00 rank 126 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 parent 0xaaaafcfbaf70 color 315732477 key 126 commId 0xf264858106496629 - Init START
31: nid005937:256589:266029 [0] NCCL INFO ncclCommSplit comm 0x400699652800 rank 124 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 parent 0xaaab2c295d90 color 315732477 key 124 commId 0xf264858106496629 - Init START
31: nid005937:256592:266031 [3] NCCL INFO ncclCommSplit comm 0x400674a86b00 rank 127 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 parent 0xaaaaedf436d0 color 315732477 key 127 commId 0xf264858106496629 - Init START
19: nid005912:12438:21868 [3] NCCL INFO bootstrapSplit: comm 0x40069964fe00 parent 0xaaaae3c43340 rank 79 nranks 128 color 315732477 key 79 prev 78 next 80 - DONE
19: nid005912:12437:21866 [2] NCCL INFO ncclCommSplit comm 0x4006a964fe00 rank 78 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 parent 0xaaaaec4bb890 color 315732477 key 78 commId 0xf264858106496629 - Init START
19: nid005912:12438:21868 [3] NCCL INFO ncclCommSplit comm 0x40069964fe00 rank 79 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 parent 0xaaaae3c43340 color 315732477 key 79 commId 0xf264858106496629 - Init START
25: nid005919:107463:116956 [1] NCCL INFO ncclCommSplit comm 0x40067d64fe00 rank 101 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 parent 0xaaaaf8221890 color 315732477 key 101 commId 0xf264858106496629 - Init START
 6: nid005584:28285:37691 [0] NCCL INFO bootstrapSplit: comm 0x40066564e8c0 parent 0xaaaafc6efb40 rank 24 nranks 128 color 315732477 key 24 prev 23 next 25 - DONE
 6: nid005584:28285:37691 [0] NCCL INFO ncclCommSplit comm 0x40066564e8c0 rank 24 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 parent 0xaaaafc6efb40 color 315732477 key 24 commId 0xf264858106496629 - Init START
22: nid005915:274815:284252 [1] NCCL INFO ncclCommSplit comm 0x40069d64f9d0 rank 89 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 parent 0xaaab0ea2ac20 color 315732477 key 89 commId 0xf264858106496629 - Init START
 6: nid005584:28286:37692 [1] NCCL INFO bootstrapSplit: comm 0x40068964fe00 parent 0xaaab2173c180 rank 25 nranks 128 color 315732477 key 25 prev 24 next 26 - DONE
 6: nid005584:28286:37692 [1] NCCL INFO ncclCommSplit comm 0x40068964fe00 rank 25 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 parent 0xaaab2173c180 color 315732477 key 25 commId 0xf264858106496629 - Init START
13: nid005595:197885:207692 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,ffffffff,ffff0000,00000000,00000000,00000000,00000000
13: nid005595:197885:207692 [2] NCCL INFO NVLS multicast support is not available on dev 2
13: nid005595:197884:207691 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,ffffff00,00000000,00000000
13: nid005595:197884:207691 [1] NCCL INFO NVLS multicast support is not available on dev 1
13: nid005595:197883:207694 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff,ffffffff
13: nid005595:197883:207694 [0] NCCL INFO NVLS multicast support is not available on dev 0
13: nid005595:197886:207693 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff,ff000000,00000000,00000000,00000000,00000000,00000000,00000000
26: nid005920:67123:76588 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff,ffffffff
26: nid005920:67123:76588 [0] NCCL INFO NVLS multicast support is not available on dev 0
26: nid005920:67125:76589 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,ffffffff,ffff0000,00000000,00000000,00000000,00000000
26: nid005920:67125:76589 [2] NCCL INFO NVLS multicast support is not available on dev 2
26: nid005920:67126:76590 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff,ff000000,00000000,00000000,00000000,00000000,00000000,00000000
26: nid005920:67126:76590 [3] NCCL INFO NVLS multicast support is not available on dev 3
26: nid005920:67124:76591 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,ffffff00,00000000,00000000
26: nid005920:67124:76591 [1] NCCL INFO NVLS multicast support is not available on dev 1
25: nid005919:107462:116957 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff,ffffffff
25: nid005919:107462:116957 [0] NCCL INFO NVLS multicast support is not available on dev 0
25: nid005919:107465:116955 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff,ff000000,00000000,00000000,00000000,00000000,00000000,00000000
25: nid005919:107464:116954 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,ffffffff,ffff0000,00000000,00000000,00000000,00000000
25: nid005919:107465:116955 [3] NCCL INFO NVLS multicast support is not available on dev 3
25: nid005919:107464:116954 [2] NCCL INFO NVLS multicast support is not available on dev 2
25: nid005919:107463:116956 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,ffffff00,00000000,00000000
25: nid005919:107463:116956 [1] NCCL INFO NVLS multicast support is not available on dev 1
30: nid005936:49910:59367 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,ffffffff,ffff0000,00000000,00000000,00000000,00000000
30: nid005936:49910:59367 [2] NCCL INFO NVLS multicast support is not available on dev 2
30: nid005936:49909:59369 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,ffffff00,00000000,00000000
30: nid005936:49908:59370 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff,ffffffff
30: nid005936:49909:59369 [1] NCCL INFO NVLS multicast support is not available on dev 1
30: nid005936:49908:59370 [0] NCCL INFO NVLS multicast support is not available on dev 0
30: nid005936:49911:59368 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff,ff000000,00000000,00000000,00000000,00000000,00000000,00000000
21: nid005914:166785:176214 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,ffffff00,00000000,00000000
21: nid005914:166785:176214 [1] NCCL INFO NVLS multicast support is not available on dev 1
21: nid005914:166784:176212 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff,ffffffff
 8: nid005586:68927:78410 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,ffffff00,00000000,00000000
21: nid005914:166784:176212 [0] NCCL INFO NVLS multicast support is not available on dev 0
21: nid005914:166786:176213 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,ffffffff,ffff0000,00000000,00000000,00000000,00000000
 8: nid005586:68927:78410 [1] NCCL INFO NVLS multicast support is not available on dev 1
21: nid005914:166786:176213 [2] NCCL INFO NVLS multicast support is not available on dev 2
 8: nid005586:68926:78412 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff,ffffffff
 8: nid005586:68926:78412 [0] NCCL INFO NVLS multicast support is not available on dev 0
20: nid005913:292683:9579 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,ffffffff,ffff0000,00000000,00000000,00000000,00000000
20: nid005913:292681:9580 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff,ffffffff
20: nid005913:292683:9579 [2] NCCL INFO NVLS multicast support is not available on dev 2
20: nid005913:292682:9578 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,ffffff00,00000000,00000000
20: nid005913:292682:9578 [1] NCCL INFO NVLS multicast support is not available on dev 1
21: nid005914:166787:176211 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff,ff000000,00000000,00000000,00000000,00000000,00000000,00000000
20: nid005913:292684:9581 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff,ff000000,00000000,00000000,00000000,00000000,00000000,00000000
21: nid005914:166787:176211 [3] NCCL INFO NVLS multicast support is not available on dev 3
20: nid005913:292684:9581 [3] NCCL INFO NVLS multicast support is not available on dev 3
 8: nid005586:68928:78413 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,ffffffff,ffff0000,00000000,00000000,00000000,00000000
 8: nid005586:68928:78413 [2] NCCL INFO NVLS multicast support is not available on dev 2
 8: nid005586:68929:78411 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff,ff000000,00000000,00000000,00000000,00000000,00000000,00000000
 8: nid005586:68929:78411 [3] NCCL INFO NVLS multicast support is not available on dev 3
16: nid005802:6297:15923 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff,ffffffff
16: nid005802:6299:15922 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,ffffffff,ffff0000,00000000,00000000,00000000,00000000
16: nid005802:6299:15922 [2] NCCL INFO NVLS multicast support is not available on dev 2
27: nid005922:80743:90166 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,ffffffff,ffff0000,00000000,00000000,00000000,00000000
16: nid005802:6297:15923 [0] NCCL INFO NVLS multicast support is not available on dev 0
27: nid005922:80743:90166 [2] NCCL INFO NVLS multicast support is not available on dev 2
 3: nid005580:71820:81294 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,ffffff00,00000000,00000000
16: nid005802:6298:15921 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,ffffff00,00000000,00000000
16: nid005802:6300:15924 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff,ff000000,00000000,00000000,00000000,00000000,00000000,00000000
16: nid005802:6298:15921 [1] NCCL INFO NVLS multicast support is not available on dev 1
 3: nid005580:71820:81294 [1] NCCL INFO NVLS multicast support is not available on dev 1
16: nid005802:6300:15924 [3] NCCL INFO NVLS multicast support is not available on dev 3
13: nid005595:197886:207693 [3] NCCL INFO NVLS multicast support is not available on dev 3
27: nid005922:80742:90165 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,ffffff00,00000000,00000000
 3: nid005580:71819:81293 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff,ffffffff
27: nid005922:80741:90164 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff,ffffffff
27: nid005922:80742:90165 [1] NCCL INFO NVLS multicast support is not available on dev 1
 3: nid005580:71819:81293 [0] NCCL INFO NVLS multicast support is not available on dev 0
27: nid005922:80741:90164 [0] NCCL INFO NVLS multicast support is not available on dev 0
 3: nid005580:71822:81295 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff,ff000000,00000000,00000000,00000000,00000000,00000000,00000000
27: nid005922:80744:90167 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff,ff000000,00000000,00000000,00000000,00000000,00000000,00000000
 3: nid005580:71821:81296 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,ffffffff,ffff0000,00000000,00000000,00000000,00000000
 3: nid005580:71821:81296 [2] NCCL INFO NVLS multicast support is not available on dev 2
 3: nid005580:71822:81295 [3] NCCL INFO NVLS multicast support is not available on dev 3
27: nid005922:80744:90167 [3] NCCL INFO NVLS multicast support is not available on dev 3
22: nid005915:274817:284251 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff,ff000000,00000000,00000000,00000000,00000000,00000000,00000000
19: nid005912:12435:21865 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff,ffffffff
22: nid005915:274817:284251 [3] NCCL INFO NVLS multicast support is not available on dev 3
19: nid005912:12435:21865 [0] NCCL INFO NVLS multicast support is not available on dev 0
31: nid005937:256591:266028 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,ffffffff,ffff0000,00000000,00000000,00000000,00000000
19: nid005912:12437:21866 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,ffffffff,ffff0000,00000000,00000000,00000000,00000000
31: nid005937:256591:266028 [2] NCCL INFO NVLS multicast support is not available on dev 2
22: nid005915:274816:284254 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,ffffffff,ffff0000,00000000,00000000,00000000,00000000
22: nid005915:274816:284254 [2] NCCL INFO NVLS multicast support is not available on dev 2
22: nid005915:274814:284253 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff,ffffffff
22: nid005915:274815:284252 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,ffffff00,00000000,00000000
22: nid005915:274814:284253 [0] NCCL INFO NVLS multicast support is not available on dev 0
22: nid005915:274815:284252 [1] NCCL INFO NVLS multicast support is not available on dev 1
31: nid005937:256589:266029 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff,ffffffff
31: nid005937:256590:266030 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,ffffff00,00000000,00000000
31: nid005937:256589:266029 [0] NCCL INFO NVLS multicast support is not available on dev 0
31: nid005937:256592:266031 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff,ff000000,00000000,00000000,00000000,00000000,00000000,00000000
31: nid005937:256590:266030 [1] NCCL INFO NVLS multicast support is not available on dev 1
31: nid005937:256592:266031 [3] NCCL INFO NVLS multicast support is not available on dev 3
10: nid005590:110710:120118 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff,ffffffff
10: nid005590:110710:120118 [0] NCCL INFO NVLS multicast support is not available on dev 0
 6: nid005584:28287:37693 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,ffffffff,ffff0000,00000000,00000000,00000000,00000000
10: nid005590:110713:120120 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff,ff000000,00000000,00000000,00000000,00000000,00000000,00000000
10: nid005590:110712:120119 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,ffffffff,ffff0000,00000000,00000000,00000000,00000000
11: nid005591:191603:202313 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff,ffffffff
11: nid005591:191605:202311 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,ffffffff,ffff0000,00000000,00000000,00000000,00000000
 6: nid005584:28287:37693 [2] NCCL INFO NVLS multicast support is not available on dev 2
10: nid005590:110713:120120 [3] NCCL INFO NVLS multicast support is not available on dev 3
10: nid005590:110712:120119 [2] NCCL INFO NVLS multicast support is not available on dev 2
11: nid005591:191605:202311 [2] NCCL INFO NVLS multicast support is not available on dev 2
11: nid005591:191604:202310 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,ffffff00,00000000,00000000
10: nid005590:110711:120117 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,ffffff00,00000000,00000000
 6: nid005584:28285:37691 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff,ffffffff
11: nid005591:191606:202312 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff,ff000000,00000000,00000000,00000000,00000000,00000000,00000000
 6: nid005584:28286:37692 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,ffffff00,00000000,00000000
11: nid005591:191606:202312 [3] NCCL INFO NVLS multicast support is not available on dev 3
11: nid005591:191604:202310 [1] NCCL INFO NVLS multicast support is not available on dev 1
11: nid005591:191603:202313 [0] NCCL INFO NVLS multicast support is not available on dev 0
10: nid005590:110711:120117 [1] NCCL INFO NVLS multicast support is not available on dev 1
 6: nid005584:28286:37692 [1] NCCL INFO NVLS multicast support is not available on dev 1
 6: nid005584:28285:37691 [0] NCCL INFO NVLS multicast support is not available on dev 0
15: nid005601:210677:220213 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,ffffff00,00000000,00000000
15: nid005601:210676:220214 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff,ffffffff
15: nid005601:210677:220213 [1] NCCL INFO NVLS multicast support is not available on dev 1
15: nid005601:210676:220214 [0] NCCL INFO NVLS multicast support is not available on dev 0
15: nid005601:210678:220212 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,ffffffff,ffff0000,00000000,00000000,00000000,00000000
15: nid005601:210678:220212 [2] NCCL INFO NVLS multicast support is not available on dev 2
15: nid005601:210679:220215 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff,ff000000,00000000,00000000,00000000,00000000,00000000,00000000
 5: nid005582:196715:206689 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,ffffffff,ffff0000,00000000,00000000,00000000,00000000
15: nid005601:210679:220215 [3] NCCL INFO NVLS multicast support is not available on dev 3
 5: nid005582:196715:206689 [2] NCCL INFO NVLS multicast support is not available on dev 2
 2: nid005577:17423:26949 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,ffffff00,00000000,00000000
 2: nid005577:17423:26949 [1] NCCL INFO NVLS multicast support is not available on dev 1
 5: nid005582:196714:206691 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,ffffff00,00000000,00000000
 5: nid005582:196713:206690 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff,ffffffff
 5: nid005582:196716:206688 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff,ff000000,00000000,00000000,00000000,00000000,00000000,00000000
 5: nid005582:196716:206688 [3] NCCL INFO NVLS multicast support is not available on dev 3
 5: nid005582:196714:206691 [1] NCCL INFO NVLS multicast support is not available on dev 1
 5: nid005582:196713:206690 [0] NCCL INFO NVLS multicast support is not available on dev 0
28: nid005929:16031:25497 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,ffffff00,00000000,00000000
28: nid005929:16031:25497 [1] NCCL INFO NVLS multicast support is not available on dev 1
 2: nid005577:17422:26952 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff,ffffffff
 2: nid005577:17422:26952 [0] NCCL INFO NVLS multicast support is not available on dev 0
 2: nid005577:17424:26951 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,ffffffff,ffff0000,00000000,00000000,00000000,00000000
14: nid005600:217721:227286 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,ffffff00,00000000,00000000
14: nid005600:217721:227286 [1] NCCL INFO NVLS multicast support is not available on dev 1
28: nid005929:16030:25495 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff,ffffffff
28: nid005929:16032:25496 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,ffffffff,ffff0000,00000000,00000000,00000000,00000000
28: nid005929:16033:25498 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff,ff000000,00000000,00000000,00000000,00000000,00000000,00000000
28: nid005929:16032:25496 [2] NCCL INFO NVLS multicast support is not available on dev 2
28: nid005929:16033:25498 [3] NCCL INFO NVLS multicast support is not available on dev 3
28: nid005929:16030:25495 [0] NCCL INFO NVLS multicast support is not available on dev 0
14: nid005600:217720:227285 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff,ffffffff
14: nid005600:217720:227285 [0] NCCL INFO NVLS multicast support is not available on dev 0
14: nid005600:217723:227284 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff,ff000000,00000000,00000000,00000000,00000000,00000000,00000000
14: nid005600:217722:227283 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,ffffffff,ffff0000,00000000,00000000,00000000,00000000
14: nid005600:217723:227284 [3] NCCL INFO NVLS multicast support is not available on dev 3
 9: nid005588:35937:45405 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,ffffffff,ffff0000,00000000,00000000,00000000,00000000
14: nid005600:217722:227283 [2] NCCL INFO NVLS multicast support is not available on dev 2
 9: nid005588:35937:45405 [2] NCCL INFO NVLS multicast support is not available on dev 2
 9: nid005588:35936:45406 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,ffffff00,00000000,00000000
 9: nid005588:35936:45406 [1] NCCL INFO NVLS multicast support is not available on dev 1
12: nid005594:53086:62556 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,ffffff00,00000000,00000000
 9: nid005588:35935:45407 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff,ffffffff
12: nid005594:53086:62556 [1] NCCL INFO NVLS multicast support is not available on dev 1
 9: nid005588:35935:45407 [0] NCCL INFO NVLS multicast support is not available on dev 0
 9: nid005588:35938:45404 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff,ff000000,00000000,00000000,00000000,00000000,00000000,00000000
12: nid005594:53085:62558 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff,ffffffff
12: nid005594:53085:62558 [0] NCCL INFO NVLS multicast support is not available on dev 0
12: nid005594:53087:62559 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,ffffffff,ffff0000,00000000,00000000,00000000,00000000
12: nid005594:53087:62559 [2] NCCL INFO NVLS multicast support is not available on dev 2
12: nid005594:53088:62557 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff,ff000000,00000000,00000000,00000000,00000000,00000000,00000000
12: nid005594:53088:62557 [3] NCCL INFO NVLS multicast support is not available on dev 3
 7: nid005585:122008:131402 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff,ff000000,00000000,00000000,00000000,00000000,00000000,00000000
 7: nid005585:122008:131402 [3] NCCL INFO NVLS multicast support is not available on dev 3
 7: nid005585:122006:131404 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,ffffff00,00000000,00000000
 7: nid005585:122007:131403 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,ffffffff,ffff0000,00000000,00000000,00000000,00000000
 7: nid005585:122007:131403 [2] NCCL INFO NVLS multicast support is not available on dev 2
 7: nid005585:122006:131404 [1] NCCL INFO NVLS multicast support is not available on dev 1
 7: nid005585:122005:131405 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff,ffffffff
30: nid005936:49911:59368 [3] NCCL INFO NVLS multicast support is not available on dev 3
 7: nid005585:122005:131405 [0] NCCL INFO NVLS multicast support is not available on dev 0
 4: nid005581:264525:273956 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,ffffffff,ffff0000,00000000,00000000,00000000,00000000
 4: nid005581:264525:273956 [2] NCCL INFO NVLS multicast support is not available on dev 2
 4: nid005581:264523:273959 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff,ffffffff
 4: nid005581:264523:273959 [0] NCCL INFO NVLS multicast support is not available on dev 0
 4: nid005581:264524:273957 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,ffffff00,00000000,00000000
19: nid005912:12437:21866 [2] NCCL INFO NVLS multicast support is not available on dev 2
19: nid005912:12436:21867 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,ffffff00,00000000,00000000
19: nid005912:12438:21868 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff,ff000000,00000000,00000000,00000000,00000000,00000000,00000000
19: nid005912:12438:21868 [3] NCCL INFO NVLS multicast support is not available on dev 3
19: nid005912:12436:21867 [1] NCCL INFO NVLS multicast support is not available on dev 1
 6: nid005584:28288:37690 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff,ff000000,00000000,00000000,00000000,00000000,00000000,00000000
 6: nid005584:28288:37690 [3] NCCL INFO NVLS multicast support is not available on dev 3
 1: nid005576:147558:156960 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,ffffff00,00000000,00000000
 1: nid005576:147558:156960 [1] NCCL INFO NVLS multicast support is not available on dev 1
 1: nid005576:147557:156962 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff,ffffffff
 1: nid005576:147559:156961 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,ffffffff,ffff0000,00000000,00000000,00000000,00000000
 1: nid005576:147560:156959 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff,ff000000,00000000,00000000,00000000,00000000,00000000,00000000
 1: nid005576:147557:156962 [0] NCCL INFO NVLS multicast support is not available on dev 0
18: nid005911:38864:48326 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff,ffffffff
18: nid005911:38865:48327 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,ffffff00,00000000,00000000
18: nid005911:38865:48327 [1] NCCL INFO NVLS multicast support is not available on dev 1
18: nid005911:38864:48326 [0] NCCL INFO NVLS multicast support is not available on dev 0
18: nid005911:38866:48328 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,ffffffff,ffff0000,00000000,00000000,00000000,00000000
18: nid005911:38867:48329 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff,ff000000,00000000,00000000,00000000,00000000,00000000,00000000
18: nid005911:38866:48328 [2] NCCL INFO NVLS multicast support is not available on dev 2
18: nid005911:38867:48329 [3] NCCL INFO NVLS multicast support is not available on dev 3
 9: nid005588:35938:45404 [3] NCCL INFO NVLS multicast support is not available on dev 3
23: nid005917:276887:286344 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,ffffffff,ffff0000,00000000,00000000,00000000,00000000
17: nid005803:180733:190220 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,ffffff00,00000000,00000000
17: nid005803:180735:190221 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff,ff000000,00000000,00000000,00000000,00000000,00000000,00000000
17: nid005803:180733:190220 [1] NCCL INFO NVLS multicast support is not available on dev 1
17: nid005803:180732:190218 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff,ffffffff
23: nid005917:276887:286344 [2] NCCL INFO NVLS multicast support is not available on dev 2
17: nid005803:180735:190221 [3] NCCL INFO NVLS multicast support is not available on dev 3
17: nid005803:180732:190218 [0] NCCL INFO NVLS multicast support is not available on dev 0
17: nid005803:180734:190219 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,ffffffff,ffff0000,00000000,00000000,00000000,00000000
20: nid005913:292681:9580 [0] NCCL INFO NVLS multicast support is not available on dev 0
17: nid005803:180734:190219 [2] NCCL INFO NVLS multicast support is not available on dev 2
23: nid005917:276888:286343 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff,ff000000,00000000,00000000,00000000,00000000,00000000,00000000
23: nid005917:276886:286341 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,ffffff00,00000000,00000000
23: nid005917:276886:286341 [1] NCCL INFO NVLS multicast support is not available on dev 1
23: nid005917:276888:286343 [3] NCCL INFO NVLS multicast support is not available on dev 3
23: nid005917:276885:286342 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff,ffffffff
23: nid005917:276885:286342 [0] NCCL INFO NVLS multicast support is not available on dev 0
 2: nid005577:17424:26951 [2] NCCL INFO NVLS multicast support is not available on dev 2
 2: nid005577:17425:26950 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff,ff000000,00000000,00000000,00000000,00000000,00000000,00000000
 2: nid005577:17425:26950 [3] NCCL INFO NVLS multicast support is not available on dev 3
 4: nid005581:264524:273957 [1] NCCL INFO NVLS multicast support is not available on dev 1
 4: nid005581:264526:273958 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff,ff000000,00000000,00000000,00000000,00000000,00000000,00000000
 4: nid005581:264526:273958 [3] NCCL INFO NVLS multicast support is not available on dev 3
 1: nid005576:147559:156961 [2] NCCL INFO NVLS multicast support is not available on dev 2
 1: nid005576:147560:156959 [3] NCCL INFO NVLS multicast support is not available on dev 3
24: nid005918:92507:101970 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff,ff000000,00000000,00000000,00000000,00000000,00000000,00000000
24: nid005918:92506:101973 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,ffffffff,ffff0000,00000000,00000000,00000000,00000000
24: nid005918:92507:101970 [3] NCCL INFO NVLS multicast support is not available on dev 3
24: nid005918:92504:101971 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff,ffffffff
24: nid005918:92506:101973 [2] NCCL INFO NVLS multicast support is not available on dev 2
24: nid005918:92504:101971 [0] NCCL INFO NVLS multicast support is not available on dev 0
24: nid005918:92505:101972 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,ffffff00,00000000,00000000
24: nid005918:92505:101972 [1] NCCL INFO NVLS multicast support is not available on dev 1
29: nid005932:167682:177113 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,ffffffff,ffff0000,00000000,00000000,00000000,00000000
29: nid005932:167682:177113 [2] NCCL INFO NVLS multicast support is not available on dev 2
29: nid005932:167680:177112 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff,ffffffff
29: nid005932:167681:177111 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,ffffff00,00000000,00000000
29: nid005932:167680:177112 [0] NCCL INFO NVLS multicast support is not available on dev 0
29: nid005932:167681:177111 [1] NCCL INFO NVLS multicast support is not available on dev 1
29: nid005932:167683:177110 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff,ff000000,00000000,00000000,00000000,00000000,00000000,00000000
29: nid005932:167683:177110 [3] NCCL INFO NVLS multicast support is not available on dev 3
 0: nid005574:69060:78861 [2] NCCL INFO Setting affinity for GPU 2 to ffffff,ffffffff,ffff0000,00000000,00000000,00000000,00000000
 0: nid005574:69060:78861 [2] NCCL INFO NVLS multicast support is not available on dev 2
 0: nid005574:69059:78862 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,ffffff00,00000000,00000000
 0: nid005574:69059:78862 [1] NCCL INFO NVLS multicast support is not available on dev 1
 0: nid005574:69058:78859 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff,ffffffff
 0: nid005574:69058:78859 [0] NCCL INFO NVLS multicast support is not available on dev 0
 0: nid005574:69061:78860 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,ffffffff,ff000000,00000000,00000000,00000000,00000000,00000000,00000000
 0: nid005574:69061:78860 [3] NCCL INFO NVLS multicast support is not available on dev 3
 3: nid005580:71822:81295 [3] NCCL INFO comm 0x4006a164fde0 rank 15 nRanks 128 nNodes 32 localRanks 4 localRank 3 MNNVL 0
 3: nid005580:71820:81294 [1] NCCL INFO comm 0x4006b564e160 rank 13 nRanks 128 nNodes 32 localRanks 4 localRank 1 MNNVL 0
 3: nid005580:71821:81296 [2] NCCL INFO comm 0x40068564fe00 rank 14 nRanks 128 nNodes 32 localRanks 4 localRank 2 MNNVL 0
 5: nid005582:196716:206688 [3] NCCL INFO comm 0x40067d64fe00 rank 23 nRanks 128 nNodes 32 localRanks 4 localRank 3 MNNVL 0
 3: nid005580:71820:81294 [1] NCCL INFO Trees [0] 14/-1/-1->13->12 [1] 14/-1/-1->13->12 [2] -1/-1/-1->13->12 [3] -1/-1/-1->13->12 [4] 14/-1/-1->13->12 [5] 14/-1/-1->13->12 [6] -1/-1/-1->13->12 [7] -1/-1/-1->13->12
 3: nid005580:71821:81296 [2] NCCL INFO Trees [0] 15/-1/-1->14->13 [1] 15/-1/-1->14->13 [2] 15/-1/-1->14->10 [3] 15/-1/-1->14->10 [4] 15/-1/-1->14->13 [5] 15/-1/-1->14->13 [6] 15/22/6->14->30 [7] 15/22/6->14->30
 3: nid005580:71822:81295 [3] NCCL INFO Trees [0] -1/-1/-1->15->14 [1] -1/-1/-1->15->14 [2] 12/-1/-1->15->14 [3] 12/-1/-1->15->14 [4] -1/-1/-1->15->14 [5] -1/-1/-1->15->14 [6] 12/-1/-1->15->14 [7] 12/-1/-1->15->14
 3: nid005580:71820:81294 [1] NCCL INFO P2P Chunksize set to 131072
 3: nid005580:71821:81296 [2] NCCL INFO P2P Chunksize set to 131072
 3: nid005580:71822:81295 [3] NCCL INFO P2P Chunksize set to 131072
 3: nid005580:71819:81293 [0] NCCL INFO comm 0x40067564e840 rank 12 nRanks 128 nNodes 32 localRanks 4 localRank 0 MNNVL 0
 2: nid005577:17425:26950 [3] NCCL INFO comm 0x40068164e900 rank 11 nRanks 128 nNodes 32 localRanks 4 localRank 3 MNNVL 0
 5: nid005582:196716:206688 [3] NCCL INFO Trees [0] -1/-1/-1->23->22 [1] -1/-1/-1->23->22 [2] 20/-1/-1->23->22 [3] 20/-1/-1->23->22 [4] -1/-1/-1->23->22 [5] -1/-1/-1->23->22 [6] 20/-1/-1->23->22 [7] 20/-1/-1->23->22
 5: nid005582:196716:206688 [3] NCCL INFO P2P Chunksize set to 131072
 5: nid005582:196715:206689 [2] NCCL INFO comm 0x4006bd651260 rank 22 nRanks 128 nNodes 32 localRanks 4 localRank 2 MNNVL 0
 5: nid005582:196714:206691 [1] NCCL INFO comm 0x400689651260 rank 21 nRanks 128 nNodes 32 localRanks 4 localRank 1 MNNVL 0
 2: nid005577:17425:26950 [3] NCCL INFO Trees [0] -1/-1/-1->11->10 [1] -1/-1/-1->11->10 [2] 8/-1/-1->11->10 [3] 8/-1/-1->11->10 [4] -1/-1/-1->11->10 [5] -1/-1/-1->11->10 [6] 8/-1/-1->11->10 [7] 8/-1/-1->11->10
 2: nid005577:17425:26950 [3] NCCL INFO P2P Chunksize set to 131072
 2: nid005577:17424:26951 [2] NCCL INFO comm 0x4006b5648640 rank 10 nRanks 128 nNodes 32 localRanks 4 localRank 2 MNNVL 0
 4: nid005581:264525:273956 [2] NCCL INFO comm 0x40069564fe00 rank 18 nRanks 128 nNodes 32 localRanks 4 localRank 2 MNNVL 0
 4: nid005581:264524:273957 [1] NCCL INFO comm 0x4006aca88070 rank 17 nRanks 128 nNodes 32 localRanks 4 localRank 1 MNNVL 0
 4: nid005581:264526:273958 [3] NCCL INFO comm 0x40069d64e840 rank 19 nRanks 128 nNodes 32 localRanks 4 localRank 3 MNNVL 0
 4: nid005581:264523:273959 [0] NCCL INFO comm 0x40068964fe00 rank 16 nRanks 128 nNodes 32 localRanks 4 localRank 0 MNNVL 0
 5: nid005582:196713:206690 [0] NCCL INFO comm 0x40068564fdf0 rank 20 nRanks 128 nNodes 32 localRanks 4 localRank 0 MNNVL 0
 5: nid005582:196715:206689 [2] NCCL INFO Trees [0] 23/-1/-1->22->21 [1] 23/-1/-1->22->21 [2] 23/-1/-1->22->26 [3] 23/-1/-1->22->26 [4] 23/-1/-1->22->21 [5] 23/-1/-1->22->21 [6] 23/26/18->22->14 [7] 23/26/18->22->14
 5: nid005582:196715:206689 [2] NCCL INFO P2P Chunksize set to 131072
 3: nid005580:71819:81293 [0] NCCL INFO Trees [0] 13/-1/-1->12->8 [1] 13/-1/-1->12->8 [2] 13/-1/-1->12->15 [3] 13/-1/-1->12->15 [4] 13/20/4->12->28 [5] 13/20/4->12->28 [6] 13/-1/-1->12->15 [7] 13/-1/-1->12->15
 3: nid005580:71819:81293 [0] NCCL INFO P2P Chunksize set to 131072
 2: nid005577:17423:26949 [1] NCCL INFO comm 0x40069164fd80 rank 9 nRanks 128 nNodes 32 localRanks 4 localRank 1 MNNVL 0
 4: nid005581:264525:273956 [2] NCCL INFO Trees [0] 19/-1/-1->18->17 [1] 19/-1/-1->18->17 [2] 19/10/26->18->34 [3] 19/10/26->18->34 [4] 19/-1/-1->18->17 [5] 19/-1/-1->18->17 [6] 19/-1/-1->18->22 [7] 19/-1/-1->18->22
 4: nid005581:264525:273956 [2] NCCL INFO P2P Chunksize set to 131072
 2: nid005577:17422:26952 [0] NCCL INFO comm 0x40069964fe00 rank 8 nRanks 128 nNodes 32 localRanks 4 localRank 0 MNNVL 0
 4: nid005581:264524:273957 [1] NCCL INFO Trees [0] 18/-1/-1->17->16 [1] 18/-1/-1->17->16 [2] -1/-1/-1->17->16 [3] -1/-1/-1->17->16 [4] 18/-1/-1->17->16 [5] 18/-1/-1->17->16 [6] -1/-1/-1->17->16 [7] -1/-1/-1->17->16
 4: nid005581:264526:273958 [3] NCCL INFO Trees [0] -1/-1/-1->19->18 [1] -1/-1/-1->19->18 [2] 16/-1/-1->19->18 [3] 16/-1/-1->19->18 [4] -1/-1/-1->19->18 [5] -1/-1/-1->19->18 [6] 16/-1/-1->19->18 [7] 16/-1/-1->19->18
 4: nid005581:264524:273957 [1] NCCL INFO P2P Chunksize set to 131072
 4: nid005581:264526:273958 [3] NCCL INFO P2P Chunksize set to 131072
 5: nid005582:196714:206691 [1] NCCL INFO Trees [0] 22/-1/-1->21->20 [1] 22/-1/-1->21->20 [2] -1/-1/-1->21->20 [3] -1/-1/-1->21->20 [4] 22/-1/-1->21->20 [5] 22/-1/-1->21->20 [6] -1/-1/-1->21->20 [7] -1/-1/-1->21->20
 2: nid005577:17424:26951 [2] NCCL INFO Trees [0] 11/-1/-1->10->9 [1] 11/-1/-1->10->9 [2] 11/6/14->10->18 [3] 11/6/14->10->18 [4] 11/-1/-1->10->9 [5] 11/-1/-1->10->9 [6] 11/-1/-1->10->6 [7] 11/-1/-1->10->6
 2: nid005577:17424:26951 [2] NCCL INFO P2P Chunksize set to 131072
 2: nid005577:17423:26949 [1] NCCL INFO Trees [0] 10/-1/-1->9->8 [1] 10/-1/-1->9->8 [2] -1/-1/-1->9->8 [3] -1/-1/-1->9->8 [4] 10/-1/-1->9->8 [5] 10/-1/-1->9->8 [6] -1/-1/-1->9->8 [7] -1/-1/-1->9->8
 2: nid005577:17423:26949 [1] NCCL INFO P2P Chunksize set to 131072
 1: nid005576:147559:156961 [2] NCCL INFO comm 0x40069d652920 rank 6 nRanks 128 nNodes 32 localRanks 4 localRank 2 MNNVL 0
 1: nid005576:147560:156959 [3] NCCL INFO comm 0x400699651260 rank 7 nRanks 128 nNodes 32 localRanks 4 localRank 3 MNNVL 0
 5: nid005582:196714:206691 [1] NCCL INFO P2P Chunksize set to 131072
 2: nid005577:17422:26952 [0] NCCL INFO Trees [0] 9/4/12->8->16 [1] 9/4/12->8->16 [2] 9/-1/-1->8->11 [3] 9/-1/-1->8->11 [4] 9/-1/-1->8->4 [5] 9/-1/-1->8->4 [6] 9/-1/-1->8->11 [7] 9/-1/-1->8->11
 2: nid005577:17422:26952 [0] NCCL INFO P2P Chunksize set to 131072
 5: nid005582:196713:206690 [0] NCCL INFO Trees [0] 21/-1/-1->20->24 [1] 21/-1/-1->20->24 [2] 21/-1/-1->20->23 [3] 21/-1/-1->20->23 [4] 21/24/16->20->12 [5] 21/24/16->20->12 [6] 21/-1/-1->20->23 [7] 21/-1/-1->20->23
 5: nid005582:196713:206690 [0] NCCL INFO P2P Chunksize set to 131072
 1: nid005576:147560:156959 [3] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6 [2] 4/-1/-1->7->6 [3] 4/-1/-1->7->6 [4] -1/-1/-1->7->6 [5] -1/-1/-1->7->6 [6] 4/-1/-1->7->6 [7] 4/-1/-1->7->6
 1: nid005576:147560:156959 [3] NCCL INFO P2P Chunksize set to 131072
 4: nid005581:264523:273959 [0] NCCL INFO Trees [0] 17/8/24->16->32 [1] 17/8/24->16->32 [2] 17/-1/-1->16->19 [3] 17/-1/-1->16->19 [4] 17/-1/-1->16->20 [5] 17/-1/-1->16->20 [6] 17/-1/-1->16->19 [7] 17/-1/-1->16->19
 4: nid005581:264523:273959 [0] NCCL INFO P2P Chunksize set to 131072
 1: nid005576:147558:156960 [1] NCCL INFO comm 0x40069964fd70 rank 5 nRanks 128 nNodes 32 localRanks 4 localRank 1 MNNVL 0
 1: nid005576:147559:156961 [2] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5 [2] 7/-1/-1->6->10 [3] 7/-1/-1->6->10 [4] 7/-1/-1->6->5 [5] 7/-1/-1->6->5 [6] 7/10/2->6->14 [7] 7/10/2->6->14
31: nid005937:256591:266028 [2] NCCL INFO comm 0x40068964fe00 rank 126 nRanks 128 nNodes 32 localRanks 4 localRank 2 MNNVL 0
31: nid005937:256592:266031 [3] NCCL INFO comm 0x400674a86b00 rank 127 nRanks 128 nNodes 32 localRanks 4 localRank 3 MNNVL 0
 1: nid005576:147559:156961 [2] NCCL INFO P2P Chunksize set to 131072
31: nid005937:256590:266030 [1] NCCL INFO comm 0x400691651360 rank 125 nRanks 128 nNodes 32 localRanks 4 localRank 1 MNNVL 0
 0: nid005574:69061:78860 [3] NCCL INFO comm 0x40069964e880 rank 3 nRanks 128 nNodes 32 localRanks 4 localRank 3 MNNVL 0
 1: nid005576:147558:156960 [1] NCCL INFO Trees [0] 6/-1/-1->5->4 [1] 6/-1/-1->5->4 [2] -1/-1/-1->5->4 [3] -1/-1/-1->5->4 [4] 6/-1/-1->5->4 [5] 6/-1/-1->5->4 [6] -1/-1/-1->5->4 [7] -1/-1/-1->5->4
 1: nid005576:147558:156960 [1] NCCL INFO P2P Chunksize set to 131072
 0: nid005574:69060:78861 [2] NCCL INFO comm 0x4006b164e420 rank 2 nRanks 128 nNodes 32 localRanks 4 localRank 2 MNNVL 0
 1: nid005576:147557:156962 [0] NCCL INFO comm 0x40066d64e900 rank 4 nRanks 128 nNodes 32 localRanks 4 localRank 0 MNNVL 0
31: nid005937:256591:266028 [2] NCCL INFO Trees [0] 127/-1/-1->126->125 [1] 127/-1/-1->126->125 [2] 127/-1/-1->126->122 [3] 127/-1/-1->126->122 [4] 127/-1/-1->126->125 [5] 127/-1/-1->126->125 [6] 127/62/-1->126->-1 [7] 127/62/-1->126->-1
31: nid005937:256591:266028 [2] NCCL INFO P2P Chunksize set to 131072
31: nid005937:256592:266031 [3] NCCL INFO Trees [0] -1/-1/-1->127->126 [1] -1/-1/-1->127->126 [2] 124/-1/-1->127->126 [3] 124/-1/-1->127->126 [4] -1/-1/-1->127->126 [5] -1/-1/-1->127->126 [6] 124/-1/-1->127->126 [7] 124/-1/-1->127->126
31: nid005937:256592:266031 [3] NCCL INFO P2P Chunksize set to 131072
 0: nid005574:69059:78862 [1] NCCL INFO comm 0x4006b964e900 rank 1 nRanks 128 nNodes 32 localRanks 4 localRank 1 MNNVL 0
 0: nid005574:69058:78859 [0] NCCL INFO comm 0x400691650620 rank 0 nRanks 128 nNodes 32 localRanks 4 localRank 0 MNNVL 0
 0: nid005574:69061:78860 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] 0/-1/-1->3->2 [3] 0/-1/-1->3->2 [4] -1/-1/-1->3->2 [5] -1/-1/-1->3->2 [6] 0/-1/-1->3->2 [7] 0/-1/-1->3->2
 0: nid005574:69061:78860 [3] NCCL INFO P2P Chunksize set to 131072
30: nid005936:49911:59368 [3] NCCL INFO comm 0x40067564fd80 rank 123 nRanks 128 nNodes 32 localRanks 4 localRank 3 MNNVL 0
27: nid005922:80744:90167 [3] NCCL INFO comm 0x40068964fe00 rank 111 nRanks 128 nNodes 32 localRanks 4 localRank 3 MNNVL 0
27: nid005922:80743:90166 [2] NCCL INFO comm 0x4006b96513a0 rank 110 nRanks 128 nNodes 32 localRanks 4 localRank 2 MNNVL 0
27: nid005922:80742:90165 [1] NCCL INFO comm 0x4006996513b0 rank 109 nRanks 128 nNodes 32 localRanks 4 localRank 1 MNNVL 0
29: nid005932:167683:177110 [3] NCCL INFO comm 0x4006a1651260 rank 119 nRanks 128 nNodes 32 localRanks 4 localRank 3 MNNVL 0
 0: nid005574:69059:78862 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] -1/-1/-1->1->0 [3] -1/-1/-1->1->0 [4] 2/-1/-1->1->0 [5] 2/-1/-1->1->0 [6] -1/-1/-1->1->0 [7] -1/-1/-1->1->0
 0: nid005574:69059:78862 [1] NCCL INFO P2P Chunksize set to 131072
31: nid005937:256590:266030 [1] NCCL INFO Trees [0] 126/-1/-1->125->124 [1] 126/-1/-1->125->124 [2] -1/-1/-1->125->124 [3] -1/-1/-1->125->124 [4] 126/-1/-1->125->124 [5] 126/-1/-1->125->124 [6] -1/-1/-1->125->124 [7] -1/-1/-1->125->124
31: nid005937:256590:266030 [1] NCCL INFO P2P Chunksize set to 131072
 0: nid005574:69060:78861 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/66/-1->2->-1 [3] 3/66/-1->2->-1 [4] 3/-1/-1->2->1 [5] 3/-1/-1->2->1 [6] 3/-1/-1->2->6 [7] 3/-1/-1->2->6
 0: nid005574:69060:78861 [2] NCCL INFO P2P Chunksize set to 131072
30: nid005936:49910:59367 [2] NCCL INFO comm 0x4006b964f9d0 rank 122 nRanks 128 nNodes 32 localRanks 4 localRank 2 MNNVL 0
31: nid005937:256589:266029 [0] NCCL INFO comm 0x400699652800 rank 124 nRanks 128 nNodes 32 localRanks 4 localRank 0 MNNVL 0
26: nid005920:67126:76590 [3] NCCL INFO comm 0x40067964fd80 rank 107 nRanks 128 nNodes 32 localRanks 4 localRank 3 MNNVL 0
30: nid005936:49909:59369 [1] NCCL INFO comm 0x4006b964fdc0 rank 121 nRanks 128 nNodes 32 localRanks 4 localRank 1 MNNVL 0
29: nid005932:167682:177113 [2] NCCL INFO comm 0x400678a86760 rank 118 nRanks 128 nNodes 32 localRanks 4 localRank 2 MNNVL 0
 1: nid005576:147557:156962 [0] NCCL INFO Trees [0] 5/-1/-1->4->8 [1] 5/-1/-1->4->8 [2] 5/-1/-1->4->7 [3] 5/-1/-1->4->7 [4] 5/8/0->4->12 [5] 5/8/0->4->12 [6] 5/-1/-1->4->7 [7] 5/-1/-1->4->7
 1: nid005576:147557:156962 [0] NCCL INFO P2P Chunksize set to 131072
27: nid005922:80744:90167 [3] NCCL INFO Trees [0] -1/-1/-1->111->110 [1] -1/-1/-1->111->110 [2] 108/-1/-1->111->110 [3] 108/-1/-1->111->110 [4] -1/-1/-1->111->110 [5] -1/-1/-1->111->110 [6] 108/-1/-1->111->110 [7] 108/-1/-1->111->110
27: nid005922:80743:90166 [2] NCCL INFO Trees [0] 111/-1/-1->110->109 [1] 111/-1/-1->110->109 [2] 111/-1/-1->110->106 [3] 111/-1/-1->110->106 [4] 111/-1/-1->110->109 [5] 111/-1/-1->110->109 [6] 111/118/102->110->94 [7] 111/118/102->110->94
27: nid005922:80744:90167 [3] NCCL INFO P2P Chunksize set to 131072
27: nid005922:80742:90165 [1] NCCL INFO Trees [0] 110/-1/-1->109->108 [1] 110/-1/-1->109->108 [2] -1/-1/-1->109->108 [3] -1/-1/-1->109->108 [4] 110/-1/-1->109->108 [5] 110/-1/-1->109->108 [6] -1/-1/-1->109->108 [7] -1/-1/-1->109->108
27: nid005922:80743:90166 [2] NCCL INFO P2P Chunksize set to 131072
31: nid005937:256589:266029 [0] NCCL INFO Trees [0] 125/-1/-1->124->120 [1] 125/-1/-1->124->120 [2] 125/-1/-1->124->127 [3] 125/-1/-1->124->127 [4] 125/60/-1->124->-1 [5] 125/60/-1->124->-1 [6] 125/-1/-1->124->127 [7] 125/-1/-1->124->127
31: nid005937:256589:266029 [0] NCCL INFO P2P Chunksize set to 131072
29: nid005932:167683:177110 [3] NCCL INFO Trees [0] -1/-1/-1->119->118 [1] -1/-1/-1->119->118 [2] 116/-1/-1->119->118 [3] 116/-1/-1->119->118 [4] -1/-1/-1->119->118 [5] -1/-1/-1->119->118 [6] 116/-1/-1->119->118 [7] 116/-1/-1->119->118
29: nid005932:167683:177110 [3] NCCL INFO P2P Chunksize set to 131072
30: nid005936:49911:59368 [3] NCCL INFO Trees [0] -1/-1/-1->123->122 [1] -1/-1/-1->123->122 [2] 120/-1/-1->123->122 [3] 120/-1/-1->123->122 [4] -1/-1/-1->123->122 [5] -1/-1/-1->123->122 [6] 120/-1/-1->123->122 [7] 120/-1/-1->123->122
30: nid005936:49911:59368 [3] NCCL INFO P2P Chunksize set to 131072
30: nid005936:49910:59367 [2] NCCL INFO Trees [0] 123/-1/-1->122->121 [1] 123/-1/-1->122->121 [2] 123/118/126->122->114 [3] 123/118/126->122->114 [4] 123/-1/-1->122->121 [5] 123/-1/-1->122->121 [6] 123/-1/-1->122->118 [7] 123/-1/-1->122->118
27: nid005922:80741:90164 [0] NCCL INFO comm 0x40067964fde0 rank 108 nRanks 128 nNodes 32 localRanks 4 localRank 0 MNNVL 0
29: nid005932:167682:177113 [2] NCCL INFO Trees [0] 119/-1/-1->118->117 [1] 119/-1/-1->118->117 [2] 119/-1/-1->118->122 [3] 119/-1/-1->118->122 [4] 119/-1/-1->118->117 [5] 119/-1/-1->118->117 [6] 119/122/114->118->110 [7] 119/122/114->118->110
29: nid005932:167682:177113 [2] NCCL INFO P2P Chunksize set to 131072
26: nid005920:67125:76589 [2] NCCL INFO comm 0x400669651220 rank 106 nRanks 128 nNodes 32 localRanks 4 localRank 2 MNNVL 0
30: nid005936:49910:59367 [2] NCCL INFO P2P Chunksize set to 131072
27: nid005922:80742:90165 [1] NCCL INFO P2P Chunksize set to 131072
29: nid005932:167681:177111 [1] NCCL INFO comm 0x4006a164fdf0 rank 117 nRanks 128 nNodes 32 localRanks 4 localRank 1 MNNVL 0
26: nid005920:67126:76590 [3] NCCL INFO Trees [0] -1/-1/-1->107->106 [1] -1/-1/-1->107->106 [2] 104/-1/-1->107->106 [3] 104/-1/-1->107->106 [4] -1/-1/-1->107->106 [5] -1/-1/-1->107->106 [6] 104/-1/-1->107->106 [7] 104/-1/-1->107->106
26: nid005920:67126:76590 [3] NCCL INFO P2P Chunksize set to 131072
30: nid005936:49908:59370 [0] NCCL INFO comm 0x40057d64fe00 rank 120 nRanks 128 nNodes 32 localRanks 4 localRank 0 MNNVL 0
28: nid005929:16032:25496 [2] NCCL INFO comm 0x40069564e840 rank 114 nRanks 128 nNodes 32 localRanks 4 localRank 2 MNNVL 0
28: nid005929:16031:25497 [1] NCCL INFO comm 0x400699647100 rank 113 nRanks 128 nNodes 32 localRanks 4 localRank 1 MNNVL 0
28: nid005929:16033:25498 [3] NCCL INFO comm 0x4006b164fdc0 rank 115 nRanks 128 nNodes 32 localRanks 4 localRank 3 MNNVL 0
26: nid005920:67123:76588 [0] NCCL INFO comm 0x40069964fe00 rank 104 nRanks 128 nNodes 32 localRanks 4 localRank 0 MNNVL 0
30: nid005936:49909:59369 [1] NCCL INFO Trees [0] 122/-1/-1->121->120 [1] 122/-1/-1->121->120 [2] -1/-1/-1->121->120 [3] -1/-1/-1->121->120 [4] 122/-1/-1->121->120 [5] 122/-1/-1->121->120 [6] -1/-1/-1->121->120 [7] -1/-1/-1->121->120
30: nid005936:49909:59369 [1] NCCL INFO P2P Chunksize set to 131072
29: nid005932:167680:177112 [0] NCCL INFO comm 0x40069d64fa60 rank 116 nRanks 128 nNodes 32 localRanks 4 localRank 0 MNNVL 0
26: nid005920:67124:76591 [1] NCCL INFO comm 0x400689651260 rank 105 nRanks 128 nNodes 32 localRanks 4 localRank 1 MNNVL 0
27: nid005922:80741:90164 [0] NCCL INFO Trees [0] 109/-1/-1->108->104 [1] 109/-1/-1->108->104 [2] 109/-1/-1->108->111 [3] 109/-1/-1->108->111 [4] 109/116/100->108->92 [5] 109/116/100->108->92 [6] 109/-1/-1->108->111 [7] 109/-1/-1->108->111
27: nid005922:80741:90164 [0] NCCL INFO P2P Chunksize set to 131072
26: nid005920:67125:76589 [2] NCCL INFO Trees [0] 107/-1/-1->106->105 [1] 107/-1/-1->106->105 [2] 107/102/110->106->114 [3] 107/102/110->106->114 [4] 107/-1/-1->106->105 [5] 107/-1/-1->106->105 [6] 107/-1/-1->106->102 [7] 107/-1/-1->106->102
26: nid005920:67125:76589 [2] NCCL INFO P2P Chunksize set to 131072
25: nid005919:107465:116955 [3] NCCL INFO comm 0x40069964fe00 rank 103 nRanks 128 nNodes 32 localRanks 4 localRank 3 MNNVL 0
28: nid005929:16030:25495 [0] NCCL INFO comm 0x40066164fe00 rank 112 nRanks 128 nNodes 32 localRanks 4 localRank 0 MNNVL 0
26: nid005920:67123:76588 [0] NCCL INFO Trees [0] 105/100/108->104->112 [1] 105/100/108->104->112 [2] 105/-1/-1->104->107 [3] 105/-1/-1->104->107 [4] 105/-1/-1->104->100 [5] 105/-1/-1->104->100 [6] 105/-1/-1->104->107 [7] 105/-1/-1->104->107
26: nid005920:67123:76588 [0] NCCL INFO P2P Chunksize set to 131072
25: nid005919:107464:116954 [2] NCCL INFO comm 0x4006b564e420 rank 102 nRanks 128 nNodes 32 localRanks 4 localRank 2 MNNVL 0
28: nid005929:16032:25496 [2] NCCL INFO Trees [0] 115/-1/-1->114->113 [1] 115/-1/-1->114->113 [2] 115/106/122->114->98 [3] 115/106/122->114->98 [4] 115/-1/-1->114->113 [5] 115/-1/-1->114->113 [6] 115/-1/-1->114->118 [7] 115/-1/-1->114->118
28: nid005929:16032:25496 [2] NCCL INFO P2P Chunksize set to 131072
29: nid005932:167681:177111 [1] NCCL INFO Trees [0] 118/-1/-1->117->116 [1] 118/-1/-1->117->116 [2] -1/-1/-1->117->116 [3] -1/-1/-1->117->116 [4] 118/-1/-1->117->116 [5] 118/-1/-1->117->116 [6] -1/-1/-1->117->116 [7] -1/-1/-1->117->116
29: nid005932:167681:177111 [1] NCCL INFO P2P Chunksize set to 131072
26: nid005920:67124:76591 [1] NCCL INFO Trees [0] 106/-1/-1->105->104 [1] 106/-1/-1->105->104 [2] -1/-1/-1->105->104 [3] -1/-1/-1->105->104 [4] 106/-1/-1->105->104 [5] 106/-1/-1->105->104 [6] -1/-1/-1->105->104 [7] -1/-1/-1->105->104
25: nid005919:107463:116956 [1] NCCL INFO comm 0x40067d64fe00 rank 101 nRanks 128 nNodes 32 localRanks 4 localRank 1 MNNVL 0
25: nid005919:107465:116955 [3] NCCL INFO Trees [0] -1/-1/-1->103->102 [1] -1/-1/-1->103->102 [2] 100/-1/-1->103->102 [3] 100/-1/-1->103->102 [4] -1/-1/-1->103->102 [5] -1/-1/-1->103->102 [6] 100/-1/-1->103->102 [7] 100/-1/-1->103->102
25: nid005919:107465:116955 [3] NCCL INFO P2P Chunksize set to 131072
28: nid005929:16031:25497 [1] NCCL INFO Trees [0] 114/-1/-1->113->112 [1] 114/-1/-1->113->112 [2] -1/-1/-1->113->112 [3] -1/-1/-1->113->112 [4] 114/-1/-1->113->112 [5] 114/-1/-1->113->112 [6] -1/-1/-1->113->112 [7] -1/-1/-1->113->112
28: nid005929:16033:25498 [3] NCCL INFO Trees [0] -1/-1/-1->115->114 [1] -1/-1/-1->115->114 [2] 112/-1/-1->115->114 [3] 112/-1/-1->115->114 [4] -1/-1/-1->115->114 [5] -1/-1/-1->115->114 [6] 112/-1/-1->115->114 [7] 112/-1/-1->115->114
28: nid005929:16031:25497 [1] NCCL INFO P2P Chunksize set to 131072
26: nid005920:67124:76591 [1] NCCL INFO P2P Chunksize set to 131072
25: nid005919:107462:116957 [0] NCCL INFO comm 0x40067964fe00 rank 100 nRanks 128 nNodes 32 localRanks 4 localRank 0 MNNVL 0
30: nid005936:49908:59370 [0] NCCL INFO Trees [0] 121/116/124->120->112 [1] 121/116/124->120->112 [2] 121/-1/-1->120->123 [3] 121/-1/-1->120->123 [4] 121/-1/-1->120->116 [5] 121/-1/-1->120->116 [6] 121/-1/-1->120->123 [7] 121/-1/-1->120->123
30: nid005936:49908:59370 [0] NCCL INFO P2P Chunksize set to 131072
28: nid005929:16033:25498 [3] NCCL INFO P2P Chunksize set to 131072
29: nid005932:167680:177112 [0] NCCL INFO Trees [0] 117/-1/-1->116->120 [1] 117/-1/-1->116->120 [2] 117/-1/-1->116->119 [3] 117/-1/-1->116->119 [4] 117/120/112->116->108 [5] 117/120/112->116->108 [6] 117/-1/-1->116->119 [7] 117/-1/-1->116->119
29: nid005932:167680:177112 [0] NCCL INFO P2P Chunksize set to 131072
24: nid005918:92507:101970 [3] NCCL INFO comm 0x40069164fe00 rank 99 nRanks 128 nNodes 32 localRanks 4 localRank 3 MNNVL 0
25: nid005919:107464:116954 [2] NCCL INFO Trees [0] 103/-1/-1->102->101 [1] 103/-1/-1->102->101 [2] 103/-1/-1->102->106 [3] 103/-1/-1->102->106 [4] 103/-1/-1->102->101 [5] 103/-1/-1->102->101 [6] 103/106/98->102->110 [7] 103/106/98->102->110
25: nid005919:107464:116954 [2] NCCL INFO P2P Chunksize set to 131072
24: nid005918:92506:101973 [2] NCCL INFO comm 0x40067d6513b0 rank 98 nRanks 128 nNodes 32 localRanks 4 localRank 2 MNNVL 0
25: nid005919:107463:116956 [1] NCCL INFO Trees [0] 102/-1/-1->101->100 [1] 102/-1/-1->101->100 [2] -1/-1/-1->101->100 [3] -1/-1/-1->101->100 [4] 102/-1/-1->101->100 [5] 102/-1/-1->101->100 [6] -1/-1/-1->101->100 [7] -1/-1/-1->101->100
25: nid005919:107463:116956 [1] NCCL INFO P2P Chunksize set to 131072
25: nid005919:107462:116957 [0] NCCL INFO Trees [0] 101/-1/-1->100->104 [1] 101/-1/-1->100->104 [2] 101/-1/-1->100->103 [3] 101/-1/-1->100->103 [4] 101/104/96->100->108 [5] 101/104/96->100->108 [6] 101/-1/-1->100->103 [7] 101/-1/-1->100->103
28: nid005929:16030:25495 [0] NCCL INFO Trees [0] 113/104/120->112->96 [1] 113/104/120->112->96 [2] 113/-1/-1->112->115 [3] 113/-1/-1->112->115 [4] 113/-1/-1->112->116 [5] 113/-1/-1->112->116 [6] 113/-1/-1->112->115 [7] 113/-1/-1->112->115
28: nid005929:16030:25495 [0] NCCL INFO P2P Chunksize set to 131072
24: nid005918:92507:101970 [3] NCCL INFO Trees [0] -1/-1/-1->99->98 [1] -1/-1/-1->99->98 [2] 96/-1/-1->99->98 [3] 96/-1/-1->99->98 [4] -1/-1/-1->99->98 [5] -1/-1/-1->99->98 [6] 96/-1/-1->99->98 [7] 96/-1/-1->99->98
24: nid005918:92507:101970 [3] NCCL INFO P2P Chunksize set to 131072
25: nid005919:107462:116957 [0] NCCL INFO P2P Chunksize set to 131072
23: nid005917:276888:286343 [3] NCCL INFO comm 0x40069d6513b0 rank 95 nRanks 128 nNodes 32 localRanks 4 localRank 3 MNNVL 0
24: nid005918:92506:101973 [2] NCCL INFO Trees [0] 99/-1/-1->98->97 [1] 99/-1/-1->98->97 [2] 99/82/114->98->66 [3] 99/82/114->98->66 [4] 99/-1/-1->98->97 [5] 99/-1/-1->98->97 [6] 99/-1/-1->98->102 [7] 99/-1/-1->98->102
24: nid005918:92506:101973 [2] NCCL INFO P2P Chunksize set to 131072
24: nid005918:92505:101972 [1] NCCL INFO comm 0x4006a564fdf0 rank 97 nRanks 128 nNodes 32 localRanks 4 localRank 1 MNNVL 0
24: nid005918:92504:101971 [0] NCCL INFO comm 0x40066d64fe00 rank 96 nRanks 128 nNodes 32 localRanks 4 localRank 0 MNNVL 0
23: nid005917:276887:286344 [2] NCCL INFO comm 0x40068d64e900 rank 94 nRanks 128 nNodes 32 localRanks 4 localRank 2 MNNVL 0
23: nid005917:276888:286343 [3] NCCL INFO Trees [0] -1/-1/-1->95->94 [1] -1/-1/-1->95->94 [2] 92/-1/-1->95->94 [3] 92/-1/-1->95->94 [4] -1/-1/-1->95->94 [5] -1/-1/-1->95->94 [6] 92/-1/-1->95->94 [7] 92/-1/-1->95->94
24: nid005918:92505:101972 [1] NCCL INFO Trees [0] 98/-1/-1->97->96 [1] 98/-1/-1->97->96 [2] -1/-1/-1->97->96 [3] -1/-1/-1->97->96 [4] 98/-1/-1->97->96 [5] 98/-1/-1->97->96 [6] -1/-1/-1->97->96 [7] -1/-1/-1->97->96
24: nid005918:92504:101971 [0] NCCL INFO Trees [0] 97/80/112->96->64 [1] 97/80/112->96->64 [2] 97/-1/-1->96->99 [3] 97/-1/-1->96->99 [4] 97/-1/-1->96->100 [5] 97/-1/-1->96->100 [6] 97/-1/-1->96->99 [7] 97/-1/-1->96->99
24: nid005918:92505:101972 [1] NCCL INFO P2P Chunksize set to 131072
24: nid005918:92504:101971 [0] NCCL INFO P2P Chunksize set to 131072
23: nid005917:276888:286343 [3] NCCL INFO P2P Chunksize set to 131072
23: nid005917:276887:286344 [2] NCCL INFO Trees [0] 95/-1/-1->94->93 [1] 95/-1/-1->94->93 [2] 95/-1/-1->94->90 [3] 95/-1/-1->94->90 [4] 95/-1/-1->94->93 [5] 95/-1/-1->94->93 [6] 95/110/78->94->62 [7] 95/110/78->94->62
23: nid005917:276887:286344 [2] NCCL INFO P2P Chunksize set to 131072
22: nid005915:274817:284251 [3] NCCL INFO comm 0x4006ad651330 rank 91 nRanks 128 nNodes 32 localRanks 4 localRank 3 MNNVL 0
23: nid005917:276886:286341 [1] NCCL INFO comm 0x40068164fb30 rank 93 nRanks 128 nNodes 32 localRanks 4 localRank 1 MNNVL 0
22: nid005915:274816:284254 [2] NCCL INFO comm 0x4006a96513b0 rank 90 nRanks 128 nNodes 32 localRanks 4 localRank 2 MNNVL 0
23: nid005917:276885:286342 [0] NCCL INFO comm 0x400668a73790 rank 92 nRanks 128 nNodes 32 localRanks 4 localRank 0 MNNVL 0
22: nid005915:274817:284251 [3] NCCL INFO Trees [0] -1/-1/-1->91->90 [1] -1/-1/-1->91->90 [2] 88/-1/-1->91->90 [3] 88/-1/-1->91->90 [4] -1/-1/-1->91->90 [5] -1/-1/-1->91->90 [6] 88/-1/-1->91->90 [7] 88/-1/-1->91->90
22: nid005915:274817:284251 [3] NCCL INFO P2P Chunksize set to 131072
23: nid005917:276886:286341 [1] NCCL INFO Trees [0] 94/-1/-1->93->92 [1] 94/-1/-1->93->92 [2] -1/-1/-1->93->92 [3] -1/-1/-1->93->92 [4] 94/-1/-1->93->92 [5] 94/-1/-1->93->92 [6] -1/-1/-1->93->92 [7] -1/-1/-1->93->92
23: nid005917:276885:286342 [0] NCCL INFO Trees [0] 93/-1/-1->92->88 [1] 93/-1/-1->92->88 [2] 93/-1/-1->92->95 [3] 93/-1/-1->92->95 [4] 93/108/76->92->60 [5] 93/108/76->92->60 [6] 93/-1/-1->92->95 [7] 93/-1/-1->92->95
23: nid005917:276886:286341 [1] NCCL INFO P2P Chunksize set to 131072
23: nid005917:276885:286342 [0] NCCL INFO P2P Chunksize set to 131072
22: nid005915:274816:284254 [2] NCCL INFO Trees [0] 91/-1/-1->90->89 [1] 91/-1/-1->90->89 [2] 91/86/94->90->82 [3] 91/86/94->90->82 [4] 91/-1/-1->90->89 [5] 91/-1/-1->90->89 [6] 91/-1/-1->90->86 [7] 91/-1/-1->90->86
22: nid005915:274816:284254 [2] NCCL INFO P2P Chunksize set to 131072
22: nid005915:274815:284252 [1] NCCL INFO comm 0x40069d64f9d0 rank 89 nRanks 128 nNodes 32 localRanks 4 localRank 1 MNNVL 0
22: nid005915:274814:284253 [0] NCCL INFO comm 0x40067d64fe00 rank 88 nRanks 128 nNodes 32 localRanks 4 localRank 0 MNNVL 0
21: nid005914:166787:176211 [3] NCCL INFO comm 0x40069964fe00 rank 87 nRanks 128 nNodes 32 localRanks 4 localRank 3 MNNVL 0
21: nid005914:166786:176213 [2] NCCL INFO comm 0x40068564fdf0 rank 86 nRanks 128 nNodes 32 localRanks 4 localRank 2 MNNVL 0
22: nid005915:274815:284252 [1] NCCL INFO Trees [0] 90/-1/-1->89->88 [1] 90/-1/-1->89->88 [2] -1/-1/-1->89->88 [3] -1/-1/-1->89->88 [4] 90/-1/-1->89->88 [5] 90/-1/-1->89->88 [6] -1/-1/-1->89->88 [7] -1/-1/-1->89->88
22: nid005915:274815:284252 [1] NCCL INFO P2P Chunksize set to 131072
21: nid005914:166787:176211 [3] NCCL INFO Trees [0] -1/-1/-1->87->86 [1] -1/-1/-1->87->86 [2] 84/-1/-1->87->86 [3] 84/-1/-1->87->86 [4] -1/-1/-1->87->86 [5] -1/-1/-1->87->86 [6] 84/-1/-1->87->86 [7] 84/-1/-1->87->86
21: nid005914:166787:176211 [3] NCCL INFO P2P Chunksize set to 131072
20: nid005913:292684:9581 [3] NCCL INFO comm 0x40069164e900 rank 83 nRanks 128 nNodes 32 localRanks 4 localRank 3 MNNVL 0
22: nid005915:274814:284253 [0] NCCL INFO Trees [0] 89/84/92->88->80 [1] 89/84/92->88->80 [2] 89/-1/-1->88->91 [3] 89/-1/-1->88->91 [4] 89/-1/-1->88->84 [5] 89/-1/-1->88->84 [6] 89/-1/-1->88->91 [7] 89/-1/-1->88->91
22: nid005915:274814:284253 [0] NCCL INFO P2P Chunksize set to 131072
21: nid005914:166786:176213 [2] NCCL INFO Trees [0] 87/-1/-1->86->85 [1] 87/-1/-1->86->85 [2] 87/-1/-1->86->90 [3] 87/-1/-1->86->90 [4] 87/-1/-1->86->85 [5] 87/-1/-1->86->85 [6] 87/90/82->86->78 [7] 87/90/82->86->78
21: nid005914:166786:176213 [2] NCCL INFO P2P Chunksize set to 131072
21: nid005914:166785:176214 [1] NCCL INFO comm 0x400689651260 rank 85 nRanks 128 nNodes 32 localRanks 4 localRank 1 MNNVL 0
20: nid005913:292684:9581 [3] NCCL INFO Trees [0] -1/-1/-1->83->82 [1] -1/-1/-1->83->82 [2] 80/-1/-1->83->82 [3] 80/-1/-1->83->82 [4] -1/-1/-1->83->82 [5] -1/-1/-1->83->82 [6] 80/-1/-1->83->82 [7] 80/-1/-1->83->82
20: nid005913:292684:9581 [3] NCCL INFO P2P Chunksize set to 131072
21: nid005914:166784:176212 [0] NCCL INFO comm 0x4006a164fe00 rank 84 nRanks 128 nNodes 32 localRanks 4 localRank 0 MNNVL 0
21: nid005914:166784:176212 [0] NCCL INFO Trees [0] 85/-1/-1->84->88 [1] 85/-1/-1->84->88 [2] 85/-1/-1->84->87 [3] 85/-1/-1->84->87 [4] 85/88/80->84->76 [5] 85/88/80->84->76 [6] 85/-1/-1->84->87 [7] 85/-1/-1->84->87
21: nid005914:166784:176212 [0] NCCL INFO P2P Chunksize set to 131072
21: nid005914:166785:176214 [1] NCCL INFO Trees [0] 86/-1/-1->85->84 [1] 86/-1/-1->85->84 [2] -1/-1/-1->85->84 [3] -1/-1/-1->85->84 [4] 86/-1/-1->85->84 [5] 86/-1/-1->85->84 [6] -1/-1/-1->85->84 [7] -1/-1/-1->85->84
21: nid005914:166785:176214 [1] NCCL INFO P2P Chunksize set to 131072
 0: nid005574:69058:78859 [0] NCCL INFO Channel 00/08 :    0   1   2   3   7   6   5   4   8   9  10  11  15  14  13  12  16  17  18  19
20: nid005913:292683:9579 [2] NCCL INFO comm 0x40069564fdf0 rank 82 nRanks 128 nNodes 32 localRanks 4 localRank 2 MNNVL 0
20: nid005913:292682:9578 [1] NCCL INFO comm 0x40066964fdf0 rank 81 nRanks 128 nNodes 32 localRanks 4 localRank 1 MNNVL 0
 0: nid005574:69058:78859 [0] NCCL INFO Channel 01/08 :    0   4   5   6   7  11  10   9   8  12  13  14  15  19  18  17  16  20  21  22
19: nid005912:12438:21868 [3] NCCL INFO comm 0x40069964fe00 rank 79 nRanks 128 nNodes 32 localRanks 4 localRank 3 MNNVL 0
20: nid005913:292683:9579 [2] NCCL INFO Trees [0] 83/-1/-1->82->81 [1] 83/-1/-1->82->81 [2] 83/74/90->82->98 [3] 83/74/90->82->98 [4] 83/-1/-1->82->81 [5] 83/-1/-1->82->81 [6] 83/-1/-1->82->86 [7] 83/-1/-1->82->86
20: nid005913:292683:9579 [2] NCCL INFO P2P Chunksize set to 131072
19: nid005912:12437:21866 [2] NCCL INFO comm 0x4006a964fe00 rank 78 nRanks 128 nNodes 32 localRanks 4 localRank 2 MNNVL 0
19: nid005912:12436:21867 [1] NCCL INFO comm 0x40067964fe00 rank 77 nRanks 128 nNodes 32 localRanks 4 localRank 1 MNNVL 0
20: nid005913:292682:9578 [1] NCCL INFO Trees [0] 82/-1/-1->81->80 [1] 82/-1/-1->81->80 [2] -1/-1/-1->81->80 [3] -1/-1/-1->81->80 [4] 82/-1/-1->81->80 [5] 82/-1/-1->81->80 [6] -1/-1/-1->81->80 [7] -1/-1/-1->81->80
20: nid005913:292682:9578 [1] NCCL INFO P2P Chunksize set to 131072
19: nid005912:12438:21868 [3] NCCL INFO Trees [0] -1/-1/-1->79->78 [1] -1/-1/-1->79->78 [2] 76/-1/-1->79->78 [3] 76/-1/-1->79->78 [4] -1/-1/-1->79->78 [5] -1/-1/-1->79->78 [6] 76/-1/-1->79->78 [7] 76/-1/-1->79->78
19: nid005912:12438:21868 [3] NCCL INFO P2P Chunksize set to 131072
18: nid005911:38867:48329 [3] NCCL INFO comm 0x40068964e420 rank 75 nRanks 128 nNodes 32 localRanks 4 localRank 3 MNNVL 0
19: nid005912:12437:21866 [2] NCCL INFO Trees [0] 79/-1/-1->78->77 [1] 79/-1/-1->78->77 [2] 79/-1/-1->78->74 [3] 79/-1/-1->78->74 [4] 79/-1/-1->78->77 [5] 79/-1/-1->78->77 [6] 79/86/70->78->94 [7] 79/86/70->78->94
19: nid005912:12437:21866 [2] NCCL INFO P2P Chunksize set to 131072
19: nid005912:12436:21867 [1] NCCL INFO Trees [0] 78/-1/-1->77->76 [1] 78/-1/-1->77->76 [2] -1/-1/-1->77->76 [3] -1/-1/-1->77->76 [4] 78/-1/-1->77->76 [5] 78/-1/-1->77->76 [6] -1/-1/-1->77->76 [7] -1/-1/-1->77->76
18: nid005911:38866:48328 [2] NCCL INFO comm 0x4006ad64e900 rank 74 nRanks 128 nNodes 32 localRanks 4 localRank 2 MNNVL 0
19: nid005912:12436:21867 [1] NCCL INFO P2P Chunksize set to 131072
20: nid005913:292681:9580 [0] NCCL INFO comm 0x40069564fe00 rank 80 nRanks 128 nNodes 32 localRanks 4 localRank 0 MNNVL 0
18: nid005911:38867:48329 [3] NCCL INFO Trees [0] -1/-1/-1->75->74 [1] -1/-1/-1->75->74 [2] 72/-1/-1->75->74 [3] 72/-1/-1->75->74 [4] -1/-1/-1->75->74 [5] -1/-1/-1->75->74 [6] 72/-1/-1->75->74 [7] 72/-1/-1->75->74
18: nid005911:38867:48329 [3] NCCL INFO P2P Chunksize set to 131072
17: nid005803:180735:190221 [3] NCCL INFO comm 0x4006896513a0 rank 71 nRanks 128 nNodes 32 localRanks 4 localRank 3 MNNVL 0
18: nid005911:38866:48328 [2] NCCL INFO Trees [0] 75/-1/-1->74->73 [1] 75/-1/-1->74->73 [2] 75/70/78->74->82 [3] 75/70/78->74->82 [4] 75/-1/-1->74->73 [5] 75/-1/-1->74->73 [6] 75/-1/-1->74->70 [7] 75/-1/-1->74->70
18: nid005911:38865:48327 [1] NCCL INFO comm 0x40068564e900 rank 73 nRanks 128 nNodes 32 localRanks 4 localRank 1 MNNVL 0
18: nid005911:38866:48328 [2] NCCL INFO P2P Chunksize set to 131072
18: nid005911:38864:48326 [0] NCCL INFO comm 0x40068964fdf0 rank 72 nRanks 128 nNodes 32 localRanks 4 localRank 0 MNNVL 0
17: nid005803:180733:190220 [1] NCCL INFO comm 0x40069164fa60 rank 69 nRanks 128 nNodes 32 localRanks 4 localRank 1 MNNVL 0
17: nid005803:180734:190219 [2] NCCL INFO comm 0x40068564fe00 rank 70 nRanks 128 nNodes 32 localRanks 4 localRank 2 MNNVL 0
19: nid005912:12435:21865 [0] NCCL INFO comm 0x40066d64e900 rank 76 nRanks 128 nNodes 32 localRanks 4 localRank 0 MNNVL 0
18: nid005911:38865:48327 [1] NCCL INFO Trees [0] 74/-1/-1->73->72 [1] 74/-1/-1->73->72 [2] -1/-1/-1->73->72 [3] -1/-1/-1->73->72 [4] 74/-1/-1->73->72 [5] 74/-1/-1->73->72 [6] -1/-1/-1->73->72 [7] -1/-1/-1->73->72
18: nid005911:38865:48327 [1] NCCL INFO P2P Chunksize set to 131072
18: nid005911:38864:48326 [0] NCCL INFO Trees [0] 73/68/76->72->80 [1] 73/68/76->72->80 [2] 73/-1/-1->72->75 [3] 73/-1/-1->72->75 [4] 73/-1/-1->72->68 [5] 73/-1/-1->72->68 [6] 73/-1/-1->72->75 [7] 73/-1/-1->72->75
18: nid005911:38864:48326 [0] NCCL INFO P2P Chunksize set to 131072
17: nid005803:180733:190220 [1] NCCL INFO Trees [0] 70/-1/-1->69->68 [1] 70/-1/-1->69->68 [2] -1/-1/-1->69->68 [3] -1/-1/-1->69->68 [4] 70/-1/-1->69->68 [5] 70/-1/-1->69->68 [6] -1/-1/-1->69->68 [7] -1/-1/-1->69->68
17: nid005803:180735:190221 [3] NCCL INFO Trees [0] -1/-1/-1->71->70 [1] -1/-1/-1->71->70 [2] 68/-1/-1->71->70 [3] 68/-1/-1->71->70 [4] -1/-1/-1->71->70 [5] -1/-1/-1->71->70 [6] 68/-1/-1->71->70 [7] 68/-1/-1->71->70
17: nid005803:180733:190220 [1] NCCL INFO P2P Chunksize set to 131072
17: nid005803:180735:190221 [3] NCCL INFO P2P Chunksize set to 131072
20: nid005913:292681:9580 [0] NCCL INFO Trees [0] 81/72/88->80->96 [1] 81/72/88->80->96 [2] 81/-1/-1->80->83 [3] 81/-1/-1->80->83 [4] 81/-1/-1->80->84 [5] 81/-1/-1->80->84 [6] 81/-1/-1->80->83 [7] 81/-1/-1->80->83
20: nid005913:292681:9580 [0] NCCL INFO P2P Chunksize set to 131072
16: nid005802:6300:15924 [3] NCCL INFO comm 0x40069164fe00 rank 67 nRanks 128 nNodes 32 localRanks 4 localRank 3 MNNVL 0
17: nid005803:180734:190219 [2] NCCL INFO Trees [0] 71/-1/-1->70->69 [1] 71/-1/-1->70->69 [2] 71/-1/-1->70->74 [3] 71/-1/-1->70->74 [4] 71/-1/-1->70->69 [5] 71/-1/-1->70->69 [6] 71/74/66->70->78 [7] 71/74/66->70->78
17: nid005803:180732:190218 [0] NCCL INFO comm 0x400681651260 rank 68 nRanks 128 nNodes 32 localRanks 4 localRank 0 MNNVL 0
17: nid005803:180734:190219 [2] NCCL INFO P2P Chunksize set to 131072
16: nid005802:6299:15922 [2] NCCL INFO comm 0x4006ad650f90 rank 66 nRanks 128 nNodes 32 localRanks 4 localRank 2 MNNVL 0
17: nid005803:180732:190218 [0] NCCL INFO Trees [0] 69/-1/-1->68->72 [1] 69/-1/-1->68->72 [2] 69/-1/-1->68->71 [3] 69/-1/-1->68->71 [4] 69/72/64->68->76 [5] 69/72/64->68->76 [6] 69/-1/-1->68->71 [7] 69/-1/-1->68->71
17: nid005803:180732:190218 [0] NCCL INFO P2P Chunksize set to 131072
19: nid005912:12435:21865 [0] NCCL INFO Trees [0] 77/-1/-1->76->72 [1] 77/-1/-1->76->72 [2] 77/-1/-1->76->79 [3] 77/-1/-1->76->79 [4] 77/84/68->76->92 [5] 77/84/68->76->92 [6] 77/-1/-1->76->79 [7] 77/-1/-1->76->79
19: nid005912:12435:21865 [0] NCCL INFO P2P Chunksize set to 131072
16: nid005802:6300:15924 [3] NCCL INFO Trees [0] -1/-1/-1->67->66 [1] -1/-1/-1->67->66 [2] 64/-1/-1->67->66 [3] 64/-1/-1->67->66 [4] -1/-1/-1->67->66 [5] -1/-1/-1->67->66 [6] 64/-1/-1->67->66 [7] 64/-1/-1->67->66
16: nid005802:6299:15922 [2] NCCL INFO Trees [0] 67/-1/-1->66->65 [1] 67/-1/-1->66->65 [2] 67/34/98->66->2 [3] 67/34/98->66->2 [4] 67/-1/-1->66->65 [5] 67/-1/-1->66->65 [6] 67/-1/-1->66->70 [7] 67/-1/-1->66->70
16: nid005802:6300:15924 [3] NCCL INFO P2P Chunksize set to 131072
16: nid005802:6299:15922 [2] NCCL INFO P2P Chunksize set to 131072
16: nid005802:6298:15921 [1] NCCL INFO comm 0x40069964e900 rank 65 nRanks 128 nNodes 32 localRanks 4 localRank 1 MNNVL 0
15: nid005601:210679:220215 [3] NCCL INFO comm 0x4006ad64fdf0 rank 63 nRanks 128 nNodes 32 localRanks 4 localRank 3 MNNVL 0
15: nid005601:210678:220212 [2] NCCL INFO comm 0x40068d6528c0 rank 62 nRanks 128 nNodes 32 localRanks 4 localRank 2 MNNVL 0
16: nid005802:6297:15923 [0] NCCL INFO comm 0x400669651260 rank 64 nRanks 128 nNodes 32 localRanks 4 localRank 0 MNNVL 0
16: nid005802:6298:15921 [1] NCCL INFO Trees [0] 66/-1/-1->65->64 [1] 66/-1/-1->65->64 [2] -1/-1/-1->65->64 [3] -1/-1/-1->65->64 [4] 66/-1/-1->65->64 [5] 66/-1/-1->65->64 [6] -1/-1/-1->65->64 [7] -1/-1/-1->65->64
16: nid005802:6298:15921 [1] NCCL INFO P2P Chunksize set to 131072
12: nid005594:53087:62559 [2] NCCL INFO comm 0x40068164e880 rank 50 nRanks 128 nNodes 32 localRanks 4 localRank 2 MNNVL 0
12: nid005594:53088:62557 [3] NCCL INFO comm 0x40068164fe00 rank 51 nRanks 128 nNodes 32 localRanks 4 localRank 3 MNNVL 0
12: nid005594:53086:62556 [1] NCCL INFO comm 0x40067164fdf0 rank 49 nRanks 128 nNodes 32 localRanks 4 localRank 1 MNNVL 0
15: nid005601:210679:220215 [3] NCCL INFO Trees [0] -1/-1/-1->63->62 [1] -1/-1/-1->63->62 [2] 60/-1/-1->63->62 [3] 60/-1/-1->63->62 [4] -1/-1/-1->63->62 [5] -1/-1/-1->63->62 [6] 60/-1/-1->63->62 [7] 60/-1/-1->63->62
15: nid005601:210678:220212 [2] NCCL INFO Trees [0] 63/-1/-1->62->61 [1] 63/-1/-1->62->61 [2] 63/-1/-1->62->58 [3] 63/-1/-1->62->58 [4] 63/-1/-1->62->61 [5] 63/-1/-1->62->61 [6] 63/94/30->62->126 [7] 63/94/30->62->126
15: nid005601:210679:220215 [3] NCCL INFO P2P Chunksize set to 131072
15: nid005601:210678:220212 [2] NCCL INFO P2P Chunksize set to 131072
 0: nid005574:69058:78859 [0] NCCL INFO Channel 02/08 :    0   3   1   5   4   7   6  10   8  11   9  13  12  15  14  18  16  19  17  21
16: nid005802:6297:15923 [0] NCCL INFO Trees [0] 65/32/96->64->0 [1] 65/32/96->64->0 [2] 65/-1/-1->64->67 [3] 65/-1/-1->64->67 [4] 65/-1/-1->64->68 [5] 65/-1/-1->64->68 [6] 65/-1/-1->64->67 [7] 65/-1/-1->64->67
16: nid005802:6297:15923 [0] NCCL INFO P2P Chunksize set to 131072
15: nid005601:210677:220213 [1] NCCL INFO comm 0x40068d64fdf0 rank 61 nRanks 128 nNodes 32 localRanks 4 localRank 1 MNNVL 0
11: nid005591:191606:202312 [3] NCCL INFO comm 0x40069164fb20 rank 47 nRanks 128 nNodes 32 localRanks 4 localRank 3 MNNVL 0
11: nid005591:191605:202311 [2] NCCL INFO comm 0x4006b56513b0 rank 46 nRanks 128 nNodes 32 localRanks 4 localRank 2 MNNVL 0
 8: nid005586:68929:78411 [3] NCCL INFO comm 0x4006b8a880b0 rank 35 nRanks 128 nNodes 32 localRanks 4 localRank 3 MNNVL 0
 8: nid005586:68928:78413 [2] NCCL INFO comm 0x4006a964f980 rank 34 nRanks 128 nNodes 32 localRanks 4 localRank 2 MNNVL 0
12: nid005594:53087:62559 [2] NCCL INFO Trees [0] 51/-1/-1->50->49 [1] 51/-1/-1->50->49 [2] 51/42/58->50->34 [3] 51/42/58->50->34 [4] 51/-1/-1->50->49 [5] 51/-1/-1->50->49 [6] 51/-1/-1->50->54 [7] 51/-1/-1->50->54
12: nid005594:53087:62559 [2] NCCL INFO P2P Chunksize set to 131072
12: nid005594:53088:62557 [3] NCCL INFO Trees [0] -1/-1/-1->51->50 [1] -1/-1/-1->51->50 [2] 48/-1/-1->51->50 [3] 48/-1/-1->51->50 [4] -1/-1/-1->51->50 [5] -1/-1/-1->51->50 [6] 48/-1/-1->51->50 [7] 48/-1/-1->51->50
15: nid005601:210676:220214 [0] NCCL INFO comm 0x40068164fe00 rank 60 nRanks 128 nNodes 32 localRanks 4 localRank 0 MNNVL 0
14: nid005600:217723:227284 [3] NCCL INFO comm 0x4006bd64e900 rank 59 nRanks 128 nNodes 32 localRanks 4 localRank 3 MNNVL 0
14: nid005600:217722:227283 [2] NCCL INFO comm 0x40068d6513b0 rank 58 nRanks 128 nNodes 32 localRanks 4 localRank 2 MNNVL 0
12: nid005594:53088:62557 [3] NCCL INFO P2P Chunksize set to 131072
12: nid005594:53086:62556 [1] NCCL INFO Trees [0] 50/-1/-1->49->48 [1] 50/-1/-1->49->48 [2] -1/-1/-1->49->48 [3] -1/-1/-1->49->48 [4] 50/-1/-1->49->48 [5] 50/-1/-1->49->48 [6] -1/-1/-1->49->48 [7] -1/-1/-1->49->48
12: nid005594:53085:62558 [0] NCCL INFO comm 0x40068d64fb30 rank 48 nRanks 128 nNodes 32 localRanks 4 localRank 0 MNNVL 0
 7: nid005585:122008:131402 [3] NCCL INFO comm 0x4006956513a0 rank 31 nRanks 128 nNodes 32 localRanks 4 localRank 3 MNNVL 0
 8: nid005586:68927:78410 [1] NCCL INFO comm 0x40066ca89660 rank 33 nRanks 128 nNodes 32 localRanks 4 localRank 1 MNNVL 0
 8: nid005586:68926:78412 [0] NCCL INFO comm 0x400665651220 rank 32 nRanks 128 nNodes 32 localRanks 4 localRank 0 MNNVL 0
14: nid005600:217721:227286 [1] NCCL INFO comm 0x400679651260 rank 57 nRanks 128 nNodes 32 localRanks 4 localRank 1 MNNVL 0
11: nid005591:191606:202312 [3] NCCL INFO Trees [0] -1/-1/-1->47->46 [1] -1/-1/-1->47->46 [2] 44/-1/-1->47->46 [3] 44/-1/-1->47->46 [4] -1/-1/-1->47->46 [5] -1/-1/-1->47->46 [6] 44/-1/-1->47->46 [7] 44/-1/-1->47->46
11: nid005591:191606:202312 [3] NCCL INFO P2P Chunksize set to 131072
11: nid005591:191605:202311 [2] NCCL INFO Trees [0] 47/-1/-1->46->45 [1] 47/-1/-1->46->45 [2] 47/-1/-1->46->42 [3] 47/-1/-1->46->42 [4] 47/-1/-1->46->45 [5] 47/-1/-1->46->45 [6] 47/54/38->46->30 [7] 47/54/38->46->30
12: nid005594:53086:62556 [1] NCCL INFO P2P Chunksize set to 131072
15: nid005601:210677:220213 [1] NCCL INFO Trees [0] 62/-1/-1->61->60 [1] 62/-1/-1->61->60 [2] -1/-1/-1->61->60 [3] -1/-1/-1->61->60 [4] 62/-1/-1->61->60 [5] 62/-1/-1->61->60 [6] -1/-1/-1->61->60 [7] -1/-1/-1->61->60
15: nid005601:210676:220214 [0] NCCL INFO Trees [0] 61/-1/-1->60->56 [1] 61/-1/-1->60->56 [2] 61/-1/-1->60->63 [3] 61/-1/-1->60->63 [4] 61/92/28->60->124 [5] 61/92/28->60->124 [6] 61/-1/-1->60->63 [7] 61/-1/-1->60->63
15: nid005601:210677:220213 [1] NCCL INFO P2P Chunksize set to 131072
15: nid005601:210676:220214 [0] NCCL INFO P2P Chunksize set to 131072
 8: nid005586:68928:78413 [2] NCCL INFO Trees [0] 35/-1/-1->34->33 [1] 35/-1/-1->34->33 [2] 35/18/50->34->66 [3] 35/18/50->34->66 [4] 35/-1/-1->34->33 [5] 35/-1/-1->34->33 [6] 35/-1/-1->34->38 [7] 35/-1/-1->34->38
 8: nid005586:68929:78411 [3] NCCL INFO Trees [0] -1/-1/-1->35->34 [1] -1/-1/-1->35->34 [2] 32/-1/-1->35->34 [3] 32/-1/-1->35->34 [4] -1/-1/-1->35->34 [5] -1/-1/-1->35->34 [6] 32/-1/-1->35->34 [7] 32/-1/-1->35->34
 8: nid005586:68928:78413 [2] NCCL INFO P2P Chunksize set to 131072
 8: nid005586:68929:78411 [3] NCCL INFO P2P Chunksize set to 131072
14: nid005600:217720:227285 [0] NCCL INFO comm 0x40066964fdc0 rank 56 nRanks 128 nNodes 32 localRanks 4 localRank 0 MNNVL 0
 7: nid005585:122007:131403 [2] NCCL INFO comm 0x4006b564fe00 rank 30 nRanks 128 nNodes 32 localRanks 4 localRank 2 MNNVL 0
 8: nid005586:68926:78412 [0] NCCL INFO Trees [0] 33/16/48->32->64 [1] 33/16/48->32->64 [2] 33/-1/-1->32->35 [3] 33/-1/-1->32->35 [4] 33/-1/-1->32->36 [5] 33/-1/-1->32->36 [6] 33/-1/-1->32->35 [7] 33/-1/-1->32->35
 8: nid005586:68926:78412 [0] NCCL INFO P2P Chunksize set to 131072
14: nid005600:217723:227284 [3] NCCL INFO Trees [0] -1/-1/-1->59->58 [1] -1/-1/-1->59->58 [2] 56/-1/-1->59->58 [3] 56/-1/-1->59->58 [4] -1/-1/-1->59->58 [5] -1/-1/-1->59->58 [6] 56/-1/-1->59->58 [7] 56/-1/-1->59->58
14: nid005600:217722:227283 [2] NCCL INFO Trees [0] 59/-1/-1->58->57 [1] 59/-1/-1->58->57 [2] 59/54/62->58->50 [3] 59/54/62->58->50 [4] 59/-1/-1->58->57 [5] 59/-1/-1->58->57 [6] 59/-1/-1->58->54 [7] 59/-1/-1->58->54
14: nid005600:217722:227283 [2] NCCL INFO P2P Chunksize set to 131072
14: nid005600:217723:227284 [3] NCCL INFO P2P Chunksize set to 131072
10: nid005590:110713:120120 [3] NCCL INFO comm 0x4006a9653dc0 rank 43 nRanks 128 nNodes 32 localRanks 4 localRank 3 MNNVL 0
10: nid005590:110712:120119 [2] NCCL INFO comm 0x40069d64e3d0 rank 42 nRanks 128 nNodes 32 localRanks 4 localRank 2 MNNVL 0
 9: nid005588:35936:45406 [1] NCCL INFO comm 0x400698a89620 rank 37 nRanks 128 nNodes 32 localRanks 4 localRank 1 MNNVL 0
 9: nid005588:35937:45405 [2] NCCL INFO comm 0x40068d64fe00 rank 38 nRanks 128 nNodes 32 localRanks 4 localRank 2 MNNVL 0
 9: nid005588:35938:45404 [3] NCCL INFO comm 0x40069164fe00 rank 39 nRanks 128 nNodes 32 localRanks 4 localRank 3 MNNVL 0
 9: nid005588:35935:45407 [0] NCCL INFO comm 0x40065964fd80 rank 36 nRanks 128 nNodes 32 localRanks 4 localRank 0 MNNVL 0
 7: nid005585:122008:131402 [3] NCCL INFO Trees [0] -1/-1/-1->31->30 [1] -1/-1/-1->31->30 [2] 28/-1/-1->31->30 [3] 28/-1/-1->31->30 [4] -1/-1/-1->31->30 [5] -1/-1/-1->31->30 [6] 28/-1/-1->31->30 [7] 28/-1/-1->31->30
13: nid005595:197886:207693 [3] NCCL INFO comm 0x40069164e840 rank 55 nRanks 128 nNodes 32 localRanks 4 localRank 3 MNNVL 0
 8: nid005586:68927:78410 [1] NCCL INFO Trees [0] 34/-1/-1->33->32 [1] 34/-1/-1->33->32 [2] -1/-1/-1->33->32 [3] -1/-1/-1->33->32 [4] 34/-1/-1->33->32 [5] 34/-1/-1->33->32 [6] -1/-1/-1->33->32 [7] -1/-1/-1->33->32
 8: nid005586:68927:78410 [1] NCCL INFO P2P Chunksize set to 131072
11: nid005591:191605:202311 [2] NCCL INFO P2P Chunksize set to 131072
12: nid005594:53085:62558 [0] NCCL INFO Trees [0] 49/40/56->48->32 [1] 49/40/56->48->32 [2] 49/-1/-1->48->51 [3] 49/-1/-1->48->51 [4] 49/-1/-1->48->52 [5] 49/-1/-1->48->52 [6] 49/-1/-1->48->51 [7] 49/-1/-1->48->51
12: nid005594:53085:62558 [0] NCCL INFO P2P Chunksize set to 131072
 9: nid005588:35936:45406 [1] NCCL INFO Trees [0] 38/-1/-1->37->36 [1] 38/-1/-1->37->36 [2] -1/-1/-1->37->36 [3] -1/-1/-1->37->36 [4] 38/-1/-1->37->36 [5] 38/-1/-1->37->36 [6] -1/-1/-1->37->36 [7] -1/-1/-1->37->36
 9: nid005588:35936:45406 [1] NCCL INFO P2P Chunksize set to 131072
 7: nid005585:122008:131402 [3] NCCL INFO P2P Chunksize set to 131072
 7: nid005585:122006:131404 [1] NCCL INFO comm 0x4006716513b0 rank 29 nRanks 128 nNodes 32 localRanks 4 localRank 1 MNNVL 0
13: nid005595:197883:207694 [0] NCCL INFO comm 0x40068164e880 rank 52 nRanks 128 nNodes 32 localRanks 4 localRank 0 MNNVL 0
13: nid005595:197884:207691 [1] NCCL INFO comm 0x40068d64e840 rank 53 nRanks 128 nNodes 32 localRanks 4 localRank 1 MNNVL 0
14: nid005600:217721:227286 [1] NCCL INFO Trees [0] 58/-1/-1->57->56 [1] 58/-1/-1->57->56 [2] -1/-1/-1->57->56 [3] -1/-1/-1->57->56 [4] 58/-1/-1->57->56 [5] 58/-1/-1->57->56 [6] -1/-1/-1->57->56 [7] -1/-1/-1->57->56
14: nid005600:217721:227286 [1] NCCL INFO P2P Chunksize set to 131072
 6: nid005584:28288:37690 [3] NCCL INFO comm 0x400698a880b0 rank 27 nRanks 128 nNodes 32 localRanks 4 localRank 3 MNNVL 0
11: nid005591:191604:202310 [1] NCCL INFO comm 0x4006a564fd80 rank 45 nRanks 128 nNodes 32 localRanks 4 localRank 1 MNNVL 0
10: nid005590:110711:120117 [1] NCCL INFO comm 0x4006896528c0 rank 41 nRanks 128 nNodes 32 localRanks 4 localRank 1 MNNVL 0
 9: nid005588:35937:45405 [2] NCCL INFO Trees [0] 39/-1/-1->38->37 [1] 39/-1/-1->38->37 [2] 39/-1/-1->38->42 [3] 39/-1/-1->38->42 [4] 39/-1/-1->38->37 [5] 39/-1/-1->38->37 [6] 39/42/34->38->46 [7] 39/42/34->38->46
 9: nid005588:35938:45404 [3] NCCL INFO Trees [0] -1/-1/-1->39->38 [1] -1/-1/-1->39->38 [2] 36/-1/-1->39->38 [3] 36/-1/-1->39->38 [4] -1/-1/-1->39->38 [5] -1/-1/-1->39->38 [6] 36/-1/-1->39->38 [7] 36/-1/-1->39->38
 9: nid005588:35937:45405 [2] NCCL INFO P2P Chunksize set to 131072
 7: nid005585:122007:131403 [2] NCCL INFO Trees [0] 31/-1/-1->30->29 [1] 31/-1/-1->30->29 [2] 31/-1/-1->30->26 [3] 31/-1/-1->30->26 [4] 31/-1/-1->30->29 [5] 31/-1/-1->30->29 [6] 31/46/14->30->62 [7] 31/46/14->30->62
 7: nid005585:122007:131403 [2] NCCL INFO P2P Chunksize set to 131072
13: nid005595:197885:207692 [2] NCCL INFO comm 0x4006a96528c0 rank 54 nRanks 128 nNodes 32 localRanks 4 localRank 2 MNNVL 0
14: nid005600:217720:227285 [0] NCCL INFO Trees [0] 57/52/60->56->48 [1] 57/52/60->56->48 [2] 57/-1/-1->56->59 [3] 57/-1/-1->56->59 [4] 57/-1/-1->56->52 [5] 57/-1/-1->56->52 [6] 57/-1/-1->56->59 [7] 57/-1/-1->56->59
14: nid005600:217720:227285 [0] NCCL INFO P2P Chunksize set to 131072
 6: nid005584:28286:37692 [1] NCCL INFO comm 0x40068964fe00 rank 25 nRanks 128 nNodes 32 localRanks 4 localRank 1 MNNVL 0
 6: nid005584:28287:37693 [2] NCCL INFO comm 0x40068964fb50 rank 26 nRanks 128 nNodes 32 localRanks 4 localRank 2 MNNVL 0
 6: nid005584:28288:37690 [3] NCCL INFO Trees [0] -1/-1/-1->27->26 [1] -1/-1/-1->27->26 [2] 24/-1/-1->27->26 [3] 24/-1/-1->27->26 [4] -1/-1/-1->27->26 [5] -1/-1/-1->27->26 [6] 24/-1/-1->27->26 [7] 24/-1/-1->27->26
 6: nid005584:28288:37690 [3] NCCL INFO P2P Chunksize set to 131072
11: nid005591:191603:202313 [0] NCCL INFO comm 0x400681651260 rank 44 nRanks 128 nNodes 32 localRanks 4 localRank 0 MNNVL 0
10: nid005590:110710:120118 [0] NCCL INFO comm 0x40066964e420 rank 40 nRanks 128 nNodes 32 localRanks 4 localRank 0 MNNVL 0
 9: nid005588:35938:45404 [3] NCCL INFO P2P Chunksize set to 131072
 7: nid005585:122006:131404 [1] NCCL INFO Trees [0] 30/-1/-1->29->28 [1] 30/-1/-1->29->28 [2] -1/-1/-1->29->28 [3] -1/-1/-1->29->28 [4] 30/-1/-1->29->28 [5] 30/-1/-1->29->28 [6] -1/-1/-1->29->28 [7] -1/-1/-1->29->28
13: nid005595:197886:207693 [3] NCCL INFO Trees [0] -1/-1/-1->55->54 [1] -1/-1/-1->55->54 [2] 52/-1/-1->55->54 [3] 52/-1/-1->55->54 [4] -1/-1/-1->55->54 [5] -1/-1/-1->55->54 [6] 52/-1/-1->55->54 [7] 52/-1/-1->55->54
13: nid005595:197886:207693 [3] NCCL INFO P2P Chunksize set to 131072
 6: nid005584:28285:37691 [0] NCCL INFO comm 0x40066564e8c0 rank 24 nRanks 128 nNodes 32 localRanks 4 localRank 0 MNNVL 0
11: nid005591:191604:202310 [1] NCCL INFO Trees [0] 46/-1/-1->45->44 [1] 46/-1/-1->45->44 [2] -1/-1/-1->45->44 [3] -1/-1/-1->45->44 [4] 46/-1/-1->45->44 [5] 46/-1/-1->45->44 [6] -1/-1/-1->45->44 [7] -1/-1/-1->45->44
11: nid005591:191603:202313 [0] NCCL INFO Trees [0] 45/-1/-1->44->40 [1] 45/-1/-1->44->40 [2] 45/-1/-1->44->47 [3] 45/-1/-1->44->47 [4] 45/52/36->44->28 [5] 45/52/36->44->28 [6] 45/-1/-1->44->47 [7] 45/-1/-1->44->47
11: nid005591:191604:202310 [1] NCCL INFO P2P Chunksize set to 131072
11: nid005591:191603:202313 [0] NCCL INFO P2P Chunksize set to 131072
10: nid005590:110713:120120 [3] NCCL INFO Trees [0] -1/-1/-1->43->42 [1] -1/-1/-1->43->42 [2] 40/-1/-1->43->42 [3] 40/-1/-1->43->42 [4] -1/-1/-1->43->42 [5] -1/-1/-1->43->42 [6] 40/-1/-1->43->42 [7] 40/-1/-1->43->42
10: nid005590:110712:120119 [2] NCCL INFO Trees [0] 43/-1/-1->42->41 [1] 43/-1/-1->42->41 [2] 43/38/46->42->50 [3] 43/38/46->42->50 [4] 43/-1/-1->42->41 [5] 43/-1/-1->42->41 [6] 43/-1/-1->42->38 [7] 43/-1/-1->42->38
10: nid005590:110713:120120 [3] NCCL INFO P2P Chunksize set to 131072
10: nid005590:110712:120119 [2] NCCL INFO P2P Chunksize set to 131072
 7: nid005585:122006:131404 [1] NCCL INFO P2P Chunksize set to 131072
13: nid005595:197885:207692 [2] NCCL INFO Trees [0] 55/-1/-1->54->53 [1] 55/-1/-1->54->53 [2] 55/-1/-1->54->58 [3] 55/-1/-1->54->58 [4] 55/-1/-1->54->53 [5] 55/-1/-1->54->53 [6] 55/58/50->54->46 [7] 55/58/50->54->46
 6: nid005584:28286:37692 [1] NCCL INFO Trees [0] 26/-1/-1->25->24 [1] 26/-1/-1->25->24 [2] -1/-1/-1->25->24 [3] -1/-1/-1->25->24 [4] 26/-1/-1->25->24 [5] 26/-1/-1->25->24 [6] -1/-1/-1->25->24 [7] -1/-1/-1->25->24
 6: nid005584:28286:37692 [1] NCCL INFO P2P Chunksize set to 131072
 6: nid005584:28287:37693 [2] NCCL INFO Trees [0] 27/-1/-1->26->25 [1] 27/-1/-1->26->25 [2] 27/22/30->26->18 [3] 27/22/30->26->18 [4] 27/-1/-1->26->25 [5] 27/-1/-1->26->25 [6] 27/-1/-1->26->22 [7] 27/-1/-1->26->22
10: nid005590:110711:120117 [1] NCCL INFO Trees [0] 42/-1/-1->41->40 [1] 42/-1/-1->41->40 [2] -1/-1/-1->41->40 [3] -1/-1/-1->41->40 [4] 42/-1/-1->41->40 [5] 42/-1/-1->41->40 [6] -1/-1/-1->41->40 [7] -1/-1/-1->41->40
10: nid005590:110711:120117 [1] NCCL INFO P2P Chunksize set to 131072
 7: nid005585:122005:131405 [0] NCCL INFO comm 0x40067964fe00 rank 28 nRanks 128 nNodes 32 localRanks 4 localRank 0 MNNVL 0
13: nid005595:197885:207692 [2] NCCL INFO P2P Chunksize set to 131072
13: nid005595:197884:207691 [1] NCCL INFO Trees [0] 54/-1/-1->53->52 [1] 54/-1/-1->53->52 [2] -1/-1/-1->53->52 [3] -1/-1/-1->53->52 [4] 54/-1/-1->53->52 [5] 54/-1/-1->53->52 [6] -1/-1/-1->53->52 [7] -1/-1/-1->53->52
13: nid005595:197884:207691 [1] NCCL INFO P2P Chunksize set to 131072
 6: nid005584:28287:37693 [2] NCCL INFO P2P Chunksize set to 131072
 0: nid005574:69058:78859 [0] NCCL INFO Channel 03/08 :    0   3   2   6   4   7   5   9   8  11  10  14  12  15  13  17  16  19  18  22
10: nid005590:110710:120118 [0] NCCL INFO Trees [0] 41/36/44->40->48 [1] 41/36/44->40->48 [2] 41/-1/-1->40->43 [3] 41/-1/-1->40->43 [4] 41/-1/-1->40->36 [5] 41/-1/-1->40->36 [6] 41/-1/-1->40->43 [7] 41/-1/-1->40->43
10: nid005590:110710:120118 [0] NCCL INFO P2P Chunksize set to 131072
 9: nid005588:35935:45407 [0] NCCL INFO Trees [0] 37/-1/-1->36->40 [1] 37/-1/-1->36->40 [2] 37/-1/-1->36->39 [3] 37/-1/-1->36->39 [4] 37/40/32->36->44 [5] 37/40/32->36->44 [6] 37/-1/-1->36->39 [7] 37/-1/-1->36->39
 9: nid005588:35935:45407 [0] NCCL INFO P2P Chunksize set to 131072
13: nid005595:197883:207694 [0] NCCL INFO Trees [0] 53/-1/-1->52->56 [1] 53/-1/-1->52->56 [2] 53/-1/-1->52->55 [3] 53/-1/-1->52->55 [4] 53/56/48->52->44 [5] 53/56/48->52->44 [6] 53/-1/-1->52->55 [7] 53/-1/-1->52->55
13: nid005595:197883:207694 [0] NCCL INFO P2P Chunksize set to 131072
 0: nid005574:69058:78859 [0] NCCL INFO Channel 04/08 :    0   1   2   3   7   6   5   4   8   9  10  11  15  14  13  12  16  17  18  19
 0: nid005574:69058:78859 [0] NCCL INFO Channel 05/08 :    0   4   5   6   7  11  10   9   8  12  13  14  15  19  18  17  16  20  21  22
 7: nid005585:122005:131405 [0] NCCL INFO Trees [0] 29/-1/-1->28->24 [1] 29/-1/-1->28->24 [2] 29/-1/-1->28->31 [3] 29/-1/-1->28->31 [4] 29/44/12->28->60 [5] 29/44/12->28->60 [6] 29/-1/-1->28->31 [7] 29/-1/-1->28->31
 7: nid005585:122005:131405 [0] NCCL INFO P2P Chunksize set to 131072
 0: nid005574:69058:78859 [0] NCCL INFO Channel 06/08 :    0   3   1   5   4   7   6  10   8  11   9  13  12  15  14  18  16  19  17  21
 0: nid005574:69058:78859 [0] NCCL INFO Channel 07/08 :    0   3   2   6   4   7   5   9   8  11  10  14  12  15  13  17  16  19  18  22
 0: nid005574:69058:78859 [0] NCCL INFO Trees [0] 1/64/-1->0->-1 [1] 1/64/-1->0->-1 [2] 1/-1/-1->0->3 [3] 1/-1/-1->0->3 [4] 1/-1/-1->0->4 [5] 1/-1/-1->0->4 [6] 1/-1/-1->0->3 [7] 1/-1/-1->0->3
 0: nid005574:69058:78859 [0] NCCL INFO P2P Chunksize set to 131072
 6: nid005584:28285:37691 [0] NCCL INFO Trees [0] 25/20/28->24->16 [1] 25/20/28->24->16 [2] 25/-1/-1->24->27 [3] 25/-1/-1->24->27 [4] 25/-1/-1->24->20 [5] 25/-1/-1->24->20 [6] 25/-1/-1->24->27 [7] 25/-1/-1->24->27
 6: nid005584:28285:37691 [0] NCCL INFO P2P Chunksize set to 131072
 4: nid005581:264525:273956 [2] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 4: nid005581:264525:273956 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 0: nid005574:69059:78862 [1] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 0: nid005574:69059:78862 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
26: nid005920:67123:76588 [0] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
26: nid005920:67123:76588 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
22: nid005915:274817:284251 [3] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
22: nid005915:274817:284251 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
30: nid005936:49910:59367 [2] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
30: nid005936:49910:59367 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 5: nid005582:196716:206688 [3] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 5: nid005582:196716:206688 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 5: nid005582:196715:206689 [2] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 5: nid005582:196715:206689 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 3: nid005580:71821:81296 [2] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 3: nid005580:71821:81296 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 1: nid005576:147560:156959 [3] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 1: nid005576:147560:156959 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 1: nid005576:147558:156960 [1] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 1: nid005576:147558:156960 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
12: nid005594:53087:62559 [2] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
12: nid005594:53087:62559 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
27: nid005922:80743:90166 [2] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
27: nid005922:80743:90166 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 3: nid005580:71820:81294 [1] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 3: nid005580:71820:81294 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
26: nid005920:67126:76590 [3] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
26: nid005920:67126:76590 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
28: nid005929:16032:25496 [2] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
28: nid005929:16032:25496 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
20: nid005913:292682:9578 [1] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
20: nid005913:292682:9578 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
17: nid005803:180733:190220 [1] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
17: nid005803:180733:190220 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
25: nid005919:107465:116955 [3] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
25: nid005919:107465:116955 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
30: nid005936:49909:59369 [1] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
30: nid005936:49909:59369 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
25: nid005919:107464:116954 [2] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
25: nid005919:107464:116954 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 2: nid005577:17425:26950 [3] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 2: nid005577:17425:26950 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 3: nid005580:71819:81293 [0] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 3: nid005580:71819:81293 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 3: nid005580:71822:81295 [3] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 3: nid005580:71822:81295 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 0: nid005574:69061:78860 [3] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 0: nid005574:69061:78860 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
14: nid005600:217721:227286 [1] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
14: nid005600:217721:227286 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
23: nid005917:276885:286342 [0] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
23: nid005917:276885:286342 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 9: nid005588:35936:45406 [1] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 9: nid005588:35936:45406 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
31: nid005937:256592:266031 [3] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
31: nid005937:256592:266031 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
27: nid005922:80744:90167 [3] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
27: nid005922:80744:90167 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 5: nid005582:196714:206691 [1] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 5: nid005582:196714:206691 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 5: nid005582:196713:206690 [0] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 5: nid005582:196713:206690 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
27: nid005922:80741:90164 [0] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
27: nid005922:80741:90164 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
19: nid005912:12438:21868 [3] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
19: nid005912:12438:21868 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
31: nid005937:256591:266028 [2] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
31: nid005937:256591:266028 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 4: nid005581:264526:273958 [3] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 4: nid005581:264526:273958 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
19: nid005912:12437:21866 [2] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
22: nid005915:274816:284254 [2] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
22: nid005915:274816:284254 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 4: nid005581:264524:273957 [1] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
19: nid005912:12437:21866 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 4: nid005581:264524:273957 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
31: nid005937:256589:266029 [0] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
31: nid005937:256589:266029 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
15: nid005601:210676:220214 [0] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
15: nid005601:210676:220214 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 0: nid005574:69060:78861 [2] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 0: nid005574:69060:78861 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
23: nid005917:276888:286343 [3] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
23: nid005917:276888:286343 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 2: nid005577:17424:26951 [2] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 2: nid005577:17424:26951 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 1: nid005576:147559:156961 [2] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 1: nid005576:147559:156961 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
17: nid005803:180735:190221 [3] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
17: nid005803:180735:190221 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 2: nid005577:17423:26949 [1] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 2: nid005577:17423:26949 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
27: nid005922:80742:90165 [1] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
27: nid005922:80742:90165 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
21: nid005914:166784:176212 [0] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
21: nid005914:166784:176212 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
28: nid005929:16033:25498 [3] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
28: nid005929:16033:25498 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 8: nid005586:68926:78412 [0] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 8: nid005586:68926:78412 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 2: nid005577:17422:26952 [0] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 2: nid005577:17422:26952 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
26: nid005920:67125:76589 [2] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
26: nid005920:67125:76589 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
25: nid005919:107462:116957 [0] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
25: nid005919:107462:116957 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 4: nid005581:264523:273959 [0] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 4: nid005581:264523:273959 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
18: nid005911:38865:48327 [1] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
18: nid005911:38865:48327 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
30: nid005936:49911:59368 [3] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
30: nid005936:49911:59368 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
11: nid005591:191606:202312 [3] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
11: nid005591:191606:202312 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 1: nid005576:147557:156962 [0] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 1: nid005576:147557:156962 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
26: nid005920:67124:76591 [1] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
26: nid005920:67124:76591 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
31: nid005937:256590:266030 [1] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
31: nid005937:256590:266030 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
18: nid005911:38866:48328 [2] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
18: nid005911:38866:48328 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 3: nid005580:71821:81296 [2] NCCL INFO ncclCommSplit comm 0x40068564fe00 rank 14 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 parent 0xaaaada12b8c0 color 315732477 key 14 commId 0xf264858106496629 - Init COMPLETE
 3: nid005580:71819:81293 [0] NCCL INFO ncclCommSplit comm 0x40067564e840 rank 12 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 parent 0xaaab065e8c10 color 315732477 key 12 commId 0xf264858106496629 - Init COMPLETE
 3: nid005580:71820:81294 [1] NCCL INFO ncclCommSplit comm 0x4006b564e160 rank 13 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 parent 0xaaaac543b4a0 color 315732477 key 13 commId 0xf264858106496629 - Init COMPLETE
 3: nid005580:71821:81296 [2] NCCL INFO Init timings: rank 14 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
 3: nid005580:71819:81293 [0] NCCL INFO Init timings: rank 12 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
28: nid005929:16030:25495 [0] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
28: nid005929:16030:25495 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
21: nid005914:166785:176214 [1] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
21: nid005914:166785:176214 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
11: nid005591:191605:202311 [2] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
11: nid005591:191605:202311 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 3: nid005580:71820:81294 [1] NCCL INFO Init timings: rank 13 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
 3: nid005580:71822:81295 [3] NCCL INFO ncclCommSplit comm 0x4006a164fde0 rank 15 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 parent 0xaaab06b93260 color 315732477 key 15 commId 0xf264858106496629 - Init COMPLETE
 3: nid005580:71822:81295 [3] NCCL INFO Init timings: rank 15 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
25: nid005919:107463:116956 [1] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
25: nid005919:107463:116956 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
22: nid005915:274814:284253 [0] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
22: nid005915:274814:284253 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 5: nid005582:196715:206689 [2] NCCL INFO ncclCommSplit comm 0x4006bd651260 rank 22 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 parent 0xaaaaeab5be10 color 315732477 key 22 commId 0xf264858106496629 - Init COMPLETE
 5: nid005582:196713:206690 [0] NCCL INFO ncclCommSplit comm 0x40068564fdf0 rank 20 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 parent 0xaaab12118df0 color 315732477 key 20 commId 0xf264858106496629 - Init COMPLETE
 5: nid005582:196715:206689 [2] NCCL INFO Init timings: rank 22 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
 5: nid005582:196713:206690 [0] NCCL INFO Init timings: rank 20 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
22: nid005915:274815:284252 [1] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
22: nid005915:274815:284252 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
16: nid005802:6299:15922 [2] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
16: nid005802:6299:15922 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
20: nid005913:292684:9581 [3] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
20: nid005913:292684:9581 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 7: nid005585:122008:131402 [3] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 7: nid005585:122008:131402 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 5: nid005582:196716:206688 [3] NCCL INFO ncclCommSplit comm 0x40067d64fe00 rank 23 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 parent 0xaaab1215f930 color 315732477 key 23 commId 0xf264858106496629 - Init COMPLETE
 5: nid005582:196714:206691 [1] NCCL INFO ncclCommSplit comm 0x400689651260 rank 21 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 parent 0xaaab201019a0 color 315732477 key 21 commId 0xf264858106496629 - Init COMPLETE
 5: nid005582:196716:206688 [3] NCCL INFO Init timings: rank 23 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
 5: nid005582:196714:206691 [1] NCCL INFO Init timings: rank 21 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
15: nid005601:210678:220212 [2] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
15: nid005601:210678:220212 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
23: nid005917:276886:286341 [1] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
23: nid005917:276886:286341 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
28: nid005929:16031:25497 [1] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
28: nid005929:16031:25497 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
10: nid005590:110712:120119 [2] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
10: nid005590:110712:120119 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 3: nid005580:71819:81307 [0] NCCL INFO Channel 01/0 : 12[0] -> 13[1] via P2P/CUMEM
16: nid005802:6298:15921 [1] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
16: nid005802:6298:15921 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 8: nid005586:68928:78413 [2] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 8: nid005586:68928:78413 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
30: nid005936:49908:59370 [0] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
30: nid005936:49908:59370 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 6: nid005584:28286:37692 [1] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 6: nid005584:28286:37692 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
19: nid005912:12436:21867 [1] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
19: nid005912:12436:21867 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 7: nid005585:122007:131403 [2] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 7: nid005585:122007:131403 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
20: nid005913:292683:9579 [2] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
20: nid005913:292683:9579 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 5: nid005582:196713:206701 [0] NCCL INFO Channel 01/0 : 20[0] -> 21[1] via P2P/CUMEM
 6: nid005584:28287:37693 [2] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 6: nid005584:28287:37693 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 4: nid005581:264526:273958 [3] NCCL INFO ncclCommSplit comm 0x40069d64e840 rank 19 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 parent 0xaaaae8963db0 color 315732477 key 19 commId 0xf264858106496629 - Init COMPLETE
 4: nid005581:264526:273958 [3] NCCL INFO Init timings: rank 19 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.20, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
 4: nid005581:264525:273956 [2] NCCL INFO ncclCommSplit comm 0x40069564fe00 rank 18 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 parent 0xaaaaf1142f20 color 315732477 key 18 commId 0xf264858106496629 - Init COMPLETE
 4: nid005581:264525:273956 [2] NCCL INFO Init timings: rank 18 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.20, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
14: nid005600:217720:227285 [0] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
14: nid005600:217720:227285 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 4: nid005581:264523:273959 [0] NCCL INFO ncclCommSplit comm 0x40068964fe00 rank 16 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 parent 0xaaaafba8b880 color 315732477 key 16 commId 0xf264858106496629 - Init COMPLETE
 4: nid005581:264524:273957 [1] NCCL INFO ncclCommSplit comm 0x4006aca88070 rank 17 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 parent 0xaaaad9b8a440 color 315732477 key 17 commId 0xf264858106496629 - Init COMPLETE
 4: nid005581:264523:273959 [0] NCCL INFO Init timings: rank 16 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.20, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
 4: nid005581:264524:273957 [1] NCCL INFO Init timings: rank 17 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.20, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
12: nid005594:53088:62557 [3] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
12: nid005594:53088:62557 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 1: nid005576:147558:156960 [1] NCCL INFO ncclCommSplit comm 0x40069964fd70 rank 5 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 parent 0xaaaaf8e03070 color 315732477 key 5 commId 0xf264858106496629 - Init COMPLETE
 1: nid005576:147560:156959 [3] NCCL INFO ncclCommSplit comm 0x400699651260 rank 7 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 parent 0xaaaaea94c330 color 315732477 key 7 commId 0xf264858106496629 - Init COMPLETE
 1: nid005576:147558:156960 [1] NCCL INFO Init timings: rank 5 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.20, topo 0.33, graphs 0.02, connections 0.01, rest 0.00)
 9: nid005588:35938:45404 [3] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 9: nid005588:35938:45404 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
23: nid005917:276887:286344 [2] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
23: nid005917:276887:286344 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 0: nid005574:69058:78859 [0] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 0: nid005574:69058:78859 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 1: nid005576:147559:156961 [2] NCCL INFO ncclCommSplit comm 0x40069d652920 rank 6 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 parent 0xaaab1c4d2400 color 315732477 key 6 commId 0xf264858106496629 - Init COMPLETE
 1: nid005576:147560:156959 [3] NCCL INFO Init timings: rank 7 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.20, topo 0.33, graphs 0.02, connections 0.01, rest 0.00)
13: nid005595:197886:207693 [3] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
13: nid005595:197886:207693 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 1: nid005576:147559:156961 [2] NCCL INFO Init timings: rank 6 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.20, topo 0.33, graphs 0.02, connections 0.01, rest 0.00)
 1: nid005576:147557:156962 [0] NCCL INFO ncclCommSplit comm 0x40066d64e900 rank 4 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 parent 0xaaab2078f8e0 color 315732477 key 4 commId 0xf264858106496629 - Init COMPLETE
31: nid005937:256589:266029 [0] NCCL INFO ncclCommSplit comm 0x400699652800 rank 124 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 parent 0xaaab2c295d90 color 315732477 key 124 commId 0xf264858106496629 - Init COMPLETE
 1: nid005576:147557:156962 [0] NCCL INFO Init timings: rank 4 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.20, topo 0.33, graphs 0.02, connections 0.01, rest 0.00)
27: nid005922:80741:90164 [0] NCCL INFO ncclCommSplit comm 0x40067964fde0 rank 108 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 parent 0xaaab18560ec0 color 315732477 key 108 commId 0xf264858106496629 - Init COMPLETE
31: nid005937:256589:266029 [0] NCCL INFO Init timings: rank 124 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
31: nid005937:256591:266028 [2] NCCL INFO ncclCommSplit comm 0x40068964fe00 rank 126 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 parent 0xaaaafcfbaf70 color 315732477 key 126 commId 0xf264858106496629 - Init COMPLETE
31: nid005937:256591:266028 [2] NCCL INFO Init timings: rank 126 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
27: nid005922:80741:90164 [0] NCCL INFO Init timings: rank 108 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
31: nid005937:256592:266031 [3] NCCL INFO ncclCommSplit comm 0x400674a86b00 rank 127 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 parent 0xaaaaedf436d0 color 315732477 key 127 commId 0xf264858106496629 - Init COMPLETE
31: nid005937:256590:266030 [1] NCCL INFO ncclCommSplit comm 0x400691651360 rank 125 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 parent 0xaaab10443c40 color 315732477 key 125 commId 0xf264858106496629 - Init COMPLETE
31: nid005937:256592:266031 [3] NCCL INFO Init timings: rank 127 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
31: nid005937:256590:266030 [1] NCCL INFO Init timings: rank 125 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
17: nid005803:180732:190218 [0] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
17: nid005803:180732:190218 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
27: nid005922:80743:90166 [2] NCCL INFO ncclCommSplit comm 0x4006b96513a0 rank 110 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 parent 0xaaab0b1de990 color 315732477 key 110 commId 0xf264858106496629 - Init COMPLETE
27: nid005922:80744:90167 [3] NCCL INFO ncclCommSplit comm 0x40068964fe00 rank 111 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 parent 0xaaaabb7ab7a0 color 315732477 key 111 commId 0xf264858106496629 - Init COMPLETE
27: nid005922:80742:90165 [1] NCCL INFO ncclCommSplit comm 0x4006996513b0 rank 109 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 parent 0xaaab00b73210 color 315732477 key 109 commId 0xf264858106496629 - Init COMPLETE
27: nid005922:80743:90166 [2] NCCL INFO Init timings: rank 110 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
 0: nid005574:69058:78859 [0] NCCL INFO CC Off, Multi-GPU CC Off, workFifoBytes 1048576
17: nid005803:180734:190219 [2] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
17: nid005803:180734:190219 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
25: nid005919:107462:116957 [0] NCCL INFO ncclCommSplit comm 0x40067964fe00 rank 100 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 parent 0xaaab262294f0 color 315732477 key 100 commId 0xf264858106496629 - Init COMPLETE
25: nid005919:107464:116954 [2] NCCL INFO ncclCommSplit comm 0x4006b564e420 rank 102 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 parent 0xaaab1682a750 color 315732477 key 102 commId 0xf264858106496629 - Init COMPLETE
25: nid005919:107464:116954 [2] NCCL INFO Init timings: rank 102 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
25: nid005919:107462:116957 [0] NCCL INFO Init timings: rank 100 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.22, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
26: nid005920:67123:76588 [0] NCCL INFO ncclCommSplit comm 0x40069964fe00 rank 104 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 parent 0xaaab021f2d20 color 315732477 key 104 commId 0xf264858106496629 - Init COMPLETE
26: nid005920:67125:76589 [2] NCCL INFO ncclCommSplit comm 0x400669651220 rank 106 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 parent 0xaaaaf841bf30 color 315732477 key 106 commId 0xf264858106496629 - Init COMPLETE
26: nid005920:67123:76588 [0] NCCL INFO Init timings: rank 104 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.22, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
25: nid005919:107465:116955 [3] NCCL INFO ncclCommSplit comm 0x40069964fe00 rank 103 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 parent 0xaaaad4543ad0 color 315732477 key 103 commId 0xf264858106496629 - Init COMPLETE
25: nid005919:107463:116956 [1] NCCL INFO ncclCommSplit comm 0x40067d64fe00 rank 101 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 parent 0xaaaaf8221890 color 315732477 key 101 commId 0xf264858106496629 - Init COMPLETE
25: nid005919:107465:116955 [3] NCCL INFO Init timings: rank 103 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.22, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
25: nid005919:107463:116956 [1] NCCL INFO Init timings: rank 101 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
20: nid005913:292681:9580 [0] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
20: nid005913:292681:9580 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
26: nid005920:67125:76589 [2] NCCL INFO Init timings: rank 106 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.22, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
27: nid005922:80744:90167 [3] NCCL INFO Init timings: rank 111 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
27: nid005922:80742:90165 [1] NCCL INFO Init timings: rank 109 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
 8: nid005586:68927:78410 [1] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 8: nid005586:68927:78410 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 4: nid005581:264523:273969 [0] NCCL INFO Channel 00/0 : 16[0] -> 17[1] via P2P/CUMEM
26: nid005920:67126:76590 [3] NCCL INFO ncclCommSplit comm 0x40067964fd80 rank 107 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 parent 0xaaab209d4590 color 315732477 key 107 commId 0xf264858106496629 - Init COMPLETE
16: nid005802:6300:15924 [3] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
16: nid005802:6300:15924 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
26: nid005920:67126:76590 [3] NCCL INFO Init timings: rank 107 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.22, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
 2: nid005577:17425:26950 [3] NCCL INFO ncclCommSplit comm 0x40068164e900 rank 11 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 parent 0xaaab1accc2e0 color 315732477 key 11 commId 0xf264858106496629 - Init COMPLETE
 2: nid005577:17423:26949 [1] NCCL INFO ncclCommSplit comm 0x40069164fd80 rank 9 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 parent 0xaaaaf479b750 color 315732477 key 9 commId 0xf264858106496629 - Init COMPLETE
 2: nid005577:17425:26950 [3] NCCL INFO Init timings: rank 11 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
16: nid005802:6297:15923 [0] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
26: nid005920:67124:76591 [1] NCCL INFO ncclCommSplit comm 0x400689651260 rank 105 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 parent 0xaaab0de132b0 color 315732477 key 105 commId 0xf264858106496629 - Init COMPLETE
26: nid005920:67124:76591 [1] NCCL INFO Init timings: rank 105 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.22, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
 2: nid005577:17423:26949 [1] NCCL INFO Init timings: rank 9 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
16: nid005802:6297:15923 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
18: nid005911:38867:48329 [3] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
18: nid005911:38867:48329 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
18: nid005911:38864:48326 [0] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 9: nid005588:35937:45405 [2] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 9: nid005588:35937:45405 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
18: nid005911:38864:48326 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
22: nid005915:274814:284253 [0] NCCL INFO ncclCommSplit comm 0x40067d64fe00 rank 88 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 parent 0xaaaad1683e90 color 315732477 key 88 commId 0xf264858106496629 - Init COMPLETE
22: nid005915:274814:284253 [0] NCCL INFO Init timings: rank 88 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
 2: nid005577:17424:26951 [2] NCCL INFO ncclCommSplit comm 0x4006b5648640 rank 10 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 parent 0xaaaaec29b7f0 color 315732477 key 10 commId 0xf264858106496629 - Init COMPLETE
 2: nid005577:17424:26951 [2] NCCL INFO Init timings: rank 10 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
14: nid005600:217723:227284 [3] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
14: nid005600:217723:227284 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
11: nid005591:191603:202313 [0] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
11: nid005591:191603:202313 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
22: nid005915:274816:284254 [2] NCCL INFO ncclCommSplit comm 0x4006a96513b0 rank 90 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 parent 0xaaaafe3ab720 color 315732477 key 90 commId 0xf264858106496629 - Init COMPLETE
 2: nid005577:17422:26952 [0] NCCL INFO ncclCommSplit comm 0x40069964fe00 rank 8 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 parent 0xaaaaf334fcf0 color 315732477 key 8 commId 0xf264858106496629 - Init COMPLETE
 1: nid005576:147557:156974 [0] NCCL INFO Channel 01/0 : 4[0] -> 5[1] via P2P/CUMEM
19: nid005912:12435:21865 [0] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
19: nid005912:12435:21865 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
26: nid005920:67123:76600 [0] NCCL INFO Channel 00/0 : 104[0] -> 105[1] via P2P/CUMEM
22: nid005915:274817:284251 [3] NCCL INFO ncclCommSplit comm 0x4006ad651330 rank 91 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 parent 0xaaab11483950 color 315732477 key 91 commId 0xf264858106496629 - Init COMPLETE
22: nid005915:274815:284252 [1] NCCL INFO ncclCommSplit comm 0x40069d64f9d0 rank 89 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 parent 0xaaab0ea2ac20 color 315732477 key 89 commId 0xf264858106496629 - Init COMPLETE
22: nid005915:274816:284254 [2] NCCL INFO Init timings: rank 90 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
10: nid005590:110711:120117 [1] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
10: nid005590:110711:120117 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 2: nid005577:17422:26952 [0] NCCL INFO Init timings: rank 8 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
 9: nid005588:35935:45407 [0] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 9: nid005588:35935:45407 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
11: nid005591:191604:202310 [1] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
11: nid005591:191604:202310 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
22: nid005915:274817:284251 [3] NCCL INFO Init timings: rank 91 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
22: nid005915:274815:284252 [1] NCCL INFO Init timings: rank 89 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
31: nid005937:256589:266041 [0] NCCL INFO Channel 01/0 : 124[0] -> 125[1] via P2P/CUMEM
 8: nid005586:68929:78411 [3] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 8: nid005586:68929:78411 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
28: nid005929:16032:25496 [2] NCCL INFO ncclCommSplit comm 0x40069564e840 rank 114 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 parent 0xaaab2fba3240 color 315732477 key 114 commId 0xf264858106496629 - Init COMPLETE
13: nid005595:197885:207692 [2] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
13: nid005595:197885:207692 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 7: nid005585:122006:131404 [1] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 7: nid005585:122006:131404 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
25: nid005919:107462:116966 [0] NCCL INFO Channel 01/0 : 100[0] -> 101[1] via P2P/CUMEM
28: nid005929:16032:25496 [2] NCCL INFO Init timings: rank 114 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
28: nid005929:16030:25495 [0] NCCL INFO ncclCommSplit comm 0x40066164fe00 rank 112 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 parent 0xaaaad57d3fc0 color 315732477 key 112 commId 0xf264858106496629 - Init COMPLETE
28: nid005929:16033:25498 [3] NCCL INFO ncclCommSplit comm 0x4006b164fdc0 rank 115 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 parent 0xaaaade0c3510 color 315732477 key 115 commId 0xf264858106496629 - Init COMPLETE
 6: nid005584:28285:37691 [0] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 6: nid005584:28285:37691 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
28: nid005929:16033:25498 [3] NCCL INFO Init timings: rank 115 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
28: nid005929:16031:25497 [1] NCCL INFO ncclCommSplit comm 0x400699647100 rank 113 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 parent 0xaaaaf8401170 color 315732477 key 113 commId 0xf264858106496629 - Init COMPLETE
27: nid005922:80741:90179 [0] NCCL INFO Channel 01/0 : 108[0] -> 109[1] via P2P/CUMEM
28: nid005929:16031:25497 [1] NCCL INFO Init timings: rank 113 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
24: nid005918:92507:101970 [3] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
24: nid005918:92507:101970 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
30: nid005936:49911:59368 [3] NCCL INFO ncclCommSplit comm 0x40067564fd80 rank 123 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 parent 0xaaaad877afc0 color 315732477 key 123 commId 0xf264858106496629 - Init COMPLETE
30: nid005936:49909:59369 [1] NCCL INFO ncclCommSplit comm 0x4006b964fdc0 rank 121 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 parent 0xaaaacaa5c1a0 color 315732477 key 121 commId 0xf264858106496629 - Init COMPLETE
30: nid005936:49911:59368 [3] NCCL INFO Init timings: rank 123 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
30: nid005936:49909:59369 [1] NCCL INFO Init timings: rank 121 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
 3: nid005580:71819:81307 [0] NCCL INFO Channel 05/0 : 12[0] -> 13[1] via P2P/CUMEM
14: nid005600:217722:227283 [2] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
14: nid005600:217722:227283 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
28: nid005929:16030:25495 [0] NCCL INFO Init timings: rank 112 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
 2: nid005577:17422:26964 [0] NCCL INFO Channel 00/0 : 8[0] -> 9[1] via P2P/CUMEM
10: nid005590:110713:120120 [3] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
10: nid005590:110713:120120 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
30: nid005936:49910:59367 [2] NCCL INFO ncclCommSplit comm 0x4006b964f9d0 rank 122 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 parent 0xaaaad8cb00f0 color 315732477 key 122 commId 0xf264858106496629 - Init COMPLETE
30: nid005936:49910:59367 [2] NCCL INFO Init timings: rank 122 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
23: nid005917:276886:286341 [1] NCCL INFO ncclCommSplit comm 0x40068164fb30 rank 93 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 parent 0xaaab0f582930 color 315732477 key 93 commId 0xf264858106496629 - Init COMPLETE
23: nid005917:276886:286341 [1] NCCL INFO Init timings: rank 93 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.20, topo 0.33, graphs 0.02, connections 0.01, rest 0.00)
23: nid005917:276888:286343 [3] NCCL INFO ncclCommSplit comm 0x40069d6513b0 rank 95 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 parent 0xaaaaf34fa080 color 315732477 key 95 commId 0xf264858106496629 - Init COMPLETE
22: nid005915:274814:284265 [0] NCCL INFO Channel 00/0 : 88[0] -> 89[1] via P2P/CUMEM
21: nid005914:166787:176211 [3] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
21: nid005914:166787:176211 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
23: nid005917:276888:286343 [3] NCCL INFO Init timings: rank 95 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.20, topo 0.33, graphs 0.02, connections 0.01, rest 0.00)
 0: nid005574:69061:78860 [3] NCCL INFO ncclCommSplit comm 0x40069964e880 rank 3 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 parent 0xaaaad3e5bbc0 color 315732477 key 3 commId 0xf264858106496629 - Init COMPLETE
 0: nid005574:69059:78862 [1] NCCL INFO ncclCommSplit comm 0x4006b964e900 rank 1 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 parent 0xaaaad1289f50 color 315732477 key 1 commId 0xf264858106496629 - Init COMPLETE
 0: nid005574:69061:78860 [3] NCCL INFO Init timings: rank 3 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.01, topo 0.51, graphs 0.02, connections 0.01, rest 0.00)
 0: nid005574:69059:78862 [1] NCCL INFO Init timings: rank 1 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.01, topo 0.51, graphs 0.02, connections 0.01, rest 0.00)
12: nid005594:53086:62556 [1] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
12: nid005594:53086:62556 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
15: nid005601:210677:220213 [1] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
15: nid005601:210677:220213 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 5: nid005582:196713:206701 [0] NCCL INFO Channel 05/0 : 20[0] -> 21[1] via P2P/CUMEM
 0: nid005574:69060:78861 [2] NCCL INFO ncclCommSplit comm 0x4006b164e420 rank 2 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 parent 0xaaaaedbf8c70 color 315732477 key 2 commId 0xf264858106496629 - Init COMPLETE
 0: nid005574:69060:78861 [2] NCCL INFO Init timings: rank 2 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.01, topo 0.51, graphs 0.02, connections 0.01, rest 0.00)
 0: nid005574:69058:78859 [0] NCCL INFO ncclCommSplit comm 0x400691650620 rank 0 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 parent 0xaaab0113f7d0 color 315732477 key 0 commId 0xf264858106496629 - Init COMPLETE
15: nid005601:210679:220215 [3] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
15: nid005601:210679:220215 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
21: nid005914:166786:176213 [2] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
21: nid005914:166786:176213 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
30: nid005936:49908:59370 [0] NCCL INFO ncclCommSplit comm 0x40057d64fe00 rank 120 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 parent 0xaaaafc2a9750 color 315732477 key 120 commId 0xf264858106496629 - Init COMPLETE
 0: nid005574:69058:78859 [0] NCCL INFO Init timings: rank 0 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.02, topo 0.51, graphs 0.02, connections 0.01, rest 0.00)
23: nid005917:276885:286342 [0] NCCL INFO ncclCommSplit comm 0x400668a73790 rank 92 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 parent 0xaaaae40fdd90 color 315732477 key 92 commId 0xf264858106496629 - Init COMPLETE
23: nid005917:276887:286344 [2] NCCL INFO ncclCommSplit comm 0x40068d64e900 rank 94 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 parent 0xaaaaf1b2b6f0 color 315732477 key 94 commId 0xf264858106496629 - Init COMPLETE
23: nid005917:276885:286342 [0] NCCL INFO Init timings: rank 92 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.20, topo 0.33, graphs 0.02, connections 0.01, rest 0.00)
30: nid005936:49908:59370 [0] NCCL INFO Init timings: rank 120 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
23: nid005917:276887:286344 [2] NCCL INFO Init timings: rank 94 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.20, topo 0.33, graphs 0.02, connections 0.01, rest 0.00)
 6: nid005584:28288:37690 [3] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 6: nid005584:28288:37690 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 7: nid005585:122005:131405 [0] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 7: nid005585:122005:131405 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
17: nid005803:180733:190220 [1] NCCL INFO ncclCommSplit comm 0x40069164fa60 rank 69 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 parent 0xaaab1f57afc0 color 315732477 key 69 commId 0xf264858106496629 - Init COMPLETE
17: nid005803:180733:190220 [1] NCCL INFO Init timings: rank 69 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.20, topo 0.33, graphs 0.02, connections 0.01, rest 0.00)
10: nid005590:110710:120118 [0] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
10: nid005590:110710:120118 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
12: nid005594:53085:62558 [0] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
12: nid005594:53085:62558 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
17: nid005803:180735:190221 [3] NCCL INFO ncclCommSplit comm 0x4006896513a0 rank 71 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 parent 0xaaab10aa06b0 color 315732477 key 71 commId 0xf264858106496629 - Init COMPLETE
17: nid005803:180735:190221 [3] NCCL INFO Init timings: rank 71 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.20, topo 0.33, graphs 0.02, connections 0.01, rest 0.00)
28: nid005929:16030:25510 [0] NCCL INFO Channel 00/0 : 112[0] -> 113[1] via P2P/CUMEM
17: nid005803:180732:190218 [0] NCCL INFO ncclCommSplit comm 0x400681651260 rank 68 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 parent 0xaaaad12a2680 color 315732477 key 68 commId 0xf264858106496629 - Init COMPLETE
 4: nid005581:264523:273969 [0] NCCL INFO Channel 04/0 : 16[0] -> 17[1] via P2P/CUMEM
17: nid005803:180734:190219 [2] NCCL INFO ncclCommSplit comm 0x40068564fe00 rank 70 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 parent 0xaaab0a6d9870 color 315732477 key 70 commId 0xf264858106496629 - Init COMPLETE
17: nid005803:180732:190218 [0] NCCL INFO Init timings: rank 68 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.20, topo 0.33, graphs 0.02, connections 0.01, rest 0.00)
 5: nid005582:196715:206700 [2] NCCL INFO Channel 01/0 : 22[2] -> 23[3] via P2P/CUMEM
17: nid005803:180734:190219 [2] NCCL INFO Init timings: rank 70 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.20, topo 0.33, graphs 0.02, connections 0.01, rest 0.00)
20: nid005913:292684:9581 [3] NCCL INFO ncclCommSplit comm 0x40069164e900 rank 83 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 parent 0xaaaae94038c0 color 315732477 key 83 commId 0xf264858106496629 - Init COMPLETE
20: nid005913:292682:9578 [1] NCCL INFO ncclCommSplit comm 0x40066964fdf0 rank 81 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 parent 0xaaaaf6e99730 color 315732477 key 81 commId 0xf264858106496629 - Init COMPLETE
20: nid005913:292684:9581 [3] NCCL INFO Init timings: rank 83 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
20: nid005913:292682:9578 [1] NCCL INFO Init timings: rank 81 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
23: nid005917:276885:286375 [0] NCCL INFO Channel 01/0 : 92[0] -> 93[1] via P2P/CUMEM
20: nid005913:292683:9579 [2] NCCL INFO ncclCommSplit comm 0x40069564fdf0 rank 82 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 parent 0xaaaaf0f2a8d0 color 315732477 key 82 commId 0xf264858106496629 - Init COMPLETE
20: nid005913:292683:9579 [2] NCCL INFO Init timings: rank 82 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
19: nid005912:12438:21868 [3] NCCL INFO ncclCommSplit comm 0x40069964fe00 rank 79 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 parent 0xaaaae3c43340 color 315732477 key 79 commId 0xf264858106496629 - Init COMPLETE
19: nid005912:12436:21867 [1] NCCL INFO ncclCommSplit comm 0x40067964fe00 rank 77 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 parent 0xaaaaeb758490 color 315732477 key 77 commId 0xf264858106496629 - Init COMPLETE
19: nid005912:12438:21868 [3] NCCL INFO Init timings: rank 79 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
16: nid005802:6300:15924 [3] NCCL INFO ncclCommSplit comm 0x40069164fe00 rank 67 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 parent 0xaaaae402b650 color 315732477 key 67 commId 0xf264858106496629 - Init COMPLETE
16: nid005802:6300:15924 [3] NCCL INFO Init timings: rank 67 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
16: nid005802:6298:15921 [1] NCCL INFO ncclCommSplit comm 0x40069964e900 rank 65 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 parent 0xaaab06e0b4f0 color 315732477 key 65 commId 0xf264858106496629 - Init COMPLETE
 3: nid005580:71820:81305 [1] NCCL INFO Channel 01/0 : 13[1] -> 14[2] via P2P/CUMEM
16: nid005802:6298:15921 [1] NCCL INFO Init timings: rank 65 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
16: nid005802:6299:15922 [2] NCCL INFO ncclCommSplit comm 0x4006ad650f90 rank 66 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 parent 0xaaab08f00a50 color 315732477 key 66 commId 0xf264858106496629 - Init COMPLETE
19: nid005912:12437:21866 [2] NCCL INFO ncclCommSplit comm 0x4006a964fe00 rank 78 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 parent 0xaaaaec4bb890 color 315732477 key 78 commId 0xf264858106496629 - Init COMPLETE
19: nid005912:12436:21867 [1] NCCL INFO Init timings: rank 77 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
19: nid005912:12437:21866 [2] NCCL INFO Init timings: rank 78 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
 0: nid005574:69058:78874 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM
20: nid005913:292681:9580 [0] NCCL INFO ncclCommSplit comm 0x40069564fe00 rank 80 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 parent 0xaaab2e755bf0 color 315732477 key 80 commId 0xf264858106496629 - Init COMPLETE
20: nid005913:292681:9580 [0] NCCL INFO Init timings: rank 80 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
19: nid005912:12435:21865 [0] NCCL INFO ncclCommSplit comm 0x40066d64e900 rank 76 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 parent 0xaaab04d29d70 color 315732477 key 76 commId 0xf264858106496629 - Init COMPLETE
26: nid005920:67123:76600 [0] NCCL INFO Channel 04/0 : 104[0] -> 105[1] via P2P/CUMEM
16: nid005802:6297:15923 [0] NCCL INFO ncclCommSplit comm 0x400669651260 rank 64 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 parent 0xaaab18b83d10 color 315732477 key 64 commId 0xf264858106496629 - Init COMPLETE
16: nid005802:6299:15922 [2] NCCL INFO Init timings: rank 66 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
 3: nid005580:71821:81306 [2] NCCL INFO Channel 01/0 : 14[2] -> 15[3] via P2P/CUMEM
18: nid005911:38867:48329 [3] NCCL INFO ncclCommSplit comm 0x40068964e420 rank 75 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 parent 0xaaab31f11170 color 315732477 key 75 commId 0xf264858106496629 - Init COMPLETE
18: nid005911:38867:48329 [3] NCCL INFO Init timings: rank 75 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.20, topo 0.33, graphs 0.02, connections 0.01, rest 0.00)
16: nid005802:6297:15923 [0] NCCL INFO Init timings: rank 64 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
18: nid005911:38865:48327 [1] NCCL INFO ncclCommSplit comm 0x40068564e900 rank 73 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 parent 0xaaaae2c31590 color 315732477 key 73 commId 0xf264858106496629 - Init COMPLETE
18: nid005911:38865:48327 [1] NCCL INFO Init timings: rank 73 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.20, topo 0.33, graphs 0.02, connections 0.01, rest 0.00)
19: nid005912:12435:21865 [0] NCCL INFO Init timings: rank 76 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
18: nid005911:38866:48328 [2] NCCL INFO ncclCommSplit comm 0x4006ad64e900 rank 74 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 parent 0xaaaafa2a9ac0 color 315732477 key 74 commId 0xf264858106496629 - Init COMPLETE
18: nid005911:38864:48326 [0] NCCL INFO ncclCommSplit comm 0x40068964fdf0 rank 72 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 parent 0xaaaade95adc0 color 315732477 key 72 commId 0xf264858106496629 - Init COMPLETE
18: nid005911:38866:48328 [2] NCCL INFO Init timings: rank 74 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.20, topo 0.33, graphs 0.02, connections 0.01, rest 0.00)
31: nid005937:256589:266041 [0] NCCL INFO Channel 05/0 : 124[0] -> 125[1] via P2P/CUMEM
18: nid005911:38864:48326 [0] NCCL INFO Init timings: rank 72 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.20, topo 0.33, graphs 0.02, connections 0.01, rest 0.00)
 8: nid005586:68926:78412 [0] NCCL INFO ncclCommSplit comm 0x400665651220 rank 32 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 parent 0xaaab12790160 color 315732477 key 32 commId 0xf264858106496629 - Init COMPLETE
 8: nid005586:68926:78412 [0] NCCL INFO Init timings: rank 32 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
 1: nid005576:147557:156974 [0] NCCL INFO Channel 05/0 : 4[0] -> 5[1] via P2P/CUMEM
30: nid005936:49908:59382 [0] NCCL INFO Channel 00/0 : 120[0] -> 121[1] via P2P/CUMEM
11: nid005591:191603:202313 [0] NCCL INFO ncclCommSplit comm 0x400681651260 rank 44 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 parent 0xaaaaf7916bf0 color 315732477 key 44 commId 0xf264858106496629 - Init COMPLETE
11: nid005591:191603:202313 [0] NCCL INFO Init timings: rank 44 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
 1: nid005576:147558:156971 [1] NCCL INFO Channel 01/0 : 5[1] -> 6[2] via P2P/CUMEM
 8: nid005586:68928:78413 [2] NCCL INFO ncclCommSplit comm 0x4006a964f980 rank 34 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 parent 0xaaaaf16101a0 color 315732477 key 34 commId 0xf264858106496629 - Init COMPLETE
 8: nid005586:68929:78411 [3] NCCL INFO ncclCommSplit comm 0x4006b8a880b0 rank 35 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 parent 0xaaab0425a760 color 315732477 key 35 commId 0xf264858106496629 - Init COMPLETE
 8: nid005586:68928:78413 [2] NCCL INFO Init timings: rank 34 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
11: nid005591:191605:202311 [2] NCCL INFO ncclCommSplit comm 0x4006b56513b0 rank 46 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 parent 0xaaaafb513f80 color 315732477 key 46 commId 0xf264858106496629 - Init COMPLETE
11: nid005591:191605:202311 [2] NCCL INFO Init timings: rank 46 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
 5: nid005582:196714:206703 [1] NCCL INFO Channel 01/0 : 21[1] -> 22[2] via P2P/CUMEM
 8: nid005586:68929:78411 [3] NCCL INFO Init timings: rank 35 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
 8: nid005586:68927:78410 [1] NCCL INFO ncclCommSplit comm 0x40066ca89660 rank 33 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 parent 0xaaaaec21b350 color 315732477 key 33 commId 0xf264858106496629 - Init COMPLETE
11: nid005591:191606:202312 [3] NCCL INFO ncclCommSplit comm 0x40069164fb20 rank 47 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 parent 0xaaaae7d03880 color 315732477 key 47 commId 0xf264858106496629 - Init COMPLETE
11: nid005591:191606:202312 [3] NCCL INFO Init timings: rank 47 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
17: nid005803:180732:190233 [0] NCCL INFO Channel 01/0 : 68[0] -> 69[1] via P2P/CUMEM
 8: nid005586:68927:78410 [1] NCCL INFO Init timings: rank 33 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
11: nid005591:191604:202310 [1] NCCL INFO ncclCommSplit comm 0x4006a564fd80 rank 45 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 parent 0xaaab196cb950 color 315732477 key 45 commId 0xf264858106496629 - Init COMPLETE
27: nid005922:80741:90179 [0] NCCL INFO Channel 05/0 : 108[0] -> 109[1] via P2P/CUMEM
11: nid005591:191604:202310 [1] NCCL INFO Init timings: rank 45 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
 2: nid005577:17422:26964 [0] NCCL INFO Channel 04/0 : 8[0] -> 9[1] via P2P/CUMEM
13: nid005595:197884:207691 [1] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
13: nid005595:197884:207691 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 5: nid005582:196715:206700 [2] NCCL INFO Channel 05/0 : 22[2] -> 23[3] via P2P/CUMEM
 4: nid005581:264525:273968 [2] NCCL INFO Channel 00/0 : 18[2] -> 19[3] via P2P/CUMEM
 9: nid005588:35938:45404 [3] NCCL INFO ncclCommSplit comm 0x40069164fe00 rank 39 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 parent 0xaaaadbd50910 color 315732477 key 39 commId 0xf264858106496629 - Init COMPLETE
 9: nid005588:35938:45404 [3] NCCL INFO Init timings: rank 39 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
25: nid005919:107462:116966 [0] NCCL INFO Channel 05/0 : 100[0] -> 101[1] via P2P/CUMEM
 3: nid005580:71820:81305 [1] NCCL INFO Channel 05/0 : 13[1] -> 14[2] via P2P/CUMEM
 9: nid005588:35936:45406 [1] NCCL INFO ncclCommSplit comm 0x400698a89620 rank 37 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 parent 0xaaab298ab220 color 315732477 key 37 commId 0xf264858106496629 - Init COMPLETE
 9: nid005588:35936:45406 [1] NCCL INFO Init timings: rank 37 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
13: nid005595:197883:207694 [0] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
13: nid005595:197883:207694 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 9: nid005588:35937:45405 [2] NCCL INFO ncclCommSplit comm 0x40068d64fe00 rank 38 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 parent 0xaaaae8a0c3a0 color 315732477 key 38 commId 0xf264858106496629 - Init COMPLETE
 9: nid005588:35937:45405 [2] NCCL INFO Init timings: rank 38 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
16: nid005802:6297:15936 [0] NCCL INFO Channel 00/0 : 64[0] -> 65[1] via P2P/CUMEM
 3: nid005580:71821:81306 [2] NCCL INFO Channel 05/0 : 14[2] -> 15[3] via P2P/CUMEM
19: nid005912:12435:21880 [0] NCCL INFO Channel 01/0 : 76[0] -> 77[1] via P2P/CUMEM
 8: nid005586:68926:78422 [0] NCCL INFO Channel 00/0 : 32[0] -> 33[1] via P2P/CUMEM
14: nid005600:217721:227286 [1] NCCL INFO ncclCommSplit comm 0x400679651260 rank 57 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 parent 0xaaaacda93d30 color 315732477 key 57 commId 0xf264858106496629 - Init COMPLETE
 6: nid005584:28287:37693 [2] NCCL INFO ncclCommSplit comm 0x40068964fb50 rank 26 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 parent 0xaaab07a0c730 color 315732477 key 26 commId 0xf264858106496629 - Init COMPLETE
 6: nid005584:28287:37693 [2] NCCL INFO Init timings: rank 26 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
18: nid005911:38864:48341 [0] NCCL INFO Channel 00/0 : 72[0] -> 73[1] via P2P/CUMEM
 9: nid005588:35935:45407 [0] NCCL INFO ncclCommSplit comm 0x40065964fd80 rank 36 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 parent 0xaaab148fdb70 color 315732477 key 36 commId 0xf264858106496629 - Init COMPLETE
 9: nid005588:35935:45407 [0] NCCL INFO Init timings: rank 36 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
 7: nid005585:122006:131404 [1] NCCL INFO ncclCommSplit comm 0x4006716513b0 rank 29 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 parent 0xaaab0e87b260 color 315732477 key 29 commId 0xf264858106496629 - Init COMPLETE
 7: nid005585:122008:131402 [3] NCCL INFO ncclCommSplit comm 0x4006956513a0 rank 31 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 parent 0xaaaaedf73db0 color 315732477 key 31 commId 0xf264858106496629 - Init COMPLETE
14: nid005600:217721:227286 [1] NCCL INFO Init timings: rank 57 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
 6: nid005584:28285:37691 [0] NCCL INFO ncclCommSplit comm 0x40066564e8c0 rank 24 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 parent 0xaaaafc6efb40 color 315732477 key 24 commId 0xf264858106496629 - Init COMPLETE
11: nid005591:191603:202323 [0] NCCL INFO Channel 01/0 : 44[0] -> 45[1] via P2P/CUMEM
 7: nid005585:122006:131404 [1] NCCL INFO Init timings: rank 29 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
 7: nid005585:122008:131402 [3] NCCL INFO Init timings: rank 31 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
20: nid005913:292681:9594 [0] NCCL INFO Channel 00/0 : 80[0] -> 81[1] via P2P/CUMEM
21: nid005914:166784:176212 [0] NCCL INFO ncclCommSplit comm 0x4006a164fe00 rank 84 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 parent 0xaaab092dcbd0 color 315732477 key 84 commId 0xf264858106496629 - Init COMPLETE
21: nid005914:166784:176212 [0] NCCL INFO Init timings: rank 84 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
14: nid005600:217723:227284 [3] NCCL INFO ncclCommSplit comm 0x4006bd64e900 rank 59 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 parent 0xaaab2a979520 color 315732477 key 59 commId 0xf264858106496629 - Init COMPLETE
14: nid005600:217723:227284 [3] NCCL INFO Init timings: rank 59 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
 7: nid005585:122007:131403 [2] NCCL INFO ncclCommSplit comm 0x4006b564fe00 rank 30 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 parent 0xaaaadd869ba0 color 315732477 key 30 commId 0xf264858106496629 - Init COMPLETE
14: nid005600:217720:227285 [0] NCCL INFO ncclCommSplit comm 0x40066964fdc0 rank 56 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 parent 0xaaaadc9bcbc0 color 315732477 key 56 commId 0xf264858106496629 - Init COMPLETE
 6: nid005584:28285:37691 [0] NCCL INFO Init timings: rank 24 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
22: nid005915:274814:284265 [0] NCCL INFO Channel 04/0 : 88[0] -> 89[1] via P2P/CUMEM
 7: nid005585:122007:131403 [2] NCCL INFO Init timings: rank 30 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
 5: nid005582:196714:206703 [1] NCCL INFO Channel 05/0 : 21[1] -> 22[2] via P2P/CUMEM
21: nid005914:166786:176213 [2] NCCL INFO ncclCommSplit comm 0x40068564fdf0 rank 86 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 parent 0xaaab02d82db0 color 315732477 key 86 commId 0xf264858106496629 - Init COMPLETE
14: nid005600:217720:227285 [0] NCCL INFO Init timings: rank 56 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
14: nid005600:217722:227283 [2] NCCL INFO ncclCommSplit comm 0x40068d6513b0 rank 58 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 parent 0xaaaada11bcd0 color 315732477 key 58 commId 0xf264858106496629 - Init COMPLETE
 6: nid005584:28286:37692 [1] NCCL INFO ncclCommSplit comm 0x40068964fe00 rank 25 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 parent 0xaaab2173c180 color 315732477 key 25 commId 0xf264858106496629 - Init COMPLETE
 6: nid005584:28286:37692 [1] NCCL INFO Init timings: rank 25 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
10: nid005590:110713:120120 [3] NCCL INFO ncclCommSplit comm 0x4006a9653dc0 rank 43 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 parent 0xaaab375e3b60 color 315732477 key 43 commId 0xf264858106496629 - Init COMPLETE
 7: nid005585:122005:131405 [0] NCCL INFO ncclCommSplit comm 0x40067964fe00 rank 28 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 parent 0xaaab166fca20 color 315732477 key 28 commId 0xf264858106496629 - Init COMPLETE
 7: nid005585:122005:131405 [0] NCCL INFO Init timings: rank 28 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
21: nid005914:166786:176213 [2] NCCL INFO Init timings: rank 86 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
14: nid005600:217722:227283 [2] NCCL INFO Init timings: rank 58 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
 6: nid005584:28288:37690 [3] NCCL INFO ncclCommSplit comm 0x400698a880b0 rank 27 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 parent 0xaaaaf69fb200 color 315732477 key 27 commId 0xf264858106496629 - Init COMPLETE
10: nid005590:110711:120117 [1] NCCL INFO ncclCommSplit comm 0x4006896528c0 rank 41 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 parent 0xaaab10df3460 color 315732477 key 41 commId 0xf264858106496629 - Init COMPLETE
10: nid005590:110713:120120 [3] NCCL INFO Init timings: rank 43 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
21: nid005914:166787:176211 [3] NCCL INFO ncclCommSplit comm 0x40069964fe00 rank 87 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 parent 0xaaaadea21c50 color 315732477 key 87 commId 0xf264858106496629 - Init COMPLETE
21: nid005914:166785:176214 [1] NCCL INFO ncclCommSplit comm 0x400689651260 rank 85 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 parent 0xaaaaf1392a50 color 315732477 key 85 commId 0xf264858106496629 - Init COMPLETE
21: nid005914:166787:176211 [3] NCCL INFO Init timings: rank 87 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
 6: nid005584:28288:37690 [3] NCCL INFO Init timings: rank 27 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
31: nid005937:256591:266040 [2] NCCL INFO Channel 01/0 : 126[2] -> 127[3] via P2P/CUMEM
12: nid005594:53085:62558 [0] NCCL INFO ncclCommSplit comm 0x40068d64fb30 rank 48 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 parent 0xaaab0e435340 color 315732477 key 48 commId 0xf264858106496629 - Init COMPLETE
10: nid005590:110711:120117 [1] NCCL INFO Init timings: rank 41 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
 4: nid005581:264524:273971 [1] NCCL INFO Channel 00/0 : 17[1] -> 18[2] via P2P/CUMEM
21: nid005914:166785:176214 [1] NCCL INFO Init timings: rank 85 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
12: nid005594:53085:62558 [0] NCCL INFO Init timings: rank 48 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
10: nid005590:110712:120119 [2] NCCL INFO ncclCommSplit comm 0x40069d64e3d0 rank 42 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 parent 0xaaab104db470 color 315732477 key 42 commId 0xf264858106496629 - Init COMPLETE
10: nid005590:110712:120119 [2] NCCL INFO Init timings: rank 42 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
12: nid005594:53087:62559 [2] NCCL INFO ncclCommSplit comm 0x40068164e880 rank 50 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 parent 0xaaab36e31f10 color 315732477 key 50 commId 0xf264858106496629 - Init COMPLETE
12: nid005594:53087:62559 [2] NCCL INFO Init timings: rank 50 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
10: nid005590:110710:120118 [0] NCCL INFO ncclCommSplit comm 0x40066964e420 rank 40 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 parent 0xaaab23d6b530 color 315732477 key 40 commId 0xf264858106496629 - Init COMPLETE
 4: nid005581:264525:273968 [2] NCCL INFO Channel 04/0 : 18[2] -> 19[3] via P2P/CUMEM
12: nid005594:53088:62557 [3] NCCL INFO ncclCommSplit comm 0x40068164fe00 rank 51 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 parent 0xaaab14e02fb0 color 315732477 key 51 commId 0xf264858106496629 - Init COMPLETE
12: nid005594:53088:62557 [3] NCCL INFO Init timings: rank 51 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
10: nid005590:110710:120118 [0] NCCL INFO Init timings: rank 40 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
28: nid005929:16030:25510 [0] NCCL INFO Channel 04/0 : 112[0] -> 113[1] via P2P/CUMEM
12: nid005594:53086:62556 [1] NCCL INFO ncclCommSplit comm 0x40067164fdf0 rank 49 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 parent 0xaaaadbafb110 color 315732477 key 49 commId 0xf264858106496629 - Init COMPLETE
12: nid005594:53086:62556 [1] NCCL INFO Init timings: rank 49 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
27: nid005922:80743:90177 [2] NCCL INFO Channel 01/0 : 110[2] -> 111[3] via P2P/CUMEM
 6: nid005584:28285:37704 [0] NCCL INFO Channel 00/0 : 24[0] -> 25[1] via P2P/CUMEM
 1: nid005576:147559:156973 [2] NCCL INFO Channel 01/0 : 6[2] -> 7[3] via P2P/CUMEM
15: nid005601:210678:220212 [2] NCCL INFO ncclCommSplit comm 0x40068d6528c0 rank 62 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 parent 0xaaab22984300 color 315732477 key 62 commId 0xf264858106496629 - Init COMPLETE
15: nid005601:210678:220212 [2] NCCL INFO Init timings: rank 62 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
 3: nid005580:71819:81307 [0] NCCL INFO Channel 02/0 : 12[0] -> 15[3] via P2P/CUMEM
14: nid005600:217720:227296 [0] NCCL INFO Channel 00/0 : 56[0] -> 57[1] via P2P/CUMEM
 1: nid005576:147558:156971 [1] NCCL INFO Channel 05/0 : 5[1] -> 6[2] via P2P/CUMEM
 9: nid005588:35935:45419 [0] NCCL INFO Channel 01/0 : 36[0] -> 37[1] via P2P/CUMEM
21: nid005914:166784:176223 [0] NCCL INFO Channel 01/0 : 84[0] -> 85[1] via P2P/CUMEM
26: nid005920:67125:76601 [2] NCCL INFO Channel 00/0 : 106[2] -> 107[3] via P2P/CUMEM
23: nid005917:276885:286375 [0] NCCL INFO Channel 05/0 : 92[0] -> 93[1] via P2P/CUMEM
28: nid005929:16032:25507 [2] NCCL INFO Channel 00/0 : 114[2] -> 115[3] via P2P/CUMEM
31: nid005937:256590:266043 [1] NCCL INFO Channel 01/0 : 125[1] -> 126[2] via P2P/CUMEM
 0: nid005574:69058:78874 [0] NCCL INFO Channel 04/0 : 0[0] -> 1[1] via P2P/CUMEM
 0: nid005574:69059:78871 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM
15: nid005601:210676:220214 [0] NCCL INFO ncclCommSplit comm 0x40068164fe00 rank 60 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 parent 0xaaab05fd2fb0 color 315732477 key 60 commId 0xf264858106496629 - Init COMPLETE
15: nid005601:210676:220214 [0] NCCL INFO Init timings: rank 60 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
 7: nid005585:122005:131417 [0] NCCL INFO Channel 01/0 : 28[0] -> 29[1] via P2P/CUMEM
 5: nid005582:196713:206701 [0] NCCL INFO Channel 02/0 : 20[0] -> 23[3] via P2P/CUMEM
26: nid005920:67124:76603 [1] NCCL INFO Channel 00/0 : 105[1] -> 106[2] via P2P/CUMEM
 2: nid005577:17423:26961 [1] NCCL INFO Channel 00/0 : 9[1] -> 10[2] via P2P/CUMEM
15: nid005601:210677:220213 [1] NCCL INFO ncclCommSplit comm 0x40068d64fdf0 rank 61 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 parent 0xaaaaee59b4c0 color 315732477 key 61 commId 0xf264858106496629 - Init COMPLETE
15: nid005601:210677:220213 [1] NCCL INFO Init timings: rank 61 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
31: nid005937:256591:266040 [2] NCCL INFO Channel 05/0 : 126[2] -> 127[3] via P2P/CUMEM
 4: nid005581:264524:273971 [1] NCCL INFO Channel 04/0 : 17[1] -> 18[2] via P2P/CUMEM
15: nid005601:210679:220215 [3] NCCL INFO ncclCommSplit comm 0x4006ad64fdf0 rank 63 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 parent 0xaaab0b2c3130 color 315732477 key 63 commId 0xf264858106496629 - Init COMPLETE
15: nid005601:210679:220215 [3] NCCL INFO Init timings: rank 63 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.21, topo 0.32, graphs 0.02, connections 0.01, rest 0.00)
 3: nid005580:71819:81307 [0] NCCL INFO Channel 03/0 : 12[0] -> 15[3] via P2P/CUMEM
25: nid005919:107464:116967 [2] NCCL INFO Channel 01/0 : 102[2] -> 103[3] via P2P/CUMEM
30: nid005936:49908:59382 [0] NCCL INFO Channel 04/0 : 120[0] -> 121[1] via P2P/CUMEM
27: nid005922:80742:90176 [1] NCCL INFO Channel 01/0 : 109[1] -> 110[2] via P2P/CUMEM
22: nid005915:274816:284264 [2] NCCL INFO Channel 00/0 : 90[2] -> 91[3] via P2P/CUMEM
 2: nid005577:17424:26963 [2] NCCL INFO Channel 00/0 : 10[2] -> 11[3] via P2P/CUMEM
25: nid005919:107463:116969 [1] NCCL INFO Channel 01/0 : 101[1] -> 102[2] via P2P/CUMEM
22: nid005915:274815:284266 [1] NCCL INFO Channel 00/0 : 89[1] -> 90[2] via P2P/CUMEM
27: nid005922:80743:90177 [2] NCCL INFO Channel 05/0 : 110[2] -> 111[3] via P2P/CUMEM
 8: nid005586:68926:78422 [0] NCCL INFO Channel 04/0 : 32[0] -> 33[1] via P2P/CUMEM
31: nid005937:256590:266043 [1] NCCL INFO Channel 05/0 : 125[1] -> 126[2] via P2P/CUMEM
10: nid005590:110710:120132 [0] NCCL INFO Channel 00/0 : 40[0] -> 41[1] via P2P/CUMEM
15: nid005601:210676:220224 [0] NCCL INFO Channel 01/0 : 60[0] -> 61[1] via P2P/CUMEM
12: nid005594:53085:62591 [0] NCCL INFO Channel 00/0 : 48[0] -> 49[1] via P2P/CUMEM
17: nid005803:180733:190230 [1] NCCL INFO Channel 01/0 : 69[1] -> 70[2] via P2P/CUMEM
 5: nid005582:196713:206701 [0] NCCL INFO Channel 03/0 : 20[0] -> 23[3] via P2P/CUMEM
13: nid005595:197885:207692 [2] NCCL INFO ncclCommSplit comm 0x4006a96528c0 rank 54 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 parent 0xaaab3c8b15f0 color 315732477 key 54 commId 0xf264858106496629 - Init COMPLETE
13: nid005595:197886:207693 [3] NCCL INFO ncclCommSplit comm 0x40069164e840 rank 55 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 parent 0xaaaaea46b560 color 315732477 key 55 commId 0xf264858106496629 - Init COMPLETE
 2: nid005577:17423:26961 [1] NCCL INFO Channel 04/0 : 9[1] -> 10[2] via P2P/CUMEM
 1: nid005576:147559:156973 [2] NCCL INFO Channel 05/0 : 6[2] -> 7[3] via P2P/CUMEM
17: nid005803:180732:190233 [0] NCCL INFO Channel 05/0 : 68[0] -> 69[1] via P2P/CUMEM
20: nid005913:292681:9594 [0] NCCL INFO Channel 04/0 : 80[0] -> 81[1] via P2P/CUMEM
26: nid005920:67125:76601 [2] NCCL INFO Channel 04/0 : 106[2] -> 107[3] via P2P/CUMEM
16: nid005802:6297:15936 [0] NCCL INFO Channel 04/0 : 64[0] -> 65[1] via P2P/CUMEM
 3: nid005580:71819:81307 [0] NCCL INFO Channel 06/0 : 12[0] -> 15[3] via P2P/CUMEM
13: nid005595:197886:207693 [3] NCCL INFO Init timings: rank 55 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.22, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
13: nid005595:197885:207692 [2] NCCL INFO Init timings: rank 54 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.23, topo 0.30, graphs 0.02, connections 0.01, rest 0.00)
26: nid005920:67124:76603 [1] NCCL INFO Channel 04/0 : 105[1] -> 106[2] via P2P/CUMEM
13: nid005595:197883:207694 [0] NCCL INFO ncclCommSplit comm 0x40068164e880 rank 52 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 parent 0xaaab1fa69360 color 315732477 key 52 commId 0xf264858106496629 - Init COMPLETE
19: nid005912:12435:21880 [0] NCCL INFO Channel 05/0 : 76[0] -> 77[1] via P2P/CUMEM
30: nid005936:49910:59381 [2] NCCL INFO Channel 00/0 : 122[2] -> 123[3] via P2P/CUMEM
28: nid005929:16031:25509 [1] NCCL INFO Channel 00/0 : 113[1] -> 114[2] via P2P/CUMEM
22: nid005915:274816:284264 [2] NCCL INFO Channel 04/0 : 90[2] -> 91[3] via P2P/CUMEM
 2: nid005577:17424:26963 [2] NCCL INFO Channel 04/0 : 10[2] -> 11[3] via P2P/CUMEM
 4: nid005581:264523:273969 [0] NCCL INFO Channel 02/0 : 16[0] -> 19[3] via P2P/CUMEM
13: nid005595:197883:207694 [0] NCCL INFO Init timings: rank 52 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.22, topo 0.31, graphs 0.02, connections 0.01, rest 0.00)
18: nid005911:38864:48341 [0] NCCL INFO Channel 04/0 : 72[0] -> 73[1] via P2P/CUMEM
25: nid005919:107464:116967 [2] NCCL INFO Channel 05/0 : 102[2] -> 103[3] via P2P/CUMEM
30: nid005936:49909:59380 [1] NCCL INFO Channel 00/0 : 121[1] -> 122[2] via P2P/CUMEM
 1: nid005576:147557:156974 [0] NCCL INFO Channel 02/0 : 4[0] -> 7[3] via P2P/CUMEM
13: nid005595:197884:207691 [1] NCCL INFO ncclCommSplit comm 0x40068d64e840 rank 53 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 parent 0xaaab0cbd2c40 color 315732477 key 53 commId 0xf264858106496629 - Init COMPLETE
13: nid005595:197884:207691 [1] NCCL INFO Init timings: rank 53 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.23, topo 0.30, graphs 0.02, connections 0.01, rest 0.00)
25: nid005919:107463:116969 [1] NCCL INFO Channel 05/0 : 101[1] -> 102[2] via P2P/CUMEM
11: nid005591:191603:202323 [0] NCCL INFO Channel 05/0 : 44[0] -> 45[1] via P2P/CUMEM
22: nid005915:274815:284266 [1] NCCL INFO Channel 04/0 : 89[1] -> 90[2] via P2P/CUMEM
27: nid005922:80742:90176 [1] NCCL INFO Channel 05/0 : 109[1] -> 110[2] via P2P/CUMEM
29: nid005932:167683:177110 [3] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
29: nid005932:167683:177110 [3] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
28: nid005929:16032:25507 [2] NCCL INFO Channel 04/0 : 114[2] -> 115[3] via P2P/CUMEM
31: nid005937:256589:266041 [0] NCCL INFO Channel 02/0 : 124[0] -> 127[3] via P2P/CUMEM
 5: nid005582:196713:206701 [0] NCCL INFO Channel 06/0 : 20[0] -> 23[3] via P2P/CUMEM
21: nid005914:166784:176223 [0] NCCL INFO Channel 05/0 : 84[0] -> 85[1] via P2P/CUMEM
28: nid005929:16031:25509 [1] NCCL INFO Channel 04/0 : 113[1] -> 114[2] via P2P/CUMEM
 1: nid005576:147557:156974 [0] NCCL INFO Channel 03/0 : 4[0] -> 7[3] via P2P/CUMEM
 3: nid005580:71819:81307 [0] NCCL INFO Channel 07/0 : 12[0] -> 15[3] via P2P/CUMEM
 4: nid005581:264523:273969 [0] NCCL INFO Channel 03/0 : 16[0] -> 19[3] via P2P/CUMEM
23: nid005917:276886:286373 [1] NCCL INFO Channel 01/0 : 93[1] -> 94[2] via P2P/CUMEM
 0: nid005574:69059:78871 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM
13: nid005595:197883:207703 [0] NCCL INFO Channel 01/0 : 52[0] -> 53[1] via P2P/CUMEM
 9: nid005588:35935:45419 [0] NCCL INFO Channel 05/0 : 36[0] -> 37[1] via P2P/CUMEM
20: nid005913:292682:9590 [1] NCCL INFO Channel 00/0 : 81[1] -> 82[2] via P2P/CUMEM
 2: nid005577:17422:26964 [0] NCCL INFO Channel 02/0 : 8[0] -> 11[3] via P2P/CUMEM
 5: nid005582:196715:206700 [2] NCCL INFO Channel 03/0 : 18[2] -> 22[2] [receive] via NET/AWS Libfabric/2
23: nid005917:276887:286376 [2] NCCL INFO Channel 01/0 : 94[2] -> 95[3] via P2P/CUMEM
 0: nid005574:69060:78872 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM
17: nid005803:180734:190232 [2] NCCL INFO Channel 01/0 : 70[2] -> 71[3] via P2P/CUMEM
17: nid005803:180733:190230 [1] NCCL INFO Channel 05/0 : 69[1] -> 70[2] via P2P/CUMEM
20: nid005913:292683:9593 [2] NCCL INFO Channel 00/0 : 82[2] -> 83[3] via P2P/CUMEM
30: nid005936:49910:59381 [2] NCCL INFO Channel 04/0 : 122[2] -> 123[3] via P2P/CUMEM
30: nid005936:49909:59380 [1] NCCL INFO Channel 04/0 : 121[1] -> 122[2] via P2P/CUMEM
 6: nid005584:28285:37704 [0] NCCL INFO Channel 04/0 : 24[0] -> 25[1] via P2P/CUMEM
 1: nid005576:147557:156974 [0] NCCL INFO Channel 06/0 : 4[0] -> 7[3] via P2P/CUMEM
16: nid005802:6299:15934 [2] NCCL INFO Channel 00/0 : 66[2] -> 67[3] via P2P/CUMEM
 5: nid005582:196715:206700 [2] NCCL INFO Channel 07/0 : 18[2] -> 22[2] [receive] via NET/AWS Libfabric/2
 3: nid005580:71820:81305 [1] NCCL INFO Channel 02/0 : 9[1] -> 13[1] [receive] via NET/AWS Libfabric/1
26: nid005920:67123:76600 [0] NCCL INFO Channel 02/0 : 104[0] -> 107[3] via P2P/CUMEM
27: nid005922:80741:90179 [0] NCCL INFO Channel 02/0 : 108[0] -> 111[3] via P2P/CUMEM
31: nid005937:256589:266041 [0] NCCL INFO Channel 03/0 : 124[0] -> 127[3] via P2P/CUMEM
 3: nid005580:71821:81306 [2] NCCL INFO Channel 03/0 : 10[2] -> 14[2] [receive] via NET/AWS Libfabric/2
 5: nid005582:196713:206701 [0] NCCL INFO Channel 07/0 : 20[0] -> 23[3] via P2P/CUMEM
 5: nid005582:196714:206703 [1] NCCL INFO Channel 02/0 : 17[1] -> 21[1] [receive] via NET/AWS Libfabric/1
14: nid005600:217720:227296 [0] NCCL INFO Channel 04/0 : 56[0] -> 57[1] via P2P/CUMEM
 2: nid005577:17422:26964 [0] NCCL INFO Channel 03/0 : 8[0] -> 11[3] via P2P/CUMEM
16: nid005802:6298:15933 [1] NCCL INFO Channel 00/0 : 65[1] -> 66[2] via P2P/CUMEM
15: nid005601:210676:220224 [0] NCCL INFO Channel 05/0 : 60[0] -> 61[1] via P2P/CUMEM
 7: nid005585:122005:131417 [0] NCCL INFO Channel 05/0 : 28[0] -> 29[1] via P2P/CUMEM
19: nid005912:12437:21879 [2] NCCL INFO Channel 01/0 : 78[2] -> 79[3] via P2P/CUMEM
22: nid005915:274814:284265 [0] NCCL INFO Channel 02/0 : 88[0] -> 91[3] via P2P/CUMEM
 4: nid005581:264523:273969 [0] NCCL INFO Channel 06/0 : 16[0] -> 19[3] via P2P/CUMEM
 3: nid005580:71820:81305 [1] NCCL INFO Channel 06/0 : 9[1] -> 13[1] [receive] via NET/AWS Libfabric/1
 5: nid005582:196715:206700 [2] NCCL INFO Channel 02/0 : 22[2] -> 26[2] [send] via NET/AWS Libfabric/2
 8: nid005586:68928:78423 [2] NCCL INFO Channel 00/0 : 34[2] -> 35[3] via P2P/CUMEM
14: nid005600:217721:227295 [1] NCCL INFO Channel 00/0 : 57[1] -> 58[2] via P2P/CUMEM
11: nid005591:191605:202322 [2] NCCL INFO Channel 01/0 : 46[2] -> 47[3] via P2P/CUMEM
 3: nid005580:71821:81306 [2] NCCL INFO Channel 07/0 : 10[2] -> 14[2] [receive] via NET/AWS Libfabric/2
 5: nid005582:196714:206703 [1] NCCL INFO Channel 06/0 : 17[1] -> 21[1] [receive] via NET/AWS Libfabric/1
19: nid005912:12436:21878 [1] NCCL INFO Channel 01/0 : 77[1] -> 78[2] via P2P/CUMEM
25: nid005919:107462:116966 [0] NCCL INFO Channel 02/0 : 100[0] -> 103[3] via P2P/CUMEM
23: nid005917:276886:286373 [1] NCCL INFO Channel 05/0 : 93[1] -> 94[2] via P2P/CUMEM
 5: nid005582:196715:206700 [2] NCCL INFO Channel 06/0 : 22[2] -> 26[2] [send] via NET/AWS Libfabric/2
23: nid005917:276887:286376 [2] NCCL INFO Channel 05/0 : 94[2] -> 95[3] via P2P/CUMEM
27: nid005922:80741:90179 [0] NCCL INFO Channel 03/0 : 108[0] -> 111[3] via P2P/CUMEM
 0: nid005574:69060:78872 [2] NCCL INFO Channel 04/0 : 2[2] -> 3[3] via P2P/CUMEM
 5: nid005582:196714:206703 [1] NCCL INFO Channel 03/0 : 21[1] -> 25[1] [send] via NET/AWS Libfabric/1
 1: nid005576:147557:156974 [0] NCCL INFO Channel 07/0 : 4[0] -> 7[3] via P2P/CUMEM
 3: nid005580:71821:81306 [2] NCCL INFO Channel 02/0 : 14[2] -> 18[2] [send] via NET/AWS Libfabric/2
 3: nid005580:71820:81305 [1] NCCL INFO Channel 03/0 : 13[1] -> 17[1] [send] via NET/AWS Libfabric/1
28: nid005929:16030:25510 [0] NCCL INFO Channel 02/0 : 112[0] -> 115[3] via P2P/CUMEM
31: nid005937:256589:266041 [0] NCCL INFO Channel 06/0 : 124[0] -> 127[3] via P2P/CUMEM
 0: nid005574:69058:78874 [0] NCCL INFO Channel 02/0 : 0[0] -> 3[3] via P2P/CUMEM
10: nid005590:110710:120132 [0] NCCL INFO Channel 04/0 : 40[0] -> 41[1] via P2P/CUMEM
 5: nid005582:196714:206703 [1] NCCL INFO Channel 07/0 : 21[1] -> 25[1] [send] via NET/AWS Libfabric/1
26: nid005920:67123:76600 [0] NCCL INFO Channel 03/0 : 104[0] -> 107[3] via P2P/CUMEM
 8: nid005586:68927:78425 [1] NCCL INFO Channel 00/0 : 33[1] -> 34[2] via P2P/CUMEM
12: nid005594:53085:62591 [0] NCCL INFO Channel 04/0 : 48[0] -> 49[1] via P2P/CUMEM
18: nid005911:38865:48338 [1] NCCL INFO Channel 00/0 : 73[1] -> 74[2] via P2P/CUMEM
29: nid005932:167682:177113 [2] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
29: nid005932:167682:177113 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
18: nid005911:38866:48340 [2] NCCL INFO Channel 00/0 : 74[2] -> 75[3] via P2P/CUMEM
22: nid005915:274814:284265 [0] NCCL INFO Channel 03/0 : 88[0] -> 91[3] via P2P/CUMEM
 2: nid005577:17422:26964 [0] NCCL INFO Channel 06/0 : 8[0] -> 11[3] via P2P/CUMEM
 4: nid005581:264525:273968 [2] NCCL INFO Channel 02/0 : 14[2] -> 18[2] [receive] via NET/AWS Libfabric/2
 9: nid005588:35936:45416 [1] NCCL INFO Channel 01/0 : 37[1] -> 38[2] via P2P/CUMEM
16: nid005802:6299:15934 [2] NCCL INFO Channel 04/0 : 66[2] -> 67[3] via P2P/CUMEM
 3: nid005580:71821:81306 [2] NCCL INFO Channel 06/0 : 14[2] -> 18[2] [send] via NET/AWS Libfabric/2
 3: nid005580:71820:81305 [1] NCCL INFO Channel 07/0 : 13[1] -> 17[1] [send] via NET/AWS Libfabric/1
30: nid005936:49908:59382 [0] NCCL INFO Channel 02/0 : 120[0] -> 123[3] via P2P/CUMEM
 8: nid005586:68928:78423 [2] NCCL INFO Channel 04/0 : 34[2] -> 35[3] via P2P/CUMEM
11: nid005591:191604:202325 [1] NCCL INFO Channel 01/0 : 45[1] -> 46[2] via P2P/CUMEM
12: nid005594:53087:62589 [2] NCCL INFO Channel 00/0 : 50[2] -> 51[3] via P2P/CUMEM
 1: nid005576:147558:156971 [1] NCCL INFO Channel 02/0 : 1[1] -> 5[1] [receive] via NET/AWS Libfabric/1
 4: nid005581:264523:273969 [0] NCCL INFO Channel 07/0 : 16[0] -> 19[3] via P2P/CUMEM
16: nid005802:6298:15933 [1] NCCL INFO Channel 04/0 : 65[1] -> 66[2] via P2P/CUMEM
20: nid005913:292682:9590 [1] NCCL INFO Channel 04/0 : 81[1] -> 82[2] via P2P/CUMEM
19: nid005912:12437:21879 [2] NCCL INFO Channel 05/0 : 78[2] -> 79[3] via P2P/CUMEM
 6: nid005584:28286:37703 [1] NCCL INFO Channel 00/0 : 25[1] -> 26[2] via P2P/CUMEM
11: nid005591:191605:202322 [2] NCCL INFO Channel 05/0 : 46[2] -> 47[3] via P2P/CUMEM
 4: nid005581:264525:273968 [2] NCCL INFO Channel 06/0 : 14[2] -> 18[2] [receive] via NET/AWS Libfabric/2
 9: nid005588:35937:45418 [2] NCCL INFO Channel 01/0 : 38[2] -> 39[3] via P2P/CUMEM
17: nid005803:180734:190232 [2] NCCL INFO Channel 05/0 : 70[2] -> 71[3] via P2P/CUMEM
20: nid005913:292683:9593 [2] NCCL INFO Channel 04/0 : 82[2] -> 83[3] via P2P/CUMEM
19: nid005912:12436:21878 [1] NCCL INFO Channel 05/0 : 77[1] -> 78[2] via P2P/CUMEM
25: nid005919:107462:116966 [0] NCCL INFO Channel 03/0 : 100[0] -> 103[3] via P2P/CUMEM
27: nid005922:80741:90179 [0] NCCL INFO Channel 06/0 : 108[0] -> 111[3] via P2P/CUMEM
 8: nid005586:68927:78425 [1] NCCL INFO Channel 04/0 : 33[1] -> 34[2] via P2P/CUMEM
 0: nid005574:69058:78874 [0] NCCL INFO Channel 03/0 : 0[0] -> 3[3] via P2P/CUMEM
 1: nid005576:147558:156971 [1] NCCL INFO Channel 06/0 : 1[1] -> 5[1] [receive] via NET/AWS Libfabric/1
 4: nid005581:264525:273968 [2] NCCL INFO Channel 03/0 : 18[2] -> 22[2] [send] via NET/AWS Libfabric/2
26: nid005920:67123:76600 [0] NCCL INFO Channel 06/0 : 104[0] -> 107[3] via P2P/CUMEM
31: nid005937:256591:266040 [2] NCCL INFO Channel 03/0 : 122[2] -> 126[2] [receive] via NET/AWS Libfabric/2
31: nid005937:256589:266041 [0] NCCL INFO Channel 07/0 : 124[0] -> 127[3] via P2P/CUMEM
 1: nid005576:147558:156971 [1] NCCL INFO Channel 03/0 : 5[1] -> 9[1] [send] via NET/AWS Libfabric/1
28: nid005929:16030:25510 [0] NCCL INFO Channel 03/0 : 112[0] -> 115[3] via P2P/CUMEM
31: nid005937:256590:266043 [1] NCCL INFO Channel 02/0 : 121[1] -> 125[1] [receive] via NET/AWS Libfabric/1
 4: nid005581:264525:273968 [2] NCCL INFO Channel 07/0 : 18[2] -> 22[2] [send] via NET/AWS Libfabric/2
18: nid005911:38865:48338 [1] NCCL INFO Channel 04/0 : 73[1] -> 74[2] via P2P/CUMEM
21: nid005914:166786:176224 [2] NCCL INFO Channel 01/0 : 86[2] -> 87[3] via P2P/CUMEM
 9: nid005588:35936:45416 [1] NCCL INFO Channel 05/0 : 37[1] -> 38[2] via P2P/CUMEM
 7: nid005585:122007:131416 [2] NCCL INFO Channel 01/0 : 30[2] -> 31[3] via P2P/CUMEM
23: nid005917:276885:286375 [0] NCCL INFO Channel 02/0 : 92[0] -> 95[3] via P2P/CUMEM
22: nid005915:274814:284265 [0] NCCL INFO Channel 06/0 : 88[0] -> 91[3] via P2P/CUMEM
31: nid005937:256591:266040 [2] NCCL INFO Channel 07/0 : 122[2] -> 126[2] [receive] via NET/AWS Libfabric/2
 0: nid005574:69058:78874 [0] NCCL INFO Channel 06/0 : 0[0] -> 3[3] via P2P/CUMEM
10: nid005590:110711:120129 [1] NCCL INFO Channel 00/0 : 41[1] -> 42[2] via P2P/CUMEM
 2: nid005577:17423:26961 [1] NCCL INFO Channel 03/0 : 5[1] -> 9[1] [receive] via NET/AWS Libfabric/1
 1: nid005576:147558:156971 [1] NCCL INFO Channel 07/0 : 5[1] -> 9[1] [send] via NET/AWS Libfabric/1
 4: nid005581:264524:273971 [1] NCCL INFO Channel 03/0 : 13[1] -> 17[1] [receive] via NET/AWS Libfabric/1
17: nid005803:180732:190233 [0] NCCL INFO Channel 02/0 : 68[0] -> 71[3] via P2P/CUMEM
 7: nid005585:122006:131415 [1] NCCL INFO Channel 01/0 : 29[1] -> 30[2] via P2P/CUMEM
13: nid005595:197883:207703 [0] NCCL INFO Channel 05/0 : 52[0] -> 53[1] via P2P/CUMEM
 6: nid005584:28287:37702 [2] NCCL INFO Channel 00/0 : 26[2] -> 27[3] via P2P/CUMEM
11: nid005591:191604:202325 [1] NCCL INFO Channel 05/0 : 45[1] -> 46[2] via P2P/CUMEM
 2: nid005577:17422:26964 [0] NCCL INFO Channel 07/0 : 8[0] -> 11[3] via P2P/CUMEM
 1: nid005576:147559:156973 [2] NCCL INFO Channel 03/0 : 2[2] -> 6[2] [receive] via NET/AWS Libfabric/2
 9: nid005588:35937:45418 [2] NCCL INFO Channel 05/0 : 38[2] -> 39[3] via P2P/CUMEM
18: nid005911:38866:48340 [2] NCCL INFO Channel 04/0 : 74[2] -> 75[3] via P2P/CUMEM
21: nid005914:166785:176225 [1] NCCL INFO Channel 01/0 : 85[1] -> 86[2] via P2P/CUMEM
25: nid005919:107462:116966 [0] NCCL INFO Channel 06/0 : 100[0] -> 103[3] via P2P/CUMEM
27: nid005922:80741:90179 [0] NCCL INFO Channel 07/0 : 108[0] -> 111[3] via P2P/CUMEM
14: nid005600:217722:227298 [2] NCCL INFO Channel 00/0 : 58[2] -> 59[3] via P2P/CUMEM
14: nid005600:217721:227295 [1] NCCL INFO Channel 04/0 : 57[1] -> 58[2] via P2P/CUMEM
31: nid005937:256590:266043 [1] NCCL INFO Channel 06/0 : 121[1] -> 125[1] [receive] via NET/AWS Libfabric/1
 2: nid005577:17423:26961 [1] NCCL INFO Channel 07/0 : 5[1] -> 9[1] [receive] via NET/AWS Libfabric/1
 4: nid005581:264524:273971 [1] NCCL INFO Channel 07/0 : 13[1] -> 17[1] [receive] via NET/AWS Libfabric/1
27: nid005922:80743:90177 [2] NCCL INFO Channel 03/0 : 106[2] -> 110[2] [receive] via NET/AWS Libfabric/2
 8: nid005586:68926:78422 [0] NCCL INFO Channel 02/0 : 32[0] -> 35[3] via P2P/CUMEM
31: nid005937:256591:266040 [2] NCCL INFO Channel 02/0 : 126[2] -> 2[2] [send] via NET/AWS Libfabric/2
 2: nid005577:17423:26961 [1] NCCL INFO Channel 02/0 : 9[1] -> 13[1] [send] via NET/AWS Libfabric/1
 1: nid005576:147559:156973 [2] NCCL INFO Channel 07/0 : 2[2] -> 6[2] [receive] via NET/AWS Libfabric/2
 4: nid005581:264524:273971 [1] NCCL INFO Channel 02/0 : 17[1] -> 21[1] [send] via NET/AWS Libfabric/1
20: nid005913:292681:9594 [0] NCCL INFO Channel 02/0 : 80[0] -> 83[3] via P2P/CUMEM
26: nid005920:67125:76601 [2] NCCL INFO Channel 02/0 : 102[2] -> 106[2] [receive] via NET/AWS Libfabric/2
30: nid005936:49908:59382 [0] NCCL INFO Channel 03/0 : 120[0] -> 123[3] via P2P/CUMEM
 2: nid005577:17424:26963 [2] NCCL INFO Channel 02/0 : 6[2] -> 10[2] [receive] via NET/AWS Libfabric/2
 4: nid005581:264525:273968 [2] NCCL INFO Channel 02/0 : 18[2] -> 16[0] via P2P/CUMEM
17: nid005803:180732:190233 [0] NCCL INFO Channel 03/0 : 68[0] -> 71[3] via P2P/CUMEM
19: nid005912:12435:21880 [0] NCCL INFO Channel 02/0 : 76[0] -> 79[3] via P2P/CUMEM
26: nid005920:67123:76600 [0] NCCL INFO Channel 07/0 : 104[0] -> 107[3] via P2P/CUMEM
28: nid005929:16030:25510 [0] NCCL INFO Channel 06/0 : 112[0] -> 115[3] via P2P/CUMEM
22: nid005915:274816:284264 [2] NCCL INFO Channel 02/0 : 86[2] -> 90[2] [receive] via NET/AWS Libfabric/2
31: nid005937:256590:266043 [1] NCCL INFO Channel 03/0 : 125[1] -> 1[1] [send] via NET/AWS Libfabric/1
 0: nid005574:69058:78874 [0] NCCL INFO Channel 07/0 : 0[0] -> 3[3] via P2P/CUMEM
12: nid005594:53086:62592 [1] NCCL INFO Channel 00/0 : 49[1] -> 50[2] via P2P/CUMEM
 2: nid005577:17423:26961 [1] NCCL INFO Channel 06/0 : 9[1] -> 13[1] [send] via NET/AWS Libfabric/1
 1: nid005576:147559:156973 [2] NCCL INFO Channel 02/0 : 6[2] -> 10[2] [send] via NET/AWS Libfabric/2
16: nid005802:6297:15936 [0] NCCL INFO Channel 02/0 : 64[0] -> 67[3] via P2P/CUMEM
21: nid005914:166786:176224 [2] NCCL INFO Channel 05/0 : 86[2] -> 87[3] via P2P/CUMEM
26: nid005920:67124:76603 [1] NCCL INFO Channel 03/0 : 101[1] -> 105[1] [receive] via NET/AWS Libfabric/1
23: nid005917:276885:286375 [0] NCCL INFO Channel 03/0 : 92[0] -> 95[3] via P2P/CUMEM
27: nid005922:80743:90177 [2] NCCL INFO Channel 07/0 : 106[2] -> 110[2] [receive] via NET/AWS Libfabric/2
28: nid005929:16032:25507 [2] NCCL INFO Channel 02/0 : 110[2] -> 114[2] [receive] via NET/AWS Libfabric/2
 6: nid005584:28286:37703 [1] NCCL INFO Channel 04/0 : 25[1] -> 26[2] via P2P/CUMEM
31: nid005937:256591:266040 [2] NCCL INFO Channel 06/0 : 126[2] -> 2[2] [send] via NET/AWS Libfabric/2
12: nid005594:53087:62589 [2] NCCL INFO Channel 04/0 : 50[2] -> 51[3] via P2P/CUMEM
10: nid005590:110712:120131 [2] NCCL INFO Channel 00/0 : 42[2] -> 43[3] via P2P/CUMEM
 2: nid005577:17424:26963 [2] NCCL INFO Channel 06/0 : 6[2] -> 10[2] [receive] via NET/AWS Libfabric/2
 1: nid005576:147559:156973 [2] NCCL INFO Channel 06/0 : 6[2] -> 10[2] [send] via NET/AWS Libfabric/2
 4: nid005581:264524:273971 [1] NCCL INFO Channel 06/0 : 17[1] -> 21[1] [send] via NET/AWS Libfabric/1
15: nid005601:210678:220225 [2] NCCL INFO Channel 01/0 : 62[2] -> 63[3] via P2P/CUMEM
26: nid005920:67125:76601 [2] NCCL INFO Channel 06/0 : 102[2] -> 106[2] [receive] via NET/AWS Libfabric/2
25: nid005919:107464:116967 [2] NCCL INFO Channel 03/0 : 98[2] -> 102[2] [receive] via NET/AWS Libfabric/2
27: nid005922:80742:90176 [1] NCCL INFO Channel 02/0 : 105[1] -> 109[1] [receive] via NET/AWS Libfabric/1
 6: nid005584:28287:37702 [2] NCCL INFO Channel 04/0 : 26[2] -> 27[3] via P2P/CUMEM
11: nid005591:191603:202323 [0] NCCL INFO Channel 02/0 : 44[0] -> 47[3] via P2P/CUMEM
22: nid005915:274814:284265 [0] NCCL INFO Channel 07/0 : 88[0] -> 91[3] via P2P/CUMEM
22: nid005915:274816:284264 [2] NCCL INFO Channel 06/0 : 86[2] -> 90[2] [receive] via NET/AWS Libfabric/2
22: nid005915:274815:284266 [1] NCCL INFO Channel 03/0 : 85[1] -> 89[1] [receive] via NET/AWS Libfabric/1
31: nid005937:256590:266043 [1] NCCL INFO Channel 07/0 : 125[1] -> 1[1] [send] via NET/AWS Libfabric/1
10: nid005590:110711:120129 [1] NCCL INFO Channel 04/0 : 41[1] -> 42[2] via P2P/CUMEM
 2: nid005577:17424:26963 [2] NCCL INFO Channel 03/0 : 10[2] -> 14[2] [send] via NET/AWS Libfabric/2
 9: nid005588:35935:45419 [0] NCCL INFO Channel 02/0 : 36[0] -> 39[3] via P2P/CUMEM
15: nid005601:210677:220226 [1] NCCL INFO Channel 01/0 : 61[1] -> 62[2] via P2P/CUMEM
 7: nid005585:122007:131416 [2] NCCL INFO Channel 05/0 : 30[2] -> 31[3] via P2P/CUMEM
21: nid005914:166785:176225 [1] NCCL INFO Channel 05/0 : 85[1] -> 86[2] via P2P/CUMEM
26: nid005920:67124:76603 [1] NCCL INFO Channel 07/0 : 101[1] -> 105[1] [receive] via NET/AWS Libfabric/1
25: nid005919:107463:116969 [1] NCCL INFO Channel 02/0 : 97[1] -> 101[1] [receive] via NET/AWS Libfabric/1
27: nid005922:80743:90177 [2] NCCL INFO Channel 02/0 : 110[2] -> 114[2] [send] via NET/AWS Libfabric/2
 2: nid005577:17424:26963 [2] NCCL INFO Channel 07/0 : 10[2] -> 14[2] [send] via NET/AWS Libfabric/2
 4: nid005581:264525:273968 [2] NCCL INFO Channel 06/0 : 18[2] -> 16[0] via P2P/CUMEM
 7: nid005585:122006:131415 [1] NCCL INFO Channel 05/0 : 29[1] -> 30[2] via P2P/CUMEM
26: nid005920:67125:76601 [2] NCCL INFO Channel 03/0 : 106[2] -> 110[2] [send] via NET/AWS Libfabric/2
25: nid005919:107464:116967 [2] NCCL INFO Channel 07/0 : 98[2] -> 102[2] [receive] via NET/AWS Libfabric/2
28: nid005929:16032:25507 [2] NCCL INFO Channel 06/0 : 110[2] -> 114[2] [receive] via NET/AWS Libfabric/2
22: nid005915:274816:284264 [2] NCCL INFO Channel 03/0 : 90[2] -> 94[2] [send] via NET/AWS Libfabric/2
17: nid005803:180732:190233 [0] NCCL INFO Channel 06/0 : 68[0] -> 71[3] via P2P/CUMEM
18: nid005911:38864:48341 [0] NCCL INFO Channel 02/0 : 72[0] -> 75[3] via P2P/CUMEM
26: nid005920:67124:76603 [1] NCCL INFO Channel 02/0 : 105[1] -> 109[1] [send] via NET/AWS Libfabric/1
25: nid005919:107462:116966 [0] NCCL INFO Channel 07/0 : 100[0] -> 103[3] via P2P/CUMEM
30: nid005936:49910:59381 [2] NCCL INFO Channel 02/0 : 118[2] -> 122[2] [receive] via NET/AWS Libfabric/2
28: nid005929:16031:25509 [1] NCCL INFO Channel 03/0 : 109[1] -> 113[1] [receive] via NET/AWS Libfabric/1
22: nid005915:274815:284266 [1] NCCL INFO Channel 07/0 : 85[1] -> 89[1] [receive] via NET/AWS Libfabric/1
12: nid005594:53086:62592 [1] NCCL INFO Channel 04/0 : 49[1] -> 50[2] via P2P/CUMEM
 3: nid005580:71819:81307 [0] NCCL INFO Channel 01/0 : 8[0] -> 12[0] [receive] via NET/AWS Libfabric/0
26: nid005920:67125:76601 [2] NCCL INFO Channel 07/0 : 106[2] -> 110[2] [send] via NET/AWS Libfabric/2
25: nid005919:107463:116969 [1] NCCL INFO Channel 06/0 : 97[1] -> 101[1] [receive] via NET/AWS Libfabric/1
27: nid005922:80743:90177 [2] NCCL INFO Channel 06/0 : 110[2] -> 114[2] [send] via NET/AWS Libfabric/2
 8: nid005586:68926:78422 [0] NCCL INFO Channel 03/0 : 32[0] -> 35[3] via P2P/CUMEM
14: nid005600:217722:227298 [2] NCCL INFO Channel 04/0 : 58[2] -> 59[3] via P2P/CUMEM
 3: nid005580:71822:81308 [3] NCCL INFO Channel 00/0 : 11[3] -> 15[3] [receive] via NET/AWS Libfabric/3
26: nid005920:67124:76603 [1] NCCL INFO Channel 06/0 : 105[1] -> 109[1] [send] via NET/AWS Libfabric/1
25: nid005919:107464:116967 [2] NCCL INFO Channel 02/0 : 102[2] -> 106[2] [send] via NET/AWS Libfabric/2
27: nid005922:80742:90176 [1] NCCL INFO Channel 06/0 : 105[1] -> 109[1] [receive] via NET/AWS Libfabric/1
 3: nid005580:71819:81307 [0] NCCL INFO Channel 05/0 : 8[0] -> 12[0] [receive] via NET/AWS Libfabric/0
27: nid005922:80742:90176 [1] NCCL INFO Channel 03/0 : 109[1] -> 113[1] [send] via NET/AWS Libfabric/1
 0: nid005574:69059:78871 [1] NCCL INFO Channel 03/0 : 125[1] -> 1[1] [receive] via NET/AWS Libfabric/1
19: nid005912:12435:21880 [0] NCCL INFO Channel 03/0 : 76[0] -> 79[3] via P2P/CUMEM
25: nid005919:107463:116969 [1] NCCL INFO Channel 03/0 : 101[1] -> 105[1] [send] via NET/AWS Libfabric/1
23: nid005917:276885:286375 [0] NCCL INFO Channel 06/0 : 92[0] -> 95[3] via P2P/CUMEM
28: nid005929:16030:25510 [0] NCCL INFO Channel 07/0 : 112[0] -> 115[3] via P2P/CUMEM
22: nid005915:274816:284264 [2] NCCL INFO Channel 07/0 : 90[2] -> 94[2] [send] via NET/AWS Libfabric/2
15: nid005601:210678:220225 [2] NCCL INFO Channel 05/0 : 62[2] -> 63[3] via P2P/CUMEM
25: nid005919:107464:116967 [2] NCCL INFO Channel 06/0 : 102[2] -> 106[2] [send] via NET/AWS Libfabric/2
30: nid005936:49908:59382 [0] NCCL INFO Channel 06/0 : 120[0] -> 123[3] via P2P/CUMEM
28: nid005929:16032:25507 [2] NCCL INFO Channel 03/0 : 114[2] -> 118[2] [send] via NET/AWS Libfabric/2
22: nid005915:274815:284266 [1] NCCL INFO Channel 02/0 : 89[1] -> 93[1] [send] via NET/AWS Libfabric/1
29: nid005932:167681:177111 [1] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
29: nid005932:167681:177111 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
24: nid005918:92506:101973 [2] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
24: nid005918:92506:101973 [2] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
10: nid005590:110712:120131 [2] NCCL INFO Channel 04/0 : 42[2] -> 43[3] via P2P/CUMEM
 9: nid005588:35935:45419 [0] NCCL INFO Channel 03/0 : 36[0] -> 39[3] via P2P/CUMEM
16: nid005802:6297:15936 [0] NCCL INFO Channel 03/0 : 64[0] -> 67[3] via P2P/CUMEM
15: nid005601:210677:220226 [1] NCCL INFO Channel 05/0 : 61[1] -> 62[2] via P2P/CUMEM
13: nid005595:197885:207704 [2] NCCL INFO Channel 01/0 : 54[2] -> 55[3] via P2P/CUMEM
20: nid005913:292681:9594 [0] NCCL INFO Channel 03/0 : 80[0] -> 83[3] via P2P/CUMEM
18: nid005911:38864:48341 [0] NCCL INFO Channel 03/0 : 72[0] -> 75[3] via P2P/CUMEM
25: nid005919:107463:116969 [1] NCCL INFO Channel 07/0 : 101[1] -> 105[1] [send] via NET/AWS Libfabric/1
30: nid005936:49910:59381 [2] NCCL INFO Channel 06/0 : 118[2] -> 122[2] [receive] via NET/AWS Libfabric/2
30: nid005936:49909:59380 [1] NCCL INFO Channel 03/0 : 117[1] -> 121[1] [receive] via NET/AWS Libfabric/1
27: nid005922:80742:90176 [1] NCCL INFO Channel 07/0 : 109[1] -> 113[1] [send] via NET/AWS Libfabric/1
28: nid005929:16031:25509 [1] NCCL INFO Channel 07/0 : 109[1] -> 113[1] [receive] via NET/AWS Libfabric/1
14: nid005600:217720:227296 [0] NCCL INFO Channel 02/0 : 56[0] -> 59[3] via P2P/CUMEM
11: nid005591:191603:202323 [0] NCCL INFO Channel 03/0 : 44[0] -> 47[3] via P2P/CUMEM
22: nid005915:274815:284266 [1] NCCL INFO Channel 06/0 : 89[1] -> 93[1] [send] via NET/AWS Libfabric/1
 0: nid005574:69059:78871 [1] NCCL INFO Channel 07/0 : 125[1] -> 1[1] [receive] via NET/AWS Libfabric/1
10: nid005590:110710:120132 [0] NCCL INFO Channel 02/0 : 40[0] -> 43[3] via P2P/CUMEM
 2: nid005577:17424:26963 [2] NCCL INFO Channel 02/0 : 10[2] -> 8[0] via P2P/CUMEM
17: nid005803:180733:190230 [1] NCCL INFO Channel 02/0 : 65[1] -> 69[1] [receive] via NET/AWS Libfabric/1
 3: nid005580:71819:81307 [0] NCCL INFO Channel 00/0 : 12[0] -> 16[0] [send] via NET/AWS Libfabric/0
 5: nid005582:196716:206702 [3] NCCL INFO Channel 00/0 : 19[3] -> 23[3] [receive] via NET/AWS Libfabric/3
21: nid005914:166784:176223 [0] NCCL INFO Channel 02/0 : 84[0] -> 87[3] via P2P/CUMEM
30: nid005936:49910:59381 [2] NCCL INFO Channel 03/0 : 122[2] -> 126[2] [send] via NET/AWS Libfabric/2
28: nid005929:16032:25507 [2] NCCL INFO Channel 07/0 : 114[2] -> 118[2] [send] via NET/AWS Libfabric/2
 8: nid005586:68926:78422 [0] NCCL INFO Channel 06/0 : 32[0] -> 35[3] via P2P/CUMEM
14: nid005600:217720:227296 [0] NCCL INFO Channel 03/0 : 56[0] -> 59[3] via P2P/CUMEM
 6: nid005584:28285:37704 [0] NCCL INFO Channel 02/0 : 24[0] -> 27[3] via P2P/CUMEM
 0: nid005574:69059:78871 [1] NCCL INFO Channel 02/0 : 1[1] -> 5[1] [send] via NET/AWS Libfabric/1
16: nid005802:6297:15936 [0] NCCL INFO Channel 06/0 : 64[0] -> 67[3] via P2P/CUMEM
17: nid005803:180732:190233 [0] NCCL INFO Channel 07/0 : 68[0] -> 71[3] via P2P/CUMEM
 3: nid005580:71819:81307 [0] NCCL INFO Channel 04/0 : 12[0] -> 16[0] [send] via NET/AWS Libfabric/0
13: nid005595:197884:207706 [1] NCCL INFO Channel 01/0 : 53[1] -> 54[2] via P2P/CUMEM
 5: nid005582:196713:206701 [0] NCCL INFO Channel 01/0 : 16[0] -> 20[0] [receive] via NET/AWS Libfabric/0
23: nid005917:276886:286373 [1] NCCL INFO Channel 02/0 : 89[1] -> 93[1] [receive] via NET/AWS Libfabric/1
30: nid005936:49909:59380 [1] NCCL INFO Channel 07/0 : 117[1] -> 121[1] [receive] via NET/AWS Libfabric/1
28: nid005929:16031:25509 [1] NCCL INFO Channel 02/0 : 113[1] -> 117[1] [send] via NET/AWS Libfabric/1
11: nid005591:191603:202323 [0] NCCL INFO Channel 06/0 : 44[0] -> 47[3] via P2P/CUMEM
 0: nid005574:69060:78872 [2] NCCL INFO Channel 02/0 : 126[2] -> 2[2] [receive] via NET/AWS Libfabric/2
12: nid005594:53085:62591 [0] NCCL INFO Channel 02/0 : 48[0] -> 51[3] via P2P/CUMEM
17: nid005803:180733:190230 [1] NCCL INFO Channel 06/0 : 65[1] -> 69[1] [receive] via NET/AWS Libfabric/1
 3: nid005580:71821:81306 [2] NCCL INFO Channel 03/0 : 14[2] -> 12[0] via P2P/CUMEM
 3: nid005580:71822:81308 [3] NCCL INFO Channel 04/0 : 11[3] -> 15[3] [receive] via NET/AWS Libfabric/3
 5: nid005582:196716:206702 [3] NCCL INFO Channel 04/0 : 19[3] -> 23[3] [receive] via NET/AWS Libfabric/3
26: nid005920:67125:76601 [2] NCCL INFO Channel 02/0 : 106[2] -> 104[0] via P2P/CUMEM
23: nid005917:276885:286375 [0] NCCL INFO Channel 07/0 : 92[0] -> 95[3] via P2P/CUMEM
23: nid005917:276886:286373 [1] NCCL INFO Channel 06/0 : 89[1] -> 93[1] [receive] via NET/AWS Libfabric/1
30: nid005936:49910:59381 [2] NCCL INFO Channel 07/0 : 122[2] -> 126[2] [send] via NET/AWS Libfabric/2
28: nid005929:16031:25509 [1] NCCL INFO Channel 06/0 : 113[1] -> 117[1] [send] via NET/AWS Libfabric/1
 0: nid005574:69059:78871 [1] NCCL INFO Channel 06/0 : 1[1] -> 5[1] [send] via NET/AWS Libfabric/1
17: nid005803:180733:190230 [1] NCCL INFO Channel 03/0 : 69[1] -> 73[1] [send] via NET/AWS Libfabric/1
 3: nid005580:71822:81308 [3] NCCL INFO Channel 01/0 : 15[3] -> 19[3] [send] via NET/AWS Libfabric/3
 5: nid005582:196713:206701 [0] NCCL INFO Channel 05/0 : 16[0] -> 20[0] [receive] via NET/AWS Libfabric/0
20: nid005913:292682:9590 [1] NCCL INFO Channel 03/0 : 77[1] -> 81[1] [receive] via NET/AWS Libfabric/1
18: nid005911:38864:48341 [0] NCCL INFO Channel 06/0 : 72[0] -> 75[3] via P2P/CUMEM
30: nid005936:49909:59380 [1] NCCL INFO Channel 02/0 : 121[1] -> 125[1] [send] via NET/AWS Libfabric/1
27: nid005922:80743:90177 [2] NCCL INFO Channel 03/0 : 110[2] -> 108[0] via P2P/CUMEM
 0: nid005574:69060:78872 [2] NCCL INFO Channel 06/0 : 126[2] -> 2[2] [receive] via NET/AWS Libfabric/2
 1: nid005576:147560:156972 [3] NCCL INFO Channel 00/0 : 3[3] -> 7[3] [receive] via NET/AWS Libfabric/3
 4: nid005581:264526:273970 [3] NCCL INFO Channel 01/0 : 15[3] -> 19[3] [receive] via NET/AWS Libfabric/3
17: nid005803:180733:190230 [1] NCCL INFO Channel 07/0 : 69[1] -> 73[1] [send] via NET/AWS Libfabric/1
 3: nid005580:71822:81308 [3] NCCL INFO Channel 05/0 : 15[3] -> 19[3] [send] via NET/AWS Libfabric/3
 5: nid005582:196716:206702 [3] NCCL INFO Channel 01/0 : 23[3] -> 27[3] [send] via NET/AWS Libfabric/3
20: nid005913:292683:9593 [2] NCCL INFO Channel 02/0 : 78[2] -> 82[2] [receive] via NET/AWS Libfabric/2
23: nid005917:276886:286373 [1] NCCL INFO Channel 03/0 : 93[1] -> 97[1] [send] via NET/AWS Libfabric/1
30: nid005936:49909:59380 [1] NCCL INFO Channel 06/0 : 121[1] -> 125[1] [send] via NET/AWS Libfabric/1
 0: nid005574:69060:78872 [2] NCCL INFO Channel 03/0 : 2[2] -> 6[2] [send] via NET/AWS Libfabric/2
10: nid005590:110710:120132 [0] NCCL INFO Channel 03/0 : 40[0] -> 43[3] via P2P/CUMEM
 1: nid005576:147560:156972 [3] NCCL INFO Channel 04/0 : 3[3] -> 7[3] [receive] via NET/AWS Libfabric/3
 4: nid005581:264523:273969 [0] NCCL INFO Channel 00/0 : 12[0] -> 16[0] [receive] via NET/AWS Libfabric/0
 9: nid005588:35935:45419 [0] NCCL INFO Channel 06/0 : 36[0] -> 39[3] via P2P/CUMEM
16: nid005802:6299:15934 [2] NCCL INFO Channel 02/0 : 62[2] -> 66[2] [receive] via NET/AWS Libfabric/2
 7: nid005585:122005:131417 [0] NCCL INFO Channel 02/0 : 28[0] -> 31[3] via P2P/CUMEM
13: nid005595:197885:207704 [2] NCCL INFO Channel 05/0 : 54[2] -> 55[3] via P2P/CUMEM
 5: nid005582:196716:206702 [3] NCCL INFO Channel 05/0 : 23[3] -> 27[3] [send] via NET/AWS Libfabric/3
 5: nid005582:196713:206701 [0] NCCL INFO Channel 00/0 : 20[0] -> 24[0] [send] via NET/AWS Libfabric/0
19: nid005912:12435:21880 [0] NCCL INFO Channel 06/0 : 76[0] -> 79[3] via P2P/CUMEM
23: nid005917:276887:286376 [2] NCCL INFO Channel 03/0 : 90[2] -> 94[2] [receive] via NET/AWS Libfabric/2
 8: nid005586:68928:78423 [2] NCCL INFO Channel 02/0 : 30[2] -> 34[2] [receive] via NET/AWS Libfabric/2
14: nid005600:217720:227296 [0] NCCL INFO Channel 06/0 : 56[0] -> 59[3] via P2P/CUMEM
 6: nid005584:28285:37704 [0] NCCL INFO Channel 03/0 : 24[0] -> 27[3] via P2P/CUMEM
 0: nid005574:69060:78872 [2] NCCL INFO Channel 07/0 : 2[2] -> 6[2] [send] via NET/AWS Libfabric/2
 1: nid005576:147560:156972 [3] NCCL INFO Channel 01/0 : 7[3] -> 11[3] [send] via NET/AWS Libfabric/3
 4: nid005581:264526:273970 [3] NCCL INFO Channel 05/0 : 15[3] -> 19[3] [receive] via NET/AWS Libfabric/3
 9: nid005588:35936:45416 [1] NCCL INFO Channel 02/0 : 33[1] -> 37[1] [receive] via NET/AWS Libfabric/1
17: nid005803:180734:190232 [2] NCCL INFO Channel 03/0 : 66[2] -> 70[2] [receive] via NET/AWS Libfabric/2
13: nid005595:197884:207706 [1] NCCL INFO Channel 05/0 : 53[1] -> 54[2] via P2P/CUMEM
20: nid005913:292682:9590 [1] NCCL INFO Channel 07/0 : 77[1] -> 81[1] [receive] via NET/AWS Libfabric/1
19: nid005912:12437:21879 [2] NCCL INFO Channel 03/0 : 74[2] -> 78[2] [receive] via NET/AWS Libfabric/2
21: nid005914:166784:176223 [0] NCCL INFO Channel 03/0 : 84[0] -> 87[3] via P2P/CUMEM
23: nid005917:276886:286373 [1] NCCL INFO Channel 07/0 : 93[1] -> 97[1] [send] via NET/AWS Libfabric/1
30: nid005936:49908:59382 [0] NCCL INFO Channel 07/0 : 120[0] -> 123[3] via P2P/CUMEM
31: nid005937:256589:266041 [0] NCCL INFO Channel 01/0 : 120[0] -> 124[0] [receive] via NET/AWS Libfabric/0
24: nid005918:92505:101972 [1] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
24: nid005918:92505:101972 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
12: nid005594:53085:62591 [0] NCCL INFO Channel 03/0 : 48[0] -> 51[3] via P2P/CUMEM
 2: nid005577:17424:26963 [2] NCCL INFO Channel 06/0 : 10[2] -> 8[0] via P2P/CUMEM
 1: nid005576:147560:156972 [3] NCCL INFO Channel 05/0 : 7[3] -> 11[3] [send] via NET/AWS Libfabric/3
 4: nid005581:264523:273969 [0] NCCL INFO Channel 04/0 : 12[0] -> 16[0] [receive] via NET/AWS Libfabric/0
 9: nid005588:35936:45416 [1] NCCL INFO Channel 06/0 : 33[1] -> 37[1] [receive] via NET/AWS Libfabric/1
16: nid005802:6298:15933 [1] NCCL INFO Channel 03/0 : 61[1] -> 65[1] [receive] via NET/AWS Libfabric/1
15: nid005601:210676:220224 [0] NCCL INFO Channel 02/0 : 60[0] -> 63[3] via P2P/CUMEM
17: nid005803:180734:190232 [2] NCCL INFO Channel 07/0 : 66[2] -> 70[2] [receive] via NET/AWS Libfabric/2
 3: nid005580:71821:81306 [2] NCCL INFO Channel 07/0 : 14[2] -> 12[0] via P2P/CUMEM
20: nid005913:292683:9593 [2] NCCL INFO Channel 06/0 : 78[2] -> 82[2] [receive] via NET/AWS Libfabric/2
19: nid005912:12436:21878 [1] NCCL INFO Channel 02/0 : 73[1] -> 77[1] [receive] via NET/AWS Libfabric/1
23: nid005917:276887:286376 [2] NCCL INFO Channel 07/0 : 90[2] -> 94[2] [receive] via NET/AWS Libfabric/2
 8: nid005586:68928:78423 [2] NCCL INFO Channel 06/0 : 30[2] -> 34[2] [receive] via NET/AWS Libfabric/2
11: nid005591:191603:202323 [0] NCCL INFO Channel 07/0 : 44[0] -> 47[3] via P2P/CUMEM
11: nid005591:191605:202322 [2] NCCL INFO Channel 03/0 : 42[2] -> 46[2] [receive] via NET/AWS Libfabric/2
24: nid005918:92504:101971 [0] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
24: nid005918:92504:101971 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 4: nid005581:264526:273970 [3] NCCL INFO Channel 00/0 : 19[3] -> 23[3] [send] via NET/AWS Libfabric/3
 9: nid005588:35936:45416 [1] NCCL INFO Channel 03/0 : 37[1] -> 41[1] [send] via NET/AWS Libfabric/1
16: nid005802:6299:15934 [2] NCCL INFO Channel 06/0 : 62[2] -> 66[2] [receive] via NET/AWS Libfabric/2
17: nid005803:180734:190232 [2] NCCL INFO Channel 02/0 : 70[2] -> 74[2] [send] via NET/AWS Libfabric/2
20: nid005913:292682:9590 [1] NCCL INFO Channel 02/0 : 81[1] -> 85[1] [send] via NET/AWS Libfabric/1
18: nid005911:38864:48341 [0] NCCL INFO Channel 07/0 : 72[0] -> 75[3] via P2P/CUMEM
19: nid005912:12437:21879 [2] NCCL INFO Channel 07/0 : 74[2] -> 78[2] [receive] via NET/AWS Libfabric/2
23: nid005917:276887:286376 [2] NCCL INFO Channel 02/0 : 94[2] -> 98[2] [send] via NET/AWS Libfabric/2
 8: nid005586:68926:78422 [0] NCCL INFO Channel 07/0 : 32[0] -> 35[3] via P2P/CUMEM
31: nid005937:256589:266041 [0] NCCL INFO Channel 05/0 : 120[0] -> 124[0] [receive] via NET/AWS Libfabric/0
10: nid005590:110710:120132 [0] NCCL INFO Channel 06/0 : 40[0] -> 43[3] via P2P/CUMEM
 4: nid005581:264523:273969 [0] NCCL INFO Channel 01/0 : 16[0] -> 20[0] [send] via NET/AWS Libfabric/0
 9: nid005588:35937:45418 [2] NCCL INFO Channel 03/0 : 34[2] -> 38[2] [receive] via NET/AWS Libfabric/2
16: nid005802:6298:15933 [1] NCCL INFO Channel 07/0 : 61[1] -> 65[1] [receive] via NET/AWS Libfabric/1
16: nid005802:6297:15936 [0] NCCL INFO Channel 07/0 : 64[0] -> 67[3] via P2P/CUMEM
20: nid005913:292683:9593 [2] NCCL INFO Channel 03/0 : 82[2] -> 86[2] [send] via NET/AWS Libfabric/2
19: nid005912:12436:21878 [1] NCCL INFO Channel 06/0 : 73[1] -> 77[1] [receive] via NET/AWS Libfabric/1
23: nid005917:276887:286376 [2] NCCL INFO Channel 06/0 : 94[2] -> 98[2] [send] via NET/AWS Libfabric/2
 8: nid005586:68927:78425 [1] NCCL INFO Channel 03/0 : 29[1] -> 33[1] [receive] via NET/AWS Libfabric/1
 6: nid005584:28285:37704 [0] NCCL INFO Channel 06/0 : 24[0] -> 27[3] via P2P/CUMEM
31: nid005937:256592:266042 [3] NCCL INFO Channel 00/0 : 123[3] -> 127[3] [receive] via NET/AWS Libfabric/3
 0: nid005574:69060:78872 [2] NCCL INFO Channel 02/0 : 2[2] -> 0[0] via P2P/CUMEM
 2: nid005577:17425:26962 [3] NCCL INFO Channel 01/0 : 7[3] -> 11[3] [receive] via NET/AWS Libfabric/3
 4: nid005581:264526:273970 [3] NCCL INFO Channel 04/0 : 19[3] -> 23[3] [send] via NET/AWS Libfabric/3
 9: nid005588:35936:45416 [1] NCCL INFO Channel 07/0 : 37[1] -> 41[1] [send] via NET/AWS Libfabric/1
16: nid005802:6299:15934 [2] NCCL INFO Channel 03/0 : 66[2] -> 70[2] [send] via NET/AWS Libfabric/2
 5: nid005582:196713:206701 [0] NCCL INFO Channel 04/0 : 20[0] -> 24[0] [send] via NET/AWS Libfabric/0
20: nid005913:292681:9594 [0] NCCL INFO Channel 06/0 : 80[0] -> 83[3] via P2P/CUMEM
19: nid005912:12437:21879 [2] NCCL INFO Channel 02/0 : 78[2] -> 82[2] [send] via NET/AWS Libfabric/2
 8: nid005586:68928:78423 [2] NCCL INFO Channel 03/0 : 34[2] -> 38[2] [send] via NET/AWS Libfabric/2
14: nid005600:217720:227296 [0] NCCL INFO Channel 07/0 : 56[0] -> 59[3] via P2P/CUMEM
11: nid005591:191605:202322 [2] NCCL INFO Channel 07/0 : 42[2] -> 46[2] [receive] via NET/AWS Libfabric/2
31: nid005937:256589:266041 [0] NCCL INFO Channel 00/0 : 124[0] -> 0[0] [send] via NET/AWS Libfabric/0
 2: nid005577:17422:26964 [0] NCCL INFO Channel 00/0 : 4[0] -> 8[0] [receive] via NET/AWS Libfabric/0
 1: nid005576:147559:156973 [2] NCCL INFO Channel 03/0 : 6[2] -> 4[0] via P2P/CUMEM
 4: nid005581:264523:273969 [0] NCCL INFO Channel 05/0 : 16[0] -> 20[0] [send] via NET/AWS Libfabric/0
 9: nid005588:35937:45418 [2] NCCL INFO Channel 07/0 : 34[2] -> 38[2] [receive] via NET/AWS Libfabric/2
16: nid005802:6298:15933 [1] NCCL INFO Channel 02/0 : 65[1] -> 69[1] [send] via NET/AWS Libfabric/1
17: nid005803:180734:190232 [2] NCCL INFO Channel 06/0 : 70[2] -> 74[2] [send] via NET/AWS Libfabric/2
 7: nid005585:122005:131417 [0] NCCL INFO Channel 03/0 : 28[0] -> 31[3] via P2P/CUMEM
20: nid005913:292682:9590 [1] NCCL INFO Channel 06/0 : 81[1] -> 85[1] [send] via NET/AWS Libfabric/1
19: nid005912:12436:21878 [1] NCCL INFO Channel 03/0 : 77[1] -> 81[1] [send] via NET/AWS Libfabric/1
21: nid005914:166784:176223 [0] NCCL INFO Channel 06/0 : 84[0] -> 87[3] via P2P/CUMEM
26: nid005920:67125:76601 [2] NCCL INFO Channel 06/0 : 106[2] -> 104[0] via P2P/CUMEM
 8: nid005586:68927:78425 [1] NCCL INFO Channel 07/0 : 29[1] -> 33[1] [receive] via NET/AWS Libfabric/1
11: nid005591:191605:202322 [2] NCCL INFO Channel 02/0 : 46[2] -> 50[2] [send] via NET/AWS Libfabric/2
31: nid005937:256592:266042 [3] NCCL INFO Channel 04/0 : 123[3] -> 127[3] [receive] via NET/AWS Libfabric/3
31: nid005937:256591:266040 [2] NCCL INFO Channel 03/0 : 126[2] -> 124[0] via P2P/CUMEM
29: nid005932:167680:177112 [0] NCCL INFO threadThresholds 8/8/64 | 1024/8/64 | 512 | 512
 2: nid005577:17425:26962 [3] NCCL INFO Channel 05/0 : 7[3] -> 11[3] [receive] via NET/AWS Libfabric/3
 9: nid005588:35937:45418 [2] NCCL INFO Channel 02/0 : 38[2] -> 42[2] [send] via NET/AWS Libfabric/2
16: nid005802:6299:15934 [2] NCCL INFO Channel 07/0 : 66[2] -> 70[2] [send] via NET/AWS Libfabric/2
20: nid005913:292683:9593 [2] NCCL INFO Channel 07/0 : 82[2] -> 86[2] [send] via NET/AWS Libfabric/2
18: nid005911:38865:48338 [1] NCCL INFO Channel 03/0 : 69[1] -> 73[1] [receive] via NET/AWS Libfabric/1
19: nid005912:12437:21879 [2] NCCL INFO Channel 06/0 : 78[2] -> 82[2] [send] via NET/AWS Libfabric/2
26: nid005920:67123:76600 [0] NCCL INFO Channel 00/0 : 100[0] -> 104[0] [receive] via NET/AWS Libfabric/0
27: nid005922:80744:90178 [3] NCCL INFO Channel 00/0 : 107[3] -> 111[3] [receive] via NET/AWS Libfabric/3
27: nid005922:80741:90179 [0] NCCL INFO Channel 01/0 : 104[0] -> 108[0] [receive] via NET/AWS Libfabric/0
 8: nid005586:68928:78423 [2] NCCL INFO Channel 07/0 : 34[2] -> 38[2] [send] via NET/AWS Libfabric/2
11: nid005591:191604:202325 [1] NCCL INFO Channel 02/0 : 41[1] -> 45[1] [receive] via NET/AWS Libfabric/1
29: nid005932:167680:177112 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 1 p2p channels per peer
 2: nid005577:17422:26964 [0] NCCL INFO Channel 04/0 : 4[0] -> 8[0] [receive] via NET/AWS Libfabric/0
 9: nid005588:35937:45418 [2] NCCL INFO Channel 06/0 : 38[2] -> 42[2] [send] via NET/AWS Libfabric/2
16: nid005802:6298:15933 [1] NCCL INFO Channel 06/0 : 65[1] -> 69[1] [send] via NET/AWS Libfabric/1
15: nid005601:210676:220224 [0] NCCL INFO Channel 03/0 : 60[0] -> 63[3] via P2P/CUMEM
13: nid005595:197883:207703 [0] NCCL INFO Channel 02/0 : 52[0] -> 55[3] via P2P/CUMEM
18: nid005911:38866:48340 [2] NCCL INFO Channel 02/0 : 70[2] -> 74[2] [receive] via NET/AWS Libfabric/2
18: nid005911:38865:48338 [1] NCCL INFO Channel 07/0 : 69[1] -> 73[1] [receive] via NET/AWS Libfabric/1
19: nid005912:12436:21878 [1] NCCL INFO Channel 07/0 : 77[1] -> 81[1] [send] via NET/AWS Libfabric/1
26: nid005920:67126:76602 [3] NCCL INFO Channel 01/0 : 103[3] -> 107[3] [receive] via NET/AWS Libfabric/3
25: nid005919:107465:116968 [3] NCCL INFO Channel 00/0 : 99[3] -> 103[3] [receive] via NET/AWS Libfabric/3
27: nid005922:80743:90177 [2] NCCL INFO Channel 07/0 : 110[2] -> 108[0] via P2P/CUMEM
 8: nid005586:68927:78425 [1] NCCL INFO Channel 02/0 : 33[1] -> 37[1] [send] via NET/AWS Libfabric/1
 6: nid005584:28285:37704 [0] NCCL INFO Channel 07/0 : 24[0] -> 27[3] via P2P/CUMEM
11: nid005591:191605:202322 [2] NCCL INFO Channel 06/0 : 46[2] -> 50[2] [send] via NET/AWS Libfabric/2
22: nid005915:274817:284263 [3] NCCL INFO Channel 01/0 : 87[3] -> 91[3] [receive] via NET/AWS Libfabric/3
31: nid005937:256589:266041 [0] NCCL INFO Channel 04/0 : 124[0] -> 0[0] [send] via NET/AWS Libfabric/0
 2: nid005577:17425:26962 [3] NCCL INFO Channel 00/0 : 11[3] -> 15[3] [send] via NET/AWS Libfabric/3
 4: nid005581:264526:273970 [3] NCCL INFO Channel 02/0 : 19[3] -> 17[1] via P2P/CUMEM
18: nid005911:38865:48338 [1] NCCL INFO Channel 02/0 : 73[1] -> 77[1] [send] via NET/AWS Libfabric/1
19: nid005912:12435:21880 [0] NCCL INFO Channel 07/0 : 76[0] -> 79[3] via P2P/CUMEM
26: nid005920:67123:76600 [0] NCCL INFO Channel 04/0 : 100[0] -> 104[0] [receive] via NET/AWS Libfabric/0
27: nid005922:80741:90179 [0] NCCL INFO Channel 05/0 : 104[0] -> 108[0] [receive] via NET/AWS Libfabric/0
27: nid005922:80744:90178 [3] NCCL INFO Channel 04/0 : 107[3] -> 111[3] [receive] via NET/AWS Libfabric/3
 8: nid005586:68927:78425 [1] NCCL INFO Channel 06/0 : 33[1] -> 37[1] [send] via NET/AWS Libfabric/1
11: nid005591:191604:202325 [1] NCCL INFO Channel 06/0 : 41[1] -> 45[1] [receive] via NET/AWS Libfabric/1
22: nid005915:274814:284265 [0] NCCL INFO Channel 00/0 : 84[0] -> 88[0] [receive] via NET/AWS Libfabric/0
31: nid005937:256592:266042 [3] NCCL INFO Channel 01/0 : 127[3] -> 3[3] [send] via NET/AWS Libfabric/3
12: nid005594:53085:62591 [0] NCCL INFO Channel 06/0 : 48[0] -> 51[3] via P2P/CUMEM
10: nid005590:110710:120132 [0] NCCL INFO Channel 07/0 : 40[0] -> 43[3] via P2P/CUMEM
 2: nid005577:17422:26964 [0] NCCL INFO Channel 01/0 : 8[0] -> 12[0] [send] via NET/AWS Libfabric/0
18: nid005911:38866:48340 [2] NCCL INFO Channel 06/0 : 70[2] -> 74[2] [receive] via NET/AWS Libfabric/2
26: nid005920:67126:76602 [3] NCCL INFO Channel 05/0 : 103[3] -> 107[3] [receive] via NET/AWS Libfabric/3
14: nid005600:217721:227295 [1] NCCL INFO Channel 03/0 : 53[1] -> 57[1] [receive] via NET/AWS Libfabric/1
11: nid005591:191604:202325 [1] NCCL INFO Channel 03/0 : 45[1] -> 49[1] [send] via NET/AWS Libfabric/1
22: nid005915:274817:284263 [3] NCCL INFO Channel 05/0 : 87[3] -> 91[3] [receive] via NET/AWS Libfabric/3
31: nid005937:256592:266042 [3] NCCL INFO Channel 05/0 : 127[3] -> 3[3] [send] via NET/AWS Libfabric/3
12: nid005594:53087:62589 [2] NCCL INFO Channel 02/0 : 46[2] -> 50[2] [receive] via NET/AWS Libfabric/2
10: nid005590:110711:120129 [1] NCCL INFO Channel 03/0 : 37[1] -> 41[1] [receive] via NET/AWS Libfabric/1
 2: nid005577:17425:26962 [3] NCCL INFO Channel 04/0 : 11[3] -> 15[3] [send] via NET/AWS Libfabric/3
 7: nid005585:122005:131417 [0] NCCL INFO Channel 06/0 : 28[0] -> 31[3] via P2P/CUMEM
18: nid005911:38865:48338 [1] NCCL INFO Channel 06/0 : 73[1] -> 77[1] [send] via NET/AWS Libfabric/1
21: nid005914:166785:176225 [1] NCCL INFO Channel 02/0 : 81[1] -> 85[1] [receive] via NET/AWS Libfabric/1
26: nid005920:67123:76600 [0] NCCL INFO Channel 01/0 : 104[0] -> 108[0] [send] via NET/AWS Libfabric/0
27: nid005922:80741:90179 [0] NCCL INFO Channel 00/0 : 108[0] -> 112[0] [send] via NET/AWS Libfabric/0
27: nid005922:80744:90178 [3] NCCL INFO Channel 01/0 : 111[3] -> 115[3] [send] via NET/AWS Libfabric/3
14: nid005600:217721:227295 [1] NCCL INFO Channel 07/0 : 53[1] -> 57[1] [receive] via NET/AWS Libfabric/1
11: nid005591:191604:202325 [1] NCCL INFO Channel 07/0 : 45[1] -> 49[1] [send] via NET/AWS Libfabric/1
22: nid005915:274814:284265 [0] NCCL INFO Channel 04/0 : 84[0] -> 88[0] [receive] via NET/AWS Libfabric/0
 0: nid005574:69058:78874 [0] NCCL INFO Channel 00/0 : 124[0] -> 0[0] [receive] via NET/AWS Libfabric/0
12: nid005594:53087:62589 [2] NCCL INFO Channel 06/0 : 46[2] -> 50[2] [receive] via NET/AWS Libfabric/2
 2: nid005577:17422:26964 [0] NCCL INFO Channel 05/0 : 8[0] -> 12[0] [send] via NET/AWS Libfabric/0
 7: nid005585:122006:131415 [1] NCCL INFO Channel 02/0 : 25[1] -> 29[1] [receive] via NET/AWS Libfabric/1
18: nid005911:38866:48340 [2] NCCL INFO Channel 03/0 : 74[2] -> 78[2] [send] via NET/AWS Libfabric/2
21: nid005914:166786:176224 [2] NCCL INFO Channel 03/0 : 82[2] -> 86[2] [receive] via NET/AWS Libfabric/2
26: nid005920:67126:76602 [3] NCCL INFO Channel 00/0 : 107[3] -> 111[3] [send] via NET/AWS Libfabric/3
25: nid005919:107462:116966 [0] NCCL INFO Channel 01/0 : 96[0] -> 100[0] [receive] via NET/AWS Libfabric/0
27: nid005922:80741:90179 [0] NCCL INFO Channel 04/0 : 108[0] -> 112[0] [send] via NET/AWS Libfabric/0
28: nid005929:16033:25508 [3] NCCL INFO Channel 01/0 : 111[3] -> 115[3] [receive] via NET/AWS Libfabric/3
14: nid005600:217721:227295 [1] NCCL INFO Channel 02/0 : 57[1] -> 61[1] [send] via NET/AWS Libfabric/1
 6: nid005584:28286:37703 [1] NCCL INFO Channel 03/0 : 21[1] -> 25[1] [receive] via NET/AWS Libfabric/1
 6: nid005584:28287:37702 [2] NCCL INFO Channel 02/0 : 22[2] -> 26[2] [receive] via NET/AWS Libfabric/2
22: nid005915:274817:284263 [3] NCCL INFO Channel 00/0 : 91[3] -> 95[3] [send] via NET/AWS Libfabric/3
31: nid005937:256591:266040 [2] NCCL INFO Channel 07/0 : 126[2] -> 124[0] via P2P/CUMEM
 0: nid005574:69061:78873 [3] NCCL INFO Channel 01/0 : 127[3] -> 3[3] [receive] via NET/AWS Libfabric/3
10: nid005590:110711:120129 [1] NCCL INFO Channel 07/0 : 37[1] -> 41[1] [receive] via NET/AWS Libfabric/1
 1: nid005576:147557:156974 [0] NCCL INFO Channel 01/0 : 0[0] -> 4[0] [receive] via NET/AWS Libfabric/0
 9: nid005588:35935:45419 [0] NCCL INFO Channel 07/0 : 36[0] -> 39[3] via P2P/CUMEM
18: nid005911:38866:48340 [2] NCCL INFO Channel 07/0 : 74[2] -> 78[2] [send] via NET/AWS Libfabric/2
21: nid005914:166785:176225 [1] NCCL INFO Channel 06/0 : 81[1] -> 85[1] [receive] via NET/AWS Libfabric/1
26: nid005920:67123:76600 [0] NCCL INFO Channel 05/0 : 104[0] -> 108[0] [send] via NET/AWS Libfabric/0
25: nid005919:107465:116968 [3] NCCL INFO Channel 04/0 : 99[3] -> 103[3] [receive] via NET/AWS Libfabric/3
27: nid005922:80744:90178 [3] NCCL INFO Channel 05/0 : 111[3] -> 115[3] [send] via NET/AWS Libfabric/3
28: nid005929:16030:25510 [0] NCCL INFO Channel 00/0 : 108[0] -> 112[0] [receive] via NET/AWS Libfabric/0
28: nid005929:16033:25508 [3] NCCL INFO Channel 05/0 : 111[3] -> 115[3] [receive] via NET/AWS Libfabric/3
14: nid005600:217722:227298 [2] NCCL INFO Channel 02/0 : 54[2] -> 58[2] [receive] via NET/AWS Libfabric/2
 6: nid005584:28286:37703 [1] NCCL INFO Channel 07/0 : 21[1] -> 25[1] [receive] via NET/AWS Libfabric/1
 6: nid005584:28287:37702 [2] NCCL INFO Channel 06/0 : 22[2] -> 26[2] [receive] via NET/AWS Libfabric/2
22: nid005915:274814:284265 [0] NCCL INFO Channel 01/0 : 88[0] -> 92[0] [send] via NET/AWS Libfabric/0
 0: nid005574:69060:78872 [2] NCCL INFO Channel 06/0 : 2[2] -> 0[0] via P2P/CUMEM
 0: nid005574:69058:78874 [0] NCCL INFO Channel 04/0 : 124[0] -> 0[0] [receive] via NET/AWS Libfabric/0
12: nid005594:53087:62589 [2] NCCL INFO Channel 03/0 : 50[2] -> 54[2] [send] via NET/AWS Libfabric/2
12: nid005594:53085:62591 [0] NCCL INFO Channel 07/0 : 48[0] -> 51[3] via P2P/CUMEM
10: nid005590:110711:120129 [1] NCCL INFO Channel 02/0 : 41[1] -> 45[1] [send] via NET/AWS Libfabric/1
15: nid005601:210676:220224 [0] NCCL INFO Channel 06/0 : 60[0] -> 63[3] via P2P/CUMEM
 7: nid005585:122007:131416 [2] NCCL INFO Channel 03/0 : 26[2] -> 30[2] [receive] via NET/AWS Libfabric/2
 3: nid005580:71822:81308 [3] NCCL INFO Channel 03/0 : 15[3] -> 13[1] via P2P/CUMEM
21: nid005914:166784:176223 [0] NCCL INFO Channel 07/0 : 84[0] -> 87[3] via P2P/CUMEM
26: nid005920:67126:76602 [3] NCCL INFO Channel 04/0 : 107[3] -> 111[3] [send] via NET/AWS Libfabric/3
25: nid005919:107462:116966 [0] NCCL INFO Channel 05/0 : 96[0] -> 100[0] [receive] via NET/AWS Libfabric/0
28: nid005929:16033:25508 [3] NCCL INFO Channel 00/0 : 115[3] -> 119[3] [send] via NET/AWS Libfabric/3
28: nid005929:16030:25510 [0] NCCL INFO Channel 04/0 : 108[0] -> 112[0] [receive] via NET/AWS Libfabric/0
14: nid005600:217721:227295 [1] NCCL INFO Channel 06/0 : 57[1] -> 61[1] [send] via NET/AWS Libfabric/1
22: nid005915:274817:284263 [3] NCCL INFO Channel 04/0 : 91[3] -> 95[3] [send] via NET/AWS Libfabric/3
 0: nid005574:69061:78873 [3] NCCL INFO Channel 05/0 : 127[3] -> 3[3] [receive] via NET/AWS Libfabric/3
12: nid005594:53086:62592 [1] NCCL INFO Channel 03/0 : 45[1] -> 49[1] [receive] via NET/AWS Libfabric/1
10: nid005590:110712:120131 [2] NCCL INFO Channel 02/0 : 38[2] -> 42[2] [receive] via NET/AWS Libfabric/2
 2: nid005577:17425:26962 [3] NCCL INFO Channel 02/0 : 11[3] -> 9[1] via P2P/CUMEM
 1: nid005576:147559:156973 [2] NCCL INFO Channel 07/0 : 6[2] -> 4[0] via P2P/CUMEM
17: nid005803:180734:190232 [2] NCCL INFO Channel 03/0 : 70[2] -> 68[0] via P2P/CUMEM
 7: nid005585:122006:131415 [1] NCCL INFO Channel 06/0 : 25[1] -> 29[1] [receive] via NET/AWS Libfabric/1
20: nid005913:292681:9594 [0] NCCL INFO Channel 07/0 : 80[0] -> 83[3] via P2P/CUMEM
21: nid005914:166786:176224 [2] NCCL INFO Channel 07/0 : 82[2] -> 86[2] [receive] via NET/AWS Libfabric/2
25: nid005919:107465:116968 [3] NCCL INFO Channel 01/0 : 103[3] -> 107[3] [send] via NET/AWS Libfabric/3
14: nid005600:217722:227298 [2] NCCL INFO Channel 06/0 : 54[2] -> 58[2] [receive] via NET/AWS Libfabric/2
 6: nid005584:28286:37703 [1] NCCL INFO Channel 02/0 : 25[1] -> 29[1] [send] via NET/AWS Libfabric/1
22: nid005915:274814:284265 [0] NCCL INFO Channel 05/0 : 88[0] -> 92[0] [send] via NET/AWS Libfabric/0
 0: nid005574:69058:78874 [0] NCCL INFO Channel 01/0 : 0[0] -> 4[0] [send] via NET/AWS Libfabric/0
12: nid005594:53087:62589 [2] NCCL INFO Channel 07/0 : 50[2] -> 54[2] [send] via NET/AWS Libfabric/2
10: nid005590:110711:120129 [1] NCCL INFO Channel 06/0 : 41[1] -> 45[1] [send] via NET/AWS Libfabric/1
 1: nid005576:147557:156974 [0] NCCL INFO Channel 05/0 : 0[0] -> 4[0] [receive] via NET/AWS Libfabric/0
 4: nid005581:264526:273970 [3] NCCL INFO Channel 06/0 : 19[3] -> 17[1] via P2P/CUMEM
 7: nid005585:122007:131416 [2] NCCL INFO Channel 07/0 : 26[2] -> 30[2] [receive] via NET/AWS Libfabric/2
 7: nid005585:122006:131415 [1] NCCL INFO Channel 03/0 : 29[1] -> 33[1] [send] via NET/AWS Libfabric/1
13: nid005595:197883:207703 [0] NCCL INFO Channel 03/0 : 52[0] -> 55[3] via P2P/CUMEM
18: nid005911:38866:48340 [2] NCCL INFO Channel 02/0 : 74[2] -> 72[0] via P2P/CUMEM
19: nid005912:12437:21879 [2] NCCL INFO Channel 03/0 : 78[2] -> 76[0] via P2P/CUMEM
21: nid005914:166785:176225 [1] NCCL INFO Channel 03/0 : 85[1] -> 89[1] [send] via NET/AWS Libfabric/1
25: nid005919:107462:116966 [0] NCCL INFO Channel 00/0 : 100[0] -> 104[0] [send] via NET/AWS Libfabric/0
23: nid005917:276885:286375 [0] NCCL INFO Channel 01/0 : 88[0] -> 92[0] [receive] via NET/AWS Libfabric/0
28: nid005929:16033:25508 [3] NCCL INFO Channel 04/0 : 115[3] -> 119[3] [send] via NET/AWS Libfabric/3
14: nid005600:217722:227298 [2] NCCL INFO Channel 03/0 : 58[2] -> 62[2] [send] via NET/AWS Libfabric/2
 6: nid005584:28287:37702 [2] NCCL INFO Channel 03/0 : 26[2] -> 30[2] [send] via NET/AWS Libfabric/2
 0: nid005574:69061:78873 [3] NCCL INFO Channel 00/0 : 3[3] -> 7[3] [send] via NET/AWS Libfabric/3
12: nid005594:53086:62592 [1] NCCL INFO Channel 07/0 : 45[1] -> 49[1] [receive] via NET/AWS Libfabric/1
10: nid005590:110712:120131 [2] NCCL INFO Channel 06/0 : 38[2] -> 42[2] [receive] via NET/AWS Libfabric/2
 1: nid005576:147557:156974 [0] NCCL INFO Channel 00/0 : 4[0] -> 8[0] [send] via NET/AWS Libfabric/0
15: nid005601:210677:220226 [1] NCCL INFO Channel 02/0 : 57[1] -> 61[1] [receive] via NET/AWS Libfabric/1
 7: nid005585:122005:131417 [0] NCCL INFO Channel 07/0 : 28[0] -> 31[3] via P2P/CUMEM
21: nid005914:166786:176224 [2] NCCL INFO Channel 02/0 : 86[2] -> 90[2] [send] via NET/AWS Libfabric/2
26: nid005920:67126:76602 [3] NCCL INFO Channel 02/0 : 107[3] -> 105[1] via P2P/CUMEM
25: nid005919:107465:116968 [3] NCCL INFO Channel 05/0 : 103[3] -> 107[3] [send] via NET/AWS Libfabric/3
28: nid005929:16030:25510 [0] NCCL INFO Channel 01/0 : 112[0] -> 116[0] [send] via NET/AWS Libfabric/0
14: nid005600:217722:227298 [2] NCCL INFO Channel 07/0 : 58[2] -> 62[2] [send] via NET/AWS Libfabric/2
 6: nid005584:28286:37703 [1] NCCL INFO Channel 06/0 : 25[1] -> 29[1] [send] via NET/AWS Libfabric/1
 0: nid005574:69058:78874 [0] NCCL INFO Channel 05/0 : 0[0] -> 4[0] [send] via NET/AWS Libfabric/0
10: nid005590:110712:120131 [2] NCCL INFO Channel 03/0 : 42[2] -> 46[2] [send] via NET/AWS Libfabric/2
15: nid005601:210678:220225 [2] NCCL INFO Channel 03/0 : 58[2] -> 62[2] [receive] via NET/AWS Libfabric/2
17: nid005803:180735:190231 [3] NCCL INFO Channel 00/0 : 67[3] -> 71[3] [receive] via NET/AWS Libfabric/3
 7: nid005585:122007:131416 [2] NCCL INFO Channel 02/0 : 30[2] -> 34[2] [send] via NET/AWS Libfabric/2
21: nid005914:166785:176225 [1] NCCL INFO Channel 07/0 : 85[1] -> 89[1] [send] via NET/AWS Libfabric/1
25: nid005919:107462:116966 [0] NCCL INFO Channel 04/0 : 100[0] -> 104[0] [send] via NET/AWS Libfabric/0
23: nid005917:276888:286374 [3] NCCL INFO Channel 00/0 : 91[3] -> 95[3] [receive] via NET/AWS Libfabric/3
28: nid005929:16030:25510 [0] NCCL INFO Channel 05/0 : 112[0] -> 116[0] [send] via NET/AWS Libfabric/0
 6: nid005584:28287:37702 [2] NCCL INFO Channel 07/0 : 26[2] -> 30[2] [send] via NET/AWS Libfabric/2
29: nid005932:167683:177110 [3] NCCL INFO ncclCommSplit comm 0x4006a1651260 rank 119 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 parent 0xaaab0adabbc0 color 315732477 key 119 commId 0xf264858106496629 - Init COMPLETE
29: nid005932:167683:177110 [3] NCCL INFO Init timings: rank 119 nranks 128 total 0.60 (kernels 0.00, bootstrap 0.03, allgathers 0.11, topo 0.42, graphs 0.02, connections 0.02, rest 0.00)
 0: nid005574:69061:78873 [3] NCCL INFO Channel 04/0 : 3[3] -> 7[3] [send] via NET/AWS Libfabric/3
12: nid005594:53086:62592 [1] NCCL INFO Channel 02/0 : 49[1] -> 53[1] [send] via NET/AWS Libfabric/1
10: nid005590:110712:120131 [2] NCCL INFO Channel 07/0 : 42[2] -> 46[2] [send] via NET/AWS Libfabric/2
 2: nid005577:17425:26962 [3] NCCL INFO Channel 06/0 : 11[3] -> 9[1] via P2P/CUMEM
15: nid005601:210677:220226 [1] NCCL INFO Channel 06/0 : 57[1] -> 61[1] [receive] via NET/AWS Libfabric/1
 7: nid005585:122006:131415 [1] NCCL INFO Channel 07/0 : 29[1] -> 33[1] [send] via NET/AWS Libfabric/1
 5: nid005582:196715:206700 [2] NCCL INFO Channel 03/0 : 22[2] -> 20[0] via P2P/CUMEM
21: nid005914:166786:176224 [2] NCCL INFO Channel 06/0 : 86[2] -> 90[2] [send] via NET/AWS Libfabric/2
23: nid005917:276885:286375 [0] NCCL INFO Channel 05/0 : 88[0] -> 92[0] [receive] via NET/AWS Libfabric/0
27: nid005922:80744:90178 [3] NCCL INFO Channel 03/0 : 111[3] -> 109[1] via P2P/CUMEM
29: nid005932:167681:177111 [1] NCCL INFO ncclCommSplit comm 0x4006a164fdf0 rank 117 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 parent 0xaaaac3b4db00 color 315732477 key 117 commId 0xf264858106496629 - Init COMPLETE
12: nid005594:53086:62592 [1] NCCL INFO Channel 06/0 : 49[1] -> 53[1] [send] via NET/AWS Libfabric/1
 1: nid005576:147557:156974 [0] NCCL INFO Channel 04/0 : 4[0] -> 8[0] [send] via NET/AWS Libfabric/0
15: nid005601:210676:220224 [0] NCCL INFO Channel 07/0 : 60[0] -> 63[3] via P2P/CUMEM
 7: nid005585:122007:131416 [2] NCCL INFO Channel 06/0 : 30[2] -> 34[2] [send] via NET/AWS Libfabric/2
21: nid005914:166786:176224 [2] NCCL INFO Channel 03/0 : 86[2] -> 84[0] via P2P/CUMEM
23: nid005917:276888:286374 [3] NCCL INFO Channel 04/0 : 91[3] -> 95[3] [receive] via NET/AWS Libfabric/3
29: nid005932:167681:177111 [1] NCCL INFO Init timings: rank 117 nranks 128 total 0.60 (kernels 0.00, bootstrap 0.03, allgathers 0.11, topo 0.42, graphs 0.02, connections 0.02, rest 0.00)
 9: nid005588:35937:45418 [2] NCCL INFO Channel 03/0 : 38[2] -> 36[0] via P2P/CUMEM
15: nid005601:210678:220225 [2] NCCL INFO Channel 07/0 : 58[2] -> 62[2] [receive] via NET/AWS Libfabric/2
17: nid005803:180735:190231 [3] NCCL INFO Channel 04/0 : 67[3] -> 71[3] [receive] via NET/AWS Libfabric/3
20: nid005913:292683:9593 [2] NCCL INFO Channel 02/0 : 82[2] -> 80[0] via P2P/CUMEM
29: nid005932:167682:177113 [2] NCCL INFO ncclCommSplit comm 0x400678a86760 rank 118 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 parent 0xaaab2bddcec0 color 315732477 key 118 commId 0xf264858106496629 - Init COMPLETE
29: nid005932:167682:177113 [2] NCCL INFO Init timings: rank 118 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.11, topo 0.42, graphs 0.02, connections 0.02, rest 0.00)
24: nid005918:92504:101971 [0] NCCL INFO ncclCommSplit comm 0x40066d64fe00 rank 96 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 parent 0xaaaaf3895ae0 color 315732477 key 96 commId 0xf264858106496629 - Init COMPLETE
24: nid005918:92504:101971 [0] NCCL INFO Init timings: rank 96 nranks 128 total 0.60 (kernels 0.00, bootstrap 0.03, allgathers 0.11, topo 0.42, graphs 0.02, connections 0.02, rest 0.00)
 0: nid005574:69061:78873 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM
 1: nid005576:147560:156972 [3] NCCL INFO Channel 03/0 : 7[3] -> 5[1] via P2P/CUMEM
15: nid005601:210677:220226 [1] NCCL INFO Channel 03/0 : 61[1] -> 65[1] [send] via NET/AWS Libfabric/1
17: nid005803:180734:190232 [2] NCCL INFO Channel 07/0 : 70[2] -> 68[0] via P2P/CUMEM
19: nid005912:12437:21879 [2] NCCL INFO Channel 07/0 : 78[2] -> 76[0] via P2P/CUMEM
23: nid005917:276885:286375 [0] NCCL INFO Channel 00/0 : 92[0] -> 96[0] [send] via NET/AWS Libfabric/0
22: nid005915:274816:284264 [2] NCCL INFO Channel 02/0 : 90[2] -> 88[0] via P2P/CUMEM
29: nid005932:167680:177112 [0] NCCL INFO ncclCommSplit comm 0x40069d64fa60 rank 116 nranks 128 cudaDev 0 nvmlDev 0 busId 901000 parent 0xaaab03ee4fa0 color 315732477 key 116 commId 0xf264858106496629 - Init COMPLETE
24: nid005918:92506:101973 [2] NCCL INFO ncclCommSplit comm 0x40067d6513b0 rank 98 nranks 128 cudaDev 2 nvmlDev 2 busId 2901000 parent 0xaaab22641a60 color 315732477 key 98 commId 0xf264858106496629 - Init COMPLETE
24: nid005918:92506:101973 [2] NCCL INFO Init timings: rank 98 nranks 128 total 0.59 (kernels 0.00, bootstrap 0.03, allgathers 0.11, topo 0.42, graphs 0.02, connections 0.02, rest 0.00)
16: nid005802:6300:15935 [3] NCCL INFO Channel 01/0 : 63[3] -> 67[3] [receive] via NET/AWS Libfabric/3
15: nid005601:210678:220225 [2] NCCL INFO Channel 02/0 : 62[2] -> 66[2] [send] via NET/AWS Libfabric/2
17: nid005803:180735:190231 [3] NCCL INFO Channel 01/0 : 71[3] -> 75[3] [send] via NET/AWS Libfabric/3
13: nid005595:197883:207703 [0] NCCL INFO Channel 06/0 : 52[0] -> 55[3] via P2P/CUMEM
23: nid005917:276888:286374 [3] NCCL INFO Channel 01/0 : 95[3] -> 99[3] [send] via NET/AWS Libfabric/3
 8: nid005586:68926:78422 [0] NCCL INFO Channel 00/0 : 28[0] -> 32[0] [receive] via NET/AWS Libfabric/0
11: nid005591:191606:202324 [3] NCCL INFO Channel 00/0 : 43[3] -> 47[3] [receive] via NET/AWS Libfabric/3
29: nid005932:167680:177112 [0] NCCL INFO Init timings: rank 116 nranks 128 total 0.60 (kernels 0.00, bootstrap 0.03, allgathers 0.11, topo 0.42, graphs 0.02, connections 0.02, rest 0.00)
24: nid005918:92507:101970 [3] NCCL INFO ncclCommSplit comm 0x40069164fe00 rank 99 nranks 128 cudaDev 3 nvmlDev 3 busId 3901000 parent 0xaaaae09e21b0 color 315732477 key 99 commId 0xf264858106496629 - Init COMPLETE
10: nid005590:110712:120131 [2] NCCL INFO Channel 02/0 : 42[2] -> 40[0] via P2P/CUMEM
 2: nid005577:17425:26962 [3] NCCL INFO Channel 01/0 : 11[3] -> 10[2] via P2P/CUMEM
16: nid005802:6297:15936 [0] NCCL INFO Channel 00/0 : 60[0] -> 64[0] [receive] via NET/AWS Libfabric/0
15: nid005601:210677:220226 [1] NCCL INFO Channel 07/0 : 61[1] -> 65[1] [send] via NET/AWS Libfabric/1
 3: nid005580:71822:81308 [3] NCCL INFO Channel 07/0 : 15[3] -> 13[1] via P2P/CUMEM
13: nid005595:197885:207704 [2] NCCL INFO Channel 03/0 : 50[2] -> 54[2] [receive] via NET/AWS Libfabric/2
23: nid005917:276885:286375 [0] NCCL INFO Channel 04/0 : 92[0] -> 96[0] [send] via NET/AWS Libfabric/0
 8: nid005586:68929:78424 [3] NCCL INFO Channel 01/0 : 31[3] -> 35[3] [receive] via NET/AWS Libfabric/3
11: nid005591:191603:202323 [0] NCCL INFO Channel 01/0 : 40[0] -> 44[0] [receive] via NET/AWS Libfabric/0
16: nid005802:6300:15935 [3] NCCL INFO Channel 05/0 : 63[3] -> 67[3] [receive] via NET/AWS Libfabric/3
15: nid005601:210678:220225 [2] NCCL INFO Channel 06/0 : 62[2] -> 66[2] [send] via NET/AWS Libfabric/2
23: nid005917:276888:286374 [3] NCCL INFO Channel 05/0 : 95[3] -> 99[3] [send] via NET/AWS Libfabric/3
30: nid005936:49911:59379 [3] NCCL INFO Channel 01/0 : 119[3] -> 123[3] [receive] via NET/AWS Libfabric/3
 8: nid005586:68926:78422 [0] NCCL INFO Channel 04/0 : 28[0] -> 32[0] [receive] via NET/AWS Libfabric/0
11: nid005591:191606:202324 [3] NCCL INFO Channel 04/0 : 43[3] -> 47[3] [receive] via NET/AWS Libfabric/3
24: nid005918:92507:101970 [3] NCCL INFO Init timings: rank 99 nranks 128 total 0.60 (kernels 0.00, bootstrap 0.03, allgathers 0.11, topo 0.42, graphs 0.02, connections 0.02, rest 0.00)
17: nid005803:180735:190231 [3] NCCL INFO Channel 05/0 : 71[3] -> 75[3] [send] via NET/AWS Libfabric/3
 7: nid005585:122007:131416 [2] NCCL INFO Channel 03/0 : 30[2] -> 28[0] via P2P/CUMEM
13: nid005595:197885:207704 [2] NCCL INFO Channel 07/0 : 50[2] -> 54[2] [receive] via NET/AWS Libfabric/2
26: nid005920:67126:76602 [3] NCCL INFO Channel 06/0 : 107[3] -> 105[1] via P2P/CUMEM
30: nid005936:49908:59382 [0] NCCL INFO Channel 00/0 : 116[0] -> 120[0] [receive] via NET/AWS Libfabric/0
 8: nid005586:68929:78424 [3] NCCL INFO Channel 05/0 : 31[3] -> 35[3] [receive] via NET/AWS Libfabric/3
 6: nid005584:28287:37702 [2] NCCL INFO Channel 02/0 : 26[2] -> 24[0] via P2P/CUMEM
11: nid005591:191605:202322 [2] NCCL INFO Channel 03/0 : 46[2] -> 44[0] via P2P/CUMEM
24: nid005918:92505:101972 [1] NCCL INFO ncclCommSplit comm 0x4006a564fdf0 rank 97 nranks 128 cudaDev 1 nvmlDev 1 busId 1901000 parent 0xaaab23b3bb80 color 315732477 key 97 commId 0xf264858106496629 - Init COMPLETE
 4: nid005581:264526:273970 [3] NCCL INFO Channel 01/0 : 19[3] -> 18[2] via P2P/CUMEM
16: nid005802:6297:15936 [0] NCCL INFO Channel 04/0 : 60[0] -> 64[0] [receive] via NET/AWS Libfabric/0
13: nid005595:197884:207706 [1] NCCL INFO Channel 02/0 : 49[1] -> 53[1] [receive] via NET/AWS Libfabric/1
13: nid005595:197885:207704 [2] NCCL INFO Channel 02/0 : 54[2] -> 58[2] [send] via NET/AWS Libfabric/2
 5: nid005582:196715:206700 [2] NCCL INFO Channel 07/0 : 22[2] -> 20[0] via P2P/CUMEM
18: nid005911:38866:48340 [2] NCCL INFO Channel 06/0 : 74[2] -> 72[0] via P2P/CUMEM
30: nid005936:49911:59379 [3] NCCL INFO Channel 05/0 : 119[3] -> 123[3] [receive] via NET/AWS Libfabric/3
27: nid005922:80744:90178 [3] NCCL INFO Channel 07/0 : 111[3] -> 109[1] via P2P/CUMEM
 8: nid005586:68926:78422 [0] NCCL INFO Channel 01/0 : 32[0] -> 36[0] [send] via NET/AWS Libfabric/0
11: nid005591:191603:202323 [0] NCCL INFO Channel 05/0 : 40[0] -> 44[0] [receive] via NET/AWS Libfabric/0
24: nid005918:92505:101972 [1] NCCL INFO Init timings: rank 97 nranks 128 total 0.60 (kernels 0.00, bootstrap 0.03, allgathers 0.11, topo 0.42, graphs 0.02, connections 0.02, rest 0.00)
 1: nid005576:147560:156972 [3] NCCL INFO Channel 07/0 : 7[3] -> 5[1] via P2P/CUMEM
16: nid005802:6300:15935 [3] NCCL INFO Channel 00/0 : 67[3] -> 71[3] [send] via NET/AWS Libfabric/3
20: nid005913:292683:9593 [2] NCCL INFO Channel 06/0 : 82[2] -> 80[0] via P2P/CUMEM
18: nid005911:38864:48341 [0] NCCL INFO Channel 00/0 : 68[0] -> 72[0] [receive] via NET/AWS Libfabric/0
18: nid005911:38867:48339 [3] NCCL INFO Channel 01/0 : 71[3] -> 75[3] [receive] via NET/AWS Libfabric/3
19: nid005912:12438:21877 [3] NCCL INFO Channel 00/0 : 75[3] -> 79[3] [receive] via NET/AWS Libfabric/3
30: nid005936:49911:59379 [3] NCCL INFO Channel 00/0 : 123[3] -> 127[3] [send] via NET/AWS Libfabric/3
 8: nid005586:68929:78424 [3] NCCL INFO Channel 00/0 : 35[3] -> 39[3] [send] via NET/AWS Libfabric/3
11: nid005591:191606:202324 [3] NCCL INFO Channel 01/0 : 47[3] -> 51[3] [send] via NET/AWS Libfabric/3
24: nid005918:92504:101984 [0] NCCL INFO Channel 00/0 : 96[0] -> 97[1] via P2P/CUMEM
16: nid005802:6297:15936 [0] NCCL INFO Channel 01/0 : 64[0] -> 68[0] [send] via NET/AWS Libfabric/0
18: nid005911:38864:48341 [0] NCCL INFO Channel 04/0 : 68[0] -> 72[0] [receive] via NET/AWS Libfabric/0
19: nid005912:12438:21877 [3] NCCL INFO Channel 04/0 : 75[3] -> 79[3] [receive] via NET/AWS Libfabric/3
19: nid005912:12435:21880 [0] NCCL INFO Channel 01/0 : 72[0] -> 76[0] [receive] via NET/AWS Libfabric/0
30: nid005936:49908:59382 [0] NCCL INFO Channel 04/0 : 116[0] -> 120[0] [receive] via NET/AWS Libfabric/0
 8: nid005586:68928:78423 [2] NCCL INFO Channel 02/0 : 34[2] -> 32[0] via P2P/CUMEM
11: nid005591:191603:202323 [0] NCCL INFO Channel 00/0 : 44[0] -> 48[0] [send] via NET/AWS Libfabric/0
22: nid005915:274816:284264 [2] NCCL INFO Channel 06/0 : 90[2] -> 88[0] via P2P/CUMEM
29: nid005932:167680:177125 [0] NCCL INFO Channel 01/0 : 116[0] -> 117[1] via P2P/CUMEM
16: nid005802:6300:15935 [3] NCCL INFO Channel 04/0 : 67[3] -> 71[3] [send] via NET/AWS Libfabric/3
13: nid005595:197883:207703 [0] NCCL INFO Channel 07/0 : 52[0] -> 55[3] via P2P/CUMEM
18: nid005911:38867:48339 [3] NCCL INFO Channel 05/0 : 71[3] -> 75[3] [receive] via NET/AWS Libfabric/3
21: nid005914:166786:176224 [2] NCCL INFO Channel 07/0 : 86[2] -> 84[0] via P2P/CUMEM
30: nid005936:49911:59379 [3] NCCL INFO Channel 04/0 : 123[3] -> 127[3] [send] via NET/AWS Libfabric/3
 8: nid005586:68926:78422 [0] NCCL INFO Channel 05/0 : 32[0] -> 36[0] [send] via NET/AWS Libfabric/0
11: nid005591:191606:202324 [3] NCCL INFO Channel 05/0 : 47[3] -> 51[3] [send] via NET/AWS Libfabric/3
 0: nid005574:69061:78873 [3] NCCL INFO Channel 06/0 : 3[3] -> 1[1] via P2P/CUMEM
 9: nid005588:35937:45418 [2] NCCL INFO Channel 07/0 : 38[2] -> 36[0] via P2P/CUMEM
16: nid005802:6297:15936 [0] NCCL INFO Channel 05/0 : 64[0] -> 68[0] [send] via NET/AWS Libfabric/0
13: nid005595:197885:207704 [2] NCCL INFO Channel 06/0 : 54[2] -> 58[2] [send] via NET/AWS Libfabric/2
13: nid005595:197884:207706 [1] NCCL INFO Channel 06/0 : 49[1] -> 53[1] [receive] via NET/AWS Libfabric/1
18: nid005911:38864:48341 [0] NCCL INFO Channel 01/0 : 72[0] -> 76[0] [send] via NET/AWS Libfabric/0
 8: nid005586:68929:78424 [3] NCCL INFO Channel 04/0 : 35[3] -> 39[3] [send] via NET/AWS Libfabric/3
11: nid005591:191603:202323 [0] NCCL INFO Channel 04/0 : 44[0] -> 48[0] [send] via NET/AWS Libfabric/0
31: nid005937:256592:266042 [3] NCCL INFO Channel 03/0 : 127[3] -> 125[1] via P2P/CUMEM
16: nid005802:6299:15934 [2] NCCL INFO Channel 02/0 : 66[2] -> 64[0] via P2P/CUMEM
15: nid005601:210678:220225 [2] NCCL INFO Channel 03/0 : 62[2] -> 60[0] via P2P/CUMEM
17: nid005803:180732:190233 [0] NCCL INFO Channel 01/0 : 64[0] -> 68[0] [receive] via NET/AWS Libfabric/0
 3: nid005580:71822:81308 [3] NCCL INFO Channel 00/0 : 15[3] -> 14[2] via P2P/CUMEM
13: nid005595:197884:207706 [1] NCCL INFO Channel 03/0 : 53[1] -> 57[1] [send] via NET/AWS Libfabric/1
18: nid005911:38867:48339 [3] NCCL INFO Channel 00/0 : 75[3] -> 79[3] [send] via NET/AWS Libfabric/3
30: nid005936:49908:59382 [0] NCCL INFO Channel 01/0 : 120[0] -> 124[0] [send] via NET/AWS Libfabric/0
14: nid005600:217720:227296 [0] NCCL INFO Channel 00/0 : 52[0] -> 56[0] [receive] via NET/AWS Libfabric/0
18: nid005911:38864:48341 [0] NCCL INFO Channel 05/0 : 72[0] -> 76[0] [send] via NET/AWS Libfabric/0
21: nid005914:166784:176223 [0] NCCL INFO Channel 01/0 : 80[0] -> 84[0] [receive] via NET/AWS Libfabric/0
14: nid005600:217720:227296 [0] NCCL INFO Channel 04/0 : 52[0] -> 56[0] [receive] via NET/AWS Libfabric/0
 6: nid005584:28285:37704 [0] NCCL INFO Channel 00/0 : 20[0] -> 24[0] [receive] via NET/AWS Libfabric/0
 6: nid005584:28288:37705 [3] NCCL INFO Channel 01/0 : 23[3] -> 27[3] [receive] via NET/AWS Libfabric/3
18: nid005911:38867:48339 [3] NCCL INFO Channel 04/0 : 75[3] -> 79[3] [send] via NET/AWS Libfabric/3
19: nid005912:12435:21880 [0] NCCL INFO Channel 05/0 : 72[0] -> 76[0] [receive] via NET/AWS Libfabric/0
19: nid005912:12438:21877 [3] NCCL INFO Channel 01/0 : 79[3] -> 83[3] [send] via NET/AWS Libfabric/3
21: nid005914:166787:176226 [3] NCCL INFO Channel 00/0 : 83[3] -> 87[3] [receive] via NET/AWS Libfabric/3
26: nid005920:67126:76602 [3] NCCL INFO Channel 01/0 : 107[3] -> 106[2] via P2P/CUMEM
12: nid005594:53087:62589 [2] NCCL INFO Channel 02/0 : 50[2] -> 48[0] via P2P/CUMEM
10: nid005590:110712:120131 [2] NCCL INFO Channel 06/0 : 42[2] -> 40[0] via P2P/CUMEM
 2: nid005577:17425:26962 [3] NCCL INFO Channel 03/0 : 11[3] -> 10[2] via P2P/CUMEM
13: nid005595:197884:207706 [1] NCCL INFO Channel 07/0 : 53[1] -> 57[1] [send] via NET/AWS Libfabric/1
30: nid005936:49908:59382 [0] NCCL INFO Channel 05/0 : 120[0] -> 124[0] [send] via NET/AWS Libfabric/0
11: nid005591:191605:202322 [2] NCCL INFO Channel 07/0 : 46[2] -> 44[0] via P2P/CUMEM
10: nid005590:110713:120130 [3] NCCL INFO Channel 01/0 : 39[3] -> 43[3] [receive] via NET/AWS Libfabric/3
21: nid005914:166784:176223 [0] NCCL INFO Channel 05/0 : 80[0] -> 84[0] [receive] via NET/AWS Libfabric/0
21: nid005914:166787:176226 [3] NCCL INFO Channel 04/0 : 83[3] -> 87[3] [receive] via NET/AWS Libfabric/3
 6: nid005584:28285:37704 [0] NCCL INFO Channel 04/0 : 20[0] -> 24[0] [receive] via NET/AWS Libfabric/0
 7: nid005585:122007:131416 [2] NCCL INFO Channel 07/0 : 30[2] -> 28[0] via P2P/CUMEM
 8: nid005586:68928:78423 [2] NCCL INFO Channel 06/0 : 34[2] -> 32[0] via P2P/CUMEM
 6: nid005584:28287:37702 [2] NCCL INFO Channel 06/0 : 26[2] -> 24[0] via P2P/CUMEM
12: nid005594:53088:62590 [3] NCCL INFO Channel 01/0 : 47[3] -> 51[3] [receive] via NET/AWS Libfabric/3
10: nid005590:110713:120130 [3] NCCL INFO Channel 05/0 : 39[3] -> 43[3] [receive] via NET/AWS Libfabric/3
14: nid005600:217720:227296 [0] NCCL INFO Channel 01/0 : 56[0] -> 60[0] [send] via NET/AWS Libfabric/0
 6: nid005584:28288:37705 [3] NCCL INFO Channel 05/0 : 23[3] -> 27[3] [receive] via NET/AWS Libfabric/3
17: nid005803:180735:190231 [3] NCCL INFO Channel 03/0 : 71[3] -> 69[1] via P2P/CUMEM
19: nid005912:12435:21880 [0] NCCL INFO Channel 00/0 : 76[0] -> 80[0] [send] via NET/AWS Libfabric/0
19: nid005912:12438:21877 [3] NCCL INFO Channel 05/0 : 79[3] -> 83[3] [send] via NET/AWS Libfabric/3
27: nid005922:80744:90178 [3] NCCL INFO Channel 00/0 : 111[3] -> 110[2] via P2P/CUMEM
 6: nid005584:28285:37704 [0] NCCL INFO Channel 01/0 : 24[0] -> 28[0] [send] via NET/AWS Libfabric/0
31: nid005937:256592:266042 [3] NCCL INFO Channel 07/0 : 127[3] -> 125[1] via P2P/CUMEM
12: nid005594:53085:62591 [0] NCCL INFO Channel 00/0 : 44[0] -> 48[0] [receive] via NET/AWS Libfabric/0
17: nid005803:180732:190233 [0] NCCL INFO Channel 05/0 : 64[0] -> 68[0] [receive] via NET/AWS Libfabric/0
13: nid005595:197885:207704 [2] NCCL INFO Channel 03/0 : 54[2] -> 52[0] via P2P/CUMEM
14: nid005600:217722:227298 [2] NCCL INFO Channel 02/0 : 58[2] -> 56[0] via P2P/CUMEM
 6: nid005584:28288:37705 [3] NCCL INFO Channel 00/0 : 27[3] -> 31[3] [send] via NET/AWS Libfabric/3
 1: nid005576:147560:156972 [3] NCCL INFO Channel 00/0 : 7[3] -> 6[2] via P2P/CUMEM
19: nid005912:12435:21880 [0] NCCL INFO Channel 04/0 : 76[0] -> 80[0] [send] via NET/AWS Libfabric/0
21: nid005914:166784:176223 [0] NCCL INFO Channel 00/0 : 84[0] -> 88[0] [send] via NET/AWS Libfabric/0
21: nid005914:166787:176226 [3] NCCL INFO Channel 01/0 : 87[3] -> 91[3] [send] via NET/AWS Libfabric/3
14: nid005600:217723:227297 [3] NCCL INFO Channel 01/0 : 55[3] -> 59[3] [receive] via NET/AWS Libfabric/3
 0: nid005574:69061:78873 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM
12: nid005594:53088:62590 [3] NCCL INFO Channel 05/0 : 47[3] -> 51[3] [receive] via NET/AWS Libfabric/3
12: nid005594:53087:62589 [2] NCCL INFO Channel 06/0 : 50[2] -> 48[0] via P2P/CUMEM
10: nid005590:110713:120130 [3] NCCL INFO Channel 00/0 : 43[3] -> 47[3] [send] via NET/AWS Libfabric/3
 9: nid005588:35938:45417 [3] NCCL INFO Channel 00/0 : 35[3] -> 39[3] [receive] via NET/AWS Libfabric/3
15: nid005601:210678:220225 [2] NCCL INFO Channel 07/0 : 62[2] -> 60[0] via P2P/CUMEM
14: nid005600:217720:227296 [0] NCCL INFO Channel 05/0 : 56[0] -> 60[0] [send] via NET/AWS Libfabric/0
 6: nid005584:28285:37704 [0] NCCL INFO Channel 05/0 : 24[0] -> 28[0] [send] via NET/AWS Libfabric/0
12: nid005594:53085:62591 [0] NCCL INFO Channel 04/0 : 44[0] -> 48[0] [receive] via NET/AWS Libfabric/0
10: nid005590:110710:120132 [0] NCCL INFO Channel 00/0 : 36[0] -> 40[0] [receive] via NET/AWS Libfabric/0
10: nid005590:110713:120130 [3] NCCL INFO Channel 04/0 : 43[3] -> 47[3] [send] via NET/AWS Libfabric/3
16: nid005802:6299:15934 [2] NCCL INFO Channel 06/0 : 66[2] -> 64[0] via P2P/CUMEM
17: nid005803:180732:190233 [0] NCCL INFO Channel 00/0 : 68[0] -> 72[0] [send] via NET/AWS Libfabric/0
21: nid005914:166784:176223 [0] NCCL INFO Channel 04/0 : 84[0] -> 88[0] [send] via NET/AWS Libfabric/0
14: nid005600:217723:227297 [3] NCCL INFO Channel 05/0 : 55[3] -> 59[3] [receive] via NET/AWS Libfabric/3
 6: nid005584:28288:37705 [3] NCCL INFO Channel 04/0 : 27[3] -> 31[3] [send] via NET/AWS Libfabric/3
12: nid005594:53088:62590 [3] NCCL INFO Channel 00/0 : 51[3] -> 55[3] [send] via NET/AWS Libfabric/3
18: nid005911:38867:48339 [3] NCCL INFO Channel 02/0 : 75[3] -> 73[1] via P2P/CUMEM
21: nid005914:166787:176226 [3] NCCL INFO Channel 05/0 : 87[3] -> 91[3] [send] via NET/AWS Libfabric/3
14: nid005600:217723:227297 [3] NCCL INFO Channel 00/0 : 59[3] -> 63[3] [send] via NET/AWS Libfabric/3
12: nid005594:53085:62591 [0] NCCL INFO Channel 01/0 : 48[0] -> 52[0] [send] via NET/AWS Libfabric/0
 4: nid005581:264526:273970 [3] NCCL INFO Channel 03/0 : 19[3] -> 18[2] via P2P/CUMEM
 9: nid005588:35938:45417 [3] NCCL INFO Channel 04/0 : 35[3] -> 39[3] [receive] via NET/AWS Libfabric/3
 7: nid005585:122005:131417 [0] NCCL INFO Channel 01/0 : 24[0] -> 28[0] [receive] via NET/AWS Libfabric/0
 2: nid005577:17423:26961 [1] NCCL INFO Channel 01/0 : 9[1] -> 8[0] via P2P/CUMEM
17: nid005803:180735:190231 [3] NCCL INFO Channel 07/0 : 71[3] -> 69[1] via P2P/CUMEM
 7: nid005585:122008:131414 [3] NCCL INFO Channel 00/0 : 27[3] -> 31[3] [receive] via NET/AWS Libfabric/3
 5: nid005582:196716:206702 [3] NCCL INFO Channel 03/0 : 23[3] -> 21[1] via P2P/CUMEM
14: nid005600:217722:227298 [2] NCCL INFO Channel 06/0 : 58[2] -> 56[0] via P2P/CUMEM
12: nid005594:53088:62590 [3] NCCL INFO Channel 04/0 : 51[3] -> 55[3] [send] via NET/AWS Libfabric/3
17: nid005803:180732:190233 [0] NCCL INFO Channel 04/0 : 68[0] -> 72[0] [send] via NET/AWS Libfabric/0
13: nid005595:197885:207704 [2] NCCL INFO Channel 07/0 : 54[2] -> 52[0] via P2P/CUMEM
14: nid005600:217723:227297 [3] NCCL INFO Channel 04/0 : 59[3] -> 63[3] [send] via NET/AWS Libfabric/3
12: nid005594:53085:62591 [0] NCCL INFO Channel 05/0 : 48[0] -> 52[0] [send] via NET/AWS Libfabric/0
15: nid005601:210676:220224 [0] NCCL INFO Channel 01/0 : 56[0] -> 60[0] [receive] via NET/AWS Libfabric/0
31: nid005937:256592:266042 [3] NCCL INFO Channel 00/0 : 127[3] -> 126[2] via P2P/CUMEM
10: nid005590:110710:120132 [0] NCCL INFO Channel 04/0 : 36[0] -> 40[0] [receive] via NET/AWS Libfabric/0
 2: nid005577:17425:26962 [3] NCCL INFO Channel 05/0 : 11[3] -> 10[2] via P2P/CUMEM
 9: nid005588:35938:45417 [3] NCCL INFO Channel 01/0 : 39[3] -> 43[3] [send] via NET/AWS Libfabric/3
 7: nid005585:122005:131417 [0] NCCL INFO Channel 05/0 : 24[0] -> 28[0] [receive] via NET/AWS Libfabric/0
 7: nid005585:122008:131414 [3] NCCL INFO Channel 04/0 : 27[3] -> 31[3] [receive] via NET/AWS Libfabric/3
15: nid005601:210679:220227 [3] NCCL INFO Channel 00/0 : 59[3] -> 63[3] [receive] via NET/AWS Libfabric/3
22: nid005915:274817:284263 [3] NCCL INFO Channel 02/0 : 91[3] -> 89[1] via P2P/CUMEM
 9: nid005588:35935:45419 [0] NCCL INFO Channel 01/0 : 32[0] -> 36[0] [receive] via NET/AWS Libfabric/0
 3: nid005580:71822:81308 [3] NCCL INFO Channel 02/0 : 15[3] -> 14[2] via P2P/CUMEM
 9: nid005588:35938:45417 [3] NCCL INFO Channel 05/0 : 39[3] -> 43[3] [send] via NET/AWS Libfabric/3
15: nid005601:210676:220224 [0] NCCL INFO Channel 05/0 : 56[0] -> 60[0] [receive] via NET/AWS Libfabric/0
 7: nid005585:122005:131417 [0] NCCL INFO Channel 00/0 : 28[0] -> 32[0] [send] via NET/AWS Libfabric/0
18: nid005911:38867:48339 [3] NCCL INFO Channel 06/0 : 75[3] -> 73[1] via P2P/CUMEM
 7: nid005585:122008:131414 [3] NCCL INFO Channel 01/0 : 31[3] -> 35[3] [send] via NET/AWS Libfabric/3
11: nid005591:191606:202324 [3] NCCL INFO Channel 03/0 : 47[3] -> 45[1] via P2P/CUMEM
 2: nid005577:17423:26961 [1] NCCL INFO Channel 03/0 : 9[1] -> 8[0] via P2P/CUMEM
15: nid005601:210679:220227 [3] NCCL INFO Channel 04/0 : 59[3] -> 63[3] [receive] via NET/AWS Libfabric/3
 7: nid005585:122005:131417 [0] NCCL INFO Channel 04/0 : 28[0] -> 32[0] [send] via NET/AWS Libfabric/0
26: nid005920:67126:76602 [3] NCCL INFO Channel 03/0 : 107[3] -> 106[2] via P2P/CUMEM
10: nid005590:110710:120132 [0] NCCL INFO Channel 01/0 : 40[0] -> 44[0] [send] via NET/AWS Libfabric/0
15: nid005601:210676:220224 [0] NCCL INFO Channel 00/0 : 60[0] -> 64[0] [send] via NET/AWS Libfabric/0
 7: nid005585:122008:131414 [3] NCCL INFO Channel 05/0 : 31[3] -> 35[3] [send] via NET/AWS Libfabric/3
17: nid005803:180735:190231 [3] NCCL INFO Channel 00/0 : 71[3] -> 70[2] via P2P/CUMEM
 1: nid005576:147560:156972 [3] NCCL INFO Channel 02/0 : 7[3] -> 6[2] via P2P/CUMEM
 9: nid005588:35935:45419 [0] NCCL INFO Channel 05/0 : 32[0] -> 36[0] [receive] via NET/AWS Libfabric/0
13: nid005595:197886:207705 [3] NCCL INFO Channel 00/0 : 51[3] -> 55[3] [receive] via NET/AWS Libfabric/3
15: nid005601:210679:220227 [3] NCCL INFO Channel 01/0 : 63[3] -> 67[3] [send] via NET/AWS Libfabric/3
15: nid005601:210676:220224 [0] NCCL INFO Channel 04/0 : 60[0] -> 64[0] [send] via NET/AWS Libfabric/0
 9: nid005588:35935:45419 [0] NCCL INFO Channel 00/0 : 36[0] -> 40[0] [send] via NET/AWS Libfabric/0
20: nid005913:292684:9592 [3] NCCL INFO Channel 01/0 : 79[3] -> 83[3] [receive] via NET/AWS Libfabric/3
 5: nid005582:196716:206702 [3] NCCL INFO Channel 07/0 : 23[3] -> 21[1] via P2P/CUMEM
 2: nid005577:17425:26962 [3] NCCL INFO Channel 07/0 : 11[3] -> 10[2] via P2P/CUMEM
27: nid005922:80744:90178 [3] NCCL INFO Channel 02/0 : 111[3] -> 110[2] via P2P/CUMEM
10: nid005590:110713:120130 [3] NCCL INFO Channel 02/0 : 43[3] -> 41[1] via P2P/CUMEM
 9: nid005588:35935:45419 [0] NCCL INFO Channel 04/0 : 36[0] -> 40[0] [send] via NET/AWS Libfabric/0
15: nid005601:210679:220227 [3] NCCL INFO Channel 05/0 : 63[3] -> 67[3] [send] via NET/AWS Libfabric/3
 6: nid005584:28288:37705 [3] NCCL INFO Channel 02/0 : 27[3] -> 25[1] via P2P/CUMEM
11: nid005591:191606:202324 [3] NCCL INFO Channel 07/0 : 47[3] -> 45[1] via P2P/CUMEM
10: nid005590:110710:120132 [0] NCCL INFO Channel 05/0 : 40[0] -> 44[0] [send] via NET/AWS Libfabric/0
 9: nid005588:35938:45417 [3] NCCL INFO Channel 03/0 : 39[3] -> 37[1] via P2P/CUMEM
 7: nid005585:122008:131414 [3] NCCL INFO Channel 03/0 : 31[3] -> 29[1] via P2P/CUMEM
13: nid005595:197886:207705 [3] NCCL INFO Channel 04/0 : 51[3] -> 55[3] [receive] via NET/AWS Libfabric/3
20: nid005913:292684:9592 [3] NCCL INFO Channel 05/0 : 79[3] -> 83[3] [receive] via NET/AWS Libfabric/3
18: nid005911:38867:48339 [3] NCCL INFO Channel 01/0 : 75[3] -> 74[2] via P2P/CUMEM
22: nid005915:274817:284263 [3] NCCL INFO Channel 06/0 : 91[3] -> 89[1] via P2P/CUMEM
24: nid005918:92504:101984 [0] NCCL INFO Channel 04/0 : 96[0] -> 97[1] via P2P/CUMEM
 0: nid005574:69061:78873 [3] NCCL INFO Channel 03/0 : 3[3] -> 2[2] via P2P/CUMEM
13: nid005595:197883:207703 [0] NCCL INFO Channel 01/0 : 48[0] -> 52[0] [receive] via NET/AWS Libfabric/0
31: nid005937:256592:266042 [3] NCCL INFO Channel 02/0 : 127[3] -> 126[2] via P2P/CUMEM
13: nid005595:197886:207705 [3] NCCL INFO Channel 01/0 : 55[3] -> 59[3] [send] via NET/AWS Libfabric/3
20: nid005913:292684:9592 [3] NCCL INFO Channel 00/0 : 83[3] -> 87[3] [send] via NET/AWS Libfabric/3
20: nid005913:292681:9594 [0] NCCL INFO Channel 00/0 : 76[0] -> 80[0] [receive] via NET/AWS Libfabric/0
 8: nid005586:68929:78424 [3] NCCL INFO Channel 02/0 : 35[3] -> 33[1] via P2P/CUMEM
13: nid005595:197883:207703 [0] NCCL INFO Channel 05/0 : 48[0] -> 52[0] [receive] via NET/AWS Libfabric/0
20: nid005913:292684:9592 [3] NCCL INFO Channel 04/0 : 83[3] -> 87[3] [send] via NET/AWS Libfabric/3
 4: nid005581:264526:273970 [3] NCCL INFO Channel 05/0 : 19[3] -> 18[2] via P2P/CUMEM
13: nid005595:197886:207705 [3] NCCL INFO Channel 05/0 : 55[3] -> 59[3] [send] via NET/AWS Libfabric/3
 4: nid005581:264524:273971 [1] NCCL INFO Channel 01/0 : 17[1] -> 16[0] via P2P/CUMEM
10: nid005590:110713:120130 [3] NCCL INFO Channel 06/0 : 43[3] -> 41[1] via P2P/CUMEM
16: nid005802:6300:15935 [3] NCCL INFO Channel 02/0 : 67[3] -> 65[1] via P2P/CUMEM
13: nid005595:197883:207703 [0] NCCL INFO Channel 00/0 : 52[0] -> 56[0] [send] via NET/AWS Libfabric/0
15: nid005601:210679:220227 [3] NCCL INFO Channel 03/0 : 63[3] -> 61[1] via P2P/CUMEM
 9: nid005588:35938:45417 [3] NCCL INFO Channel 07/0 : 39[3] -> 37[1] via P2P/CUMEM
 3: nid005580:71820:81305 [1] NCCL INFO Channel 00/0 : 13[1] -> 12[0] via P2P/CUMEM
11: nid005591:191606:202324 [3] NCCL INFO Channel 00/0 : 47[3] -> 46[2] via P2P/CUMEM
13: nid005595:197883:207703 [0] NCCL INFO Channel 04/0 : 52[0] -> 56[0] [send] via NET/AWS Libfabric/0
 3: nid005580:71822:81308 [3] NCCL INFO Channel 04/0 : 15[3] -> 14[2] via P2P/CUMEM
17: nid005803:180735:190231 [3] NCCL INFO Channel 02/0 : 71[3] -> 70[2] via P2P/CUMEM
 6: nid005584:28288:37705 [3] NCCL INFO Channel 06/0 : 27[3] -> 25[1] via P2P/CUMEM
19: nid005912:12438:21877 [3] NCCL INFO Channel 03/0 : 79[3] -> 77[1] via P2P/CUMEM
12: nid005594:53088:62590 [3] NCCL INFO Channel 02/0 : 51[3] -> 49[1] via P2P/CUMEM
 1: nid005576:147558:156971 [1] NCCL INFO Channel 00/0 : 5[1] -> 4[0] via P2P/CUMEM
 7: nid005585:122008:131414 [3] NCCL INFO Channel 07/0 : 31[3] -> 29[1] via P2P/CUMEM
 2: nid005577:17423:26961 [1] NCCL INFO Channel 05/0 : 9[1] -> 8[0] via P2P/CUMEM
 5: nid005582:196716:206702 [3] NCCL INFO Channel 00/0 : 23[3] -> 22[2] via P2P/CUMEM
26: nid005920:67124:76603 [1] NCCL INFO Channel 01/0 : 105[1] -> 104[0] via P2P/CUMEM
26: nid005920:67126:76602 [3] NCCL INFO Channel 05/0 : 107[3] -> 106[2] via P2P/CUMEM
31: nid005937:256592:266042 [3] NCCL INFO Channel 04/0 : 127[3] -> 126[2] via P2P/CUMEM
20: nid005913:292684:9592 [3] NCCL INFO Channel 02/0 : 83[3] -> 81[1] via P2P/CUMEM
21: nid005914:166787:176226 [3] NCCL INFO Channel 03/0 : 87[3] -> 85[1] via P2P/CUMEM
31: nid005937:256590:266043 [1] NCCL INFO Channel 00/0 : 125[1] -> 124[0] via P2P/CUMEM
27: nid005922:80744:90178 [3] NCCL INFO Channel 04/0 : 111[3] -> 110[2] via P2P/CUMEM
 1: nid005576:147560:156972 [3] NCCL INFO Channel 04/0 : 7[3] -> 6[2] via P2P/CUMEM
18: nid005911:38867:48339 [3] NCCL INFO Channel 03/0 : 75[3] -> 74[2] via P2P/CUMEM
13: nid005595:197886:207705 [3] NCCL INFO Channel 03/0 : 55[3] -> 53[1] via P2P/CUMEM
22: nid005915:274817:284263 [3] NCCL INFO Channel 01/0 : 91[3] -> 90[2] via P2P/CUMEM
 0: nid005574:69059:78871 [1] NCCL INFO Channel 01/0 : 1[1] -> 0[0] via P2P/CUMEM
10: nid005590:110713:120130 [3] NCCL INFO Channel 01/0 : 43[3] -> 42[2] via P2P/CUMEM
15: nid005601:210679:220227 [3] NCCL INFO Channel 07/0 : 63[3] -> 61[1] via P2P/CUMEM
20: nid005913:292681:9594 [0] NCCL INFO Channel 04/0 : 76[0] -> 80[0] [receive] via NET/AWS Libfabric/0
 8: nid005586:68929:78424 [3] NCCL INFO Channel 06/0 : 35[3] -> 33[1] via P2P/CUMEM
14: nid005600:217723:227297 [3] NCCL INFO Channel 02/0 : 59[3] -> 57[1] via P2P/CUMEM
29: nid005932:167680:177125 [0] NCCL INFO Channel 05/0 : 116[0] -> 117[1] via P2P/CUMEM
17: nid005803:180733:190230 [1] NCCL INFO Channel 00/0 : 69[1] -> 68[0] via P2P/CUMEM
29: nid005932:167682:177124 [2] NCCL INFO Channel 01/0 : 118[2] -> 119[3] via P2P/CUMEM
16: nid005802:6300:15935 [3] NCCL INFO Channel 06/0 : 67[3] -> 65[1] via P2P/CUMEM
19: nid005912:12438:21877 [3] NCCL INFO Channel 07/0 : 79[3] -> 77[1] via P2P/CUMEM
29: nid005932:167681:177123 [1] NCCL INFO Channel 01/0 : 117[1] -> 118[2] via P2P/CUMEM
20: nid005913:292681:9594 [0] NCCL INFO Channel 01/0 : 80[0] -> 84[0] [send] via NET/AWS Libfabric/0
 0: nid005574:69061:78873 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM
21: nid005914:166787:176226 [3] NCCL INFO Channel 07/0 : 87[3] -> 85[1] via P2P/CUMEM
12: nid005594:53088:62590 [3] NCCL INFO Channel 06/0 : 51[3] -> 49[1] via P2P/CUMEM
24: nid005918:92506:101983 [2] NCCL INFO Channel 00/0 : 98[2] -> 99[3] via P2P/CUMEM
17: nid005803:180735:190231 [3] NCCL INFO Channel 04/0 : 71[3] -> 70[2] via P2P/CUMEM
20: nid005913:292681:9594 [0] NCCL INFO Channel 05/0 : 80[0] -> 84[0] [send] via NET/AWS Libfabric/0
 4: nid005581:264526:273970 [3] NCCL INFO Channel 07/0 : 19[3] -> 18[2] via P2P/CUMEM
 9: nid005588:35938:45417 [3] NCCL INFO Channel 00/0 : 39[3] -> 38[2] via P2P/CUMEM
 6: nid005584:28288:37705 [3] NCCL INFO Channel 01/0 : 27[3] -> 26[2] via P2P/CUMEM
11: nid005591:191606:202324 [3] NCCL INFO Channel 02/0 : 47[3] -> 46[2] via P2P/CUMEM
 4: nid005581:264524:273971 [1] NCCL INFO Channel 03/0 : 17[1] -> 16[0] via P2P/CUMEM
17: nid005803:180733:190230 [1] NCCL INFO Channel 02/0 : 69[1] -> 68[0] via P2P/CUMEM
 7: nid005585:122008:131414 [3] NCCL INFO Channel 00/0 : 31[3] -> 30[2] via P2P/CUMEM
20: nid005913:292684:9592 [3] NCCL INFO Channel 06/0 : 83[3] -> 81[1] via P2P/CUMEM
18: nid005911:38865:48338 [1] NCCL INFO Channel 01/0 : 73[1] -> 72[0] via P2P/CUMEM
24: nid005918:92505:101985 [1] NCCL INFO Channel 00/0 : 97[1] -> 98[2] via P2P/CUMEM
 1: nid005576:147558:156971 [1] NCCL INFO Channel 02/0 : 5[1] -> 4[0] via P2P/CUMEM
 3: nid005580:71820:81305 [1] NCCL INFO Channel 02/0 : 13[1] -> 12[0] via P2P/CUMEM
14: nid005600:217723:227297 [3] NCCL INFO Channel 06/0 : 59[3] -> 57[1] via P2P/CUMEM
 2: nid005577:17423:26961 [1] NCCL INFO Channel 07/0 : 9[1] -> 8[0] via P2P/CUMEM
 3: nid005580:71822:81308 [3] NCCL INFO Channel 06/0 : 15[3] -> 14[2] via P2P/CUMEM
19: nid005912:12438:21877 [3] NCCL INFO Channel 00/0 : 79[3] -> 78[2] via P2P/CUMEM
15: nid005601:210679:220227 [3] NCCL INFO Channel 00/0 : 63[3] -> 62[2] via P2P/CUMEM
10: nid005590:110713:120130 [3] NCCL INFO Channel 03/0 : 43[3] -> 42[2] via P2P/CUMEM
13: nid005595:197886:207705 [3] NCCL INFO Channel 07/0 : 55[3] -> 53[1] via P2P/CUMEM
26: nid005920:67124:76603 [1] NCCL INFO Channel 03/0 : 105[1] -> 104[0] via P2P/CUMEM
 8: nid005586:68929:78424 [3] NCCL INFO Channel 01/0 : 35[3] -> 34[2] via P2P/CUMEM
21: nid005914:166787:176226 [3] NCCL INFO Channel 00/0 : 87[3] -> 86[2] via P2P/CUMEM
 0: nid005574:69059:78871 [1] NCCL INFO Channel 03/0 : 1[1] -> 0[0] via P2P/CUMEM
27: nid005922:80744:90178 [3] NCCL INFO Channel 06/0 : 111[3] -> 110[2] via P2P/CUMEM
12: nid005594:53088:62590 [3] NCCL INFO Channel 01/0 : 51[3] -> 50[2] via P2P/CUMEM
26: nid005920:67126:76602 [3] NCCL INFO Channel 07/0 : 107[3] -> 106[2] via P2P/CUMEM
27: nid005922:80742:90176 [1] NCCL INFO Channel 00/0 : 109[1] -> 108[0] via P2P/CUMEM
31: nid005937:256592:266042 [3] NCCL INFO Channel 06/0 : 127[3] -> 126[2] via P2P/CUMEM
18: nid005911:38867:48339 [3] NCCL INFO Channel 05/0 : 75[3] -> 74[2] via P2P/CUMEM
31: nid005937:256590:266043 [1] NCCL INFO Channel 02/0 : 125[1] -> 124[0] via P2P/CUMEM
16: nid005802:6300:15935 [3] NCCL INFO Channel 01/0 : 67[3] -> 66[2] via P2P/CUMEM
 5: nid005582:196716:206702 [3] NCCL INFO Channel 02/0 : 23[3] -> 22[2] via P2P/CUMEM
 1: nid005576:147560:156972 [3] NCCL INFO Channel 06/0 : 7[3] -> 6[2] via P2P/CUMEM
20: nid005913:292684:9592 [3] NCCL INFO Channel 01/0 : 83[3] -> 82[2] via P2P/CUMEM
17: nid005803:180735:190231 [3] NCCL INFO Channel 06/0 : 71[3] -> 70[2] via P2P/CUMEM
22: nid005915:274817:284263 [3] NCCL INFO Channel 03/0 : 91[3] -> 90[2] via P2P/CUMEM
29: nid005932:167682:177124 [2] NCCL INFO Channel 05/0 : 118[2] -> 119[3] via P2P/CUMEM
24: nid005918:92506:101983 [2] NCCL INFO Channel 04/0 : 98[2] -> 99[3] via P2P/CUMEM
29: nid005932:167681:177123 [1] NCCL INFO Channel 05/0 : 117[1] -> 118[2] via P2P/CUMEM
24: nid005918:92505:101985 [1] NCCL INFO Channel 04/0 : 97[1] -> 98[2] via P2P/CUMEM
11: nid005591:191604:202325 [1] NCCL INFO Channel 00/0 : 45[1] -> 44[0] via P2P/CUMEM
11: nid005591:191606:202324 [3] NCCL INFO Channel 04/0 : 47[3] -> 46[2] via P2P/CUMEM
10: nid005590:110713:120130 [3] NCCL INFO Channel 05/0 : 43[3] -> 42[2] via P2P/CUMEM
 0: nid005574:69061:78873 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM
 9: nid005588:35938:45417 [3] NCCL INFO Channel 02/0 : 39[3] -> 38[2] via P2P/CUMEM
14: nid005600:217723:227297 [3] NCCL INFO Channel 01/0 : 59[3] -> 58[2] via P2P/CUMEM
 4: nid005581:264525:273968 [2] NCCL INFO Channel 01/0 : 18[2] -> 17[1] via P2P/CUMEM
 4: nid005581:264524:273971 [1] NCCL INFO Channel 05/0 : 17[1] -> 16[0] via P2P/CUMEM
18: nid005911:38865:48338 [1] NCCL INFO Channel 03/0 : 73[1] -> 72[0] via P2P/CUMEM
17: nid005803:180733:190230 [1] NCCL INFO Channel 04/0 : 69[1] -> 68[0] via P2P/CUMEM
 1: nid005576:147558:156971 [1] NCCL INFO Channel 04/0 : 5[1] -> 4[0] via P2P/CUMEM
19: nid005912:12438:21877 [3] NCCL INFO Channel 02/0 : 79[3] -> 78[2] via P2P/CUMEM
10: nid005590:110711:120129 [1] NCCL INFO Channel 01/0 : 41[1] -> 40[0] via P2P/CUMEM
 3: nid005580:71821:81306 [2] NCCL INFO Channel 00/0 : 14[2] -> 13[1] via P2P/CUMEM
13: nid005595:197886:207705 [3] NCCL INFO Channel 00/0 : 55[3] -> 54[2] via P2P/CUMEM
 6: nid005584:28288:37705 [3] NCCL INFO Channel 03/0 : 27[3] -> 26[2] via P2P/CUMEM
 3: nid005580:71820:81305 [1] NCCL INFO Channel 04/0 : 13[1] -> 12[0] via P2P/CUMEM
21: nid005914:166787:176226 [3] NCCL INFO Channel 02/0 : 87[3] -> 86[2] via P2P/CUMEM
 7: nid005585:122008:131414 [3] NCCL INFO Channel 02/0 : 31[3] -> 30[2] via P2P/CUMEM
27: nid005922:80743:90177 [2] NCCL INFO Channel 00/0 : 110[2] -> 109[1] via P2P/CUMEM
 0: nid005574:69059:78871 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM
26: nid005920:67124:76603 [1] NCCL INFO Channel 05/0 : 105[1] -> 104[0] via P2P/CUMEM
12: nid005594:53088:62590 [3] NCCL INFO Channel 03/0 : 51[3] -> 50[2] via P2P/CUMEM
15: nid005601:210679:220227 [3] NCCL INFO Channel 02/0 : 63[3] -> 62[2] via P2P/CUMEM
 4: nid005581:264525:273968 [2] NCCL INFO Channel 05/0 : 18[2] -> 17[1] via P2P/CUMEM
20: nid005913:292684:9592 [3] NCCL INFO Channel 03/0 : 83[3] -> 82[2] via P2P/CUMEM
 4: nid005581:264524:273971 [1] NCCL INFO Channel 07/0 : 17[1] -> 16[0] via P2P/CUMEM
31: nid005937:256590:266043 [1] NCCL INFO Channel 04/0 : 125[1] -> 124[0] via P2P/CUMEM
 2: nid005577:17424:26963 [2] NCCL INFO Channel 01/0 : 10[2] -> 9[1] via P2P/CUMEM
 8: nid005586:68929:78424 [3] NCCL INFO Channel 03/0 : 35[3] -> 34[2] via P2P/CUMEM
26: nid005920:67125:76601 [2] NCCL INFO Channel 01/0 : 106[2] -> 105[1] via P2P/CUMEM
27: nid005922:80742:90176 [1] NCCL INFO Channel 02/0 : 109[1] -> 108[0] via P2P/CUMEM
16: nid005802:6300:15935 [3] NCCL INFO Channel 03/0 : 67[3] -> 66[2] via P2P/CUMEM
 5: nid005582:196714:206703 [1] NCCL INFO Channel 00/0 : 21[1] -> 20[0] via P2P/CUMEM
 5: nid005582:196716:206702 [3] NCCL INFO Channel 04/0 : 23[3] -> 22[2] via P2P/CUMEM
27: nid005922:80743:90177 [2] NCCL INFO Channel 04/0 : 110[2] -> 109[1] via P2P/CUMEM
29: nid005932:167680:177125 [0] NCCL INFO Channel 02/0 : 116[0] -> 119[3] via P2P/CUMEM
18: nid005911:38867:48339 [3] NCCL INFO Channel 07/0 : 75[3] -> 74[2] via P2P/CUMEM
 3: nid005580:71821:81306 [2] NCCL INFO Channel 04/0 : 14[2] -> 13[1] via P2P/CUMEM
11: nid005591:191604:202325 [1] NCCL INFO Channel 02/0 : 45[1] -> 44[0] via P2P/CUMEM
 9: nid005588:35936:45416 [1] NCCL INFO Channel 00/0 : 37[1] -> 36[0] via P2P/CUMEM
 3: nid005580:71820:81305 [1] NCCL INFO Channel 06/0 : 13[1] -> 12[0] via P2P/CUMEM
24: nid005918:92504:101984 [0] NCCL INFO Channel 02/0 : 96[0] -> 99[3] via P2P/CUMEM
 2: nid005577:17424:26963 [2] NCCL INFO Channel 05/0 : 10[2] -> 9[1] via P2P/CUMEM
 1: nid005576:147559:156973 [2] NCCL INFO Channel 00/0 : 6[2] -> 5[1] via P2P/CUMEM
11: nid005591:191606:202324 [3] NCCL INFO Channel 06/0 : 47[3] -> 46[2] via P2P/CUMEM
22: nid005915:274815:284266 [1] NCCL INFO Channel 01/0 : 89[1] -> 88[0] via P2P/CUMEM
26: nid005920:67124:76603 [1] NCCL INFO Channel 07/0 : 105[1] -> 104[0] via P2P/CUMEM
22: nid005915:274817:284263 [3] NCCL INFO Channel 05/0 : 91[3] -> 90[2] via P2P/CUMEM
10: nid005590:110713:120130 [3] NCCL INFO Channel 07/0 : 43[3] -> 42[2] via P2P/CUMEM
19: nid005912:12438:21877 [3] NCCL INFO Channel 04/0 : 79[3] -> 78[2] via P2P/CUMEM
 1: nid005576:147558:156971 [1] NCCL INFO Channel 06/0 : 5[1] -> 4[0] via P2P/CUMEM
 0: nid005574:69060:78872 [2] NCCL INFO Channel 01/0 : 2[2] -> 1[1] via P2P/CUMEM
 9: nid005588:35938:45417 [3] NCCL INFO Channel 04/0 : 39[3] -> 38[2] via P2P/CUMEM
20: nid005913:292682:9590 [1] NCCL INFO Channel 01/0 : 81[1] -> 80[0] via P2P/CUMEM
26: nid005920:67125:76601 [2] NCCL INFO Channel 05/0 : 106[2] -> 105[1] via P2P/CUMEM
20: nid005913:292684:9592 [3] NCCL INFO Channel 05/0 : 83[3] -> 82[2] via P2P/CUMEM
14: nid005600:217723:227297 [3] NCCL INFO Channel 03/0 : 59[3] -> 58[2] via P2P/CUMEM
 0: nid005574:69059:78871 [1] NCCL INFO Channel 07/0 : 1[1] -> 0[0] via P2P/CUMEM
17: nid005803:180733:190230 [1] NCCL INFO Channel 06/0 : 69[1] -> 68[0] via P2P/CUMEM
27: nid005922:80742:90176 [1] NCCL INFO Channel 04/0 : 109[1] -> 108[0] via P2P/CUMEM
19: nid005912:12436:21878 [1] NCCL INFO Channel 00/0 : 77[1] -> 76[0] via P2P/CUMEM
18: nid005911:38865:48338 [1] NCCL INFO Channel 05/0 : 73[1] -> 72[0] via P2P/CUMEM
21: nid005914:166787:176226 [3] NCCL INFO Channel 04/0 : 87[3] -> 86[2] via P2P/CUMEM
10: nid005590:110711:120129 [1] NCCL INFO Channel 03/0 : 41[1] -> 40[0] via P2P/CUMEM
21: nid005914:166785:176225 [1] NCCL INFO Channel 00/0 : 85[1] -> 84[0] via P2P/CUMEM
31: nid005937:256590:266043 [1] NCCL INFO Channel 06/0 : 125[1] -> 124[0] via P2P/CUMEM
 6: nid005584:28286:37703 [1] NCCL INFO Channel 01/0 : 25[1] -> 24[0] via P2P/CUMEM
12: nid005594:53086:62592 [1] NCCL INFO Channel 01/0 : 49[1] -> 48[0] via P2P/CUMEM
 1: nid005576:147559:156973 [2] NCCL INFO Channel 04/0 : 6[2] -> 5[1] via P2P/CUMEM
 7: nid005585:122006:131415 [1] NCCL INFO Channel 00/0 : 29[1] -> 28[0] via P2P/CUMEM
 6: nid005584:28288:37705 [3] NCCL INFO Channel 05/0 : 27[3] -> 26[2] via P2P/CUMEM
 7: nid005585:122008:131414 [3] NCCL INFO Channel 04/0 : 31[3] -> 30[2] via P2P/CUMEM
12: nid005594:53088:62590 [3] NCCL INFO Channel 05/0 : 51[3] -> 50[2] via P2P/CUMEM
15: nid005601:210677:220226 [1] NCCL INFO Channel 00/0 : 61[1] -> 60[0] via P2P/CUMEM
13: nid005595:197886:207705 [3] NCCL INFO Channel 02/0 : 55[3] -> 54[2] via P2P/CUMEM
27: nid005922:80742:90176 [1] NCCL INFO Channel 06/0 : 109[1] -> 108[0] via P2P/CUMEM
24: nid005918:92504:101984 [0] NCCL INFO Channel 03/0 : 96[0] -> 99[3] via P2P/CUMEM
15: nid005601:210679:220227 [3] NCCL INFO Channel 04/0 : 63[3] -> 62[2] via P2P/CUMEM
29: nid005932:167680:177125 [0] NCCL INFO Channel 03/0 : 116[0] -> 119[3] via P2P/CUMEM
 0: nid005574:69060:78872 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM
19: nid005912:12438:21877 [3] NCCL INFO Channel 06/0 : 79[3] -> 78[2] via P2P/CUMEM
 8: nid005586:68927:78425 [1] NCCL INFO Channel 01/0 : 33[1] -> 32[0] via P2P/CUMEM
16: nid005802:6298:15933 [1] NCCL INFO Channel 01/0 : 65[1] -> 64[0] via P2P/CUMEM
 9: nid005588:35936:45416 [1] NCCL INFO Channel 02/0 : 37[1] -> 36[0] via P2P/CUMEM
 5: nid005582:196714:206703 [1] NCCL INFO Channel 02/0 : 21[1] -> 20[0] via P2P/CUMEM
16: nid005802:6300:15935 [3] NCCL INFO Channel 05/0 : 67[3] -> 66[2] via P2P/CUMEM
 8: nid005586:68929:78424 [3] NCCL INFO Channel 05/0 : 35[3] -> 34[2] via P2P/CUMEM
 5: nid005582:196716:206702 [3] NCCL INFO Channel 06/0 : 23[3] -> 22[2] via P2P/CUMEM
20: nid005913:292682:9590 [1] NCCL INFO Channel 03/0 : 81[1] -> 80[0] via P2P/CUMEM
11: nid005591:191604:202325 [1] NCCL INFO Channel 04/0 : 45[1] -> 44[0] via P2P/CUMEM
22: nid005915:274817:284263 [3] NCCL INFO Channel 07/0 : 91[3] -> 90[2] via P2P/CUMEM
20: nid005913:292684:9592 [3] NCCL INFO Channel 07/0 : 83[3] -> 82[2] via P2P/CUMEM
22: nid005915:274815:284266 [1] NCCL INFO Channel 03/0 : 89[1] -> 88[0] via P2P/CUMEM
19: nid005912:12436:21878 [1] NCCL INFO Channel 02/0 : 77[1] -> 76[0] via P2P/CUMEM
31: nid005937:256591:266040 [2] NCCL INFO Channel 00/0 : 126[2] -> 125[1] via P2P/CUMEM
18: nid005911:38865:48338 [1] NCCL INFO Channel 07/0 : 73[1] -> 72[0] via P2P/CUMEM
14: nid005600:217721:227295 [1] NCCL INFO Channel 01/0 : 57[1] -> 56[0] via P2P/CUMEM
21: nid005914:166787:176226 [3] NCCL INFO Channel 06/0 : 87[3] -> 86[2] via P2P/CUMEM
24: nid005918:92506:101983 [2] NCCL INFO Channel 02/0 : 94[2] -> 98[2] [receive] via NET/AWS Libfabric/2
10: nid005590:110711:120129 [1] NCCL INFO Channel 05/0 : 41[1] -> 40[0] via P2P/CUMEM
24: nid005918:92504:101984 [0] NCCL INFO Channel 06/0 : 96[0] -> 99[3] via P2P/CUMEM
21: nid005914:166785:176225 [1] NCCL INFO Channel 02/0 : 85[1] -> 84[0] via P2P/CUMEM
 9: nid005588:35938:45417 [3] NCCL INFO Channel 06/0 : 39[3] -> 38[2] via P2P/CUMEM
14: nid005600:217723:227297 [3] NCCL INFO Channel 05/0 : 59[3] -> 58[2] via P2P/CUMEM
29: nid005932:167682:177124 [2] NCCL INFO Channel 03/0 : 114[2] -> 118[2] [receive] via NET/AWS Libfabric/2
31: nid005937:256591:266040 [2] NCCL INFO Channel 04/0 : 126[2] -> 125[1] via P2P/CUMEM
20: nid005913:292682:9590 [1] NCCL INFO Channel 05/0 : 81[1] -> 80[0] via P2P/CUMEM
29: nid005932:167680:177125 [0] NCCL INFO Channel 06/0 : 116[0] -> 119[3] via P2P/CUMEM
24: nid005918:92506:101983 [2] NCCL INFO Channel 06/0 : 94[2] -> 98[2] [receive] via NET/AWS Libfabric/2
 6: nid005584:28286:37703 [1] NCCL INFO Channel 03/0 : 25[1] -> 24[0] via P2P/CUMEM
 7: nid005585:122006:131415 [1] NCCL INFO Channel 02/0 : 29[1] -> 28[0] via P2P/CUMEM
12: nid005594:53086:62592 [1] NCCL INFO Channel 03/0 : 49[1] -> 48[0] via P2P/CUMEM
 7: nid005585:122008:131414 [3] NCCL INFO Channel 06/0 : 31[3] -> 30[2] via P2P/CUMEM
 6: nid005584:28288:37705 [3] NCCL INFO Channel 07/0 : 27[3] -> 26[2] via P2P/CUMEM
24: nid005918:92505:101985 [1] NCCL INFO Channel 03/0 : 93[1] -> 97[1] [receive] via NET/AWS Libfabric/1
12: nid005594:53088:62590 [3] NCCL INFO Channel 07/0 : 51[3] -> 50[2] via P2P/CUMEM
13: nid005595:197884:207706 [1] NCCL INFO Channel 00/0 : 53[1] -> 52[0] via P2P/CUMEM
29: nid005932:167682:177124 [2] NCCL INFO Channel 07/0 : 114[2] -> 118[2] [receive] via NET/AWS Libfabric/2
29: nid005932:167681:177123 [1] NCCL INFO Channel 02/0 : 113[1] -> 117[1] [receive] via NET/AWS Libfabric/1
15: nid005601:210677:220226 [1] NCCL INFO Channel 02/0 : 61[1] -> 60[0] via P2P/CUMEM
17: nid005803:180734:190232 [2] NCCL INFO Channel 00/0 : 70[2] -> 69[1] via P2P/CUMEM
24: nid005918:92506:101983 [2] NCCL INFO Channel 03/0 : 98[2] -> 102[2] [send] via NET/AWS Libfabric/2
15: nid005601:210679:220227 [3] NCCL INFO Channel 06/0 : 63[3] -> 62[2] via P2P/CUMEM
13: nid005595:197886:207705 [3] NCCL INFO Channel 04/0 : 55[3] -> 54[2] via P2P/CUMEM
29: nid005932:167682:177124 [2] NCCL INFO Channel 02/0 : 118[2] -> 122[2] [send] via NET/AWS Libfabric/2
11: nid005591:191604:202325 [1] NCCL INFO Channel 06/0 : 45[1] -> 44[0] via P2P/CUMEM
29: nid005932:167681:177123 [1] NCCL INFO Channel 06/0 : 113[1] -> 117[1] [receive] via NET/AWS Libfabric/1
24: nid005918:92505:101985 [1] NCCL INFO Channel 07/0 : 93[1] -> 97[1] [receive] via NET/AWS Libfabric/1
 9: nid005588:35936:45416 [1] NCCL INFO Channel 04/0 : 37[1] -> 36[0] via P2P/CUMEM
 5: nid005582:196715:206700 [2] NCCL INFO Channel 00/0 : 22[2] -> 21[1] via P2P/CUMEM
 8: nid005586:68927:78425 [1] NCCL INFO Channel 03/0 : 33[1] -> 32[0] via P2P/CUMEM
24: nid005918:92506:101983 [2] NCCL INFO Channel 07/0 : 98[2] -> 102[2] [send] via NET/AWS Libfabric/2
16: nid005802:6298:15933 [1] NCCL INFO Channel 03/0 : 65[1] -> 64[0] via P2P/CUMEM
 5: nid005582:196714:206703 [1] NCCL INFO Channel 04/0 : 21[1] -> 20[0] via P2P/CUMEM
17: nid005803:180734:190232 [2] NCCL INFO Channel 04/0 : 70[2] -> 69[1] via P2P/CUMEM
29: nid005932:167682:177124 [2] NCCL INFO Channel 06/0 : 118[2] -> 122[2] [send] via NET/AWS Libfabric/2
24: nid005918:92505:101985 [1] NCCL INFO Channel 02/0 : 97[1] -> 101[1] [send] via NET/AWS Libfabric/1
18: nid005911:38866:48340 [2] NCCL INFO Channel 01/0 : 74[2] -> 73[1] via P2P/CUMEM
22: nid005915:274816:284264 [2] NCCL INFO Channel 01/0 : 90[2] -> 89[1] via P2P/CUMEM
29: nid005932:167681:177123 [1] NCCL INFO Channel 03/0 : 117[1] -> 121[1] [send] via NET/AWS Libfabric/1
16: nid005802:6300:15935 [3] NCCL INFO Channel 07/0 : 67[3] -> 66[2] via P2P/CUMEM
 8: nid005586:68929:78424 [3] NCCL INFO Channel 07/0 : 35[3] -> 34[2] via P2P/CUMEM
24: nid005918:92504:101984 [0] NCCL INFO Channel 07/0 : 96[0] -> 99[3] via P2P/CUMEM
10: nid005590:110711:120129 [1] NCCL INFO Channel 07/0 : 41[1] -> 40[0] via P2P/CUMEM
29: nid005932:167681:177123 [1] NCCL INFO Channel 07/0 : 117[1] -> 121[1] [send] via NET/AWS Libfabric/1
24: nid005918:92505:101985 [1] NCCL INFO Channel 06/0 : 97[1] -> 101[1] [send] via NET/AWS Libfabric/1
19: nid005912:12436:21878 [1] NCCL INFO Channel 04/0 : 77[1] -> 76[0] via P2P/CUMEM
22: nid005915:274815:284266 [1] NCCL INFO Channel 05/0 : 89[1] -> 88[0] via P2P/CUMEM
29: nid005932:167680:177125 [0] NCCL INFO Channel 07/0 : 116[0] -> 119[3] via P2P/CUMEM
23: nid005917:276887:286376 [2] NCCL INFO Channel 03/0 : 94[2] -> 92[0] via P2P/CUMEM
18: nid005911:38866:48340 [2] NCCL INFO Channel 05/0 : 74[2] -> 73[1] via P2P/CUMEM
28: nid005929:16032:25507 [2] NCCL INFO Channel 02/0 : 114[2] -> 112[0] via P2P/CUMEM
24: nid005918:92506:101983 [2] NCCL INFO Channel 02/0 : 98[2] -> 96[0] via P2P/CUMEM
25: nid005919:107464:116967 [2] NCCL INFO Channel 03/0 : 102[2] -> 100[0] via P2P/CUMEM
22: nid005915:274816:284264 [2] NCCL INFO Channel 05/0 : 90[2] -> 89[1] via P2P/CUMEM
14: nid005600:217721:227295 [1] NCCL INFO Channel 03/0 : 57[1] -> 56[0] via P2P/CUMEM
20: nid005913:292682:9590 [1] NCCL INFO Channel 07/0 : 81[1] -> 80[0] via P2P/CUMEM
29: nid005932:167682:177124 [2] NCCL INFO Channel 03/0 : 118[2] -> 116[0] via P2P/CUMEM
 6: nid005584:28287:37702 [2] NCCL INFO Channel 01/0 : 26[2] -> 25[1] via P2P/CUMEM
 5: nid005582:196715:206700 [2] NCCL INFO Channel 04/0 : 22[2] -> 21[1] via P2P/CUMEM
21: nid005914:166785:176225 [1] NCCL INFO Channel 04/0 : 85[1] -> 84[0] via P2P/CUMEM
30: nid005936:49910:59381 [2] NCCL INFO Channel 02/0 : 122[2] -> 120[0] via P2P/CUMEM
 5: nid005582:196714:206703 [1] NCCL INFO Channel 06/0 : 21[1] -> 20[0] via P2P/CUMEM
14: nid005600:217723:227297 [3] NCCL INFO Channel 07/0 : 59[3] -> 58[2] via P2P/CUMEM
15: nid005601:210678:220225 [2] NCCL INFO Channel 00/0 : 62[2] -> 61[1] via P2P/CUMEM
22: nid005915:274815:284266 [1] NCCL INFO Channel 07/0 : 89[1] -> 88[0] via P2P/CUMEM
 7: nid005585:122007:131416 [2] NCCL INFO Channel 00/0 : 30[2] -> 29[1] via P2P/CUMEM
 6: nid005584:28286:37703 [1] NCCL INFO Channel 05/0 : 25[1] -> 24[0] via P2P/CUMEM
12: nid005594:53086:62592 [1] NCCL INFO Channel 05/0 : 49[1] -> 48[0] via P2P/CUMEM
 7: nid005585:122006:131415 [1] NCCL INFO Channel 04/0 : 29[1] -> 28[0] via P2P/CUMEM
28: nid005929:16032:25507 [2] NCCL INFO Channel 06/0 : 114[2] -> 112[0] via P2P/CUMEM
11: nid005591:191605:202322 [2] NCCL INFO Channel 00/0 : 46[2] -> 45[1] via P2P/CUMEM
10: nid005590:110712:120131 [2] NCCL INFO Channel 01/0 : 42[2] -> 41[1] via P2P/CUMEM
 9: nid005588:35937:45418 [2] NCCL INFO Channel 00/0 : 38[2] -> 37[1] via P2P/CUMEM
15: nid005601:210677:220226 [1] NCCL INFO Channel 04/0 : 61[1] -> 60[0] via P2P/CUMEM
13: nid005595:197884:207706 [1] NCCL INFO Channel 02/0 : 53[1] -> 52[0] via P2P/CUMEM
19: nid005912:12436:21878 [1] NCCL INFO Channel 06/0 : 77[1] -> 76[0] via P2P/CUMEM
 9: nid005588:35936:45416 [1] NCCL INFO Channel 06/0 : 37[1] -> 36[0] via P2P/CUMEM
23: nid005917:276887:286376 [2] NCCL INFO Channel 07/0 : 94[2] -> 92[0] via P2P/CUMEM
13: nid005595:197886:207705 [3] NCCL INFO Channel 06/0 : 55[3] -> 54[2] via P2P/CUMEM
16: nid005802:6299:15934 [2] NCCL INFO Channel 01/0 : 66[2] -> 65[1] via P2P/CUMEM
 8: nid005586:68927:78425 [1] NCCL INFO Channel 05/0 : 33[1] -> 32[0] via P2P/CUMEM
12: nid005594:53087:62589 [2] NCCL INFO Channel 01/0 : 50[2] -> 49[1] via P2P/CUMEM
16: nid005802:6298:15933 [1] NCCL INFO Channel 05/0 : 65[1] -> 64[0] via P2P/CUMEM
25: nid005919:107464:116967 [2] NCCL INFO Channel 07/0 : 102[2] -> 100[0] via P2P/CUMEM
11: nid005591:191605:202322 [2] NCCL INFO Channel 04/0 : 46[2] -> 45[1] via P2P/CUMEM
10: nid005590:110712:120131 [2] NCCL INFO Channel 05/0 : 42[2] -> 41[1] via P2P/CUMEM
 8: nid005586:68928:78423 [2] NCCL INFO Channel 01/0 : 34[2] -> 33[1] via P2P/CUMEM
 6: nid005584:28287:37702 [2] NCCL INFO Channel 05/0 : 26[2] -> 25[1] via P2P/CUMEM
21: nid005914:166785:176225 [1] NCCL INFO Channel 06/0 : 85[1] -> 84[0] via P2P/CUMEM
30: nid005936:49910:59381 [2] NCCL INFO Channel 06/0 : 122[2] -> 120[0] via P2P/CUMEM
 6: nid005584:28286:37703 [1] NCCL INFO Channel 07/0 : 25[1] -> 24[0] via P2P/CUMEM
15: nid005601:210678:220225 [2] NCCL INFO Channel 04/0 : 62[2] -> 61[1] via P2P/CUMEM
15: nid005601:210677:220226 [1] NCCL INFO Channel 06/0 : 61[1] -> 60[0] via P2P/CUMEM
 7: nid005585:122007:131416 [2] NCCL INFO Channel 04/0 : 30[2] -> 29[1] via P2P/CUMEM
 7: nid005585:122006:131415 [1] NCCL INFO Channel 06/0 : 29[1] -> 28[0] via P2P/CUMEM
12: nid005594:53086:62592 [1] NCCL INFO Channel 07/0 : 49[1] -> 48[0] via P2P/CUMEM
 9: nid005588:35937:45418 [2] NCCL INFO Channel 04/0 : 38[2] -> 37[1] via P2P/CUMEM
24: nid005918:92506:101983 [2] NCCL INFO Channel 06/0 : 98[2] -> 96[0] via P2P/CUMEM
12: nid005594:53087:62589 [2] NCCL INFO Channel 05/0 : 50[2] -> 49[1] via P2P/CUMEM
14: nid005600:217721:227295 [1] NCCL INFO Channel 05/0 : 57[1] -> 56[0] via P2P/CUMEM
16: nid005802:6299:15934 [2] NCCL INFO Channel 05/0 : 66[2] -> 65[1] via P2P/CUMEM
16: nid005802:6298:15933 [1] NCCL INFO Channel 07/0 : 65[1] -> 64[0] via P2P/CUMEM
 8: nid005586:68927:78425 [1] NCCL INFO Channel 07/0 : 33[1] -> 32[0] via P2P/CUMEM
 8: nid005586:68928:78423 [2] NCCL INFO Channel 05/0 : 34[2] -> 33[1] via P2P/CUMEM
14: nid005600:217722:227298 [2] NCCL INFO Channel 01/0 : 58[2] -> 57[1] via P2P/CUMEM
29: nid005932:167682:177124 [2] NCCL INFO Channel 07/0 : 118[2] -> 116[0] via P2P/CUMEM
13: nid005595:197884:207706 [1] NCCL INFO Channel 04/0 : 53[1] -> 52[0] via P2P/CUMEM
13: nid005595:197885:207704 [2] NCCL INFO Channel 00/0 : 54[2] -> 53[1] via P2P/CUMEM
19: nid005912:12437:21879 [2] NCCL INFO Channel 00/0 : 78[2] -> 77[1] via P2P/CUMEM
14: nid005600:217721:227295 [1] NCCL INFO Channel 07/0 : 57[1] -> 56[0] via P2P/CUMEM
24: nid005918:92507:101982 [3] NCCL INFO Channel 01/0 : 95[3] -> 99[3] [receive] via NET/AWS Libfabric/3
20: nid005913:292683:9593 [2] NCCL INFO Channel 01/0 : 82[2] -> 81[1] via P2P/CUMEM
21: nid005914:166786:176224 [2] NCCL INFO Channel 00/0 : 86[2] -> 85[1] via P2P/CUMEM
14: nid005600:217722:227298 [2] NCCL INFO Channel 05/0 : 58[2] -> 57[1] via P2P/CUMEM
24: nid005918:92504:101984 [0] NCCL INFO Channel 00/0 : 92[0] -> 96[0] [receive] via NET/AWS Libfabric/0
24: nid005918:92507:101982 [3] NCCL INFO Channel 05/0 : 95[3] -> 99[3] [receive] via NET/AWS Libfabric/3
19: nid005912:12437:21879 [2] NCCL INFO Channel 04/0 : 78[2] -> 77[1] via P2P/CUMEM
24: nid005918:92504:101984 [0] NCCL INFO Channel 04/0 : 92[0] -> 96[0] [receive] via NET/AWS Libfabric/0
24: nid005918:92507:101982 [3] NCCL INFO Channel 00/0 : 99[3] -> 103[3] [send] via NET/AWS Libfabric/3
21: nid005914:166786:176224 [2] NCCL INFO Channel 04/0 : 86[2] -> 85[1] via P2P/CUMEM
24: nid005918:92504:101984 [0] NCCL INFO Channel 01/0 : 96[0] -> 100[0] [send] via NET/AWS Libfabric/0
20: nid005913:292683:9593 [2] NCCL INFO Channel 05/0 : 82[2] -> 81[1] via P2P/CUMEM
24: nid005918:92507:101982 [3] NCCL INFO Channel 04/0 : 99[3] -> 103[3] [send] via NET/AWS Libfabric/3
13: nid005595:197884:207706 [1] NCCL INFO Channel 06/0 : 53[1] -> 52[0] via P2P/CUMEM
13: nid005595:197885:207704 [2] NCCL INFO Channel 04/0 : 54[2] -> 53[1] via P2P/CUMEM
24: nid005918:92504:101984 [0] NCCL INFO Channel 05/0 : 96[0] -> 100[0] [send] via NET/AWS Libfabric/0
23: nid005917:276888:286374 [3] NCCL INFO Channel 03/0 : 95[3] -> 93[1] via P2P/CUMEM
29: nid005932:167683:177122 [3] NCCL INFO Channel 00/0 : 115[3] -> 119[3] [receive] via NET/AWS Libfabric/3
29: nid005932:167680:177125 [0] NCCL INFO Channel 01/0 : 112[0] -> 116[0] [receive] via NET/AWS Libfabric/0
24: nid005918:92507:101982 [3] NCCL INFO Channel 02/0 : 99[3] -> 97[1] via P2P/CUMEM
29: nid005932:167683:177122 [3] NCCL INFO Channel 04/0 : 115[3] -> 119[3] [receive] via NET/AWS Libfabric/3
25: nid005919:107465:116968 [3] NCCL INFO Channel 03/0 : 103[3] -> 101[1] via P2P/CUMEM
29: nid005932:167680:177125 [0] NCCL INFO Channel 05/0 : 112[0] -> 116[0] [receive] via NET/AWS Libfabric/0
29: nid005932:167683:177122 [3] NCCL INFO Channel 01/0 : 119[3] -> 123[3] [send] via NET/AWS Libfabric/3
29: nid005932:167680:177125 [0] NCCL INFO Channel 00/0 : 116[0] -> 120[0] [send] via NET/AWS Libfabric/0
29: nid005932:167680:177125 [0] NCCL INFO Channel 04/0 : 116[0] -> 120[0] [send] via NET/AWS Libfabric/0
29: nid005932:167683:177122 [3] NCCL INFO Channel 05/0 : 119[3] -> 123[3] [send] via NET/AWS Libfabric/3
23: nid005917:276888:286374 [3] NCCL INFO Channel 07/0 : 95[3] -> 93[1] via P2P/CUMEM
25: nid005919:107465:116968 [3] NCCL INFO Channel 07/0 : 103[3] -> 101[1] via P2P/CUMEM
24: nid005918:92507:101982 [3] NCCL INFO Channel 06/0 : 99[3] -> 97[1] via P2P/CUMEM
28: nid005929:16033:25508 [3] NCCL INFO Channel 02/0 : 115[3] -> 113[1] via P2P/CUMEM
29: nid005932:167683:177122 [3] NCCL INFO Channel 03/0 : 119[3] -> 117[1] via P2P/CUMEM
30: nid005936:49911:59379 [3] NCCL INFO Channel 02/0 : 123[3] -> 121[1] via P2P/CUMEM
28: nid005929:16033:25508 [3] NCCL INFO Channel 06/0 : 115[3] -> 113[1] via P2P/CUMEM
23: nid005917:276888:286374 [3] NCCL INFO Channel 00/0 : 95[3] -> 94[2] via P2P/CUMEM
25: nid005919:107465:116968 [3] NCCL INFO Channel 00/0 : 103[3] -> 102[2] via P2P/CUMEM
29: nid005932:167683:177122 [3] NCCL INFO Channel 07/0 : 119[3] -> 117[1] via P2P/CUMEM
24: nid005918:92507:101982 [3] NCCL INFO Channel 01/0 : 99[3] -> 98[2] via P2P/CUMEM
30: nid005936:49911:59379 [3] NCCL INFO Channel 06/0 : 123[3] -> 121[1] via P2P/CUMEM
28: nid005929:16033:25508 [3] NCCL INFO Channel 01/0 : 115[3] -> 114[2] via P2P/CUMEM
29: nid005932:167683:177122 [3] NCCL INFO Channel 00/0 : 119[3] -> 118[2] via P2P/CUMEM
25: nid005919:107465:116968 [3] NCCL INFO Channel 02/0 : 103[3] -> 102[2] via P2P/CUMEM
23: nid005917:276888:286374 [3] NCCL INFO Channel 02/0 : 95[3] -> 94[2] via P2P/CUMEM
30: nid005936:49911:59379 [3] NCCL INFO Channel 01/0 : 123[3] -> 122[2] via P2P/CUMEM
24: nid005918:92507:101982 [3] NCCL INFO Channel 03/0 : 99[3] -> 98[2] via P2P/CUMEM
28: nid005929:16033:25508 [3] NCCL INFO Channel 03/0 : 115[3] -> 114[2] via P2P/CUMEM
25: nid005919:107463:116969 [1] NCCL INFO Channel 00/0 : 101[1] -> 100[0] via P2P/CUMEM
23: nid005917:276888:286374 [3] NCCL INFO Channel 04/0 : 95[3] -> 94[2] via P2P/CUMEM
25: nid005919:107465:116968 [3] NCCL INFO Channel 04/0 : 103[3] -> 102[2] via P2P/CUMEM
23: nid005917:276886:286373 [1] NCCL INFO Channel 00/0 : 93[1] -> 92[0] via P2P/CUMEM
30: nid005936:49911:59379 [3] NCCL INFO Channel 03/0 : 123[3] -> 122[2] via P2P/CUMEM
29: nid005932:167683:177122 [3] NCCL INFO Channel 02/0 : 119[3] -> 118[2] via P2P/CUMEM
28: nid005929:16033:25508 [3] NCCL INFO Channel 05/0 : 115[3] -> 114[2] via P2P/CUMEM
24: nid005918:92505:101985 [1] NCCL INFO Channel 01/0 : 97[1] -> 96[0] via P2P/CUMEM
24: nid005918:92507:101982 [3] NCCL INFO Channel 05/0 : 99[3] -> 98[2] via P2P/CUMEM
28: nid005929:16031:25509 [1] NCCL INFO Channel 01/0 : 113[1] -> 112[0] via P2P/CUMEM
25: nid005919:107463:116969 [1] NCCL INFO Channel 02/0 : 101[1] -> 100[0] via P2P/CUMEM
25: nid005919:107465:116968 [3] NCCL INFO Channel 06/0 : 103[3] -> 102[2] via P2P/CUMEM
23: nid005917:276888:286374 [3] NCCL INFO Channel 06/0 : 95[3] -> 94[2] via P2P/CUMEM
23: nid005917:276886:286373 [1] NCCL INFO Channel 02/0 : 93[1] -> 92[0] via P2P/CUMEM
30: nid005936:49909:59380 [1] NCCL INFO Channel 01/0 : 121[1] -> 120[0] via P2P/CUMEM
30: nid005936:49911:59379 [3] NCCL INFO Channel 05/0 : 123[3] -> 122[2] via P2P/CUMEM
28: nid005929:16033:25508 [3] NCCL INFO Channel 07/0 : 115[3] -> 114[2] via P2P/CUMEM
29: nid005932:167681:177123 [1] NCCL INFO Channel 00/0 : 117[1] -> 116[0] via P2P/CUMEM
29: nid005932:167683:177122 [3] NCCL INFO Channel 04/0 : 119[3] -> 118[2] via P2P/CUMEM
24: nid005918:92505:101985 [1] NCCL INFO Channel 03/0 : 97[1] -> 96[0] via P2P/CUMEM
24: nid005918:92507:101982 [3] NCCL INFO Channel 07/0 : 99[3] -> 98[2] via P2P/CUMEM
28: nid005929:16031:25509 [1] NCCL INFO Channel 03/0 : 113[1] -> 112[0] via P2P/CUMEM
25: nid005919:107464:116967 [2] NCCL INFO Channel 00/0 : 102[2] -> 101[1] via P2P/CUMEM
25: nid005919:107463:116969 [1] NCCL INFO Channel 04/0 : 101[1] -> 100[0] via P2P/CUMEM
23: nid005917:276887:286376 [2] NCCL INFO Channel 00/0 : 94[2] -> 93[1] via P2P/CUMEM
23: nid005917:276886:286373 [1] NCCL INFO Channel 04/0 : 93[1] -> 92[0] via P2P/CUMEM
30: nid005936:49909:59380 [1] NCCL INFO Channel 03/0 : 121[1] -> 120[0] via P2P/CUMEM
30: nid005936:49911:59379 [3] NCCL INFO Channel 07/0 : 123[3] -> 122[2] via P2P/CUMEM
25: nid005919:107464:116967 [2] NCCL INFO Channel 04/0 : 102[2] -> 101[1] via P2P/CUMEM
25: nid005919:107463:116969 [1] NCCL INFO Channel 06/0 : 101[1] -> 100[0] via P2P/CUMEM
23: nid005917:276887:286376 [2] NCCL INFO Channel 04/0 : 94[2] -> 93[1] via P2P/CUMEM
23: nid005917:276886:286373 [1] NCCL INFO Channel 06/0 : 93[1] -> 92[0] via P2P/CUMEM
28: nid005929:16032:25507 [2] NCCL INFO Channel 01/0 : 114[2] -> 113[1] via P2P/CUMEM
28: nid005929:16031:25509 [1] NCCL INFO Channel 05/0 : 113[1] -> 112[0] via P2P/CUMEM
29: nid005932:167681:177123 [1] NCCL INFO Channel 02/0 : 117[1] -> 116[0] via P2P/CUMEM
29: nid005932:167683:177122 [3] NCCL INFO Channel 06/0 : 119[3] -> 118[2] via P2P/CUMEM
24: nid005918:92506:101983 [2] NCCL INFO Channel 01/0 : 98[2] -> 97[1] via P2P/CUMEM
24: nid005918:92505:101985 [1] NCCL INFO Channel 05/0 : 97[1] -> 96[0] via P2P/CUMEM
30: nid005936:49909:59380 [1] NCCL INFO Channel 05/0 : 121[1] -> 120[0] via P2P/CUMEM
28: nid005929:16032:25507 [2] NCCL INFO Channel 05/0 : 114[2] -> 113[1] via P2P/CUMEM
28: nid005929:16031:25509 [1] NCCL INFO Channel 07/0 : 113[1] -> 112[0] via P2P/CUMEM
30: nid005936:49910:59381 [2] NCCL INFO Channel 01/0 : 122[2] -> 121[1] via P2P/CUMEM
30: nid005936:49909:59380 [1] NCCL INFO Channel 07/0 : 121[1] -> 120[0] via P2P/CUMEM
24: nid005918:92506:101983 [2] NCCL INFO Channel 05/0 : 98[2] -> 97[1] via P2P/CUMEM
24: nid005918:92505:101985 [1] NCCL INFO Channel 07/0 : 97[1] -> 96[0] via P2P/CUMEM
30: nid005936:49910:59381 [2] NCCL INFO Channel 05/0 : 122[2] -> 121[1] via P2P/CUMEM
29: nid005932:167682:177124 [2] NCCL INFO Channel 00/0 : 118[2] -> 117[1] via P2P/CUMEM
29: nid005932:167681:177123 [1] NCCL INFO Channel 04/0 : 117[1] -> 116[0] via P2P/CUMEM
29: nid005932:167682:177124 [2] NCCL INFO Channel 04/0 : 118[2] -> 117[1] via P2P/CUMEM
29: nid005932:167681:177123 [1] NCCL INFO Channel 06/0 : 117[1] -> 116[0] via P2P/CUMEM
11: nid005591:191603:202323 [0] NCCL INFO Connected all rings
11: nid005591:191604:202325 [1] NCCL INFO Connected all rings
11: nid005591:191606:202324 [3] NCCL INFO Connected all rings
11: nid005591:191605:202322 [2] NCCL INFO Connected all rings
 4: nid005581:264523:273969 [0] NCCL INFO Connected all rings
 4: nid005581:264526:273970 [3] NCCL INFO Connected all rings
 4: nid005581:264524:273971 [1] NCCL INFO Connected all rings
 4: nid005581:264525:273968 [2] NCCL INFO Connected all rings
17: nid005803:180732:190233 [0] NCCL INFO Connected all rings
17: nid005803:180733:190230 [1] NCCL INFO Connected all rings
17: nid005803:180735:190231 [3] NCCL INFO Connected all rings
17: nid005803:180734:190232 [2] NCCL INFO Connected all rings
 3: nid005580:71820:81305 [1] NCCL INFO Connected all rings
 3: nid005580:71819:81307 [0] NCCL INFO Connected all rings
 3: nid005580:71822:81308 [3] NCCL INFO Connected all rings
 2: nid005577:17422:26964 [0] NCCL INFO Connected all rings
 3: nid005580:71821:81306 [2] NCCL INFO Connected all rings
 2: nid005577:17423:26961 [1] NCCL INFO Connected all rings
 2: nid005577:17425:26962 [3] NCCL INFO Connected all rings
 2: nid005577:17424:26963 [2] NCCL INFO Connected all rings
26: nid005920:67123:76600 [0] NCCL INFO Connected all rings
26: nid005920:67124:76603 [1] NCCL INFO Connected all rings
26: nid005920:67126:76602 [3] NCCL INFO Connected all rings
26: nid005920:67125:76601 [2] NCCL INFO Connected all rings
16: nid005802:6297:15936 [0] NCCL INFO Connected all rings
16: nid005802:6298:15933 [1] NCCL INFO Connected all rings
16: nid005802:6300:15935 [3] NCCL INFO Connected all rings
16: nid005802:6299:15934 [2] NCCL INFO Connected all rings
 7: nid005585:122005:131417 [0] NCCL INFO Connected all rings
 7: nid005585:122008:131414 [3] NCCL INFO Connected all rings
 5: nid005582:196716:206702 [3] NCCL INFO Connected all rings
 6: nid005584:28285:37704 [0] NCCL INFO Connected all rings
 7: nid005585:122007:131416 [2] NCCL INFO Connected all rings
 7: nid005585:122006:131415 [1] NCCL INFO Connected all rings
 6: nid005584:28288:37705 [3] NCCL INFO Connected all rings
 5: nid005582:196713:206701 [0] NCCL INFO Connected all rings
 5: nid005582:196715:206700 [2] NCCL INFO Connected all rings
 6: nid005584:28286:37703 [1] NCCL INFO Connected all rings
 6: nid005584:28287:37702 [2] NCCL INFO Connected all rings
 5: nid005582:196714:206703 [1] NCCL INFO Connected all rings
10: nid005590:110710:120132 [0] NCCL INFO Connected all rings
 9: nid005588:35938:45417 [3] NCCL INFO Connected all rings
10: nid005590:110711:120129 [1] NCCL INFO Connected all rings
 9: nid005588:35935:45419 [0] NCCL INFO Connected all rings
 8: nid005586:68926:78422 [0] NCCL INFO Connected all rings
 8: nid005586:68929:78424 [3] NCCL INFO Connected all rings
 9: nid005588:35937:45418 [2] NCCL INFO Connected all rings
 8: nid005586:68928:78423 [2] NCCL INFO Connected all rings
 8: nid005586:68927:78425 [1] NCCL INFO Connected all rings
 9: nid005588:35936:45416 [1] NCCL INFO Connected all rings
10: nid005590:110712:120131 [2] NCCL INFO Connected all rings
10: nid005590:110713:120130 [3] NCCL INFO Connected all rings
12: nid005594:53085:62591 [0] NCCL INFO Connected all rings
12: nid005594:53088:62590 [3] NCCL INFO Connected all rings
12: nid005594:53087:62589 [2] NCCL INFO Connected all rings
12: nid005594:53086:62592 [1] NCCL INFO Connected all rings
15: nid005601:210679:220227 [3] NCCL INFO Connected all rings
15: nid005601:210676:220224 [0] NCCL INFO Connected all rings
15: nid005601:210678:220225 [2] NCCL INFO Connected all rings
15: nid005601:210677:220226 [1] NCCL INFO Connected all rings
14: nid005600:217720:227296 [0] NCCL INFO Connected all rings
13: nid005595:197886:207705 [3] NCCL INFO Connected all rings
13: nid005595:197883:207703 [0] NCCL INFO Connected all rings
14: nid005600:217723:227297 [3] NCCL INFO Connected all rings
14: nid005600:217722:227298 [2] NCCL INFO Connected all rings
13: nid005595:197885:207704 [2] NCCL INFO Connected all rings
14: nid005600:217721:227295 [1] NCCL INFO Connected all rings
13: nid005595:197884:207706 [1] NCCL INFO Connected all rings
19: nid005912:12438:21877 [3] NCCL INFO Connected all rings
19: nid005912:12435:21880 [0] NCCL INFO Connected all rings
18: nid005911:38867:48339 [3] NCCL INFO Connected all rings
18: nid005911:38864:48341 [0] NCCL INFO Connected all rings
19: nid005912:12437:21879 [2] NCCL INFO Connected all rings
18: nid005911:38866:48340 [2] NCCL INFO Connected all rings
18: nid005911:38865:48338 [1] NCCL INFO Connected all rings
19: nid005912:12436:21878 [1] NCCL INFO Connected all rings
27: nid005922:80741:90179 [0] NCCL INFO Connected all rings
27: nid005922:80742:90176 [1] NCCL INFO Connected all rings
27: nid005922:80744:90178 [3] NCCL INFO Connected all rings
27: nid005922:80743:90177 [2] NCCL INFO Connected all rings
22: nid005915:274814:284265 [0] NCCL INFO Connected all rings
22: nid005915:274815:284266 [1] NCCL INFO Connected all rings
22: nid005915:274817:284263 [3] NCCL INFO Connected all rings
21: nid005914:166784:176223 [0] NCCL INFO Connected all rings
20: nid005913:292681:9594 [0] NCCL INFO Connected all rings
21: nid005914:166785:176225 [1] NCCL INFO Connected all rings
21: nid005914:166787:176226 [3] NCCL INFO Connected all rings
22: nid005915:274816:284264 [2] NCCL INFO Connected all rings
21: nid005914:166786:176224 [2] NCCL INFO Connected all rings
20: nid005913:292684:9592 [3] NCCL INFO Connected all rings
20: nid005913:292682:9590 [1] NCCL INFO Connected all rings
20: nid005913:292683:9593 [2] NCCL INFO Connected all rings
 1: nid005576:147557:156974 [0] NCCL INFO Connected all rings
 1: nid005576:147560:156972 [3] NCCL INFO Connected all rings
 1: nid005576:147558:156971 [1] NCCL INFO Connected all rings
 1: nid005576:147559:156973 [2] NCCL INFO Connected all rings
 0: nid005574:69061:78873 [3] NCCL INFO Connected all rings
 0: nid005574:69058:78874 [0] NCCL INFO Connected all rings
 0: nid005574:69060:78872 [2] NCCL INFO Connected all rings
 0: nid005574:69059:78871 [1] NCCL INFO Connected all rings
31: nid005937:256589:266041 [0] NCCL INFO Connected all rings
31: nid005937:256592:266042 [3] NCCL INFO Connected all rings
31: nid005937:256591:266040 [2] NCCL INFO Connected all rings
31: nid005937:256590:266043 [1] NCCL INFO Connected all rings
25: nid005919:107465:116968 [3] NCCL INFO Connected all rings
25: nid005919:107462:116966 [0] NCCL INFO Connected all rings
24: nid005918:92504:101984 [0] NCCL INFO Connected all rings
24: nid005918:92505:101985 [1] NCCL INFO Connected all rings
24: nid005918:92507:101982 [3] NCCL INFO Connected all rings
25: nid005919:107464:116967 [2] NCCL INFO Connected all rings
24: nid005918:92506:101983 [2] NCCL INFO Connected all rings
25: nid005919:107463:116969 [1] NCCL INFO Connected all rings
23: nid005917:276888:286374 [3] NCCL INFO Connected all rings
23: nid005917:276885:286375 [0] NCCL INFO Connected all rings
23: nid005917:276887:286376 [2] NCCL INFO Connected all rings
23: nid005917:276886:286373 [1] NCCL INFO Connected all rings
29: nid005932:167680:177125 [0] NCCL INFO Connected all rings
28: nid005929:16030:25510 [0] NCCL INFO Connected all rings
29: nid005932:167681:177123 [1] NCCL INFO Connected all rings
29: nid005932:167683:177122 [3] NCCL INFO Connected all rings
28: nid005929:16031:25509 [1] NCCL INFO Connected all rings
29: nid005932:167682:177124 [2] NCCL INFO Connected all rings
28: nid005929:16033:25508 [3] NCCL INFO Connected all rings
28: nid005929:16032:25507 [2] NCCL INFO Connected all rings
30: nid005936:49908:59382 [0] NCCL INFO Connected all rings
30: nid005936:49911:59379 [3] NCCL INFO Connected all rings
30: nid005936:49909:59380 [1] NCCL INFO Connected all rings
30: nid005936:49910:59381 [2] NCCL INFO Connected all rings
29: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
29:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
29: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
29:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
17: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
17:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
30: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
30:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
25: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
25:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
 0:   0%|          | 0/4399 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
 0:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
18: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
18:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
 3: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
 3:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
22: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
22:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
16: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
16:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
10: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
10:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
10: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
10:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
 8: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
 8:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
30: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
30:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
 2: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
 2:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
 1: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
 1:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
18: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
18:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
22: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
22:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
28: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
28:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
26: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
26:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
31: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
31:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
21: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
21:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
17: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
17:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
12: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
12:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
 5: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
 5:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
13: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
13:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
14: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
14:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
12: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
12:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
 5: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
 5:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
 8: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
 8:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
11: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
11:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
 8: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
 8:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
21: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
21:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
11: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
11:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
28: nid005929:16030:25536 [0] NCCL INFO Channel 01/0 : 112[0] -> 113[1] via P2P/CUMEM
17: nid005803:180732:190254 [0] NCCL INFO Channel 00/0 : 68[0] -> 69[1] via P2P/CUMEM
28: nid005929:16030:25536 [0] NCCL INFO Channel 02/0 : 112[0] -> 113[1] via P2P/CUMEM
28: nid005929:16030:25536 [0] NCCL INFO Channel 03/0 : 112[0] -> 113[1] via P2P/CUMEM
17: nid005803:180732:190254 [0] NCCL INFO Channel 02/0 : 68[0] -> 69[1] via P2P/CUMEM
28: nid005929:16030:25536 [0] NCCL INFO Channel 05/0 : 112[0] -> 113[1] via P2P/CUMEM
27: nid005922:80741:90205 [0] NCCL INFO Channel 00/0 : 108[0] -> 109[1] via P2P/CUMEM
17: nid005803:180732:190254 [0] NCCL INFO Channel 03/0 : 68[0] -> 69[1] via P2P/CUMEM
28: nid005929:16030:25536 [0] NCCL INFO Channel 06/0 : 112[0] -> 113[1] via P2P/CUMEM
17: nid005803:180732:190254 [0] NCCL INFO Channel 04/0 : 68[0] -> 69[1] via P2P/CUMEM
28: nid005929:16030:25536 [0] NCCL INFO Channel 07/0 : 112[0] -> 113[1] via P2P/CUMEM
17: nid005803:180732:190254 [0] NCCL INFO Channel 06/0 : 68[0] -> 69[1] via P2P/CUMEM
27: nid005922:80741:90205 [0] NCCL INFO Channel 02/0 : 108[0] -> 109[1] via P2P/CUMEM
17: nid005803:180732:190254 [0] NCCL INFO Channel 07/0 : 68[0] -> 69[1] via P2P/CUMEM
 2: nid005577:17422:27010 [0] NCCL INFO Channel 01/0 : 8[0] -> 9[1] via P2P/CUMEM
 2: nid005577:17423:27009 [1] NCCL INFO Channel 01/0 : 9[1] -> 10[2] via P2P/CUMEM
 2: nid005577:17423:27009 [1] NCCL INFO Channel 05/0 : 9[1] -> 10[2] via P2P/CUMEM
27: nid005922:80741:90205 [0] NCCL INFO Channel 03/0 : 108[0] -> 109[1] via P2P/CUMEM
 3: nid005580:71819:81333 [0] NCCL INFO Channel 00/0 : 12[0] -> 13[1] via P2P/CUMEM
 2: nid005577:17422:27010 [0] NCCL INFO Channel 02/0 : 8[0] -> 9[1] via P2P/CUMEM
15: nid005601:210676:220272 [0] NCCL INFO Channel 00/0 : 60[0] -> 61[1] via P2P/CUMEM
27: nid005922:80743:90206 [2] NCCL INFO Channel 00/0 : 110[2] -> 111[3] via P2P/CUMEM
27: nid005922:80741:90205 [0] NCCL INFO Channel 04/0 : 108[0] -> 109[1] via P2P/CUMEM
28: nid005929:16032:25538 [2] NCCL INFO Channel 01/0 : 114[2] -> 115[3] via P2P/CUMEM
10: nid005590:110710:120158 [0] NCCL INFO Channel 01/0 : 40[0] -> 41[1] via P2P/CUMEM
 2: nid005577:17422:27010 [0] NCCL INFO Channel 03/0 : 8[0] -> 9[1] via P2P/CUMEM
28: nid005929:16032:25538 [2] NCCL INFO Channel 02/0 : 114[2] -> 115[3] via P2P/CUMEM
21: nid005914:166784:176252 [0] NCCL INFO Channel 00/0 : 84[0] -> 85[1] via P2P/CUMEM
15: nid005601:210676:220272 [0] NCCL INFO Channel 02/0 : 60[0] -> 61[1] via P2P/CUMEM
16: nid005802:6297:15957 [0] NCCL INFO Channel 01/0 : 64[0] -> 65[1] via P2P/CUMEM
28: nid005929:16032:25538 [2] NCCL INFO Channel 03/0 : 114[2] -> 115[3] via P2P/CUMEM
 0: nid005574:69058:78920 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM
 2: nid005577:17422:27010 [0] NCCL INFO Channel 05/0 : 8[0] -> 9[1] via P2P/CUMEM
15: nid005601:210676:220272 [0] NCCL INFO Channel 03/0 : 60[0] -> 61[1] via P2P/CUMEM
27: nid005922:80743:90206 [2] NCCL INFO Channel 02/0 : 110[2] -> 111[3] via P2P/CUMEM
28: nid005929:16032:25538 [2] NCCL INFO Channel 05/0 : 114[2] -> 115[3] via P2P/CUMEM
27: nid005922:80741:90205 [0] NCCL INFO Channel 06/0 : 108[0] -> 109[1] via P2P/CUMEM
15: nid005601:210676:220272 [0] NCCL INFO Channel 04/0 : 60[0] -> 61[1] via P2P/CUMEM
28: nid005929:16032:25538 [2] NCCL INFO Channel 06/0 : 114[2] -> 115[3] via P2P/CUMEM
 3: nid005580:71821:81332 [2] NCCL INFO Channel 00/0 : 14[2] -> 15[3] via P2P/CUMEM
 3: nid005580:71821:81332 [2] NCCL INFO Channel 02/0 : 14[2] -> 15[3] via P2P/CUMEM
21: nid005914:166786:176251 [2] NCCL INFO Channel 00/0 : 86[2] -> 87[3] via P2P/CUMEM
15: nid005601:210676:220272 [0] NCCL INFO Channel 06/0 : 60[0] -> 61[1] via P2P/CUMEM
10: nid005590:110710:120158 [0] NCCL INFO Channel 02/0 : 40[0] -> 41[1] via P2P/CUMEM
14: nid005600:217720:227327 [0] NCCL INFO Channel 01/0 : 56[0] -> 57[1] via P2P/CUMEM
21: nid005914:166784:176252 [0] NCCL INFO Channel 02/0 : 84[0] -> 85[1] via P2P/CUMEM
27: nid005922:80743:90206 [2] NCCL INFO Channel 03/0 : 110[2] -> 111[3] via P2P/CUMEM
28: nid005929:16032:25538 [2] NCCL INFO Channel 07/0 : 114[2] -> 115[3] via P2P/CUMEM
 2: nid005577:17422:27010 [0] NCCL INFO Channel 06/0 : 8[0] -> 9[1] via P2P/CUMEM
16: nid005802:6297:15957 [0] NCCL INFO Channel 02/0 : 64[0] -> 65[1] via P2P/CUMEM
20: nid005913:292681:9616 [0] NCCL INFO Channel 01/0 : 80[0] -> 81[1] via P2P/CUMEM
15: nid005601:210676:220272 [0] NCCL INFO Channel 07/0 : 60[0] -> 61[1] via P2P/CUMEM
26: nid005920:67123:76628 [0] NCCL INFO Channel 01/0 : 104[0] -> 105[1] via P2P/CUMEM
27: nid005922:80741:90205 [0] NCCL INFO Channel 07/0 : 108[0] -> 109[1] via P2P/CUMEM
 0: nid005574:69059:78919 [1] NCCL INFO Channel 01/0 : 1[1] -> 2[2] via P2P/CUMEM
 0: nid005574:69058:78920 [0] NCCL INFO Channel 02/0 : 0[0] -> 1[1] via P2P/CUMEM
16: nid005802:6297:15957 [0] NCCL INFO Channel 03/0 : 64[0] -> 65[1] via P2P/CUMEM
10: nid005590:110710:120158 [0] NCCL INFO Channel 03/0 : 40[0] -> 41[1] via P2P/CUMEM
21: nid005914:166786:176251 [2] NCCL INFO Channel 02/0 : 86[2] -> 87[3] via P2P/CUMEM
27: nid005922:80743:90206 [2] NCCL INFO Channel 04/0 : 110[2] -> 111[3] via P2P/CUMEM
21: nid005914:166784:176252 [0] NCCL INFO Channel 03/0 : 84[0] -> 85[1] via P2P/CUMEM
 2: nid005577:17422:27010 [0] NCCL INFO Channel 07/0 : 8[0] -> 9[1] via P2P/CUMEM
16: nid005802:6297:15957 [0] NCCL INFO Channel 05/0 : 64[0] -> 65[1] via P2P/CUMEM
19: nid005912:12435:21904 [0] NCCL INFO Channel 00/0 : 76[0] -> 77[1] via P2P/CUMEM
19: nid005912:12437:21903 [2] NCCL INFO Channel 00/0 : 78[2] -> 79[3] via P2P/CUMEM
10: nid005590:110710:120158 [0] NCCL INFO Channel 05/0 : 40[0] -> 41[1] via P2P/CUMEM
 0: nid005574:69059:78919 [1] NCCL INFO Channel 05/0 : 1[1] -> 2[2] via P2P/CUMEM
27: nid005922:80743:90206 [2] NCCL INFO Channel 06/0 : 110[2] -> 111[3] via P2P/CUMEM
 0: nid005574:69058:78920 [0] NCCL INFO Channel 03/0 : 0[0] -> 1[1] via P2P/CUMEM
16: nid005802:6297:15957 [0] NCCL INFO Channel 06/0 : 64[0] -> 65[1] via P2P/CUMEM
12: nid005594:53085:62618 [0] NCCL INFO Channel 01/0 : 48[0] -> 49[1] via P2P/CUMEM
23: nid005917:276885:286402 [0] NCCL INFO Channel 00/0 : 92[0] -> 93[1] via P2P/CUMEM
26: nid005920:67123:76628 [0] NCCL INFO Channel 02/0 : 104[0] -> 105[1] via P2P/CUMEM
27: nid005922:80743:90206 [2] NCCL INFO Channel 07/0 : 110[2] -> 111[3] via P2P/CUMEM
10: nid005590:110710:120158 [0] NCCL INFO Channel 06/0 : 40[0] -> 41[1] via P2P/CUMEM
16: nid005802:6297:15957 [0] NCCL INFO Channel 07/0 : 64[0] -> 65[1] via P2P/CUMEM
 0: nid005574:69058:78920 [0] NCCL INFO Channel 05/0 : 0[0] -> 1[1] via P2P/CUMEM
 5: nid005582:196713:206729 [0] NCCL INFO Channel 00/0 : 20[0] -> 21[1] via P2P/CUMEM
21: nid005914:166786:176251 [2] NCCL INFO Channel 03/0 : 86[2] -> 87[3] via P2P/CUMEM
26: nid005920:67123:76628 [0] NCCL INFO Channel 03/0 : 104[0] -> 105[1] via P2P/CUMEM
19: nid005912:12437:21903 [2] NCCL INFO Channel 02/0 : 78[2] -> 79[3] via P2P/CUMEM
21: nid005914:166784:176252 [0] NCCL INFO Channel 04/0 : 84[0] -> 85[1] via P2P/CUMEM
 0: nid005574:69058:78920 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM
26: nid005920:67123:76628 [0] NCCL INFO Channel 05/0 : 104[0] -> 105[1] via P2P/CUMEM
10: nid005590:110710:120158 [0] NCCL INFO Channel 07/0 : 40[0] -> 41[1] via P2P/CUMEM
 2: nid005577:17422:27010 [0] NCCL INFO Channel 01/0 : 4[0] -> 8[0] [receive] via NET/AWS Libfabric/0
17: nid005803:180733:190255 [1] NCCL INFO Channel 00/0 : 69[1] -> 70[2] via P2P/CUMEM
20: nid005913:292681:9616 [0] NCCL INFO Channel 02/0 : 80[0] -> 81[1] via P2P/CUMEM
 0: nid005574:69058:78920 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM
 1: nid005576:147559:157018 [2] NCCL INFO Channel 00/0 : 6[2] -> 7[3] via P2P/CUMEM
26: nid005920:67123:76628 [0] NCCL INFO Channel 06/0 : 104[0] -> 105[1] via P2P/CUMEM
 2: nid005577:17422:27010 [0] NCCL INFO Channel 05/0 : 4[0] -> 8[0] [receive] via NET/AWS Libfabric/0
 2: nid005577:17424:27012 [2] NCCL INFO Channel 01/0 : 10[2] -> 11[3] via P2P/CUMEM
12: nid005594:53085:62618 [0] NCCL INFO Channel 02/0 : 48[0] -> 49[1] via P2P/CUMEM
 1: nid005576:147559:157018 [2] NCCL INFO Channel 02/0 : 6[2] -> 7[3] via P2P/CUMEM
27: nid005922:80744:90204 [3] NCCL INFO Channel 02/0 : 111[3] -> 108[0] via P2P/CUMEM
 2: nid005577:17422:27010 [0] NCCL INFO Channel 00/0 : 8[0] -> 12[0] [send] via NET/AWS Libfabric/0
21: nid005914:166786:176251 [2] NCCL INFO Channel 04/0 : 86[2] -> 87[3] via P2P/CUMEM
26: nid005920:67123:76628 [0] NCCL INFO Channel 07/0 : 104[0] -> 105[1] via P2P/CUMEM
23: nid005917:276885:286402 [0] NCCL INFO Channel 02/0 : 92[0] -> 93[1] via P2P/CUMEM
21: nid005914:166784:176252 [0] NCCL INFO Channel 06/0 : 84[0] -> 85[1] via P2P/CUMEM
23: nid005917:276887:286401 [2] NCCL INFO Channel 00/0 : 94[2] -> 95[3] via P2P/CUMEM
 2: nid005577:17424:27012 [2] NCCL INFO Channel 02/0 : 10[2] -> 11[3] via P2P/CUMEM
 1: nid005576:147559:157018 [2] NCCL INFO Channel 03/0 : 6[2] -> 7[3] via P2P/CUMEM
17: nid005803:180733:190255 [1] NCCL INFO Channel 04/0 : 69[1] -> 70[2] via P2P/CUMEM
19: nid005912:12435:21904 [0] NCCL INFO Channel 02/0 : 76[0] -> 77[1] via P2P/CUMEM
 5: nid005582:196714:206728 [1] NCCL INFO Channel 00/0 : 21[1] -> 22[2] via P2P/CUMEM
12: nid005594:53085:62618 [0] NCCL INFO Channel 03/0 : 48[0] -> 49[1] via P2P/CUMEM
19: nid005912:12437:21903 [2] NCCL INFO Channel 03/0 : 78[2] -> 79[3] via P2P/CUMEM
 2: nid005577:17424:27012 [2] NCCL INFO Channel 03/0 : 10[2] -> 11[3] via P2P/CUMEM
 1: nid005576:147559:157018 [2] NCCL INFO Channel 04/0 : 6[2] -> 7[3] via P2P/CUMEM
14: nid005600:217721:227326 [1] NCCL INFO Channel 01/0 : 57[1] -> 58[2] via P2P/CUMEM
 0: nid005574:69058:78920 [0] NCCL INFO Channel 04/0 : 0[0] -> 4[0] [send] via NET/AWS Libfabric/0
27: nid005922:80744:90204 [3] NCCL INFO Channel 03/0 : 111[3] -> 108[0] via P2P/CUMEM
31: nid005937:256589:266070 [0] NCCL INFO Channel 00/0 : 124[0] -> 125[1] via P2P/CUMEM
 4: nid005581:264523:274015 [0] NCCL INFO Channel 01/0 : 16[0] -> 17[1] via P2P/CUMEM
 5: nid005582:196713:206729 [0] NCCL INFO Channel 02/0 : 20[0] -> 21[1] via P2P/CUMEM
 2: nid005577:17424:27012 [2] NCCL INFO Channel 05/0 : 10[2] -> 11[3] via P2P/CUMEM
12: nid005594:53085:62618 [0] NCCL INFO Channel 05/0 : 48[0] -> 49[1] via P2P/CUMEM
 1: nid005576:147559:157018 [2] NCCL INFO Channel 06/0 : 6[2] -> 7[3] via P2P/CUMEM
21: nid005914:166786:176251 [2] NCCL INFO Channel 06/0 : 86[2] -> 87[3] via P2P/CUMEM
21: nid005914:166784:176252 [0] NCCL INFO Channel 07/0 : 84[0] -> 85[1] via P2P/CUMEM
14: nid005600:217722:227328 [2] NCCL INFO Channel 01/0 : 58[2] -> 59[3] via P2P/CUMEM
14: nid005600:217721:227326 [1] NCCL INFO Channel 05/0 : 57[1] -> 58[2] via P2P/CUMEM
23: nid005917:276885:286402 [0] NCCL INFO Channel 03/0 : 92[0] -> 93[1] via P2P/CUMEM
 2: nid005577:17424:27012 [2] NCCL INFO Channel 06/0 : 10[2] -> 11[3] via P2P/CUMEM
19: nid005912:12436:21902 [1] NCCL INFO Channel 00/0 : 77[1] -> 78[2] via P2P/CUMEM
23: nid005917:276887:286401 [2] NCCL INFO Channel 02/0 : 94[2] -> 95[3] via P2P/CUMEM
17: nid005803:180732:190254 [0] NCCL INFO Channel 04/0 : 64[0] -> 68[0] [receive] via NET/AWS Libfabric/0
20: nid005913:292681:9616 [0] NCCL INFO Channel 03/0 : 80[0] -> 81[1] via P2P/CUMEM
 5: nid005582:196714:206728 [1] NCCL INFO Channel 04/0 : 21[1] -> 22[2] via P2P/CUMEM
27: nid005922:80744:90204 [3] NCCL INFO Channel 06/0 : 111[3] -> 108[0] via P2P/CUMEM
12: nid005594:53085:62618 [0] NCCL INFO Channel 06/0 : 48[0] -> 49[1] via P2P/CUMEM
17: nid005803:180732:190254 [0] NCCL INFO Channel 01/0 : 68[0] -> 72[0] [send] via NET/AWS Libfabric/0
 2: nid005577:17424:27012 [2] NCCL INFO Channel 07/0 : 10[2] -> 11[3] via P2P/CUMEM
 1: nid005576:147557:157020 [0] NCCL INFO Channel 00/0 : 4[0] -> 5[1] via P2P/CUMEM
 1: nid005576:147559:157018 [2] NCCL INFO Channel 07/0 : 6[2] -> 7[3] via P2P/CUMEM
19: nid005912:12435:21904 [0] NCCL INFO Channel 03/0 : 76[0] -> 77[1] via P2P/CUMEM
17: nid005803:180732:190254 [0] NCCL INFO Channel 05/0 : 68[0] -> 72[0] [send] via NET/AWS Libfabric/0
12: nid005594:53085:62618 [0] NCCL INFO Channel 07/0 : 48[0] -> 49[1] via P2P/CUMEM
21: nid005914:166786:176251 [2] NCCL INFO Channel 07/0 : 86[2] -> 87[3] via P2P/CUMEM
19: nid005912:12437:21903 [2] NCCL INFO Channel 04/0 : 78[2] -> 79[3] via P2P/CUMEM
31: nid005937:256589:266070 [0] NCCL INFO Channel 02/0 : 124[0] -> 125[1] via P2P/CUMEM
30: nid005936:49908:59406 [0] NCCL INFO Channel 01/0 : 120[0] -> 121[1] via P2P/CUMEM
13: nid005595:197885:207750 [2] NCCL INFO Channel 00/0 : 54[2] -> 55[3] via P2P/CUMEM
27: nid005922:80744:90204 [3] NCCL INFO Channel 07/0 : 111[3] -> 108[0] via P2P/CUMEM
22: nid005915:274814:284312 [0] NCCL INFO Channel 01/0 : 88[0] -> 89[1] via P2P/CUMEM
 4: nid005581:264523:274015 [0] NCCL INFO Channel 02/0 : 16[0] -> 17[1] via P2P/CUMEM
31: nid005937:256589:266070 [0] NCCL INFO Channel 03/0 : 124[0] -> 125[1] via P2P/CUMEM
18: nid005911:38864:48384 [0] NCCL INFO Channel 01/0 : 72[0] -> 73[1] via P2P/CUMEM
23: nid005917:276885:286402 [0] NCCL INFO Channel 04/0 : 92[0] -> 93[1] via P2P/CUMEM
 5: nid005582:196713:206729 [0] NCCL INFO Channel 03/0 : 20[0] -> 21[1] via P2P/CUMEM
 2: nid005577:17425:27011 [3] NCCL INFO Channel 02/0 : 11[3] -> 8[0] via P2P/CUMEM
17: nid005803:180734:190257 [2] NCCL INFO Channel 00/0 : 70[2] -> 71[3] via P2P/CUMEM
19: nid005912:12436:21902 [1] NCCL INFO Channel 04/0 : 77[1] -> 78[2] via P2P/CUMEM
20: nid005913:292681:9616 [0] NCCL INFO Channel 05/0 : 80[0] -> 81[1] via P2P/CUMEM
22: nid005915:274816:284311 [2] NCCL INFO Channel 01/0 : 90[2] -> 91[3] via P2P/CUMEM
31: nid005937:256589:266070 [0] NCCL INFO Channel 04/0 : 124[0] -> 125[1] via P2P/CUMEM
 4: nid005581:264525:274016 [2] NCCL INFO Channel 01/0 : 18[2] -> 19[3] via P2P/CUMEM
13: nid005595:197885:207750 [2] NCCL INFO Channel 02/0 : 54[2] -> 55[3] via P2P/CUMEM
10: nid005590:110712:120160 [2] NCCL INFO Channel 01/0 : 42[2] -> 43[3] via P2P/CUMEM
 4: nid005581:264523:274015 [0] NCCL INFO Channel 03/0 : 16[0] -> 17[1] via P2P/CUMEM
23: nid005917:276887:286401 [2] NCCL INFO Channel 03/0 : 94[2] -> 95[3] via P2P/CUMEM
17: nid005803:180734:190257 [2] NCCL INFO Channel 02/0 : 70[2] -> 71[3] via P2P/CUMEM
 2: nid005577:17424:27012 [2] NCCL INFO Channel 03/0 : 6[2] -> 10[2] [receive] via NET/AWS Libfabric/2
19: nid005912:12437:21903 [2] NCCL INFO Channel 06/0 : 78[2] -> 79[3] via P2P/CUMEM
20: nid005913:292683:9619 [2] NCCL INFO Channel 01/0 : 82[2] -> 83[3] via P2P/CUMEM
31: nid005937:256589:266070 [0] NCCL INFO Channel 06/0 : 124[0] -> 125[1] via P2P/CUMEM
 2: nid005577:17424:27012 [2] NCCL INFO Channel 07/0 : 6[2] -> 10[2] [receive] via NET/AWS Libfabric/2
 2: nid005577:17425:27011 [3] NCCL INFO Channel 03/0 : 11[3] -> 8[0] via P2P/CUMEM
 4: nid005581:264525:274016 [2] NCCL INFO Channel 02/0 : 18[2] -> 19[3] via P2P/CUMEM
17: nid005803:180734:190257 [2] NCCL INFO Channel 03/0 : 70[2] -> 71[3] via P2P/CUMEM
27: nid005922:80742:90207 [1] NCCL INFO Channel 00/0 : 109[1] -> 110[2] via P2P/CUMEM
19: nid005912:12435:21904 [0] NCCL INFO Channel 04/0 : 76[0] -> 77[1] via P2P/CUMEM
 2: nid005577:17424:27012 [2] NCCL INFO Channel 02/0 : 10[2] -> 14[2] [send] via NET/AWS Libfabric/2
 0: nid005574:69060:78921 [2] NCCL INFO Channel 01/0 : 2[2] -> 3[3] via P2P/CUMEM
13: nid005595:197885:207750 [2] NCCL INFO Channel 03/0 : 54[2] -> 55[3] via P2P/CUMEM
 5: nid005582:196713:206729 [0] NCCL INFO Channel 04/0 : 20[0] -> 21[1] via P2P/CUMEM
31: nid005937:256589:266070 [0] NCCL INFO Channel 07/0 : 124[0] -> 125[1] via P2P/CUMEM
10: nid005590:110711:120159 [1] NCCL INFO Channel 01/0 : 41[1] -> 42[2] via P2P/CUMEM
10: nid005590:110712:120160 [2] NCCL INFO Channel 02/0 : 42[2] -> 43[3] via P2P/CUMEM
 4: nid005581:264523:274015 [0] NCCL INFO Channel 05/0 : 16[0] -> 17[1] via P2P/CUMEM
17: nid005803:180734:190257 [2] NCCL INFO Channel 04/0 : 70[2] -> 71[3] via P2P/CUMEM
27: nid005922:80742:90207 [1] NCCL INFO Channel 04/0 : 109[1] -> 110[2] via P2P/CUMEM
 3: nid005580:71821:81332 [2] NCCL INFO Channel 03/0 : 14[2] -> 15[3] via P2P/CUMEM
 5: nid005582:196715:206731 [2] NCCL INFO Channel 00/0 : 22[2] -> 23[3] via P2P/CUMEM
 4: nid005581:264525:274016 [2] NCCL INFO Channel 03/0 : 18[2] -> 19[3] via P2P/CUMEM
 3: nid005580:71821:81332 [2] NCCL INFO Channel 04/0 : 14[2] -> 15[3] via P2P/CUMEM
26: nid005920:67125:76630 [2] NCCL INFO Channel 01/0 : 106[2] -> 107[3] via P2P/CUMEM
15: nid005601:210678:220275 [2] NCCL INFO Channel 00/0 : 62[2] -> 63[3] via P2P/CUMEM
 3: nid005580:71821:81332 [2] NCCL INFO Channel 06/0 : 14[2] -> 15[3] via P2P/CUMEM
 3: nid005580:71821:81332 [2] NCCL INFO Channel 07/0 : 14[2] -> 15[3] via P2P/CUMEM
 3: nid005580:71822:81331 [3] NCCL INFO Channel 02/0 : 15[3] -> 12[0] via P2P/CUMEM
 3: nid005580:71822:81331 [3] NCCL INFO Channel 03/0 : 15[3] -> 12[0] via P2P/CUMEM
13: nid005595:197885:207750 [2] NCCL INFO Channel 04/0 : 54[2] -> 55[3] via P2P/CUMEM
 2: nid005577:17423:27009 [1] NCCL INFO Channel 00/0 : 9[1] -> 8[0] via P2P/CUMEM
 3: nid005580:71822:81331 [3] NCCL INFO Channel 06/0 : 15[3] -> 12[0] via P2P/CUMEM
23: nid005917:276885:286402 [0] NCCL INFO Channel 06/0 : 92[0] -> 93[1] via P2P/CUMEM
 1: nid005576:147557:157020 [0] NCCL INFO Channel 02/0 : 4[0] -> 5[1] via P2P/CUMEM
 3: nid005580:71822:81331 [3] NCCL INFO Channel 07/0 : 15[3] -> 12[0] via P2P/CUMEM
22: nid005915:274816:284311 [2] NCCL INFO Channel 02/0 : 90[2] -> 91[3] via P2P/CUMEM
 0: nid005574:69060:78921 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM
21: nid005914:166787:176253 [3] NCCL INFO Channel 02/0 : 87[3] -> 84[0] via P2P/CUMEM
30: nid005936:49908:59406 [0] NCCL INFO Channel 02/0 : 120[0] -> 121[1] via P2P/CUMEM
17: nid005803:180734:190257 [2] NCCL INFO Channel 06/0 : 70[2] -> 71[3] via P2P/CUMEM
18: nid005911:38864:48384 [0] NCCL INFO Channel 02/0 : 72[0] -> 73[1] via P2P/CUMEM
 2: nid005577:17425:27011 [3] NCCL INFO Channel 06/0 : 11[3] -> 8[0] via P2P/CUMEM
 3: nid005580:71820:81334 [1] NCCL INFO Channel 00/0 : 13[1] -> 14[2] via P2P/CUMEM
28: nid005929:16031:25540 [1] NCCL INFO Channel 01/0 : 113[1] -> 114[2] via P2P/CUMEM
22: nid005915:274814:284312 [0] NCCL INFO Channel 02/0 : 88[0] -> 89[1] via P2P/CUMEM
24: nid005918:92504:102030 [0] NCCL INFO Channel 01/0 : 96[0] -> 97[1] via P2P/CUMEM
12: nid005594:53087:62620 [2] NCCL INFO Channel 01/0 : 50[2] -> 51[3] via P2P/CUMEM
20: nid005913:292683:9619 [2] NCCL INFO Channel 02/0 : 82[2] -> 83[3] via P2P/CUMEM
23: nid005917:276887:286401 [2] NCCL INFO Channel 04/0 : 94[2] -> 95[3] via P2P/CUMEM
19: nid005912:12437:21903 [2] NCCL INFO Channel 07/0 : 78[2] -> 79[3] via P2P/CUMEM
18: nid005911:38866:48385 [2] NCCL INFO Channel 01/0 : 74[2] -> 75[3] via P2P/CUMEM
28: nid005929:16031:25540 [1] NCCL INFO Channel 05/0 : 113[1] -> 114[2] via P2P/CUMEM
 5: nid005582:196713:206729 [0] NCCL INFO Channel 06/0 : 20[0] -> 21[1] via P2P/CUMEM
21: nid005914:166787:176253 [3] NCCL INFO Channel 03/0 : 87[3] -> 84[0] via P2P/CUMEM
17: nid005803:180734:190257 [2] NCCL INFO Channel 07/0 : 70[2] -> 71[3] via P2P/CUMEM
10: nid005590:110711:120159 [1] NCCL INFO Channel 05/0 : 41[1] -> 42[2] via P2P/CUMEM
16: nid005802:6299:15959 [2] NCCL INFO Channel 01/0 : 66[2] -> 67[3] via P2P/CUMEM
10: nid005590:110712:120160 [2] NCCL INFO Channel 03/0 : 42[2] -> 43[3] via P2P/CUMEM
 4: nid005581:264523:274015 [0] NCCL INFO Channel 06/0 : 16[0] -> 17[1] via P2P/CUMEM
19: nid005912:12435:21904 [0] NCCL INFO Channel 06/0 : 76[0] -> 77[1] via P2P/CUMEM
15: nid005601:210678:220275 [2] NCCL INFO Channel 02/0 : 62[2] -> 63[3] via P2P/CUMEM
28: nid005929:16033:25541 [3] NCCL INFO Channel 02/0 : 115[3] -> 112[0] via P2P/CUMEM
 4: nid005581:264525:274016 [2] NCCL INFO Channel 05/0 : 18[2] -> 19[3] via P2P/CUMEM
 0: nid005574:69060:78921 [2] NCCL INFO Channel 03/0 : 2[2] -> 3[3] via P2P/CUMEM
 2: nid005577:17423:27009 [1] NCCL INFO Channel 02/0 : 9[1] -> 8[0] via P2P/CUMEM
 5: nid005582:196715:206731 [2] NCCL INFO Channel 02/0 : 22[2] -> 23[3] via P2P/CUMEM
 3: nid005580:71820:81334 [1] NCCL INFO Channel 04/0 : 13[1] -> 14[2] via P2P/CUMEM
26: nid005920:67125:76630 [2] NCCL INFO Channel 02/0 : 106[2] -> 107[3] via P2P/CUMEM
 2: nid005577:17425:27011 [3] NCCL INFO Channel 07/0 : 11[3] -> 8[0] via P2P/CUMEM
27: nid005922:80741:90205 [0] NCCL INFO Channel 00/0 : 104[0] -> 108[0] [receive] via NET/AWS Libfabric/0
22: nid005915:274816:284311 [2] NCCL INFO Channel 03/0 : 90[2] -> 91[3] via P2P/CUMEM
30: nid005936:49908:59406 [0] NCCL INFO Channel 03/0 : 120[0] -> 121[1] via P2P/CUMEM
12: nid005594:53087:62620 [2] NCCL INFO Channel 02/0 : 50[2] -> 51[3] via P2P/CUMEM
 1: nid005576:147557:157020 [0] NCCL INFO Channel 03/0 : 4[0] -> 5[1] via P2P/CUMEM
28: nid005929:16033:25541 [3] NCCL INFO Channel 03/0 : 115[3] -> 112[0] via P2P/CUMEM
13: nid005595:197885:207750 [2] NCCL INFO Channel 06/0 : 54[2] -> 55[3] via P2P/CUMEM
21: nid005914:166787:176253 [3] NCCL INFO Channel 06/0 : 87[3] -> 84[0] via P2P/CUMEM
27: nid005922:80743:90206 [2] NCCL INFO Channel 02/0 : 106[2] -> 110[2] [receive] via NET/AWS Libfabric/2
22: nid005915:274814:284312 [0] NCCL INFO Channel 03/0 : 88[0] -> 89[1] via P2P/CUMEM
20: nid005913:292681:9616 [0] NCCL INFO Channel 06/0 : 80[0] -> 81[1] via P2P/CUMEM
 5: nid005582:196713:206729 [0] NCCL INFO Channel 07/0 : 20[0] -> 21[1] via P2P/CUMEM
 3: nid005580:71819:81333 [0] NCCL INFO Channel 02/0 : 12[0] -> 13[1] via P2P/CUMEM
14: nid005600:217722:227328 [2] NCCL INFO Channel 02/0 : 58[2] -> 59[3] via P2P/CUMEM
15: nid005601:210678:220275 [2] NCCL INFO Channel 03/0 : 62[2] -> 63[3] via P2P/CUMEM
14: nid005600:217722:227328 [2] NCCL INFO Channel 03/0 : 58[2] -> 59[3] via P2P/CUMEM
16: nid005802:6298:15958 [1] NCCL INFO Channel 01/0 : 65[1] -> 66[2] via P2P/CUMEM
14: nid005600:217722:227328 [2] NCCL INFO Channel 05/0 : 58[2] -> 59[3] via P2P/CUMEM
10: nid005590:110712:120160 [2] NCCL INFO Channel 05/0 : 42[2] -> 43[3] via P2P/CUMEM
23: nid005917:276885:286402 [0] NCCL INFO Channel 07/0 : 92[0] -> 93[1] via P2P/CUMEM
28: nid005929:16033:25541 [3] NCCL INFO Channel 06/0 : 115[3] -> 112[0] via P2P/CUMEM
14: nid005600:217722:227328 [2] NCCL INFO Channel 06/0 : 58[2] -> 59[3] via P2P/CUMEM
19: nid005912:12435:21904 [0] NCCL INFO Channel 07/0 : 76[0] -> 77[1] via P2P/CUMEM
14: nid005600:217722:227328 [2] NCCL INFO Channel 07/0 : 58[2] -> 59[3] via P2P/CUMEM
14: nid005600:217723:227325 [3] NCCL INFO Channel 02/0 : 59[3] -> 56[0] via P2P/CUMEM
 0: nid005574:69060:78921 [2] NCCL INFO Channel 05/0 : 2[2] -> 3[3] via P2P/CUMEM
 7: nid005585:122007:131444 [2] NCCL INFO Channel 00/0 : 30[2] -> 31[3] via P2P/CUMEM
14: nid005600:217723:227325 [3] NCCL INFO Channel 03/0 : 59[3] -> 56[0] via P2P/CUMEM
14: nid005600:217722:227328 [2] NCCL INFO Channel 03/0 : 54[2] -> 58[2] [receive] via NET/AWS Libfabric/2
18: nid005911:38864:48384 [0] NCCL INFO Channel 03/0 : 72[0] -> 73[1] via P2P/CUMEM
14: nid005600:217722:227328 [2] NCCL INFO Channel 07/0 : 54[2] -> 58[2] [receive] via NET/AWS Libfabric/2
 2: nid005577:17423:27009 [1] NCCL INFO Channel 04/0 : 9[1] -> 8[0] via P2P/CUMEM
 4: nid005581:264525:274016 [2] NCCL INFO Channel 06/0 : 18[2] -> 19[3] via P2P/CUMEM
 5: nid005582:196715:206731 [2] NCCL INFO Channel 03/0 : 22[2] -> 23[3] via P2P/CUMEM
18: nid005911:38866:48385 [2] NCCL INFO Channel 02/0 : 74[2] -> 75[3] via P2P/CUMEM
14: nid005600:217723:227325 [3] NCCL INFO Channel 06/0 : 59[3] -> 56[0] via P2P/CUMEM
28: nid005929:16030:25536 [0] NCCL INFO Channel 04/0 : 112[0] -> 116[0] [send] via NET/AWS Libfabric/0
14: nid005600:217722:227328 [2] NCCL INFO Channel 02/0 : 58[2] -> 62[2] [send] via NET/AWS Libfabric/2
20: nid005913:292683:9619 [2] NCCL INFO Channel 03/0 : 82[2] -> 83[3] via P2P/CUMEM
26: nid005920:67125:76630 [2] NCCL INFO Channel 03/0 : 106[2] -> 107[3] via P2P/CUMEM
30: nid005936:49910:59408 [2] NCCL INFO Channel 01/0 : 122[2] -> 123[3] via P2P/CUMEM
14: nid005600:217723:227325 [3] NCCL INFO Channel 07/0 : 59[3] -> 56[0] via P2P/CUMEM
10: nid005590:110712:120160 [2] NCCL INFO Channel 06/0 : 42[2] -> 43[3] via P2P/CUMEM
27: nid005922:80742:90207 [1] NCCL INFO Channel 01/0 : 109[1] -> 108[0] via P2P/CUMEM
22: nid005915:274816:284311 [2] NCCL INFO Channel 05/0 : 90[2] -> 91[3] via P2P/CUMEM
 3: nid005580:71819:81333 [0] NCCL INFO Channel 03/0 : 12[0] -> 13[1] via P2P/CUMEM
23: nid005917:276887:286401 [2] NCCL INFO Channel 06/0 : 94[2] -> 95[3] via P2P/CUMEM
28: nid005929:16032:25538 [2] NCCL INFO Channel 06/0 : 114[2] -> 118[2] [send] via NET/AWS Libfabric/2
28: nid005929:16033:25541 [3] NCCL INFO Channel 07/0 : 115[3] -> 112[0] via P2P/CUMEM
 4: nid005581:264523:274015 [0] NCCL INFO Channel 07/0 : 16[0] -> 17[1] via P2P/CUMEM
17: nid005803:180735:190256 [3] NCCL INFO Channel 02/0 : 71[3] -> 68[0] via P2P/CUMEM
22: nid005915:274814:284312 [0] NCCL INFO Channel 05/0 : 88[0] -> 89[1] via P2P/CUMEM
 2: nid005577:17423:27009 [1] NCCL INFO Channel 06/0 : 9[1] -> 8[0] via P2P/CUMEM
30: nid005936:49908:59406 [0] NCCL INFO Channel 05/0 : 120[0] -> 121[1] via P2P/CUMEM
15: nid005601:210677:220274 [1] NCCL INFO Channel 00/0 : 61[1] -> 62[2] via P2P/CUMEM
27: nid005922:80742:90207 [1] NCCL INFO Channel 03/0 : 109[1] -> 108[0] via P2P/CUMEM
16: nid005802:6299:15959 [2] NCCL INFO Channel 02/0 : 66[2] -> 67[3] via P2P/CUMEM
 1: nid005576:147557:157020 [0] NCCL INFO Channel 04/0 : 4[0] -> 5[1] via P2P/CUMEM
21: nid005914:166787:176253 [3] NCCL INFO Channel 07/0 : 87[3] -> 84[0] via P2P/CUMEM
10: nid005590:110712:120160 [2] NCCL INFO Channel 07/0 : 42[2] -> 43[3] via P2P/CUMEM
15: nid005601:210678:220275 [2] NCCL INFO Channel 04/0 : 62[2] -> 63[3] via P2P/CUMEM
10: nid005590:110710:120158 [0] NCCL INFO Channel 01/0 : 36[0] -> 40[0] [receive] via NET/AWS Libfabric/0
 3: nid005580:71819:81333 [0] NCCL INFO Channel 04/0 : 12[0] -> 13[1] via P2P/CUMEM
 4: nid005581:264525:274016 [2] NCCL INFO Channel 07/0 : 18[2] -> 19[3] via P2P/CUMEM
16: nid005802:6298:15958 [1] NCCL INFO Channel 05/0 : 65[1] -> 66[2] via P2P/CUMEM
 5: nid005582:196715:206731 [2] NCCL INFO Channel 04/0 : 22[2] -> 23[3] via P2P/CUMEM
25: nid005919:107462:116999 [0] NCCL INFO Channel 00/0 : 100[0] -> 101[1] via P2P/CUMEM
17: nid005803:180734:190257 [2] NCCL INFO Channel 06/0 : 66[2] -> 70[2] [receive] via NET/AWS Libfabric/2
26: nid005920:67125:76630 [2] NCCL INFO Channel 05/0 : 106[2] -> 107[3] via P2P/CUMEM
10: nid005590:110710:120158 [0] NCCL INFO Channel 05/0 : 36[0] -> 40[0] [receive] via NET/AWS Libfabric/0
 7: nid005585:122007:131444 [2] NCCL INFO Channel 02/0 : 30[2] -> 31[3] via P2P/CUMEM
13: nid005595:197885:207750 [2] NCCL INFO Channel 07/0 : 54[2] -> 55[3] via P2P/CUMEM
27: nid005922:80742:90207 [1] NCCL INFO Channel 05/0 : 109[1] -> 108[0] via P2P/CUMEM
 0: nid005574:69060:78921 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM
12: nid005594:53087:62620 [2] NCCL INFO Channel 03/0 : 50[2] -> 51[3] via P2P/CUMEM
 3: nid005580:71821:81332 [2] NCCL INFO Channel 02/0 : 10[2] -> 14[2] [receive] via NET/AWS Libfabric/2
22: nid005915:274816:284311 [2] NCCL INFO Channel 06/0 : 90[2] -> 91[3] via P2P/CUMEM
30: nid005936:49910:59408 [2] NCCL INFO Channel 02/0 : 122[2] -> 123[3] via P2P/CUMEM
22: nid005915:274814:284312 [0] NCCL INFO Channel 06/0 : 88[0] -> 89[1] via P2P/CUMEM
17: nid005803:180734:190257 [2] NCCL INFO Channel 03/0 : 70[2] -> 74[2] [send] via NET/AWS Libfabric/2
26: nid005920:67124:76629 [1] NCCL INFO Channel 01/0 : 105[1] -> 106[2] via P2P/CUMEM
10: nid005590:110710:120158 [0] NCCL INFO Channel 00/0 : 40[0] -> 44[0] [send] via NET/AWS Libfabric/0
18: nid005911:38866:48385 [2] NCCL INFO Channel 03/0 : 74[2] -> 75[3] via P2P/CUMEM
14: nid005600:217720:227327 [0] NCCL INFO Channel 02/0 : 56[0] -> 57[1] via P2P/CUMEM
 5: nid005582:196715:206731 [2] NCCL INFO Channel 06/0 : 22[2] -> 23[3] via P2P/CUMEM
23: nid005917:276887:286401 [2] NCCL INFO Channel 07/0 : 94[2] -> 95[3] via P2P/CUMEM
17: nid005803:180735:190256 [3] NCCL INFO Channel 03/0 : 71[3] -> 68[0] via P2P/CUMEM
20: nid005913:292682:9618 [1] NCCL INFO Channel 01/0 : 81[1] -> 82[2] via P2P/CUMEM
17: nid005803:180734:190257 [2] NCCL INFO Channel 07/0 : 70[2] -> 74[2] [send] via NET/AWS Libfabric/2
18: nid005911:38864:48384 [0] NCCL INFO Channel 05/0 : 72[0] -> 73[1] via P2P/CUMEM
27: nid005922:80742:90207 [1] NCCL INFO Channel 07/0 : 109[1] -> 108[0] via P2P/CUMEM
 3: nid005580:71821:81332 [2] NCCL INFO Channel 06/0 : 6[2] -> 14[2] [receive] via NET/AWS Libfabric/2
17: nid005803:180733:190255 [1] NCCL INFO Channel 01/0 : 69[1] -> 68[0] via P2P/CUMEM
20: nid005913:292683:9619 [2] NCCL INFO Channel 05/0 : 82[2] -> 83[3] via P2P/CUMEM
15: nid005601:210677:220274 [1] NCCL INFO Channel 04/0 : 61[1] -> 62[2] via P2P/CUMEM
 5: nid005582:196715:206731 [2] NCCL INFO Channel 07/0 : 22[2] -> 23[3] via P2P/CUMEM
15: nid005601:210678:220275 [2] NCCL INFO Channel 06/0 : 62[2] -> 63[3] via P2P/CUMEM
28: nid005929:16031:25540 [1] NCCL INFO Channel 00/0 : 113[1] -> 112[0] via P2P/CUMEM
11: nid005591:191603:202359 [0] NCCL INFO Channel 00/0 : 44[0] -> 45[1] via P2P/CUMEM
22: nid005915:274816:284311 [2] NCCL INFO Channel 07/0 : 90[2] -> 91[3] via P2P/CUMEM
 1: nid005576:147557:157020 [0] NCCL INFO Channel 06/0 : 4[0] -> 5[1] via P2P/CUMEM
 5: nid005582:196713:206729 [0] NCCL INFO Channel 04/0 : 16[0] -> 20[0] [receive] via NET/AWS Libfabric/0
14: nid005600:217720:227327 [0] NCCL INFO Channel 03/0 : 56[0] -> 57[1] via P2P/CUMEM
 3: nid005580:71819:81333 [0] NCCL INFO Channel 06/0 : 12[0] -> 13[1] via P2P/CUMEM
 3: nid005580:71821:81332 [2] NCCL INFO Channel 07/0 : 6[2] -> 14[2] [receive] via NET/AWS Libfabric/2
22: nid005915:274814:284312 [0] NCCL INFO Channel 07/0 : 88[0] -> 89[1] via P2P/CUMEM
19: nid005912:12438:21905 [3] NCCL INFO Channel 02/0 : 79[3] -> 76[0] via P2P/CUMEM
30: nid005936:49908:59406 [0] NCCL INFO Channel 06/0 : 120[0] -> 121[1] via P2P/CUMEM
29: nid005932:167680:177152 [0] NCCL INFO Channel 00/0 : 116[0] -> 117[1] via P2P/CUMEM
10: nid005590:110713:120157 [3] NCCL INFO Channel 02/0 : 43[3] -> 40[0] via P2P/CUMEM
 7: nid005585:122007:131444 [2] NCCL INFO Channel 03/0 : 30[2] -> 31[3] via P2P/CUMEM
11: nid005591:191605:202358 [2] NCCL INFO Channel 00/0 : 46[2] -> 47[3] via P2P/CUMEM
 3: nid005580:71821:81332 [2] NCCL INFO Channel 06/0 : 14[2] -> 22[2] [send] via NET/AWS Libfabric/2
 5: nid005582:196713:206729 [0] NCCL INFO Channel 01/0 : 20[0] -> 24[0] [send] via NET/AWS Libfabric/0
 0: nid005574:69060:78921 [2] NCCL INFO Channel 07/0 : 2[2] -> 3[3] via P2P/CUMEM
18: nid005911:38866:48385 [2] NCCL INFO Channel 05/0 : 74[2] -> 75[3] via P2P/CUMEM
19: nid005912:12435:21904 [0] NCCL INFO Channel 00/0 : 72[0] -> 76[0] [receive] via NET/AWS Libfabric/0
28: nid005929:16031:25540 [1] NCCL INFO Channel 02/0 : 113[1] -> 112[0] via P2P/CUMEM
16: nid005802:6299:15959 [2] NCCL INFO Channel 03/0 : 66[2] -> 67[3] via P2P/CUMEM
 3: nid005580:71821:81332 [2] NCCL INFO Channel 07/0 : 14[2] -> 22[2] [send] via NET/AWS Libfabric/2
 3: nid005580:71819:81333 [0] NCCL INFO Channel 07/0 : 12[0] -> 13[1] via P2P/CUMEM
 5: nid005582:196713:206729 [0] NCCL INFO Channel 05/0 : 20[0] -> 24[0] [send] via NET/AWS Libfabric/0
21: nid005914:166785:176254 [1] NCCL INFO Channel 00/0 : 85[1] -> 86[2] via P2P/CUMEM
30: nid005936:49910:59408 [2] NCCL INFO Channel 03/0 : 122[2] -> 123[3] via P2P/CUMEM
26: nid005920:67125:76630 [2] NCCL INFO Channel 06/0 : 106[2] -> 107[3] via P2P/CUMEM
17: nid005803:180735:190256 [3] NCCL INFO Channel 06/0 : 71[3] -> 68[0] via P2P/CUMEM
26: nid005920:67124:76629 [1] NCCL INFO Channel 05/0 : 105[1] -> 106[2] via P2P/CUMEM
12: nid005594:53087:62620 [2] NCCL INFO Channel 05/0 : 50[2] -> 51[3] via P2P/CUMEM
14: nid005600:217720:227327 [0] NCCL INFO Channel 05/0 : 56[0] -> 57[1] via P2P/CUMEM
19: nid005912:12437:21903 [2] NCCL INFO Channel 02/0 : 74[2] -> 78[2] [receive] via NET/AWS Libfabric/2
28: nid005929:16031:25540 [1] NCCL INFO Channel 04/0 : 113[1] -> 112[0] via P2P/CUMEM
17: nid005803:180733:190255 [1] NCCL INFO Channel 03/0 : 69[1] -> 68[0] via P2P/CUMEM
20: nid005913:292681:9616 [0] NCCL INFO Channel 07/0 : 80[0] -> 81[1] via P2P/CUMEM
10: nid005590:110712:120160 [2] NCCL INFO Channel 03/0 : 38[2] -> 42[2] [receive] via NET/AWS Libfabric/2
20: nid005913:292682:9618 [1] NCCL INFO Channel 05/0 : 81[1] -> 82[2] via P2P/CUMEM
15: nid005601:210678:220275 [2] NCCL INFO Channel 07/0 : 62[2] -> 63[3] via P2P/CUMEM
19: nid005912:12438:21905 [3] NCCL INFO Channel 03/0 : 79[3] -> 76[0] via P2P/CUMEM
21: nid005914:166785:176254 [1] NCCL INFO Channel 04/0 : 85[1] -> 86[2] via P2P/CUMEM
10: nid005590:110713:120157 [3] NCCL INFO Channel 03/0 : 43[3] -> 40[0] via P2P/CUMEM
10: nid005590:110712:120160 [2] NCCL INFO Channel 07/0 : 38[2] -> 42[2] [receive] via NET/AWS Libfabric/2
20: nid005913:292683:9619 [2] NCCL INFO Channel 06/0 : 82[2] -> 83[3] via P2P/CUMEM
 1: nid005576:147558:157019 [1] NCCL INFO Channel 00/0 : 5[1] -> 6[2] via P2P/CUMEM
14: nid005600:217720:227327 [0] NCCL INFO Channel 06/0 : 56[0] -> 57[1] via P2P/CUMEM
23: nid005917:276886:286403 [1] NCCL INFO Channel 00/0 : 93[1] -> 94[2] via P2P/CUMEM
28: nid005929:16031:25540 [1] NCCL INFO Channel 06/0 : 113[1] -> 112[0] via P2P/CUMEM
 7: nid005585:122006:131443 [1] NCCL INFO Channel 00/0 : 29[1] -> 30[2] via P2P/CUMEM
 7: nid005585:122007:131444 [2] NCCL INFO Channel 04/0 : 30[2] -> 31[3] via P2P/CUMEM
30: nid005936:49908:59406 [0] NCCL INFO Channel 07/0 : 120[0] -> 121[1] via P2P/CUMEM
 1: nid005576:147557:157020 [0] NCCL INFO Channel 07/0 : 4[0] -> 5[1] via P2P/CUMEM
18: nid005911:38864:48384 [0] NCCL INFO Channel 06/0 : 72[0] -> 73[1] via P2P/CUMEM
18: nid005911:38866:48385 [2] NCCL INFO Channel 06/0 : 74[2] -> 75[3] via P2P/CUMEM
23: nid005917:276888:286400 [3] NCCL INFO Channel 02/0 : 95[3] -> 92[0] via P2P/CUMEM
10: nid005590:110712:120160 [2] NCCL INFO Channel 02/0 : 42[2] -> 46[2] [send] via NET/AWS Libfabric/2
 9: nid005588:35937:45448 [2] NCCL INFO Channel 00/0 : 38[2] -> 39[3] via P2P/CUMEM
16: nid005802:6297:15957 [0] NCCL INFO Channel 04/0 : 64[0] -> 68[0] [send] via NET/AWS Libfabric/0
16: nid005802:6299:15959 [2] NCCL INFO Channel 05/0 : 66[2] -> 67[3] via P2P/CUMEM
 5: nid005582:196716:206730 [3] NCCL INFO Channel 02/0 : 23[3] -> 20[0] via P2P/CUMEM
 7: nid005585:122005:131445 [0] NCCL INFO Channel 00/0 : 28[0] -> 29[1] via P2P/CUMEM
22: nid005915:274817:284310 [3] NCCL INFO Channel 02/0 : 91[3] -> 88[0] via P2P/CUMEM
13: nid005595:197883:207753 [0] NCCL INFO Channel 00/0 : 52[0] -> 53[1] via P2P/CUMEM
14: nid005600:217720:227327 [0] NCCL INFO Channel 07/0 : 56[0] -> 57[1] via P2P/CUMEM
30: nid005936:49910:59408 [2] NCCL INFO Channel 05/0 : 122[2] -> 123[3] via P2P/CUMEM
17: nid005803:180735:190256 [3] NCCL INFO Channel 07/0 : 71[3] -> 68[0] via P2P/CUMEM
17: nid005803:180733:190255 [1] NCCL INFO Channel 05/0 : 69[1] -> 68[0] via P2P/CUMEM
25: nid005919:107464:116998 [2] NCCL INFO Channel 00/0 : 102[2] -> 103[3] via P2P/CUMEM
 0: nid005574:69061:78922 [3] NCCL INFO Channel 02/0 : 3[3] -> 0[0] via P2P/CUMEM
19: nid005912:12436:21902 [1] NCCL INFO Channel 01/0 : 77[1] -> 76[0] via P2P/CUMEM
10: nid005590:110711:120159 [1] NCCL INFO Channel 00/0 : 41[1] -> 40[0] via P2P/CUMEM
19: nid005912:12438:21905 [3] NCCL INFO Channel 06/0 : 79[3] -> 76[0] via P2P/CUMEM
15: nid005601:210676:220272 [0] NCCL INFO Channel 00/0 : 56[0] -> 60[0] [receive] via NET/AWS Libfabric/0
25: nid005919:107462:116999 [0] NCCL INFO Channel 02/0 : 100[0] -> 101[1] via P2P/CUMEM
23: nid005917:276886:286403 [1] NCCL INFO Channel 04/0 : 93[1] -> 94[2] via P2P/CUMEM
10: nid005590:110713:120157 [3] NCCL INFO Channel 06/0 : 43[3] -> 40[0] via P2P/CUMEM
 5: nid005582:196715:206731 [2] NCCL INFO Channel 06/0 : 18[2] -> 22[2] [receive] via NET/AWS Libfabric/2
26: nid005920:67125:76630 [2] NCCL INFO Channel 07/0 : 106[2] -> 107[3] via P2P/CUMEM
23: nid005917:276888:286400 [3] NCCL INFO Channel 03/0 : 95[3] -> 92[0] via P2P/CUMEM
 9: nid005588:35935:45450 [0] NCCL INFO Channel 00/0 : 36[0] -> 37[1] via P2P/CUMEM
22: nid005915:274817:284310 [3] NCCL INFO Channel 03/0 : 91[3] -> 88[0] via P2P/CUMEM
16: nid005802:6297:15957 [0] NCCL INFO Channel 00/0 : 32[0] -> 64[0] [receive] via NET/AWS Libfabric/0
 1: nid005576:147558:157019 [1] NCCL INFO Channel 04/0 : 5[1] -> 6[2] via P2P/CUMEM
 5: nid005582:196716:206730 [3] NCCL INFO Channel 03/0 : 23[3] -> 20[0] via P2P/CUMEM
12: nid005594:53087:62620 [2] NCCL INFO Channel 06/0 : 50[2] -> 51[3] via P2P/CUMEM
15: nid005601:210679:220273 [3] NCCL INFO Channel 02/0 : 63[3] -> 60[0] via P2P/CUMEM
 5: nid005582:196715:206731 [2] NCCL INFO Channel 03/0 : 22[2] -> 26[2] [send] via NET/AWS Libfabric/2
 7: nid005585:122006:131443 [1] NCCL INFO Channel 04/0 : 29[1] -> 30[2] via P2P/CUMEM
11: nid005591:191605:202358 [2] NCCL INFO Channel 02/0 : 46[2] -> 47[3] via P2P/CUMEM
21: nid005914:166784:176252 [0] NCCL INFO Channel 04/0 : 80[0] -> 84[0] [receive] via NET/AWS Libfabric/0
11: nid005591:191605:202358 [2] NCCL INFO Channel 03/0 : 46[2] -> 47[3] via P2P/CUMEM
16: nid005802:6297:15957 [0] NCCL INFO Channel 01/0 : 32[0] -> 64[0] [receive] via NET/AWS Libfabric/0
 7: nid005585:122007:131444 [2] NCCL INFO Channel 06/0 : 30[2] -> 31[3] via P2P/CUMEM
20: nid005913:292683:9619 [2] NCCL INFO Channel 07/0 : 82[2] -> 83[3] via P2P/CUMEM
 5: nid005582:196715:206731 [2] NCCL INFO Channel 07/0 : 22[2] -> 26[2] [send] via NET/AWS Libfabric/2
18: nid005911:38864:48384 [0] NCCL INFO Channel 07/0 : 72[0] -> 73[1] via P2P/CUMEM
 0: nid005574:69060:78921 [2] NCCL INFO Channel 06/0 : 2[2] -> 6[2] [send] via NET/AWS Libfabric/2
16: nid005802:6297:15957 [0] NCCL INFO Channel 00/0 : 64[0] -> 96[0] [send] via NET/AWS Libfabric/0
18: nid005911:38866:48385 [2] NCCL INFO Channel 07/0 : 74[2] -> 75[3] via P2P/CUMEM
13: nid005595:197884:207751 [1] NCCL INFO Channel 00/0 : 53[1] -> 54[2] via P2P/CUMEM
 9: nid005588:35937:45448 [2] NCCL INFO Channel 02/0 : 38[2] -> 39[3] via P2P/CUMEM
21: nid005914:166784:176252 [0] NCCL INFO Channel 01/0 : 84[0] -> 88[0] [send] via NET/AWS Libfabric/0
 6: nid005584:28285:37730 [0] NCCL INFO Channel 01/0 : 24[0] -> 25[1] via P2P/CUMEM
 0: nid005574:69061:78922 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM
16: nid005802:6299:15959 [2] NCCL INFO Channel 06/0 : 66[2] -> 67[3] via P2P/CUMEM
17: nid005803:180733:190255 [1] NCCL INFO Channel 07/0 : 69[1] -> 68[0] via P2P/CUMEM
 3: nid005580:71819:81333 [0] NCCL INFO Channel 00/0 : 8[0] -> 12[0] [receive] via NET/AWS Libfabric/0
16: nid005802:6297:15957 [0] NCCL INFO Channel 01/0 : 64[0] -> 96[0] [send] via NET/AWS Libfabric/0
23: nid005917:276888:286400 [3] NCCL INFO Channel 06/0 : 95[3] -> 92[0] via P2P/CUMEM
15: nid005601:210678:220275 [2] NCCL INFO Channel 02/0 : 58[2] -> 62[2] [receive] via NET/AWS Libfabric/2
19: nid005912:12436:21902 [1] NCCL INFO Channel 03/0 : 77[1] -> 76[0] via P2P/CUMEM
21: nid005914:166786:176251 [2] NCCL INFO Channel 06/0 : 82[2] -> 86[2] [receive] via NET/AWS Libfabric/2
10: nid005590:110711:120159 [1] NCCL INFO Channel 02/0 : 41[1] -> 40[0] via P2P/CUMEM
19: nid005912:12438:21905 [3] NCCL INFO Channel 07/0 : 79[3] -> 76[0] via P2P/CUMEM
21: nid005914:166784:176252 [0] NCCL INFO Channel 05/0 : 84[0] -> 88[0] [send] via NET/AWS Libfabric/0
22: nid005915:274817:284310 [3] NCCL INFO Channel 06/0 : 91[3] -> 88[0] via P2P/CUMEM
10: nid005590:110713:120157 [3] NCCL INFO Channel 07/0 : 43[3] -> 40[0] via P2P/CUMEM
15: nid005601:210679:220273 [3] NCCL INFO Channel 03/0 : 63[3] -> 60[0] via P2P/CUMEM
20: nid005913:292681:9616 [0] NCCL INFO Channel 04/0 : 80[0] -> 84[0] [send] via NET/AWS Libfabric/0
21: nid005914:166786:176251 [2] NCCL INFO Channel 03/0 : 86[2] -> 90[2] [send] via NET/AWS Libfabric/2
 4: nid005581:264526:274017 [3] NCCL INFO Channel 02/0 : 19[3] -> 16[0] via P2P/CUMEM
 3: nid005580:71820:81334 [1] NCCL INFO Channel 01/0 : 13[1] -> 12[0] via P2P/CUMEM
 5: nid005582:196714:206728 [1] NCCL INFO Channel 01/0 : 21[1] -> 20[0] via P2P/CUMEM
 5: nid005582:196716:206730 [3] NCCL INFO Channel 06/0 : 23[3] -> 20[0] via P2P/CUMEM
23: nid005917:276888:286400 [3] NCCL INFO Channel 07/0 : 95[3] -> 92[0] via P2P/CUMEM
26: nid005920:67123:76628 [0] NCCL INFO Channel 01/0 : 100[0] -> 104[0] [receive] via NET/AWS Libfabric/0
 1: nid005576:147560:157021 [3] NCCL INFO Channel 02/0 : 7[3] -> 4[0] via P2P/CUMEM
21: nid005914:166786:176251 [2] NCCL INFO Channel 07/0 : 86[2] -> 90[2] [send] via NET/AWS Libfabric/2
30: nid005936:49910:59408 [2] NCCL INFO Channel 06/0 : 122[2] -> 123[3] via P2P/CUMEM
26: nid005920:67123:76628 [0] NCCL INFO Channel 05/0 : 100[0] -> 104[0] [receive] via NET/AWS Libfabric/0
25: nid005919:107464:116998 [2] NCCL INFO Channel 02/0 : 102[2] -> 103[3] via P2P/CUMEM
23: nid005917:276885:286402 [0] NCCL INFO Channel 00/0 : 88[0] -> 92[0] [receive] via NET/AWS Libfabric/0
14: nid005600:217720:227327 [0] NCCL INFO Channel 01/0 : 52[0] -> 56[0] [receive] via NET/AWS Libfabric/0
22: nid005915:274817:284310 [3] NCCL INFO Channel 07/0 : 91[3] -> 88[0] via P2P/CUMEM
15: nid005601:210678:220275 [2] NCCL INFO Channel 06/0 : 30[2] -> 62[2] [receive] via NET/AWS Libfabric/2
 3: nid005580:71820:81334 [1] NCCL INFO Channel 03/0 : 13[1] -> 12[0] via P2P/CUMEM
 4: nid005581:264526:274017 [3] NCCL INFO Channel 03/0 : 19[3] -> 16[0] via P2P/CUMEM
16: nid005802:6299:15959 [2] NCCL INFO Channel 07/0 : 66[2] -> 67[3] via P2P/CUMEM
 3: nid005580:71819:81333 [0] NCCL INFO Channel 04/0 : 4[0] -> 12[0] [receive] via NET/AWS Libfabric/0
26: nid005920:67123:76628 [0] NCCL INFO Channel 00/0 : 104[0] -> 108[0] [send] via NET/AWS Libfabric/0
 0: nid005574:69059:78919 [1] NCCL INFO Channel 00/0 : 1[1] -> 0[0] via P2P/CUMEM
12: nid005594:53086:62619 [1] NCCL INFO Channel 01/0 : 49[1] -> 50[2] via P2P/CUMEM
 1: nid005576:147557:157020 [0] NCCL INFO Channel 04/0 : 0[0] -> 4[0] [receive] via NET/AWS Libfabric/0
 7: nid005585:122007:131444 [2] NCCL INFO Channel 07/0 : 30[2] -> 31[3] via P2P/CUMEM
 3: nid005580:71819:81333 [0] NCCL INFO Channel 05/0 : 4[0] -> 12[0] [receive] via NET/AWS Libfabric/0
21: nid005914:166785:176254 [1] NCCL INFO Channel 01/0 : 85[1] -> 84[0] via P2P/CUMEM
 0: nid005574:69061:78922 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM
15: nid005601:210678:220275 [2] NCCL INFO Channel 07/0 : 30[2] -> 62[2] [receive] via NET/AWS Libfabric/2
14: nid005600:217720:227327 [0] NCCL INFO Channel 05/0 : 52[0] -> 56[0] [receive] via NET/AWS Libfabric/0
 6: nid005584:28287:37728 [2] NCCL INFO Channel 01/0 : 26[2] -> 27[3] via P2P/CUMEM
12: nid005594:53087:62620 [2] NCCL INFO Channel 07/0 : 50[2] -> 51[3] via P2P/CUMEM
 1: nid005576:147560:157021 [3] NCCL INFO Channel 03/0 : 7[3] -> 4[0] via P2P/CUMEM
 7: nid005585:122005:131445 [0] NCCL INFO Channel 02/0 : 28[0] -> 29[1] via P2P/CUMEM
 3: nid005580:71820:81334 [1] NCCL INFO Channel 05/0 : 13[1] -> 12[0] via P2P/CUMEM
25: nid005919:107462:116999 [0] NCCL INFO Channel 03/0 : 100[0] -> 101[1] via P2P/CUMEM
23: nid005917:276887:286401 [2] NCCL INFO Channel 02/0 : 90[2] -> 94[2] [receive] via NET/AWS Libfabric/2
10: nid005590:110711:120159 [1] NCCL INFO Channel 04/0 : 41[1] -> 40[0] via P2P/CUMEM
 1: nid005576:147557:157020 [0] NCCL INFO Channel 01/0 : 4[0] -> 8[0] [send] via NET/AWS Libfabric/0
15: nid005601:210678:220275 [2] NCCL INFO Channel 06/0 : 62[2] -> 94[2] [send] via NET/AWS Libfabric/2
15: nid005601:210677:220274 [1] NCCL INFO Channel 01/0 : 61[1] -> 60[0] via P2P/CUMEM
 3: nid005580:71819:81333 [0] NCCL INFO Channel 04/0 : 12[0] -> 20[0] [send] via NET/AWS Libfabric/0
13: nid005595:197884:207751 [1] NCCL INFO Channel 04/0 : 53[1] -> 54[2] via P2P/CUMEM
13: nid005595:197883:207753 [0] NCCL INFO Channel 02/0 : 52[0] -> 53[1] via P2P/CUMEM
 5: nid005582:196714:206728 [1] NCCL INFO Channel 03/0 : 21[1] -> 20[0] via P2P/CUMEM
19: nid005912:12436:21902 [1] NCCL INFO Channel 05/0 : 77[1] -> 76[0] via P2P/CUMEM
30: nid005936:49910:59408 [2] NCCL INFO Channel 07/0 : 122[2] -> 123[3] via P2P/CUMEM
14: nid005600:217721:227326 [1] NCCL INFO Channel 00/0 : 57[1] -> 56[0] via P2P/CUMEM
 1: nid005576:147559:157018 [2] NCCL INFO Channel 06/0 : 2[2] -> 6[2] [receive] via NET/AWS Libfabric/2
15: nid005601:210679:220273 [3] NCCL INFO Channel 06/0 : 63[3] -> 60[0] via P2P/CUMEM
 3: nid005580:71819:81333 [0] NCCL INFO Channel 05/0 : 12[0] -> 20[0] [send] via NET/AWS Libfabric/0
 5: nid005582:196716:206730 [3] NCCL INFO Channel 07/0 : 23[3] -> 20[0] via P2P/CUMEM
20: nid005913:292684:9617 [3] NCCL INFO Channel 02/0 : 83[3] -> 80[0] via P2P/CUMEM
20: nid005913:292681:9616 [0] NCCL INFO Channel 00/0 : 72[0] -> 80[0] [receive] via NET/AWS Libfabric/0
21: nid005914:166785:176254 [1] NCCL INFO Channel 03/0 : 85[1] -> 84[0] via P2P/CUMEM
14: nid005600:217720:227327 [0] NCCL INFO Channel 00/0 : 56[0] -> 60[0] [send] via NET/AWS Libfabric/0
15: nid005601:210678:220275 [2] NCCL INFO Channel 07/0 : 62[2] -> 94[2] [send] via NET/AWS Libfabric/2
 3: nid005580:71820:81334 [1] NCCL INFO Channel 07/0 : 13[1] -> 12[0] via P2P/CUMEM
20: nid005913:292683:9619 [2] NCCL INFO Channel 06/0 : 82[2] -> 86[2] [send] via NET/AWS Libfabric/2
19: nid005912:12436:21902 [1] NCCL INFO Channel 07/0 : 77[1] -> 76[0] via P2P/CUMEM
 4: nid005581:264526:274017 [3] NCCL INFO Channel 06/0 : 19[3] -> 16[0] via P2P/CUMEM
14: nid005600:217721:227326 [1] NCCL INFO Channel 02/0 : 57[1] -> 56[0] via P2P/CUMEM
10: nid005590:110711:120159 [1] NCCL INFO Channel 06/0 : 41[1] -> 40[0] via P2P/CUMEM
20: nid005913:292681:9616 [0] NCCL INFO Channel 01/0 : 72[0] -> 80[0] [receive] via NET/AWS Libfabric/0
21: nid005914:166785:176254 [1] NCCL INFO Channel 05/0 : 85[1] -> 84[0] via P2P/CUMEM
24: nid005918:92504:102030 [0] NCCL INFO Channel 02/0 : 96[0] -> 97[1] via P2P/CUMEM
 7: nid005585:122005:131445 [0] NCCL INFO Channel 03/0 : 28[0] -> 29[1] via P2P/CUMEM
18: nid005911:38867:48386 [3] NCCL INFO Channel 02/0 : 75[3] -> 72[0] via P2P/CUMEM
 0: nid005574:69059:78919 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM
 9: nid005588:35936:45447 [1] NCCL INFO Channel 00/0 : 37[1] -> 38[2] via P2P/CUMEM
 1: nid005576:147557:157020 [0] NCCL INFO Channel 05/0 : 4[0] -> 8[0] [send] via NET/AWS Libfabric/0
 1: nid005576:147559:157018 [2] NCCL INFO Channel 03/0 : 6[2] -> 10[2] [send] via NET/AWS Libfabric/2
 0: nid005574:69061:78922 [3] NCCL INFO Channel 07/0 : 3[3] -> 0[0] via P2P/CUMEM
14: nid005600:217721:227326 [1] NCCL INFO Channel 04/0 : 57[1] -> 56[0] via P2P/CUMEM
 9: nid005588:35937:45448 [2] NCCL INFO Channel 03/0 : 38[2] -> 39[3] via P2P/CUMEM
20: nid005913:292681:9616 [0] NCCL INFO Channel 00/0 : 80[0] -> 88[0] [send] via NET/AWS Libfabric/0
25: nid005919:107464:116998 [2] NCCL INFO Channel 03/0 : 102[2] -> 103[3] via P2P/CUMEM
27: nid005922:80741:90205 [0] NCCL INFO Channel 04/0 : 100[0] -> 108[0] [receive] via NET/AWS Libfabric/0
15: nid005601:210677:220274 [1] NCCL INFO Channel 03/0 : 61[1] -> 60[0] via P2P/CUMEM
23: nid005917:276886:286403 [1] NCCL INFO Channel 01/0 : 93[1] -> 92[0] via P2P/CUMEM
 6: nid005584:28287:37728 [2] NCCL INFO Channel 02/0 : 26[2] -> 27[3] via P2P/CUMEM
 6: nid005584:28285:37730 [0] NCCL INFO Channel 02/0 : 24[0] -> 25[1] via P2P/CUMEM
 1: nid005576:147560:157021 [3] NCCL INFO Channel 06/0 : 7[3] -> 4[0] via P2P/CUMEM
16: nid005802:6300:15960 [3] NCCL INFO Channel 02/0 : 67[3] -> 64[0] via P2P/CUMEM
13: nid005595:197883:207753 [0] NCCL INFO Channel 03/0 : 52[0] -> 53[1] via P2P/CUMEM
 5: nid005582:196714:206728 [1] NCCL INFO Channel 05/0 : 21[1] -> 20[0] via P2P/CUMEM
 1: nid005576:147559:157018 [2] NCCL INFO Channel 07/0 : 6[2] -> 10[2] [send] via NET/AWS Libfabric/2
 9: nid005588:35935:45450 [0] NCCL INFO Channel 02/0 : 36[0] -> 37[1] via P2P/CUMEM
15: nid005601:210679:220273 [3] NCCL INFO Channel 07/0 : 63[3] -> 60[0] via P2P/CUMEM
 7: nid005585:122008:131442 [3] NCCL INFO Channel 02/0 : 31[3] -> 28[0] via P2P/CUMEM
 4: nid005581:264526:274017 [3] NCCL INFO Channel 07/0 : 19[3] -> 16[0] via P2P/CUMEM
15: nid005601:210676:220272 [0] NCCL INFO Channel 04/0 : 28[0] -> 60[0] [receive] via NET/AWS Libfabric/0
20: nid005913:292684:9617 [3] NCCL INFO Channel 03/0 : 83[3] -> 80[0] via P2P/CUMEM
18: nid005911:38867:48386 [3] NCCL INFO Channel 03/0 : 75[3] -> 72[0] via P2P/CUMEM
21: nid005914:166785:176254 [1] NCCL INFO Channel 07/0 : 85[1] -> 84[0] via P2P/CUMEM
 7: nid005585:122005:131445 [0] NCCL INFO Channel 04/0 : 28[0] -> 29[1] via P2P/CUMEM
13: nid005595:197886:207752 [3] NCCL INFO Channel 02/0 : 55[3] -> 52[0] via P2P/CUMEM
20: nid005913:292682:9618 [1] NCCL INFO Channel 00/0 : 81[1] -> 80[0] via P2P/CUMEM
27: nid005922:80741:90205 [0] NCCL INFO Channel 05/0 : 100[0] -> 108[0] [receive] via NET/AWS Libfabric/0
12: nid005594:53086:62619 [1] NCCL INFO Channel 05/0 : 49[1] -> 50[2] via P2P/CUMEM
20: nid005913:292683:9619 [2] NCCL INFO Channel 02/0 : 74[2] -> 82[2] [receive] via NET/AWS Libfabric/2
14: nid005600:217721:227326 [1] NCCL INFO Channel 06/0 : 57[1] -> 56[0] via P2P/CUMEM
 1: nid005576:147557:157020 [0] NCCL INFO Channel 04/0 : 4[0] -> 12[0] [send] via NET/AWS Libfabric/0
15: nid005601:210676:220272 [0] NCCL INFO Channel 05/0 : 28[0] -> 60[0] [receive] via NET/AWS Libfabric/0
20: nid005913:292683:9619 [2] NCCL INFO Channel 03/0 : 74[2] -> 82[2] [receive] via NET/AWS Libfabric/2
26: nid005920:67124:76629 [1] NCCL INFO Channel 00/0 : 105[1] -> 104[0] via P2P/CUMEM
23: nid005917:276886:286403 [1] NCCL INFO Channel 03/0 : 93[1] -> 92[0] via P2P/CUMEM
 0: nid005574:69058:78920 [0] NCCL INFO Channel 00/0 : 64[0] -> 0[0] [receive] via NET/AWS Libfabric/0
 2: nid005577:17422:27010 [0] NCCL INFO Channel 00/0 : 8[0] -> 16[0] [send] via NET/AWS Libfabric/0
16: nid005802:6299:15959 [2] NCCL INFO Channel 06/0 : 66[2] -> 70[2] [send] via NET/AWS Libfabric/2
27: nid005922:80741:90205 [0] NCCL INFO Channel 04/0 : 108[0] -> 116[0] [send] via NET/AWS Libfabric/0
 0: nid005574:69059:78919 [1] NCCL INFO Channel 04/0 : 1[1] -> 0[0] via P2P/CUMEM
 1: nid005576:147557:157020 [0] NCCL INFO Channel 05/0 : 4[0] -> 12[0] [send] via NET/AWS Libfabric/0
15: nid005601:210676:220272 [0] NCCL INFO Channel 04/0 : 60[0] -> 92[0] [send] via NET/AWS Libfabric/0
 5: nid005582:196714:206728 [1] NCCL INFO Channel 07/0 : 21[1] -> 20[0] via P2P/CUMEM
 7: nid005585:122007:131444 [2] NCCL INFO Channel 02/0 : 26[2] -> 30[2] [receive] via NET/AWS Libfabric/2
20: nid005913:292683:9619 [2] NCCL INFO Channel 02/0 : 82[2] -> 90[2] [send] via NET/AWS Libfabric/2
20: nid005913:292681:9616 [0] NCCL INFO Channel 01/0 : 80[0] -> 88[0] [send] via NET/AWS Libfabric/0
27: nid005922:80741:90205 [0] NCCL INFO Channel 05/0 : 108[0] -> 116[0] [send] via NET/AWS Libfabric/0
 0: nid005574:69058:78920 [0] NCCL INFO Channel 01/0 : 64[0] -> 0[0] [receive] via NET/AWS Libfabric/0
 2: nid005577:17422:27010 [0] NCCL INFO Channel 01/0 : 8[0] -> 16[0] [send] via NET/AWS Libfabric/0
15: nid005601:210676:220272 [0] NCCL INFO Channel 05/0 : 60[0] -> 92[0] [send] via NET/AWS Libfabric/0
 7: nid005585:122008:131442 [3] NCCL INFO Channel 03/0 : 31[3] -> 28[0] via P2P/CUMEM
13: nid005595:197883:207753 [0] NCCL INFO Channel 04/0 : 52[0] -> 53[1] via P2P/CUMEM
25: nid005919:107463:116996 [1] NCCL INFO Channel 00/0 : 101[1] -> 102[2] via P2P/CUMEM
 1: nid005576:147558:157019 [1] NCCL INFO Channel 01/0 : 5[1] -> 4[0] via P2P/CUMEM
13: nid005595:197886:207752 [3] NCCL INFO Channel 03/0 : 55[3] -> 52[0] via P2P/CUMEM
25: nid005919:107462:116999 [0] NCCL INFO Channel 04/0 : 100[0] -> 101[1] via P2P/CUMEM
23: nid005917:276886:286403 [1] NCCL INFO Channel 05/0 : 93[1] -> 92[0] via P2P/CUMEM
 0: nid005574:69058:78920 [0] NCCL INFO Channel 00/0 : 0[0] -> 64[0] [send] via NET/AWS Libfabric/0
15: nid005601:210677:220274 [1] NCCL INFO Channel 05/0 : 61[1] -> 60[0] via P2P/CUMEM
30: nid005936:49911:59407 [3] NCCL INFO Channel 02/0 : 123[3] -> 120[0] via P2P/CUMEM
16: nid005802:6300:15960 [3] NCCL INFO Channel 03/0 : 67[3] -> 64[0] via P2P/CUMEM
20: nid005913:292683:9619 [2] NCCL INFO Channel 03/0 : 82[2] -> 90[2] [send] via NET/AWS Libfabric/2
26: nid005920:67124:76629 [1] NCCL INFO Channel 02/0 : 105[1] -> 104[0] via P2P/CUMEM
 0: nid005574:69060:78921 [2] NCCL INFO Channel 02/0 : 66[2] -> 2[2] [receive] via NET/AWS Libfabric/2
16: nid005802:6298:15958 [1] NCCL INFO Channel 00/0 : 65[1] -> 64[0] via P2P/CUMEM
20: nid005913:292684:9617 [3] NCCL INFO Channel 06/0 : 83[3] -> 80[0] via P2P/CUMEM
 0: nid005574:69059:78919 [1] NCCL INFO Channel 06/0 : 1[1] -> 0[0] via P2P/CUMEM
 1: nid005576:147560:157021 [3] NCCL INFO Channel 07/0 : 7[3] -> 4[0] via P2P/CUMEM
13: nid005595:197885:207750 [2] NCCL INFO Channel 06/0 : 50[2] -> 54[2] [receive] via NET/AWS Libfabric/2
20: nid005913:292682:9618 [1] NCCL INFO Channel 02/0 : 81[1] -> 80[0] via P2P/CUMEM
 0: nid005574:69058:78920 [0] NCCL INFO Channel 01/0 : 0[0] -> 64[0] [send] via NET/AWS Libfabric/0
 1: nid005576:147559:157018 [2] NCCL INFO Channel 06/0 : 6[2] -> 14[2] [send] via NET/AWS Libfabric/2
16: nid005802:6299:15959 [2] NCCL INFO Channel 02/0 : 34[2] -> 66[2] [receive] via NET/AWS Libfabric/2
 7: nid005585:122008:131442 [3] NCCL INFO Channel 06/0 : 31[3] -> 28[0] via P2P/CUMEM
 7: nid005585:122005:131445 [0] NCCL INFO Channel 06/0 : 28[0] -> 29[1] via P2P/CUMEM
23: nid005917:276886:286403 [1] NCCL INFO Channel 07/0 : 93[1] -> 92[0] via P2P/CUMEM
 1: nid005576:147557:157020 [0] NCCL INFO Channel 04/0 : 12[0] -> 4[0] [receive] via NET/AWS Libfabric/0
25: nid005919:107464:116998 [2] NCCL INFO Channel 04/0 : 102[2] -> 103[3] via P2P/CUMEM
 2: nid005577:17424:27012 [2] NCCL INFO Channel 02/0 : 10[2] -> 18[2] [send] via NET/AWS Libfabric/2
 1: nid005576:147559:157018 [2] NCCL INFO Channel 07/0 : 6[2] -> 14[2] [send] via NET/AWS Libfabric/2
 9: nid005588:35936:45447 [1] NCCL INFO Channel 04/0 : 37[1] -> 38[2] via P2P/CUMEM
16: nid005802:6299:15959 [2] NCCL INFO Channel 03/0 : 34[2] -> 66[2] [receive] via NET/AWS Libfabric/2
13: nid005595:197883:207753 [0] NCCL INFO Channel 06/0 : 52[0] -> 53[1] via P2P/CUMEM
13: nid005595:197885:207750 [2] NCCL INFO Channel 03/0 : 54[2] -> 58[2] [send] via NET/AWS Libfabric/2
 0: nid005574:69060:78921 [2] NCCL INFO Channel 03/0 : 66[2] -> 2[2] [receive] via NET/AWS Libfabric/2
 1: nid005576:147557:157020 [0] NCCL INFO Channel 05/0 : 12[0] -> 4[0] [receive] via NET/AWS Libfabric/0
 9: nid005588:35937:45448 [2] NCCL INFO Channel 04/0 : 38[2] -> 39[3] via P2P/CUMEM
15: nid005601:210677:220274 [1] NCCL INFO Channel 07/0 : 61[1] -> 60[0] via P2P/CUMEM
18: nid005911:38867:48386 [3] NCCL INFO Channel 06/0 : 75[3] -> 72[0] via P2P/CUMEM
26: nid005920:67124:76629 [1] NCCL INFO Channel 04/0 : 105[1] -> 104[0] via P2P/CUMEM
 2: nid005577:17424:27012 [2] NCCL INFO Channel 03/0 : 10[2] -> 18[2] [send] via NET/AWS Libfabric/2
16: nid005802:6299:15959 [2] NCCL INFO Channel 02/0 : 66[2] -> 98[2] [send] via NET/AWS Libfabric/2
13: nid005595:197886:207752 [3] NCCL INFO Channel 06/0 : 55[3] -> 52[0] via P2P/CUMEM
26: nid005920:67126:76631 [3] NCCL INFO Channel 02/0 : 107[3] -> 104[0] via P2P/CUMEM
 0: nid005574:69060:78921 [2] NCCL INFO Channel 02/0 : 2[2] -> 66[2] [send] via NET/AWS Libfabric/2
22: nid005915:274815:284313 [1] NCCL INFO Channel 01/0 : 89[1] -> 90[2] via P2P/CUMEM
31: nid005937:256591:266071 [2] NCCL INFO Channel 00/0 : 126[2] -> 127[3] via P2P/CUMEM
 0: nid005574:69060:78921 [2] NCCL INFO Channel 03/0 : 2[2] -> 66[2] [send] via NET/AWS Libfabric/2
 1: nid005576:147558:157019 [1] NCCL INFO Channel 03/0 : 5[1] -> 4[0] via P2P/CUMEM
16: nid005802:6299:15959 [2] NCCL INFO Channel 03/0 : 66[2] -> 98[2] [send] via NET/AWS Libfabric/2
 7: nid005585:122008:131442 [3] NCCL INFO Channel 07/0 : 31[3] -> 28[0] via P2P/CUMEM
13: nid005595:197885:207750 [2] NCCL INFO Channel 07/0 : 54[2] -> 58[2] [send] via NET/AWS Libfabric/2
20: nid005913:292684:9617 [3] NCCL INFO Channel 07/0 : 83[3] -> 80[0] via P2P/CUMEM
26: nid005920:67125:76630 [2] NCCL INFO Channel 03/0 : 102[2] -> 106[2] [receive] via NET/AWS Libfabric/2
30: nid005936:49911:59407 [3] NCCL INFO Channel 03/0 : 123[3] -> 120[0] via P2P/CUMEM
 6: nid005584:28287:37728 [2] NCCL INFO Channel 03/0 : 26[2] -> 27[3] via P2P/CUMEM
 1: nid005576:147559:157018 [2] NCCL INFO Channel 06/0 : 14[2] -> 6[2] [receive] via NET/AWS Libfabric/2
 7: nid005585:122005:131445 [0] NCCL INFO Channel 07/0 : 28[0] -> 29[1] via P2P/CUMEM
13: nid005595:197883:207753 [0] NCCL INFO Channel 07/0 : 52[0] -> 53[1] via P2P/CUMEM
20: nid005913:292682:9618 [1] NCCL INFO Channel 04/0 : 81[1] -> 80[0] via P2P/CUMEM
26: nid005920:67125:76630 [2] NCCL INFO Channel 07/0 : 102[2] -> 106[2] [receive] via NET/AWS Libfabric/2
 6: nid005584:28285:37730 [0] NCCL INFO Channel 03/0 : 24[0] -> 25[1] via P2P/CUMEM
22: nid005915:274815:284313 [1] NCCL INFO Channel 05/0 : 89[1] -> 90[2] via P2P/CUMEM
16: nid005802:6300:15960 [3] NCCL INFO Channel 06/0 : 67[3] -> 64[0] via P2P/CUMEM
13: nid005595:197886:207752 [3] NCCL INFO Channel 07/0 : 55[3] -> 52[0] via P2P/CUMEM
16: nid005802:6298:15958 [1] NCCL INFO Channel 02/0 : 65[1] -> 64[0] via P2P/CUMEM
26: nid005920:67125:76630 [2] NCCL INFO Channel 02/0 : 106[2] -> 110[2] [send] via NET/AWS Libfabric/2
 1: nid005576:147559:157018 [2] NCCL INFO Channel 07/0 : 14[2] -> 6[2] [receive] via NET/AWS Libfabric/2
26: nid005920:67124:76629 [1] NCCL INFO Channel 06/0 : 105[1] -> 104[0] via P2P/CUMEM
25: nid005919:107463:116996 [1] NCCL INFO Channel 04/0 : 101[1] -> 102[2] via P2P/CUMEM
12: nid005594:53085:62618 [0] NCCL INFO Channel 04/0 : 48[0] -> 52[0] [send] via NET/AWS Libfabric/0
26: nid005920:67126:76631 [3] NCCL INFO Channel 03/0 : 107[3] -> 104[0] via P2P/CUMEM
 1: nid005576:147558:157019 [1] NCCL INFO Channel 05/0 : 5[1] -> 4[0] via P2P/CUMEM
11: nid005591:191605:202358 [2] NCCL INFO Channel 04/0 : 46[2] -> 47[3] via P2P/CUMEM
12: nid005594:53088:62621 [3] NCCL INFO Channel 02/0 : 51[3] -> 48[0] via P2P/CUMEM
11: nid005591:191605:202358 [2] NCCL INFO Channel 06/0 : 46[2] -> 47[3] via P2P/CUMEM
11: nid005591:191604:202357 [1] NCCL INFO Channel 00/0 : 45[1] -> 46[2] via P2P/CUMEM
11: nid005591:191605:202358 [2] NCCL INFO Channel 07/0 : 46[2] -> 47[3] via P2P/CUMEM
11: nid005591:191604:202357 [1] NCCL INFO Channel 04/0 : 45[1] -> 46[2] via P2P/CUMEM
18: nid005911:38867:48386 [3] NCCL INFO Channel 07/0 : 75[3] -> 72[0] via P2P/CUMEM
11: nid005591:191606:202356 [3] NCCL INFO Channel 02/0 : 47[3] -> 44[0] via P2P/CUMEM
11: nid005591:191606:202356 [3] NCCL INFO Channel 03/0 : 47[3] -> 44[0] via P2P/CUMEM
20: nid005913:292682:9618 [1] NCCL INFO Channel 06/0 : 81[1] -> 80[0] via P2P/CUMEM
11: nid005591:191605:202358 [2] NCCL INFO Channel 02/0 : 42[2] -> 46[2] [receive] via NET/AWS Libfabric/2
25: nid005919:107462:116999 [0] NCCL INFO Channel 06/0 : 100[0] -> 101[1] via P2P/CUMEM
11: nid005591:191606:202356 [3] NCCL INFO Channel 06/0 : 47[3] -> 44[0] via P2P/CUMEM
14: nid005600:217722:227328 [2] NCCL INFO Channel 02/0 : 50[2] -> 58[2] [receive] via NET/AWS Libfabric/2
11: nid005591:191606:202356 [3] NCCL INFO Channel 07/0 : 47[3] -> 44[0] via P2P/CUMEM
12: nid005594:53087:62620 [2] NCCL INFO Channel 06/0 : 50[2] -> 54[2] [send] via NET/AWS Libfabric/2
 1: nid005576:147558:157019 [1] NCCL INFO Channel 07/0 : 5[1] -> 4[0] via P2P/CUMEM
30: nid005936:49909:59409 [1] NCCL INFO Channel 01/0 : 121[1] -> 122[2] via P2P/CUMEM
30: nid005936:49911:59407 [3] NCCL INFO Channel 06/0 : 123[3] -> 120[0] via P2P/CUMEM
24: nid005918:92506:102031 [2] NCCL INFO Channel 01/0 : 98[2] -> 99[3] via P2P/CUMEM
25: nid005919:107464:116998 [2] NCCL INFO Channel 06/0 : 102[2] -> 103[3] via P2P/CUMEM
24: nid005918:92504:102030 [0] NCCL INFO Channel 03/0 : 96[0] -> 97[1] via P2P/CUMEM
 9: nid005588:35937:45448 [2] NCCL INFO Channel 06/0 : 38[2] -> 39[3] via P2P/CUMEM
11: nid005591:191605:202358 [2] NCCL INFO Channel 06/0 : 38[2] -> 46[2] [receive] via NET/AWS Libfabric/2
12: nid005594:53088:62621 [3] NCCL INFO Channel 03/0 : 51[3] -> 48[0] via P2P/CUMEM
 4: nid005581:264524:274018 [1] NCCL INFO Channel 01/0 : 17[1] -> 18[2] via P2P/CUMEM
16: nid005802:6300:15960 [3] NCCL INFO Channel 07/0 : 67[3] -> 64[0] via P2P/CUMEM
14: nid005600:217722:227328 [2] NCCL INFO Channel 03/0 : 50[2] -> 58[2] [receive] via NET/AWS Libfabric/2
27: nid005922:80743:90206 [2] NCCL INFO Channel 06/0 : 102[2] -> 110[2] [receive] via NET/AWS Libfabric/2
31: nid005937:256591:266071 [2] NCCL INFO Channel 02/0 : 126[2] -> 127[3] via P2P/CUMEM
16: nid005802:6298:15958 [1] NCCL INFO Channel 04/0 : 65[1] -> 64[0] via P2P/CUMEM
11: nid005591:191605:202358 [2] NCCL INFO Channel 07/0 : 38[2] -> 46[2] [receive] via NET/AWS Libfabric/2
 9: nid005588:35935:45450 [0] NCCL INFO Channel 03/0 : 36[0] -> 37[1] via P2P/CUMEM
26: nid005920:67126:76631 [3] NCCL INFO Channel 06/0 : 107[3] -> 104[0] via P2P/CUMEM
27: nid005922:80743:90206 [2] NCCL INFO Channel 07/0 : 102[2] -> 110[2] [receive] via NET/AWS Libfabric/2
29: nid005932:167680:177152 [0] NCCL INFO Channel 02/0 : 116[0] -> 117[1] via P2P/CUMEM
12: nid005594:53087:62620 [2] NCCL INFO Channel 02/0 : 42[2] -> 50[2] [receive] via NET/AWS Libfabric/2
 8: nid005586:68926:78453 [0] NCCL INFO Channel 01/0 : 32[0] -> 33[1] via P2P/CUMEM
 6: nid005584:28287:37728 [2] NCCL INFO Channel 05/0 : 26[2] -> 27[3] via P2P/CUMEM
22: nid005915:274814:284312 [0] NCCL INFO Channel 01/0 : 84[0] -> 88[0] [receive] via NET/AWS Libfabric/0
 4: nid005581:264524:274018 [1] NCCL INFO Channel 05/0 : 17[1] -> 18[2] via P2P/CUMEM
13: nid005595:197885:207750 [2] NCCL INFO Channel 06/0 : 46[2] -> 54[2] [receive] via NET/AWS Libfabric/2
11: nid005591:191605:202358 [2] NCCL INFO Channel 06/0 : 46[2] -> 54[2] [send] via NET/AWS Libfabric/2
27: nid005922:80743:90206 [2] NCCL INFO Channel 06/0 : 110[2] -> 118[2] [send] via NET/AWS Libfabric/2
13: nid005595:197885:207750 [2] NCCL INFO Channel 07/0 : 46[2] -> 54[2] [receive] via NET/AWS Libfabric/2
11: nid005591:191605:202358 [2] NCCL INFO Channel 07/0 : 46[2] -> 54[2] [send] via NET/AWS Libfabric/2
12: nid005594:53087:62620 [2] NCCL INFO Channel 03/0 : 42[2] -> 50[2] [receive] via NET/AWS Libfabric/2
 7: nid005585:122005:131445 [0] NCCL INFO Channel 00/0 : 24[0] -> 28[0] [receive] via NET/AWS Libfabric/0
26: nid005920:67126:76631 [3] NCCL INFO Channel 07/0 : 107[3] -> 104[0] via P2P/CUMEM
27: nid005922:80743:90206 [2] NCCL INFO Channel 07/0 : 110[2] -> 118[2] [send] via NET/AWS Libfabric/2
 6: nid005584:28285:37730 [0] NCCL INFO Channel 05/0 : 24[0] -> 25[1] via P2P/CUMEM
12: nid005594:53087:62620 [2] NCCL INFO Channel 02/0 : 50[2] -> 58[2] [send] via NET/AWS Libfabric/2
25: nid005919:107462:116999 [0] NCCL INFO Channel 07/0 : 100[0] -> 101[1] via P2P/CUMEM
22: nid005915:274816:284311 [2] NCCL INFO Channel 03/0 : 86[2] -> 90[2] [receive] via NET/AWS Libfabric/2
22: nid005915:274814:284312 [0] NCCL INFO Channel 05/0 : 84[0] -> 88[0] [receive] via NET/AWS Libfabric/0
25: nid005919:107464:116998 [2] NCCL INFO Channel 07/0 : 102[2] -> 103[3] via P2P/CUMEM
30: nid005936:49909:59409 [1] NCCL INFO Channel 05/0 : 121[1] -> 122[2] via P2P/CUMEM
30: nid005936:49911:59407 [3] NCCL INFO Channel 07/0 : 123[3] -> 120[0] via P2P/CUMEM
12: nid005594:53088:62621 [3] NCCL INFO Channel 06/0 : 51[3] -> 48[0] via P2P/CUMEM
22: nid005915:274816:284311 [2] NCCL INFO Channel 07/0 : 86[2] -> 90[2] [receive] via NET/AWS Libfabric/2
13: nid005595:197883:207753 [0] NCCL INFO Channel 04/0 : 48[0] -> 52[0] [receive] via NET/AWS Libfabric/0
12: nid005594:53087:62620 [2] NCCL INFO Channel 03/0 : 50[2] -> 58[2] [send] via NET/AWS Libfabric/2
22: nid005915:274814:284312 [0] NCCL INFO Channel 00/0 : 88[0] -> 92[0] [send] via NET/AWS Libfabric/0
12: nid005594:53086:62619 [1] NCCL INFO Channel 00/0 : 49[1] -> 48[0] via P2P/CUMEM
16: nid005802:6298:15958 [1] NCCL INFO Channel 06/0 : 65[1] -> 64[0] via P2P/CUMEM
 7: nid005585:122006:131443 [1] NCCL INFO Channel 01/0 : 29[1] -> 28[0] via P2P/CUMEM
13: nid005595:197883:207753 [0] NCCL INFO Channel 01/0 : 52[0] -> 56[0] [send] via NET/AWS Libfabric/0
31: nid005937:256591:266071 [2] NCCL INFO Channel 03/0 : 126[2] -> 127[3] via P2P/CUMEM
 9: nid005588:35937:45448 [2] NCCL INFO Channel 07/0 : 38[2] -> 39[3] via P2P/CUMEM
22: nid005915:274816:284311 [2] NCCL INFO Channel 02/0 : 90[2] -> 94[2] [send] via NET/AWS Libfabric/2
11: nid005591:191603:202359 [0] NCCL INFO Channel 02/0 : 44[0] -> 45[1] via P2P/CUMEM
22: nid005915:274815:284313 [1] NCCL INFO Channel 00/0 : 89[1] -> 88[0] via P2P/CUMEM
13: nid005595:197883:207753 [0] NCCL INFO Channel 05/0 : 52[0] -> 56[0] [send] via NET/AWS Libfabric/0
21: nid005914:166784:176252 [0] NCCL INFO Channel 04/0 : 76[0] -> 84[0] [receive] via NET/AWS Libfabric/0
 7: nid005585:122006:131443 [1] NCCL INFO Channel 03/0 : 29[1] -> 28[0] via P2P/CUMEM
22: nid005915:274814:284312 [0] NCCL INFO Channel 00/0 : 80[0] -> 88[0] [receive] via NET/AWS Libfabric/0
 9: nid005588:35935:45450 [0] NCCL INFO Channel 04/0 : 36[0] -> 37[1] via P2P/CUMEM
13: nid005595:197884:207751 [1] NCCL INFO Channel 01/0 : 53[1] -> 52[0] via P2P/CUMEM
12: nid005594:53088:62621 [3] NCCL INFO Channel 07/0 : 51[3] -> 48[0] via P2P/CUMEM
 4: nid005581:264523:274015 [0] NCCL INFO Channel 04/0 : 16[0] -> 20[0] [send] via NET/AWS Libfabric/0
13: nid005595:197885:207750 [2] NCCL INFO Channel 06/0 : 54[2] -> 46[2] [send] via NET/AWS Libfabric/2
 8: nid005586:68926:78453 [0] NCCL INFO Channel 02/0 : 32[0] -> 33[1] via P2P/CUMEM
12: nid005594:53086:62619 [1] NCCL INFO Channel 02/0 : 49[1] -> 48[0] via P2P/CUMEM
21: nid005914:166784:176252 [0] NCCL INFO Channel 05/0 : 76[0] -> 84[0] [receive] via NET/AWS Libfabric/0
23: nid005917:276885:286402 [0] NCCL INFO Channel 04/0 : 76[0] -> 92[0] [receive] via NET/AWS Libfabric/0
22: nid005915:274815:284313 [1] NCCL INFO Channel 02/0 : 89[1] -> 88[0] via P2P/CUMEM
22: nid005915:274814:284312 [0] NCCL INFO Channel 01/0 : 80[0] -> 88[0] [receive] via NET/AWS Libfabric/0
 7: nid005585:122006:131443 [1] NCCL INFO Channel 05/0 : 29[1] -> 28[0] via P2P/CUMEM
13: nid005595:197885:207750 [2] NCCL INFO Channel 07/0 : 54[2] -> 46[2] [send] via NET/AWS Libfabric/2
14: nid005600:217722:227328 [2] NCCL INFO Channel 02/0 : 58[2] -> 50[2] [send] via NET/AWS Libfabric/2
 6: nid005584:28287:37728 [2] NCCL INFO Channel 06/0 : 26[2] -> 27[3] via P2P/CUMEM
 4: nid005581:264525:274016 [2] NCCL INFO Channel 06/0 : 18[2] -> 22[2] [send] via NET/AWS Libfabric/2
21: nid005914:166786:176251 [2] NCCL INFO Channel 06/0 : 78[2] -> 86[2] [receive] via NET/AWS Libfabric/2
23: nid005917:276885:286402 [0] NCCL INFO Channel 05/0 : 76[0] -> 92[0] [receive] via NET/AWS Libfabric/0
13: nid005595:197884:207751 [1] NCCL INFO Channel 03/0 : 53[1] -> 52[0] via P2P/CUMEM
14: nid005600:217722:227328 [2] NCCL INFO Channel 03/0 : 58[2] -> 50[2] [send] via NET/AWS Libfabric/2
25: nid005919:107465:116997 [3] NCCL INFO Channel 02/0 : 103[3] -> 100[0] via P2P/CUMEM
23: nid005917:276885:286402 [0] NCCL INFO Channel 04/0 : 92[0] -> 108[0] [send] via NET/AWS Libfabric/0
13: nid005595:197883:207753 [0] NCCL INFO Channel 04/0 : 44[0] -> 52[0] [receive] via NET/AWS Libfabric/0
25: nid005919:107462:116999 [0] NCCL INFO Channel 04/0 : 96[0] -> 100[0] [receive] via NET/AWS Libfabric/0
22: nid005915:274815:284313 [1] NCCL INFO Channel 04/0 : 89[1] -> 88[0] via P2P/CUMEM
12: nid005594:53085:62618 [0] NCCL INFO Channel 00/0 : 40[0] -> 48[0] [receive] via NET/AWS Libfabric/0
21: nid005914:166786:176251 [2] NCCL INFO Channel 07/0 : 78[2] -> 86[2] [receive] via NET/AWS Libfabric/2
14: nid005600:217720:227327 [0] NCCL INFO Channel 00/0 : 48[0] -> 56[0] [receive] via NET/AWS Libfabric/0
11: nid005591:191603:202359 [0] NCCL INFO Channel 03/0 : 44[0] -> 45[1] via P2P/CUMEM
 9: nid005588:35935:45450 [0] NCCL INFO Channel 06/0 : 36[0] -> 37[1] via P2P/CUMEM
 7: nid005585:122006:131443 [1] NCCL INFO Channel 07/0 : 29[1] -> 28[0] via P2P/CUMEM
18: nid005911:38865:48387 [1] NCCL INFO Channel 01/0 : 73[1] -> 74[2] via P2P/CUMEM
23: nid005917:276887:286401 [2] NCCL INFO Channel 06/0 : 78[2] -> 94[2] [receive] via NET/AWS Libfabric/2
24: nid005918:92506:102031 [2] NCCL INFO Channel 02/0 : 98[2] -> 99[3] via P2P/CUMEM
12: nid005594:53085:62618 [0] NCCL INFO Channel 01/0 : 40[0] -> 48[0] [receive] via NET/AWS Libfabric/0
13: nid005595:197883:207753 [0] NCCL INFO Channel 05/0 : 44[0] -> 52[0] [receive] via NET/AWS Libfabric/0
23: nid005917:276885:286402 [0] NCCL INFO Channel 05/0 : 92[0] -> 108[0] [send] via NET/AWS Libfabric/0
30: nid005936:49908:59406 [0] NCCL INFO Channel 01/0 : 116[0] -> 120[0] [receive] via NET/AWS Libfabric/0
14: nid005600:217720:227327 [0] NCCL INFO Channel 01/0 : 48[0] -> 56[0] [receive] via NET/AWS Libfabric/0
 6: nid005584:28285:37730 [0] NCCL INFO Channel 06/0 : 24[0] -> 25[1] via P2P/CUMEM
22: nid005915:274816:284311 [2] NCCL INFO Channel 02/0 : 82[2] -> 90[2] [receive] via NET/AWS Libfabric/2
 4: nid005581:264523:274015 [0] NCCL INFO Channel 00/0 : 8[0] -> 16[0] [receive] via NET/AWS Libfabric/0
25: nid005919:107462:116999 [0] NCCL INFO Channel 01/0 : 100[0] -> 104[0] [send] via NET/AWS Libfabric/0
23: nid005917:276887:286401 [2] NCCL INFO Channel 07/0 : 78[2] -> 94[2] [receive] via NET/AWS Libfabric/2
22: nid005915:274814:284312 [0] NCCL INFO Channel 00/0 : 88[0] -> 80[0] [send] via NET/AWS Libfabric/0
31: nid005937:256591:266071 [2] NCCL INFO Channel 04/0 : 126[2] -> 127[3] via P2P/CUMEM
24: nid005918:92504:102030 [0] NCCL INFO Channel 05/0 : 96[0] -> 97[1] via P2P/CUMEM
 4: nid005581:264525:274016 [2] NCCL INFO Channel 02/0 : 10[2] -> 18[2] [receive] via NET/AWS Libfabric/2
13: nid005595:197884:207751 [1] NCCL INFO Channel 05/0 : 53[1] -> 52[0] via P2P/CUMEM
23: nid005917:276887:286401 [2] NCCL INFO Channel 06/0 : 94[2] -> 110[2] [send] via NET/AWS Libfabric/2
22: nid005915:274815:284313 [1] NCCL INFO Channel 06/0 : 89[1] -> 88[0] via P2P/CUMEM
22: nid005915:274816:284311 [2] NCCL INFO Channel 03/0 : 82[2] -> 90[2] [receive] via NET/AWS Libfabric/2
12: nid005594:53085:62618 [0] NCCL INFO Channel 00/0 : 48[0] -> 56[0] [send] via NET/AWS Libfabric/0
 9: nid005588:35938:45449 [3] NCCL INFO Channel 02/0 : 39[3] -> 36[0] via P2P/CUMEM
18: nid005911:38865:48387 [1] NCCL INFO Channel 05/0 : 73[1] -> 74[2] via P2P/CUMEM
30: nid005936:49908:59406 [0] NCCL INFO Channel 05/0 : 116[0] -> 120[0] [receive] via NET/AWS Libfabric/0
 8: nid005586:68926:78453 [0] NCCL INFO Channel 03/0 : 32[0] -> 33[1] via P2P/CUMEM
22: nid005915:274814:284312 [0] NCCL INFO Channel 01/0 : 88[0] -> 80[0] [send] via NET/AWS Libfabric/0
12: nid005594:53086:62619 [1] NCCL INFO Channel 04/0 : 49[1] -> 48[0] via P2P/CUMEM
 4: nid005581:264523:274015 [0] NCCL INFO Channel 01/0 : 8[0] -> 16[0] [receive] via NET/AWS Libfabric/0
25: nid005919:107464:116998 [2] NCCL INFO Channel 06/0 : 98[2] -> 102[2] [receive] via NET/AWS Libfabric/2
23: nid005917:276887:286401 [2] NCCL INFO Channel 07/0 : 94[2] -> 110[2] [send] via NET/AWS Libfabric/2
 8: nid005586:68927:78452 [1] NCCL INFO Channel 01/0 : 33[1] -> 34[2] via P2P/CUMEM
11: nid005591:191603:202359 [0] NCCL INFO Channel 04/0 : 44[0] -> 45[1] via P2P/CUMEM
12: nid005594:53085:62618 [0] NCCL INFO Channel 01/0 : 48[0] -> 56[0] [send] via NET/AWS Libfabric/0
 4: nid005581:264524:274018 [1] NCCL INFO Channel 00/0 : 17[1] -> 16[0] via P2P/CUMEM
 4: nid005581:264525:274016 [2] NCCL INFO Channel 03/0 : 10[2] -> 18[2] [receive] via NET/AWS Libfabric/2
25: nid005919:107465:116997 [3] NCCL INFO Channel 03/0 : 103[3] -> 100[0] via P2P/CUMEM
30: nid005936:49910:59408 [2] NCCL INFO Channel 03/0 : 118[2] -> 122[2] [receive] via NET/AWS Libfabric/2
12: nid005594:53086:62619 [1] NCCL INFO Channel 06/0 : 49[1] -> 48[0] via P2P/CUMEM
 4: nid005581:264523:274015 [0] NCCL INFO Channel 00/0 : 16[0] -> 24[0] [send] via NET/AWS Libfabric/0
 9: nid005588:35935:45450 [0] NCCL INFO Channel 07/0 : 36[0] -> 37[1] via P2P/CUMEM
25: nid005919:107462:116999 [0] NCCL INFO Channel 05/0 : 100[0] -> 104[0] [send] via NET/AWS Libfabric/0
 4: nid005581:264525:274016 [2] NCCL INFO Channel 02/0 : 18[2] -> 26[2] [send] via NET/AWS Libfabric/2
13: nid005595:197884:207751 [1] NCCL INFO Channel 07/0 : 53[1] -> 52[0] via P2P/CUMEM
25: nid005919:107464:116998 [2] NCCL INFO Channel 03/0 : 102[2] -> 106[2] [send] via NET/AWS Libfabric/2
22: nid005915:274816:284311 [2] NCCL INFO Channel 02/0 : 90[2] -> 82[2] [send] via NET/AWS Libfabric/2
 4: nid005581:264524:274018 [1] NCCL INFO Channel 02/0 : 17[1] -> 16[0] via P2P/CUMEM
 9: nid005588:35937:45448 [2] NCCL INFO Channel 06/0 : 34[2] -> 38[2] [receive] via NET/AWS Libfabric/2
22: nid005915:274816:284311 [2] NCCL INFO Channel 03/0 : 90[2] -> 82[2] [send] via NET/AWS Libfabric/2
30: nid005936:49908:59406 [0] NCCL INFO Channel 00/0 : 120[0] -> 124[0] [send] via NET/AWS Libfabric/0
30: nid005936:49910:59408 [2] NCCL INFO Channel 07/0 : 118[2] -> 122[2] [receive] via NET/AWS Libfabric/2
 9: nid005588:35938:45449 [3] NCCL INFO Channel 03/0 : 39[3] -> 36[0] via P2P/CUMEM
25: nid005919:107464:116998 [2] NCCL INFO Channel 07/0 : 102[2] -> 106[2] [send] via NET/AWS Libfabric/2
 9: nid005588:35937:45448 [2] NCCL INFO Channel 03/0 : 38[2] -> 42[2] [send] via NET/AWS Libfabric/2
11: nid005591:191603:202359 [0] NCCL INFO Channel 06/0 : 44[0] -> 45[1] via P2P/CUMEM
29: nid005932:167680:177152 [0] NCCL INFO Channel 03/0 : 116[0] -> 117[1] via P2P/CUMEM
30: nid005936:49910:59408 [2] NCCL INFO Channel 02/0 : 122[2] -> 126[2] [send] via NET/AWS Libfabric/2
 4: nid005581:264525:274016 [2] NCCL INFO Channel 03/0 : 18[2] -> 26[2] [send] via NET/AWS Libfabric/2
29: nid005932:167682:177153 [2] NCCL INFO Channel 00/0 : 118[2] -> 119[3] via P2P/CUMEM
 4: nid005581:264524:274018 [1] NCCL INFO Channel 04/0 : 17[1] -> 16[0] via P2P/CUMEM
 4: nid005581:264523:274015 [0] NCCL INFO Channel 01/0 : 16[0] -> 24[0] [send] via NET/AWS Libfabric/0
30: nid005936:49909:59409 [1] NCCL INFO Channel 00/0 : 121[1] -> 120[0] via P2P/CUMEM
 6: nid005584:28287:37728 [2] NCCL INFO Channel 07/0 : 26[2] -> 27[3] via P2P/CUMEM
11: nid005591:191603:202359 [0] NCCL INFO Channel 07/0 : 44[0] -> 45[1] via P2P/CUMEM
 9: nid005588:35937:45448 [2] NCCL INFO Channel 07/0 : 38[2] -> 42[2] [send] via NET/AWS Libfabric/2
25: nid005919:107463:116996 [1] NCCL INFO Channel 01/0 : 101[1] -> 100[0] via P2P/CUMEM
25: nid005919:107465:116997 [3] NCCL INFO Channel 06/0 : 103[3] -> 100[0] via P2P/CUMEM
 6: nid005584:28285:37730 [0] NCCL INFO Channel 07/0 : 24[0] -> 25[1] via P2P/CUMEM
26: nid005920:67123:76628 [0] NCCL INFO Channel 00/0 : 104[0] -> 112[0] [send] via NET/AWS Libfabric/0
18: nid005911:38864:48384 [0] NCCL INFO Channel 01/0 : 68[0] -> 72[0] [receive] via NET/AWS Libfabric/0
26: nid005920:67123:76628 [0] NCCL INFO Channel 01/0 : 104[0] -> 112[0] [send] via NET/AWS Libfabric/0
31: nid005937:256591:266071 [2] NCCL INFO Channel 06/0 : 126[2] -> 127[3] via P2P/CUMEM
 4: nid005581:264524:274018 [1] NCCL INFO Channel 06/0 : 17[1] -> 16[0] via P2P/CUMEM
14: nid005600:217720:227327 [0] NCCL INFO Channel 00/0 : 56[0] -> 48[0] [send] via NET/AWS Libfabric/0
30: nid005936:49909:59409 [1] NCCL INFO Channel 02/0 : 121[1] -> 120[0] via P2P/CUMEM
 2: nid005577:17424:27012 [2] NCCL INFO Channel 02/0 : 18[2] -> 10[2] [receive] via NET/AWS Libfabric/2
 9: nid005588:35938:45449 [3] NCCL INFO Channel 06/0 : 39[3] -> 36[0] via P2P/CUMEM
26: nid005920:67125:76630 [2] NCCL INFO Channel 02/0 : 106[2] -> 114[2] [send] via NET/AWS Libfabric/2
14: nid005600:217720:227327 [0] NCCL INFO Channel 01/0 : 56[0] -> 48[0] [send] via NET/AWS Libfabric/0
18: nid005911:38864:48384 [0] NCCL INFO Channel 05/0 : 68[0] -> 72[0] [receive] via NET/AWS Libfabric/0
 2: nid005577:17422:27010 [0] NCCL INFO Channel 00/0 : 16[0] -> 8[0] [receive] via NET/AWS Libfabric/0
 8: nid005586:68926:78453 [0] NCCL INFO Channel 05/0 : 32[0] -> 33[1] via P2P/CUMEM
18: nid005911:38866:48385 [2] NCCL INFO Channel 03/0 : 70[2] -> 74[2] [receive] via NET/AWS Libfabric/2
24: nid005918:92506:102031 [2] NCCL INFO Channel 03/0 : 98[2] -> 99[3] via P2P/CUMEM
 2: nid005577:17424:27012 [2] NCCL INFO Channel 03/0 : 18[2] -> 10[2] [receive] via NET/AWS Libfabric/2
26: nid005920:67125:76630 [2] NCCL INFO Channel 03/0 : 106[2] -> 114[2] [send] via NET/AWS Libfabric/2
 2: nid005577:17422:27010 [0] NCCL INFO Channel 01/0 : 16[0] -> 8[0] [receive] via NET/AWS Libfabric/0
30: nid005936:49909:59409 [1] NCCL INFO Channel 04/0 : 121[1] -> 120[0] via P2P/CUMEM
 9: nid005588:35938:45449 [3] NCCL INFO Channel 07/0 : 39[3] -> 36[0] via P2P/CUMEM
18: nid005911:38866:48385 [2] NCCL INFO Channel 07/0 : 70[2] -> 74[2] [receive] via NET/AWS Libfabric/2
24: nid005918:92504:102030 [0] NCCL INFO Channel 06/0 : 96[0] -> 97[1] via P2P/CUMEM
25: nid005919:107463:116996 [1] NCCL INFO Channel 03/0 : 101[1] -> 100[0] via P2P/CUMEM
 8: nid005586:68927:78452 [1] NCCL INFO Channel 05/0 : 33[1] -> 34[2] via P2P/CUMEM
25: nid005919:107465:116997 [3] NCCL INFO Channel 07/0 : 103[3] -> 100[0] via P2P/CUMEM
18: nid005911:38864:48384 [0] NCCL INFO Channel 00/0 : 72[0] -> 76[0] [send] via NET/AWS Libfabric/0
10: nid005590:110712:120160 [2] NCCL INFO Channel 02/0 : 42[2] -> 50[2] [send] via NET/AWS Libfabric/2
18: nid005911:38866:48385 [2] NCCL INFO Channel 02/0 : 74[2] -> 78[2] [send] via NET/AWS Libfabric/2
30: nid005936:49909:59409 [1] NCCL INFO Channel 06/0 : 121[1] -> 120[0] via P2P/CUMEM
10: nid005590:110712:120160 [2] NCCL INFO Channel 03/0 : 42[2] -> 50[2] [send] via NET/AWS Libfabric/2
18: nid005911:38865:48387 [1] NCCL INFO Channel 00/0 : 73[1] -> 72[0] via P2P/CUMEM
11: nid005591:191603:202359 [0] NCCL INFO Channel 00/0 : 40[0] -> 44[0] [receive] via NET/AWS Libfabric/0
31: nid005937:256590:266072 [1] NCCL INFO Channel 00/0 : 125[1] -> 126[2] via P2P/CUMEM
18: nid005911:38865:48387 [1] NCCL INFO Channel 02/0 : 73[1] -> 72[0] via P2P/CUMEM
31: nid005937:256591:266071 [2] NCCL INFO Channel 07/0 : 126[2] -> 127[3] via P2P/CUMEM
10: nid005590:110712:120160 [2] NCCL INFO Channel 02/0 : 50[2] -> 42[2] [receive] via NET/AWS Libfabric/2
12: nid005594:53087:62620 [2] NCCL INFO Channel 02/0 : 34[2] -> 50[2] [receive] via NET/AWS Libfabric/2
17: nid005803:180732:190254 [0] NCCL INFO Channel 04/0 : 68[0] -> 76[0] [send] via NET/AWS Libfabric/0
25: nid005919:107463:116996 [1] NCCL INFO Channel 05/0 : 101[1] -> 100[0] via P2P/CUMEM
17: nid005803:180734:190257 [2] NCCL INFO Channel 06/0 : 70[2] -> 78[2] [send] via NET/AWS Libfabric/2
12: nid005594:53087:62620 [2] NCCL INFO Channel 03/0 : 34[2] -> 50[2] [receive] via NET/AWS Libfabric/2
17: nid005803:180732:190254 [0] NCCL INFO Channel 05/0 : 68[0] -> 76[0] [send] via NET/AWS Libfabric/0
18: nid005911:38864:48384 [0] NCCL INFO Channel 00/0 : 72[0] -> 80[0] [send] via NET/AWS Libfabric/0
18: nid005911:38865:48387 [1] NCCL INFO Channel 04/0 : 73[1] -> 72[0] via P2P/CUMEM
10: nid005590:110712:120160 [2] NCCL INFO Channel 03/0 : 50[2] -> 42[2] [receive] via NET/AWS Libfabric/2
 6: nid005584:28288:37729 [3] NCCL INFO Channel 02/0 : 27[3] -> 24[0] via P2P/CUMEM
11: nid005591:191604:202357 [1] NCCL INFO Channel 01/0 : 45[1] -> 44[0] via P2P/CUMEM
17: nid005803:180734:190257 [2] NCCL INFO Channel 07/0 : 70[2] -> 78[2] [send] via NET/AWS Libfabric/2
29: nid005932:167682:177153 [2] NCCL INFO Channel 02/0 : 118[2] -> 119[3] via P2P/CUMEM
29: nid005932:167680:177152 [0] NCCL INFO Channel 04/0 : 116[0] -> 117[1] via P2P/CUMEM
 8: nid005586:68926:78453 [0] NCCL INFO Channel 06/0 : 32[0] -> 33[1] via P2P/CUMEM
 6: nid005584:28286:37731 [1] NCCL INFO Channel 01/0 : 25[1] -> 26[2] via P2P/CUMEM
11: nid005591:191603:202359 [0] NCCL INFO Channel 04/0 : 36[0] -> 44[0] [receive] via NET/AWS Libfabric/0
25: nid005919:107463:116996 [1] NCCL INFO Channel 07/0 : 101[1] -> 100[0] via P2P/CUMEM
18: nid005911:38866:48385 [2] NCCL INFO Channel 02/0 : 74[2] -> 82[2] [send] via NET/AWS Libfabric/2
18: nid005911:38864:48384 [0] NCCL INFO Channel 01/0 : 72[0] -> 80[0] [send] via NET/AWS Libfabric/0
 9: nid005588:35935:45450 [0] NCCL INFO Channel 04/0 : 32[0] -> 36[0] [receive] via NET/AWS Libfabric/0
18: nid005911:38865:48387 [1] NCCL INFO Channel 06/0 : 73[1] -> 72[0] via P2P/CUMEM
11: nid005591:191604:202357 [1] NCCL INFO Channel 03/0 : 45[1] -> 44[0] via P2P/CUMEM
11: nid005591:191603:202359 [0] NCCL INFO Channel 05/0 : 36[0] -> 44[0] [receive] via NET/AWS Libfabric/0
18: nid005911:38866:48385 [2] NCCL INFO Channel 03/0 : 74[2] -> 82[2] [send] via NET/AWS Libfabric/2
19: nid005912:12435:21904 [0] NCCL INFO Channel 04/0 : 68[0] -> 76[0] [receive] via NET/AWS Libfabric/0
19: nid005912:12437:21903 [2] NCCL INFO Channel 06/0 : 70[2] -> 78[2] [receive] via NET/AWS Libfabric/2
11: nid005591:191603:202359 [0] NCCL INFO Channel 04/0 : 44[0] -> 52[0] [send] via NET/AWS Libfabric/0
 9: nid005588:35935:45450 [0] NCCL INFO Channel 01/0 : 36[0] -> 40[0] [send] via NET/AWS Libfabric/0
24: nid005918:92506:102031 [2] NCCL INFO Channel 05/0 : 98[2] -> 99[3] via P2P/CUMEM
 6: nid005584:28288:37729 [3] NCCL INFO Channel 03/0 : 27[3] -> 24[0] via P2P/CUMEM
 9: nid005588:35936:45447 [1] NCCL INFO Channel 01/0 : 37[1] -> 36[0] via P2P/CUMEM
11: nid005591:191604:202357 [1] NCCL INFO Channel 05/0 : 45[1] -> 44[0] via P2P/CUMEM
19: nid005912:12437:21903 [2] NCCL INFO Channel 07/0 : 70[2] -> 78[2] [receive] via NET/AWS Libfabric/2
11: nid005591:191603:202359 [0] NCCL INFO Channel 05/0 : 44[0] -> 52[0] [send] via NET/AWS Libfabric/0
19: nid005912:12435:21904 [0] NCCL INFO Channel 05/0 : 68[0] -> 76[0] [receive] via NET/AWS Libfabric/0
 6: nid005584:28286:37731 [1] NCCL INFO Channel 05/0 : 25[1] -> 26[2] via P2P/CUMEM
20: nid005913:292681:9616 [0] NCCL INFO Channel 00/0 : 80[0] -> 96[0] [send] via NET/AWS Libfabric/0
24: nid005918:92504:102030 [0] NCCL INFO Channel 07/0 : 96[0] -> 97[1] via P2P/CUMEM
18: nid005911:38864:48384 [0] NCCL INFO Channel 00/0 : 80[0] -> 72[0] [receive] via NET/AWS Libfabric/0
31: nid005937:256590:266072 [1] NCCL INFO Channel 04/0 : 125[1] -> 126[2] via P2P/CUMEM
19: nid005912:12437:21903 [2] NCCL INFO Channel 06/0 : 78[2] -> 86[2] [send] via NET/AWS Libfabric/2
19: nid005912:12435:21904 [0] NCCL INFO Channel 04/0 : 76[0] -> 84[0] [send] via NET/AWS Libfabric/0
18: nid005911:38864:48384 [0] NCCL INFO Channel 01/0 : 80[0] -> 72[0] [receive] via NET/AWS Libfabric/0
 8: nid005586:68928:78455 [2] NCCL INFO Channel 01/0 : 34[2] -> 35[3] via P2P/CUMEM
 9: nid005588:35936:45447 [1] NCCL INFO Channel 03/0 : 37[1] -> 36[0] via P2P/CUMEM
18: nid005911:38866:48385 [2] NCCL INFO Channel 02/0 : 82[2] -> 74[2] [receive] via NET/AWS Libfabric/2
 8: nid005586:68926:78453 [0] NCCL INFO Channel 07/0 : 32[0] -> 33[1] via P2P/CUMEM
11: nid005591:191604:202357 [1] NCCL INFO Channel 07/0 : 45[1] -> 44[0] via P2P/CUMEM
20: nid005913:292683:9619 [2] NCCL INFO Channel 02/0 : 82[2] -> 98[2] [send] via NET/AWS Libfabric/2
19: nid005912:12437:21903 [2] NCCL INFO Channel 07/0 : 78[2] -> 86[2] [send] via NET/AWS Libfabric/2
 9: nid005588:35935:45450 [0] NCCL INFO Channel 05/0 : 36[0] -> 40[0] [send] via NET/AWS Libfabric/0
20: nid005913:292681:9616 [0] NCCL INFO Channel 01/0 : 80[0] -> 96[0] [send] via NET/AWS Libfabric/0
18: nid005911:38866:48385 [2] NCCL INFO Channel 03/0 : 82[2] -> 74[2] [receive] via NET/AWS Libfabric/2
20: nid005913:292683:9619 [2] NCCL INFO Channel 03/0 : 82[2] -> 98[2] [send] via NET/AWS Libfabric/2
19: nid005912:12435:21904 [0] NCCL INFO Channel 05/0 : 76[0] -> 84[0] [send] via NET/AWS Libfabric/0
 6: nid005584:28288:37729 [3] NCCL INFO Channel 06/0 : 27[3] -> 24[0] via P2P/CUMEM
 9: nid005588:35936:45447 [1] NCCL INFO Channel 05/0 : 37[1] -> 36[0] via P2P/CUMEM
13: nid005595:197883:207753 [0] NCCL INFO Channel 04/0 : 52[0] -> 44[0] [send] via NET/AWS Libfabric/0
31: nid005937:256592:266073 [3] NCCL INFO Channel 02/0 : 127[3] -> 124[0] via P2P/CUMEM
 9: nid005588:35936:45447 [1] NCCL INFO Channel 07/0 : 37[1] -> 36[0] via P2P/CUMEM
13: nid005595:197883:207753 [0] NCCL INFO Channel 05/0 : 52[0] -> 44[0] [send] via NET/AWS Libfabric/0
17: nid005803:180734:190257 [2] NCCL INFO Channel 06/0 : 78[2] -> 70[2] [receive] via NET/AWS Libfabric/2
 6: nid005584:28288:37729 [3] NCCL INFO Channel 07/0 : 27[3] -> 24[0] via P2P/CUMEM
17: nid005803:180732:190254 [0] NCCL INFO Channel 04/0 : 76[0] -> 68[0] [receive] via NET/AWS Libfabric/0
29: nid005932:167682:177153 [2] NCCL INFO Channel 03/0 : 118[2] -> 119[3] via P2P/CUMEM
17: nid005803:180734:190257 [2] NCCL INFO Channel 07/0 : 78[2] -> 70[2] [receive] via NET/AWS Libfabric/2
21: nid005914:166786:176251 [2] NCCL INFO Channel 06/0 : 86[2] -> 78[2] [send] via NET/AWS Libfabric/2
17: nid005803:180732:190254 [0] NCCL INFO Channel 05/0 : 76[0] -> 68[0] [receive] via NET/AWS Libfabric/0
10: nid005590:110710:120158 [0] NCCL INFO Channel 00/0 : 40[0] -> 48[0] [send] via NET/AWS Libfabric/0
 8: nid005586:68928:78455 [2] NCCL INFO Channel 02/0 : 34[2] -> 35[3] via P2P/CUMEM
21: nid005914:166784:176252 [0] NCCL INFO Channel 04/0 : 84[0] -> 76[0] [send] via NET/AWS Libfabric/0
29: nid005932:167680:177152 [0] NCCL INFO Channel 06/0 : 116[0] -> 117[1] via P2P/CUMEM
31: nid005937:256592:266073 [3] NCCL INFO Channel 03/0 : 127[3] -> 124[0] via P2P/CUMEM
19: nid005912:12437:21903 [2] NCCL INFO Channel 06/0 : 78[2] -> 94[2] [send] via NET/AWS Libfabric/2
19: nid005912:12435:21904 [0] NCCL INFO Channel 04/0 : 76[0] -> 92[0] [send] via NET/AWS Libfabric/0
31: nid005937:256589:266070 [0] NCCL INFO Channel 00/0 : 120[0] -> 124[0] [receive] via NET/AWS Libfabric/0
10: nid005590:110710:120158 [0] NCCL INFO Channel 01/0 : 40[0] -> 48[0] [send] via NET/AWS Libfabric/0
21: nid005914:166786:176251 [2] NCCL INFO Channel 07/0 : 86[2] -> 78[2] [send] via NET/AWS Libfabric/2
21: nid005914:166784:176252 [0] NCCL INFO Channel 05/0 : 84[0] -> 76[0] [send] via NET/AWS Libfabric/0
31: nid005937:256591:266071 [2] NCCL INFO Channel 02/0 : 122[2] -> 126[2] [receive] via NET/AWS Libfabric/2
19: nid005912:12435:21904 [0] NCCL INFO Channel 05/0 : 76[0] -> 92[0] [send] via NET/AWS Libfabric/0
19: nid005912:12437:21903 [2] NCCL INFO Channel 07/0 : 78[2] -> 94[2] [send] via NET/AWS Libfabric/2
 6: nid005584:28285:37730 [0] NCCL INFO Channel 01/0 : 20[0] -> 24[0] [receive] via NET/AWS Libfabric/0
24: nid005918:92506:102031 [2] NCCL INFO Channel 06/0 : 98[2] -> 99[3] via P2P/CUMEM
 6: nid005584:28287:37728 [2] NCCL INFO Channel 03/0 : 22[2] -> 26[2] [receive] via NET/AWS Libfabric/2
24: nid005918:92505:102033 [1] NCCL INFO Channel 01/0 : 97[1] -> 98[2] via P2P/CUMEM
 6: nid005584:28285:37730 [0] NCCL INFO Channel 05/0 : 20[0] -> 24[0] [receive] via NET/AWS Libfabric/0
10: nid005590:110710:120158 [0] NCCL INFO Channel 00/0 : 48[0] -> 40[0] [receive] via NET/AWS Libfabric/0
12: nid005594:53085:62618 [0] NCCL INFO Channel 00/0 : 32[0] -> 48[0] [receive] via NET/AWS Libfabric/0
 6: nid005584:28287:37728 [2] NCCL INFO Channel 07/0 : 22[2] -> 26[2] [receive] via NET/AWS Libfabric/2
31: nid005937:256592:266073 [3] NCCL INFO Channel 06/0 : 127[3] -> 124[0] via P2P/CUMEM
19: nid005912:12435:21904 [0] NCCL INFO Channel 04/0 : 92[0] -> 76[0] [receive] via NET/AWS Libfabric/0
10: nid005590:110710:120158 [0] NCCL INFO Channel 01/0 : 48[0] -> 40[0] [receive] via NET/AWS Libfabric/0
12: nid005594:53085:62618 [0] NCCL INFO Channel 01/0 : 32[0] -> 48[0] [receive] via NET/AWS Libfabric/0
19: nid005912:12437:21903 [2] NCCL INFO Channel 06/0 : 94[2] -> 78[2] [receive] via NET/AWS Libfabric/2
 8: nid005586:68928:78455 [2] NCCL INFO Channel 03/0 : 34[2] -> 35[3] via P2P/CUMEM
 8: nid005586:68926:78453 [0] NCCL INFO Channel 04/0 : 32[0] -> 36[0] [send] via NET/AWS Libfabric/0
 6: nid005584:28287:37728 [2] NCCL INFO Channel 02/0 : 26[2] -> 30[2] [send] via NET/AWS Libfabric/2
19: nid005912:12435:21904 [0] NCCL INFO Channel 05/0 : 92[0] -> 76[0] [receive] via NET/AWS Libfabric/0
31: nid005937:256591:266071 [2] NCCL INFO Channel 06/0 : 62[2] -> 126[2] [receive] via NET/AWS Libfabric/2
31: nid005937:256589:266070 [0] NCCL INFO Channel 04/0 : 60[0] -> 124[0] [receive] via NET/AWS Libfabric/0
19: nid005912:12437:21903 [2] NCCL INFO Channel 07/0 : 94[2] -> 78[2] [receive] via NET/AWS Libfabric/2
 6: nid005584:28285:37730 [0] NCCL INFO Channel 00/0 : 24[0] -> 28[0] [send] via NET/AWS Libfabric/0
31: nid005937:256591:266071 [2] NCCL INFO Channel 07/0 : 62[2] -> 126[2] [receive] via NET/AWS Libfabric/2
31: nid005937:256589:266070 [0] NCCL INFO Channel 05/0 : 60[0] -> 124[0] [receive] via NET/AWS Libfabric/0
 6: nid005584:28286:37731 [1] NCCL INFO Channel 00/0 : 25[1] -> 24[0] via P2P/CUMEM
31: nid005937:256591:266071 [2] NCCL INFO Channel 06/0 : 126[2] -> 62[2] [send] via NET/AWS Libfabric/2
31: nid005937:256592:266073 [3] NCCL INFO Channel 07/0 : 127[3] -> 124[0] via P2P/CUMEM
 9: nid005588:35935:45450 [0] NCCL INFO Channel 04/0 : 36[0] -> 44[0] [send] via NET/AWS Libfabric/0
 8: nid005586:68926:78453 [0] NCCL INFO Channel 00/0 : 16[0] -> 32[0] [receive] via NET/AWS Libfabric/0
 5: nid005582:196715:206731 [2] NCCL INFO Channel 06/0 : 14[2] -> 22[2] [receive] via NET/AWS Libfabric/2
31: nid005937:256589:266070 [0] NCCL INFO Channel 04/0 : 124[0] -> 60[0] [send] via NET/AWS Libfabric/0
31: nid005937:256590:266072 [1] NCCL INFO Channel 01/0 : 125[1] -> 124[0] via P2P/CUMEM
31: nid005937:256591:266071 [2] NCCL INFO Channel 07/0 : 126[2] -> 62[2] [send] via NET/AWS Libfabric/2
24: nid005918:92506:102031 [2] NCCL INFO Channel 07/0 : 98[2] -> 99[3] via P2P/CUMEM
24: nid005918:92505:102033 [1] NCCL INFO Channel 05/0 : 97[1] -> 98[2] via P2P/CUMEM
 5: nid005582:196715:206731 [2] NCCL INFO Channel 07/0 : 14[2] -> 22[2] [receive] via NET/AWS Libfabric/2
 6: nid005584:28286:37731 [1] NCCL INFO Channel 02/0 : 25[1] -> 24[0] via P2P/CUMEM
 9: nid005588:35935:45450 [0] NCCL INFO Channel 05/0 : 36[0] -> 44[0] [send] via NET/AWS Libfabric/0
 8: nid005586:68926:78453 [0] NCCL INFO Channel 01/0 : 16[0] -> 32[0] [receive] via NET/AWS Libfabric/0
31: nid005937:256589:266070 [0] NCCL INFO Channel 05/0 : 124[0] -> 60[0] [send] via NET/AWS Libfabric/0
29: nid005932:167682:177153 [2] NCCL INFO Channel 04/0 : 118[2] -> 119[3] via P2P/CUMEM
 8: nid005586:68928:78455 [2] NCCL INFO Channel 05/0 : 34[2] -> 35[3] via P2P/CUMEM
 7: nid005585:122007:131444 [2] NCCL INFO Channel 06/0 : 14[2] -> 30[2] [receive] via NET/AWS Libfabric/2
 6: nid005584:28287:37728 [2] NCCL INFO Channel 02/0 : 18[2] -> 26[2] [receive] via NET/AWS Libfabric/2
 5: nid005582:196713:206729 [0] NCCL INFO Channel 04/0 : 12[0] -> 20[0] [receive] via NET/AWS Libfabric/0
 8: nid005586:68926:78453 [0] NCCL INFO Channel 00/0 : 32[0] -> 48[0] [send] via NET/AWS Libfabric/0
 5: nid005582:196713:206729 [0] NCCL INFO Channel 05/0 : 12[0] -> 20[0] [receive] via NET/AWS Libfabric/0
29: nid005932:167680:177152 [0] NCCL INFO Channel 07/0 : 116[0] -> 117[1] via P2P/CUMEM
 6: nid005584:28286:37731 [1] NCCL INFO Channel 04/0 : 25[1] -> 24[0] via P2P/CUMEM
 7: nid005585:122007:131444 [2] NCCL INFO Channel 07/0 : 14[2] -> 30[2] [receive] via NET/AWS Libfabric/2
 8: nid005586:68926:78453 [0] NCCL INFO Channel 01/0 : 32[0] -> 48[0] [send] via NET/AWS Libfabric/0
 7: nid005585:122005:131445 [0] NCCL INFO Channel 04/0 : 12[0] -> 28[0] [receive] via NET/AWS Libfabric/0
 5: nid005582:196715:206731 [2] NCCL INFO Channel 06/0 : 22[2] -> 14[2] [send] via NET/AWS Libfabric/2
 9: nid005588:35935:45450 [0] NCCL INFO Channel 04/0 : 44[0] -> 36[0] [receive] via NET/AWS Libfabric/0
 7: nid005585:122007:131444 [2] NCCL INFO Channel 06/0 : 30[2] -> 46[2] [send] via NET/AWS Libfabric/2
 6: nid005584:28287:37728 [2] NCCL INFO Channel 03/0 : 18[2] -> 26[2] [receive] via NET/AWS Libfabric/2
 7: nid005585:122005:131445 [0] NCCL INFO Channel 05/0 : 12[0] -> 28[0] [receive] via NET/AWS Libfabric/0
31: nid005937:256590:266072 [1] NCCL INFO Channel 03/0 : 125[1] -> 124[0] via P2P/CUMEM
 3: nid005580:71821:81332 [2] NCCL INFO Channel 06/0 : 14[2] -> 30[2] [send] via NET/AWS Libfabric/2
 5: nid005582:196715:206731 [2] NCCL INFO Channel 07/0 : 22[2] -> 14[2] [send] via NET/AWS Libfabric/2
 6: nid005584:28285:37730 [0] NCCL INFO Channel 00/0 : 16[0] -> 24[0] [receive] via NET/AWS Libfabric/0
 6: nid005584:28286:37731 [1] NCCL INFO Channel 06/0 : 25[1] -> 24[0] via P2P/CUMEM
11: nid005591:191603:202359 [0] NCCL INFO Channel 04/0 : 28[0] -> 44[0] [receive] via NET/AWS Libfabric/0
 6: nid005584:28285:37730 [0] NCCL INFO Channel 01/0 : 16[0] -> 24[0] [receive] via NET/AWS Libfabric/0
11: nid005591:191603:202359 [0] NCCL INFO Channel 05/0 : 28[0] -> 44[0] [receive] via NET/AWS Libfabric/0
 3: nid005580:71821:81332 [2] NCCL INFO Channel 07/0 : 14[2] -> 30[2] [send] via NET/AWS Libfabric/2
 5: nid005582:196713:206729 [0] NCCL INFO Channel 04/0 : 20[0] -> 12[0] [send] via NET/AWS Libfabric/0
 9: nid005588:35935:45450 [0] NCCL INFO Channel 05/0 : 44[0] -> 36[0] [receive] via NET/AWS Libfabric/0
 7: nid005585:122005:131445 [0] NCCL INFO Channel 04/0 : 28[0] -> 44[0] [send] via NET/AWS Libfabric/0
 8: nid005586:68928:78455 [2] NCCL INFO Channel 06/0 : 34[2] -> 35[3] via P2P/CUMEM
31: nid005937:256590:266072 [1] NCCL INFO Channel 05/0 : 125[1] -> 124[0] via P2P/CUMEM
 3: nid005580:71819:81333 [0] NCCL INFO Channel 04/0 : 12[0] -> 28[0] [send] via NET/AWS Libfabric/0
 5: nid005582:196713:206729 [0] NCCL INFO Channel 05/0 : 20[0] -> 12[0] [send] via NET/AWS Libfabric/0
 7: nid005585:122007:131444 [2] NCCL INFO Channel 07/0 : 30[2] -> 46[2] [send] via NET/AWS Libfabric/2
 3: nid005580:71819:81333 [0] NCCL INFO Channel 05/0 : 12[0] -> 28[0] [send] via NET/AWS Libfabric/0
12: nid005594:53085:62618 [0] NCCL INFO Channel 00/0 : 48[0] -> 32[0] [send] via NET/AWS Libfabric/0
 7: nid005585:122005:131445 [0] NCCL INFO Channel 05/0 : 28[0] -> 44[0] [send] via NET/AWS Libfabric/0
 6: nid005584:28287:37728 [2] NCCL INFO Channel 02/0 : 26[2] -> 18[2] [send] via NET/AWS Libfabric/2
 4: nid005581:264525:274016 [2] NCCL INFO Channel 02/0 : 18[2] -> 34[2] [send] via NET/AWS Libfabric/2
 6: nid005584:28287:37728 [2] NCCL INFO Channel 03/0 : 26[2] -> 18[2] [send] via NET/AWS Libfabric/2
12: nid005594:53085:62618 [0] NCCL INFO Channel 01/0 : 48[0] -> 32[0] [send] via NET/AWS Libfabric/0
 8: nid005586:68928:78455 [2] NCCL INFO Channel 07/0 : 34[2] -> 35[3] via P2P/CUMEM
31: nid005937:256590:266072 [1] NCCL INFO Channel 07/0 : 125[1] -> 124[0] via P2P/CUMEM
 4: nid005581:264525:274016 [2] NCCL INFO Channel 03/0 : 18[2] -> 34[2] [send] via NET/AWS Libfabric/2
 6: nid005584:28285:37730 [0] NCCL INFO Channel 00/0 : 24[0] -> 16[0] [send] via NET/AWS Libfabric/0
 4: nid005581:264523:274015 [0] NCCL INFO Channel 00/0 : 16[0] -> 32[0] [send] via NET/AWS Libfabric/0
 6: nid005584:28285:37730 [0] NCCL INFO Channel 01/0 : 24[0] -> 16[0] [send] via NET/AWS Libfabric/0
24: nid005918:92507:102032 [3] NCCL INFO Channel 02/0 : 99[3] -> 96[0] via P2P/CUMEM
 4: nid005581:264523:274015 [0] NCCL INFO Channel 01/0 : 16[0] -> 32[0] [send] via NET/AWS Libfabric/0
24: nid005918:92504:102030 [0] NCCL INFO Channel 04/0 : 96[0] -> 100[0] [send] via NET/AWS Libfabric/0
 7: nid005585:122005:131445 [0] NCCL INFO Channel 04/0 : 28[0] -> 60[0] [send] via NET/AWS Libfabric/0
 3: nid005580:71819:81333 [0] NCCL INFO Channel 04/0 : 28[0] -> 12[0] [receive] via NET/AWS Libfabric/0
11: nid005591:191603:202359 [0] NCCL INFO Channel 04/0 : 44[0] -> 28[0] [send] via NET/AWS Libfabric/0
 3: nid005580:71819:81333 [0] NCCL INFO Channel 05/0 : 28[0] -> 12[0] [receive] via NET/AWS Libfabric/0
 7: nid005585:122005:131445 [0] NCCL INFO Channel 05/0 : 28[0] -> 60[0] [send] via NET/AWS Libfabric/0
29: nid005932:167682:177153 [2] NCCL INFO Channel 06/0 : 118[2] -> 119[3] via P2P/CUMEM
 4: nid005581:264523:274015 [0] NCCL INFO Channel 00/0 : 32[0] -> 16[0] [receive] via NET/AWS Libfabric/0
 8: nid005586:68926:78453 [0] NCCL INFO Channel 00/0 : 32[0] -> 64[0] [send] via NET/AWS Libfabric/0
11: nid005591:191603:202359 [0] NCCL INFO Channel 05/0 : 44[0] -> 28[0] [send] via NET/AWS Libfabric/0
 3: nid005580:71821:81332 [2] NCCL INFO Channel 06/0 : 30[2] -> 14[2] [receive] via NET/AWS Libfabric/2
29: nid005932:167681:177151 [1] NCCL INFO Channel 00/0 : 117[1] -> 118[2] via P2P/CUMEM
 8: nid005586:68926:78453 [0] NCCL INFO Channel 01/0 : 32[0] -> 64[0] [send] via NET/AWS Libfabric/0
 3: nid005580:71821:81332 [2] NCCL INFO Channel 07/0 : 30[2] -> 14[2] [receive] via NET/AWS Libfabric/2
 4: nid005581:264523:274015 [0] NCCL INFO Channel 01/0 : 32[0] -> 16[0] [receive] via NET/AWS Libfabric/0
24: nid005918:92506:102031 [2] NCCL INFO Channel 06/0 : 98[2] -> 102[2] [send] via NET/AWS Libfabric/2
 7: nid005585:122005:131445 [0] NCCL INFO Channel 04/0 : 60[0] -> 28[0] [receive] via NET/AWS Libfabric/0
25: nid005919:107462:116999 [0] NCCL INFO Channel 04/0 : 100[0] -> 108[0] [send] via NET/AWS Libfabric/0
24: nid005918:92507:102032 [3] NCCL INFO Channel 03/0 : 99[3] -> 96[0] via P2P/CUMEM
 7: nid005585:122005:131445 [0] NCCL INFO Channel 05/0 : 60[0] -> 28[0] [receive] via NET/AWS Libfabric/0
 8: nid005586:68929:78454 [3] NCCL INFO Channel 02/0 : 35[3] -> 32[0] via P2P/CUMEM
25: nid005919:107462:116999 [0] NCCL INFO Channel 05/0 : 100[0] -> 108[0] [send] via NET/AWS Libfabric/0
 8: nid005586:68926:78453 [0] NCCL INFO Channel 00/0 : 64[0] -> 32[0] [receive] via NET/AWS Libfabric/0
 8: nid005586:68926:78453 [0] NCCL INFO Channel 01/0 : 64[0] -> 32[0] [receive] via NET/AWS Libfabric/0
24: nid005918:92504:102030 [0] NCCL INFO Channel 00/0 : 80[0] -> 96[0] [receive] via NET/AWS Libfabric/0
24: nid005918:92506:102031 [2] NCCL INFO Channel 02/0 : 82[2] -> 98[2] [receive] via NET/AWS Libfabric/2
25: nid005919:107464:116998 [2] NCCL INFO Channel 06/0 : 102[2] -> 110[2] [send] via NET/AWS Libfabric/2
25: nid005919:107462:116999 [0] NCCL INFO Channel 04/0 : 108[0] -> 100[0] [receive] via NET/AWS Libfabric/0
24: nid005918:92506:102031 [2] NCCL INFO Channel 03/0 : 82[2] -> 98[2] [receive] via NET/AWS Libfabric/2
25: nid005919:107464:116998 [2] NCCL INFO Channel 07/0 : 102[2] -> 110[2] [send] via NET/AWS Libfabric/2
29: nid005932:167682:177153 [2] NCCL INFO Channel 07/0 : 118[2] -> 119[3] via P2P/CUMEM
24: nid005918:92504:102030 [0] NCCL INFO Channel 01/0 : 80[0] -> 96[0] [receive] via NET/AWS Libfabric/0
 8: nid005586:68928:78455 [2] NCCL INFO Channel 06/0 : 34[2] -> 38[2] [send] via NET/AWS Libfabric/2
29: nid005932:167681:177151 [1] NCCL INFO Channel 04/0 : 117[1] -> 118[2] via P2P/CUMEM
25: nid005919:107462:116999 [0] NCCL INFO Channel 05/0 : 108[0] -> 100[0] [receive] via NET/AWS Libfabric/0
 8: nid005586:68929:78454 [3] NCCL INFO Channel 03/0 : 35[3] -> 32[0] via P2P/CUMEM
24: nid005918:92506:102031 [2] NCCL INFO Channel 02/0 : 98[2] -> 114[2] [send] via NET/AWS Libfabric/2
24: nid005918:92507:102032 [3] NCCL INFO Channel 06/0 : 99[3] -> 96[0] via P2P/CUMEM
24: nid005918:92506:102031 [2] NCCL INFO Channel 03/0 : 98[2] -> 114[2] [send] via NET/AWS Libfabric/2
24: nid005918:92505:102033 [1] NCCL INFO Channel 00/0 : 97[1] -> 96[0] via P2P/CUMEM
25: nid005919:107464:116998 [2] NCCL INFO Channel 06/0 : 110[2] -> 102[2] [receive] via NET/AWS Libfabric/2
 9: nid005588:35937:45448 [2] NCCL INFO Channel 06/0 : 38[2] -> 46[2] [send] via NET/AWS Libfabric/2
 8: nid005586:68928:78455 [2] NCCL INFO Channel 02/0 : 18[2] -> 34[2] [receive] via NET/AWS Libfabric/2
25: nid005919:107464:116998 [2] NCCL INFO Channel 07/0 : 110[2] -> 102[2] [receive] via NET/AWS Libfabric/2
 8: nid005586:68927:78452 [1] NCCL INFO Channel 00/0 : 33[1] -> 32[0] via P2P/CUMEM
 8: nid005586:68929:78454 [3] NCCL INFO Channel 06/0 : 35[3] -> 32[0] via P2P/CUMEM
 9: nid005588:35937:45448 [2] NCCL INFO Channel 07/0 : 38[2] -> 46[2] [send] via NET/AWS Libfabric/2
 8: nid005586:68928:78455 [2] NCCL INFO Channel 03/0 : 18[2] -> 34[2] [receive] via NET/AWS Libfabric/2
20: nid005913:292683:9619 [2] NCCL INFO Channel 02/0 : 98[2] -> 82[2] [receive] via NET/AWS Libfabric/2
24: nid005918:92504:102030 [0] NCCL INFO Channel 00/0 : 96[0] -> 112[0] [send] via NET/AWS Libfabric/0
 8: nid005586:68928:78455 [2] NCCL INFO Channel 02/0 : 34[2] -> 50[2] [send] via NET/AWS Libfabric/2
20: nid005913:292683:9619 [2] NCCL INFO Channel 03/0 : 98[2] -> 82[2] [receive] via NET/AWS Libfabric/2
 8: nid005586:68928:78455 [2] NCCL INFO Channel 03/0 : 34[2] -> 50[2] [send] via NET/AWS Libfabric/2
24: nid005918:92507:102032 [3] NCCL INFO Channel 07/0 : 99[3] -> 96[0] via P2P/CUMEM
24: nid005918:92505:102033 [1] NCCL INFO Channel 02/0 : 97[1] -> 96[0] via P2P/CUMEM
 9: nid005588:35937:45448 [2] NCCL INFO Channel 06/0 : 46[2] -> 38[2] [receive] via NET/AWS Libfabric/2
11: nid005591:191605:202358 [2] NCCL INFO Channel 06/0 : 30[2] -> 46[2] [receive] via NET/AWS Libfabric/2
24: nid005918:92504:102030 [0] NCCL INFO Channel 01/0 : 96[0] -> 112[0] [send] via NET/AWS Libfabric/0
 8: nid005586:68927:78452 [1] NCCL INFO Channel 02/0 : 33[1] -> 32[0] via P2P/CUMEM
 9: nid005588:35937:45448 [2] NCCL INFO Channel 07/0 : 46[2] -> 38[2] [receive] via NET/AWS Libfabric/2
 8: nid005586:68929:78454 [3] NCCL INFO Channel 07/0 : 35[3] -> 32[0] via P2P/CUMEM
11: nid005591:191605:202358 [2] NCCL INFO Channel 07/0 : 30[2] -> 46[2] [receive] via NET/AWS Libfabric/2
29: nid005932:167683:177154 [3] NCCL INFO Channel 02/0 : 119[3] -> 116[0] via P2P/CUMEM
 4: nid005581:264525:274016 [2] NCCL INFO Channel 02/0 : 34[2] -> 18[2] [receive] via NET/AWS Libfabric/2
29: nid005932:167680:177152 [0] NCCL INFO Channel 04/0 : 112[0] -> 116[0] [receive] via NET/AWS Libfabric/0
 8: nid005586:68928:78455 [2] NCCL INFO Channel 02/0 : 34[2] -> 66[2] [send] via NET/AWS Libfabric/2
 4: nid005581:264525:274016 [2] NCCL INFO Channel 03/0 : 34[2] -> 18[2] [receive] via NET/AWS Libfabric/2
12: nid005594:53087:62620 [2] NCCL INFO Channel 02/0 : 50[2] -> 34[2] [send] via NET/AWS Libfabric/2
29: nid005932:167680:177152 [0] NCCL INFO Channel 01/0 : 116[0] -> 120[0] [send] via NET/AWS Libfabric/0
20: nid005913:292681:9616 [0] NCCL INFO Channel 00/0 : 96[0] -> 80[0] [receive] via NET/AWS Libfabric/0
 8: nid005586:68928:78455 [2] NCCL INFO Channel 03/0 : 34[2] -> 66[2] [send] via NET/AWS Libfabric/2
11: nid005591:191605:202358 [2] NCCL INFO Channel 06/0 : 46[2] -> 30[2] [send] via NET/AWS Libfabric/2
12: nid005594:53087:62620 [2] NCCL INFO Channel 03/0 : 50[2] -> 34[2] [send] via NET/AWS Libfabric/2
24: nid005918:92505:102033 [1] NCCL INFO Channel 04/0 : 97[1] -> 96[0] via P2P/CUMEM
29: nid005932:167682:177153 [2] NCCL INFO Channel 06/0 : 114[2] -> 118[2] [receive] via NET/AWS Libfabric/2
 7: nid005585:122007:131444 [2] NCCL INFO Channel 06/0 : 30[2] -> 62[2] [send] via NET/AWS Libfabric/2
20: nid005913:292681:9616 [0] NCCL INFO Channel 01/0 : 96[0] -> 80[0] [receive] via NET/AWS Libfabric/0
11: nid005591:191605:202358 [2] NCCL INFO Channel 07/0 : 46[2] -> 30[2] [send] via NET/AWS Libfabric/2
29: nid005932:167680:177152 [0] NCCL INFO Channel 05/0 : 116[0] -> 120[0] [send] via NET/AWS Libfabric/0
29: nid005932:167682:177153 [2] NCCL INFO Channel 03/0 : 118[2] -> 122[2] [send] via NET/AWS Libfabric/2
 7: nid005585:122007:131444 [2] NCCL INFO Channel 07/0 : 30[2] -> 62[2] [send] via NET/AWS Libfabric/2
 8: nid005586:68927:78452 [1] NCCL INFO Channel 04/0 : 33[1] -> 32[0] via P2P/CUMEM
 8: nid005586:68928:78455 [2] NCCL INFO Channel 02/0 : 66[2] -> 34[2] [receive] via NET/AWS Libfabric/2
24: nid005918:92505:102033 [1] NCCL INFO Channel 06/0 : 97[1] -> 96[0] via P2P/CUMEM
29: nid005932:167683:177154 [3] NCCL INFO Channel 03/0 : 119[3] -> 116[0] via P2P/CUMEM
29: nid005932:167682:177153 [2] NCCL INFO Channel 07/0 : 118[2] -> 122[2] [send] via NET/AWS Libfabric/2
 8: nid005586:68928:78455 [2] NCCL INFO Channel 03/0 : 66[2] -> 34[2] [receive] via NET/AWS Libfabric/2
 8: nid005586:68927:78452 [1] NCCL INFO Channel 06/0 : 33[1] -> 32[0] via P2P/CUMEM
 7: nid005585:122007:131444 [2] NCCL INFO Channel 06/0 : 62[2] -> 30[2] [receive] via NET/AWS Libfabric/2
 7: nid005585:122007:131444 [2] NCCL INFO Channel 07/0 : 62[2] -> 30[2] [receive] via NET/AWS Libfabric/2
29: nid005932:167680:177152 [0] NCCL INFO Channel 04/0 : 108[0] -> 116[0] [receive] via NET/AWS Libfabric/0
30: nid005936:49908:59406 [0] NCCL INFO Channel 00/0 : 112[0] -> 120[0] [receive] via NET/AWS Libfabric/0
29: nid005932:167680:177152 [0] NCCL INFO Channel 05/0 : 108[0] -> 116[0] [receive] via NET/AWS Libfabric/0
28: nid005929:16032:25538 [2] NCCL INFO Channel 02/0 : 106[2] -> 114[2] [receive] via NET/AWS Libfabric/2
30: nid005936:49908:59406 [0] NCCL INFO Channel 01/0 : 112[0] -> 120[0] [receive] via NET/AWS Libfabric/0
28: nid005929:16030:25536 [0] NCCL INFO Channel 00/0 : 104[0] -> 112[0] [receive] via NET/AWS Libfabric/0
28: nid005929:16032:25538 [2] NCCL INFO Channel 03/0 : 106[2] -> 114[2] [receive] via NET/AWS Libfabric/2
30: nid005936:49910:59408 [2] NCCL INFO Channel 02/0 : 114[2] -> 122[2] [receive] via NET/AWS Libfabric/2
29: nid005932:167682:177153 [2] NCCL INFO Channel 06/0 : 110[2] -> 118[2] [receive] via NET/AWS Libfabric/2
29: nid005932:167683:177154 [3] NCCL INFO Channel 06/0 : 119[3] -> 116[0] via P2P/CUMEM
29: nid005932:167680:177152 [0] NCCL INFO Channel 04/0 : 116[0] -> 108[0] [send] via NET/AWS Libfabric/0
28: nid005929:16032:25538 [2] NCCL INFO Channel 02/0 : 114[2] -> 122[2] [send] via NET/AWS Libfabric/2
30: nid005936:49910:59408 [2] NCCL INFO Channel 03/0 : 114[2] -> 122[2] [receive] via NET/AWS Libfabric/2
29: nid005932:167681:177151 [1] NCCL INFO Channel 01/0 : 117[1] -> 116[0] via P2P/CUMEM
27: nid005922:80741:90205 [0] NCCL INFO Channel 04/0 : 92[0] -> 108[0] [receive] via NET/AWS Libfabric/0
29: nid005932:167682:177153 [2] NCCL INFO Channel 07/0 : 110[2] -> 118[2] [receive] via NET/AWS Libfabric/2
28: nid005929:16032:25538 [2] NCCL INFO Channel 03/0 : 114[2] -> 122[2] [send] via NET/AWS Libfabric/2
29: nid005932:167680:177152 [0] NCCL INFO Channel 05/0 : 116[0] -> 108[0] [send] via NET/AWS Libfabric/0
27: nid005922:80741:90205 [0] NCCL INFO Channel 05/0 : 92[0] -> 108[0] [receive] via NET/AWS Libfabric/0
29: nid005932:167682:177153 [2] NCCL INFO Channel 06/0 : 118[2] -> 110[2] [send] via NET/AWS Libfabric/2
27: nid005922:80743:90206 [2] NCCL INFO Channel 06/0 : 94[2] -> 110[2] [receive] via NET/AWS Libfabric/2
26: nid005920:67125:76630 [2] NCCL INFO Channel 02/0 : 114[2] -> 106[2] [receive] via NET/AWS Libfabric/2
27: nid005922:80741:90205 [0] NCCL INFO Channel 04/0 : 108[0] -> 92[0] [send] via NET/AWS Libfabric/0
23: nid005917:276885:286402 [0] NCCL INFO Channel 04/0 : 60[0] -> 92[0] [receive] via NET/AWS Libfabric/0
28: nid005929:16032:25538 [2] NCCL INFO Channel 02/0 : 98[2] -> 114[2] [receive] via NET/AWS Libfabric/2
30: nid005936:49910:59408 [2] NCCL INFO Channel 02/0 : 122[2] -> 114[2] [send] via NET/AWS Libfabric/2
29: nid005932:167682:177153 [2] NCCL INFO Channel 07/0 : 118[2] -> 110[2] [send] via NET/AWS Libfabric/2
27: nid005922:80743:90206 [2] NCCL INFO Channel 07/0 : 94[2] -> 110[2] [receive] via NET/AWS Libfabric/2
29: nid005932:167683:177154 [3] NCCL INFO Channel 07/0 : 119[3] -> 116[0] via P2P/CUMEM
26: nid005920:67125:76630 [2] NCCL INFO Channel 03/0 : 114[2] -> 106[2] [receive] via NET/AWS Libfabric/2
27: nid005922:80741:90205 [0] NCCL INFO Channel 05/0 : 108[0] -> 92[0] [send] via NET/AWS Libfabric/0
23: nid005917:276885:286402 [0] NCCL INFO Channel 05/0 : 60[0] -> 92[0] [receive] via NET/AWS Libfabric/0
30: nid005936:49910:59408 [2] NCCL INFO Channel 03/0 : 122[2] -> 114[2] [send] via NET/AWS Libfabric/2
28: nid005929:16030:25536 [0] NCCL INFO Channel 01/0 : 104[0] -> 112[0] [receive] via NET/AWS Libfabric/0
29: nid005932:167681:177151 [1] NCCL INFO Channel 03/0 : 117[1] -> 116[0] via P2P/CUMEM
28: nid005929:16032:25538 [2] NCCL INFO Channel 03/0 : 98[2] -> 114[2] [receive] via NET/AWS Libfabric/2
23: nid005917:276885:286402 [0] NCCL INFO Channel 04/0 : 92[0] -> 60[0] [send] via NET/AWS Libfabric/0
15: nid005601:210676:220272 [0] NCCL INFO Channel 04/0 : 124[0] -> 60[0] [receive] via NET/AWS Libfabric/0
28: nid005929:16032:25538 [2] NCCL INFO Channel 02/0 : 114[2] -> 98[2] [send] via NET/AWS Libfabric/2
27: nid005922:80743:90206 [2] NCCL INFO Channel 06/0 : 110[2] -> 94[2] [send] via NET/AWS Libfabric/2
28: nid005929:16032:25538 [2] NCCL INFO Channel 03/0 : 114[2] -> 98[2] [send] via NET/AWS Libfabric/2
15: nid005601:210676:220272 [0] NCCL INFO Channel 05/0 : 124[0] -> 60[0] [receive] via NET/AWS Libfabric/0
24: nid005918:92506:102031 [2] NCCL INFO Channel 02/0 : 66[2] -> 98[2] [receive] via NET/AWS Libfabric/2
23: nid005917:276887:286401 [2] NCCL INFO Channel 06/0 : 62[2] -> 94[2] [receive] via NET/AWS Libfabric/2
23: nid005917:276885:286402 [0] NCCL INFO Channel 05/0 : 92[0] -> 60[0] [send] via NET/AWS Libfabric/0
27: nid005922:80743:90206 [2] NCCL INFO Channel 07/0 : 110[2] -> 94[2] [send] via NET/AWS Libfabric/2
15: nid005601:210676:220272 [0] NCCL INFO Channel 04/0 : 60[0] -> 124[0] [send] via NET/AWS Libfabric/0
24: nid005918:92506:102031 [2] NCCL INFO Channel 03/0 : 66[2] -> 98[2] [receive] via NET/AWS Libfabric/2
23: nid005917:276887:286401 [2] NCCL INFO Channel 07/0 : 62[2] -> 94[2] [receive] via NET/AWS Libfabric/2
29: nid005932:167681:177151 [1] NCCL INFO Channel 05/0 : 117[1] -> 116[0] via P2P/CUMEM
28: nid005929:16030:25536 [0] NCCL INFO Channel 00/0 : 112[0] -> 120[0] [send] via NET/AWS Libfabric/0
15: nid005601:210676:220272 [0] NCCL INFO Channel 05/0 : 60[0] -> 124[0] [send] via NET/AWS Libfabric/0
24: nid005918:92506:102031 [2] NCCL INFO Channel 02/0 : 98[2] -> 66[2] [send] via NET/AWS Libfabric/2
15: nid005601:210676:220272 [0] NCCL INFO Channel 04/0 : 92[0] -> 60[0] [receive] via NET/AWS Libfabric/0
28: nid005929:16030:25536 [0] NCCL INFO Channel 01/0 : 112[0] -> 120[0] [send] via NET/AWS Libfabric/0
29: nid005932:167681:177151 [1] NCCL INFO Channel 07/0 : 117[1] -> 116[0] via P2P/CUMEM
16: nid005802:6299:15959 [2] NCCL INFO Channel 02/0 : 2[2] -> 66[2] [receive] via NET/AWS Libfabric/2
23: nid005917:276887:286401 [2] NCCL INFO Channel 06/0 : 94[2] -> 62[2] [send] via NET/AWS Libfabric/2
31: nid005937:256589:266070 [0] NCCL INFO Channel 00/0 : 124[0] -> 120[0] [send] via NET/AWS Libfabric/0
15: nid005601:210676:220272 [0] NCCL INFO Channel 05/0 : 92[0] -> 60[0] [receive] via NET/AWS Libfabric/0
24: nid005918:92506:102031 [2] NCCL INFO Channel 03/0 : 98[2] -> 66[2] [send] via NET/AWS Libfabric/2
16: nid005802:6299:15959 [2] NCCL INFO Channel 03/0 : 2[2] -> 66[2] [receive] via NET/AWS Libfabric/2
23: nid005917:276887:286401 [2] NCCL INFO Channel 07/0 : 94[2] -> 62[2] [send] via NET/AWS Libfabric/2
31: nid005937:256589:266070 [0] NCCL INFO Channel 01/0 : 124[0] -> 120[0] [send] via NET/AWS Libfabric/0
15: nid005601:210678:220275 [2] NCCL INFO Channel 06/0 : 126[2] -> 62[2] [receive] via NET/AWS Libfabric/2
16: nid005802:6299:15959 [2] NCCL INFO Channel 02/0 : 66[2] -> 2[2] [send] via NET/AWS Libfabric/2
15: nid005601:210676:220272 [0] NCCL INFO Channel 04/0 : 60[0] -> 28[0] [send] via NET/AWS Libfabric/0
26: nid005920:67123:76628 [0] NCCL INFO Channel 00/0 : 112[0] -> 104[0] [receive] via NET/AWS Libfabric/0
15: nid005601:210676:220272 [0] NCCL INFO Channel 05/0 : 60[0] -> 28[0] [send] via NET/AWS Libfabric/0
16: nid005802:6299:15959 [2] NCCL INFO Channel 03/0 : 66[2] -> 2[2] [send] via NET/AWS Libfabric/2
15: nid005601:210678:220275 [2] NCCL INFO Channel 07/0 : 126[2] -> 62[2] [receive] via NET/AWS Libfabric/2
26: nid005920:67123:76628 [0] NCCL INFO Channel 01/0 : 112[0] -> 104[0] [receive] via NET/AWS Libfabric/0
30: nid005936:49908:59406 [0] NCCL INFO Channel 00/0 : 120[0] -> 112[0] [send] via NET/AWS Libfabric/0
15: nid005601:210678:220275 [2] NCCL INFO Channel 06/0 : 62[2] -> 126[2] [send] via NET/AWS Libfabric/2
28: nid005929:16030:25536 [0] NCCL INFO Channel 00/0 : 96[0] -> 112[0] [receive] via NET/AWS Libfabric/0
30: nid005936:49908:59406 [0] NCCL INFO Channel 01/0 : 120[0] -> 112[0] [send] via NET/AWS Libfabric/0
15: nid005601:210678:220275 [2] NCCL INFO Channel 07/0 : 62[2] -> 126[2] [send] via NET/AWS Libfabric/2
23: nid005917:276885:286402 [0] NCCL INFO Channel 04/0 : 108[0] -> 92[0] [receive] via NET/AWS Libfabric/0
28: nid005929:16030:25536 [0] NCCL INFO Channel 01/0 : 96[0] -> 112[0] [receive] via NET/AWS Libfabric/0
16: nid005802:6299:15959 [2] NCCL INFO Channel 02/0 : 98[2] -> 66[2] [receive] via NET/AWS Libfabric/2
15: nid005601:210676:220272 [0] NCCL INFO Channel 00/0 : 60[0] -> 56[0] [send] via NET/AWS Libfabric/0
 7: nid005585:122005:131445 [0] NCCL INFO Channel 04/0 : 44[0] -> 28[0] [receive] via NET/AWS Libfabric/0
 0: nid005574:69060:78921 [2] NCCL INFO Channel 06/0 : 6[2] -> 2[2] [receive] via NET/AWS Libfabric/2
23: nid005917:276885:286402 [0] NCCL INFO Channel 05/0 : 108[0] -> 92[0] [receive] via NET/AWS Libfabric/0
15: nid005601:210676:220272 [0] NCCL INFO Channel 01/0 : 60[0] -> 56[0] [send] via NET/AWS Libfabric/0
 7: nid005585:122005:131445 [0] NCCL INFO Channel 05/0 : 44[0] -> 28[0] [receive] via NET/AWS Libfabric/0
16: nid005802:6299:15959 [2] NCCL INFO Channel 03/0 : 98[2] -> 66[2] [receive] via NET/AWS Libfabric/2
 0: nid005574:69060:78921 [2] NCCL INFO Channel 07/0 : 6[2] -> 2[2] [receive] via NET/AWS Libfabric/2
23: nid005917:276885:286402 [0] NCCL INFO Channel 04/0 : 92[0] -> 76[0] [send] via NET/AWS Libfabric/0
 7: nid005585:122005:131445 [0] NCCL INFO Channel 04/0 : 28[0] -> 12[0] [send] via NET/AWS Libfabric/0
16: nid005802:6299:15959 [2] NCCL INFO Channel 02/0 : 66[2] -> 34[2] [send] via NET/AWS Libfabric/2
15: nid005601:210678:220275 [2] NCCL INFO Channel 06/0 : 94[2] -> 62[2] [receive] via NET/AWS Libfabric/2
23: nid005917:276885:286402 [0] NCCL INFO Channel 05/0 : 92[0] -> 76[0] [send] via NET/AWS Libfabric/0
 7: nid005585:122005:131445 [0] NCCL INFO Channel 05/0 : 28[0] -> 12[0] [send] via NET/AWS Libfabric/0
24: nid005918:92504:102030 [0] NCCL INFO Channel 00/0 : 64[0] -> 96[0] [receive] via NET/AWS Libfabric/0
16: nid005802:6299:15959 [2] NCCL INFO Channel 03/0 : 66[2] -> 34[2] [send] via NET/AWS Libfabric/2
28: nid005929:16030:25536 [0] NCCL INFO Channel 00/0 : 112[0] -> 96[0] [send] via NET/AWS Libfabric/0
31: nid005937:256591:266071 [2] NCCL INFO Channel 02/0 : 126[2] -> 122[2] [send] via NET/AWS Libfabric/2
24: nid005918:92504:102030 [0] NCCL INFO Channel 01/0 : 64[0] -> 96[0] [receive] via NET/AWS Libfabric/0
15: nid005601:210678:220275 [2] NCCL INFO Channel 07/0 : 94[2] -> 62[2] [receive] via NET/AWS Libfabric/2
28: nid005929:16030:25536 [0] NCCL INFO Channel 01/0 : 112[0] -> 96[0] [send] via NET/AWS Libfabric/0
31: nid005937:256591:266071 [2] NCCL INFO Channel 03/0 : 126[2] -> 122[2] [send] via NET/AWS Libfabric/2
27: nid005922:80741:90205 [0] NCCL INFO Channel 04/0 : 116[0] -> 108[0] [receive] via NET/AWS Libfabric/0
15: nid005601:210678:220275 [2] NCCL INFO Channel 06/0 : 62[2] -> 30[2] [send] via NET/AWS Libfabric/2
23: nid005917:276885:286402 [0] NCCL INFO Channel 00/0 : 92[0] -> 88[0] [send] via NET/AWS Libfabric/0
11: nid005591:191603:202359 [0] NCCL INFO Channel 04/0 : 52[0] -> 44[0] [receive] via NET/AWS Libfabric/0
15: nid005601:210678:220275 [2] NCCL INFO Channel 07/0 : 62[2] -> 30[2] [send] via NET/AWS Libfabric/2
27: nid005922:80741:90205 [0] NCCL INFO Channel 05/0 : 116[0] -> 108[0] [receive] via NET/AWS Libfabric/0
 7: nid005585:122005:131445 [0] NCCL INFO Channel 00/0 : 28[0] -> 24[0] [send] via NET/AWS Libfabric/0
19: nid005912:12435:21904 [0] NCCL INFO Channel 04/0 : 84[0] -> 76[0] [receive] via NET/AWS Libfabric/0
23: nid005917:276885:286402 [0] NCCL INFO Channel 01/0 : 92[0] -> 88[0] [send] via NET/AWS Libfabric/0
24: nid005918:92506:102031 [2] NCCL INFO Channel 02/0 : 114[2] -> 98[2] [receive] via NET/AWS Libfabric/2
27: nid005922:80741:90205 [0] NCCL INFO Channel 04/0 : 108[0] -> 100[0] [send] via NET/AWS Libfabric/0
11: nid005591:191603:202359 [0] NCCL INFO Channel 05/0 : 52[0] -> 44[0] [receive] via NET/AWS Libfabric/0
 7: nid005585:122005:131445 [0] NCCL INFO Channel 01/0 : 28[0] -> 24[0] [send] via NET/AWS Libfabric/0
27: nid005922:80741:90205 [0] NCCL INFO Channel 05/0 : 108[0] -> 100[0] [send] via NET/AWS Libfabric/0
24: nid005918:92504:102030 [0] NCCL INFO Channel 00/0 : 96[0] -> 64[0] [send] via NET/AWS Libfabric/0
16: nid005802:6299:15959 [2] NCCL INFO Channel 06/0 : 70[2] -> 66[2] [receive] via NET/AWS Libfabric/2
 3: nid005580:71819:81333 [0] NCCL INFO Channel 04/0 : 20[0] -> 12[0] [receive] via NET/AWS Libfabric/0
 8: nid005586:68928:78455 [2] NCCL INFO Channel 02/0 : 50[2] -> 34[2] [receive] via NET/AWS Libfabric/2
11: nid005591:191603:202359 [0] NCCL INFO Channel 04/0 : 44[0] -> 36[0] [send] via NET/AWS Libfabric/0
19: nid005912:12435:21904 [0] NCCL INFO Channel 05/0 : 84[0] -> 76[0] [receive] via NET/AWS Libfabric/0
24: nid005918:92506:102031 [2] NCCL INFO Channel 03/0 : 114[2] -> 98[2] [receive] via NET/AWS Libfabric/2
16: nid005802:6297:15957 [0] NCCL INFO Channel 00/0 : 0[0] -> 64[0] [receive] via NET/AWS Libfabric/0
 8: nid005586:68928:78455 [2] NCCL INFO Channel 03/0 : 50[2] -> 34[2] [receive] via NET/AWS Libfabric/2
11: nid005591:191603:202359 [0] NCCL INFO Channel 05/0 : 44[0] -> 36[0] [send] via NET/AWS Libfabric/0
24: nid005918:92504:102030 [0] NCCL INFO Channel 01/0 : 96[0] -> 64[0] [send] via NET/AWS Libfabric/0
 3: nid005580:71819:81333 [0] NCCL INFO Channel 05/0 : 20[0] -> 12[0] [receive] via NET/AWS Libfabric/0
19: nid005912:12435:21904 [0] NCCL INFO Channel 04/0 : 76[0] -> 68[0] [send] via NET/AWS Libfabric/0
24: nid005918:92506:102031 [2] NCCL INFO Channel 02/0 : 98[2] -> 82[2] [send] via NET/AWS Libfabric/2
19: nid005912:12435:21904 [0] NCCL INFO Channel 05/0 : 76[0] -> 68[0] [send] via NET/AWS Libfabric/0
16: nid005802:6299:15959 [2] NCCL INFO Channel 07/0 : 70[2] -> 66[2] [receive] via NET/AWS Libfabric/2
16: nid005802:6297:15957 [0] NCCL INFO Channel 01/0 : 0[0] -> 64[0] [receive] via NET/AWS Libfabric/0
 8: nid005586:68928:78455 [2] NCCL INFO Channel 02/0 : 34[2] -> 18[2] [send] via NET/AWS Libfabric/2
 3: nid005580:71819:81333 [0] NCCL INFO Channel 04/0 : 12[0] -> 4[0] [send] via NET/AWS Libfabric/0
29: nid005932:167680:177152 [0] NCCL INFO Channel 00/0 : 120[0] -> 116[0] [receive] via NET/AWS Libfabric/0
24: nid005918:92506:102031 [2] NCCL INFO Channel 03/0 : 98[2] -> 82[2] [send] via NET/AWS Libfabric/2
23: nid005917:276887:286401 [2] NCCL INFO Channel 06/0 : 110[2] -> 94[2] [receive] via NET/AWS Libfabric/2
16: nid005802:6297:15957 [0] NCCL INFO Channel 00/0 : 64[0] -> 0[0] [send] via NET/AWS Libfabric/0
 8: nid005586:68928:78455 [2] NCCL INFO Channel 03/0 : 34[2] -> 18[2] [send] via NET/AWS Libfabric/2
15: nid005601:210678:220275 [2] NCCL INFO Channel 02/0 : 62[2] -> 58[2] [send] via NET/AWS Libfabric/2
 7: nid005585:122007:131444 [2] NCCL INFO Channel 06/0 : 46[2] -> 30[2] [receive] via NET/AWS Libfabric/2
 3: nid005580:71819:81333 [0] NCCL INFO Channel 05/0 : 12[0] -> 4[0] [send] via NET/AWS Libfabric/0
27: nid005922:80741:90205 [0] NCCL INFO Channel 00/0 : 108[0] -> 104[0] [send] via NET/AWS Libfabric/0
29: nid005932:167680:177152 [0] NCCL INFO Channel 01/0 : 120[0] -> 116[0] [receive] via NET/AWS Libfabric/0
25: nid005919:107462:116999 [0] NCCL INFO Channel 00/0 : 104[0] -> 100[0] [receive] via NET/AWS Libfabric/0
27: nid005922:80741:90205 [0] NCCL INFO Channel 01/0 : 108[0] -> 104[0] [send] via NET/AWS Libfabric/0
15: nid005601:210678:220275 [2] NCCL INFO Channel 03/0 : 62[2] -> 58[2] [send] via NET/AWS Libfabric/2
23: nid005917:276887:286401 [2] NCCL INFO Channel 07/0 : 110[2] -> 94[2] [receive] via NET/AWS Libfabric/2
 7: nid005585:122007:131444 [2] NCCL INFO Channel 07/0 : 46[2] -> 30[2] [receive] via NET/AWS Libfabric/2
13: nid005595:197883:207753 [0] NCCL INFO Channel 00/0 : 56[0] -> 52[0] [receive] via NET/AWS Libfabric/0
25: nid005919:107462:116999 [0] NCCL INFO Channel 01/0 : 104[0] -> 100[0] [receive] via NET/AWS Libfabric/0
16: nid005802:6297:15957 [0] NCCL INFO Channel 01/0 : 64[0] -> 0[0] [send] via NET/AWS Libfabric/0
21: nid005914:166784:176252 [0] NCCL INFO Channel 00/0 : 88[0] -> 84[0] [receive] via NET/AWS Libfabric/0
11: nid005591:191603:202359 [0] NCCL INFO Channel 00/0 : 44[0] -> 40[0] [send] via NET/AWS Libfabric/0
29: nid005932:167680:177152 [0] NCCL INFO Channel 04/0 : 120[0] -> 116[0] [receive] via NET/AWS Libfabric/0
 9: nid005588:35935:45450 [0] NCCL INFO Channel 00/0 : 40[0] -> 36[0] [receive] via NET/AWS Libfabric/0
13: nid005595:197883:207753 [0] NCCL INFO Channel 01/0 : 56[0] -> 52[0] [receive] via NET/AWS Libfabric/0
23: nid005917:276887:286401 [2] NCCL INFO Channel 06/0 : 94[2] -> 78[2] [send] via NET/AWS Libfabric/2
11: nid005591:191603:202359 [0] NCCL INFO Channel 01/0 : 44[0] -> 40[0] [send] via NET/AWS Libfabric/0
29: nid005932:167680:177152 [0] NCCL INFO Channel 05/0 : 120[0] -> 116[0] [receive] via NET/AWS Libfabric/0
 7: nid005585:122007:131444 [2] NCCL INFO Channel 06/0 : 30[2] -> 14[2] [send] via NET/AWS Libfabric/2
12: nid005594:53087:62620 [2] NCCL INFO Channel 02/0 : 58[2] -> 50[2] [receive] via NET/AWS Libfabric/2
 7: nid005585:122007:131444 [2] NCCL INFO Channel 07/0 : 30[2] -> 14[2] [send] via NET/AWS Libfabric/2
21: nid005914:166784:176252 [0] NCCL INFO Channel 01/0 : 88[0] -> 84[0] [receive] via NET/AWS Libfabric/0
29: nid005932:167680:177152 [0] NCCL INFO Channel 04/0 : 116[0] -> 112[0] [send] via NET/AWS Libfabric/0
24: nid005918:92506:102031 [2] NCCL INFO Channel 06/0 : 102[2] -> 98[2] [receive] via NET/AWS Libfabric/2
 4: nid005581:264525:274016 [2] NCCL INFO Channel 02/0 : 26[2] -> 18[2] [receive] via NET/AWS Libfabric/2
 9: nid005588:35935:45450 [0] NCCL INFO Channel 01/0 : 40[0] -> 36[0] [receive] via NET/AWS Libfabric/0
17: nid005803:180732:190254 [0] NCCL INFO Channel 00/0 : 72[0] -> 68[0] [receive] via NET/AWS Libfabric/0
20: nid005913:292683:9619 [2] NCCL INFO Channel 02/0 : 90[2] -> 82[2] [receive] via NET/AWS Libfabric/2
19: nid005912:12435:21904 [0] NCCL INFO Channel 00/0 : 76[0] -> 72[0] [send] via NET/AWS Libfabric/0
25: nid005919:107462:116999 [0] NCCL INFO Channel 04/0 : 104[0] -> 100[0] [receive] via NET/AWS Libfabric/0
23: nid005917:276887:286401 [2] NCCL INFO Channel 07/0 : 94[2] -> 78[2] [send] via NET/AWS Libfabric/2
28: nid005929:16032:25538 [2] NCCL INFO Channel 02/0 : 122[2] -> 114[2] [receive] via NET/AWS Libfabric/2
 1: nid005576:147557:157020 [0] NCCL INFO Channel 00/0 : 8[0] -> 4[0] [receive] via NET/AWS Libfabric/0
16: nid005802:6297:15957 [0] NCCL INFO Channel 00/0 : 96[0] -> 64[0] [receive] via NET/AWS Libfabric/0
13: nid005595:197883:207753 [0] NCCL INFO Channel 04/0 : 56[0] -> 52[0] [receive] via NET/AWS Libfabric/0
 5: nid005582:196713:206729 [0] NCCL INFO Channel 00/0 : 24[0] -> 20[0] [receive] via NET/AWS Libfabric/0
19: nid005912:12435:21904 [0] NCCL INFO Channel 01/0 : 76[0] -> 72[0] [send] via NET/AWS Libfabric/0
25: nid005919:107462:116999 [0] NCCL INFO Channel 05/0 : 104[0] -> 100[0] [receive] via NET/AWS Libfabric/0
28: nid005929:16032:25538 [2] NCCL INFO Channel 03/0 : 122[2] -> 114[2] [receive] via NET/AWS Libfabric/2
 8: nid005586:68928:78455 [2] NCCL INFO Channel 06/0 : 38[2] -> 34[2] [receive] via NET/AWS Libfabric/2
 0: nid005574:69058:78920 [0] NCCL INFO Channel 04/0 : 4[0] -> 0[0] [receive] via NET/AWS Libfabric/0
12: nid005594:53087:62620 [2] NCCL INFO Channel 03/0 : 58[2] -> 50[2] [receive] via NET/AWS Libfabric/2
 4: nid005581:264525:274016 [2] NCCL INFO Channel 03/0 : 26[2] -> 18[2] [receive] via NET/AWS Libfabric/2
17: nid005803:180732:190254 [0] NCCL INFO Channel 01/0 : 72[0] -> 68[0] [receive] via NET/AWS Libfabric/0
 3: nid005580:71819:81333 [0] NCCL INFO Channel 00/0 : 12[0] -> 8[0] [send] via NET/AWS Libfabric/0
13: nid005595:197883:207753 [0] NCCL INFO Channel 05/0 : 56[0] -> 52[0] [receive] via NET/AWS Libfabric/0
 5: nid005582:196713:206729 [0] NCCL INFO Channel 01/0 : 24[0] -> 20[0] [receive] via NET/AWS Libfabric/0
20: nid005913:292683:9619 [2] NCCL INFO Channel 03/0 : 90[2] -> 82[2] [receive] via NET/AWS Libfabric/2
21: nid005914:166784:176252 [0] NCCL INFO Channel 04/0 : 88[0] -> 84[0] [receive] via NET/AWS Libfabric/0
25: nid005919:107462:116999 [0] NCCL INFO Channel 04/0 : 100[0] -> 96[0] [send] via NET/AWS Libfabric/0
28: nid005929:16032:25538 [2] NCCL INFO Channel 02/0 : 114[2] -> 106[2] [send] via NET/AWS Libfabric/2
29: nid005932:167680:177152 [0] NCCL INFO Channel 05/0 : 116[0] -> 112[0] [send] via NET/AWS Libfabric/0
24: nid005918:92506:102031 [2] NCCL INFO Channel 07/0 : 102[2] -> 98[2] [receive] via NET/AWS Libfabric/2
 0: nid005574:69058:78920 [0] NCCL INFO Channel 05/0 : 4[0] -> 0[0] [receive] via NET/AWS Libfabric/0
12: nid005594:53087:62620 [2] NCCL INFO Channel 02/0 : 50[2] -> 42[2] [send] via NET/AWS Libfabric/2
 1: nid005576:147557:157020 [0] NCCL INFO Channel 01/0 : 8[0] -> 4[0] [receive] via NET/AWS Libfabric/0
 4: nid005581:264525:274016 [2] NCCL INFO Channel 02/0 : 18[2] -> 10[2] [send] via NET/AWS Libfabric/2
 9: nid005588:35935:45450 [0] NCCL INFO Channel 04/0 : 40[0] -> 36[0] [receive] via NET/AWS Libfabric/0
16: nid005802:6297:15957 [0] NCCL INFO Channel 01/0 : 96[0] -> 64[0] [receive] via NET/AWS Libfabric/0
17: nid005803:180732:190254 [0] NCCL INFO Channel 04/0 : 72[0] -> 68[0] [receive] via NET/AWS Libfabric/0
 3: nid005580:71819:81333 [0] NCCL INFO Channel 01/0 : 12[0] -> 8[0] [send] via NET/AWS Libfabric/0
13: nid005595:197883:207753 [0] NCCL INFO Channel 04/0 : 52[0] -> 48[0] [send] via NET/AWS Libfabric/0
 5: nid005582:196713:206729 [0] NCCL INFO Channel 04/0 : 24[0] -> 20[0] [receive] via NET/AWS Libfabric/0
20: nid005913:292683:9619 [2] NCCL INFO Channel 02/0 : 82[2] -> 74[2] [send] via NET/AWS Libfabric/2
21: nid005914:166784:176252 [0] NCCL INFO Channel 05/0 : 88[0] -> 84[0] [receive] via NET/AWS Libfabric/0
25: nid005919:107462:116999 [0] NCCL INFO Channel 05/0 : 100[0] -> 96[0] [send] via NET/AWS Libfabric/0
27: nid005922:80743:90206 [2] NCCL INFO Channel 06/0 : 118[2] -> 110[2] [receive] via NET/AWS Libfabric/2
28: nid005929:16032:25538 [2] NCCL INFO Channel 03/0 : 114[2] -> 106[2] [send] via NET/AWS Libfabric/2
 8: nid005586:68928:78455 [2] NCCL INFO Channel 07/0 : 38[2] -> 34[2] [receive] via NET/AWS Libfabric/2
12: nid005594:53087:62620 [2] NCCL INFO Channel 03/0 : 50[2] -> 42[2] [send] via NET/AWS Libfabric/2
 1: nid005576:147557:157020 [0] NCCL INFO Channel 04/0 : 8[0] -> 4[0] [receive] via NET/AWS Libfabric/0
 4: nid005581:264525:274016 [2] NCCL INFO Channel 03/0 : 18[2] -> 10[2] [send] via NET/AWS Libfabric/2
16: nid005802:6297:15957 [0] NCCL INFO Channel 00/0 : 64[0] -> 32[0] [send] via NET/AWS Libfabric/0
17: nid005803:180732:190254 [0] NCCL INFO Channel 05/0 : 72[0] -> 68[0] [receive] via NET/AWS Libfabric/0
13: nid005595:197883:207753 [0] NCCL INFO Channel 05/0 : 52[0] -> 48[0] [send] via NET/AWS Libfabric/0
 5: nid005582:196713:206729 [0] NCCL INFO Channel 05/0 : 24[0] -> 20[0] [receive] via NET/AWS Libfabric/0
20: nid005913:292683:9619 [2] NCCL INFO Channel 03/0 : 82[2] -> 74[2] [send] via NET/AWS Libfabric/2
21: nid005914:166784:176252 [0] NCCL INFO Channel 04/0 : 84[0] -> 80[0] [send] via NET/AWS Libfabric/0
23: nid005917:276887:286401 [2] NCCL INFO Channel 02/0 : 94[2] -> 90[2] [send] via NET/AWS Libfabric/2
27: nid005922:80743:90206 [2] NCCL INFO Channel 07/0 : 118[2] -> 110[2] [receive] via NET/AWS Libfabric/2
11: nid005591:191605:202358 [2] NCCL INFO Channel 06/0 : 54[2] -> 46[2] [receive] via NET/AWS Libfabric/2
 1: nid005576:147557:157020 [0] NCCL INFO Channel 05/0 : 8[0] -> 4[0] [receive] via NET/AWS Libfabric/0
 9: nid005588:35935:45450 [0] NCCL INFO Channel 05/0 : 40[0] -> 36[0] [receive] via NET/AWS Libfabric/0
16: nid005802:6297:15957 [0] NCCL INFO Channel 01/0 : 64[0] -> 32[0] [send] via NET/AWS Libfabric/0
17: nid005803:180732:190254 [0] NCCL INFO Channel 04/0 : 68[0] -> 64[0] [send] via NET/AWS Libfabric/0
 7: nid005585:122007:131444 [2] NCCL INFO Channel 02/0 : 30[2] -> 26[2] [send] via NET/AWS Libfabric/2
 3: nid005580:71821:81332 [2] NCCL INFO Channel 06/0 : 22[2] -> 14[2] [receive] via NET/AWS Libfabric/2
 5: nid005582:196713:206729 [0] NCCL INFO Channel 04/0 : 20[0] -> 16[0] [send] via NET/AWS Libfabric/0
19: nid005912:12437:21903 [2] NCCL INFO Channel 06/0 : 86[2] -> 78[2] [receive] via NET/AWS Libfabric/2
21: nid005914:166784:176252 [0] NCCL INFO Channel 05/0 : 84[0] -> 80[0] [send] via NET/AWS Libfabric/0
23: nid005917:276887:286401 [2] NCCL INFO Channel 03/0 : 94[2] -> 90[2] [send] via NET/AWS Libfabric/2
27: nid005922:80743:90206 [2] NCCL INFO Channel 06/0 : 110[2] -> 102[2] [send] via NET/AWS Libfabric/2
11: nid005591:191605:202358 [2] NCCL INFO Channel 07/0 : 54[2] -> 46[2] [receive] via NET/AWS Libfabric/2
 1: nid005576:147557:157020 [0] NCCL INFO Channel 04/0 : 4[0] -> 0[0] [send] via NET/AWS Libfabric/0
 9: nid005588:35935:45450 [0] NCCL INFO Channel 04/0 : 36[0] -> 32[0] [send] via NET/AWS Libfabric/0
17: nid005803:180732:190254 [0] NCCL INFO Channel 05/0 : 68[0] -> 64[0] [send] via NET/AWS Libfabric/0
 7: nid005585:122007:131444 [2] NCCL INFO Channel 03/0 : 30[2] -> 26[2] [send] via NET/AWS Libfabric/2
 5: nid005582:196713:206729 [0] NCCL INFO Channel 05/0 : 20[0] -> 16[0] [send] via NET/AWS Libfabric/0
30: nid005936:49910:59408 [2] NCCL INFO Channel 02/0 : 126[2] -> 122[2] [receive] via NET/AWS Libfabric/2
27: nid005922:80743:90206 [2] NCCL INFO Channel 07/0 : 110[2] -> 102[2] [send] via NET/AWS Libfabric/2
11: nid005591:191605:202358 [2] NCCL INFO Channel 06/0 : 46[2] -> 38[2] [send] via NET/AWS Libfabric/2
 1: nid005576:147557:157020 [0] NCCL INFO Channel 05/0 : 4[0] -> 0[0] [send] via NET/AWS Libfabric/0
 3: nid005580:71821:81332 [2] NCCL INFO Channel 07/0 : 22[2] -> 14[2] [receive] via NET/AWS Libfabric/2
19: nid005912:12437:21903 [2] NCCL INFO Channel 07/0 : 86[2] -> 78[2] [receive] via NET/AWS Libfabric/2
28: nid005929:16032:25538 [2] NCCL INFO Channel 06/0 : 118[2] -> 114[2] [receive] via NET/AWS Libfabric/2
11: nid005591:191605:202358 [2] NCCL INFO Channel 07/0 : 46[2] -> 38[2] [send] via NET/AWS Libfabric/2
12: nid005594:53087:62620 [2] NCCL INFO Channel 06/0 : 54[2] -> 50[2] [receive] via NET/AWS Libfabric/2
 3: nid005580:71821:81332 [2] NCCL INFO Channel 06/0 : 14[2] -> 6[2] [send] via NET/AWS Libfabric/2
19: nid005912:12437:21903 [2] NCCL INFO Channel 06/0 : 78[2] -> 70[2] [send] via NET/AWS Libfabric/2
14: nid005600:217722:227328 [2] NCCL INFO Channel 02/0 : 62[2] -> 58[2] [receive] via NET/AWS Libfabric/2
 6: nid005584:28287:37728 [2] NCCL INFO Channel 02/0 : 30[2] -> 26[2] [receive] via NET/AWS Libfabric/2
 9: nid005588:35935:45450 [0] NCCL INFO Channel 05/0 : 36[0] -> 32[0] [send] via NET/AWS Libfabric/0
20: nid005913:292683:9619 [2] NCCL INFO Channel 06/0 : 86[2] -> 82[2] [receive] via NET/AWS Libfabric/2
26: nid005920:67125:76630 [2] NCCL INFO Channel 02/0 : 110[2] -> 106[2] [receive] via NET/AWS Libfabric/2
30: nid005936:49910:59408 [2] NCCL INFO Channel 03/0 : 126[2] -> 122[2] [receive] via NET/AWS Libfabric/2
28: nid005929:16032:25538 [2] NCCL INFO Channel 07/0 : 118[2] -> 114[2] [receive] via NET/AWS Libfabric/2
22: nid005915:274816:284311 [2] NCCL INFO Channel 02/0 : 94[2] -> 90[2] [receive] via NET/AWS Libfabric/2
24: nid005918:92504:102030 [0] NCCL INFO Channel 00/0 : 112[0] -> 96[0] [receive] via NET/AWS Libfabric/0
12: nid005594:53087:62620 [2] NCCL INFO Channel 07/0 : 54[2] -> 50[2] [receive] via NET/AWS Libfabric/2
10: nid005590:110712:120160 [2] NCCL INFO Channel 02/0 : 46[2] -> 42[2] [receive] via NET/AWS Libfabric/2
 4: nid005581:264525:274016 [2] NCCL INFO Channel 06/0 : 22[2] -> 18[2] [receive] via NET/AWS Libfabric/2
16: nid005802:6297:15957 [0] NCCL INFO Channel 04/0 : 68[0] -> 64[0] [receive] via NET/AWS Libfabric/0
 3: nid005580:71821:81332 [2] NCCL INFO Channel 07/0 : 14[2] -> 6[2] [send] via NET/AWS Libfabric/2
19: nid005912:12437:21903 [2] NCCL INFO Channel 07/0 : 78[2] -> 70[2] [send] via NET/AWS Libfabric/2
30: nid005936:49910:59408 [2] NCCL INFO Channel 02/0 : 122[2] -> 118[2] [send] via NET/AWS Libfabric/2
 8: nid005586:68926:78453 [0] NCCL INFO Channel 00/0 : 48[0] -> 32[0] [receive] via NET/AWS Libfabric/0
14: nid005600:217722:227328 [2] NCCL INFO Channel 03/0 : 62[2] -> 58[2] [receive] via NET/AWS Libfabric/2
 6: nid005584:28287:37728 [2] NCCL INFO Channel 03/0 : 30[2] -> 26[2] [receive] via NET/AWS Libfabric/2
 4: nid005581:264525:274016 [2] NCCL INFO Channel 07/0 : 22[2] -> 18[2] [receive] via NET/AWS Libfabric/2
20: nid005913:292683:9619 [2] NCCL INFO Channel 07/0 : 86[2] -> 82[2] [receive] via NET/AWS Libfabric/2
18: nid005911:38866:48385 [2] NCCL INFO Channel 02/0 : 78[2] -> 74[2] [receive] via NET/AWS Libfabric/2
26: nid005920:67125:76630 [2] NCCL INFO Channel 03/0 : 110[2] -> 106[2] [receive] via NET/AWS Libfabric/2
30: nid005936:49910:59408 [2] NCCL INFO Channel 03/0 : 122[2] -> 118[2] [send] via NET/AWS Libfabric/2
27: nid005922:80743:90206 [2] NCCL INFO Channel 02/0 : 110[2] -> 106[2] [send] via NET/AWS Libfabric/2
 6: nid005584:28287:37728 [2] NCCL INFO Channel 02/0 : 26[2] -> 22[2] [send] via NET/AWS Libfabric/2
29: nid005932:167682:177153 [2] NCCL INFO Channel 02/0 : 122[2] -> 118[2] [receive] via NET/AWS Libfabric/2
24: nid005918:92504:102030 [0] NCCL INFO Channel 01/0 : 112[0] -> 96[0] [receive] via NET/AWS Libfabric/0
 2: nid005577:17424:27012 [2] NCCL INFO Channel 02/0 : 14[2] -> 10[2] [receive] via NET/AWS Libfabric/2
16: nid005802:6297:15957 [0] NCCL INFO Channel 05/0 : 68[0] -> 64[0] [receive] via NET/AWS Libfabric/0
18: nid005911:38866:48385 [2] NCCL INFO Channel 03/0 : 78[2] -> 74[2] [receive] via NET/AWS Libfabric/2
26: nid005920:67125:76630 [2] NCCL INFO Channel 02/0 : 106[2] -> 102[2] [send] via NET/AWS Libfabric/2
25: nid005919:107464:116998 [2] NCCL INFO Channel 02/0 : 106[2] -> 102[2] [receive] via NET/AWS Libfabric/2
30: nid005936:49910:59408 [2] NCCL INFO Channel 06/0 : 122[2] -> 118[2] [send] via NET/AWS Libfabric/2
 8: nid005586:68926:78453 [0] NCCL INFO Channel 01/0 : 48[0] -> 32[0] [receive] via NET/AWS Libfabric/0
14: nid005600:217722:227328 [2] NCCL INFO Channel 02/0 : 58[2] -> 54[2] [send] via NET/AWS Libfabric/2
22: nid005915:274816:284311 [2] NCCL INFO Channel 03/0 : 94[2] -> 90[2] [receive] via NET/AWS Libfabric/2
29: nid005932:167682:177153 [2] NCCL INFO Channel 03/0 : 122[2] -> 118[2] [receive] via NET/AWS Libfabric/2
24: nid005918:92504:102030 [0] NCCL INFO Channel 00/0 : 96[0] -> 80[0] [send] via NET/AWS Libfabric/0
 2: nid005577:17424:27012 [2] NCCL INFO Channel 03/0 : 14[2] -> 10[2] [receive] via NET/AWS Libfabric/2
26: nid005920:67125:76630 [2] NCCL INFO Channel 03/0 : 106[2] -> 102[2] [send] via NET/AWS Libfabric/2
14: nid005600:217722:227328 [2] NCCL INFO Channel 03/0 : 58[2] -> 54[2] [send] via NET/AWS Libfabric/2
22: nid005915:274816:284311 [2] NCCL INFO Channel 02/0 : 90[2] -> 86[2] [send] via NET/AWS Libfabric/2
24: nid005918:92504:102030 [0] NCCL INFO Channel 01/0 : 96[0] -> 80[0] [send] via NET/AWS Libfabric/0
 9: nid005588:35937:45448 [2] NCCL INFO Channel 02/0 : 42[2] -> 38[2] [receive] via NET/AWS Libfabric/2
13: nid005595:197885:207750 [2] NCCL INFO Channel 02/0 : 58[2] -> 54[2] [receive] via NET/AWS Libfabric/2
18: nid005911:38866:48385 [2] NCCL INFO Channel 02/0 : 74[2] -> 70[2] [send] via NET/AWS Libfabric/2
27: nid005922:80743:90206 [2] NCCL INFO Channel 03/0 : 110[2] -> 106[2] [send] via NET/AWS Libfabric/2
 6: nid005584:28287:37728 [2] NCCL INFO Channel 03/0 : 26[2] -> 22[2] [send] via NET/AWS Libfabric/2
10: nid005590:110712:120160 [2] NCCL INFO Channel 03/0 : 46[2] -> 42[2] [receive] via NET/AWS Libfabric/2
 2: nid005577:17424:27012 [2] NCCL INFO Channel 02/0 : 10[2] -> 6[2] [send] via NET/AWS Libfabric/2
13: nid005595:197885:207750 [2] NCCL INFO Channel 03/0 : 58[2] -> 54[2] [receive] via NET/AWS Libfabric/2
18: nid005911:38866:48385 [2] NCCL INFO Channel 03/0 : 74[2] -> 70[2] [send] via NET/AWS Libfabric/2
 8: nid005586:68926:78453 [0] NCCL INFO Channel 00/0 : 32[0] -> 16[0] [send] via NET/AWS Libfabric/0
 6: nid005584:28287:37728 [2] NCCL INFO Channel 06/0 : 26[2] -> 22[2] [send] via NET/AWS Libfabric/2
11: nid005591:191605:202358 [2] NCCL INFO Channel 02/0 : 46[2] -> 42[2] [send] via NET/AWS Libfabric/2
10: nid005590:110712:120160 [2] NCCL INFO Channel 02/0 : 42[2] -> 38[2] [send] via NET/AWS Libfabric/2
 2: nid005577:17424:27012 [2] NCCL INFO Channel 03/0 : 10[2] -> 6[2] [send] via NET/AWS Libfabric/2
19: nid005912:12437:21903 [2] NCCL INFO Channel 02/0 : 78[2] -> 74[2] [send] via NET/AWS Libfabric/2
25: nid005919:107464:116998 [2] NCCL INFO Channel 03/0 : 106[2] -> 102[2] [receive] via NET/AWS Libfabric/2
 8: nid005586:68926:78453 [0] NCCL INFO Channel 01/0 : 32[0] -> 16[0] [send] via NET/AWS Libfabric/0
 6: nid005584:28287:37728 [2] NCCL INFO Channel 07/0 : 26[2] -> 22[2] [send] via NET/AWS Libfabric/2
11: nid005591:191605:202358 [2] NCCL INFO Channel 03/0 : 46[2] -> 42[2] [send] via NET/AWS Libfabric/2
22: nid005915:274816:284311 [2] NCCL INFO Channel 03/0 : 90[2] -> 86[2] [send] via NET/AWS Libfabric/2
10: nid005590:110712:120160 [2] NCCL INFO Channel 03/0 : 42[2] -> 38[2] [send] via NET/AWS Libfabric/2
 9: nid005588:35937:45448 [2] NCCL INFO Channel 03/0 : 42[2] -> 38[2] [receive] via NET/AWS Libfabric/2
17: nid005803:180734:190257 [2] NCCL INFO Channel 02/0 : 74[2] -> 70[2] [receive] via NET/AWS Libfabric/2
 5: nid005582:196715:206731 [2] NCCL INFO Channel 02/0 : 26[2] -> 22[2] [receive] via NET/AWS Libfabric/2
21: nid005914:166786:176251 [2] NCCL INFO Channel 02/0 : 90[2] -> 86[2] [receive] via NET/AWS Libfabric/2
26: nid005920:67125:76630 [2] NCCL INFO Channel 06/0 : 106[2] -> 102[2] [send] via NET/AWS Libfabric/2
25: nid005919:107464:116998 [2] NCCL INFO Channel 06/0 : 106[2] -> 102[2] [receive] via NET/AWS Libfabric/2
30: nid005936:49910:59408 [2] NCCL INFO Channel 07/0 : 122[2] -> 118[2] [send] via NET/AWS Libfabric/2
14: nid005600:217722:227328 [2] NCCL INFO Channel 06/0 : 58[2] -> 54[2] [send] via NET/AWS Libfabric/2
22: nid005915:274816:284311 [2] NCCL INFO Channel 06/0 : 90[2] -> 86[2] [send] via NET/AWS Libfabric/2
29: nid005932:167682:177153 [2] NCCL INFO Channel 06/0 : 122[2] -> 118[2] [receive] via NET/AWS Libfabric/2
10: nid005590:110712:120160 [2] NCCL INFO Channel 06/0 : 42[2] -> 38[2] [send] via NET/AWS Libfabric/2
 2: nid005577:17424:27012 [2] NCCL INFO Channel 06/0 : 10[2] -> 6[2] [send] via NET/AWS Libfabric/2
 1: nid005576:147559:157018 [2] NCCL INFO Channel 02/0 : 10[2] -> 6[2] [receive] via NET/AWS Libfabric/2
 9: nid005588:35937:45448 [2] NCCL INFO Channel 06/0 : 42[2] -> 38[2] [receive] via NET/AWS Libfabric/2
 3: nid005580:71821:81332 [2] NCCL INFO Channel 02/0 : 14[2] -> 10[2] [send] via NET/AWS Libfabric/2
13: nid005595:197885:207750 [2] NCCL INFO Channel 06/0 : 58[2] -> 54[2] [receive] via NET/AWS Libfabric/2
 5: nid005582:196715:206731 [2] NCCL INFO Channel 03/0 : 26[2] -> 22[2] [receive] via NET/AWS Libfabric/2
18: nid005911:38866:48385 [2] NCCL INFO Channel 06/0 : 74[2] -> 70[2] [send] via NET/AWS Libfabric/2
21: nid005914:166786:176251 [2] NCCL INFO Channel 03/0 : 90[2] -> 86[2] [receive] via NET/AWS Libfabric/2
26: nid005920:67125:76630 [2] NCCL INFO Channel 07/0 : 106[2] -> 102[2] [send] via NET/AWS Libfabric/2
14: nid005600:217722:227328 [2] NCCL INFO Channel 07/0 : 58[2] -> 54[2] [send] via NET/AWS Libfabric/2
29: nid005932:167682:177153 [2] NCCL INFO Channel 07/0 : 122[2] -> 118[2] [receive] via NET/AWS Libfabric/2
10: nid005590:110712:120160 [2] NCCL INFO Channel 07/0 : 42[2] -> 38[2] [send] via NET/AWS Libfabric/2
 2: nid005577:17424:27012 [2] NCCL INFO Channel 07/0 : 10[2] -> 6[2] [send] via NET/AWS Libfabric/2
 4: nid005581:264523:274015 [0] NCCL INFO Channel 00/0 : 24[0] -> 16[0] [receive] via NET/AWS Libfabric/0
 9: nid005588:35937:45448 [2] NCCL INFO Channel 07/0 : 42[2] -> 38[2] [receive] via NET/AWS Libfabric/2
17: nid005803:180734:190257 [2] NCCL INFO Channel 03/0 : 74[2] -> 70[2] [receive] via NET/AWS Libfabric/2
13: nid005595:197885:207750 [2] NCCL INFO Channel 07/0 : 58[2] -> 54[2] [receive] via NET/AWS Libfabric/2
 5: nid005582:196715:206731 [2] NCCL INFO Channel 06/0 : 26[2] -> 22[2] [receive] via NET/AWS Libfabric/2
20: nid005913:292681:9616 [0] NCCL INFO Channel 00/0 : 88[0] -> 80[0] [receive] via NET/AWS Libfabric/0
18: nid005911:38866:48385 [2] NCCL INFO Channel 07/0 : 74[2] -> 70[2] [send] via NET/AWS Libfabric/2
19: nid005912:12437:21903 [2] NCCL INFO Channel 03/0 : 78[2] -> 74[2] [send] via NET/AWS Libfabric/2
21: nid005914:166786:176251 [2] NCCL INFO Channel 06/0 : 90[2] -> 86[2] [receive] via NET/AWS Libfabric/2
25: nid005919:107464:116998 [2] NCCL INFO Channel 07/0 : 106[2] -> 102[2] [receive] via NET/AWS Libfabric/2
28: nid005929:16030:25536 [0] NCCL INFO Channel 00/0 : 120[0] -> 112[0] [receive] via NET/AWS Libfabric/0
22: nid005915:274816:284311 [2] NCCL INFO Channel 07/0 : 90[2] -> 86[2] [send] via NET/AWS Libfabric/2
29: nid005932:167682:177153 [2] NCCL INFO Channel 06/0 : 118[2] -> 114[2] [send] via NET/AWS Libfabric/2
24: nid005918:92504:102030 [0] NCCL INFO Channel 04/0 : 100[0] -> 96[0] [receive] via NET/AWS Libfabric/0
12: nid005594:53085:62618 [0] NCCL INFO Channel 00/0 : 56[0] -> 48[0] [receive] via NET/AWS Libfabric/0
 1: nid005576:147559:157018 [2] NCCL INFO Channel 03/0 : 10[2] -> 6[2] [receive] via NET/AWS Libfabric/2
 4: nid005581:264523:274015 [0] NCCL INFO Channel 01/0 : 24[0] -> 16[0] [receive] via NET/AWS Libfabric/0
17: nid005803:180734:190257 [2] NCCL INFO Channel 06/0 : 74[2] -> 70[2] [receive] via NET/AWS Libfabric/2
 3: nid005580:71821:81332 [2] NCCL INFO Channel 03/0 : 14[2] -> 10[2] [send] via NET/AWS Libfabric/2
13: nid005595:197885:207750 [2] NCCL INFO Channel 06/0 : 54[2] -> 50[2] [send] via NET/AWS Libfabric/2
 5: nid005582:196715:206731 [2] NCCL INFO Channel 07/0 : 26[2] -> 22[2] [receive] via NET/AWS Libfabric/2
20: nid005913:292681:9616 [0] NCCL INFO Channel 01/0 : 88[0] -> 80[0] [receive] via NET/AWS Libfabric/0
21: nid005914:166786:176251 [2] NCCL INFO Channel 07/0 : 90[2] -> 86[2] [receive] via NET/AWS Libfabric/2
25: nid005919:107464:116998 [2] NCCL INFO Channel 06/0 : 102[2] -> 98[2] [send] via NET/AWS Libfabric/2
28: nid005929:16030:25536 [0] NCCL INFO Channel 01/0 : 120[0] -> 112[0] [receive] via NET/AWS Libfabric/0
 8: nid005586:68926:78453 [0] NCCL INFO Channel 04/0 : 36[0] -> 32[0] [receive] via NET/AWS Libfabric/0
29: nid005932:167682:177153 [2] NCCL INFO Channel 07/0 : 118[2] -> 114[2] [send] via NET/AWS Libfabric/2
24: nid005918:92504:102030 [0] NCCL INFO Channel 05/0 : 100[0] -> 96[0] [receive] via NET/AWS Libfabric/0
12: nid005594:53085:62618 [0] NCCL INFO Channel 01/0 : 56[0] -> 48[0] [receive] via NET/AWS Libfabric/0
 1: nid005576:147559:157018 [2] NCCL INFO Channel 06/0 : 10[2] -> 6[2] [receive] via NET/AWS Libfabric/2
 4: nid005581:264523:274015 [0] NCCL INFO Channel 00/0 : 16[0] -> 8[0] [send] via NET/AWS Libfabric/0
 9: nid005588:35937:45448 [2] NCCL INFO Channel 06/0 : 38[2] -> 34[2] [send] via NET/AWS Libfabric/2
17: nid005803:180734:190257 [2] NCCL INFO Channel 07/0 : 74[2] -> 70[2] [receive] via NET/AWS Libfabric/2
13: nid005595:197885:207750 [2] NCCL INFO Channel 07/0 : 54[2] -> 50[2] [send] via NET/AWS Libfabric/2
 5: nid005582:196715:206731 [2] NCCL INFO Channel 06/0 : 22[2] -> 18[2] [send] via NET/AWS Libfabric/2
20: nid005913:292681:9616 [0] NCCL INFO Channel 00/0 : 80[0] -> 72[0] [send] via NET/AWS Libfabric/0
21: nid005914:166786:176251 [2] NCCL INFO Channel 06/0 : 86[2] -> 82[2] [send] via NET/AWS Libfabric/2
25: nid005919:107464:116998 [2] NCCL INFO Channel 07/0 : 102[2] -> 98[2] [send] via NET/AWS Libfabric/2
28: nid005929:16030:25536 [0] NCCL INFO Channel 00/0 : 112[0] -> 104[0] [send] via NET/AWS Libfabric/0
 8: nid005586:68926:78453 [0] NCCL INFO Channel 05/0 : 36[0] -> 32[0] [receive] via NET/AWS Libfabric/0
12: nid005594:53085:62618 [0] NCCL INFO Channel 00/0 : 48[0] -> 40[0] [send] via NET/AWS Libfabric/0
 1: nid005576:147559:157018 [2] NCCL INFO Channel 07/0 : 10[2] -> 6[2] [receive] via NET/AWS Libfabric/2
 4: nid005581:264523:274015 [0] NCCL INFO Channel 01/0 : 16[0] -> 8[0] [send] via NET/AWS Libfabric/0
17: nid005803:180734:190257 [2] NCCL INFO Channel 06/0 : 70[2] -> 66[2] [send] via NET/AWS Libfabric/2
 5: nid005582:196715:206731 [2] NCCL INFO Channel 07/0 : 22[2] -> 18[2] [send] via NET/AWS Libfabric/2
20: nid005913:292681:9616 [0] NCCL INFO Channel 01/0 : 80[0] -> 72[0] [send] via NET/AWS Libfabric/0
21: nid005914:166786:176251 [2] NCCL INFO Channel 07/0 : 86[2] -> 82[2] [send] via NET/AWS Libfabric/2
28: nid005929:16030:25536 [0] NCCL INFO Channel 01/0 : 112[0] -> 104[0] [send] via NET/AWS Libfabric/0
12: nid005594:53085:62618 [0] NCCL INFO Channel 01/0 : 48[0] -> 40[0] [send] via NET/AWS Libfabric/0
 1: nid005576:147559:157018 [2] NCCL INFO Channel 06/0 : 6[2] -> 2[2] [send] via NET/AWS Libfabric/2
 9: nid005588:35937:45448 [2] NCCL INFO Channel 07/0 : 38[2] -> 34[2] [send] via NET/AWS Libfabric/2
17: nid005803:180734:190257 [2] NCCL INFO Channel 07/0 : 70[2] -> 66[2] [send] via NET/AWS Libfabric/2
30: nid005936:49908:59406 [0] NCCL INFO Channel 00/0 : 124[0] -> 120[0] [receive] via NET/AWS Libfabric/0
14: nid005600:217720:227327 [0] NCCL INFO Channel 00/0 : 60[0] -> 56[0] [receive] via NET/AWS Libfabric/0
 1: nid005576:147559:157018 [2] NCCL INFO Channel 07/0 : 6[2] -> 2[2] [send] via NET/AWS Libfabric/2
12: nid005594:53085:62618 [0] NCCL INFO Channel 04/0 : 52[0] -> 48[0] [receive] via NET/AWS Libfabric/0
28: nid005929:16030:25536 [0] NCCL INFO Channel 04/0 : 116[0] -> 112[0] [receive] via NET/AWS Libfabric/0
30: nid005936:49908:59406 [0] NCCL INFO Channel 01/0 : 124[0] -> 120[0] [receive] via NET/AWS Libfabric/0
26: nid005920:67123:76628 [0] NCCL INFO Channel 00/0 : 108[0] -> 104[0] [receive] via NET/AWS Libfabric/0
14: nid005600:217720:227327 [0] NCCL INFO Channel 01/0 : 60[0] -> 56[0] [receive] via NET/AWS Libfabric/0
 6: nid005584:28285:37730 [0] NCCL INFO Channel 00/0 : 28[0] -> 24[0] [receive] via NET/AWS Libfabric/0
12: nid005594:53085:62618 [0] NCCL INFO Channel 05/0 : 52[0] -> 48[0] [receive] via NET/AWS Libfabric/0
10: nid005590:110710:120158 [0] NCCL INFO Channel 00/0 : 44[0] -> 40[0] [receive] via NET/AWS Libfabric/0
 4: nid005581:264523:274015 [0] NCCL INFO Channel 04/0 : 20[0] -> 16[0] [receive] via NET/AWS Libfabric/0
10: nid005590:110710:120158 [0] NCCL INFO Channel 01/0 : 44[0] -> 40[0] [receive] via NET/AWS Libfabric/0
26: nid005920:67123:76628 [0] NCCL INFO Channel 01/0 : 108[0] -> 104[0] [receive] via NET/AWS Libfabric/0
30: nid005936:49908:59406 [0] NCCL INFO Channel 00/0 : 120[0] -> 116[0] [send] via NET/AWS Libfabric/0
28: nid005929:16030:25536 [0] NCCL INFO Channel 05/0 : 116[0] -> 112[0] [receive] via NET/AWS Libfabric/0
14: nid005600:217720:227327 [0] NCCL INFO Channel 00/0 : 56[0] -> 52[0] [send] via NET/AWS Libfabric/0
22: nid005915:274814:284312 [0] NCCL INFO Channel 00/0 : 92[0] -> 88[0] [receive] via NET/AWS Libfabric/0
30: nid005936:49908:59406 [0] NCCL INFO Channel 01/0 : 120[0] -> 116[0] [send] via NET/AWS Libfabric/0
22: nid005915:274814:284312 [0] NCCL INFO Channel 01/0 : 92[0] -> 88[0] [receive] via NET/AWS Libfabric/0
 4: nid005581:264523:274015 [0] NCCL INFO Channel 05/0 : 20[0] -> 16[0] [receive] via NET/AWS Libfabric/0
20: nid005913:292681:9616 [0] NCCL INFO Channel 04/0 : 84[0] -> 80[0] [receive] via NET/AWS Libfabric/0
26: nid005920:67123:76628 [0] NCCL INFO Channel 00/0 : 104[0] -> 100[0] [send] via NET/AWS Libfabric/0
 6: nid005584:28285:37730 [0] NCCL INFO Channel 01/0 : 28[0] -> 24[0] [receive] via NET/AWS Libfabric/0
10: nid005590:110710:120158 [0] NCCL INFO Channel 00/0 : 40[0] -> 36[0] [send] via NET/AWS Libfabric/0
 2: nid005577:17422:27010 [0] NCCL INFO Channel 00/0 : 12[0] -> 8[0] [receive] via NET/AWS Libfabric/0
16: nid005802:6300:15960 [3] NCCL INFO Channel 00/0 : 67[3] -> 66[2] via P2P/CUMEM
14: nid005600:217720:227327 [0] NCCL INFO Channel 01/0 : 56[0] -> 52[0] [send] via NET/AWS Libfabric/0
20: nid005913:292681:9616 [0] NCCL INFO Channel 05/0 : 84[0] -> 80[0] [receive] via NET/AWS Libfabric/0
18: nid005911:38864:48384 [0] NCCL INFO Channel 00/0 : 76[0] -> 72[0] [receive] via NET/AWS Libfabric/0
26: nid005920:67123:76628 [0] NCCL INFO Channel 01/0 : 104[0] -> 100[0] [send] via NET/AWS Libfabric/0
30: nid005936:49908:59406 [0] NCCL INFO Channel 04/0 : 120[0] -> 116[0] [send] via NET/AWS Libfabric/0
14: nid005600:217720:227327 [0] NCCL INFO Channel 04/0 : 56[0] -> 52[0] [send] via NET/AWS Libfabric/0
10: nid005590:110710:120158 [0] NCCL INFO Channel 01/0 : 40[0] -> 36[0] [send] via NET/AWS Libfabric/0
 2: nid005577:17422:27010 [0] NCCL INFO Channel 01/0 : 12[0] -> 8[0] [receive] via NET/AWS Libfabric/0
30: nid005936:49908:59406 [0] NCCL INFO Channel 05/0 : 120[0] -> 116[0] [send] via NET/AWS Libfabric/0
14: nid005600:217720:227327 [0] NCCL INFO Channel 05/0 : 56[0] -> 52[0] [send] via NET/AWS Libfabric/0
 6: nid005584:28285:37730 [0] NCCL INFO Channel 00/0 : 24[0] -> 20[0] [send] via NET/AWS Libfabric/0
22: nid005915:274814:284312 [0] NCCL INFO Channel 00/0 : 88[0] -> 84[0] [send] via NET/AWS Libfabric/0
31: nid005937:256591:266071 [2] NCCL INFO Channel 01/0 : 126[2] -> 125[1] via P2P/CUMEM
 0: nid005574:69061:78922 [3] NCCL INFO Channel 00/0 : 3[3] -> 2[2] via P2P/CUMEM
10: nid005590:110710:120158 [0] NCCL INFO Channel 04/0 : 40[0] -> 36[0] [send] via NET/AWS Libfabric/0
 2: nid005577:17422:27010 [0] NCCL INFO Channel 00/0 : 8[0] -> 4[0] [send] via NET/AWS Libfabric/0
 7: nid005585:122007:131444 [2] NCCL INFO Channel 01/0 : 30[2] -> 29[1] via P2P/CUMEM
18: nid005911:38864:48384 [0] NCCL INFO Channel 01/0 : 76[0] -> 72[0] [receive] via NET/AWS Libfabric/0
26: nid005920:67123:76628 [0] NCCL INFO Channel 04/0 : 104[0] -> 100[0] [send] via NET/AWS Libfabric/0
 6: nid005584:28285:37730 [0] NCCL INFO Channel 01/0 : 24[0] -> 20[0] [send] via NET/AWS Libfabric/0
22: nid005915:274814:284312 [0] NCCL INFO Channel 01/0 : 88[0] -> 84[0] [send] via NET/AWS Libfabric/0
15: nid005601:210678:220275 [2] NCCL INFO Channel 01/0 : 62[2] -> 61[1] via P2P/CUMEM
18: nid005911:38864:48384 [0] NCCL INFO Channel 00/0 : 72[0] -> 68[0] [send] via NET/AWS Libfabric/0
26: nid005920:67123:76628 [0] NCCL INFO Channel 05/0 : 104[0] -> 100[0] [send] via NET/AWS Libfabric/0
27: nid005922:80743:90206 [2] NCCL INFO Channel 01/0 : 110[2] -> 109[1] via P2P/CUMEM
 6: nid005584:28285:37730 [0] NCCL INFO Channel 04/0 : 24[0] -> 20[0] [send] via NET/AWS Libfabric/0
22: nid005915:274814:284312 [0] NCCL INFO Channel 04/0 : 88[0] -> 84[0] [send] via NET/AWS Libfabric/0
31: nid005937:256591:266071 [2] NCCL INFO Channel 05/0 : 126[2] -> 125[1] via P2P/CUMEM
10: nid005590:110710:120158 [0] NCCL INFO Channel 05/0 : 40[0] -> 36[0] [send] via NET/AWS Libfabric/0
 2: nid005577:17422:27010 [0] NCCL INFO Channel 01/0 : 8[0] -> 4[0] [send] via NET/AWS Libfabric/0
18: nid005911:38864:48384 [0] NCCL INFO Channel 01/0 : 72[0] -> 68[0] [send] via NET/AWS Libfabric/0
19: nid005912:12437:21903 [2] NCCL INFO Channel 01/0 : 78[2] -> 77[1] via P2P/CUMEM
23: nid005917:276887:286401 [2] NCCL INFO Channel 01/0 : 94[2] -> 93[1] via P2P/CUMEM
22: nid005915:274814:284312 [0] NCCL INFO Channel 05/0 : 88[0] -> 84[0] [send] via NET/AWS Libfabric/0
 2: nid005577:17422:27010 [0] NCCL INFO Channel 04/0 : 8[0] -> 4[0] [send] via NET/AWS Libfabric/0
 7: nid005585:122007:131444 [2] NCCL INFO Channel 05/0 : 30[2] -> 29[1] via P2P/CUMEM
 6: nid005584:28285:37730 [0] NCCL INFO Channel 05/0 : 24[0] -> 20[0] [send] via NET/AWS Libfabric/0
11: nid005591:191605:202358 [2] NCCL INFO Channel 01/0 : 46[2] -> 45[1] via P2P/CUMEM
 3: nid005580:71821:81332 [2] NCCL INFO Channel 01/0 : 14[2] -> 13[1] via P2P/CUMEM
18: nid005911:38864:48384 [0] NCCL INFO Channel 04/0 : 72[0] -> 68[0] [send] via NET/AWS Libfabric/0
27: nid005922:80743:90206 [2] NCCL INFO Channel 05/0 : 110[2] -> 109[1] via P2P/CUMEM
 2: nid005577:17422:27010 [0] NCCL INFO Channel 05/0 : 8[0] -> 4[0] [send] via NET/AWS Libfabric/0
23: nid005917:276887:286401 [2] NCCL INFO Channel 05/0 : 94[2] -> 93[1] via P2P/CUMEM
30: nid005936:49910:59408 [2] NCCL INFO Channel 00/0 : 122[2] -> 121[1] via P2P/CUMEM
18: nid005911:38864:48384 [0] NCCL INFO Channel 05/0 : 72[0] -> 68[0] [send] via NET/AWS Libfabric/0
26: nid005920:67125:76630 [2] NCCL INFO Channel 00/0 : 106[2] -> 105[1] via P2P/CUMEM
19: nid005912:12437:21903 [2] NCCL INFO Channel 05/0 : 78[2] -> 77[1] via P2P/CUMEM
11: nid005591:191605:202358 [2] NCCL INFO Channel 05/0 : 46[2] -> 45[1] via P2P/CUMEM
16: nid005802:6300:15960 [3] NCCL INFO Channel 02/0 : 67[3] -> 66[2] via P2P/CUMEM
 3: nid005580:71821:81332 [2] NCCL INFO Channel 05/0 : 14[2] -> 13[1] via P2P/CUMEM
15: nid005601:210678:220275 [2] NCCL INFO Channel 05/0 : 62[2] -> 61[1] via P2P/CUMEM
 0: nid005574:69061:78922 [3] NCCL INFO Channel 02/0 : 3[3] -> 2[2] via P2P/CUMEM
 6: nid005584:28287:37728 [2] NCCL INFO Channel 00/0 : 26[2] -> 25[1] via P2P/CUMEM
25: nid005919:107464:116998 [2] NCCL INFO Channel 01/0 : 102[2] -> 101[1] via P2P/CUMEM
18: nid005911:38866:48385 [2] NCCL INFO Channel 00/0 : 74[2] -> 73[1] via P2P/CUMEM
 5: nid005582:196715:206731 [2] NCCL INFO Channel 01/0 : 22[2] -> 21[1] via P2P/CUMEM
10: nid005590:110712:120160 [2] NCCL INFO Channel 00/0 : 42[2] -> 41[1] via P2P/CUMEM
13: nid005595:197885:207750 [2] NCCL INFO Channel 01/0 : 54[2] -> 53[1] via P2P/CUMEM
30: nid005936:49910:59408 [2] NCCL INFO Channel 04/0 : 122[2] -> 121[1] via P2P/CUMEM
26: nid005920:67125:76630 [2] NCCL INFO Channel 04/0 : 106[2] -> 105[1] via P2P/CUMEM
14: nid005600:217722:227328 [2] NCCL INFO Channel 00/0 : 58[2] -> 57[1] via P2P/CUMEM
25: nid005919:107464:116998 [2] NCCL INFO Channel 05/0 : 102[2] -> 101[1] via P2P/CUMEM
 5: nid005582:196715:206731 [2] NCCL INFO Channel 05/0 : 22[2] -> 21[1] via P2P/CUMEM
 6: nid005584:28287:37728 [2] NCCL INFO Channel 04/0 : 26[2] -> 25[1] via P2P/CUMEM
 2: nid005577:17424:27012 [2] NCCL INFO Channel 00/0 : 10[2] -> 9[1] via P2P/CUMEM
 9: nid005588:35937:45448 [2] NCCL INFO Channel 01/0 : 38[2] -> 37[1] via P2P/CUMEM
17: nid005803:180734:190257 [2] NCCL INFO Channel 01/0 : 70[2] -> 69[1] via P2P/CUMEM
28: nid005929:16032:25538 [2] NCCL INFO Channel 00/0 : 114[2] -> 113[1] via P2P/CUMEM
16: nid005802:6300:15960 [3] NCCL INFO Channel 04/0 : 67[3] -> 66[2] via P2P/CUMEM
 8: nid005586:68929:78454 [3] NCCL INFO Channel 00/0 : 35[3] -> 34[2] via P2P/CUMEM
22: nid005915:274816:284311 [2] NCCL INFO Channel 00/0 : 90[2] -> 89[1] via P2P/CUMEM
21: nid005914:166786:176251 [2] NCCL INFO Channel 01/0 : 86[2] -> 85[1] via P2P/CUMEM
18: nid005911:38866:48385 [2] NCCL INFO Channel 04/0 : 74[2] -> 73[1] via P2P/CUMEM
 8: nid005586:68928:78455 [2] NCCL INFO Channel 00/0 : 34[2] -> 33[1] via P2P/CUMEM
12: nid005594:53087:62620 [2] NCCL INFO Channel 00/0 : 50[2] -> 49[1] via P2P/CUMEM
10: nid005590:110712:120160 [2] NCCL INFO Channel 04/0 : 42[2] -> 41[1] via P2P/CUMEM
 0: nid005574:69061:78922 [3] NCCL INFO Channel 04/0 : 3[3] -> 2[2] via P2P/CUMEM
14: nid005600:217722:227328 [2] NCCL INFO Channel 04/0 : 58[2] -> 57[1] via P2P/CUMEM
 1: nid005576:147559:157018 [2] NCCL INFO Channel 01/0 : 6[2] -> 5[1] via P2P/CUMEM
 9: nid005588:35937:45448 [2] NCCL INFO Channel 05/0 : 38[2] -> 37[1] via P2P/CUMEM
13: nid005595:197885:207750 [2] NCCL INFO Channel 05/0 : 54[2] -> 53[1] via P2P/CUMEM
17: nid005803:180734:190257 [2] NCCL INFO Channel 05/0 : 70[2] -> 69[1] via P2P/CUMEM
 4: nid005581:264525:274016 [2] NCCL INFO Channel 00/0 : 18[2] -> 17[1] via P2P/CUMEM
 2: nid005577:17424:27012 [2] NCCL INFO Channel 04/0 : 10[2] -> 9[1] via P2P/CUMEM
28: nid005929:16032:25538 [2] NCCL INFO Channel 04/0 : 114[2] -> 113[1] via P2P/CUMEM
22: nid005915:274816:284311 [2] NCCL INFO Channel 04/0 : 90[2] -> 89[1] via P2P/CUMEM
21: nid005914:166786:176251 [2] NCCL INFO Channel 05/0 : 86[2] -> 85[1] via P2P/CUMEM
 7: nid005585:122008:131442 [3] NCCL INFO Channel 01/0 : 31[3] -> 30[2] via P2P/CUMEM
12: nid005594:53087:62620 [2] NCCL INFO Channel 04/0 : 50[2] -> 49[1] via P2P/CUMEM
29: nid005932:167682:177153 [2] NCCL INFO Channel 01/0 : 118[2] -> 117[1] via P2P/CUMEM
16: nid005802:6300:15960 [3] NCCL INFO Channel 06/0 : 67[3] -> 66[2] via P2P/CUMEM
15: nid005601:210679:220273 [3] NCCL INFO Channel 01/0 : 63[3] -> 62[2] via P2P/CUMEM
20: nid005913:292683:9619 [2] NCCL INFO Channel 00/0 : 82[2] -> 81[1] via P2P/CUMEM
27: nid005922:80744:90204 [3] NCCL INFO Channel 01/0 : 111[3] -> 110[2] via P2P/CUMEM
 1: nid005576:147559:157018 [2] NCCL INFO Channel 05/0 : 6[2] -> 5[1] via P2P/CUMEM
28: nid005929:16033:25541 [3] NCCL INFO Channel 00/0 : 115[3] -> 114[2] via P2P/CUMEM
31: nid005937:256592:266073 [3] NCCL INFO Channel 01/0 : 127[3] -> 126[2] via P2P/CUMEM
 8: nid005586:68929:78454 [3] NCCL INFO Channel 02/0 : 35[3] -> 34[2] via P2P/CUMEM
11: nid005591:191606:202356 [3] NCCL INFO Channel 01/0 : 47[3] -> 46[2] via P2P/CUMEM
23: nid005917:276888:286400 [3] NCCL INFO Channel 01/0 : 95[3] -> 94[2] via P2P/CUMEM
 8: nid005586:68928:78455 [2] NCCL INFO Channel 04/0 : 34[2] -> 33[1] via P2P/CUMEM
 0: nid005574:69061:78922 [3] NCCL INFO Channel 06/0 : 3[3] -> 2[2] via P2P/CUMEM
12: nid005594:53088:62621 [3] NCCL INFO Channel 00/0 : 51[3] -> 50[2] via P2P/CUMEM
 3: nid005580:71822:81331 [3] NCCL INFO Channel 01/0 : 15[3] -> 14[2] via P2P/CUMEM
26: nid005920:67126:76631 [3] NCCL INFO Channel 00/0 : 107[3] -> 106[2] via P2P/CUMEM
25: nid005919:107465:116997 [3] NCCL INFO Channel 01/0 : 103[3] -> 102[2] via P2P/CUMEM
 4: nid005581:264525:274016 [2] NCCL INFO Channel 04/0 : 18[2] -> 17[1] via P2P/CUMEM
30: nid005936:49911:59407 [3] NCCL INFO Channel 00/0 : 123[3] -> 122[2] via P2P/CUMEM
19: nid005912:12438:21905 [3] NCCL INFO Channel 01/0 : 79[3] -> 78[2] via P2P/CUMEM
 5: nid005582:196716:206730 [3] NCCL INFO Channel 01/0 : 23[3] -> 22[2] via P2P/CUMEM
24: nid005918:92506:102031 [2] NCCL INFO Channel 00/0 : 98[2] -> 97[1] via P2P/CUMEM
 7: nid005585:122008:131442 [3] NCCL INFO Channel 03/0 : 31[3] -> 30[2] via P2P/CUMEM
27: nid005922:80744:90204 [3] NCCL INFO Channel 03/0 : 111[3] -> 110[2] via P2P/CUMEM
15: nid005601:210679:220273 [3] NCCL INFO Channel 03/0 : 63[3] -> 62[2] via P2P/CUMEM
31: nid005937:256592:266073 [3] NCCL INFO Channel 03/0 : 127[3] -> 126[2] via P2P/CUMEM
13: nid005595:197886:207752 [3] NCCL INFO Channel 01/0 : 55[3] -> 54[2] via P2P/CUMEM
 6: nid005584:28288:37729 [3] NCCL INFO Channel 00/0 : 27[3] -> 26[2] via P2P/CUMEM
 4: nid005581:264526:274017 [3] NCCL INFO Channel 00/0 : 19[3] -> 18[2] via P2P/CUMEM
16: nid005802:6299:15959 [2] NCCL INFO Channel 00/0 : 66[2] -> 65[1] via P2P/CUMEM
14: nid005600:217723:227325 [3] NCCL INFO Channel 00/0 : 59[3] -> 58[2] via P2P/CUMEM
11: nid005591:191606:202356 [3] NCCL INFO Channel 03/0 : 47[3] -> 46[2] via P2P/CUMEM
 0: nid005574:69060:78921 [2] NCCL INFO Channel 00/0 : 2[2] -> 1[1] via P2P/CUMEM
21: nid005914:166787:176253 [3] NCCL INFO Channel 01/0 : 87[3] -> 86[2] via P2P/CUMEM
22: nid005915:274817:284310 [3] NCCL INFO Channel 00/0 : 91[3] -> 90[2] via P2P/CUMEM
29: nid005932:167682:177153 [2] NCCL INFO Channel 05/0 : 118[2] -> 117[1] via P2P/CUMEM
24: nid005918:92507:102032 [3] NCCL INFO Channel 00/0 : 99[3] -> 98[2] via P2P/CUMEM
 3: nid005580:71822:81331 [3] NCCL INFO Channel 03/0 : 15[3] -> 14[2] via P2P/CUMEM
20: nid005913:292683:9619 [2] NCCL INFO Channel 04/0 : 82[2] -> 81[1] via P2P/CUMEM
18: nid005911:38867:48386 [3] NCCL INFO Channel 00/0 : 75[3] -> 74[2] via P2P/CUMEM
23: nid005917:276888:286400 [3] NCCL INFO Channel 03/0 : 95[3] -> 94[2] via P2P/CUMEM
28: nid005929:16033:25541 [3] NCCL INFO Channel 02/0 : 115[3] -> 114[2] via P2P/CUMEM
12: nid005594:53088:62621 [3] NCCL INFO Channel 02/0 : 51[3] -> 50[2] via P2P/CUMEM
10: nid005590:110713:120157 [3] NCCL INFO Channel 00/0 : 43[3] -> 42[2] via P2P/CUMEM
 2: nid005577:17425:27011 [3] NCCL INFO Channel 00/0 : 11[3] -> 10[2] via P2P/CUMEM
17: nid005803:180735:190256 [3] NCCL INFO Channel 01/0 : 71[3] -> 70[2] via P2P/CUMEM
26: nid005920:67126:76631 [3] NCCL INFO Channel 02/0 : 107[3] -> 106[2] via P2P/CUMEM
 1: nid005576:147560:157021 [3] NCCL INFO Channel 01/0 : 7[3] -> 6[2] via P2P/CUMEM
 9: nid005588:35938:45449 [3] NCCL INFO Channel 01/0 : 39[3] -> 38[2] via P2P/CUMEM
16: nid005802:6299:15959 [2] NCCL INFO Channel 04/0 : 66[2] -> 65[1] via P2P/CUMEM
20: nid005913:292684:9617 [3] NCCL INFO Channel 00/0 : 83[3] -> 82[2] via P2P/CUMEM
25: nid005919:107465:116997 [3] NCCL INFO Channel 03/0 : 103[3] -> 102[2] via P2P/CUMEM
 8: nid005586:68929:78454 [3] NCCL INFO Channel 04/0 : 35[3] -> 34[2] via P2P/CUMEM
24: nid005918:92506:102031 [2] NCCL INFO Channel 04/0 : 98[2] -> 97[1] via P2P/CUMEM
 7: nid005585:122008:131442 [3] NCCL INFO Channel 05/0 : 31[3] -> 30[2] via P2P/CUMEM
 5: nid005582:196716:206730 [3] NCCL INFO Channel 03/0 : 23[3] -> 22[2] via P2P/CUMEM
19: nid005912:12438:21905 [3] NCCL INFO Channel 03/0 : 79[3] -> 78[2] via P2P/CUMEM
30: nid005936:49911:59407 [3] NCCL INFO Channel 02/0 : 123[3] -> 122[2] via P2P/CUMEM
 0: nid005574:69060:78921 [2] NCCL INFO Channel 04/0 : 2[2] -> 1[1] via P2P/CUMEM
27: nid005922:80744:90204 [3] NCCL INFO Channel 05/0 : 111[3] -> 110[2] via P2P/CUMEM
15: nid005601:210679:220273 [3] NCCL INFO Channel 05/0 : 63[3] -> 62[2] via P2P/CUMEM
31: nid005937:256592:266073 [3] NCCL INFO Channel 05/0 : 127[3] -> 126[2] via P2P/CUMEM
 6: nid005584:28288:37729 [3] NCCL INFO Channel 02/0 : 27[3] -> 26[2] via P2P/CUMEM
21: nid005914:166787:176253 [3] NCCL INFO Channel 03/0 : 87[3] -> 86[2] via P2P/CUMEM
14: nid005600:217723:227325 [3] NCCL INFO Channel 02/0 : 59[3] -> 58[2] via P2P/CUMEM
11: nid005591:191606:202356 [3] NCCL INFO Channel 05/0 : 47[3] -> 46[2] via P2P/CUMEM
23: nid005917:276888:286400 [3] NCCL INFO Channel 05/0 : 95[3] -> 94[2] via P2P/CUMEM
28: nid005929:16033:25541 [3] NCCL INFO Channel 04/0 : 115[3] -> 114[2] via P2P/CUMEM
 3: nid005580:71822:81331 [3] NCCL INFO Channel 05/0 : 15[3] -> 14[2] via P2P/CUMEM
13: nid005595:197886:207752 [3] NCCL INFO Channel 03/0 : 55[3] -> 54[2] via P2P/CUMEM
22: nid005915:274817:284310 [3] NCCL INFO Channel 02/0 : 91[3] -> 90[2] via P2P/CUMEM
 2: nid005577:17425:27011 [3] NCCL INFO Channel 02/0 : 11[3] -> 10[2] via P2P/CUMEM
 4: nid005581:264526:274017 [3] NCCL INFO Channel 02/0 : 19[3] -> 18[2] via P2P/CUMEM
18: nid005911:38867:48386 [3] NCCL INFO Channel 02/0 : 75[3] -> 74[2] via P2P/CUMEM
12: nid005594:53088:62621 [3] NCCL INFO Channel 04/0 : 51[3] -> 50[2] via P2P/CUMEM
 1: nid005576:147560:157021 [3] NCCL INFO Channel 03/0 : 7[3] -> 6[2] via P2P/CUMEM
17: nid005803:180735:190256 [3] NCCL INFO Channel 03/0 : 71[3] -> 70[2] via P2P/CUMEM
26: nid005920:67126:76631 [3] NCCL INFO Channel 04/0 : 107[3] -> 106[2] via P2P/CUMEM
10: nid005590:110713:120157 [3] NCCL INFO Channel 02/0 : 43[3] -> 42[2] via P2P/CUMEM
25: nid005919:107465:116997 [3] NCCL INFO Channel 05/0 : 103[3] -> 102[2] via P2P/CUMEM
 8: nid005586:68929:78454 [3] NCCL INFO Channel 06/0 : 35[3] -> 34[2] via P2P/CUMEM
 5: nid005582:196716:206730 [3] NCCL INFO Channel 05/0 : 23[3] -> 22[2] via P2P/CUMEM
 9: nid005588:35938:45449 [3] NCCL INFO Channel 03/0 : 39[3] -> 38[2] via P2P/CUMEM
 7: nid005585:122008:131442 [3] NCCL INFO Channel 07/0 : 31[3] -> 30[2] via P2P/CUMEM
27: nid005922:80744:90204 [3] NCCL INFO Channel 07/0 : 111[3] -> 110[2] via P2P/CUMEM
30: nid005936:49911:59407 [3] NCCL INFO Channel 04/0 : 123[3] -> 122[2] via P2P/CUMEM
15: nid005601:210679:220273 [3] NCCL INFO Channel 07/0 : 63[3] -> 62[2] via P2P/CUMEM
20: nid005913:292684:9617 [3] NCCL INFO Channel 02/0 : 83[3] -> 82[2] via P2P/CUMEM
21: nid005914:166787:176253 [3] NCCL INFO Channel 05/0 : 87[3] -> 86[2] via P2P/CUMEM
 6: nid005584:28288:37729 [3] NCCL INFO Channel 04/0 : 27[3] -> 26[2] via P2P/CUMEM
11: nid005591:191606:202356 [3] NCCL INFO Channel 07/0 : 47[3] -> 46[2] via P2P/CUMEM
29: nid005932:167683:177154 [3] NCCL INFO Channel 01/0 : 119[3] -> 118[2] via P2P/CUMEM
19: nid005912:12438:21905 [3] NCCL INFO Channel 05/0 : 79[3] -> 78[2] via P2P/CUMEM
14: nid005600:217723:227325 [3] NCCL INFO Channel 04/0 : 59[3] -> 58[2] via P2P/CUMEM
22: nid005915:274817:284310 [3] NCCL INFO Channel 04/0 : 91[3] -> 90[2] via P2P/CUMEM
31: nid005937:256592:266073 [3] NCCL INFO Channel 07/0 : 127[3] -> 126[2] via P2P/CUMEM
 1: nid005576:147560:157021 [3] NCCL INFO Channel 05/0 : 7[3] -> 6[2] via P2P/CUMEM
 3: nid005580:71822:81331 [3] NCCL INFO Channel 07/0 : 15[3] -> 14[2] via P2P/CUMEM
28: nid005929:16033:25541 [3] NCCL INFO Channel 06/0 : 115[3] -> 114[2] via P2P/CUMEM
24: nid005918:92507:102032 [3] NCCL INFO Channel 02/0 : 99[3] -> 98[2] via P2P/CUMEM
 2: nid005577:17425:27011 [3] NCCL INFO Channel 04/0 : 11[3] -> 10[2] via P2P/CUMEM
13: nid005595:197886:207752 [3] NCCL INFO Channel 05/0 : 55[3] -> 54[2] via P2P/CUMEM
18: nid005911:38867:48386 [3] NCCL INFO Channel 04/0 : 75[3] -> 74[2] via P2P/CUMEM
26: nid005920:67126:76631 [3] NCCL INFO Channel 06/0 : 107[3] -> 106[2] via P2P/CUMEM
12: nid005594:53088:62621 [3] NCCL INFO Channel 06/0 : 51[3] -> 50[2] via P2P/CUMEM
17: nid005803:180735:190256 [3] NCCL INFO Channel 05/0 : 71[3] -> 70[2] via P2P/CUMEM
23: nid005917:276888:286400 [3] NCCL INFO Channel 07/0 : 95[3] -> 94[2] via P2P/CUMEM
10: nid005590:110713:120157 [3] NCCL INFO Channel 04/0 : 43[3] -> 42[2] via P2P/CUMEM
 4: nid005581:264526:274017 [3] NCCL INFO Channel 04/0 : 19[3] -> 18[2] via P2P/CUMEM
 9: nid005588:35938:45449 [3] NCCL INFO Channel 05/0 : 39[3] -> 38[2] via P2P/CUMEM
25: nid005919:107465:116997 [3] NCCL INFO Channel 07/0 : 103[3] -> 102[2] via P2P/CUMEM
 5: nid005582:196716:206730 [3] NCCL INFO Channel 07/0 : 23[3] -> 22[2] via P2P/CUMEM
21: nid005914:166787:176253 [3] NCCL INFO Channel 07/0 : 87[3] -> 86[2] via P2P/CUMEM
 6: nid005584:28288:37729 [3] NCCL INFO Channel 06/0 : 27[3] -> 26[2] via P2P/CUMEM
22: nid005915:274817:284310 [3] NCCL INFO Channel 06/0 : 91[3] -> 90[2] via P2P/CUMEM
14: nid005600:217723:227325 [3] NCCL INFO Channel 06/0 : 59[3] -> 58[2] via P2P/CUMEM
 1: nid005576:147560:157021 [3] NCCL INFO Channel 07/0 : 7[3] -> 6[2] via P2P/CUMEM
30: nid005936:49911:59407 [3] NCCL INFO Channel 06/0 : 123[3] -> 122[2] via P2P/CUMEM
29: nid005932:167683:177154 [3] NCCL INFO Channel 03/0 : 119[3] -> 118[2] via P2P/CUMEM
20: nid005913:292684:9617 [3] NCCL INFO Channel 04/0 : 83[3] -> 82[2] via P2P/CUMEM
18: nid005911:38867:48386 [3] NCCL INFO Channel 06/0 : 75[3] -> 74[2] via P2P/CUMEM
19: nid005912:12438:21905 [3] NCCL INFO Channel 07/0 : 79[3] -> 78[2] via P2P/CUMEM
 2: nid005577:17425:27011 [3] NCCL INFO Channel 06/0 : 11[3] -> 10[2] via P2P/CUMEM
 9: nid005588:35938:45449 [3] NCCL INFO Channel 07/0 : 39[3] -> 38[2] via P2P/CUMEM
13: nid005595:197886:207752 [3] NCCL INFO Channel 07/0 : 55[3] -> 54[2] via P2P/CUMEM
10: nid005590:110713:120157 [3] NCCL INFO Channel 06/0 : 43[3] -> 42[2] via P2P/CUMEM
17: nid005803:180735:190256 [3] NCCL INFO Channel 07/0 : 71[3] -> 70[2] via P2P/CUMEM
24: nid005918:92507:102032 [3] NCCL INFO Channel 04/0 : 99[3] -> 98[2] via P2P/CUMEM
 4: nid005581:264526:274017 [3] NCCL INFO Channel 06/0 : 19[3] -> 18[2] via P2P/CUMEM
20: nid005913:292684:9617 [3] NCCL INFO Channel 06/0 : 83[3] -> 82[2] via P2P/CUMEM
29: nid005932:167683:177154 [3] NCCL INFO Channel 05/0 : 119[3] -> 118[2] via P2P/CUMEM
24: nid005918:92507:102032 [3] NCCL INFO Channel 06/0 : 99[3] -> 98[2] via P2P/CUMEM
29: nid005932:167683:177154 [3] NCCL INFO Channel 07/0 : 119[3] -> 118[2] via P2P/CUMEM
 0: nid005574:69058:78920 [0] NCCL INFO Connected all trees
 2: nid005577:17422:27010 [0] NCCL INFO Connected all trees
16: nid005802:6297:15957 [0] NCCL INFO Connected all trees
 3: nid005580:71819:81333 [0] NCCL INFO Connected all trees
 1: nid005576:147557:157020 [0] NCCL INFO Connected all trees
 4: nid005581:264523:274015 [0] NCCL INFO Connected all trees
23: nid005917:276885:286402 [0] NCCL INFO Connected all trees
 9: nid005588:35935:45450 [0] NCCL INFO Connected all trees
 7: nid005585:122005:131445 [0] NCCL INFO Connected all trees
31: nid005937:256589:266070 [0] NCCL INFO Connected all trees
10: nid005590:110710:120158 [0] NCCL INFO Connected all trees
11: nid005591:191603:202359 [0] NCCL INFO Connected all trees
 5: nid005582:196713:206729 [0] NCCL INFO Connected all trees
12: nid005594:53085:62618 [0] NCCL INFO Connected all trees
 6: nid005584:28285:37730 [0] NCCL INFO Connected all trees
24: nid005918:92504:102030 [0] NCCL INFO Connected all trees
17: nid005803:180732:190254 [0] NCCL INFO Connected all trees
27: nid005922:80741:90205 [0] NCCL INFO Connected all trees
20: nid005913:292681:9616 [0] NCCL INFO Connected all trees
25: nid005919:107462:116999 [0] NCCL INFO Connected all trees
28: nid005929:16030:25536 [0] NCCL INFO Connected all trees
19: nid005912:12435:21904 [0] NCCL INFO Connected all trees
18: nid005911:38864:48384 [0] NCCL INFO Connected all trees
30: nid005936:49908:59406 [0] NCCL INFO Connected all trees
29: nid005932:167680:177152 [0] NCCL INFO Connected all trees
26: nid005920:67123:76628 [0] NCCL INFO Connected all trees
22: nid005915:274814:284312 [0] NCCL INFO Connected all trees
21: nid005914:166784:176252 [0] NCCL INFO Connected all trees
 0: nid005574:69059:78919 [1] NCCL INFO Connected all trees
 0: nid005574:69061:78922 [3] NCCL INFO Connected all trees
 0: nid005574:69060:78921 [2] NCCL INFO Connected all trees
16: nid005802:6298:15958 [1] NCCL INFO Connected all trees
16: nid005802:6300:15960 [3] NCCL INFO Connected all trees
16: nid005802:6299:15959 [2] NCCL INFO Connected all trees
14: nid005600:217720:227327 [0] NCCL INFO Connected all trees
24: nid005918:92505:102033 [1] NCCL INFO Connected all trees
13: nid005595:197883:207753 [0] NCCL INFO Connected all trees
17: nid005803:180733:190255 [1] NCCL INFO Connected all trees
24: nid005918:92507:102032 [3] NCCL INFO Connected all trees
15: nid005601:210676:220272 [0] NCCL INFO Connected all trees
20: nid005913:292682:9618 [1] NCCL INFO Connected all trees
24: nid005918:92506:102031 [2] NCCL INFO Connected all trees
21: nid005914:166785:176254 [1] NCCL INFO Connected all trees
25: nid005919:107463:116996 [1] NCCL INFO Connected all trees
28: nid005929:16031:25540 [1] NCCL INFO Connected all trees
19: nid005912:12436:21902 [1] NCCL INFO Connected all trees
17: nid005803:180735:190256 [3] NCCL INFO Connected all trees
18: nid005911:38865:48387 [1] NCCL INFO Connected all trees
22: nid005915:274815:284313 [1] NCCL INFO Connected all trees
17: nid005803:180734:190257 [2] NCCL INFO Connected all trees
26: nid005920:67124:76629 [1] NCCL INFO Connected all trees
20: nid005913:292684:9617 [3] NCCL INFO Connected all trees
18: nid005911:38867:48386 [3] NCCL INFO Connected all trees
27: nid005922:80742:90207 [1] NCCL INFO Connected all trees
21: nid005914:166787:176253 [3] NCCL INFO Connected all trees
30: nid005936:49909:59409 [1] NCCL INFO Connected all trees
29: nid005932:167681:177151 [1] NCCL INFO Connected all trees
25: nid005919:107465:116997 [3] NCCL INFO Connected all trees
28: nid005929:16033:25541 [3] NCCL INFO Connected all trees
19: nid005912:12438:21905 [3] NCCL INFO Connected all trees
25: nid005919:107464:116998 [2] NCCL INFO Connected all trees
31: nid005937:256590:266072 [1] NCCL INFO Connected all trees
20: nid005913:292683:9619 [2] NCCL INFO Connected all trees
19: nid005912:12437:21903 [2] NCCL INFO Connected all trees
26: nid005920:67126:76631 [3] NCCL INFO Connected all trees
22: nid005915:274817:284310 [3] NCCL INFO Connected all trees
18: nid005911:38866:48385 [2] NCCL INFO Connected all trees
26: nid005920:67125:76630 [2] NCCL INFO Connected all trees
27: nid005922:80744:90204 [3] NCCL INFO Connected all trees
21: nid005914:166786:176251 [2] NCCL INFO Connected all trees
30: nid005936:49911:59407 [3] NCCL INFO Connected all trees
27: nid005922:80743:90206 [2] NCCL INFO Connected all trees
29: nid005932:167683:177154 [3] NCCL INFO Connected all trees
28: nid005929:16032:25538 [2] NCCL INFO Connected all trees
22: nid005915:274816:284311 [2] NCCL INFO Connected all trees
29: nid005932:167682:177153 [2] NCCL INFO Connected all trees
31: nid005937:256592:266073 [3] NCCL INFO Connected all trees
30: nid005936:49910:59408 [2] NCCL INFO Connected all trees
31: nid005937:256591:266071 [2] NCCL INFO Connected all trees
 8: nid005586:68926:78453 [0] NCCL INFO Connected all trees
23: nid005917:276886:286403 [1] NCCL INFO Connected all trees
 8: nid005586:68927:78452 [1] NCCL INFO Connected all trees
 1: nid005576:147558:157019 [1] NCCL INFO Connected all trees
 2: nid005577:17423:27009 [1] NCCL INFO Connected all trees
 9: nid005588:35936:45447 [1] NCCL INFO Connected all trees
 4: nid005581:264524:274018 [1] NCCL INFO Connected all trees
 3: nid005580:71820:81334 [1] NCCL INFO Connected all trees
 8: nid005586:68929:78454 [3] NCCL INFO Connected all trees
12: nid005594:53086:62619 [1] NCCL INFO Connected all trees
 8: nid005586:68928:78455 [2] NCCL INFO Connected all trees
 4: nid005581:264526:274017 [3] NCCL INFO Connected all trees
10: nid005590:110711:120159 [1] NCCL INFO Connected all trees
 7: nid005585:122006:131443 [1] NCCL INFO Connected all trees
 5: nid005582:196714:206728 [1] NCCL INFO Connected all trees
 9: nid005588:35938:45449 [3] NCCL INFO Connected all trees
 3: nid005580:71822:81331 [3] NCCL INFO Connected all trees
 4: nid005581:264525:274016 [2] NCCL INFO Connected all trees
 6: nid005584:28286:37731 [1] NCCL INFO Connected all trees
 2: nid005577:17425:27011 [3] NCCL INFO Connected all trees
15: nid005601:210677:220274 [1] NCCL INFO Connected all trees
13: nid005595:197884:207751 [1] NCCL INFO Connected all trees
11: nid005591:191604:202357 [1] NCCL INFO Connected all trees
 9: nid005588:35937:45448 [2] NCCL INFO Connected all trees
 3: nid005580:71821:81332 [2] NCCL INFO Connected all trees
14: nid005600:217721:227326 [1] NCCL INFO Connected all trees
12: nid005594:53088:62621 [3] NCCL INFO Connected all trees
10: nid005590:110713:120157 [3] NCCL INFO Connected all trees
 5: nid005582:196716:206730 [3] NCCL INFO Connected all trees
 7: nid005585:122008:131442 [3] NCCL INFO Connected all trees
 6: nid005584:28288:37729 [3] NCCL INFO Connected all trees
11: nid005591:191606:202356 [3] NCCL INFO Connected all trees
 7: nid005585:122007:131444 [2] NCCL INFO Connected all trees
 5: nid005582:196715:206731 [2] NCCL INFO Connected all trees
12: nid005594:53087:62620 [2] NCCL INFO Connected all trees
13: nid005595:197886:207752 [3] NCCL INFO Connected all trees
 6: nid005584:28287:37728 [2] NCCL INFO Connected all trees
10: nid005590:110712:120160 [2] NCCL INFO Connected all trees
 2: nid005577:17424:27012 [2] NCCL INFO Connected all trees
11: nid005591:191605:202358 [2] NCCL INFO Connected all trees
14: nid005600:217723:227325 [3] NCCL INFO Connected all trees
15: nid005601:210679:220273 [3] NCCL INFO Connected all trees
13: nid005595:197885:207750 [2] NCCL INFO Connected all trees
15: nid005601:210678:220275 [2] NCCL INFO Connected all trees
14: nid005600:217722:227328 [2] NCCL INFO Connected all trees
23: nid005917:276887:286401 [2] NCCL INFO Connected all trees
 1: nid005576:147560:157021 [3] NCCL INFO Connected all trees
23: nid005917:276888:286400 [3] NCCL INFO Connected all trees
 1: nid005576:147559:157018 [2] NCCL INFO Connected all trees
26: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
26:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
14: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
14:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
24: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
24:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
 0:   0%|          | 1/4399 [00:17<21:58:17, 17.98s/it]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
 0:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
25: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
25:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
 3: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
 3:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
30: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
30:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
17: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
17:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
20: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
20:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
31: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
31:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
 4: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
 4:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
20: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
20:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
 8: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
 8:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
21: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
21:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
31: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
31:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
22: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
22:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
12: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
12:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
27: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
27:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
14: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
14:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
20: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
20:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
 3: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
 3:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
23: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
23:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
 7: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
 7:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
 4: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
 4:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
23: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
23:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
18: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
18:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
13: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
13:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
28: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
28:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
 7: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
 7:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
16: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
16:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
 4: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
 4:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
13: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
13:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
25: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
25:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
18: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
18:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
30: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
30:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
11: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
11:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
 6: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
 6:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
10: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
10:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
10: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
10:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
 7: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
 7:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
 1: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
 1:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
 6: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
 6:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
24: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
24:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
29: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
29:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
31: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
31:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
21: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
21:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
22: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
22:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
 6: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
 6:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
26: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
26:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
 0:   0%|          | 2/4399 [00:24<14:04:01, 11.52s/it]  0%|          | 3/4399 [00:31<11:30:05,  9.42s/it]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
 0:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
 2: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
 2:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
 7: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
 7:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
 2: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
 2:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
24: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
24:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
27: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
27:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
15: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
15:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
28: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
28:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
17: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
17:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
 4: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
 4:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
29: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
29:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
19: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
19:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
15: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
15:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
 9: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
 9:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
20: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
20:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
16: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
16:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
 9: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
 9:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
15: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
15:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
 1: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
 1:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
13: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
13:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
26: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
26:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
 0:   0%|          | 4/4399 [00:38<10:16:42,  8.42s/it]  0%|          | 5/4399 [00:46<9:49:02,  8.04s/it]   0%|          | 6/4399 [00:53<9:23:19,  7.69s/it]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
 0:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
11: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
11:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
12: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
12:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
19: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
19:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
15: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
15:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
24: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
24:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
 3: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
 3:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
19: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
19:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
16: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
16:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
27: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
27:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
 5: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
 5:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
28: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
28:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
 9: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
 9:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
 0: {'loss': 2.7518, 'grad_norm': 36.914617145303936, 'learning_rate': 2.0454545454545456e-07, 'epoch': 0.0}
14: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
14:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
19: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
19:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
23: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
23:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
 2: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
 2:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
 9: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
 9:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
 5: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
 5:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
25: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
25:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
 1: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
 1:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
27: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
27:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
 6: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
 6:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
 0: {'loss': 2.6261, 'grad_norm': 32.18447295594785, 'learning_rate': 4.3181818181818187e-07, 'epoch': 0.0}
 0:   0%|          | 7/4399 [01:00<9:13:48,  7.57s/it]  0%|          | 8/4399 [01:08<9:30:08,  7.79s/it]  0%|          | 9/4399 [01:15<9:13:18,  7.56s/it]  0%|          | 10/4399 [01:22<8:57:14,  7.34s/it]                                                     0%|          | 10/4399 [01:22<8:57:14,  7.34s/it]  0%|          | 11/4399 [01:29<8:46:34,  7.20s/it]  0%|          | 12/4399 [01:36<8:43:01,  7.15s/it]  0%|          | 13/4399 [01:43<8:38:21,  7.09s/it]  0%|          | 14/4399 [01:50<8:38:17,  7.09s/it]  0%|          | 15/4399 [01:57<8:31:29,  7.00s/it]  0%|          | 16/4399 [02:05<9:00:55,  7.40s/it]  0%|          | 17/4399 [02:12<8:46:36,  7.21s/it]  0%|          | 18/4399 [02:19<8:42:57,  7.16s/it]  0%|          | 19/4399 [02:26<8:36:58,  7.08s/it]  0%|          | 20/4399 [02:33<8:33:03,  7.03s/it]                                                     0%|          | 20/4399 [02:33<8:33:03,  7.03s/it]  0%|          | 21/4399 [02:40<8:26:56,  6.95s/it]  1%|          | 22/4399 [02:46<8:23
23: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
23:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
 0: {'loss': 2.2063, 'grad_norm': 20.949065710587774, 'learning_rate': 6.590909090909091e-07, 'epoch': 0.01}
 0: :09,  6.90s/it]  1%|          | 23/4399 [02:53<8:20:45,  6.87s/it]  1%|          | 24/4399 [03:02<9:06:58,  7.50s/it]  1%|          | 25/4399 [03:09<8:50:15,  7.27s/it]  1%|          | 26/4399 [03:16<8:43:12,  7.18s/it]  1%|          | 27/4399 [03:23<8:33:58,  7.05s/it]  1%|          | 28/4399 [03:30<8:30:25,  7.01s/it]  1%|          | 29/4399 [03:36<8:24:56,  6.93s/it]  1%|          | 30/4399 [03:43<8:20:53,  6.88s/it]                                                     1%|          | 30/4399 [03:43<8:20:53,  6.88s/it]  1%|          | 31/4399 [03:50<8:27:31,  6.97s/it]  1%|          | 32/4399 [03:59<9:08:12,  7.53s/it]  1%|          | 33/4399 [04:06<8:50:16,  7.29s/it]  1%|          | 34/4399 [04:13<8:41:58,  7.18s/it]  1%|          | 35/4399 [04:20<8:36:48,  7.11s/it]  1%|          | 36/4399 [04:26<8:28:47,  7.00s/it]  1%|          | 37/4399 [04:33<8:22:58,  6.92s/it]  1%|          | 38/4399 [04:40<8:18:54,  6.86s/it]  1%|          | 39/4399 [04:47<8:26:20,  6.97s/it]  1%|          | 40
 0: {'loss': 1.7266, 'grad_norm': 12.319895129009439, 'learning_rate': 8.863636363636364e-07, 'epoch': 0.01}
 0: {'loss': 1.3159, 'grad_norm': 11.243589633355967, 'learning_rate': 1.1136363636363637e-06, 'epoch': 0.01}
 0: /4399 [04:56<9:16:06,  7.65s/it]                                                     1%|          | 40/4399 [04:56<9:16:06,  7.65s/it]  1%|          | 41/4399 [05:03<8:55:02,  7.37s/it]  1%|          | 42/4399 [05:10<8:41:10,  7.18s/it]  1%|          | 43/4399 [05:17<8:35:31,  7.10s/it]  1%|          | 44/4399 [05:23<8:28:14,  7.00s/it]  1%|          | 45/4399 [05:30<8:21:40,  6.91s/it]  1%|          | 46/4399 [05:37<8:18:29,  6.87s/it]  1%|          | 47/4399 [05:45<8:35:32,  7.11s/it]  1%|          | 48/4399 [05:53<9:10:08,  7.59s/it]  1%|          | 49/4399 [06:00<8:56:49,  7.40s/it]  1%|          | 50/4399 [06:07<8:41:55,  7.20s/it]                                                     1%|          | 50/4399 [06:07<8:41:55,  7.20s/it]  1%|          | 51/4399 [06:14<8:31:29,  7.06s/it]  1%|          | 52/4399 [06:21<8:25:04,  6.97s/it]  1%|          | 53/4399 [06:27<8:19:39,  6.90s/it]  1%|          | 54/4399 [06:34<8:16:21,  6.85s/it]  1%|▏         | 55/4399 [06:42<8:30:39,  7.05s/it]
 0: {'loss': 1.0928, 'grad_norm': 5.62647599824452, 'learning_rate': 1.3409090909090911e-06, 'epoch': 0.01}
 0: {'loss': 1.0019, 'grad_norm': 5.705517848340801, 'learning_rate': 1.5681818181818184e-06, 'epoch': 0.02}
 0:   1%|▏         | 56/4399 [06:50<9:05:27,  7.54s/it]  1%|▏         | 57/4399 [06:57<8:47:17,  7.29s/it]  1%|▏         | 58/4399 [07:04<8:38:23,  7.17s/it]  1%|▏         | 59/4399 [07:10<8:28:43,  7.03s/it]  1%|▏         | 60/4399 [07:17<8:21:46,  6.94s/it]                                                     1%|▏         | 60/4399 [07:17<8:21:46,  6.94s/it]  1%|▏         | 61/4399 [07:24<8:17:32,  6.88s/it]  1%|▏         | 62/4399 [07:31<8:13:39,  6.83s/it]  1%|▏         | 63/4399 [07:39<8:41:22,  7.21s/it]  1%|▏         | 64/4399 [07:48<9:16:13,  7.70s/it]  1%|▏         | 65/4399 [07:55<9:04:12,  7.53s/it]  2%|▏         | 66/4399 [08:01<8:46:10,  7.29s/it]  2%|▏         | 67/4399 [08:08<8:32:51,  7.10s/it]  2%|▏         | 68/4399 [08:15<8:25:03,  7.00s/it]  2%|▏         | 69/4399 [08:21<7:57:29,  6.62s/it]  2%|▏         | 70/4399 [08:27<8:00:28,  6.66s/it]                                                     2%|▏         | 70/4399 [08:27<8:00:28,  6.66s/it]
 0: {'loss': 0.9477, 'grad_norm': 4.478085531127649, 'learning_rate': 1.7954545454545456e-06, 'epoch': 0.02}
 0:   2%|▏         | 71/4399 [08:35<8:13:23,  6.84s/it]  2%|▏         | 72/4399 [08:44<9:10:46,  7.64s/it]  2%|▏         | 73/4399 [08:51<8:56:22,  7.44s/it]  2%|▏         | 74/4399 [08:58<8:47:15,  7.31s/it]  2%|▏         | 75/4399 [09:05<8:35:23,  7.15s/it]  2%|▏         | 76/4399 [09:12<8:26:34,  7.03s/it]  2%|▏         | 77/4399 [09:18<8:20:21,  6.95s/it]  2%|▏         | 78/4399 [09:25<8:15:30,  6.88s/it]  2%|▏         | 79/4399 [09:32<8:21:39,  6.97s/it]  2%|▏         | 80/4399 [09:41<8:55:28,  7.44s/it]                                                     2%|▏         | 80/4399 [09:41<8:55:28,  7.44s/it]  2%|▏         | 81/4399 [09:48<8:40:00,  7.23s/it]  2%|▏         | 82/4399 [09:54<8:28:24,  7.07s/it]  2%|▏         | 83/4399 [10:01<8:19:29,  6.94s/it]  2%|▏         | 84/4399 [10:08<8:14:29,  6.88s/it]  2%|▏         | 85/4399 [10:14<8:12:23,  6.85s/it]  2%|▏         | 86/4399 [10:21<8:11:18,  6.83s/it]  2%|▏         | 87/4399 [10:28<8:14:42,  6.88s/it
 0: {'loss': 0.9265, 'grad_norm': 5.0449213513561615, 'learning_rate': 2.022727272727273e-06, 'epoch': 0.02}
 0: {'loss': 0.874, 'grad_norm': 8.532166442125604, 'learning_rate': 2.25e-06, 'epoch': 0.02}
 0: ]  2%|▏         | 88/4399 [10:38<9:25:20,  7.87s/it]  2%|▏         | 89/4399 [10:46<9:10:48,  7.67s/it]  2%|▏         | 90/4399 [10:52<8:49:13,  7.37s/it]                                                     2%|▏         | 90/4399 [10:52<8:49:13,  7.37s/it]  2%|▏         | 91/4399 [10:59<8:34:45,  7.17s/it]  2%|▏         | 92/4399 [11:06<8:30:00,  7.10s/it]  2%|▏         | 93/4399 [11:13<8:22:05,  7.00s/it]  2%|▏         | 94/4399 [11:19<8:16:25,  6.92s/it]  2%|▏         | 95/4399 [11:27<8:25:02,  7.04s/it]  2%|▏         | 96/4399 [11:36<9:08:53,  7.65s/it]  2%|▏         | 97/4399 [11:43<8:58:43,  7.51s/it]  2%|▏         | 98/4399 [11:50<8:41:47,  7.28s/it]  2%|▏         | 99/4399 [11:56<8:29:25,  7.11s/it]  2%|▏         | 100/4399 [12:03<8:20:29,  6.99s/it]                                                      2%|▏         | 100/4399 [12:03<8:20:29,  6.99s/it]  2%|▏         | 101/4399 [12:10<8:13:27,  6.89s/it]  2%|▏         | 102/4399 [12:17<8:09:49,  6.8
 0: {'loss': 0.8477, 'grad_norm': 5.884677455227049, 'learning_rate': 2.4772727272727275e-06, 'epoch': 0.03}
 0: 4s/it]  2%|▏         | 103/4399 [12:25<8:37:00,  7.22s/it]  2%|▏         | 104/4399 [12:33<9:00:31,  7.55s/it]  2%|▏         | 105/4399 [12:40<8:39:09,  7.25s/it]  2%|▏         | 106/4399 [12:46<8:27:52,  7.10s/it]  2%|▏         | 107/4399 [12:53<8:22:53,  7.03s/it]  2%|▏         | 108/4399 [13:00<8:15:06,  6.92s/it]  2%|▏         | 109/4399 [13:07<8:10:42,  6.86s/it]  3%|▎         | 110/4399 [13:13<8:07:11,  6.82s/it]                                                      3%|▎         | 110/4399 [13:13<8:07:11,  6.82s/it]  3%|▎         | 111/4399 [13:21<8:24:33,  7.06s/it]  3%|▎         | 112/4399 [13:30<9:10:23,  7.70s/it]  3%|▎         | 113/4399 [13:38<9:16:10,  7.79s/it]  3%|▎         | 114/4399 [13:44<8:32:25,  7.18s/it]  3%|▎         | 115/4399 [13:50<8:02:33,  6.76s/it]  3%|▎         | 116/4399 [13:55<7:40:38,  6.45s/it]  3%|▎         | 117/4399 [14:02<7:48:50,  6.57s/it]  3%|▎         | 118/4399 [14:09<7:52:30,  6.62s/it]  3%|▎         | 119/4399 
 0: {'loss': 0.8352, 'grad_norm': 4.945356058839593, 'learning_rate': 2.7045454545454545e-06, 'epoch': 0.03}
 0: {'loss': 0.8392, 'grad_norm': 6.639643222172753, 'learning_rate': 2.931818181818182e-06, 'epoch': 0.03}
 0: [14:16<8:07:49,  6.84s/it]  3%|▎         | 120/4399 [14:25<8:48:59,  7.42s/it]                                                      3%|▎         | 120/4399 [14:25<8:48:59,  7.42s/it]  3%|▎         | 121/4399 [14:32<8:46:13,  7.38s/it]  3%|▎         | 122/4399 [14:39<8:33:30,  7.20s/it]  3%|▎         | 123/4399 [14:46<8:23:04,  7.06s/it]  3%|▎         | 124/4399 [14:53<8:15:55,  6.96s/it]  3%|▎         | 125/4399 [14:59<8:12:51,  6.92s/it]  3%|▎         | 126/4399 [15:06<8:08:13,  6.86s/it]  3%|▎         | 127/4399 [15:14<8:22:47,  7.06s/it]  3%|▎         | 128/4399 [15:23<9:05:35,  7.66s/it]  3%|▎         | 129/4399 [15:31<9:15:58,  7.81s/it]  3%|▎         | 130/4399 [15:38<8:52:35,  7.49s/it]                                                      3%|▎         | 130/4399 [15:38<8:52:35,  7.49s/it]  3%|▎         | 131/4399 [15:44<8:35:54,  7.25s/it]  3%|▎         | 132/4399 [15:51<8:24:00,  7.09s/it]  3%|▎         | 133/4399 [15:58<8:16:07,  6.98s/it]  3%|▎ 
 0: {'loss': 0.8113, 'grad_norm': 4.750001720854625, 'learning_rate': 3.1590909090909094e-06, 'epoch': 0.03}
 0:         | 134/4399 [16:04<8:11:11,  6.91s/it]  3%|▎         | 135/4399 [16:12<8:31:20,  7.20s/it]  3%|▎         | 136/4399 [16:22<9:18:13,  7.86s/it]  3%|▎         | 137/4399 [16:30<9:33:03,  8.07s/it]  3%|▎         | 138/4399 [16:37<9:03:37,  7.65s/it]  3%|▎         | 139/4399 [16:44<8:46:49,  7.42s/it]  3%|▎         | 140/4399 [16:51<8:31:14,  7.20s/it]                                                      3%|▎         | 140/4399 [16:51<8:31:14,  7.20s/it]  3%|▎         | 141/4399 [16:57<8:20:43,  7.06s/it]  3%|▎         | 142/4399 [17:04<8:12:36,  6.94s/it]  3%|▎         | 143/4399 [17:11<8:11:50,  6.93s/it]  3%|▎         | 144/4399 [17:21<9:11:39,  7.78s/it]  3%|▎         | 145/4399 [17:28<9:09:34,  7.75s/it]  3%|▎         | 146/4399 [17:35<8:49:38,  7.47s/it]  3%|▎         | 147/4399 [17:42<8:34:15,  7.26s/it]  3%|▎         | 148/4399 [17:49<8:24:42,  7.12s/it]  3%|▎         | 149/4399 [17:55<8:17:44,  7.03s/it]  3%|▎         | 150/4399 [18:02<8:10:57, 
 0: {'loss': 0.8116, 'grad_norm': 5.183076820457382, 'learning_rate': 3.3863636363636364e-06, 'epoch': 0.03}
 0: {'loss': 0.7924, 'grad_norm': 6.415795316271113, 'learning_rate': 3.6136363636363643e-06, 'epoch': 0.04}
 0:  6.93s/it]                                                      3%|▎         | 150/4399 [18:02<8:10:57,  6.93s/it]  3%|▎         | 151/4399 [18:09<8:17:51,  7.03s/it]  3%|▎         | 152/4399 [18:19<9:20:21,  7.92s/it]  3%|▎         | 153/4399 [18:28<9:43:53,  8.25s/it]  4%|▎         | 154/4399 [18:35<9:10:25,  7.78s/it]  4%|▎         | 155/4399 [18:42<8:47:20,  7.46s/it]  4%|▎         | 156/4399 [18:49<8:31:49,  7.24s/it]  4%|▎         | 157/4399 [18:54<8:00:58,  6.80s/it]  4%|▎         | 158/4399 [19:01<7:59:34,  6.78s/it]  4%|▎         | 159/4399 [19:08<8:02:15,  6.82s/it]  4%|▎         | 160/4399 [19:18<9:18:06,  7.90s/it]                                                      4%|▎         | 160/4399 [19:18<9:18:06,  7.90s/it]  4%|▎         | 161/4399 [19:26<9:08:52,  7.77s/it]  4%|▎         | 162/4399 [19:32<8:25:40,  7.16s/it]  4%|▎         | 163/4399 [19:38<8:16:53,  7.04s/it]  4%|▎         | 164/4399 [19:45<8:09:35,  6.94s/it]  4%|▍         | 165/43
 0: {'loss': 0.7845, 'grad_norm': 6.288912449126692, 'learning_rate': 3.840909090909091e-06, 'epoch': 0.04}
 0: {'loss': 0.7854, 'grad_norm': 4.146413969062398, 'learning_rate': 4.068181818181818e-06, 'epoch': 0.04}
 0: 99 [19:52<8:05:05,  6.87s/it]  4%|▍         | 166/4399 [19:59<8:05:10,  6.88s/it]  4%|▍         | 167/4399 [20:06<8:12:23,  6.98s/it]  4%|▍         | 168/4399 [20:16<9:26:57,  8.04s/it]  4%|▍         | 169/4399 [20:23<9:04:17,  7.72s/it]  4%|▍         | 170/4399 [20:30<8:47:54,  7.49s/it]                                                      4%|▍         | 170/4399 [20:30<8:47:54,  7.49s/it]  4%|▍         | 171/4399 [20:36<8:10:58,  6.97s/it]  4%|▍         | 172/4399 [20:43<8:04:55,  6.88s/it]  4%|▍         | 173/4399 [20:49<8:00:52,  6.83s/it]  4%|▍         | 174/4399 [20:56<7:58:25,  6.79s/it]  4%|▍         | 175/4399 [21:04<8:18:13,  7.08s/it]  4%|▍         | 176/4399 [21:13<9:08:31,  7.79s/it]  4%|▍         | 177/4399 [21:22<9:26:38,  8.05s/it]  4%|▍         | 178/4399 [21:29<9:02:20,  7.71s/it]  4%|▍         | 179/4399 [21:36<8:40:28,  7.40s/it]  4%|▍         | 180/4399 [21:42<8:25:04,  7.18s/it]                                                      4%|
 0: {'loss': 0.7556, 'grad_norm': 3.1441882069698392, 'learning_rate': 4.295454545454546e-06, 'epoch': 0.04}
 0:          | 180/4399 [21:42<8:25:04,  7.18s/it]  4%|▍         | 181/4399 [21:49<8:15:14,  7.04s/it]  4%|▍         | 182/4399 [21:56<8:07:08,  6.93s/it]  4%|▍         | 183/4399 [22:03<8:16:04,  7.06s/it]  4%|▍         | 184/4399 [22:13<9:18:24,  7.95s/it]  4%|▍         | 185/4399 [22:21<9:09:04,  7.82s/it]  4%|▍         | 186/4399 [22:28<8:58:40,  7.67s/it]  4%|▍         | 187/4399 [22:35<8:38:41,  7.39s/it]  4%|▍         | 188/4399 [22:41<8:23:35,  7.18s/it]  4%|▍         | 189/4399 [22:48<8:16:22,  7.07s/it]  4%|▍         | 190/4399 [22:55<8:11:43,  7.01s/it]                                                      4%|▍         | 190/4399 [22:55<8:11:43,  7.01s/it]  4%|▍         | 191/4399 [23:01<7:59:31,  6.84s/it]  4%|▍         | 192/4399 [23:12<9:10:14,  7.85s/it]  4%|▍         | 193/4399 [23:19<9:07:35,  7.81s/it]  4%|▍         | 194/4399 [23:26<8:48:25,  7.54s/it]  4%|▍         | 195/4399 [23:32<8:14:08,  7.05s/it]  4%|▍         | 196/4399 [23:38<7:46:2
 0: {'loss': 0.7727, 'grad_norm': 4.9995948895515525, 'learning_rate': 4.522727272727273e-06, 'epoch': 0.05}
 0: {'loss': 0.7672, 'grad_norm': 3.2653850969401854, 'learning_rate': 4.75e-06, 'epoch': 0.05}
 0: 2,  6.66s/it]  4%|▍         | 197/4399 [23:45<7:48:02,  6.68s/it]  5%|▍         | 198/4399 [23:52<7:52:18,  6.75s/it]  5%|▍         | 199/4399 [23:59<8:08:58,  6.99s/it]  5%|▍         | 200/4399 [24:10<9:19:57,  8.00s/it]                                                      5%|▍         | 200/4399 [24:10<9:19:57,  8.00s/it]  5%|▍         | 201/4399 [24:18<9:39:08,  8.28s/it]  5%|▍         | 202/4399 [24:26<9:24:11,  8.07s/it]  5%|▍         | 203/4399 [24:33<8:59:20,  7.71s/it]  5%|▍         | 204/4399 [24:39<8:22:43,  7.19s/it]  5%|▍         | 205/4399 [24:46<8:16:08,  7.10s/it]  5%|▍         | 206/4399 [24:52<7:50:52,  6.74s/it]  5%|▍         | 207/4399 [25:00<8:15:15,  7.09s/it]  5%|▍         | 208/4399 [25:10<9:15:57,  7.96s/it]  5%|▍         | 209/4399 [25:19<9:42:33,  8.34s/it]  5%|▍         | 210/4399 [25:26<9:11:13,  7.90s/it]                                                      5%|▍         | 210/4399 [25:26<9:11:13,  7.90s/it]  5%|▍         | 211
 0: {'loss': 0.7601, 'grad_norm': 7.44929618494439, 'learning_rate': 4.977272727272728e-06, 'epoch': 0.05}
 0: /4399 [25:33<8:49:58,  7.59s/it]  5%|▍         | 212/4399 [25:39<8:35:01,  7.38s/it]  5%|▍         | 213/4399 [25:45<8:05:54,  6.96s/it]  5%|▍         | 214/4399 [25:52<8:04:34,  6.95s/it]  5%|▍         | 215/4399 [26:00<8:25:23,  7.25s/it]  5%|▍         | 216/4399 [26:10<9:24:53,  8.10s/it]  5%|▍         | 217/4399 [26:18<9:17:28,  8.00s/it]  5%|▍         | 218/4399 [26:26<9:06:52,  7.85s/it]  5%|▍         | 219/4399 [26:32<8:46:45,  7.56s/it]  5%|▌         | 220/4399 [26:39<8:33:18,  7.37s/it]                                                      5%|▌         | 220/4399 [26:39<8:33:18,  7.37s/it]  5%|▌         | 221/4399 [26:46<8:22:55,  7.22s/it]  5%|▌         | 222/4399 [26:53<8:16:05,  7.13s/it]  5%|▌         | 223/4399 [27:00<8:06:50,  6.99s/it]  5%|▌         | 224/4399 [27:11<9:39:01,  8.32s/it]  5%|▌         | 225/4399 [27:20<9:37:41,  8.30s/it]  5%|▌         | 226/4399 [27:27<9:18:35,  8.03s/it]  5%|▌         | 227/4399 [27:34<8:55:33,  7.70s/it]  
 0: {'loss': 0.7717, 'grad_norm': 3.763253835109269, 'learning_rate': 5.204545454545455e-06, 'epoch': 0.05}
 0: {'loss': 0.7689, 'grad_norm': 4.016750646452613, 'learning_rate': 5.431818181818182e-06, 'epoch': 0.05}
 0: 5%|▌         | 228/4399 [27:40<8:18:18,  7.17s/it]  5%|▌         | 229/4399 [27:47<8:11:40,  7.07s/it]  5%|▌         | 230/4399 [27:54<8:07:40,  7.02s/it]                                                      5%|▌         | 230/4399 [27:54<8:07:40,  7.02s/it]  5%|▌         | 231/4399 [28:00<8:05:46,  6.99s/it]  5%|▌         | 232/4399 [28:12<9:29:57,  8.21s/it]  5%|▌         | 233/4399 [28:20<9:44:50,  8.42s/it]  5%|▌         | 234/4399 [28:28<9:27:40,  8.18s/it]  5%|▌         | 235/4399 [28:35<9:00:21,  7.79s/it]  5%|▌         | 236/4399 [28:41<8:22:56,  7.25s/it]  5%|▌         | 237/4399 [28:48<8:16:19,  7.16s/it]  5%|▌         | 238/4399 [28:55<8:10:50,  7.08s/it]  5%|▌         | 239/4399 [29:02<8:15:13,  7.14s/it]  5%|▌         | 240/4399 [29:13<9:43:17,  8.41s/it]                                                      5%|▌         | 240/4399 [29:13<9:43:17,  8.41s/it]  5%|▌         | 241/4399 [29:22<9:51:00,  8.53s/it]  6%|▌         | 242/4399 [29:30<9:2
 0: {'loss': 0.751, 'grad_norm': 4.563785296658619, 'learning_rate': 5.65909090909091e-06, 'epoch': 0.06}
 0: 4:47,  8.15s/it]  6%|▌         | 243/4399 [29:36<8:58:19,  7.77s/it]  6%|▌         | 244/4399 [29:42<8:19:51,  7.22s/it]  6%|▌         | 245/4399 [29:48<7:51:51,  6.82s/it]  6%|▌         | 246/4399 [29:55<7:53:01,  6.83s/it]  6%|▌         | 247/4399 [30:02<8:02:56,  6.98s/it]  6%|▌         | 248/4399 [30:13<9:08:27,  7.93s/it]  6%|▌         | 249/4399 [30:21<9:11:19,  7.97s/it]  6%|▌         | 250/4399 [30:28<8:59:08,  7.80s/it]                                                      6%|▌         | 250/4399 [30:28<8:59:08,  7.80s/it]  6%|▌         | 251/4399 [30:35<8:40:32,  7.53s/it]  6%|▌         | 252/4399 [30:41<8:11:27,  7.11s/it]  6%|▌         | 253/4399 [30:48<8:10:17,  7.10s/it]  6%|▌         | 254/4399 [30:54<7:46:00,  6.75s/it]  6%|▌         | 255/4399 [31:01<7:53:37,  6.86s/it]  6%|▌         | 256/4399 [31:13<9:47:01,  8.50s/it]  6%|▌         | 257/4399 [31:22<9:57:25,  8.65s/it]  6%|▌         | 258/4399 [31:30<9:23:56,  8.17s/it]  6%|▌         |
 0: {'loss': 0.7499, 'grad_norm': 4.710493021663428, 'learning_rate': 5.886363636363637e-06, 'epoch': 0.06}
 0: {'loss': 0.7411, 'grad_norm': 3.2271437532949774, 'learning_rate': 6.113636363636364e-06, 'epoch': 0.06}
 0:  259/4399 [31:36<8:57:03,  7.78s/it]  6%|▌         | 260/4399 [31:43<8:37:46,  7.51s/it]                                                      6%|▌         | 260/4399 [31:43<8:37:46,  7.51s/it]  6%|▌         | 261/4399 [31:50<8:26:01,  7.34s/it]  6%|▌         | 262/4399 [31:56<7:57:31,  6.93s/it]  6%|▌         | 263/4399 [32:03<8:01:38,  6.99s/it]  6%|▌         | 264/4399 [32:15<9:40:53,  8.43s/it]  6%|▌         | 265/4399 [32:23<9:31:30,  8.29s/it]  6%|▌         | 266/4399 [32:30<9:10:18,  7.99s/it]  6%|▌         | 267/4399 [32:37<8:46:19,  7.64s/it]  6%|▌         | 268/4399 [32:43<8:10:00,  7.12s/it]  6%|▌         | 269/4399 [32:49<7:45:16,  6.76s/it]  6%|▌         | 270/4399 [32:56<7:48:01,  6.80s/it]                                                      6%|▌         | 270/4399 [32:56<7:48:01,  6.80s/it]  6%|▌         | 271/4399 [33:03<7:54:18,  6.89s/it]  6%|▌         | 272/4399 [33:14<9:28:28,  8.26s/it]  6%|▌         | 273/4399 [33:24<9:51:42,  8.60s/it]
 0: {'loss': 0.7391, 'grad_norm': 4.347193519762235, 'learning_rate': 6.340909090909091e-06, 'epoch': 0.06}
 0:   6%|▌         | 274/4399 [33:31<9:25:56,  8.23s/it]  6%|▋         | 275/4399 [33:37<8:36:58,  7.52s/it]  6%|▋         | 276/4399 [33:44<8:23:04,  7.32s/it]  6%|▋         | 277/4399 [33:51<8:16:56,  7.23s/it]  6%|▋         | 278/4399 [33:58<8:12:22,  7.17s/it]  6%|▋         | 279/4399 [34:05<8:09:05,  7.12s/it]  6%|▋         | 280/4399 [34:16<9:20:52,  8.17s/it]                                                      6%|▋         | 280/4399 [34:16<9:20:52,  8.17s/it]  6%|▋         | 281/4399 [34:26<9:59:09,  8.73s/it]  6%|▋         | 282/4399 [34:33<9:30:54,  8.32s/it]  6%|▋         | 283/4399 [34:40<8:59:36,  7.87s/it]  6%|▋         | 284/4399 [34:46<8:20:18,  7.29s/it]  6%|▋         | 285/4399 [34:52<7:52:54,  6.90s/it]  7%|▋         | 286/4399 [34:59<7:52:18,  6.89s/it]  7%|▋         | 287/4399 [35:06<7:56:00,  6.95s/it]  7%|▋         | 288/4399 [35:16<9:06:08,  7.97s/it]  7%|▋         | 289/4399 [35:25<9:33:37,  8.37s/it]  7%|▋         | 290/4399 [35:33
 0: {'loss': 0.7375, 'grad_norm': 3.5065035891035734, 'learning_rate': 6.568181818181819e-06, 'epoch': 0.07}
 0: {'loss': 0.7365, 'grad_norm': 4.535293504766243, 'learning_rate': 6.795454545454546e-06, 'epoch': 0.07}
 0: <9:11:39,  8.06s/it]                                                      7%|▋         | 290/4399 [35:33<9:11:39,  8.06s/it]  7%|▋         | 291/4399 [35:40<8:48:40,  7.72s/it]  7%|▋         | 292/4399 [35:47<8:30:58,  7.46s/it]  7%|▋         | 293/4399 [35:53<8:18:33,  7.29s/it]  7%|▋         | 294/4399 [35:59<7:52:01,  6.90s/it]  7%|▋         | 295/4399 [36:06<7:36:47,  6.68s/it]  7%|▋         | 296/4399 [36:15<8:31:43,  7.48s/it]  7%|▋         | 297/4399 [36:24<9:14:08,  8.11s/it]  7%|▋         | 298/4399 [36:32<9:12:13,  8.08s/it]  7%|▋         | 299/4399 [36:40<8:50:59,  7.77s/it]  7%|▋         | 300/4399 [36:46<8:31:32,  7.49s/it]                                                      7%|▋         | 300/4399 [36:46<8:31:32,  7.49s/it]  7%|▋         | 301/4399 [36:53<8:03:44,  7.08s/it]  7%|▋         | 302/4399 [36:59<8:00:24,  7.04s/it]  7%|▋         | 303/4399 [37:06<7:57:47,  7.00s/it]  7%|▋         | 304/4399 [37:17<9:08:25,  8.04s/it]  7%|▋       
 0: {'loss': 0.7509, 'grad_norm': 3.585268558872358, 'learning_rate': 7.022727272727273e-06, 'epoch': 0.07}
 0:   | 305/4399 [37:25<9:21:31,  8.23s/it]  7%|▋         | 306/4399 [37:33<9:03:05,  7.96s/it]  7%|▋         | 307/4399 [37:39<8:20:23,  7.34s/it]  7%|▋         | 308/4399 [37:46<8:14:48,  7.26s/it]  7%|▋         | 309/4399 [37:52<7:47:57,  6.86s/it]  7%|▋         | 310/4399 [37:59<7:50:50,  6.91s/it]                                                      7%|▋         | 310/4399 [37:59<7:50:50,  6.91s/it]  7%|▋         | 311/4399 [38:06<7:54:13,  6.96s/it]  7%|▋         | 312/4399 [38:16<9:06:18,  8.02s/it]  7%|▋         | 313/4399 [38:26<9:40:18,  8.52s/it]  7%|▋         | 314/4399 [38:34<9:24:04,  8.28s/it]  7%|▋         | 315/4399 [38:40<8:35:50,  7.58s/it]  7%|▋         | 316/4399 [38:47<8:22:20,  7.38s/it]  7%|▋         | 317/4399 [38:53<7:52:37,  6.95s/it]  7%|▋         | 318/4399 [38:59<7:52:40,  6.95s/it]  7%|▋         | 319/4399 [39:07<7:58:40,  7.04s/it]  7%|▋         | 320/4399 [39:17<9:00:41,  7.95s/it]                                                  
 0: {'loss': 0.7239, 'grad_norm': 3.8568884419984646, 'learning_rate': 7.25e-06, 'epoch': 0.07}
 0: {'loss': 0.7272, 'grad_norm': 4.037995718363306, 'learning_rate': 7.477272727272727e-06, 'epoch': 0.08}
 0:     7%|▋         | 320/4399 [39:17<9:00:41,  7.95s/it]  7%|▋         | 321/4399 [39:28<10:01:27,  8.85s/it]  7%|▋         | 322/4399 [39:35<9:34:28,  8.45s/it]   7%|▋         | 323/4399 [39:42<9:02:47,  7.99s/it]  7%|▋         | 324/4399 [39:49<8:40:26,  7.66s/it]  7%|▋         | 325/4399 [39:56<8:26:05,  7.45s/it]  7%|▋         | 326/4399 [40:02<7:55:44,  7.01s/it]  7%|▋         | 327/4399 [40:08<7:37:39,  6.74s/it]  7%|▋         | 328/4399 [40:19<8:59:44,  7.95s/it]  7%|▋         | 329/4399 [40:30<9:53:09,  8.74s/it]  8%|▊         | 330/4399 [40:37<9:30:54,  8.42s/it]                                                      8%|▊         | 330/4399 [40:37<9:30:54,  8.42s/it]  8%|▊         | 331/4399 [40:43<8:40:09,  7.67s/it]  8%|▊         | 332/4399 [40:50<8:25:00,  7.45s/it]  8%|▊         | 333/4399 [40:55<7:36:01,  6.73s/it]  8%|▊         | 334/4399 [41:01<7:21:56,  6.52s/it]  8%|▊         | 335/4399 [41:08<7:33:39,  6.70s/it]  8%|▊         | 336/4399 [
 0: {'loss': 0.7399, 'grad_norm': 3.635781181346682, 'learning_rate': 7.704545454545456e-06, 'epoch': 0.08}
 0: {'loss': 0.7203, 'grad_norm': 6.418753466791797, 'learning_rate': 7.931818181818182e-06, 'epoch': 0.08}
 0: 41:19<8:56:38,  7.92s/it]  8%|▊         | 337/4399 [41:30<9:51:33,  8.74s/it]  8%|▊         | 338/4399 [41:38<9:34:09,  8.48s/it]  8%|▊         | 339/4399 [41:44<9:01:43,  8.01s/it]  8%|▊         | 340/4399 [41:51<8:39:38,  7.68s/it]                                                      8%|▊         | 340/4399 [41:51<8:39:38,  7.68s/it]  8%|▊         | 341/4399 [41:58<8:23:42,  7.45s/it]  8%|▊         | 342/4399 [42:05<8:13:20,  7.30s/it]  8%|▊         | 343/4399 [42:12<8:10:27,  7.26s/it]  8%|▊         | 344/4399 [42:22<9:06:25,  8.09s/it]  8%|▊         | 345/4399 [42:32<9:47:35,  8.70s/it]  8%|▊         | 346/4399 [42:40<9:31:46,  8.46s/it]  8%|▊         | 347/4399 [42:47<8:59:09,  7.98s/it]  8%|▊         | 348/4399 [42:54<8:36:57,  7.66s/it]  8%|▊         | 349/4399 [43:00<8:04:40,  7.18s/it]  8%|▊         | 350/4399 [43:07<7:58:54,  7.10s/it]                                                      8%|▊         | 350/4399 [43:07<7:58:54,  7.10s/it]  8%|▊  
 0: {'loss': 0.7196, 'grad_norm': 3.227135720211463, 'learning_rate': 8.15909090909091e-06, 'epoch': 0.08}
 0:        | 351/4399 [43:14<7:59:30,  7.11s/it]  8%|▊         | 352/4399 [43:25<9:12:01,  8.18s/it]  8%|▊         | 353/4399 [43:36<10:03:52,  8.96s/it]  8%|▊         | 354/4399 [43:43<9:26:26,  8.40s/it]   8%|▊         | 355/4399 [43:50<8:55:35,  7.95s/it]  8%|▊         | 356/4399 [43:57<8:35:54,  7.66s/it]  8%|▊         | 357/4399 [44:04<8:18:45,  7.40s/it]  8%|▊         | 358/4399 [44:10<8:08:18,  7.25s/it]  8%|▊         | 359/4399 [44:17<8:02:00,  7.16s/it]  8%|▊         | 360/4399 [44:29<9:28:58,  8.45s/it]                                                      8%|▊         | 360/4399 [44:29<9:28:58,  8.45s/it]  8%|▊         | 361/4399 [44:38<9:45:43,  8.70s/it]  8%|▊         | 362/4399 [44:45<9:08:14,  8.15s/it]  8%|▊         | 363/4399 [44:51<8:23:46,  7.49s/it]  8%|▊         | 364/4399 [44:58<8:11:53,  7.31s/it]  8%|▊         | 365/4399 [45:05<8:03:17,  7.19s/it]  8%|▊         | 366/4399 [45:12<7:58:13,  7.11s/it]  8%|▊         | 367/4399 [45:17<7:20:15,
 0: {'loss': 0.7157, 'grad_norm': 3.628047174988976, 'learning_rate': 8.386363636363638e-06, 'epoch': 0.08}
 0: {'loss': 0.7116, 'grad_norm': 3.511907745568411, 'learning_rate': 8.613636363636364e-06, 'epoch': 0.09}
 0:   6.55s/it]  8%|▊         | 368/4399 [45:27<8:36:08,  7.68s/it]  8%|▊         | 369/4399 [45:37<9:10:12,  8.19s/it]  8%|▊         | 370/4399 [45:44<8:55:26,  7.97s/it]                                                      8%|▊         | 370/4399 [45:44<8:55:26,  7.97s/it]  8%|▊         | 371/4399 [45:51<8:35:22,  7.68s/it]  8%|▊         | 372/4399 [45:58<8:20:51,  7.46s/it]  8%|▊         | 373/4399 [46:04<7:51:38,  7.03s/it]  9%|▊         | 374/4399 [46:10<7:28:29,  6.69s/it]  9%|▊         | 375/4399 [46:16<7:14:06,  6.47s/it]  9%|▊         | 376/4399 [46:25<8:13:42,  7.36s/it]  9%|▊         | 377/4399 [46:36<9:16:07,  8.30s/it]  9%|▊         | 378/4399 [46:44<9:11:45,  8.23s/it]  9%|▊         | 379/4399 [46:50<8:26:11,  7.56s/it]  9%|▊         | 380/4399 [46:57<8:13:28,  7.37s/it]                                                      9%|▊         | 380/4399 [46:57<8:13:28,  7.37s/it]  9%|▊         | 381/4399 [47:04<8:03:39,  7.22s/it]  9%|▊         | 382/4
 0: {'loss': 0.711, 'grad_norm': 3.5427961050239443, 'learning_rate': 8.840909090909092e-06, 'epoch': 0.09}
 0: 399 [47:11<7:57:25,  7.13s/it]  9%|▊         | 383/4399 [47:18<7:53:48,  7.08s/it]  9%|▊         | 384/4399 [47:27<8:49:12,  7.91s/it]  9%|▉         | 385/4399 [47:37<9:31:51,  8.55s/it]  9%|▉         | 386/4399 [47:45<9:18:22,  8.35s/it]  9%|▉         | 387/4399 [47:52<8:52:00,  7.96s/it]  9%|▉         | 388/4399 [47:59<8:30:50,  7.64s/it]  9%|▉         | 389/4399 [48:06<8:15:09,  7.41s/it]  9%|▉         | 390/4399 [48:13<8:04:58,  7.26s/it]                                                      9%|▉         | 390/4399 [48:13<8:04:58,  7.26s/it]  9%|▉         | 391/4399 [48:20<8:03:36,  7.24s/it]  9%|▉         | 392/4399 [48:30<9:01:43,  8.11s/it]  9%|▉         | 393/4399 [48:41<9:46:07,  8.78s/it]  9%|▉         | 394/4399 [48:48<9:13:50,  8.30s/it]  9%|▉         | 395/4399 [48:55<8:45:46,  7.88s/it]  9%|▉         | 396/4399 [49:01<8:06:43,  7.30s/it]  9%|▉         | 397/4399 [49:07<7:38:45,  6.88s/it]  9%|▉         | 398/4399 [49:14<7:39:27,  6.89s/it]  9%
 0: {'loss': 0.7062, 'grad_norm': 5.503397924441666, 'learning_rate': 9.06818181818182e-06, 'epoch': 0.09}
 0: {'loss': 0.6981, 'grad_norm': 4.134096081241862, 'learning_rate': 9.295454545454546e-06, 'epoch': 0.09}
 0: |▉         | 399/4399 [49:21<7:44:39,  6.97s/it]  9%|▉         | 400/4399 [49:32<9:06:10,  8.19s/it]                                                      9%|▉         | 400/4399 [49:32<9:06:10,  8.19s/it]  9%|▉         | 401/4399 [49:41<9:31:35,  8.58s/it]  9%|▉         | 402/4399 [49:49<9:24:23,  8.47s/it]  9%|▉         | 403/4399 [49:55<8:32:55,  7.70s/it]  9%|▉         | 404/4399 [50:02<8:17:02,  7.46s/it]  9%|▉         | 405/4399 [50:09<8:06:10,  7.30s/it]  9%|▉         | 406/4399 [50:16<7:58:58,  7.20s/it]  9%|▉         | 407/4399 [50:23<7:56:53,  7.17s/it]  9%|▉         | 408/4399 [50:33<8:50:22,  7.97s/it]  9%|▉         | 409/4399 [50:44<9:46:52,  8.83s/it]  9%|▉         | 410/4399 [50:51<9:15:18,  8.35s/it]                                                      9%|▉         | 410/4399 [50:51<9:15:18,  8.35s/it]  9%|▉         | 411/4399 [50:57<8:26:13,  7.62s/it]  9%|▉         | 412/4399 [51:04<8:12:45,  7.42s/it]  9%|▉         | 413/4399 [51:11<8:03:
 0: {'loss': 0.6973, 'grad_norm': 3.601408831908618, 'learning_rate': 9.522727272727274e-06, 'epoch': 0.1}
 0: 22,  7.28s/it]  9%|▉         | 414/4399 [51:17<7:37:30,  6.89s/it]  9%|▉         | 415/4399 [51:24<7:41:59,  6.96s/it]  9%|▉         | 416/4399 [51:34<8:50:56,  8.00s/it]  9%|▉         | 417/4399 [51:44<9:22:30,  8.48s/it] 10%|▉         | 418/4399 [51:51<8:55:19,  8.07s/it] 10%|▉         | 419/4399 [51:58<8:32:15,  7.72s/it] 10%|▉         | 420/4399 [52:04<7:56:01,  7.18s/it]                                                     10%|▉         | 420/4399 [52:04<7:56:01,  7.18s/it] 10%|▉         | 421/4399 [52:11<7:50:25,  7.10s/it] 10%|▉         | 422/4399 [52:18<7:45:34,  7.02s/it] 10%|▉         | 423/4399 [52:24<7:28:34,  6.77s/it] 10%|▉         | 424/4399 [52:33<8:18:29,  7.52s/it] 10%|▉         | 425/4399 [52:44<9:12:55,  8.35s/it] 10%|▉         | 426/4399 [52:52<9:14:29,  8.37s/it] 10%|▉         | 427/4399 [52:58<8:26:40,  7.65s/it] 10%|▉         | 428/4399 [53:05<8:11:23,  7.42s/it] 10%|▉         | 429/4399 [53:12<8:03:11,  7.30s/it] 10%|▉         | 4
 0: {'loss': 0.7087, 'grad_norm': 3.4835783978098274, 'learning_rate': 9.75e-06, 'epoch': 0.1}
 0: {'loss': 0.7118, 'grad_norm': 3.216620541151138, 'learning_rate': 9.977272727272728e-06, 'epoch': 0.1}
 0: 30/4399 [53:19<7:55:06,  7.18s/it]                                                     10%|▉         | 430/4399 [53:19<7:55:06,  7.18s/it] 10%|▉         | 431/4399 [53:26<7:49:46,  7.10s/it] 10%|▉         | 432/4399 [53:36<9:03:56,  8.23s/it] 10%|▉         | 433/4399 [53:47<9:49:04,  8.91s/it] 10%|▉         | 434/4399 [53:56<9:50:29,  8.94s/it] 10%|▉         | 435/4399 [54:02<8:51:11,  8.04s/it] 10%|▉         | 436/4399 [54:08<8:10:06,  7.42s/it] 10%|▉         | 437/4399 [54:14<7:40:44,  6.98s/it] 10%|▉         | 438/4399 [54:21<7:40:28,  6.98s/it] 10%|▉         | 439/4399 [54:27<7:20:15,  6.67s/it] 10%|█         | 440/4399 [54:38<8:53:39,  8.09s/it]                                                     10%|█         | 440/4399 [54:38<8:53:39,  8.09s/it] 10%|█         | 441/4399 [54:49<9:42:51,  8.84s/it] 10%|█         | 442/4399 [54:58<9:49:27,  8.94s/it] 10%|█         | 443/4399 [55:04<8:50:06,  8.04s/it] 10%|█         | 444/4399 [55:11<8:27:54,  7.71s/it] 
 0: {'loss': 0.7101, 'grad_norm': 3.055882450649718, 'learning_rate': 9.999872487745773e-06, 'epoch': 0.1}
 0: 10%|█         | 445/4399 [55:18<8:11:58,  7.47s/it] 10%|█         | 446/4399 [55:25<8:00:51,  7.30s/it] 10%|█         | 447/4399 [55:32<7:55:10,  7.21s/it] 10%|█         | 448/4399 [55:42<8:55:15,  8.13s/it] 10%|█         | 449/4399 [55:53<10:02:33,  9.15s/it] 10%|█         | 450/4399 [56:02<9:42:27,  8.85s/it]                                                      10%|█         | 450/4399 [56:02<9:42:27,  8.85s/it] 10%|█         | 451/4399 [56:09<9:06:24,  8.30s/it] 10%|█         | 452/4399 [56:15<8:19:45,  7.60s/it] 10%|█         | 453/4399 [56:21<8:04:51,  7.37s/it] 10%|█         | 454/4399 [56:28<7:54:53,  7.22s/it] 10%|█         | 455/4399 [56:34<7:34:27,  6.91s/it] 10%|█         | 456/4399 [56:45<8:38:24,  7.89s/it] 10%|█         | 457/4399 [56:56<9:46:04,  8.92s/it] 10%|█         | 458/4399 [57:04<9:30:26,  8.68s/it] 10%|█         | 459/4399 [57:11<8:56:07,  8.16s/it] 10%|█         | 460/4399 [57:18<8:31:12,  7.79s/it]                                  
 0: {'loss': 0.7172, 'grad_norm': 3.2382434517639624, 'learning_rate': 9.999431712994567e-06, 'epoch': 0.1}
 0: {'loss': 0.6947, 'grad_norm': 3.387875229075157, 'learning_rate': 9.998676129269534e-06, 'epoch': 0.11}
 0:                    10%|█         | 460/4399 [57:18<8:31:12,  7.79s/it] 10%|█         | 461/4399 [57:25<8:13:59,  7.53s/it] 11%|█         | 462/4399 [57:31<7:42:42,  7.05s/it] 11%|█         | 463/4399 [57:37<7:21:32,  6.73s/it] 11%|█         | 464/4399 [57:47<8:22:04,  7.66s/it] 11%|█         | 465/4399 [57:57<9:22:52,  8.58s/it] 11%|█         | 466/4399 [58:05<9:06:17,  8.33s/it] 11%|█         | 467/4399 [58:11<8:19:52,  7.63s/it] 11%|█         | 468/4399 [58:18<8:04:41,  7.40s/it] 11%|█         | 469/4399 [58:25<7:53:54,  7.24s/it] 11%|█         | 470/4399 [58:32<7:47:20,  7.14s/it]                                                     11%|█         | 470/4399 [58:32<7:47:20,  7.14s/it] 11%|█         | 471/4399 [58:38<7:23:11,  6.77s/it] 11%|█         | 472/4399 [58:48<8:29:47,  7.79s/it] 11%|█         | 473/4399 [58:59<9:37:16,  8.82s/it] 11%|█         | 474/4399 [59:07<9:21:27,  8.58s/it] 11%|█         | 475/4399 [59:13<8:31:08,  7.82s/it] 11%|█       
 0: {'loss': 0.7125, 'grad_norm': 3.1252511726186336, 'learning_rate': 9.997605784148992e-06, 'epoch': 0.11}
 0: {'loss': 0.7047, 'grad_norm': 2.8774600031312376, 'learning_rate': 9.996220745031451e-06, 'epoch': 0.11}
 0:   | 476/4399 [59:18<7:36:13,  6.98s/it] 11%|█         | 477/4399 [59:25<7:34:46,  6.96s/it] 11%|█         | 478/4399 [59:32<7:35:16,  6.97s/it] 11%|█         | 479/4399 [59:39<7:33:22,  6.94s/it] 11%|█         | 480/4399 [59:49<8:41:09,  7.98s/it]                                                     11%|█         | 480/4399 [59:49<8:41:09,  7.98s/it] 11%|█         | 481/4399 [1:00:00<9:25:45,  8.66s/it] 11%|█         | 482/4399 [1:00:08<9:28:24,  8.71s/it] 11%|█         | 483/4399 [1:00:16<9:02:06,  8.31s/it] 11%|█         | 484/4399 [1:00:23<8:34:01,  7.88s/it] 11%|█         | 485/4399 [1:00:29<7:58:33,  7.34s/it] 11%|█         | 486/4399 [1:00:36<7:50:23,  7.21s/it] 11%|█         | 487/4399 [1:00:42<7:26:07,  6.84s/it] 11%|█         | 488/4399 [1:00:52<8:44:48,  8.05s/it] 11%|█         | 489/4399 [1:01:03<9:30:31,  8.75s/it] 11%|█         | 490/4399 [1:01:11<9:20:40,  8.61s/it]                                                       11%|█         | 490/4399 [
 0: {'loss': 0.7027, 'grad_norm': 2.9896133503114437, 'learning_rate': 9.994521099131369e-06, 'epoch': 0.11}
 0: 1:01:11<9:20:40,  8.61s/it] 11%|█         | 491/4399 [1:01:18<8:47:17,  8.10s/it] 11%|█         | 492/4399 [1:01:25<8:25:10,  7.76s/it] 11%|█         | 493/4399 [1:01:32<8:08:39,  7.51s/it] 11%|█         | 494/4399 [1:01:39<7:57:09,  7.33s/it] 11%|█▏        | 495/4399 [1:01:46<7:48:26,  7.20s/it] 11%|█▏        | 496/4399 [1:01:56<8:40:45,  8.01s/it] 11%|█▏        | 497/4399 [1:02:06<9:35:11,  8.84s/it] 11%|█▏        | 498/4399 [1:02:15<9:29:39,  8.76s/it] 11%|█▏        | 499/4399 [1:02:21<8:42:34,  8.04s/it] 11%|█▏        | 500/4399 [1:02:28<8:20:05,  7.70s/it]                                                       11%|█▏        | 500/4399 [1:02:28<8:20:05,  7.70s/it][INFO|trainer.py:3984] 2025-06-27 22:06:58,072 >> Saving model checkpoint to /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500
 0: [INFO|configuration_utils.py:419] 2025-06-27 22:06:58,079 >> Configuration saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/config.json
 0: [INFO|configuration_utils.py:911] 2025-06-27 22:06:58,081 >> Configuration saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/generation_config.json
 0: [INFO|modeling_utils.py:3580] 2025-06-27 22:07:05,672 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 4 checkpoint shards. You can find where each parameters has been saved in the index located at /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/model.safetensors.index.json.
 0: [INFO|tokenization_utils_base.py:2510] 2025-06-27 22:07:05,676 >> tokenizer config file saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/tokenizer_config.json
 0: [INFO|tokenization_utils_base.py:2519] 2025-06-27 22:07:05,678 >> Special tokens file saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/special_tokens_map.json
 0: [2025-06-27 22:07:05,909] [INFO] [logging.py:107:log_dist] [Rank 0] [Torch] Checkpoint global_step500 is about to be saved!
19: [2025-06-27 22:07:05,918] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_76_mp_rank_00_model_states.pt...
20: [2025-06-27 22:07:05,919] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_80_mp_rank_00_model_states.pt...
22: [2025-06-27 22:07:05,919] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_88_mp_rank_00_model_states.pt...
28: [2025-06-27 22:07:05,919] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_112_mp_rank_00_model_states.pt...
 4: [2025-06-27 22:07:05,919] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_16_mp_rank_00_model_states.pt...
17: [2025-06-27 22:07:05,919] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_68_mp_rank_00_model_states.pt...
 1: [2025-06-27 22:07:05,919] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_4_mp_rank_00_model_states.pt...
18: [2025-06-27 22:07:05,919] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_72_mp_rank_00_model_states.pt...
23: [2025-06-27 22:07:05,919] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_92_mp_rank_00_model_states.pt...
29: [2025-06-27 22:07:05,919] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_116_mp_rank_00_model_states.pt...
12: [2025-06-27 22:07:05,919] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_48_mp_rank_00_model_states.pt...
30: [2025-06-27 22:07:05,919] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_120_mp_rank_00_model_states.pt...
11: [2025-06-27 22:07:05,919] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_44_mp_rank_00_model_states.pt...
15: [2025-06-27 22:07:05,919] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_60_mp_rank_00_model_states.pt...
14: [2025-06-27 22:07:05,919] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_56_mp_rank_00_model_states.pt...
 0: [2025-06-27 22:07:05,920] [INFO] [logging.py:107:log_dist] [Rank 0] Saving model checkpoint: /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_0_mp_rank_00_model_states.pt
 9: [2025-06-27 22:07:05,920] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_36_mp_rank_00_model_states.pt...
 6: [2025-06-27 22:07:05,920] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_24_mp_rank_00_model_states.pt...
25: [2025-06-27 22:07:05,920] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_100_mp_rank_00_model_states.pt...
 0: [2025-06-27 22:07:05,920] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_0_mp_rank_00_model_states.pt...
10: [2025-06-27 22:07:05,920] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_40_mp_rank_00_model_states.pt...
24: [2025-06-27 22:07:05,920] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_96_mp_rank_00_model_states.pt...
 8: [2025-06-27 22:07:05,920] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_32_mp_rank_00_model_states.pt...
27: [2025-06-27 22:07:05,920] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_108_mp_rank_00_model_states.pt...
16: [2025-06-27 22:07:05,920] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_64_mp_rank_00_model_states.pt...
 5: [2025-06-27 22:07:05,920] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_20_mp_rank_00_model_states.pt...
 3: [2025-06-27 22:07:05,920] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_12_mp_rank_00_model_states.pt...
 2: [2025-06-27 22:07:05,920] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_8_mp_rank_00_model_states.pt...
13: [2025-06-27 22:07:05,920] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_52_mp_rank_00_model_states.pt...
31: [2025-06-27 22:07:05,920] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_124_mp_rank_00_model_states.pt...
 7: [2025-06-27 22:07:05,920] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_28_mp_rank_00_model_states.pt...
21: [2025-06-27 22:07:05,924] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_84_mp_rank_00_model_states.pt...
26: [2025-06-27 22:07:05,924] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_104_mp_rank_00_model_states.pt...
20: [2025-06-27 22:07:05,946] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_80_mp_rank_00_model_states.pt.
 1: [2025-06-27 22:07:05,946] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_4_mp_rank_00_model_states.pt.
12: [2025-06-27 22:07:05,947] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_48_mp_rank_00_model_states.pt.
18: [2025-06-27 22:07:05,949] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_72_mp_rank_00_model_states.pt.
30: [2025-06-27 22:07:05,952] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_120_mp_rank_00_model_states.pt.
 0: [2025-06-27 22:07:05,956] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_0_mp_rank_00_model_states.pt.
23: [2025-06-27 22:07:05,956] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_92_mp_rank_00_model_states.pt.
15: [2025-06-27 22:07:05,960] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_60_mp_rank_00_model_states.pt.
29: [2025-06-27 22:07:05,960] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_116_mp_rank_00_model_states.pt.
22: [2025-06-27 22:07:05,960] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_88_mp_rank_00_model_states.pt.
19: [2025-06-27 22:07:05,963] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_76_mp_rank_00_model_states.pt.
11: [2025-06-27 22:07:05,965] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_44_mp_rank_00_model_states.pt.
25: [2025-06-27 22:07:05,965] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_100_mp_rank_00_model_states.pt.
28: [2025-06-27 22:07:05,965] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_112_mp_rank_00_model_states.pt.
 4: [2025-06-27 22:07:05,966] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_16_mp_rank_00_model_states.pt.
 5: [2025-06-27 22:07:05,967] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_20_mp_rank_00_model_states.pt.
14: [2025-06-27 22:07:05,969] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_56_mp_rank_00_model_states.pt.
 3: [2025-06-27 22:07:05,969] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_12_mp_rank_00_model_states.pt.
10: [2025-06-27 22:07:05,970] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_40_mp_rank_00_model_states.pt.
27: [2025-06-27 22:07:05,971] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_108_mp_rank_00_model_states.pt.
17: [2025-06-27 22:07:05,971] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_68_mp_rank_00_model_states.pt.
31: [2025-06-27 22:07:05,971] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_124_mp_rank_00_model_states.pt.
 2: [2025-06-27 22:07:05,971] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_8_mp_rank_00_model_states.pt.
24: [2025-06-27 22:07:05,971] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_96_mp_rank_00_model_states.pt.
 8: [2025-06-27 22:07:05,971] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_32_mp_rank_00_model_states.pt.
16: [2025-06-27 22:07:05,971] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_64_mp_rank_00_model_states.pt.
 7: [2025-06-27 22:07:05,972] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_28_mp_rank_00_model_states.pt.
 9: [2025-06-27 22:07:05,972] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_36_mp_rank_00_model_states.pt.
 6: [2025-06-27 22:07:05,972] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_24_mp_rank_00_model_states.pt.
13: [2025-06-27 22:07:05,974] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_52_mp_rank_00_model_states.pt.
26: [2025-06-27 22:07:05,974] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_104_mp_rank_00_model_states.pt.
21: [2025-06-27 22:07:05,974] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/zero_pp_rank_84_mp_rank_00_model_states.pt.
 0: [2025-06-27 22:07:06,016] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
 4: [2025-06-27 22:07:06,016] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_16_mp_rank_00_optim_states.pt...
 1: [2025-06-27 22:07:06,016] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_4_mp_rank_00_optim_states.pt...
10: [2025-06-27 22:07:06,016] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_40_mp_rank_00_optim_states.pt...
 8: [2025-06-27 22:07:06,016] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_32_mp_rank_00_optim_states.pt...
14: [2025-06-27 22:07:06,016] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_56_mp_rank_00_optim_states.pt...
12: [2025-06-27 22:07:06,016] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_48_mp_rank_00_optim_states.pt...
 9: [2025-06-27 22:07:06,016] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_36_mp_rank_00_optim_states.pt...
15: [2025-06-27 22:07:06,016] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_60_mp_rank_00_optim_states.pt...
 7: [2025-06-27 22:07:06,016] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_28_mp_rank_00_optim_states.pt...
 3: [2025-06-27 22:07:06,016] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_12_mp_rank_00_optim_states.pt...
 5: [2025-06-27 22:07:06,016] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_20_mp_rank_00_optim_states.pt...
30: [2025-06-27 22:07:06,016] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_120_mp_rank_00_optim_states.pt...
17: [2025-06-27 22:07:06,016] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_68_mp_rank_00_optim_states.pt...
20: [2025-06-27 22:07:06,016] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_80_mp_rank_00_optim_states.pt...
18: [2025-06-27 22:07:06,016] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_72_mp_rank_00_optim_states.pt...
27: [2025-06-27 22:07:06,016] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_108_mp_rank_00_optim_states.pt...
29: [2025-06-27 22:07:06,016] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_116_mp_rank_00_optim_states.pt...
24: [2025-06-27 22:07:06,016] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_96_mp_rank_00_optim_states.pt...
25: [2025-06-27 22:07:06,016] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_100_mp_rank_00_optim_states.pt...
23: [2025-06-27 22:07:06,016] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_92_mp_rank_00_optim_states.pt...
28: [2025-06-27 22:07:06,016] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_112_mp_rank_00_optim_states.pt...
31: [2025-06-27 22:07:06,016] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_124_mp_rank_00_optim_states.pt...
19: [2025-06-27 22:07:06,016] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_76_mp_rank_00_optim_states.pt...
 6: [2025-06-27 22:07:06,016] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_24_mp_rank_00_optim_states.pt...
22: [2025-06-27 22:07:06,016] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_88_mp_rank_00_optim_states.pt...
 2: [2025-06-27 22:07:06,016] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_8_mp_rank_00_optim_states.pt...
13: [2025-06-27 22:07:06,016] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_52_mp_rank_00_optim_states.pt...
11: [2025-06-27 22:07:06,016] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_44_mp_rank_00_optim_states.pt...
16: [2025-06-27 22:07:06,016] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_64_mp_rank_00_optim_states.pt...
21: [2025-06-27 22:07:06,016] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_84_mp_rank_00_optim_states.pt...
26: [2025-06-27 22:07:06,016] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_104_mp_rank_00_optim_states.pt...
 0: [2025-06-27 22:07:06,501] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
 0: [2025-06-27 22:07:06,509] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
 8: [2025-06-27 22:07:08,751] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_32_mp_rank_00_optim_states.pt.
 8: [2025-06-27 22:07:08,751] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_32_mp_rank_00_optim_states.pt
15: [2025-06-27 22:07:08,757] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_60_mp_rank_00_optim_states.pt.
15: [2025-06-27 22:07:08,758] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_60_mp_rank_00_optim_states.pt
26: [2025-06-27 22:07:08,812] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_104_mp_rank_00_optim_states.pt.
26: [2025-06-27 22:07:08,812] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_104_mp_rank_00_optim_states.pt
23: [2025-06-27 22:07:08,815] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_92_mp_rank_00_optim_states.pt.
23: [2025-06-27 22:07:08,815] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_92_mp_rank_00_optim_states.pt
13: [2025-06-27 22:07:08,825] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_52_mp_rank_00_optim_states.pt.
13: [2025-06-27 22:07:08,825] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_52_mp_rank_00_optim_states.pt
 4: [2025-06-27 22:07:08,826] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_16_mp_rank_00_optim_states.pt.
 4: [2025-06-27 22:07:08,826] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_16_mp_rank_00_optim_states.pt
 6: [2025-06-27 22:07:08,827] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_24_mp_rank_00_optim_states.pt.
 6: [2025-06-27 22:07:08,827] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_24_mp_rank_00_optim_states.pt
30: [2025-06-27 22:07:08,829] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_120_mp_rank_00_optim_states.pt.
30: [2025-06-27 22:07:08,829] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_120_mp_rank_00_optim_states.pt
 2: [2025-06-27 22:07:08,829] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_8_mp_rank_00_optim_states.pt.
 2: [2025-06-27 22:07:08,830] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_8_mp_rank_00_optim_states.pt
18: [2025-06-27 22:07:08,831] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_72_mp_rank_00_optim_states.pt.
18: [2025-06-27 22:07:08,831] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_72_mp_rank_00_optim_states.pt
14: [2025-06-27 22:07:08,832] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_56_mp_rank_00_optim_states.pt.
14: [2025-06-27 22:07:08,832] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_56_mp_rank_00_optim_states.pt
17: [2025-06-27 22:07:08,832] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_68_mp_rank_00_optim_states.pt.
17: [2025-06-27 22:07:08,832] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_68_mp_rank_00_optim_states.pt
25: [2025-06-27 22:07:08,834] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_100_mp_rank_00_optim_states.pt.
25: [2025-06-27 22:07:08,834] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_100_mp_rank_00_optim_states.pt
 3: [2025-06-27 22:07:08,835] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_12_mp_rank_00_optim_states.pt.
 3: [2025-06-27 22:07:08,835] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_12_mp_rank_00_optim_states.pt
 7: [2025-06-27 22:07:08,846] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_28_mp_rank_00_optim_states.pt.
 7: [2025-06-27 22:07:08,846] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_28_mp_rank_00_optim_states.pt
 5: [2025-06-27 22:07:08,848] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_20_mp_rank_00_optim_states.pt.
 5: [2025-06-27 22:07:08,848] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_20_mp_rank_00_optim_states.pt
21: [2025-06-27 22:07:08,889] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_84_mp_rank_00_optim_states.pt.
21: [2025-06-27 22:07:08,889] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_84_mp_rank_00_optim_states.pt
11: [2025-06-27 22:07:08,897] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_44_mp_rank_00_optim_states.pt.
11: [2025-06-27 22:07:08,897] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_44_mp_rank_00_optim_states.pt
 1: [2025-06-27 22:07:08,900] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_4_mp_rank_00_optim_states.pt.
 1: [2025-06-27 22:07:08,901] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_4_mp_rank_00_optim_states.pt
16: [2025-06-27 22:07:08,904] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_64_mp_rank_00_optim_states.pt.
16: [2025-06-27 22:07:08,904] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_64_mp_rank_00_optim_states.pt
31: [2025-06-27 22:07:08,909] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_124_mp_rank_00_optim_states.pt.
31: [2025-06-27 22:07:08,909] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_124_mp_rank_00_optim_states.pt
27: [2025-06-27 22:07:08,910] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_108_mp_rank_00_optim_states.pt.
27: [2025-06-27 22:07:08,910] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_108_mp_rank_00_optim_states.pt
22: [2025-06-27 22:07:08,925] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_88_mp_rank_00_optim_states.pt.
22: [2025-06-27 22:07:08,926] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_88_mp_rank_00_optim_states.pt
 9: [2025-06-27 22:07:08,927] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_36_mp_rank_00_optim_states.pt.
 9: [2025-06-27 22:07:08,927] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_36_mp_rank_00_optim_states.pt
28: [2025-06-27 22:07:08,937] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_112_mp_rank_00_optim_states.pt.
28: [2025-06-27 22:07:08,938] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_112_mp_rank_00_optim_states.pt
12: [2025-06-27 22:07:08,942] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_48_mp_rank_00_optim_states.pt.
12: [2025-06-27 22:07:08,943] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_48_mp_rank_00_optim_states.pt
19: [2025-06-27 22:07:08,947] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_76_mp_rank_00_optim_states.pt.
19: [2025-06-27 22:07:08,948] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_76_mp_rank_00_optim_states.pt
20: [2025-06-27 22:07:08,952] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_80_mp_rank_00_optim_states.pt.
20: [2025-06-27 22:07:08,952] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_80_mp_rank_00_optim_states.pt
10: [2025-06-27 22:07:08,952] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_40_mp_rank_00_optim_states.pt.
10: [2025-06-27 22:07:08,952] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_40_mp_rank_00_optim_states.pt
24: [2025-06-27 22:07:09,044] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_96_mp_rank_00_optim_states.pt.
24: [2025-06-27 22:07:09,044] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_96_mp_rank_00_optim_states.pt
29: [2025-06-27 22:07:09,050] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_116_mp_rank_00_optim_states.pt.
29: [2025-06-27 22:07:09,050] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/global_step500/bf16_zero_pp_rank_116_mp_rank_00_optim_states.pt
12: [2025-06-27 22:07:09,174] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step500 is ready now!
 1: [2025-06-27 22:07:09,174] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step500 is ready now!
 9: [2025-06-27 22:07:09,174] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step500 is ready now!
16: [2025-06-27 22:07:09,174] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step500 is ready now!
25: [2025-06-27 22:07:09,174] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step500 is ready now!
28: [2025-06-27 22:07:09,174] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step500 is ready now!
29: [2025-06-27 22:07:09,174] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step500 is ready now!
11: [2025-06-27 22:07:09,174] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step500 is ready now!
24: [2025-06-27 22:07:09,174] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step500 is ready now!
 6: [2025-06-27 22:07:09,174] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step500 is ready now!
14: [2025-06-27 22:07:09,174] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step500 is ready now!
17: [2025-06-27 22:07:09,174] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step500 is ready now!
31: [2025-06-27 22:07:09,175] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step500 is ready now!
18: [2025-06-27 22:07:09,175] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step500 is ready now!
22: [2025-06-27 22:07:09,175] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step500 is ready now!
19: [2025-06-27 22:07:09,175] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step500 is ready now!
 5: [2025-06-27 22:07:09,175] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step500 is ready now!
 0: [2025-06-27 22:07:09,175] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step500 is ready now!
23: [2025-06-27 22:07:09,175] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step500 is ready now!
10: [2025-06-27 22:07:09,175] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step500 is ready now!
20: [2025-06-27 22:07:09,175] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step500 is ready now!
15: [2025-06-27 22:07:09,175] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step500 is ready now!
30: [2025-06-27 22:07:09,175] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step500 is ready now!
 2: [2025-06-27 22:07:09,175] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step500 is ready now!
 7: [2025-06-27 22:07:09,175] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step500 is ready now!
 3: [2025-06-27 22:07:09,175] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step500 is ready now!
27: [2025-06-27 22:07:09,175] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step500 is ready now!
26: [2025-06-27 22:07:09,175] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step500 is ready now!
 4: [2025-06-27 22:07:09,175] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step500 is ready now!
 8: [2025-06-27 22:07:09,175] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step500 is ready now!
13: [2025-06-27 22:07:09,175] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step500 is ready now!
21: [2025-06-27 22:07:09,176] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step500 is ready now!
 0: [INFO|image_processing_base.py:260] 2025-06-27 22:07:09,219 >> Image processor saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/preprocessor_config.json
 0: [INFO|tokenization_utils_base.py:2510] 2025-06-27 22:07:09,221 >> tokenizer config file saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/tokenizer_config.json
 0: [INFO|tokenization_utils_base.py:2519] 2025-06-27 22:07:09,223 >> Special tokens file saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/special_tokens_map.json
 0: [INFO|processing_utils.py:648] 2025-06-27 22:07:09,800 >> chat template saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-500/chat_template.json
 0:  11%|█▏        | 501/4399 [1:03:46<31:11:50, 28.81s/it] 11%|█▏        | 502/4399 [1:03:53<24:03:53, 22.23s/it]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
 0:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
 0: {'loss': 0.6945, 'grad_norm': 3.192182585179496, 'learning_rate': 9.99250695347367e-06, 'epoch': 0.12}
 0:  11%|█▏        | 503/4399 [1:04:00<19:05:25, 17.64s/it] 11%|█▏        | 504/4399 [1:04:11<16:51:42, 15.58s/it] 11%|█▏        | 505/4399 [1:04:22<15:22:44, 14.22s/it] 12%|█▏        | 506/4399 [1:04:30<13:21:59, 12.36s/it] 12%|█▏        | 507/4399 [1:04:37<11:38:14, 10.76s/it] 12%|█▏        | 508/4399 [1:04:44<10:24:17,  9.63s/it] 12%|█▏        | 509/4399 [1:04:51<9:31:43,  8.82s/it]  12%|█▏        | 510/4399 [1:04:58<8:54:26,  8.25s/it]                                                       12%|█▏        | 510/4399 [1:04:58<8:54:26,  8.25s/it] 12%|█▏        | 511/4399 [1:05:05<8:30:21,  7.88s/it] 12%|█▏        | 512/4399 [1:05:15<9:08:24,  8.47s/it] 12%|█▏        | 513/4399 [1:05:26<9:58:38,  9.24s/it] 12%|█▏        | 514/4399 [1:05:33<9:26:22,  8.75s/it] 12%|█▏        | 515/4399 [1:05:41<8:57:25,  8.30s/it] 12%|█▏        | 516/4399 [1:05:47<8:29:18,  7.87s/it] 12%|█▏        | 517/4399 [1:05:54<8:10:46,  7.59s/it] 12%|█▏     
 0: {'loss': 0.6895, 'grad_norm': 2.825969466761999, 'learning_rate': 9.990178434886994e-06, 'epoch': 0.12}
 0: {'loss': 0.7097, 'grad_norm': 2.40492185998661, 'learning_rate': 9.987535689995715e-06, 'epoch': 0.12}
 0:    | 518/4399 [1:06:01<7:57:19,  7.38s/it] 12%|█▏        | 519/4399 [1:06:09<7:55:47,  7.36s/it] 12%|█▏        | 520/4399 [1:06:19<9:00:49,  8.37s/it]                                                       12%|█▏        | 520/4399 [1:06:19<9:00:49,  8.37s/it] 12%|█▏        | 521/4399 [1:06:30<9:53:03,  9.18s/it] 12%|█▏        | 522/4399 [1:06:38<9:23:23,  8.72s/it] 12%|█▏        | 523/4399 [1:06:44<8:38:39,  8.03s/it] 12%|█▏        | 524/4399 [1:06:50<7:58:13,  7.40s/it] 12%|█▏        | 525/4399 [1:06:56<7:30:07,  6.97s/it] 12%|█▏        | 526/4399 [1:07:03<7:28:21,  6.95s/it] 12%|█▏        | 527/4399 [1:07:11<7:36:32,  7.07s/it] 12%|█▏        | 528/4399 [1:07:21<8:47:36,  8.18s/it] 12%|█▏        | 529/4399 [1:07:33<9:58:47,  9.28s/it] 12%|█▏        | 530/4399 [1:07:42<9:43:28,  9.05s/it]                                                       12%|█▏        | 530/4399 [1:07:42<9:43:28,  9.05s/it] 12%|█▏        | 531/4399 [1:07:48<8:50
 0: {'loss': 0.7006, 'grad_norm': 5.2129462033640825, 'learning_rate': 9.98457888521071e-06, 'epoch': 0.12}
 0: :18,  8.23s/it] 12%|█▏        | 532/4399 [1:07:54<8:07:25,  7.56s/it] 12%|█▏        | 533/4399 [1:08:01<7:54:38,  7.37s/it] 12%|█▏        | 534/4399 [1:08:07<7:27:38,  6.95s/it] 12%|█▏        | 535/4399 [1:08:14<7:34:13,  7.05s/it] 12%|█▏        | 536/4399 [1:08:24<8:31:57,  7.95s/it] 12%|█▏        | 537/4399 [1:08:36<9:40:01,  9.01s/it] 12%|█▏        | 538/4399 [1:08:45<9:50:19,  9.17s/it] 12%|█▏        | 539/4399 [1:08:52<9:06:11,  8.49s/it] 12%|█▏        | 540/4399 [1:08:58<8:18:07,  7.74s/it]                                                       12%|█▏        | 540/4399 [1:08:58<8:18:07,  7.74s/it] 12%|█▏        | 541/4399 [1:09:04<7:44:29,  7.22s/it] 12%|█▏        | 542/4399 [1:09:10<7:19:18,  6.83s/it] 12%|█▏        | 543/4399 [1:09:17<7:12:59,  6.74s/it] 12%|█▏        | 544/4399 [1:09:28<8:49:13,  8.24s/it] 12%|█▏        | 545/4399 [1:09:39<9:31:25,  8.90s/it] 12%|█▏        | 546/4399 [1:09:47<9:09:59,  8.56s/it] 12%|█
 0: {'loss': 0.6947, 'grad_norm': 3.1406292584797066, 'learning_rate': 9.981308206718871e-06, 'epoch': 0.13}
 0: {'loss': 0.6961, 'grad_norm': 2.4278322683419535, 'learning_rate': 9.9777238604714e-06, 'epoch': 0.13}
 0: ▏        | 547/4399 [1:09:54<8:40:42,  8.11s/it] 12%|█▏        | 548/4399 [1:10:00<8:15:40,  7.72s/it] 12%|█▏        | 549/4399 [1:10:08<8:04:28,  7.55s/it] 13%|█▎        | 550/4399 [1:10:13<7:31:56,  7.05s/it]                                                       13%|█▎        | 550/4399 [1:10:13<7:31:56,  7.05s/it] 13%|█▎        | 551/4399 [1:10:20<7:18:14,  6.83s/it] 13%|█▎        | 552/4399 [1:10:32<9:03:09,  8.47s/it] 13%|█▎        | 553/4399 [1:10:43<9:58:28,  9.34s/it] 13%|█▎        | 554/4399 [1:10:52<9:33:23,  8.95s/it] 13%|█▎        | 555/4399 [1:10:58<8:42:23,  8.15s/it] 13%|█▎        | 556/4399 [1:11:04<8:00:12,  7.50s/it] 13%|█▎        | 557/4399 [1:11:11<7:49:50,  7.34s/it] 13%|█▎        | 558/4399 [1:11:18<7:40:31,  7.19s/it] 13%|█▎        | 559/4399 [1:11:25<7:42:34,  7.23s/it] 13%|█▎        | 560/4399 [1:11:36<9:03:56,  8.50s/it]                                                       13%|█▎        | 560/4399 [1:11
 0: {'loss': 0.6865, 'grad_norm': 2.287537444201139, 'learning_rate': 9.97382607217082e-06, 'epoch': 0.13}
 0: :36<9:03:56,  8.50s/it] 13%|█▎        | 561/4399 [1:11:48<10:01:31,  9.40s/it] 13%|█▎        | 562/4399 [1:11:56<9:41:30,  9.09s/it]  13%|█▎        | 563/4399 [1:12:03<8:49:57,  8.29s/it] 13%|█▎        | 564/4399 [1:12:09<8:04:53,  7.59s/it] 13%|█▎        | 565/4399 [1:12:15<7:34:05,  7.11s/it] 13%|█▎        | 566/4399 [1:12:21<7:11:27,  6.75s/it] 13%|█▎        | 567/4399 [1:12:28<7:21:56,  6.92s/it] 13%|█▎        | 568/4399 [1:12:37<8:09:25,  7.67s/it] 13%|█▎        | 569/4399 [1:12:47<8:51:31,  8.33s/it] 13%|█▎        | 570/4399 [1:12:55<8:38:48,  8.13s/it]                                                       13%|█▎        | 570/4399 [1:12:55<8:38:48,  8.13s/it] 13%|█▎        | 571/4399 [1:13:02<8:19:09,  7.82s/it] 13%|█▎        | 572/4399 [1:13:08<7:42:44,  7.25s/it] 13%|█▎        | 573/4399 [1:13:15<7:35:15,  7.14s/it] 13%|█▎        | 574/4399 [1:13:20<6:54:12,  6.50s/it] 13%|█▎        | 575/4399 [1:13:26<6:47:17,  6.39s/it
 0: {'loss': 0.6971, 'grad_norm': 3.0516480283003715, 'learning_rate': 9.969615087256772e-06, 'epoch': 0.13}
 0: ] 13%|█▎        | 576/4399 [1:13:38<8:30:15,  8.01s/it] 13%|█▎        | 577/4399 [1:13:48<9:13:12,  8.68s/it] 13%|█▎        | 578/4399 [1:13:57<9:15:56,  8.73s/it] 13%|█▎        | 579/4399 [1:14:04<8:51:14,  8.34s/it] 13%|█▎        | 580/4399 [1:14:11<8:23:01,  7.90s/it]                                                       13%|█▎        | 580/4399 [1:14:11<8:23:01,  7.90s/it] 13%|█▎        | 581/4399 [1:14:18<8:03:58,  7.61s/it] 13%|█▎        | 582/4399 [1:14:24<7:32:13,  7.11s/it] 13%|█▎        | 583/4399 [1:14:31<7:39:56,  7.23s/it] 13%|█▎        | 584/4399 [1:14:43<9:02:46,  8.54s/it] 13%|█▎        | 585/4399 [1:14:54<9:55:26,  9.37s/it] 13%|█▎        | 586/4399 [1:15:03<9:39:37,  9.12s/it] 13%|█▎        | 587/4399 [1:15:08<8:28:30,  8.00s/it] 13%|█▎        | 588/4399 [1:15:15<8:07:13,  7.67s/it] 13%|█▎        | 589/4399 [1:15:21<7:34:30,  7.16s/it] 13%|█▎        | 590/4399 [1:15:28<7:29:35,  7.08s/it]                      
 0: {'loss': 0.6991, 'grad_norm': 3.1890350909101, 'learning_rate': 9.965091170890565e-06, 'epoch': 0.13}
 0: {'loss': 0.683, 'grad_norm': 2.846842637492739, 'learning_rate': 9.960254607938468e-06, 'epoch': 0.14}
 0:                                  13%|█▎        | 590/4399 [1:15:28<7:29:35,  7.08s/it] 13%|█▎        | 591/4399 [1:15:35<7:27:17,  7.05s/it] 13%|█▎        | 592/4399 [1:15:46<8:34:31,  8.11s/it] 13%|█▎        | 593/4399 [1:15:57<9:37:56,  9.11s/it] 14%|█▎        | 594/4399 [1:16:06<9:34:36,  9.06s/it] 14%|█▎        | 595/4399 [1:16:13<9:01:12,  8.54s/it] 14%|█▎        | 596/4399 [1:16:19<8:12:31,  7.77s/it] 14%|█▎        | 597/4399 [1:16:26<7:58:54,  7.56s/it] 14%|█▎        | 598/4399 [1:16:33<7:46:07,  7.36s/it] 14%|█▎        | 599/4399 [1:16:39<7:18:26,  6.92s/it] 14%|█▎        | 600/4399 [1:16:49<8:14:22,  7.81s/it]                                                       14%|█▎        | 600/4399 [1:16:49<8:14:22,  7.81s/it] 14%|█▎        | 601/4399 [1:17:00<9:13:41,  8.75s/it] 14%|█▎        | 602/4399 [1:17:08<8:53:23,  8.43s/it] 14%|█▎        | 603/4399 [1:17:13<7:55:52,  7.52s/it] 14%|█▎        | 604/4399 [1:17:20<7:44:12,  
 0: {'loss': 0.6843, 'grad_norm': 2.2987481020204292, 'learning_rate': 9.95510570295378e-06, 'epoch': 0.14}
 0: 7.34s/it] 14%|█▍        | 605/4399 [1:17:27<7:35:13,  7.20s/it] 14%|█▍        | 606/4399 [1:17:34<7:29:52,  7.12s/it] 14%|█▍        | 607/4399 [1:17:41<7:34:11,  7.19s/it] 14%|█▍        | 608/4399 [1:17:53<8:58:25,  8.52s/it] 14%|█▍        | 609/4399 [1:18:04<9:57:26,  9.46s/it] 14%|█▍        | 610/4399 [1:18:13<9:49:50,  9.34s/it]                                                       14%|█▍        | 610/4399 [1:18:13<9:49:50,  9.34s/it] 14%|█▍        | 611/4399 [1:18:20<8:53:35,  8.45s/it] 14%|█▍        | 612/4399 [1:18:26<8:05:35,  7.69s/it] 14%|█▍        | 613/4399 [1:18:32<7:32:46,  7.18s/it] 14%|█▍        | 614/4399 [1:18:38<7:09:10,  6.80s/it] 14%|█▍        | 615/4399 [1:18:44<6:57:46,  6.62s/it] 14%|█▍        | 616/4399 [1:18:55<8:19:35,  7.92s/it] 14%|█▍        | 617/4399 [1:19:06<9:22:13,  8.92s/it] 14%|█▍        | 618/4399 [1:19:14<9:10:00,  8.73s/it] 14%|█▍        | 619/4399 [1:19:22<8:43:19,  8.31s/it] 14%|█▍   
 0: {'loss': 0.6888, 'grad_norm': 2.256645151593096, 'learning_rate': 9.949644780157652e-06, 'epoch': 0.14}
 0: {'loss': 0.6988, 'grad_norm': 2.5769972114587865, 'learning_rate': 9.943872183418664e-06, 'epoch': 0.14}
 0:      | 620/4399 [1:19:28<7:57:46,  7.59s/it]                                                       14%|█▍        | 620/4399 [1:19:28<7:57:46,  7.59s/it] 14%|█▍        | 621/4399 [1:19:35<7:47:49,  7.43s/it] 14%|█▍        | 622/4399 [1:19:42<7:39:34,  7.30s/it] 14%|█▍        | 623/4399 [1:19:48<7:18:55,  6.97s/it] 14%|█▍        | 624/4399 [1:19:59<8:37:45,  8.23s/it] 14%|█▍        | 625/4399 [1:20:09<9:18:20,  8.88s/it] 14%|█▍        | 626/4399 [1:20:19<9:41:18,  9.24s/it] 14%|█▍        | 627/4399 [1:20:27<9:06:58,  8.70s/it] 14%|█▍        | 628/4399 [1:20:33<8:15:08,  7.88s/it] 14%|█▍        | 629/4399 [1:20:39<7:38:16,  7.29s/it] 14%|█▍        | 630/4399 [1:20:45<7:12:38,  6.89s/it]                                                       14%|█▍        | 630/4399 [1:20:45<7:12:38,  6.89s/it] 14%|█▍        | 631/4399 [1:20:52<7:17:59,  6.97s/it] 14%|█▍        | 632/4399 [1:21:02<8:24:08,  8.03s/it] 14%|█▍        | 633/4399 [1:21:12<8:
 0: {'loss': 0.6721, 'grad_norm': 2.443116771045898, 'learning_rate': 9.937788276231183e-06, 'epoch': 0.15}
 0: 53:29,  8.50s/it] 14%|█▍        | 634/4399 [1:21:22<9:15:19,  8.85s/it] 14%|█▍        | 635/4399 [1:21:29<8:41:42,  8.32s/it] 14%|█▍        | 636/4399 [1:21:34<7:39:43,  7.33s/it] 14%|█▍        | 637/4399 [1:21:41<7:32:09,  7.21s/it] 15%|█▍        | 638/4399 [1:21:48<7:26:25,  7.12s/it] 15%|█▍        | 639/4399 [1:21:55<7:25:57,  7.12s/it] 15%|█▍        | 640/4399 [1:22:05<8:33:45,  8.20s/it]                                                       15%|█▍        | 640/4399 [1:22:05<8:33:45,  8.20s/it] 15%|█▍        | 641/4399 [1:22:16<9:10:17,  8.79s/it] 15%|█▍        | 642/4399 [1:22:25<9:15:19,  8.87s/it] 15%|█▍        | 643/4399 [1:22:32<8:45:29,  8.39s/it] 15%|█▍        | 644/4399 [1:22:38<7:57:24,  7.63s/it] 15%|█▍        | 645/4399 [1:22:44<7:24:44,  7.11s/it] 15%|█▍        | 646/4399 [1:22:51<7:22:20,  7.07s/it] 15%|█▍        | 647/4399 [1:22:58<7:19:14,  7.02s/it] 15%|█▍        | 648/4399 [1:23:09<8:43:01,  8.37s/it] 15%|
 0: {'loss': 0.6787, 'grad_norm': 2.2831675089647896, 'learning_rate': 9.931393441692468e-06, 'epoch': 0.15}
 0: {'loss': 0.6783, 'grad_norm': 2.3427250909114705, 'learning_rate': 9.924688082478541e-06, 'epoch': 0.15}
 0: ▍        | 649/4399 [1:23:21<9:42:33,  9.32s/it] 15%|█▍        | 650/4399 [1:23:30<9:43:59,  9.35s/it]                                                       15%|█▍        | 650/4399 [1:23:30<9:43:59,  9.35s/it] 15%|█▍        | 651/4399 [1:23:37<9:04:30,  8.72s/it] 15%|█▍        | 652/4399 [1:23:44<8:29:35,  8.16s/it] 15%|█▍        | 653/4399 [1:23:51<8:03:32,  7.75s/it] 15%|█▍        | 654/4399 [1:23:57<7:29:11,  7.20s/it] 15%|█▍        | 655/4399 [1:24:03<7:10:37,  6.90s/it] 15%|█▍        | 656/4399 [1:24:14<8:32:03,  8.21s/it] 15%|█▍        | 657/4399 [1:24:25<9:18:51,  8.96s/it] 15%|█▍        | 658/4399 [1:24:33<8:57:40,  8.62s/it] 15%|█▍        | 659/4399 [1:24:40<8:29:18,  8.17s/it] 15%|█▌        | 660/4399 [1:24:46<7:47:14,  7.50s/it]                                                       15%|█▌        | 660/4399 [1:24:46<7:47:14,  7.50s/it] 15%|█▌        | 661/4399 [1:24:52<7:19:05,  7.05s/it] 15%|█▌        | 662/4399 [1:
 0: {'loss': 0.6758, 'grad_norm': 1.9440103754699312, 'learning_rate': 9.917672620818848e-06, 'epoch': 0.15}
 0: 24:59<7:16:18,  7.01s/it] 15%|█▌        | 663/4399 [1:25:05<6:55:55,  6.68s/it] 15%|█▌        | 664/4399 [1:25:16<8:29:31,  8.19s/it] 15%|█▌        | 665/4399 [1:25:26<8:52:13,  8.55s/it] 15%|█▌        | 666/4399 [1:25:36<9:18:03,  8.97s/it] 15%|█▌        | 667/4399 [1:25:42<8:35:36,  8.29s/it] 15%|█▌        | 668/4399 [1:25:49<8:08:22,  7.85s/it] 15%|█▌        | 669/4399 [1:25:55<7:35:20,  7.32s/it] 15%|█▌        | 670/4399 [1:26:01<7:10:27,  6.93s/it]                                                       15%|█▌        | 670/4399 [1:26:01<7:10:27,  6.93s/it] 15%|█▌        | 671/4399 [1:26:08<6:56:04,  6.70s/it] 15%|█▌        | 672/4399 [1:26:20<8:43:45,  8.43s/it] 15%|█▌        | 673/4399 [1:26:30<9:19:24,  9.01s/it] 15%|█▌        | 674/4399 [1:26:40<9:29:04,  9.17s/it] 15%|█▌        | 675/4399 [1:26:47<8:53:44,  8.60s/it] 15%|█▌        | 676/4399 [1:26:53<8:03:44,  7.80s/it] 15%|█▌        | 677/4399 [1:27:00<7:46:52,  7.53s/it
 0: {'loss': 0.6863, 'grad_norm': 2.6896201737723433, 'learning_rate': 9.910347498469651e-06, 'epoch': 0.15}
 0: {'loss': 0.676, 'grad_norm': 2.3855470814983373, 'learning_rate': 9.902713176686228e-06, 'epoch': 0.16}
 0: ] 15%|█▌        | 678/4399 [1:27:06<7:19:04,  7.08s/it] 15%|█▌        | 679/4399 [1:27:12<7:03:16,  6.83s/it] 15%|█▌        | 680/4399 [1:27:23<8:17:42,  8.03s/it]                                                       15%|█▌        | 680/4399 [1:27:23<8:17:42,  8.03s/it] 15%|█▌        | 681/4399 [1:27:33<8:59:15,  8.70s/it] 16%|█▌        | 682/4399 [1:27:43<9:10:22,  8.88s/it] 16%|█▌        | 683/4399 [1:27:50<8:45:07,  8.48s/it] 16%|█▌        | 684/4399 [1:27:57<8:15:02,  8.00s/it] 16%|█▌        | 685/4399 [1:28:02<7:19:34,  7.10s/it] 16%|█▌        | 686/4399 [1:28:09<7:16:10,  7.05s/it] 16%|█▌        | 687/4399 [1:28:15<6:58:34,  6.77s/it] 16%|█▌        | 688/4399 [1:28:27<8:37:11,  8.36s/it] 16%|█▌        | 689/4399 [1:28:38<9:20:37,  9.07s/it] 16%|█▌        | 690/4399 [1:28:46<9:09:26,  8.89s/it]                                                       16%|█▌        | 690/4399 [1:28:46<9:09:26,  8.89s/it] 16%|█▌        | 691/
 0: {'loss': 0.6813, 'grad_norm': 1.9399094270997632, 'learning_rate': 9.894770136193814e-06, 'epoch': 0.16}
 0: 4399 [1:28:52<8:14:38,  8.00s/it] 16%|█▌        | 692/4399 [1:28:58<7:36:01,  7.38s/it] 16%|█▌        | 693/4399 [1:29:04<7:08:54,  6.94s/it] 16%|█▌        | 694/4399 [1:29:11<7:08:08,  6.93s/it] 16%|█▌        | 695/4399 [1:29:17<6:54:59,  6.72s/it] 16%|█▌        | 696/4399 [1:29:29<8:27:30,  8.22s/it] 16%|█▌        | 697/4399 [1:29:40<9:08:47,  8.89s/it] 16%|█▌        | 698/4399 [1:29:50<9:40:02,  9.40s/it] 16%|█▌        | 699/4399 [1:29:58<9:09:54,  8.92s/it] 16%|█▌        | 700/4399 [1:30:05<8:35:26,  8.36s/it]                                                       16%|█▌        | 700/4399 [1:30:05<8:35:26,  8.36s/it] 16%|█▌        | 701/4399 [1:30:12<8:08:32,  7.93s/it] 16%|█▌        | 702/4399 [1:30:19<7:48:33,  7.60s/it] 16%|█▌        | 703/4399 [1:30:25<7:20:59,  7.16s/it] 16%|█▌        | 704/4399 [1:30:35<8:19:23,  8.11s/it] 16%|█▌        | 705/4399 [1:30:46<9:02:32,  8.81s/it] 16%|█▌        | 706/4399 [1:30:54<8:58:54,  
 0: {'loss': 0.6882, 'grad_norm': 2.686541799068452, 'learning_rate': 9.886518877157347e-06, 'epoch': 0.16}
 0: {'loss': 0.6706, 'grad_norm': 2.2617013564466233, 'learning_rate': 9.877959919149955e-06, 'epoch': 0.16}
 0: 8.76s/it] 16%|█▌        | 707/4399 [1:31:01<8:21:52,  8.16s/it] 16%|█▌        | 708/4399 [1:31:07<7:39:57,  7.48s/it] 16%|█▌        | 709/4399 [1:31:14<7:28:26,  7.29s/it] 16%|█▌        | 710/4399 [1:31:21<7:21:29,  7.18s/it]                                                       16%|█▌        | 710/4399 [1:31:21<7:21:29,  7.18s/it] 16%|█▌        | 711/4399 [1:31:28<7:19:50,  7.16s/it] 16%|█▌        | 712/4399 [1:31:39<8:26:19,  8.24s/it] 16%|█▌        | 713/4399 [1:31:49<9:14:54,  9.03s/it] 16%|█▌        | 714/4399 [1:31:59<9:25:56,  9.21s/it] 16%|█▋        | 715/4399 [1:32:06<8:44:03,  8.54s/it] 16%|█▋        | 716/4399 [1:32:12<7:56:12,  7.76s/it] 16%|█▋        | 717/4399 [1:32:19<7:39:36,  7.49s/it] 16%|█▋        | 718/4399 [1:32:25<7:10:24,  7.02s/it] 16%|█▋        | 719/4399 [1:32:31<6:50:03,  6.69s/it] 16%|█▋        | 720/4399 [1:32:40<7:34:28,  7.41s/it]                                                       16%|█▋      
 0: {'loss': 0.6759, 'grad_norm': 2.5038201769374333, 'learning_rate': 9.86909380112025e-06, 'epoch': 0.17}
 0:   | 720/4399 [1:32:40<7:34:28,  7.41s/it] 16%|█▋        | 721/4399 [1:32:51<8:37:22,  8.44s/it] 16%|█▋        | 722/4399 [1:33:01<9:09:18,  8.96s/it] 16%|█▋        | 723/4399 [1:33:09<8:49:05,  8.64s/it] 16%|█▋        | 724/4399 [1:33:16<8:16:28,  8.11s/it] 16%|█▋        | 725/4399 [1:33:21<7:18:58,  7.17s/it] 17%|█▋        | 726/4399 [1:33:26<6:56:30,  6.80s/it] 17%|█▋        | 727/4399 [1:33:34<7:02:23,  6.90s/it] 17%|█▋        | 728/4399 [1:33:44<8:06:09,  7.95s/it] 17%|█▋        | 729/4399 [1:33:55<8:59:06,  8.81s/it] 17%|█▋        | 730/4399 [1:34:06<9:40:08,  9.49s/it]                                                       17%|█▋        | 730/4399 [1:34:06<9:40:08,  9.49s/it] 17%|█▋        | 731/4399 [1:34:14<9:13:00,  9.05s/it] 17%|█▋        | 732/4399 [1:34:21<8:39:32,  8.50s/it] 17%|█▋        | 733/4399 [1:34:27<7:51:33,  7.72s/it] 17%|█▋        | 734/4399 [1:34:34<7:38:47,  7.51s/it] 17%|█▋        | 735/4399 [1:34:40<7:
 0: {'loss': 0.6538, 'grad_norm': 4.640706651483579, 'learning_rate': 9.859921081358395e-06, 'epoch': 0.17}
 0: 10:10,  7.04s/it] 17%|█▋        | 736/4399 [1:34:49<7:36:52,  7.48s/it] 17%|█▋        | 737/4399 [1:35:00<8:48:02,  8.65s/it] 17%|█▋        | 738/4399 [1:35:11<9:29:49,  9.34s/it] 17%|█▋        | 739/4399 [1:35:19<9:07:05,  8.97s/it] 17%|█▋        | 740/4399 [1:35:26<8:31:30,  8.39s/it]                                                       17%|█▋        | 740/4399 [1:35:26<8:31:30,  8.39s/it] 17%|█▋        | 741/4399 [1:35:33<8:03:53,  7.94s/it] 17%|█▋        | 742/4399 [1:35:39<7:26:10,  7.32s/it] 17%|█▋        | 743/4399 [1:35:46<7:18:09,  7.19s/it] 17%|█▋        | 744/4399 [1:35:54<7:47:36,  7.68s/it] 17%|█▋        | 745/4399 [1:36:06<8:50:39,  8.71s/it] 17%|█▋        | 746/4399 [1:36:15<9:09:41,  9.03s/it] 17%|█▋        | 747/4399 [1:36:23<8:53:17,  8.76s/it] 17%|█▋        | 748/4399 [1:36:29<8:02:34,  7.93s/it] 17%|█▋        | 749/4399 [1:36:36<7:43:44,  7.62s/it] 17%|█▋        | 750/4399 [1:36:42<7:13:55,  7.13s/it]      
 0: {'loss': 0.6892, 'grad_norm': 7.578523583393782, 'learning_rate': 9.850442337460931e-06, 'epoch': 0.17}
 0: {'loss': 0.6589, 'grad_norm': 2.340715578401505, 'learning_rate': 9.840658166294427e-06, 'epoch': 0.17}
 0:                                                  17%|█▋        | 750/4399 [1:36:42<7:13:55,  7.13s/it] 17%|█▋        | 751/4399 [1:36:49<6:57:11,  6.86s/it] 17%|█▋        | 752/4399 [1:36:58<7:50:15,  7.74s/it] 17%|█▋        | 753/4399 [1:37:08<8:25:00,  8.31s/it] 17%|█▋        | 754/4399 [1:37:19<9:08:35,  9.03s/it] 17%|█▋        | 755/4399 [1:37:27<8:51:39,  8.75s/it] 17%|█▋        | 756/4399 [1:37:33<8:00:53,  7.92s/it] 17%|█▋        | 757/4399 [1:37:40<7:48:07,  7.71s/it] 17%|█▋        | 758/4399 [1:37:47<7:33:40,  7.48s/it] 17%|█▋        | 759/4399 [1:37:54<7:29:45,  7.41s/it] 17%|█▋        | 760/4399 [1:38:04<8:16:59,  8.19s/it]                                                       17%|█▋        | 760/4399 [1:38:04<8:16:59,  8.19s/it] 17%|█▋        | 761/4399 [1:38:15<9:01:50,  8.94s/it] 17%|█▋        | 762/4399 [1:38:25<9:27:28,  9.36s/it] 17%|█▋        | 763/4399 [1:38:32<8:41:56,  8.61s/it] 17%|█▋        | 764/4399 [1:
 0: {'loss': 0.6672, 'grad_norm': 2.0978907048474276, 'learning_rate': 9.830569183957883e-06, 'epoch': 0.18}
 0: 38:38<7:52:15,  7.80s/it] 17%|█▋        | 765/4399 [1:38:45<7:36:06,  7.53s/it] 17%|█▋        | 766/4399 [1:38:51<7:06:59,  7.05s/it] 17%|█▋        | 767/4399 [1:38:56<6:33:33,  6.50s/it] 17%|█▋        | 768/4399 [1:39:04<7:06:55,  7.05s/it] 17%|█▋        | 769/4399 [1:39:15<8:06:35,  8.04s/it] 18%|█▊        | 770/4399 [1:39:25<8:42:17,  8.64s/it]                                                       18%|█▊        | 770/4399 [1:39:25<8:42:17,  8.64s/it] 18%|█▊        | 771/4399 [1:39:33<8:37:46,  8.56s/it] 18%|█▊        | 772/4399 [1:39:40<8:07:32,  8.07s/it] 18%|█▊        | 773/4399 [1:39:47<7:46:25,  7.72s/it] 18%|█▊        | 774/4399 [1:39:54<7:31:50,  7.48s/it] 18%|█▊        | 775/4399 [1:40:00<7:08:05,  7.09s/it] 18%|█▊        | 776/4399 [1:40:09<7:43:41,  7.68s/it] 18%|█▊        | 777/4399 [1:40:20<8:46:02,  8.71s/it] 18%|█▊        | 778/4399 [1:40:31<9:15:44,  9.21s/it] 18%|█▊        | 779/4399 [1:40:37<8:19:18,  8.28s/it
 0: {'loss': 0.6801, 'grad_norm': 2.4413269430623026, 'learning_rate': 9.82017602574394e-06, 'epoch': 0.18}
 0: {'loss': 0.6677, 'grad_norm': 2.2764202837131498, 'learning_rate': 9.809479346098881e-06, 'epoch': 0.18}
 0: ] 18%|█▊        | 780/4399 [1:40:43<7:44:10,  7.70s/it]                                                       18%|█▊        | 780/4399 [1:40:43<7:44:10,  7.70s/it] 18%|█▊        | 781/4399 [1:40:49<7:11:43,  7.16s/it] 18%|█▊        | 782/4399 [1:40:55<6:48:43,  6.78s/it] 18%|█▊        | 783/4399 [1:41:02<6:55:54,  6.90s/it] 18%|█▊        | 784/4399 [1:41:11<7:39:14,  7.62s/it] 18%|█▊        | 785/4399 [1:41:23<8:49:31,  8.79s/it] 18%|█▊        | 786/4399 [1:41:33<9:20:57,  9.32s/it] 18%|█▊        | 787/4399 [1:41:42<8:58:44,  8.95s/it] 18%|█▊        | 788/4399 [1:41:48<8:14:19,  8.21s/it] 18%|█▊        | 789/4399 [1:41:54<7:34:11,  7.55s/it] 18%|█▊        | 790/4399 [1:42:00<7:03:50,  7.05s/it]                                                       18%|█▊        | 790/4399 [1:42:00<7:03:50,  7.05s/it] 18%|█▊        | 791/4399 [1:42:07<7:01:37,  7.01s/it] 18%|█▊        | 792/4399 [1:42:17<7:58:57,  7.97s/it] 18%|█▊        | 793/
 0: {'loss': 0.6643, 'grad_norm': 2.2405784648201523, 'learning_rate': 9.7984798185814e-06, 'epoch': 0.18}
 0: 4399 [1:42:28<8:49:14,  8.81s/it] 18%|█▊        | 794/4399 [1:42:39<9:23:53,  9.39s/it] 18%|█▊        | 795/4399 [1:42:45<8:24:21,  8.40s/it] 18%|█▊        | 796/4399 [1:42:52<8:07:55,  8.13s/it] 18%|█▊        | 797/4399 [1:42:59<7:45:53,  7.76s/it] 18%|█▊        | 798/4399 [1:43:04<6:55:37,  6.93s/it] 18%|█▊        | 799/4399 [1:43:10<6:41:46,  6.70s/it] 18%|█▊        | 800/4399 [1:43:19<7:14:48,  7.25s/it]                                                       18%|█▊        | 800/4399 [1:43:19<7:14:48,  7.25s/it] 18%|█▊        | 801/4399 [1:43:30<8:22:00,  8.37s/it] 18%|█▊        | 802/4399 [1:43:38<8:24:47,  8.42s/it] 18%|█▊        | 803/4399 [1:43:46<8:05:05,  8.09s/it] 18%|█▊        | 804/4399 [1:43:52<7:34:13,  7.58s/it] 18%|█▊        | 805/4399 [1:43:58<7:05:23,  7.10s/it] 18%|█▊        | 806/4399 [1:44:05<7:01:22,  7.04s/it] 18%|█▊        | 807/4399 [1:44:11<6:41:22,  6.70s/it] 18%|█▊        | 808/4399 [1:44:20<7:27:08,  
 0: {'loss': 0.6462, 'grad_norm': 2.7461251480076525, 'learning_rate': 9.787178135820218e-06, 'epoch': 0.18}
 0: {'loss': 0.6611, 'grad_norm': 2.118911698344449, 'learning_rate': 9.775575009470453e-06, 'epoch': 0.19}
 0: 7.47s/it] 18%|█▊        | 809/4399 [1:44:31<8:24:10,  8.43s/it] 18%|█▊        | 810/4399 [1:44:41<8:56:47,  8.97s/it]                                                       18%|█▊        | 810/4399 [1:44:41<8:56:47,  8.97s/it] 18%|█▊        | 811/4399 [1:44:48<8:20:20,  8.37s/it] 18%|█▊        | 812/4399 [1:44:54<7:48:49,  7.84s/it] 18%|█▊        | 813/4399 [1:45:01<7:31:13,  7.55s/it] 19%|█▊        | 814/4399 [1:45:06<6:45:16,  6.78s/it] 19%|█▊        | 815/4399 [1:45:12<6:29:13,  6.52s/it] 19%|█▊        | 816/4399 [1:45:22<7:26:28,  7.48s/it] 19%|█▊        | 817/4399 [1:45:33<8:31:44,  8.57s/it] 19%|█▊        | 818/4399 [1:45:43<8:48:18,  8.85s/it] 19%|█▊        | 819/4399 [1:45:50<8:19:34,  8.37s/it] 19%|█▊        | 820/4399 [1:45:57<8:02:41,  8.09s/it]                                                       19%|█▊        | 820/4399 [1:45:57<8:02:41,  8.09s/it] 19%|█▊        | 821/4399 [1:46:03<7:23:17,  7.43s/it] 19%|█▊      
 0: {'loss': 0.6656, 'grad_norm': 2.312347984279664, 'learning_rate': 9.763671170168802e-06, 'epoch': 0.19}
 0:   | 822/4399 [1:46:10<7:12:34,  7.26s/it] 19%|█▊        | 823/4399 [1:46:16<6:53:22,  6.94s/it] 19%|█▊        | 824/4399 [1:46:24<7:15:33,  7.31s/it] 19%|█▉        | 825/4399 [1:46:36<8:31:41,  8.59s/it] 19%|█▉        | 826/4399 [1:46:45<8:42:27,  8.77s/it] 19%|█▉        | 827/4399 [1:46:53<8:29:26,  8.56s/it] 19%|█▉        | 828/4399 [1:47:00<7:56:13,  8.00s/it] 19%|█▉        | 829/4399 [1:47:06<7:20:08,  7.40s/it] 19%|█▉        | 830/4399 [1:47:13<7:10:01,  7.23s/it]                                                       19%|█▉        | 830/4399 [1:47:13<7:10:01,  7.23s/it] 19%|█▉        | 831/4399 [1:47:20<7:07:43,  7.19s/it] 19%|█▉        | 832/4399 [1:47:29<7:49:02,  7.89s/it] 19%|█▉        | 833/4399 [1:47:40<8:43:16,  8.80s/it] 19%|█▉        | 834/4399 [1:47:50<8:57:40,  9.05s/it] 19%|█▉        | 835/4399 [1:47:58<8:45:16,  8.84s/it] 19%|█▉        | 836/4399 [1:48:06<8:21:01,  8.44s/it] 19%|█▉        | 837/4399 [1:48:12<7:
 0: {'loss': 0.6506, 'grad_norm': 2.9220363041322983, 'learning_rate': 9.751467367487548e-06, 'epoch': 0.19}
 0: {'loss': 0.6577, 'grad_norm': 2.448434011534857, 'learning_rate': 9.738964369887354e-06, 'epoch': 0.19}
 0: 38:39,  7.73s/it] 19%|█▉        | 838/4399 [1:48:19<7:23:10,  7.47s/it] 19%|█▉        | 839/4399 [1:48:24<6:43:24,  6.80s/it] 19%|█▉        | 840/4399 [1:48:34<7:32:14,  7.62s/it]                                                       19%|█▉        | 840/4399 [1:48:34<7:32:14,  7.62s/it] 19%|█▉        | 841/4399 [1:48:44<8:28:29,  8.57s/it] 19%|█▉        | 842/4399 [1:48:54<8:51:39,  8.97s/it] 19%|█▉        | 843/4399 [1:49:03<8:41:36,  8.80s/it] 19%|█▉        | 844/4399 [1:49:09<8:00:38,  8.11s/it] 19%|█▉        | 845/4399 [1:49:14<7:05:38,  7.19s/it] 19%|█▉        | 846/4399 [1:49:20<6:44:14,  6.83s/it] 19%|█▉        | 847/4399 [1:49:26<6:31:33,  6.61s/it] 19%|█▉        | 848/4399 [1:49:36<7:31:41,  7.63s/it] 19%|█▉        | 849/4399 [1:49:48<8:49:41,  8.95s/it] 19%|█▉        | 850/4399 [1:49:58<9:09:57,  9.30s/it]                                                       19%|█▉        | 850/4399 [1:49:58<9:09:57,  9.30s/it] 19%|█
 0: {'loss': 0.6802, 'grad_norm': 2.1976429762282996, 'learning_rate': 9.72616296466887e-06, 'epoch': 0.2}
 0:         | 851/4399 [1:50:08<9:07:48,  9.26s/it] 19%|█▉        | 852/4399 [1:50:14<8:20:23,  8.46s/it] 19%|█▉        | 853/4399 [1:50:21<7:53:25,  8.01s/it] 19%|█▉        | 854/4399 [1:50:27<7:16:46,  7.39s/it] 19%|█▉        | 855/4399 [1:50:34<7:10:30,  7.29s/it] 19%|█▉        | 856/4399 [1:50:44<7:50:24,  7.97s/it] 19%|█▉        | 857/4399 [1:50:54<8:33:58,  8.71s/it] 20%|█▉        | 858/4399 [1:51:03<8:36:36,  8.75s/it] 20%|█▉        | 859/4399 [1:51:12<8:41:29,  8.84s/it] 20%|█▉        | 860/4399 [1:51:19<8:02:42,  8.18s/it]                                                       20%|█▉        | 860/4399 [1:51:19<8:02:42,  8.18s/it] 20%|█▉        | 861/4399 [1:51:25<7:22:51,  7.51s/it] 20%|█▉        | 862/4399 [1:51:32<7:14:44,  7.37s/it] 20%|█▉        | 863/4399 [1:51:39<7:08:52,  7.28s/it] 20%|█▉        | 864/4399 [1:51:47<7:31:04,  7.66s/it] 20%|█▉        | 865/4399 [1:51:58<8:26:52,  8.61s/it] 20%|█▉        | 866/4399 [1:
 0: {'loss': 0.6506, 'grad_norm': 1.9484622975654446, 'learning_rate': 9.713063957923164e-06, 'epoch': 0.2}
 0: {'loss': 0.6636, 'grad_norm': 2.36026118002753, 'learning_rate': 9.699668174480956e-06, 'epoch': 0.2}
 0: 52:07<8:37:00,  8.78s/it] 20%|█▉        | 867/4399 [1:52:16<8:35:40,  8.76s/it] 20%|█▉        | 868/4399 [1:52:23<7:59:53,  8.15s/it] 20%|█▉        | 869/4399 [1:52:29<7:20:23,  7.49s/it] 20%|█▉        | 870/4399 [1:52:35<7:08:31,  7.29s/it]                                                       20%|█▉        | 870/4399 [1:52:35<7:08:31,  7.29s/it] 20%|█▉        | 871/4399 [1:52:43<7:08:34,  7.29s/it] 20%|█▉        | 872/4399 [1:52:52<7:42:12,  7.86s/it] 20%|█▉        | 873/4399 [1:53:02<8:24:21,  8.58s/it] 20%|█▉        | 874/4399 [1:53:12<8:41:20,  8.87s/it] 20%|█▉        | 875/4399 [1:53:20<8:31:35,  8.71s/it] 20%|█▉        | 876/4399 [1:53:27<8:06:39,  8.29s/it] 20%|█▉        | 877/4399 [1:53:34<7:41:43,  7.87s/it] 20%|█▉        | 878/4399 [1:53:39<6:51:13,  7.01s/it] 20%|█▉        | 879/4399 [1:53:44<6:18:50,  6.46s/it] 20%|██        | 880/4399 [1:53:53<6:55:21,  7.08s/it]                                                       
 0: {'loss': 0.6688, 'grad_norm': 2.5420878315664543, 'learning_rate': 9.685976457860686e-06, 'epoch': 0.2}
 0: 20%|██        | 880/4399 [1:53:53<6:55:21,  7.08s/it] 20%|██        | 881/4399 [1:54:03<7:47:03,  7.97s/it] 20%|██        | 882/4399 [1:54:12<8:03:01,  8.24s/it] 20%|██        | 883/4399 [1:54:22<8:27:10,  8.65s/it] 20%|██        | 884/4399 [1:54:28<7:49:19,  8.01s/it] 20%|██        | 885/4399 [1:54:35<7:30:46,  7.70s/it] 20%|██        | 886/4399 [1:54:40<6:43:01,  6.88s/it] 20%|██        | 887/4399 [1:54:47<6:45:26,  6.93s/it] 20%|██        | 888/4399 [1:54:57<7:31:23,  7.71s/it] 20%|██        | 889/4399 [1:55:08<8:37:37,  8.85s/it] 20%|██        | 890/4399 [1:55:17<8:34:39,  8.80s/it]                                                       20%|██        | 890/4399 [1:55:17<8:34:39,  8.80s/it] 20%|██        | 891/4399 [1:55:26<8:47:26,  9.02s/it] 20%|██        | 892/4399 [1:55:34<8:19:48,  8.55s/it] 20%|██        | 893/4399 [1:55:41<7:50:18,  8.05s/it] 20%|██        | 894/4399 [1:55:48<7:30:23,  7.71s/it] 20%|██        | 895/
 0: {'loss': 0.6536, 'grad_norm': 1.9753831556637127, 'learning_rate': 9.671989670215395e-06, 'epoch': 0.2}
 0: 4399 [1:55:54<7:03:12,  7.25s/it] 20%|██        | 896/4399 [1:56:02<7:29:36,  7.70s/it] 20%|██        | 897/4399 [1:56:12<8:03:47,  8.29s/it] 20%|██        | 898/4399 [1:56:22<8:27:41,  8.70s/it] 20%|██        | 899/4399 [1:56:30<8:23:32,  8.63s/it] 20%|██        | 900/4399 [1:56:38<8:02:55,  8.28s/it]                                                       20%|██        | 900/4399 [1:56:38<8:02:55,  8.28s/it] 20%|██        | 901/4399 [1:56:44<7:21:03,  7.57s/it] 21%|██        | 902/4399 [1:56:49<6:35:46,  6.79s/it] 21%|██        | 903/4399 [1:56:55<6:24:04,  6.59s/it] 21%|██        | 904/4399 [1:57:03<7:01:50,  7.24s/it] 21%|██        | 905/4399 [1:57:14<7:56:06,  8.18s/it] 21%|██        | 906/4399 [1:57:22<7:53:15,  8.13s/it] 21%|██        | 907/4399 [1:57:31<8:18:44,  8.57s/it] 21%|██        | 908/4399 [1:57:39<7:59:54,  8.25s/it] 21%|██        | 909/4399 [1:57:46<7:35:07,  7.82s/it] 21%|██        | 910/4399 [1:57:52<7:02:08,  
 0: {'loss': 0.6501, 'grad_norm': 1.8448419281619823, 'learning_rate': 9.657708692278443e-06, 'epoch': 0.21}
 0: {'loss': 0.6627, 'grad_norm': 1.977511041008867, 'learning_rate': 9.643134423308036e-06, 'epoch': 0.21}
 0: 7.26s/it]                                                       21%|██        | 910/4399 [1:57:52<7:02:08,  7.26s/it] 21%|██        | 911/4399 [1:57:59<6:58:22,  7.20s/it] 21%|██        | 912/4399 [1:58:08<7:42:02,  7.95s/it] 21%|██        | 913/4399 [1:58:21<9:06:23,  9.40s/it] 21%|██        | 914/4399 [1:58:29<8:29:51,  8.78s/it] 21%|██        | 915/4399 [1:58:39<8:51:38,  9.16s/it] 21%|██        | 916/4399 [1:58:44<7:49:12,  8.08s/it] 21%|██        | 917/4399 [1:58:50<7:15:03,  7.50s/it] 21%|██        | 918/4399 [1:58:56<6:47:51,  7.03s/it] 21%|██        | 919/4399 [1:59:02<6:32:19,  6.76s/it] 21%|██        | 920/4399 [1:59:11<7:07:35,  7.37s/it]                                                       21%|██        | 920/4399 [1:59:11<7:07:35,  7.37s/it] 21%|██        | 921/4399 [1:59:23<8:16:01,  8.56s/it] 21%|██        | 922/4399 [1:59:31<8:11:14,  8.48s/it] 21%|██        | 923/4399 [1:59:40<8:23:48,  8.70s/it] 21%|██      
 0: {'loss': 0.6549, 'grad_norm': 2.1280035172745753, 'learning_rate': 9.62826778103061e-06, 'epoch': 0.21}
 0:   | 924/4399 [1:59:47<7:48:44,  8.09s/it] 21%|██        | 925/4399 [1:59:53<7:18:59,  7.58s/it] 21%|██        | 926/4399 [1:59:59<6:50:07,  7.09s/it] 21%|██        | 927/4399 [2:00:05<6:33:24,  6.80s/it] 21%|██        | 928/4399 [2:00:14<7:13:56,  7.50s/it] 21%|██        | 929/4399 [2:00:26<8:21:51,  8.68s/it] 21%|██        | 930/4399 [2:00:34<8:11:04,  8.49s/it]                                                       21%|██        | 930/4399 [2:00:34<8:11:04,  8.49s/it] 21%|██        | 931/4399 [2:00:42<8:10:00,  8.48s/it] 21%|██        | 932/4399 [2:00:49<7:36:55,  7.91s/it] 21%|██        | 933/4399 [2:00:56<7:26:38,  7.73s/it] 21%|██        | 934/4399 [2:01:01<6:39:04,  6.91s/it] 21%|██▏       | 935/4399 [2:01:08<6:41:03,  6.95s/it] 21%|██▏       | 936/4399 [2:01:17<7:14:51,  7.53s/it] 21%|██▏       | 937/4399 [2:01:28<8:07:43,  8.45s/it] 21%|██▏       | 938/4399 [2:01:38<8:33:59,  8.91s/it] 21%|██▏       | 939/4399 [
 0: {'loss': 0.661, 'grad_norm': 2.1216980645127914, 'learning_rate': 9.613109701583047e-06, 'epoch': 0.21}
 0: {'loss': 0.6396, 'grad_norm': 2.0073839077724602, 'learning_rate': 9.597661139453718e-06, 'epoch': 0.22}
 0: 2:01:48<8:51:04,  9.21s/it] 21%|██▏       | 940/4399 [2:01:55<8:26:18,  8.78s/it]                                                       21%|██▏       | 940/4399 [2:01:55<8:26:18,  8.78s/it] 21%|██▏       | 941/4399 [2:02:01<7:40:18,  7.99s/it] 21%|██▏       | 942/4399 [2:02:08<7:20:38,  7.65s/it] 21%|██▏       | 943/4399 [2:02:14<6:53:55,  7.19s/it] 21%|██▏       | 944/4399 [2:02:24<7:33:37,  7.88s/it] 21%|██▏       | 945/4399 [2:02:35<8:21:47,  8.72s/it] 22%|██▏       | 946/4399 [2:02:45<8:49:42,  9.20s/it] 22%|██▏       | 947/4399 [2:02:54<8:41:12,  9.06s/it] 22%|██▏       | 948/4399 [2:03:02<8:22:00,  8.73s/it] 22%|██▏       | 949/4399 [2:03:09<7:58:08,  8.32s/it] 22%|██▏       | 950/4399 [2:03:15<7:17:16,  7.61s/it]                                                       22%|██▏       | 950/4399 [2:03:15<7:17:16,  7.61s/it] 22%|██▏       | 951/4399 [2:03:22<7:04:51,  7.39s/it] 22%|██▏       | 952/439
 0: {'loss': 0.6432, 'grad_norm': 2.924945973672073, 'learning_rate': 9.581923067422384e-06, 'epoch': 0.22}
 0: 9 [2:03:31<7:31:54,  7.87s/it] 22%|██▏       | 953/4399 [2:03:41<8:15:28,  8.63s/it] 22%|██▏       | 954/4399 [2:03:50<8:14:59,  8.62s/it] 22%|██▏       | 955/4399 [2:03:58<8:14:19,  8.61s/it] 22%|██▏       | 956/4399 [2:04:07<8:14:45,  8.62s/it] 22%|██▏       | 957/4399 [2:04:14<7:44:47,  8.10s/it] 22%|██▏       | 958/4399 [2:04:21<7:23:33,  7.73s/it] 22%|██▏       | 959/4399 [2:04:26<6:36:17,  6.91s/it] 22%|██▏       | 960/4399 [2:04:35<7:11:25,  7.53s/it]                                                       22%|██▏       | 960/4399 [2:04:35<7:11:25,  7.53s/it] 22%|██▏       | 961/4399 [2:04:46<8:16:19,  8.66s/it] 22%|██▏       | 962/4399 [2:04:54<8:07:03,  8.50s/it] 22%|██▏       | 963/4399 [2:05:02<8:00:03,  8.38s/it] 22%|██▏       | 964/4399 [2:05:11<7:58:06,  8.35s/it] 22%|██▏       | 965/4399 [2:05:17<7:22:12,  7.73s/it] 22%|██▏       | 966/4399 [2:05:23<6:51:27,  7.19s/it] 22%|██▏       |
 0: {'loss': 0.649, 'grad_norm': 2.0761142392019454, 'learning_rate': 9.565896476498944e-06, 'epoch': 0.22}
 0: {'loss': 0.6407, 'grad_norm': 2.3246999008095948, 'learning_rate': 9.549582375861024e-06, 'epoch': 0.22}
 0:  967/4399 [2:05:29<6:30:06,  6.82s/it] 22%|██▏       | 968/4399 [2:05:38<7:05:27,  7.44s/it] 22%|██▏       | 969/4399 [2:05:50<8:29:31,  8.91s/it] 22%|██▏       | 970/4399 [2:05:59<8:33:01,  8.98s/it]                                                       22%|██▏       | 970/4399 [2:05:59<8:33:01,  8.98s/it] 22%|██▏       | 971/4399 [2:06:08<8:36:51,  9.05s/it] 22%|██▏       | 972/4399 [2:06:15<7:48:00,  8.19s/it] 22%|██▏       | 973/4399 [2:06:19<6:52:45,  7.23s/it] 22%|██▏       | 974/4399 [2:06:25<6:30:04,  6.83s/it] 22%|██▏       | 975/4399 [2:06:32<6:32:50,  6.88s/it] 22%|██▏       | 976/4399 [2:06:41<6:59:50,  7.36s/it] 22%|██▏       | 977/4399 [2:06:52<8:05:24,  8.51s/it] 22%|██▏       | 978/4399 [2:07:01<8:06:05,  8.53s/it] 22%|██▏       | 979/4399 [2:07:09<8:11:20,  8.62s/it] 22%|██▏       | 980/4399 [2:07:17<7:51:22,  8.27s/it]                                                       22%|██▏     
 0: {'loss': 0.6317, 'grad_norm': 2.767911244488843, 'learning_rate': 9.532981792790441e-06, 'epoch': 0.23}
 0:   | 980/4399 [2:07:17<7:51:22,  8.27s/it] 22%|██▏       | 981/4399 [2:07:23<7:17:17,  7.68s/it] 22%|██▏       | 982/4399 [2:07:30<7:04:56,  7.46s/it] 22%|██▏       | 983/4399 [2:07:37<6:54:26,  7.28s/it] 22%|██▏       | 984/4399 [2:07:47<7:42:00,  8.12s/it] 22%|██▏       | 985/4399 [2:07:57<8:17:44,  8.75s/it] 22%|██▏       | 986/4399 [2:08:07<8:31:39,  8.99s/it] 22%|██▏       | 987/4399 [2:08:15<8:23:43,  8.86s/it] 22%|██▏       | 988/4399 [2:08:23<8:04:25,  8.52s/it] 22%|██▏       | 989/4399 [2:08:29<7:10:14,  7.57s/it] 23%|██▎       | 990/4399 [2:08:35<6:58:38,  7.37s/it]                                                       23%|██▎       | 990/4399 [2:08:35<6:58:38,  7.37s/it] 23%|██▎       | 991/4399 [2:08:41<6:34:07,  6.94s/it] 23%|██▎       | 992/4399 [2:08:51<7:18:33,  7.72s/it] 23%|██▎       | 993/4399 [2:09:01<7:59:30,  8.45s/it] 23%|██▎       | 994/4399 [2:09:11<8:17:15,  8.76s/it] 23%|██
 0: {'loss': 0.6577, 'grad_norm': 2.2800646726783684, 'learning_rate': 9.516095772608507e-06, 'epoch': 0.23}
 0: ▎       | 995/4399 [2:09:18<7:55:57,  8.39s/it] 23%|██▎       | 996/4399 [2:09:25<7:36:37,  8.05s/it] 23%|██▎       | 997/4399 [2:09:33<7:23:46,  7.83s/it] 23%|██▎       | 998/4399 [2:09:38<6:34:56,  6.97s/it] 23%|██▎       | 999/4399 [2:09:43<6:01:14,  6.37s/it] 23%|██▎       | 1000/4399 [2:09:52<6:55:00,  7.33s/it]                                                        23%|██▎       | 1000/4399 [2:09:52<6:55:00,  7.33s/it][INFO|trainer.py:3984] 2025-06-27 23:14:20,610 >> Saving model checkpoint to /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000
 0: [INFO|configuration_utils.py:419] 2025-06-27 23:14:20,617 >> Configuration saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/config.json
 0: [INFO|configuration_utils.py:911] 2025-06-27 23:14:20,619 >> Configuration saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/generation_config.json
 0: [INFO|modeling_utils.py:3580] 2025-06-27 23:14:27,477 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 4 checkpoint shards. You can find where each parameters has been saved in the index located at /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/model.safetensors.index.json.
 0: [INFO|tokenization_utils_base.py:2510] 2025-06-27 23:14:27,484 >> tokenizer config file saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/tokenizer_config.json
 0: [INFO|tokenization_utils_base.py:2519] 2025-06-27 23:14:27,808 >> Special tokens file saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/special_tokens_map.json
 0: [2025-06-27 23:14:27,967] [INFO] [logging.py:107:log_dist] [Rank 0] [Torch] Checkpoint global_step1000 is about to be saved!
25: [2025-06-27 23:14:27,978] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_100_mp_rank_00_model_states.pt...
 3: [2025-06-27 23:14:27,978] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_12_mp_rank_00_model_states.pt...
12: [2025-06-27 23:14:27,978] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_48_mp_rank_00_model_states.pt...
 1: [2025-06-27 23:14:27,978] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_4_mp_rank_00_model_states.pt...
19: [2025-06-27 23:14:27,978] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_76_mp_rank_00_model_states.pt...
22: [2025-06-27 23:14:27,978] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_88_mp_rank_00_model_states.pt...
15: [2025-06-27 23:14:27,978] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_60_mp_rank_00_model_states.pt...
23: [2025-06-27 23:14:27,978] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_92_mp_rank_00_model_states.pt...
28: [2025-06-27 23:14:27,978] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_112_mp_rank_00_model_states.pt...
30: [2025-06-27 23:14:27,978] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_120_mp_rank_00_model_states.pt...
24: [2025-06-27 23:14:27,978] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_96_mp_rank_00_model_states.pt...
20: [2025-06-27 23:14:27,978] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_80_mp_rank_00_model_states.pt...
13: [2025-06-27 23:14:27,978] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_52_mp_rank_00_model_states.pt...
16: [2025-06-27 23:14:27,978] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_64_mp_rank_00_model_states.pt...
 5: [2025-06-27 23:14:27,978] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_20_mp_rank_00_model_states.pt...
31: [2025-06-27 23:14:27,978] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_124_mp_rank_00_model_states.pt...
 9: [2025-06-27 23:14:27,978] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_36_mp_rank_00_model_states.pt...
 8: [2025-06-27 23:14:27,978] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_32_mp_rank_00_model_states.pt...
 6: [2025-06-27 23:14:27,978] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_24_mp_rank_00_model_states.pt...
18: [2025-06-27 23:14:27,978] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_72_mp_rank_00_model_states.pt...
10: [2025-06-27 23:14:27,978] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_40_mp_rank_00_model_states.pt...
 2: [2025-06-27 23:14:27,978] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_8_mp_rank_00_model_states.pt...
29: [2025-06-27 23:14:27,978] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_116_mp_rank_00_model_states.pt...
 0: [2025-06-27 23:14:27,978] [INFO] [logging.py:107:log_dist] [Rank 0] Saving model checkpoint: /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_0_mp_rank_00_model_states.pt
14: [2025-06-27 23:14:27,978] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_56_mp_rank_00_model_states.pt...
27: [2025-06-27 23:14:27,978] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_108_mp_rank_00_model_states.pt...
 4: [2025-06-27 23:14:27,978] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_16_mp_rank_00_model_states.pt...
17: [2025-06-27 23:14:27,978] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_68_mp_rank_00_model_states.pt...
 0: [2025-06-27 23:14:27,979] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_0_mp_rank_00_model_states.pt...
 7: [2025-06-27 23:14:27,979] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_28_mp_rank_00_model_states.pt...
21: [2025-06-27 23:14:27,980] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_84_mp_rank_00_model_states.pt...
11: [2025-06-27 23:14:27,980] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_44_mp_rank_00_model_states.pt...
26: [2025-06-27 23:14:27,980] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_104_mp_rank_00_model_states.pt...
25: [2025-06-27 23:14:28,002] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_100_mp_rank_00_model_states.pt.
31: [2025-06-27 23:14:28,010] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_124_mp_rank_00_model_states.pt.
 4: [2025-06-27 23:14:28,013] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_16_mp_rank_00_model_states.pt.
 1: [2025-06-27 23:14:28,013] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_4_mp_rank_00_model_states.pt.
 3: [2025-06-27 23:14:28,015] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_12_mp_rank_00_model_states.pt.
 5: [2025-06-27 23:14:28,015] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_20_mp_rank_00_model_states.pt.
22: [2025-06-27 23:14:28,017] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_88_mp_rank_00_model_states.pt.
 8: [2025-06-27 23:14:28,018] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_32_mp_rank_00_model_states.pt.
 6: [2025-06-27 23:14:28,018] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_24_mp_rank_00_model_states.pt.
12: [2025-06-27 23:14:28,020] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_48_mp_rank_00_model_states.pt.
27: [2025-06-27 23:14:28,021] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_108_mp_rank_00_model_states.pt.
20: [2025-06-27 23:14:28,023] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_80_mp_rank_00_model_states.pt.
15: [2025-06-27 23:14:28,023] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_60_mp_rank_00_model_states.pt.
29: [2025-06-27 23:14:28,024] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_116_mp_rank_00_model_states.pt.
24: [2025-06-27 23:14:28,025] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_96_mp_rank_00_model_states.pt.
 2: [2025-06-27 23:14:28,025] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_8_mp_rank_00_model_states.pt.
13: [2025-06-27 23:14:28,026] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_52_mp_rank_00_model_states.pt.
19: [2025-06-27 23:14:28,027] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_76_mp_rank_00_model_states.pt.
14: [2025-06-27 23:14:28,028] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_56_mp_rank_00_model_states.pt.
30: [2025-06-27 23:14:28,028] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_120_mp_rank_00_model_states.pt.
28: [2025-06-27 23:14:28,030] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_112_mp_rank_00_model_states.pt.
23: [2025-06-27 23:14:28,030] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_92_mp_rank_00_model_states.pt.
18: [2025-06-27 23:14:28,031] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_72_mp_rank_00_model_states.pt.
10: [2025-06-27 23:14:28,031] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_40_mp_rank_00_model_states.pt.
17: [2025-06-27 23:14:28,031] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_68_mp_rank_00_model_states.pt.
16: [2025-06-27 23:14:28,031] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_64_mp_rank_00_model_states.pt.
 9: [2025-06-27 23:14:28,032] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_36_mp_rank_00_model_states.pt.
 7: [2025-06-27 23:14:28,033] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_28_mp_rank_00_model_states.pt.
26: [2025-06-27 23:14:28,033] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_104_mp_rank_00_model_states.pt.
21: [2025-06-27 23:14:28,033] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_84_mp_rank_00_model_states.pt.
11: [2025-06-27 23:14:28,034] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_44_mp_rank_00_model_states.pt.
 0: [2025-06-27 23:14:28,058] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/zero_pp_rank_0_mp_rank_00_model_states.pt.
 0: [2025-06-27 23:14:28,302] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
 1: [2025-06-27 23:14:28,302] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_4_mp_rank_00_optim_states.pt...
 4: [2025-06-27 23:14:28,302] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_16_mp_rank_00_optim_states.pt...
 9: [2025-06-27 23:14:28,302] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_36_mp_rank_00_optim_states.pt...
 8: [2025-06-27 23:14:28,302] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_32_mp_rank_00_optim_states.pt...
10: [2025-06-27 23:14:28,302] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_40_mp_rank_00_optim_states.pt...
 2: [2025-06-27 23:14:28,302] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_8_mp_rank_00_optim_states.pt...
15: [2025-06-27 23:14:28,302] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_60_mp_rank_00_optim_states.pt...
 7: [2025-06-27 23:14:28,302] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_28_mp_rank_00_optim_states.pt...
 3: [2025-06-27 23:14:28,302] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_12_mp_rank_00_optim_states.pt...
 5: [2025-06-27 23:14:28,302] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_20_mp_rank_00_optim_states.pt...
14: [2025-06-27 23:14:28,302] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_56_mp_rank_00_optim_states.pt...
12: [2025-06-27 23:14:28,302] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_48_mp_rank_00_optim_states.pt...
17: [2025-06-27 23:14:28,302] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_68_mp_rank_00_optim_states.pt...
20: [2025-06-27 23:14:28,302] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_80_mp_rank_00_optim_states.pt...
18: [2025-06-27 23:14:28,302] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_72_mp_rank_00_optim_states.pt...
26: [2025-06-27 23:14:28,302] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_104_mp_rank_00_optim_states.pt...
30: [2025-06-27 23:14:28,302] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_120_mp_rank_00_optim_states.pt...
29: [2025-06-27 23:14:28,302] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_116_mp_rank_00_optim_states.pt...
24: [2025-06-27 23:14:28,302] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_96_mp_rank_00_optim_states.pt...
13: [2025-06-27 23:14:28,302] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_52_mp_rank_00_optim_states.pt...
25: [2025-06-27 23:14:28,302] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_100_mp_rank_00_optim_states.pt...
23: [2025-06-27 23:14:28,302] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_92_mp_rank_00_optim_states.pt...
27: [2025-06-27 23:14:28,302] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_108_mp_rank_00_optim_states.pt...
 6: [2025-06-27 23:14:28,302] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_24_mp_rank_00_optim_states.pt...
16: [2025-06-27 23:14:28,302] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_64_mp_rank_00_optim_states.pt...
19: [2025-06-27 23:14:28,302] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_76_mp_rank_00_optim_states.pt...
22: [2025-06-27 23:14:28,302] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_88_mp_rank_00_optim_states.pt...
31: [2025-06-27 23:14:28,302] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_124_mp_rank_00_optim_states.pt...
21: [2025-06-27 23:14:28,302] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_84_mp_rank_00_optim_states.pt...
11: [2025-06-27 23:14:28,302] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_44_mp_rank_00_optim_states.pt...
28: [2025-06-27 23:14:28,302] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_112_mp_rank_00_optim_states.pt...
 0: [2025-06-27 23:14:28,780] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
 0: [2025-06-27 23:14:28,786] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
 8: [2025-06-27 23:14:31,057] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_32_mp_rank_00_optim_states.pt.
 8: [2025-06-27 23:14:31,057] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_32_mp_rank_00_optim_states.pt
15: [2025-06-27 23:14:31,066] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_60_mp_rank_00_optim_states.pt.
15: [2025-06-27 23:14:31,066] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_60_mp_rank_00_optim_states.pt
 6: [2025-06-27 23:14:31,109] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_24_mp_rank_00_optim_states.pt.
 6: [2025-06-27 23:14:31,109] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_24_mp_rank_00_optim_states.pt
 1: [2025-06-27 23:14:31,113] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_4_mp_rank_00_optim_states.pt.
 1: [2025-06-27 23:14:31,113] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_4_mp_rank_00_optim_states.pt
31: [2025-06-27 23:14:31,119] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_124_mp_rank_00_optim_states.pt.
31: [2025-06-27 23:14:31,119] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_124_mp_rank_00_optim_states.pt
25: [2025-06-27 23:14:31,125] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_100_mp_rank_00_optim_states.pt.
25: [2025-06-27 23:14:31,125] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_100_mp_rank_00_optim_states.pt
 7: [2025-06-27 23:14:31,129] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_28_mp_rank_00_optim_states.pt.
 7: [2025-06-27 23:14:31,129] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_28_mp_rank_00_optim_states.pt
 5: [2025-06-27 23:14:31,129] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_20_mp_rank_00_optim_states.pt.
 5: [2025-06-27 23:14:31,129] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_20_mp_rank_00_optim_states.pt
 3: [2025-06-27 23:14:31,131] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_12_mp_rank_00_optim_states.pt.
 3: [2025-06-27 23:14:31,131] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_12_mp_rank_00_optim_states.pt
28: [2025-06-27 23:14:31,133] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_112_mp_rank_00_optim_states.pt.
28: [2025-06-27 23:14:31,133] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_112_mp_rank_00_optim_states.pt
11: [2025-06-27 23:14:31,152] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_44_mp_rank_00_optim_states.pt.
11: [2025-06-27 23:14:31,152] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_44_mp_rank_00_optim_states.pt
22: [2025-06-27 23:14:31,164] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_88_mp_rank_00_optim_states.pt.
22: [2025-06-27 23:14:31,164] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_88_mp_rank_00_optim_states.pt
 9: [2025-06-27 23:14:31,166] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_36_mp_rank_00_optim_states.pt.
 9: [2025-06-27 23:14:31,166] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_36_mp_rank_00_optim_states.pt
16: [2025-06-27 23:14:31,169] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_64_mp_rank_00_optim_states.pt.
16: [2025-06-27 23:14:31,169] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_64_mp_rank_00_optim_states.pt
21: [2025-06-27 23:14:31,177] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_84_mp_rank_00_optim_states.pt.
21: [2025-06-27 23:14:31,178] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_84_mp_rank_00_optim_states.pt
27: [2025-06-27 23:14:31,188] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_108_mp_rank_00_optim_states.pt.
27: [2025-06-27 23:14:31,188] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_108_mp_rank_00_optim_states.pt
12: [2025-06-27 23:14:31,197] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_48_mp_rank_00_optim_states.pt.
12: [2025-06-27 23:14:31,197] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_48_mp_rank_00_optim_states.pt
 2: [2025-06-27 23:14:31,201] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_8_mp_rank_00_optim_states.pt.
 2: [2025-06-27 23:14:31,202] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_8_mp_rank_00_optim_states.pt
26: [2025-06-27 23:14:31,202] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_104_mp_rank_00_optim_states.pt.
26: [2025-06-27 23:14:31,203] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_104_mp_rank_00_optim_states.pt
20: [2025-06-27 23:14:31,204] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_80_mp_rank_00_optim_states.pt.
20: [2025-06-27 23:14:31,204] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_80_mp_rank_00_optim_states.pt
13: [2025-06-27 23:14:31,218] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_52_mp_rank_00_optim_states.pt.
13: [2025-06-27 23:14:31,219] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_52_mp_rank_00_optim_states.pt
 4: [2025-06-27 23:14:31,221] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_16_mp_rank_00_optim_states.pt.
 4: [2025-06-27 23:14:31,221] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_16_mp_rank_00_optim_states.pt
30: [2025-06-27 23:14:31,226] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_120_mp_rank_00_optim_states.pt.
30: [2025-06-27 23:14:31,226] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_120_mp_rank_00_optim_states.pt
18: [2025-06-27 23:14:31,240] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_72_mp_rank_00_optim_states.pt.
18: [2025-06-27 23:14:31,240] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_72_mp_rank_00_optim_states.pt
29: [2025-06-27 23:14:31,245] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_116_mp_rank_00_optim_states.pt.
29: [2025-06-27 23:14:31,245] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_116_mp_rank_00_optim_states.pt
14: [2025-06-27 23:14:31,252] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_56_mp_rank_00_optim_states.pt.
14: [2025-06-27 23:14:31,253] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_56_mp_rank_00_optim_states.pt
17: [2025-06-27 23:14:31,253] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_68_mp_rank_00_optim_states.pt.
17: [2025-06-27 23:14:31,253] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_68_mp_rank_00_optim_states.pt
10: [2025-06-27 23:14:31,144] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_40_mp_rank_00_optim_states.pt.
10: [2025-06-27 23:14:31,145] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_40_mp_rank_00_optim_states.pt
19: [2025-06-27 23:14:31,308] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_76_mp_rank_00_optim_states.pt.
19: [2025-06-27 23:14:31,308] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_76_mp_rank_00_optim_states.pt
24: [2025-06-27 23:14:31,398] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_96_mp_rank_00_optim_states.pt.
24: [2025-06-27 23:14:31,398] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_96_mp_rank_00_optim_states.pt
23: [2025-06-27 23:14:31,981] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_92_mp_rank_00_optim_states.pt.
23: [2025-06-27 23:14:31,981] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/global_step1000/bf16_zero_pp_rank_92_mp_rank_00_optim_states.pt
14: [2025-06-27 23:14:33,767] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1000 is ready now!
 9: [2025-06-27 23:14:33,767] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1000 is ready now!
24: [2025-06-27 23:14:33,767] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1000 is ready now!
20: [2025-06-27 23:14:33,767] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1000 is ready now!
12: [2025-06-27 23:14:33,767] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1000 is ready now!
 7: [2025-06-27 23:14:33,767] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1000 is ready now!
31: [2025-06-27 23:14:33,767] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1000 is ready now!
17: [2025-06-27 23:14:33,767] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1000 is ready now!
 1: [2025-06-27 23:14:33,768] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1000 is ready now!
19: [2025-06-27 23:14:33,768] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1000 is ready now!
30: [2025-06-27 23:14:33,768] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1000 is ready now!
 6: [2025-06-27 23:14:33,768] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1000 is ready now!
18: [2025-06-27 23:14:33,768] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1000 is ready now!
22: [2025-06-27 23:14:33,768] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1000 is ready now!
29: [2025-06-27 23:14:33,768] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1000 is ready now!
27: [2025-06-27 23:14:33,768] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1000 is ready now!
 2: [2025-06-27 23:14:33,768] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1000 is ready now!
 4: [2025-06-27 23:14:33,768] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1000 is ready now!
15: [2025-06-27 23:14:33,768] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1000 is ready now!
13: [2025-06-27 23:14:33,768] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1000 is ready now!
23: [2025-06-27 23:14:33,768] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1000 is ready now!
16: [2025-06-27 23:14:33,768] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1000 is ready now!
 3: [2025-06-27 23:14:33,768] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1000 is ready now!
 5: [2025-06-27 23:14:33,768] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1000 is ready now!
10: [2025-06-27 23:14:33,768] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1000 is ready now!
25: [2025-06-27 23:14:33,768] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1000 is ready now!
28: [2025-06-27 23:14:33,768] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1000 is ready now!
 8: [2025-06-27 23:14:33,768] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1000 is ready now!
11: [2025-06-27 23:14:33,769] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1000 is ready now!
26: [2025-06-27 23:14:33,770] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1000 is ready now!
 0: [2025-06-27 23:14:33,770] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1000 is ready now!
21: [2025-06-27 23:14:33,770] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1000 is ready now!
 0: [INFO|image_processing_base.py:260] 2025-06-27 23:14:33,814 >> Image processor saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/preprocessor_config.json
 0: [INFO|tokenization_utils_base.py:2510] 2025-06-27 23:14:33,816 >> tokenizer config file saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/tokenizer_config.json
 0: [INFO|tokenization_utils_base.py:2519] 2025-06-27 23:14:33,965 >> Special tokens file saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/special_tokens_map.json
 0: [INFO|processing_utils.py:648] 2025-06-27 23:14:34,530 >> chat template saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1000/chat_template.json
 0:  23%|██▎       | 1001/4399 [2:11:15<28:26:33, 30.13s/it] 23%|██▎       | 1002/4399 [2:11:24<22:12:08, 23.53s/it] 23%|██▎       | 1003/4399 [2:11:34<18:26:26, 19.55s/it] 23%|██▎       | 1004/4399 [2:11:41<14:49:17, 15.72s/it] 23%|██▎       | 1005/4399 [2:11:48<12:30:37, 13.27s/it]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
 0:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
 0: {'loss': 0.6482, 'grad_norm': 1.8848441494967048, 'learning_rate': 9.498925378610209e-06, 'epoch': 0.23}
 0:  23%|██▎       | 1006/4399 [2:11:54<10:28:28, 11.11s/it] 23%|██▎       | 1007/4399 [2:12:00<9:02:19,  9.59s/it]  23%|██▎       | 1008/4399 [2:12:10<8:56:10,  9.49s/it] 23%|██▎       | 1009/4399 [2:12:21<9:25:38, 10.01s/it] 23%|██▎       | 1010/4399 [2:12:30<9:08:01,  9.70s/it]                                                        23%|██▎       | 1010/4399 [2:12:30<9:08:01,  9.70s/it] 23%|██▎       | 1011/4399 [2:12:40<9:23:00,  9.97s/it] 23%|██▎       | 1012/4399 [2:12:48<8:35:24,  9.13s/it] 23%|██▎       | 1013/4399 [2:12:55<8:07:11,  8.63s/it] 23%|██▎       | 1014/4399 [2:13:02<7:38:36,  8.13s/it] 23%|██▎       | 1015/4399 [2:13:09<7:22:44,  7.85s/it] 23%|██▎       | 1016/4399 [2:13:19<7:57:42,  8.47s/it] 23%|██▎       | 1017/4399 [2:13:29<8:23:56,  8.94s/it] 23%|██▎       | 1018/4399 [2:13:39<8:41:29,  9.25s/it] 23%|██▎       | 1019/4399 [2:13:50<9:02:29,  9.63s/it] 23%|██▎       | 1020/4399 [
 0: {'loss': 0.6499, 'grad_norm': 2.076870277622996, 'learning_rate': 9.481471691997257e-06, 'epoch': 0.23}
 0: {'loss': 0.6546, 'grad_norm': 2.9746893497425417, 'learning_rate': 9.463735811810002e-06, 'epoch': 0.23}
 0: 2:13:58<8:35:03,  9.15s/it]                                                        23%|██▎       | 1020/4399 [2:13:58<8:35:03,  9.15s/it] 23%|██▎       | 1021/4399 [2:14:05<8:08:50,  8.68s/it] 23%|██▎       | 1022/4399 [2:14:12<7:40:57,  8.19s/it] 23%|██▎       | 1023/4399 [2:14:19<7:08:44,  7.62s/it] 23%|██▎       | 1024/4399 [2:14:27<7:20:08,  7.82s/it] 23%|██▎       | 1025/4399 [2:14:38<8:20:22,  8.90s/it] 23%|██▎       | 1026/4399 [2:14:49<8:57:36,  9.56s/it] 23%|██▎       | 1027/4399 [2:14:58<8:38:12,  9.22s/it] 23%|██▎       | 1028/4399 [2:15:04<7:42:39,  8.23s/it] 23%|██▎       | 1029/4399 [2:15:10<7:15:15,  7.75s/it] 23%|██▎       | 1030/4399 [2:15:15<6:29:33,  6.94s/it]                                                        23%|██▎       | 1030/4399 [2:15:15<6:29:33,  6.94s/it] 23%|██▎       | 1031/4399 [2:15:21<6:00:37,  6.42s/it] 23%|██▎       | 1032/4399 [2:15:30<6:48:56,  7.29s/it] 23%|██▎
 0: {'loss': 0.6431, 'grad_norm': 2.1196339532672326, 'learning_rate': 9.445718854858221e-06, 'epoch': 0.24}
 0:        | 1033/4399 [2:15:41<7:48:14,  8.35s/it] 24%|██▎       | 1034/4399 [2:15:52<8:32:12,  9.13s/it] 24%|██▎       | 1035/4399 [2:16:00<8:22:38,  8.97s/it] 24%|██▎       | 1036/4399 [2:16:07<7:52:06,  8.42s/it] 24%|██▎       | 1037/4399 [2:16:13<7:05:27,  7.59s/it] 24%|██▎       | 1038/4399 [2:16:19<6:39:17,  7.13s/it] 24%|██▎       | 1039/4399 [2:16:25<6:23:25,  6.85s/it] 24%|██▎       | 1040/4399 [2:16:35<7:10:23,  7.69s/it]                                                        24%|██▎       | 1040/4399 [2:16:35<7:10:23,  7.69s/it] 24%|██▎       | 1041/4399 [2:16:45<7:50:26,  8.41s/it] 24%|██▎       | 1042/4399 [2:16:55<8:12:17,  8.80s/it] 24%|██▎       | 1043/4399 [2:17:04<8:13:57,  8.83s/it] 24%|██▎       | 1044/4399 [2:17:11<7:44:37,  8.31s/it] 24%|██▍       | 1045/4399 [2:17:16<6:57:49,  7.47s/it] 24%|██▍       | 1046/4399 [2:17:22<6:34:25,  7.06s/it] 24%|██▍       | 1047/4399 [2:17:28<6:03:23, 
 0: {'loss': 0.6553, 'grad_norm': 2.2324581758703625, 'learning_rate': 9.42742195565081e-06, 'epoch': 0.24}
 0: {'loss': 0.6594, 'grad_norm': 1.8828700710719768, 'learning_rate': 9.40884626632433e-06, 'epoch': 0.24}
 0:  6.50s/it] 24%|██▍       | 1048/4399 [2:17:38<7:03:35,  7.58s/it] 24%|██▍       | 1049/4399 [2:17:48<7:45:55,  8.34s/it] 24%|██▍       | 1050/4399 [2:17:59<8:33:06,  9.19s/it]                                                        24%|██▍       | 1050/4399 [2:17:59<8:33:06,  9.19s/it] 24%|██▍       | 1051/4399 [2:18:07<8:14:19,  8.86s/it] 24%|██▍       | 1052/4399 [2:18:13<7:31:23,  8.09s/it] 24%|██▍       | 1053/4399 [2:18:21<7:23:44,  7.96s/it] 24%|██▍       | 1054/4399 [2:18:27<6:50:50,  7.37s/it] 24%|██▍       | 1055/4399 [2:18:33<6:33:06,  7.05s/it] 24%|██▍       | 1056/4399 [2:18:43<7:12:18,  7.76s/it] 24%|██▍       | 1057/4399 [2:18:53<8:02:09,  8.66s/it] 24%|██▍       | 1058/4399 [2:19:05<8:42:57,  9.39s/it] 24%|██▍       | 1059/4399 [2:19:14<8:35:27,  9.26s/it] 24%|██▍       | 1060/4399 [2:19:21<8:03:53,  8.70s/it]                                                        24%|██▍       | 1060/439
 0: {'loss': 0.6637, 'grad_norm': 3.9909815776633444, 'learning_rate': 9.389992956570463e-06, 'epoch': 0.24}
 0: 9 [2:19:21<8:03:53,  8.70s/it] 24%|██▍       | 1061/4399 [2:19:28<7:44:18,  8.35s/it] 24%|██▍       | 1062/4399 [2:19:34<7:03:59,  7.62s/it] 24%|██▍       | 1063/4399 [2:19:41<6:41:04,  7.21s/it] 24%|██▍       | 1064/4399 [2:19:51<7:28:11,  8.06s/it] 24%|██▍       | 1065/4399 [2:19:59<7:39:31,  8.27s/it] 24%|██▍       | 1066/4399 [2:20:09<8:02:08,  8.68s/it] 24%|██▍       | 1067/4399 [2:20:19<8:18:02,  8.97s/it] 24%|██▍       | 1068/4399 [2:20:26<7:52:18,  8.51s/it] 24%|██▍       | 1069/4399 [2:20:32<7:04:15,  7.64s/it] 24%|██▍       | 1070/4399 [2:20:38<6:36:28,  7.15s/it]                                                        24%|██▍       | 1070/4399 [2:20:38<6:36:28,  7.15s/it] 24%|██▍       | 1071/4399 [2:20:45<6:39:03,  7.19s/it] 24%|██▍       | 1072/4399 [2:20:55<7:21:47,  7.97s/it] 24%|██▍       | 1073/4399 [2:21:06<8:16:49,  8.96s/it] 24%|██▍       | 1074/4399 [2:21:18<8:57:36,  9.70s/it] 24%|
 0: {'loss': 0.6509, 'grad_norm': 2.1259685407527815, 'learning_rate': 9.370863213562359e-06, 'epoch': 0.25}
 0: █▍       | 1075/4399 [2:21:27<8:59:47,  9.74s/it] 24%|██▍       | 1076/4399 [2:21:34<8:11:17,  8.87s/it] 24%|██▍       | 1077/4399 [2:21:42<7:53:47,  8.56s/it] 25%|██▍       | 1078/4399 [2:21:48<7:12:05,  7.81s/it] 25%|██▍       | 1079/4399 [2:21:54<6:42:22,  7.27s/it] 25%|██▍       | 1080/4399 [2:22:03<7:06:06,  7.70s/it]                                                        25%|██▍       | 1080/4399 [2:22:03<7:06:06,  7.70s/it] 25%|██▍       | 1081/4399 [2:22:13<7:44:30,  8.40s/it] 25%|██▍       | 1082/4399 [2:22:25<8:38:22,  9.38s/it] 25%|██▍       | 1083/4399 [2:22:33<8:31:24,  9.25s/it] 25%|██▍       | 1084/4399 [2:22:40<7:47:18,  8.46s/it] 25%|██▍       | 1085/4399 [2:22:46<7:04:44,  7.69s/it] 25%|██▍       | 1086/4399 [2:22:53<6:53:14,  7.48s/it] 25%|██▍       | 1087/4399 [2:23:00<6:47:49,  7.39s/it] 25%|██▍       | 1088/4399 [2:23:09<7:19:23,  7.96s/it] 25%|██▍       | 1089/4399 [2:23:20<8
 0: {'loss': 0.6458, 'grad_norm': 2.391737667211664, 'learning_rate': 9.35145824187988e-06, 'epoch': 0.25}
 0: {'loss': 0.6418, 'grad_norm': 1.7669660761069317, 'learning_rate': 9.33177926343375e-06, 'epoch': 0.25}
 0: :02:50,  8.75s/it] 25%|██▍       | 1090/4399 [2:23:30<8:28:50,  9.23s/it]                                                        25%|██▍       | 1090/4399 [2:23:30<8:28:50,  9.23s/it] 25%|██▍       | 1091/4399 [2:23:38<8:09:52,  8.89s/it] 25%|██▍       | 1092/4399 [2:23:45<7:31:30,  8.19s/it] 25%|██▍       | 1093/4399 [2:23:52<7:08:16,  7.77s/it] 25%|██▍       | 1094/4399 [2:23:59<6:57:38,  7.58s/it] 25%|██▍       | 1095/4399 [2:24:05<6:31:50,  7.12s/it] 25%|██▍       | 1096/4399 [2:24:14<7:05:14,  7.72s/it] 25%|██▍       | 1097/4399 [2:24:23<7:19:40,  7.99s/it] 25%|██▍       | 1098/4399 [2:24:34<8:19:10,  9.07s/it] 25%|██▍       | 1099/4399 [2:24:45<8:37:21,  9.41s/it] 25%|██▌       | 1100/4399 [2:24:52<8:11:18,  8.94s/it]                                                        25%|██▌       | 1100/4399 [2:24:52<8:11:18,  8.94s/it] 25%|██▌       | 1101/4399 [2:25:00<7:54:12,  8.63s/it] 25%|██▌       | 
 0: {'loss': 0.645, 'grad_norm': 4.263553377864458, 'learning_rate': 9.311827517388614e-06, 'epoch': 0.25}
 0: 1102/4399 [2:25:07<7:28:01,  8.15s/it] 25%|██▌       | 1103/4399 [2:25:14<7:09:03,  7.81s/it] 25%|██▌       | 1104/4399 [2:25:23<7:24:43,  8.10s/it] 25%|██▌       | 1105/4399 [2:25:34<8:17:11,  9.06s/it] 25%|██▌       | 1106/4399 [2:25:46<8:52:15,  9.70s/it] 25%|██▌       | 1107/4399 [2:25:55<8:50:25,  9.67s/it] 25%|██▌       | 1108/4399 [2:26:02<8:08:31,  8.91s/it] 25%|██▌       | 1109/4399 [2:26:10<7:39:57,  8.39s/it] 25%|██▌       | 1110/4399 [2:26:17<7:17:24,  7.98s/it]                                                        25%|██▌       | 1110/4399 [2:26:17<7:17:24,  7.98s/it] 25%|██▌       | 1111/4399 [2:26:23<6:47:24,  7.43s/it] 25%|██▌       | 1112/4399 [2:26:31<7:08:57,  7.83s/it] 25%|██▌       | 1113/4399 [2:26:42<7:54:01,  8.66s/it] 25%|██▌       | 1114/4399 [2:26:53<8:31:04,  9.33s/it] 25%|██▌       | 1115/4399 [2:27:02<8:18:05,  9.10s/it] 25%|██▌       | 1116/4399 [2:27:09<7:46:12,  8.52s/it
 0: {'loss': 0.6312, 'grad_norm': 1.5864142347831722, 'learning_rate': 9.291604260085002e-06, 'epoch': 0.25}
 0: ] 25%|██▌       | 1117/4399 [2:27:15<7:14:05,  7.94s/it] 25%|██▌       | 1118/4399 [2:27:21<6:40:47,  7.33s/it] 25%|██▌       | 1119/4399 [2:27:26<6:05:50,  6.69s/it] 25%|██▌       | 1120/4399 [2:27:35<6:36:33,  7.26s/it]                                                        25%|██▌       | 1120/4399 [2:27:35<6:36:33,  7.26s/it] 25%|██▌       | 1121/4399 [2:27:45<7:22:28,  8.10s/it] 26%|██▌       | 1122/4399 [2:27:57<8:23:09,  9.21s/it] 26%|██▌       | 1123/4399 [2:28:06<8:14:42,  9.06s/it] 26%|██▌       | 1124/4399 [2:28:13<7:46:36,  8.55s/it] 26%|██▌       | 1125/4399 [2:28:20<7:21:20,  8.09s/it] 26%|██▌       | 1126/4399 [2:28:27<7:06:58,  7.83s/it] 26%|██▌       | 1127/4399 [2:28:33<6:40:33,  7.35s/it] 26%|██▌       | 1128/4399 [2:28:42<6:57:36,  7.66s/it] 26%|██▌       | 1129/4399 [2:28:52<7:47:35,  8.58s/it] 26%|██▌       | 1130/4399 [2:29:03<8:20:27,  9.19s/it]                                   
 0: {'loss': 0.6472, 'grad_norm': 1.9685074895930559, 'learning_rate': 9.271110764960224e-06, 'epoch': 0.26}
 0: {'loss': 0.6342, 'grad_norm': 2.1943719772197117, 'learning_rate': 9.250348322468187e-06, 'epoch': 0.26}
 0:                      26%|██▌       | 1130/4399 [2:29:03<8:20:27,  9.19s/it] 26%|██▌       | 1131/4399 [2:29:12<8:21:20,  9.20s/it] 26%|██▌       | 1132/4399 [2:29:19<7:41:56,  8.48s/it] 26%|██▌       | 1133/4399 [2:29:27<7:33:22,  8.33s/it] 26%|██▌       | 1134/4399 [2:29:33<6:55:38,  7.64s/it] 26%|██▌       | 1135/4399 [2:29:40<6:46:49,  7.48s/it] 26%|██▌       | 1136/4399 [2:29:49<7:11:45,  7.94s/it] 26%|██▌       | 1137/4399 [2:29:59<7:49:20,  8.63s/it] 26%|██▌       | 1138/4399 [2:30:12<8:55:13,  9.85s/it] 26%|██▌       | 1139/4399 [2:30:21<8:40:59,  9.59s/it] 26%|██▌       | 1140/4399 [2:30:29<8:17:24,  9.16s/it]                                                        26%|██▌       | 1140/4399 [2:30:29<8:17:24,  9.16s/it] 26%|██▌       | 1141/4399 [2:30:36<7:38:18,  8.44s/it] 26%|██▌       | 1142/4399 [2:30:42<7:01:47,  7.77s/it] 26%|██▌       | 1143/4399 [2:30:47<6:20:06,  7.00s/it] 26%|██▌ 
 0: {'loss': 0.64, 'grad_norm': 1.9226595779754259, 'learning_rate': 9.229318239998126e-06, 'epoch': 0.26}
 0:       | 1144/4399 [2:30:55<6:34:04,  7.26s/it] 26%|██▌       | 1145/4399 [2:31:06<7:22:51,  8.17s/it] 26%|██▌       | 1146/4399 [2:31:17<8:19:08,  9.21s/it] 26%|██▌       | 1147/4399 [2:31:26<8:13:14,  9.10s/it] 26%|██▌       | 1148/4399 [2:31:33<7:41:39,  8.52s/it] 26%|██▌       | 1149/4399 [2:31:40<7:09:30,  7.93s/it] 26%|██▌       | 1150/4399 [2:31:46<6:39:49,  7.38s/it]                                                        26%|██▌       | 1150/4399 [2:31:46<6:39:49,  7.38s/it] 26%|██▌       | 1151/4399 [2:31:52<6:20:22,  7.03s/it] 26%|██▌       | 1152/4399 [2:32:00<6:37:34,  7.35s/it] 26%|██▌       | 1153/4399 [2:32:10<7:17:25,  8.09s/it] 26%|██▌       | 1154/4399 [2:32:23<8:31:05,  9.45s/it] 26%|██▋       | 1155/4399 [2:32:32<8:25:26,  9.35s/it] 26%|██▋       | 1156/4399 [2:32:39<7:51:26,  8.72s/it] 26%|██▋       | 1157/4399 [2:32:46<7:19:53,  8.14s/it] 26%|██▋       | 1158/4399 [2:32:51<6:32:55,  
 0: {'loss': 0.6347, 'grad_norm': 2.539273983132258, 'learning_rate': 9.208021841792288e-06, 'epoch': 0.26}
 0: {'loss': 0.6357, 'grad_norm': 2.50984249250322, 'learning_rate': 9.186460468862541e-06, 'epoch': 0.27}
 0: 7.27s/it] 26%|██▋       | 1159/4399 [2:32:57<6:13:55,  6.92s/it] 26%|██▋       | 1160/4399 [2:33:06<6:42:17,  7.45s/it]                                                        26%|██▋       | 1160/4399 [2:33:06<6:42:17,  7.45s/it] 26%|██▋       | 1161/4399 [2:33:16<7:17:58,  8.12s/it] 26%|██▋       | 1162/4399 [2:33:27<8:05:51,  9.01s/it] 26%|██▋       | 1163/4399 [2:33:35<7:54:27,  8.80s/it] 26%|██▋       | 1164/4399 [2:33:42<7:25:33,  8.26s/it] 26%|██▋       | 1165/4399 [2:33:50<7:15:24,  8.08s/it] 27%|██▋       | 1166/4399 [2:33:57<6:58:11,  7.76s/it] 27%|██▋       | 1167/4399 [2:34:03<6:30:24,  7.25s/it] 27%|██▋       | 1168/4399 [2:34:11<6:46:52,  7.56s/it] 27%|██▋       | 1169/4399 [2:34:21<7:23:19,  8.24s/it] 27%|██▋       | 1170/4399 [2:34:31<8:02:04,  8.96s/it]                                                        27%|██▋       | 1170/4399 [2:34:31<8:02:04,  8.96s/it] 27%|██▋       | 1171/4399
 0: {'loss': 0.6468, 'grad_norm': 2.3713051932445044, 'learning_rate': 9.164635478905936e-06, 'epoch': 0.27}
 0:  [2:34:41<8:07:11,  9.06s/it] 27%|██▋       | 1172/4399 [2:34:48<7:43:51,  8.62s/it] 27%|██▋       | 1173/4399 [2:34:55<7:10:40,  8.01s/it] 27%|██▋       | 1174/4399 [2:35:01<6:41:24,  7.47s/it] 27%|██▋       | 1175/4399 [2:35:07<6:17:40,  7.03s/it] 27%|██▋       | 1176/4399 [2:35:14<6:18:58,  7.06s/it] 27%|██▋       | 1177/4399 [2:35:26<7:38:16,  8.53s/it] 27%|██▋       | 1178/4399 [2:35:38<8:23:46,  9.38s/it] 27%|██▋       | 1179/4399 [2:35:46<8:09:19,  9.12s/it] 27%|██▋       | 1180/4399 [2:35:53<7:40:02,  8.57s/it]                                                        27%|██▋       | 1180/4399 [2:35:53<7:40:02,  8.57s/it] 27%|██▋       | 1181/4399 [2:36:01<7:18:09,  8.17s/it] 27%|██▋       | 1182/4399 [2:36:07<6:43:18,  7.52s/it] 27%|██▋       | 1183/4399 [2:36:13<6:22:13,  7.13s/it] 27%|██▋       | 1184/4399 [2:36:21<6:41:51,  7.50s/it] 27%|██▋       | 1185/4399 [2:36:31<7:16:33,  8.15s/it] 27%|
 0: {'loss': 0.6324, 'grad_norm': 1.9032221533011136, 'learning_rate': 9.142548246219212e-06, 'epoch': 0.27}
 0: █▋       | 1186/4399 [2:36:41<7:44:42,  8.68s/it] 27%|██▋       | 1187/4399 [2:36:50<8:00:59,  8.98s/it] 27%|██▋       | 1188/4399 [2:36:58<7:37:13,  8.54s/it] 27%|██▋       | 1189/4399 [2:37:04<6:53:41,  7.73s/it] 27%|██▋       | 1190/4399 [2:37:10<6:27:46,  7.25s/it]                                                        27%|██▋       | 1190/4399 [2:37:10<6:27:46,  7.25s/it] 27%|██▋       | 1191/4399 [2:37:17<6:24:38,  7.19s/it] 27%|██▋       | 1192/4399 [2:37:24<6:28:29,  7.27s/it] 27%|██▋       | 1193/4399 [2:37:35<7:28:10,  8.39s/it] 27%|██▋       | 1194/4399 [2:37:46<8:04:32,  9.07s/it] 27%|██▋       | 1195/4399 [2:37:55<8:02:35,  9.04s/it] 27%|██▋       | 1196/4399 [2:38:04<7:59:22,  8.98s/it] 27%|██▋       | 1197/4399 [2:38:11<7:26:03,  8.36s/it] 27%|██▋       | 1198/4399 [2:38:18<7:04:16,  7.95s/it] 27%|██▋       | 1199/4399 [2:38:24<6:35:36,  7.42s/it] 27%|██▋       | 1200/4399 [2:38:32<6:
 0: {'loss': 0.648, 'grad_norm': 2.604814139726408, 'learning_rate': 9.120200161612251e-06, 'epoch': 0.27}
 0: {'loss': 0.6327, 'grad_norm': 1.8865981308340691, 'learning_rate': 9.097592632320518e-06, 'epoch': 0.28}
 0: 43:29,  7.57s/it]                                                        27%|██▋       | 1200/4399 [2:38:32<6:43:29,  7.57s/it] 27%|██▋       | 1201/4399 [2:38:43<7:37:09,  8.58s/it] 27%|██▋       | 1202/4399 [2:38:54<8:14:20,  9.28s/it] 27%|██▋       | 1203/4399 [2:39:03<8:21:33,  9.42s/it] 27%|██▋       | 1204/4399 [2:39:11<7:53:45,  8.90s/it] 27%|██▋       | 1205/4399 [2:39:18<7:23:54,  8.34s/it] 27%|██▋       | 1206/4399 [2:39:23<6:33:15,  7.39s/it] 27%|██▋       | 1207/4399 [2:39:30<6:13:26,  7.02s/it] 27%|██▋       | 1208/4399 [2:39:36<6:12:09,  7.00s/it] 27%|██▋       | 1209/4399 [2:39:48<7:27:40,  8.42s/it] 28%|██▊       | 1210/4399 [2:39:59<8:06:40,  9.16s/it]                                                        28%|██▊       | 1210/4399 [2:39:59<8:06:40,  9.16s/it] 28%|██▊       | 1211/4399 [2:40:09<8:10:22,  9.23s/it] 28%|██▊       | 1212/4399 [2:40:16<7:36:25,  8.59s/it] 28%|██▊       | 1
 0: {'loss': 0.6536, 'grad_norm': 1.8700230102897086, 'learning_rate': 9.074727081916428e-06, 'epoch': 0.28}
 0: 213/4399 [2:40:22<7:07:44,  8.06s/it] 28%|██▊       | 1214/4399 [2:40:30<6:54:02,  7.80s/it] 28%|██▊       | 1215/4399 [2:40:36<6:26:46,  7.29s/it] 28%|██▊       | 1216/4399 [2:40:44<6:41:28,  7.57s/it] 28%|██▊       | 1217/4399 [2:40:54<7:26:32,  8.42s/it] 28%|██▊       | 1218/4399 [2:41:05<8:02:12,  9.10s/it] 28%|██▊       | 1219/4399 [2:41:15<8:17:28,  9.39s/it] 28%|██▊       | 1220/4399 [2:41:23<7:50:18,  8.88s/it]                                                        28%|██▊       | 1220/4399 [2:41:23<7:50:18,  8.88s/it] 28%|██▊       | 1221/4399 [2:41:29<7:00:52,  7.95s/it] 28%|██▊       | 1222/4399 [2:41:35<6:32:21,  7.41s/it] 28%|██▊       | 1223/4399 [2:41:42<6:24:43,  7.27s/it] 28%|██▊       | 1224/4399 [2:41:50<6:34:59,  7.46s/it] 28%|██▊       | 1225/4399 [2:41:59<7:13:30,  8.19s/it] 28%|██▊       | 1226/4399 [2:42:11<7:58:50,  9.05s/it] 28%|██▊       | 1227/4399 [2:42:19<7:49:12,  8.88s/it]
 0: {'loss': 0.648, 'grad_norm': 2.0643776445254014, 'learning_rate': 9.05160495021972e-06, 'epoch': 0.28}
 0: {'loss': 0.6179, 'grad_norm': 2.2582777331327635, 'learning_rate': 9.028227693206788e-06, 'epoch': 0.28}
 0:  28%|██▊       | 1228/4399 [2:42:27<7:35:32,  8.62s/it] 28%|██▊       | 1229/4399 [2:42:35<7:26:10,  8.44s/it] 28%|██▊       | 1230/4399 [2:42:42<7:02:03,  7.99s/it]                                                        28%|██▊       | 1230/4399 [2:42:42<7:02:03,  7.99s/it] 28%|██▊       | 1231/4399 [2:42:49<6:48:19,  7.73s/it] 28%|██▊       | 1232/4399 [2:42:56<6:31:59,  7.43s/it] 28%|██▊       | 1233/4399 [2:43:06<7:22:36,  8.39s/it] 28%|██▊       | 1234/4399 [2:43:17<7:52:51,  8.96s/it] 28%|██▊       | 1235/4399 [2:43:26<8:01:02,  9.12s/it] 28%|██▊       | 1236/4399 [2:43:36<8:06:07,  9.22s/it] 28%|██▊       | 1237/4399 [2:43:43<7:42:17,  8.77s/it] 28%|██▊       | 1238/4399 [2:43:49<6:46:38,  7.72s/it] 28%|██▊       | 1239/4399 [2:43:54<6:04:10,  6.91s/it] 28%|██▊       | 1240/4399 [2:44:01<6:05:55,  6.95s/it]                                                        28%|██▊       | 1240/4399 [2:44:01
 0: {'loss': 0.6511, 'grad_norm': 2.047924350447711, 'learning_rate': 9.004596782918995e-06, 'epoch': 0.28}
 0: <6:05:55,  6.95s/it] 28%|██▊       | 1241/4399 [2:44:12<7:10:59,  8.19s/it] 28%|██▊       | 1242/4399 [2:44:22<7:45:14,  8.84s/it] 28%|██▊       | 1243/4399 [2:44:30<7:23:40,  8.43s/it] 28%|██▊       | 1244/4399 [2:44:38<7:19:18,  8.35s/it] 28%|██▊       | 1245/4399 [2:44:44<6:42:34,  7.66s/it] 28%|██▊       | 1246/4399 [2:44:50<6:20:13,  7.24s/it] 28%|██▊       | 1247/4399 [2:44:56<6:00:53,  6.87s/it] 28%|██▊       | 1248/4399 [2:45:03<5:58:37,  6.83s/it] 28%|██▊       | 1249/4399 [2:45:13<6:48:03,  7.77s/it] 28%|██▊       | 1250/4399 [2:45:24<7:43:04,  8.82s/it]                                                        28%|██▊       | 1250/4399 [2:45:24<7:43:04,  8.82s/it] 28%|██▊       | 1251/4399 [2:45:33<7:50:24,  8.97s/it] 28%|██▊       | 1252/4399 [2:45:42<7:46:40,  8.90s/it] 28%|██▊       | 1253/4399 [2:45:49<7:14:06,  8.28s/it] 29%|██▊       | 1254/4399 [2:45:55<6:41:00,  7.65s/it] 29%|██▊  
 0: {'loss': 0.6381, 'grad_norm': 2.0079115604755016, 'learning_rate': 8.980713707369993e-06, 'epoch': 0.29}
 0:      | 1255/4399 [2:46:02<6:33:59,  7.52s/it] 29%|██▊       | 1256/4399 [2:46:11<6:48:51,  7.81s/it] 29%|██▊       | 1257/4399 [2:46:23<7:51:05,  9.00s/it] 29%|██▊       | 1258/4399 [2:46:33<8:14:54,  9.45s/it] 29%|██▊       | 1259/4399 [2:46:42<8:00:51,  9.19s/it] 29%|██▊       | 1260/4399 [2:46:51<8:00:07,  9.18s/it]                                                        29%|██▊       | 1260/4399 [2:46:51<8:00:07,  9.18s/it] 29%|██▊       | 1261/4399 [2:46:58<7:26:25,  8.54s/it] 29%|██▊       | 1262/4399 [2:47:04<6:50:24,  7.85s/it] 29%|██▊       | 1263/4399 [2:47:09<6:09:29,  7.07s/it] 29%|██▊       | 1264/4399 [2:47:17<6:18:49,  7.25s/it] 29%|██▉       | 1265/4399 [2:47:28<7:18:58,  8.40s/it] 29%|██▉       | 1266/4399 [2:47:38<7:42:27,  8.86s/it] 29%|██▉       | 1267/4399 [2:47:48<7:59:34,  9.19s/it] 29%|██▉       | 1268/4399 [2:47:57<7:51:50,  9.04s/it] 29%|██▉       | 1269/4399 [2:48:04<7:19:59,  8
 0: {'loss': 0.6358, 'grad_norm': 2.12423977378928, 'learning_rate': 8.956579970452011e-06, 'epoch': 0.29}
 0: {'loss': 0.6292, 'grad_norm': 1.889102354509106, 'learning_rate': 8.932197091841159e-06, 'epoch': 0.29}
 0: .43s/it] 29%|██▉       | 1270/4399 [2:48:09<6:28:43,  7.45s/it]                                                        29%|██▉       | 1270/4399 [2:48:09<6:28:43,  7.45s/it] 29%|██▉       | 1271/4399 [2:48:16<6:23:24,  7.35s/it] 29%|██▉       | 1272/4399 [2:48:24<6:38:26,  7.65s/it] 29%|██▉       | 1273/4399 [2:48:33<6:55:53,  7.98s/it] 29%|██▉       | 1274/4399 [2:48:44<7:43:14,  8.89s/it] 29%|██▉       | 1275/4399 [2:48:55<8:17:35,  9.56s/it] 29%|██▉       | 1276/4399 [2:49:03<7:42:53,  8.89s/it] 29%|██▉       | 1277/4399 [2:49:11<7:27:07,  8.59s/it] 29%|██▉       | 1278/4399 [2:49:17<6:49:58,  7.88s/it] 29%|██▉       | 1279/4399 [2:49:23<6:22:33,  7.36s/it] 29%|██▉       | 1280/4399 [2:49:31<6:35:50,  7.61s/it]                                                        29%|██▉       | 1280/4399 [2:49:31<6:35:50,  7.61s/it] 29%|██▉       | 1281/4399 [2:49:42<7:23:33,  8.54s/it] 29%|██▉       | 1282/4399 
 0: {'loss': 0.6239, 'grad_norm': 1.9039107957391725, 'learning_rate': 8.907566606901742e-06, 'epoch': 0.29}
 0: [2:49:51<7:34:28,  8.75s/it] 29%|██▉       | 1283/4399 [2:50:01<7:48:52,  9.03s/it] 29%|██▉       | 1284/4399 [2:50:10<7:46:49,  8.99s/it] 29%|██▉       | 1285/4399 [2:50:16<7:04:12,  8.17s/it] 29%|██▉       | 1286/4399 [2:50:21<6:18:51,  7.30s/it] 29%|██▉       | 1287/4399 [2:50:28<6:16:49,  7.27s/it] 29%|██▉       | 1288/4399 [2:50:37<6:31:30,  7.55s/it] 29%|██▉       | 1289/4399 [2:50:46<6:56:17,  8.03s/it] 29%|██▉       | 1290/4399 [2:50:57<7:50:22,  9.08s/it]                                                        29%|██▉       | 1290/4399 [2:50:57<7:50:22,  9.08s/it] 29%|██▉       | 1291/4399 [2:51:07<8:01:18,  9.29s/it] 29%|██▉       | 1292/4399 [2:51:15<7:47:41,  9.03s/it] 29%|██▉       | 1293/4399 [2:51:24<7:38:39,  8.86s/it] 29%|██▉       | 1294/4399 [2:51:29<6:41:16,  7.75s/it] 29%|██▉       | 1295/4399 [2:51:35<6:14:20,  7.24s/it] 29%|██▉       | 1296/4399 [2:51:43<6:30:25,  7.55s/it] 29%|█
 0: {'loss': 0.6311, 'grad_norm': 1.8907643398870013, 'learning_rate': 8.882690066589578e-06, 'epoch': 0.3}
 0: █▉       | 1297/4399 [2:51:55<7:30:59,  8.72s/it] 30%|██▉       | 1298/4399 [2:52:06<8:12:03,  9.52s/it] 30%|██▉       | 1299/4399 [2:52:15<8:02:13,  9.33s/it] 30%|██▉       | 1300/4399 [2:52:24<7:54:32,  9.19s/it]                                                        30%|██▉       | 1300/4399 [2:52:24<7:54:32,  9.19s/it] 30%|██▉       | 1301/4399 [2:52:32<7:35:25,  8.82s/it] 30%|██▉       | 1302/4399 [2:52:38<6:54:27,  8.03s/it] 30%|██▉       | 1303/4399 [2:52:44<6:24:34,  7.45s/it] 30%|██▉       | 1304/4399 [2:52:52<6:36:00,  7.68s/it] 30%|██▉       | 1305/4399 [2:53:02<7:01:30,  8.17s/it] 30%|██▉       | 1306/4399 [2:53:13<7:53:07,  9.18s/it] 30%|██▉       | 1307/4399 [2:53:23<8:06:25,  9.44s/it] 30%|██▉       | 1308/4399 [2:53:31<7:45:48,  9.04s/it] 30%|██▉       | 1309/4399 [2:53:39<7:25:53,  8.66s/it] 30%|██▉       | 1310/4399 [2:53:46<7:03:03,  8.22s/it]                                             
 0: {'loss': 0.6318, 'grad_norm': 2.1097541913939604, 'learning_rate': 8.85756903735433e-06, 'epoch': 0.3}
 0: {'loss': 0.6346, 'grad_norm': 2.0533256417841956, 'learning_rate': 8.832205101040873e-06, 'epoch': 0.3}
 0:            30%|██▉       | 1310/4399 [2:53:46<7:03:03,  8.22s/it] 30%|██▉       | 1311/4399 [2:53:53<6:31:30,  7.61s/it] 30%|██▉       | 1312/4399 [2:54:02<6:57:26,  8.11s/it] 30%|██▉       | 1313/4399 [2:54:12<7:24:05,  8.63s/it] 30%|██▉       | 1314/4399 [2:54:23<8:12:21,  9.58s/it] 30%|██▉       | 1315/4399 [2:54:34<8:20:22,  9.73s/it] 30%|██▉       | 1316/4399 [2:54:40<7:33:40,  8.83s/it] 30%|██▉       | 1317/4399 [2:54:48<7:22:58,  8.62s/it] 30%|██▉       | 1318/4399 [2:54:55<6:48:15,  7.95s/it] 30%|██▉       | 1319/4399 [2:55:02<6:32:23,  7.64s/it] 30%|███       | 1320/4399 [2:55:10<6:41:52,  7.83s/it]                                                        30%|███       | 1320/4399 [2:55:10<6:41:52,  7.83s/it] 30%|███       | 1321/4399 [2:55:21<7:27:59,  8.73s/it] 30%|███       | 1322/4399 [2:55:32<8:12:09,  9.60s/it] 30%|███       | 1323/4399 [2:55:42<8:13:12,  9.62s/it] 30%|███       | 13
 0: {'loss': 0.632, 'grad_norm': 2.529113701916644, 'learning_rate': 8.806599854789687e-06, 'epoch': 0.3}
 0: 24/4399 [2:55:49<7:30:09,  8.78s/it] 30%|███       | 1325/4399 [2:55:56<7:04:57,  8.29s/it] 30%|███       | 1326/4399 [2:56:03<6:35:35,  7.72s/it] 30%|███       | 1327/4399 [2:56:08<5:54:23,  6.92s/it] 30%|███       | 1328/4399 [2:56:16<6:09:57,  7.23s/it] 30%|███       | 1329/4399 [2:56:26<6:56:35,  8.14s/it] 30%|███       | 1330/4399 [2:56:37<7:46:23,  9.12s/it]                                                        30%|███       | 1330/4399 [2:56:37<7:46:23,  9.12s/it] 30%|███       | 1331/4399 [2:56:47<8:01:59,  9.43s/it] 30%|███       | 1332/4399 [2:56:55<7:33:42,  8.88s/it] 30%|███       | 1333/4399 [2:57:03<7:25:50,  8.72s/it] 30%|███       | 1334/4399 [2:57:09<6:46:26,  7.96s/it] 30%|███       | 1335/4399 [2:57:15<6:15:49,  7.36s/it] 30%|███       | 1336/4399 [2:57:24<6:32:26,  7.69s/it] 30%|███       | 1337/4399 [2:57:32<6:38:03,  7.80s/it] 30%|███       | 1338/4399 [2:57:42<7:08:44,  8.40s/it]
 0: {'loss': 0.636, 'grad_norm': 2.1040760691702523, 'learning_rate': 8.780754910936284e-06, 'epoch': 0.3}
 0: {'loss': 0.6311, 'grad_norm': 1.9727555060837314, 'learning_rate': 8.754671896909686e-06, 'epoch': 0.31}
 0:  30%|███       | 1339/4399 [2:57:53<7:51:08,  9.24s/it] 30%|███       | 1340/4399 [2:58:01<7:38:34,  8.99s/it]                                                        30%|███       | 1340/4399 [2:58:01<7:38:34,  8.99s/it] 30%|███       | 1341/4399 [2:58:09<7:20:53,  8.65s/it] 31%|███       | 1342/4399 [2:58:16<6:58:25,  8.21s/it] 31%|███       | 1343/4399 [2:58:22<6:24:41,  7.55s/it] 31%|███       | 1344/4399 [2:58:30<6:31:39,  7.69s/it] 31%|███       | 1345/4399 [2:58:41<7:10:01,  8.45s/it] 31%|███       | 1346/4399 [2:58:52<7:46:43,  9.17s/it] 31%|███       | 1347/4399 [2:59:01<7:51:40,  9.27s/it] 31%|███       | 1348/4399 [2:59:09<7:30:35,  8.86s/it] 31%|███       | 1349/4399 [2:59:15<6:54:53,  8.16s/it] 31%|███       | 1350/4399 [2:59:23<6:40:38,  7.88s/it]                                                        31%|███       | 1350/4399 [2:59:23<6:40:38,  7.88s/it] 31%|███       | 1351/4399 [2:59:28<
 0: {'loss': 0.644, 'grad_norm': 1.9877567869466481, 'learning_rate': 8.728352455129938e-06, 'epoch': 0.31}
 0: 5:57:24,  7.04s/it] 31%|███       | 1352/4399 [2:59:37<6:30:17,  7.69s/it] 31%|███       | 1353/4399 [2:59:47<7:01:29,  8.30s/it] 31%|███       | 1354/4399 [2:59:57<7:31:53,  8.90s/it] 31%|███       | 1355/4399 [3:00:07<7:51:08,  9.29s/it] 31%|███       | 1356/4399 [3:00:14<7:18:37,  8.65s/it] 31%|███       | 1357/4399 [3:00:22<7:01:55,  8.32s/it] 31%|███       | 1358/4399 [3:00:28<6:26:43,  7.63s/it] 31%|███       | 1359/4399 [3:00:33<5:50:54,  6.93s/it] 31%|███       | 1360/4399 [3:00:41<6:08:55,  7.28s/it]                                                        31%|███       | 1360/4399 [3:00:41<6:08:55,  7.28s/it] 31%|███       | 1361/4399 [3:00:52<6:58:44,  8.27s/it] 31%|███       | 1362/4399 [3:01:03<7:36:22,  9.02s/it] 31%|███       | 1363/4399 [3:01:13<7:56:31,  9.42s/it] 31%|███       | 1364/4399 [3:01:20<7:23:15,  8.76s/it] 31%|███       | 1365/4399 [3:01:27<6:58:02,  8.27s/it] 31%|███   
 0: {'loss': 0.6207, 'grad_norm': 2.5010045943804426, 'learning_rate': 8.701798242904704e-06, 'epoch': 0.31}
 0:     | 1366/4399 [3:01:32<6:09:00,  7.30s/it] 31%|███       | 1367/4399 [3:01:39<5:53:25,  6.99s/it] 31%|███       | 1368/4399 [3:01:47<6:10:56,  7.34s/it] 31%|███       | 1369/4399 [3:01:57<6:50:25,  8.13s/it] 31%|███       | 1370/4399 [3:02:07<7:29:16,  8.90s/it]                                                        31%|███       | 1370/4399 [3:02:07<7:29:16,  8.90s/it] 31%|███       | 1371/4399 [3:02:18<7:49:53,  9.31s/it] 31%|███       | 1372/4399 [3:02:26<7:40:14,  9.12s/it] 31%|███       | 1373/4399 [3:02:34<7:16:39,  8.66s/it] 31%|███       | 1374/4399 [3:02:39<6:22:20,  7.58s/it] 31%|███▏      | 1375/4399 [3:02:44<5:46:19,  6.87s/it] 31%|███▏      | 1376/4399 [3:02:53<6:15:31,  7.45s/it] 31%|███▏      | 1377/4399 [3:03:02<6:44:40,  8.03s/it] 31%|███▏      | 1378/4399 [3:03:13<7:16:04,  8.66s/it] 31%|███▏      | 1379/4399 [3:03:23<7:48:58,  9.32s/it] 31%|███▏      | 1380/4399 [3:03:32<
 0: {'loss': 0.6297, 'grad_norm': 1.9872574986957807, 'learning_rate': 8.675010932324882e-06, 'epoch': 0.31}
 0: {'loss': 0.6229, 'grad_norm': 5.157279268540585, 'learning_rate': 8.64799221015934e-06, 'epoch': 0.32}
 0: 7:42:38,  9.19s/it]                                                        31%|███▏      | 1380/4399 [3:03:32<7:42:38,  9.19s/it] 31%|███▏      | 1381/4399 [3:03:41<7:32:11,  8.99s/it] 31%|███▏      | 1382/4399 [3:03:48<7:03:57,  8.43s/it] 31%|███▏      | 1383/4399 [3:03:54<6:29:06,  7.74s/it] 31%|███▏      | 1384/4399 [3:04:01<6:16:42,  7.50s/it] 31%|███▏      | 1385/4399 [3:04:09<6:23:19,  7.63s/it] 32%|███▏      | 1386/4399 [3:04:20<7:11:35,  8.59s/it] 32%|███▏      | 1387/4399 [3:04:30<7:40:35,  9.18s/it] 32%|███▏      | 1388/4399 [3:04:38<7:17:42,  8.72s/it] 32%|███▏      | 1389/4399 [3:04:45<6:52:01,  8.21s/it] 32%|███▏      | 1390/4399 [3:04:51<6:19:05,  7.56s/it]                                                        32%|███▏      | 1390/4399 [3:04:51<6:19:05,  7.56s/it] 32%|███▏      | 1391/4399 [3:04:57<5:57:34,  7.13s/it] 32%|███▏      | 1392/4399 [3:05:04<5:56:01,  7.10
 0: {'loss': 0.6401, 'grad_norm': 1.8692927663787253, 'learning_rate': 8.620743777748693e-06, 'epoch': 0.32}
 0: s/it] 32%|███▏      | 1393/4399 [3:05:13<6:16:38,  7.52s/it] 32%|███▏      | 1394/4399 [3:05:23<6:56:44,  8.32s/it] 32%|███▏      | 1395/4399 [3:05:32<7:09:10,  8.57s/it] 32%|███▏      | 1396/4399 [3:05:42<7:24:43,  8.89s/it] 32%|███▏      | 1397/4399 [3:05:51<7:24:09,  8.88s/it] 32%|███▏      | 1398/4399 [3:05:56<6:26:58,  7.74s/it] 32%|███▏      | 1399/4399 [3:06:01<5:48:53,  6.98s/it] 32%|███▏      | 1400/4399 [3:06:09<6:02:26,  7.25s/it]                                                        32%|███▏      | 1400/4399 [3:06:09<6:02:26,  7.25s/it] 32%|███▏      | 1401/4399 [3:06:17<6:23:45,  7.68s/it] 32%|███▏      | 1402/4399 [3:06:27<6:56:55,  8.35s/it] 32%|███▏      | 1403/4399 [3:06:37<7:21:13,  8.84s/it] 32%|███▏      | 1404/4399 [3:06:46<7:14:48,  8.71s/it] 32%|███▏      | 1405/4399 [3:06:55<7:17:43,  8.77s/it] 32%|███▏      | 1406/4399 [3:07:01<6:35:47,  7.93s/it] 
 0: {'loss': 0.6262, 'grad_norm': 2.0937286106470037, 'learning_rate': 8.593267350898156e-06, 'epoch': 0.32}
 0: 32%|███▏      | 1407/4399 [3:07:06<5:55:27,  7.13s/it] 32%|███▏      | 1408/4399 [3:07:14<6:09:33,  7.41s/it] 32%|███▏      | 1409/4399 [3:07:23<6:30:08,  7.83s/it] 32%|███▏      | 1410/4399 [3:07:34<7:14:40,  8.73s/it]                                                        32%|███▏      | 1410/4399 [3:07:34<7:14:40,  8.73s/it] 32%|███▏      | 1411/4399 [3:07:45<7:49:23,  9.43s/it] 32%|███▏      | 1412/4399 [3:07:53<7:30:19,  9.05s/it] 32%|███▏      | 1413/4399 [3:08:00<7:09:57,  8.64s/it] 32%|███▏      | 1414/4399 [3:08:06<6:16:05,  7.56s/it] 32%|███▏      | 1415/4399 [3:08:12<5:52:38,  7.09s/it] 32%|███▏      | 1416/4399 [3:08:20<6:06:37,  7.37s/it] 32%|███▏      | 1417/4399 [3:08:27<6:10:22,  7.45s/it] 32%|███▏      | 1418/4399 [3:08:38<6:55:10,  8.36s/it] 32%|███▏      | 1419/4399 [3:08:49<7:33:26,  9.13s/it] 32%|███▏      | 1420/4399 [3:08:58<7:43:48,  9.34s/it]        
 0: {'loss': 0.6513, 'grad_norm': 1.8489554292641364, 'learning_rate': 8.565564659769526e-06, 'epoch': 0.32}
 0: {'loss': 0.6218, 'grad_norm': 1.689332521975561, 'learning_rate': 8.537637448772222e-06, 'epoch': 0.33}
 0:                                                 32%|███▏      | 1420/4399 [3:08:58<7:43:48,  9.34s/it] 32%|███▏      | 1421/4399 [3:09:05<7:03:35,  8.53s/it] 32%|███▏      | 1422/4399 [3:09:12<6:39:47,  8.06s/it] 32%|███▏      | 1423/4399 [3:09:17<5:58:20,  7.22s/it] 32%|███▏      | 1424/4399 [3:09:25<6:10:10,  7.47s/it] 32%|███▏      | 1425/4399 [3:09:34<6:20:59,  7.69s/it] 32%|███▏      | 1426/4399 [3:09:45<7:16:59,  8.82s/it] 32%|███▏      | 1427/4399 [3:09:55<7:30:58,  9.10s/it] 32%|███▏      | 1428/4399 [3:10:03<7:22:46,  8.94s/it] 32%|███▏      | 1429/4399 [3:10:10<6:50:44,  8.30s/it] 33%|███▎      | 1430/4399 [3:10:17<6:26:31,  7.81s/it]                                                        33%|███▎      | 1430/4399 [3:10:17<6:26:31,  7.81s/it] 33%|███▎      | 1431/4399 [3:10:22<5:45:39,  6.99s/it] 33%|███▎      | 1432/4399 [3:10:28<5:38:26,  6.84s/it] 33%|███▎     
 0: {'loss': 0.6394, 'grad_norm': 1.9358485811534611, 'learning_rate': 8.509487476453442e-06, 'epoch': 0.33}
 0:  | 1433/4399 [3:10:37<5:58:37,  7.25s/it] 33%|███▎      | 1434/4399 [3:10:46<6:32:18,  7.94s/it] 33%|███▎      | 1435/4399 [3:10:57<7:10:50,  8.72s/it] 33%|███▎      | 1436/4399 [3:11:05<7:10:06,  8.71s/it] 33%|███▎      | 1437/4399 [3:11:13<6:51:23,  8.33s/it] 33%|███▎      | 1438/4399 [3:11:19<6:23:19,  7.77s/it] 33%|███▎      | 1439/4399 [3:11:26<6:12:43,  7.56s/it] 33%|███▎      | 1440/4399 [3:11:33<6:02:53,  7.36s/it]                                                        33%|███▎      | 1440/4399 [3:11:33<6:02:53,  7.36s/it] 33%|███▎      | 1441/4399 [3:11:41<6:09:37,  7.50s/it] 33%|███▎      | 1442/4399 [3:11:52<6:58:24,  8.49s/it] 33%|███▎      | 1443/4399 [3:12:03<7:30:13,  9.14s/it] 33%|███▎      | 1444/4399 [3:12:12<7:40:35,  9.35s/it] 33%|███▎      | 1445/4399 [3:12:19<6:58:40,  8.50s/it] 33%|███▎      | 1446/4399 [3:12:24<6:10:27,  7.53s/it] 33%|███▎      | 1447
 0: {'loss': 0.6255, 'grad_norm': 1.843380373113822, 'learning_rate': 8.481116515387434e-06, 'epoch': 0.33}
 0: /4399 [3:12:30<5:50:50,  7.13s/it] 33%|███▎      | 1448/4399 [3:12:39<6:11:09,  7.55s/it] 33%|███▎      | 1449/4399 [3:12:47<6:21:58,  7.77s/it] 33%|███▎      | 1450/4399 [3:12:58<7:01:29,  8.58s/it]                                                        33%|███▎      | 1450/4399 [3:12:58<7:01:29,  8.58s/it] 33%|███▎      | 1451/4399 [3:13:10<7:57:01,  9.71s/it] 33%|███▎      | 1452/4399 [3:13:18<7:27:19,  9.11s/it] 33%|███▎      | 1453/4399 [3:13:24<6:46:30,  8.28s/it] 33%|███▎      | 1454/4399 [3:13:30<6:19:05,  7.72s/it] 33%|███▎      | 1455/4399 [3:13:36<5:53:55,  7.21s/it] 33%|███▎      | 1456/4399 [3:13:43<5:46:01,  7.05s/it] 33%|███▎      | 1457/4399 [3:13:51<6:03:35,  7.42s/it] 33%|███▎      | 1458/4399 [3:14:02<6:43:09,  8.22s/it] 33%|███▎      | 1459/4399 [3:14:12<7:12:00,  8.82s/it] 33%|███▎      | 1460/4399 [3:14:21<7:14:13,  8.86s/it]                                    
 0: {'loss': 0.6242, 'grad_norm': 1.964676885976243, 'learning_rate': 8.45252635206387e-06, 'epoch': 0.33}
 0: {'loss': 0.6247, 'grad_norm': 2.009456825191219, 'learning_rate': 8.423718786775365e-06, 'epoch': 0.33}
 0:                     33%|███▎      | 1460/4399 [3:14:21<7:14:13,  8.86s/it] 33%|███▎      | 1461/4399 [3:14:28<6:45:31,  8.28s/it] 33%|███▎      | 1462/4399 [3:14:33<6:07:25,  7.51s/it] 33%|███▎      | 1463/4399 [3:14:39<5:45:47,  7.07s/it] 33%|███▎      | 1464/4399 [3:14:47<5:50:26,  7.16s/it] 33%|███▎      | 1465/4399 [3:14:55<6:13:31,  7.64s/it] 33%|███▎      | 1466/4399 [3:15:06<6:53:51,  8.47s/it] 33%|███▎      | 1467/4399 [3:15:16<7:18:54,  8.98s/it] 33%|███▎      | 1468/4399 [3:15:23<6:54:56,  8.49s/it] 33%|███▎      | 1469/4399 [3:15:31<6:40:20,  8.20s/it] 33%|███▎      | 1470/4399 [3:15:38<6:28:00,  7.95s/it]                                                        33%|███▎      | 1470/4399 [3:15:38<6:28:00,  7.95s/it] 33%|███▎      | 1471/4399 [3:15:43<5:45:55,  7.09s/it] 33%|███▎      | 1472/4399 [3:15:51<5:49:26,  7.16s/it] 33%|███▎      | 1473/4399 [3:16:00<6:14:2
 0: {'loss': 0.6212, 'grad_norm': 1.8938210847907988, 'learning_rate': 8.394695633504106e-06, 'epoch': 0.34}
 0: 2,  7.68s/it] 34%|███▎      | 1474/4399 [3:16:10<6:48:54,  8.39s/it] 34%|███▎      | 1475/4399 [3:16:19<7:02:48,  8.68s/it] 34%|███▎      | 1476/4399 [3:16:28<7:06:32,  8.76s/it] 34%|███▎      | 1477/4399 [3:16:36<6:52:25,  8.47s/it] 34%|███▎      | 1478/4399 [3:16:42<6:17:14,  7.75s/it] 34%|███▎      | 1479/4399 [3:16:49<6:06:42,  7.54s/it] 34%|███▎      | 1480/4399 [3:16:57<6:17:58,  7.77s/it]                                                        34%|███▎      | 1480/4399 [3:16:57<6:17:58,  7.77s/it] 34%|███▎      | 1481/4399 [3:17:05<6:20:15,  7.82s/it] 34%|███▎      | 1482/4399 [3:17:14<6:34:27,  8.11s/it] 34%|███▎      | 1483/4399 [3:17:25<7:12:05,  8.89s/it] 34%|███▎      | 1484/4399 [3:17:32<6:48:16,  8.40s/it] 34%|███▍      | 1485/4399 [3:17:38<6:17:40,  7.78s/it] 34%|███▍      | 1486/4399 [3:17:44<5:50:31,  7.22s/it] 34%|███▍      | 1487/4399 [3:17:51<5:48:41,  7.1
 0: {'loss': 0.6145, 'grad_norm': 1.6980776884266726, 'learning_rate': 8.365458719807624e-06, 'epoch': 0.34}
 0: {'loss': 0.6239, 'grad_norm': 1.6898642742591972, 'learning_rate': 8.336009886703728e-06, 'epoch': 0.34}
 0: 8s/it] 34%|███▍      | 1488/4399 [3:17:58<5:40:32,  7.02s/it] 34%|███▍      | 1489/4399 [3:18:06<6:01:08,  7.45s/it] 34%|███▍      | 1490/4399 [3:18:16<6:35:02,  8.15s/it]                                                        34%|███▍      | 1490/4399 [3:18:16<6:35:02,  8.15s/it] 34%|███▍      | 1491/4399 [3:18:27<7:16:47,  9.01s/it] 34%|███▍      | 1492/4399 [3:18:35<6:58:31,  8.64s/it] 34%|███▍      | 1493/4399 [3:18:42<6:42:36,  8.31s/it] 34%|███▍      | 1494/4399 [3:18:50<6:29:02,  8.04s/it] 34%|███▍      | 1495/4399 [3:18:55<5:49:06,  7.21s/it] 34%|███▍      | 1496/4399 [3:19:02<5:49:40,  7.23s/it] 34%|███▍      | 1497/4399 [3:19:12<6:21:50,  7.89s/it] 34%|███▍      | 1498/4399 [3:19:22<6:54:20,  8.57s/it] 34%|███▍      | 1499/4399 [3:19:33<7:23:16,  9.17s/it] 34%|███▍      | 1500/4399 [3:19:41<7:08:39,  8.87s/it]                                                        34%|
 0: ██▍      | 1500/4399 [3:19:41<7:08:39,  8.87s/it][INFO|trainer.py:3984] 2025-06-28 00:24:09,133 >> Saving model checkpoint to /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500
 0: [INFO|configuration_utils.py:419] 2025-06-28 00:24:09,139 >> Configuration saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/config.json
 0: [INFO|configuration_utils.py:911] 2025-06-28 00:24:09,142 >> Configuration saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/generation_config.json
 0: [INFO|modeling_utils.py:3580] 2025-06-28 00:24:16,515 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 4 checkpoint shards. You can find where each parameters has been saved in the index located at /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/model.safetensors.index.json.
 0: [INFO|tokenization_utils_base.py:2510] 2025-06-28 00:24:16,518 >> tokenizer config file saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/tokenizer_config.json
 0: [INFO|tokenization_utils_base.py:2519] 2025-06-28 00:24:16,530 >> Special tokens file saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/special_tokens_map.json
 0: [2025-06-28 00:24:16,740] [INFO] [logging.py:107:log_dist] [Rank 0] [Torch] Checkpoint global_step1500 is about to be saved!
 0: [2025-06-28 00:24:16,749] [INFO] [logging.py:107:log_dist] [Rank 0] Saving model checkpoint: /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_0_mp_rank_00_model_states.pt
 0: [2025-06-28 00:24:16,750] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_0_mp_rank_00_model_states.pt...
17: [2025-06-28 00:24:16,749] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_68_mp_rank_00_model_states.pt...
28: [2025-06-28 00:24:16,750] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_112_mp_rank_00_model_states.pt...
27: [2025-06-28 00:24:16,750] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_108_mp_rank_00_model_states.pt...
12: [2025-06-28 00:24:16,751] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_48_mp_rank_00_model_states.pt...
23: [2025-06-28 00:24:16,751] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_92_mp_rank_00_model_states.pt...
30: [2025-06-28 00:24:16,751] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_120_mp_rank_00_model_states.pt...
 2: [2025-06-28 00:24:16,751] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_8_mp_rank_00_model_states.pt...
 9: [2025-06-28 00:24:16,751] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_36_mp_rank_00_model_states.pt...
 3: [2025-06-28 00:24:16,751] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_12_mp_rank_00_model_states.pt...
 5: [2025-06-28 00:24:16,751] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_20_mp_rank_00_model_states.pt...
10: [2025-06-28 00:24:16,751] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_40_mp_rank_00_model_states.pt...
22: [2025-06-28 00:24:16,751] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_88_mp_rank_00_model_states.pt...
20: [2025-06-28 00:24:16,751] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_80_mp_rank_00_model_states.pt...
 8: [2025-06-28 00:24:16,751] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_32_mp_rank_00_model_states.pt...
 6: [2025-06-28 00:24:16,751] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_24_mp_rank_00_model_states.pt...
16: [2025-06-28 00:24:16,751] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_64_mp_rank_00_model_states.pt...
13: [2025-06-28 00:24:16,751] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_52_mp_rank_00_model_states.pt...
19: [2025-06-28 00:24:16,751] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_76_mp_rank_00_model_states.pt...
14: [2025-06-28 00:24:16,751] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_56_mp_rank_00_model_states.pt...
29: [2025-06-28 00:24:16,751] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_116_mp_rank_00_model_states.pt...
25: [2025-06-28 00:24:16,751] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_100_mp_rank_00_model_states.pt...
24: [2025-06-28 00:24:16,751] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_96_mp_rank_00_model_states.pt...
18: [2025-06-28 00:24:16,751] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_72_mp_rank_00_model_states.pt...
31: [2025-06-28 00:24:16,751] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_124_mp_rank_00_model_states.pt...
15: [2025-06-28 00:24:16,751] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_60_mp_rank_00_model_states.pt...
 4: [2025-06-28 00:24:16,752] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_16_mp_rank_00_model_states.pt...
 7: [2025-06-28 00:24:16,752] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_28_mp_rank_00_model_states.pt...
 1: [2025-06-28 00:24:16,753] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_4_mp_rank_00_model_states.pt...
11: [2025-06-28 00:24:16,753] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_44_mp_rank_00_model_states.pt...
26: [2025-06-28 00:24:16,753] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_104_mp_rank_00_model_states.pt...
21: [2025-06-28 00:24:16,754] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_84_mp_rank_00_model_states.pt...
27: [2025-06-28 00:24:16,776] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_108_mp_rank_00_model_states.pt.
28: [2025-06-28 00:24:16,778] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_112_mp_rank_00_model_states.pt.
 2: [2025-06-28 00:24:16,784] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_8_mp_rank_00_model_states.pt.
12: [2025-06-28 00:24:16,789] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_48_mp_rank_00_model_states.pt.
 6: [2025-06-28 00:24:16,790] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_24_mp_rank_00_model_states.pt.
 0: [2025-06-28 00:24:16,792] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_0_mp_rank_00_model_states.pt.
 5: [2025-06-28 00:24:16,794] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_20_mp_rank_00_model_states.pt.
25: [2025-06-28 00:24:16,795] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_100_mp_rank_00_model_states.pt.
15: [2025-06-28 00:24:16,795] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_60_mp_rank_00_model_states.pt.
17: [2025-06-28 00:24:16,796] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_68_mp_rank_00_model_states.pt.
31: [2025-06-28 00:24:16,796] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_124_mp_rank_00_model_states.pt.
30: [2025-06-28 00:24:16,798] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_120_mp_rank_00_model_states.pt.
23: [2025-06-28 00:24:16,798] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_92_mp_rank_00_model_states.pt.
 3: [2025-06-28 00:24:16,799] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_12_mp_rank_00_model_states.pt.
13: [2025-06-28 00:24:16,799] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_52_mp_rank_00_model_states.pt.
24: [2025-06-28 00:24:16,801] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_96_mp_rank_00_model_states.pt.
18: [2025-06-28 00:24:16,803] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_72_mp_rank_00_model_states.pt.
22: [2025-06-28 00:24:16,803] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_88_mp_rank_00_model_states.pt.
14: [2025-06-28 00:24:16,804] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_56_mp_rank_00_model_states.pt.
 8: [2025-06-28 00:24:16,805] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_32_mp_rank_00_model_states.pt.
19: [2025-06-28 00:24:16,806] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_76_mp_rank_00_model_states.pt.
29: [2025-06-28 00:24:16,806] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_116_mp_rank_00_model_states.pt.
 4: [2025-06-28 00:24:16,806] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_16_mp_rank_00_model_states.pt.
20: [2025-06-28 00:24:16,806] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_80_mp_rank_00_model_states.pt.
16: [2025-06-28 00:24:16,806] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_64_mp_rank_00_model_states.pt.
 7: [2025-06-28 00:24:16,806] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_28_mp_rank_00_model_states.pt.
11: [2025-06-28 00:24:16,807] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_44_mp_rank_00_model_states.pt.
 9: [2025-06-28 00:24:16,808] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_36_mp_rank_00_model_states.pt.
26: [2025-06-28 00:24:16,809] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_104_mp_rank_00_model_states.pt.
 1: [2025-06-28 00:24:16,809] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_4_mp_rank_00_model_states.pt.
21: [2025-06-28 00:24:16,809] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_84_mp_rank_00_model_states.pt.
10: [2025-06-28 00:24:16,995] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/zero_pp_rank_40_mp_rank_00_model_states.pt.
 4: [2025-06-28 00:24:17,042] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_16_mp_rank_00_optim_states.pt...
 7: [2025-06-28 00:24:17,042] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_28_mp_rank_00_optim_states.pt...
14: [2025-06-28 00:24:17,042] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_56_mp_rank_00_optim_states.pt...
 0: [2025-06-28 00:24:17,042] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
12: [2025-06-28 00:24:17,042] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_48_mp_rank_00_optim_states.pt...
 9: [2025-06-28 00:24:17,042] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_36_mp_rank_00_optim_states.pt...
15: [2025-06-28 00:24:17,042] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_60_mp_rank_00_optim_states.pt...
 3: [2025-06-28 00:24:17,042] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_12_mp_rank_00_optim_states.pt...
 1: [2025-06-28 00:24:17,042] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_4_mp_rank_00_optim_states.pt...
19: [2025-06-28 00:24:17,042] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_76_mp_rank_00_optim_states.pt...
25: [2025-06-28 00:24:17,042] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_100_mp_rank_00_optim_states.pt...
23: [2025-06-28 00:24:17,042] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_92_mp_rank_00_optim_states.pt...
28: [2025-06-28 00:24:17,042] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_112_mp_rank_00_optim_states.pt...
22: [2025-06-28 00:24:17,042] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_88_mp_rank_00_optim_states.pt...
31: [2025-06-28 00:24:17,042] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_124_mp_rank_00_optim_states.pt...
10: [2025-06-28 00:24:17,042] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_40_mp_rank_00_optim_states.pt...
 2: [2025-06-28 00:24:17,042] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_8_mp_rank_00_optim_states.pt...
16: [2025-06-28 00:24:17,042] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_64_mp_rank_00_optim_states.pt...
13: [2025-06-28 00:24:17,042] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_52_mp_rank_00_optim_states.pt...
 8: [2025-06-28 00:24:17,042] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_32_mp_rank_00_optim_states.pt...
 6: [2025-06-28 00:24:17,042] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_24_mp_rank_00_optim_states.pt...
11: [2025-06-28 00:24:17,042] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_44_mp_rank_00_optim_states.pt...
17: [2025-06-28 00:24:17,042] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_68_mp_rank_00_optim_states.pt...
20: [2025-06-28 00:24:17,042] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_80_mp_rank_00_optim_states.pt...
21: [2025-06-28 00:24:17,042] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_84_mp_rank_00_optim_states.pt...
30: [2025-06-28 00:24:17,042] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_120_mp_rank_00_optim_states.pt...
29: [2025-06-28 00:24:17,042] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_116_mp_rank_00_optim_states.pt...
24: [2025-06-28 00:24:17,042] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_96_mp_rank_00_optim_states.pt...
18: [2025-06-28 00:24:17,042] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_72_mp_rank_00_optim_states.pt...
26: [2025-06-28 00:24:17,042] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_104_mp_rank_00_optim_states.pt...
27: [2025-06-28 00:24:17,042] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_108_mp_rank_00_optim_states.pt...
 5: [2025-06-28 00:24:17,042] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_20_mp_rank_00_optim_states.pt...
 0: [2025-06-28 00:24:17,568] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
 0: [2025-06-28 00:24:17,577] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
 8: [2025-06-28 00:24:19,785] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_32_mp_rank_00_optim_states.pt.
 8: [2025-06-28 00:24:19,785] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_32_mp_rank_00_optim_states.pt
 1: [2025-06-28 00:24:19,812] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_4_mp_rank_00_optim_states.pt.
 1: [2025-06-28 00:24:19,813] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_4_mp_rank_00_optim_states.pt
15: [2025-06-28 00:24:19,812] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_60_mp_rank_00_optim_states.pt.
15: [2025-06-28 00:24:19,813] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_60_mp_rank_00_optim_states.pt
16: [2025-06-28 00:24:19,840] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_64_mp_rank_00_optim_states.pt.
16: [2025-06-28 00:24:19,840] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_64_mp_rank_00_optim_states.pt
22: [2025-06-28 00:24:19,842] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_88_mp_rank_00_optim_states.pt.
22: [2025-06-28 00:24:19,842] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_88_mp_rank_00_optim_states.pt
18: [2025-06-28 00:24:19,846] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_72_mp_rank_00_optim_states.pt.
18: [2025-06-28 00:24:19,846] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_72_mp_rank_00_optim_states.pt
13: [2025-06-28 00:24:19,851] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_52_mp_rank_00_optim_states.pt.
13: [2025-06-28 00:24:19,851] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_52_mp_rank_00_optim_states.pt
23: [2025-06-28 00:24:19,853] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_92_mp_rank_00_optim_states.pt.
23: [2025-06-28 00:24:19,854] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_92_mp_rank_00_optim_states.pt
30: [2025-06-28 00:24:19,854] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_120_mp_rank_00_optim_states.pt.
30: [2025-06-28 00:24:19,854] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_120_mp_rank_00_optim_states.pt
14: [2025-06-28 00:24:19,854] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_56_mp_rank_00_optim_states.pt.
14: [2025-06-28 00:24:19,854] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_56_mp_rank_00_optim_states.pt
10: [2025-06-28 00:24:19,852] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_40_mp_rank_00_optim_states.pt.
10: [2025-06-28 00:24:19,852] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_40_mp_rank_00_optim_states.pt
19: [2025-06-28 00:24:19,856] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_76_mp_rank_00_optim_states.pt.
19: [2025-06-28 00:24:19,856] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_76_mp_rank_00_optim_states.pt
 2: [2025-06-28 00:24:19,857] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_8_mp_rank_00_optim_states.pt.
 2: [2025-06-28 00:24:19,857] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_8_mp_rank_00_optim_states.pt
17: [2025-06-28 00:24:19,858] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_68_mp_rank_00_optim_states.pt.
17: [2025-06-28 00:24:19,858] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_68_mp_rank_00_optim_states.pt
31: [2025-06-28 00:24:19,858] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_124_mp_rank_00_optim_states.pt.
31: [2025-06-28 00:24:19,858] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_124_mp_rank_00_optim_states.pt
25: [2025-06-28 00:24:19,860] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_100_mp_rank_00_optim_states.pt.
25: [2025-06-28 00:24:19,861] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_100_mp_rank_00_optim_states.pt
11: [2025-06-28 00:24:19,862] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_44_mp_rank_00_optim_states.pt.
11: [2025-06-28 00:24:19,863] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_44_mp_rank_00_optim_states.pt
21: [2025-06-28 00:24:19,865] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_84_mp_rank_00_optim_states.pt.
21: [2025-06-28 00:24:19,865] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_84_mp_rank_00_optim_states.pt
 9: [2025-06-28 00:24:19,868] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_36_mp_rank_00_optim_states.pt.
 9: [2025-06-28 00:24:19,868] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_36_mp_rank_00_optim_states.pt
 7: [2025-06-28 00:24:19,869] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_28_mp_rank_00_optim_states.pt.
 7: [2025-06-28 00:24:19,869] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_28_mp_rank_00_optim_states.pt
 6: [2025-06-28 00:24:19,877] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_24_mp_rank_00_optim_states.pt.
 6: [2025-06-28 00:24:19,877] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_24_mp_rank_00_optim_states.pt
28: [2025-06-28 00:24:19,926] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_112_mp_rank_00_optim_states.pt.
28: [2025-06-28 00:24:19,926] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_112_mp_rank_00_optim_states.pt
26: [2025-06-28 00:24:19,934] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_104_mp_rank_00_optim_states.pt.
26: [2025-06-28 00:24:19,934] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_104_mp_rank_00_optim_states.pt
27: [2025-06-28 00:24:19,950] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_108_mp_rank_00_optim_states.pt.
27: [2025-06-28 00:24:19,951] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_108_mp_rank_00_optim_states.pt
20: [2025-06-28 00:24:19,963] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_80_mp_rank_00_optim_states.pt.
20: [2025-06-28 00:24:19,963] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_80_mp_rank_00_optim_states.pt
12: [2025-06-28 00:24:19,962] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_48_mp_rank_00_optim_states.pt.
12: [2025-06-28 00:24:19,962] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_48_mp_rank_00_optim_states.pt
 3: [2025-06-28 00:24:19,983] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_12_mp_rank_00_optim_states.pt.
 3: [2025-06-28 00:24:19,983] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_12_mp_rank_00_optim_states.pt
 4: [2025-06-28 00:24:19,983] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_16_mp_rank_00_optim_states.pt.
 4: [2025-06-28 00:24:19,984] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_16_mp_rank_00_optim_states.pt
 5: [2025-06-28 00:24:19,992] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_20_mp_rank_00_optim_states.pt.
 5: [2025-06-28 00:24:19,992] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_20_mp_rank_00_optim_states.pt
24: [2025-06-28 00:24:20,071] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_96_mp_rank_00_optim_states.pt.
24: [2025-06-28 00:24:20,071] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_96_mp_rank_00_optim_states.pt
29: [2025-06-28 00:24:20,115] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_116_mp_rank_00_optim_states.pt.
29: [2025-06-28 00:24:20,115] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/global_step1500/bf16_zero_pp_rank_116_mp_rank_00_optim_states.pt
24: [2025-06-28 00:24:20,333] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1500 is ready now!
12: [2025-06-28 00:24:20,334] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1500 is ready now!
31: [2025-06-28 00:24:20,334] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1500 is ready now!
30: [2025-06-28 00:24:20,334] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1500 is ready now!
18: [2025-06-28 00:24:20,334] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1500 is ready now!
 3: [2025-06-28 00:24:20,334] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1500 is ready now!
19: [2025-06-28 00:24:20,334] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1500 is ready now!
28: [2025-06-28 00:24:20,334] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1500 is ready now!
25: [2025-06-28 00:24:20,334] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1500 is ready now!
29: [2025-06-28 00:24:20,334] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1500 is ready now!
16: [2025-06-28 00:24:20,334] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1500 is ready now!
15: [2025-06-28 00:24:20,334] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1500 is ready now!
14: [2025-06-28 00:24:20,335] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1500 is ready now!
 7: [2025-06-28 00:24:20,334] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1500 is ready now!
23: [2025-06-28 00:24:20,335] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1500 is ready now!
27: [2025-06-28 00:24:20,335] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1500 is ready now!
 5: [2025-06-28 00:24:20,335] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1500 is ready now!
26: [2025-06-28 00:24:20,335] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1500 is ready now!
10: [2025-06-28 00:24:20,335] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1500 is ready now!
 2: [2025-06-28 00:24:20,335] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1500 is ready now!
 6: [2025-06-28 00:24:20,335] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1500 is ready now!
22: [2025-06-28 00:24:20,335] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1500 is ready now!
13: [2025-06-28 00:24:20,335] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1500 is ready now!
 4: [2025-06-28 00:24:20,335] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1500 is ready now!
20: [2025-06-28 00:24:20,335] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1500 is ready now!
 9: [2025-06-28 00:24:20,335] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1500 is ready now!
 8: [2025-06-28 00:24:20,335] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1500 is ready now!
17: [2025-06-28 00:24:20,335] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1500 is ready now!
11: [2025-06-28 00:24:20,336] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1500 is ready now!
 0: [2025-06-28 00:24:20,336] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1500 is ready now!
 1: [2025-06-28 00:24:20,337] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1500 is ready now!
21: [2025-06-28 00:24:20,338] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step1500 is ready now!
 0: [INFO|image_processing_base.py:260] 2025-06-28 00:24:20,386 >> Image processor saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/preprocessor_config.json
 0: [INFO|tokenization_utils_base.py:2510] 2025-06-28 00:24:20,388 >> tokenizer config file saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/tokenizer_config.json
 0: [INFO|tokenization_utils_base.py:2519] 2025-06-28 00:24:20,389 >> Special tokens file saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/special_tokens_map.json
 0: [INFO|processing_utils.py:648] 2025-06-28 00:24:20,977 >> chat template saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-1500/chat_template.json
 0:  34%|███▍      | 1501/4399 [3:20:57<23:27:42, 29.15s/it] 34%|███▍      | 1502/4399 [3:21:04<18:01:03, 22.39s/it] 34%|███▍      | 1503/4399 [3:21:11<14:16:11, 17.74s/it] 34%|███▍      | 1504/4399 [3:21:18<11:44:14, 14.60s/it]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
 0:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
 0: {'loss': 0.6328, 'grad_norm': 2.5867804285103007, 'learning_rate': 8.306350988554564e-06, 'epoch': 0.34}
 0:  34%|███▍      | 1505/4399 [3:21:27<10:23:50, 12.93s/it] 34%|███▍      | 1506/4399 [3:21:36<9:33:17, 11.89s/it]  34%|███▍      | 1507/4399 [3:21:48<9:21:37, 11.65s/it] 34%|███▍      | 1508/4399 [3:21:55<8:24:43, 10.48s/it] 34%|███▍      | 1509/4399 [3:22:04<7:53:27,  9.83s/it] 34%|███▍      | 1510/4399 [3:22:10<7:06:12,  8.85s/it]                                                        34%|███▍      | 1510/4399 [3:22:10<7:06:12,  8.85s/it] 34%|███▍      | 1511/4399 [3:22:16<6:28:11,  8.06s/it] 34%|███▍      | 1512/4399 [3:22:24<6:17:22,  7.84s/it] 34%|███▍      | 1513/4399 [3:22:31<6:05:33,  7.60s/it] 34%|███▍      | 1514/4399 [3:22:42<7:00:27,  8.74s/it] 34%|███▍      | 1515/4399 [3:22:52<7:19:16,  9.14s/it] 34%|███▍      | 1516/4399 [3:23:00<7:06:07,  8.87s/it] 34%|███▍      | 1517/4399 [3:23:09<7:00:51,  8.76s/it] 35%|███▍      | 1518/4399 [3:23:16<6:30:18,  8.13s/it] 35%
 0: {'loss': 0.6342, 'grad_norm': 1.9003252893291347, 'learning_rate': 8.276483892949854e-06, 'epoch': 0.35}
 0: {'loss': 0.6273, 'grad_norm': 1.5798454715624917, 'learning_rate': 8.246410480589301e-06, 'epoch': 0.35}
 0: |███▍      | 1519/4399 [3:23:21<5:45:43,  7.20s/it] 35%|███▍      | 1520/4399 [3:23:26<5:25:24,  6.78s/it]                                                        35%|███▍      | 1520/4399 [3:23:26<5:25:24,  6.78s/it] 35%|███▍      | 1521/4399 [3:23:35<5:52:28,  7.35s/it] 35%|███▍      | 1522/4399 [3:23:46<6:46:59,  8.49s/it] 35%|███▍      | 1523/4399 [3:23:58<7:33:58,  9.47s/it] 35%|███▍      | 1524/4399 [3:24:06<7:13:08,  9.04s/it] 35%|███▍      | 1525/4399 [3:24:15<7:13:30,  9.05s/it] 35%|███▍      | 1526/4399 [3:24:22<6:38:21,  8.32s/it] 35%|███▍      | 1527/4399 [3:24:29<6:21:23,  7.97s/it] 35%|███▍      | 1528/4399 [3:24:37<6:17:25,  7.89s/it] 35%|███▍      | 1529/4399 [3:24:45<6:24:34,  8.04s/it] 35%|███▍      | 1530/4399 [3:24:55<6:49:37,  8.57s/it]                                                        35%|███▍      | 1530/4399 [3:24:55<6:49:37,  8.57s/it] 35%|███▍ 
 0: {'loss': 0.631, 'grad_norm': 1.7204744544449482, 'learning_rate': 8.216132645164152e-06, 'epoch': 0.35}
 0:      | 1531/4399 [3:25:07<7:36:29,  9.55s/it] 35%|███▍      | 1532/4399 [3:25:14<7:07:37,  8.95s/it] 35%|███▍      | 1533/4399 [3:25:23<7:06:49,  8.94s/it] 35%|███▍      | 1534/4399 [3:25:29<6:19:57,  7.96s/it] 35%|███▍      | 1535/4399 [3:25:35<5:51:00,  7.35s/it] 35%|███▍      | 1536/4399 [3:25:41<5:34:36,  7.01s/it] 35%|███▍      | 1537/4399 [3:25:48<5:41:45,  7.16s/it] 35%|███▍      | 1538/4399 [3:26:00<6:43:13,  8.46s/it] 35%|███▍      | 1539/4399 [3:26:11<7:18:47,  9.21s/it] 35%|███▌      | 1540/4399 [3:26:19<7:03:53,  8.90s/it]                                                        35%|███▌      | 1540/4399 [3:26:19<7:03:53,  8.90s/it] 35%|███▌      | 1541/4399 [3:26:26<6:39:05,  8.38s/it] 35%|███▌      | 1542/4399 [3:26:33<6:14:10,  7.86s/it] 35%|███▌      | 1543/4399 [3:26:39<5:45:58,  7.27s/it] 35%|███▌      | 1544/4399 [3:26:46<5:46:26,  7.28s/it] 35%|███▌      | 
 0: {'loss': 0.6131, 'grad_norm': 2.662934229573933, 'learning_rate': 8.185652293237962e-06, 'epoch': 0.35}
 0: 1545/4399 [3:26:55<6:11:39,  7.81s/it] 35%|███▌      | 1546/4399 [3:27:05<6:34:22,  8.29s/it] 35%|███▌      | 1547/4399 [3:27:16<7:18:03,  9.22s/it] 35%|███▌      | 1548/4399 [3:27:25<7:18:04,  9.22s/it] 35%|███▌      | 1549/4399 [3:27:32<6:44:50,  8.52s/it] 35%|███▌      | 1550/4399 [3:27:40<6:31:25,  8.24s/it]                                                        35%|███▌      | 1550/4399 [3:27:40<6:31:25,  8.24s/it] 35%|███▌      | 1551/4399 [3:27:46<5:58:56,  7.56s/it] 35%|███▌      | 1552/4399 [3:27:53<5:50:07,  7.38s/it] 35%|███▌      | 1553/4399 [3:28:01<6:03:45,  7.67s/it] 35%|███▌      | 1554/4399 [3:28:10<6:26:17,  8.15s/it] 35%|███▌      | 1555/4399 [3:28:22<7:20:04,  9.28s/it] 35%|███▌      | 1556/4399 [3:28:31<7:10:23,  9.08s/it] 35%|███▌      | 1557/4399 [3:28:39<6:52:36,  8.71s/it] 35%|███▌      | 1558/4399 [3:28:44<6:06:19,  7.74s/it] 35%|███▌      | 1559/43
 0: {'loss': 0.6216, 'grad_norm': 1.660900253135219, 'learning_rate': 8.154971344126537e-06, 'epoch': 0.35}
 0: {'loss': 0.6286, 'grad_norm': 1.498297161980424, 'learning_rate': 8.12409172977708e-06, 'epoch': 0.36}
 0: 99 [3:28:50<5:42:38,  7.24s/it] 35%|███▌      | 1560/4399 [3:28:58<5:58:04,  7.57s/it]                                                        35%|███▌      | 1560/4399 [3:28:58<5:58:04,  7.57s/it] 35%|███▌      | 1561/4399 [3:29:07<6:10:56,  7.84s/it] 36%|███▌      | 1562/4399 [3:29:17<6:38:29,  8.43s/it] 36%|███▌      | 1563/4399 [3:29:26<6:50:25,  8.68s/it] 36%|███▌      | 1564/4399 [3:29:35<7:02:14,  8.94s/it] 36%|███▌      | 1565/4399 [3:29:43<6:46:30,  8.61s/it] 36%|███▌      | 1566/4399 [3:29:50<6:15:02,  7.94s/it] 36%|███▌      | 1567/4399 [3:29:55<5:37:08,  7.14s/it] 36%|███▌      | 1568/4399 [3:30:01<5:23:53,  6.86s/it] 36%|███▌      | 1569/4399 [3:30:10<5:45:23,  7.32s/it] 36%|███▌      | 1570/4399 [3:30:20<6:30:40,  8.29s/it]                                                        36%|███▌      | 1570/4399 [3:30:20<6:30:40,  8.29s/it] 36%|███▌      | 1571/4399 [3:30:30<6:
 0: {'loss': 0.6193, 'grad_norm': 1.5982264981387908, 'learning_rate': 8.093015394646531e-06, 'epoch': 0.36}
 0: 58:56,  8.89s/it] 36%|███▌      | 1572/4399 [3:30:41<7:23:36,  9.42s/it] 36%|███▌      | 1573/4399 [3:30:48<6:52:22,  8.76s/it] 36%|███▌      | 1574/4399 [3:30:55<6:23:55,  8.15s/it] 36%|███▌      | 1575/4399 [3:31:00<5:39:44,  7.22s/it] 36%|███▌      | 1576/4399 [3:31:07<5:35:03,  7.12s/it] 36%|███▌      | 1577/4399 [3:31:16<6:02:25,  7.71s/it] 36%|███▌      | 1578/4399 [3:31:26<6:30:41,  8.31s/it] 36%|███▌      | 1579/4399 [3:31:36<7:01:09,  8.96s/it] 36%|███▌      | 1580/4399 [3:31:47<7:21:12,  9.39s/it]                                                        36%|███▌      | 1580/4399 [3:31:47<7:21:12,  9.39s/it] 36%|███▌      | 1581/4399 [3:31:55<7:02:49,  9.00s/it] 36%|███▌      | 1582/4399 [3:32:01<6:28:54,  8.28s/it] 36%|███▌      | 1583/4399 [3:32:09<6:13:10,  7.95s/it] 36%|███▌      | 1584/4399 [3:32:15<5:58:33,  7.64s/it] 36%|███▌      | 1585/4399 [3:32:24<6:08:02, 
 0: {'loss': 0.6256, 'grad_norm': 1.8146850597163542, 'learning_rate': 8.061744295579138e-06, 'epoch': 0.36}
 0:  7.85s/it] 36%|███▌      | 1586/4399 [3:32:35<6:53:42,  8.82s/it] 36%|███▌      | 1587/4399 [3:32:45<7:15:16,  9.29s/it] 36%|███▌      | 1588/4399 [3:32:54<7:12:13,  9.23s/it] 36%|███▌      | 1589/4399 [3:33:02<6:51:56,  8.80s/it] 36%|███▌      | 1590/4399 [3:33:09<6:26:47,  8.26s/it]                                                        36%|███▌      | 1590/4399 [3:33:09<6:26:47,  8.26s/it] 36%|███▌      | 1591/4399 [3:33:16<6:08:14,  7.87s/it] 36%|███▌      | 1592/4399 [3:33:24<6:05:53,  7.82s/it] 36%|███▌      | 1593/4399 [3:33:31<6:01:02,  7.72s/it] 36%|███▌      | 1594/4399 [3:33:40<6:14:12,  8.00s/it] 36%|███▋      | 1595/4399 [3:33:50<6:44:12,  8.65s/it] 36%|███▋      | 1596/4399 [3:33:59<6:52:33,  8.83s/it] 36%|███▋      | 1597/4399 [3:34:07<6:39:18,  8.55s/it] 36%|███▋      | 1598/4399 [3:34:15<6:25:50,  8.27s/it] 36%|███▋      | 1599/4399 [3:34:21<6:00:25,  7.72s/
 0: {'loss': 0.6215, 'grad_norm': 1.843909229135045, 'learning_rate': 8.030280401683226e-06, 'epoch': 0.36}
 0: {'loss': 0.6254, 'grad_norm': 1.5956045834428667, 'learning_rate': 7.998625694207206e-06, 'epoch': 0.37}
 0: it] 36%|███▋      | 1600/4399 [3:34:28<5:50:46,  7.52s/it]                                                        36%|███▋      | 1600/4399 [3:34:28<5:50:46,  7.52s/it] 36%|███▋      | 1601/4399 [3:34:37<6:07:30,  7.88s/it] 36%|███▋      | 1602/4399 [3:34:46<6:27:06,  8.30s/it] 36%|███▋      | 1603/4399 [3:34:56<6:45:31,  8.70s/it] 36%|███▋      | 1604/4399 [3:35:04<6:37:29,  8.53s/it] 36%|███▋      | 1605/4399 [3:35:11<6:13:40,  8.02s/it] 37%|███▋      | 1606/4399 [3:35:17<5:40:56,  7.32s/it] 37%|███▋      | 1607/4399 [3:35:23<5:27:07,  7.03s/it] 37%|███▋      | 1608/4399 [3:35:29<5:07:00,  6.60s/it] 37%|███▋      | 1609/4399 [3:35:36<5:18:42,  6.85s/it] 37%|███▋      | 1610/4399 [3:35:46<6:08:23,  7.93s/it]                                                        37%|███▋      | 1610/4399 [3:35:46<6:08:23,  7.93s/it] 37%|███▋      | 1611/4399 [3:35:58<6:56:11,  8.96s/it] 37%|█
 0: {'loss': 0.6178, 'grad_norm': 1.6734507694226708, 'learning_rate': 7.966782166414822e-06, 'epoch': 0.37}
 0: █▋      | 1612/4399 [3:36:06<6:50:57,  8.85s/it] 37%|███▋      | 1613/4399 [3:36:14<6:37:12,  8.55s/it] 37%|███▋      | 1614/4399 [3:36:20<5:59:13,  7.74s/it] 37%|███▋      | 1615/4399 [3:36:26<5:36:34,  7.25s/it] 37%|███▋      | 1616/4399 [3:36:34<5:40:06,  7.33s/it] 37%|███▋      | 1617/4399 [3:36:42<5:52:52,  7.61s/it] 37%|███▋      | 1618/4399 [3:36:53<6:36:01,  8.54s/it] 37%|███▋      | 1619/4399 [3:37:03<7:01:26,  9.10s/it] 37%|███▋      | 1620/4399 [3:37:13<7:10:48,  9.30s/it]                                                        37%|███▋      | 1620/4399 [3:37:13<7:10:48,  9.30s/it] 37%|███▋      | 1621/4399 [3:37:21<6:59:38,  9.06s/it] 37%|███▋      | 1622/4399 [3:37:29<6:38:31,  8.61s/it] 37%|███▋      | 1623/4399 [3:37:35<6:03:52,  7.86s/it] 37%|███▋      | 1624/4399 [3:37:41<5:35:09,  7.25s/it] 37%|███▋      | 1625/4399 [3:37:49<5:52:37,  7.63s/it] 37%|███▋
 0: {'loss': 0.6339, 'grad_norm': 1.5097493451618398, 'learning_rate': 7.934751823459639e-06, 'epoch': 0.37}
 0:       | 1626/4399 [3:37:59<6:16:44,  8.15s/it] 37%|███▋      | 1627/4399 [3:38:09<6:49:13,  8.86s/it] 37%|███▋      | 1628/4399 [3:38:18<6:45:40,  8.78s/it] 37%|███▋      | 1629/4399 [3:38:27<6:43:10,  8.73s/it] 37%|███▋      | 1630/4399 [3:38:33<6:13:46,  8.10s/it]                                                        37%|███▋      | 1630/4399 [3:38:33<6:13:46,  8.10s/it] 37%|███▋      | 1631/4399 [3:38:40<5:50:32,  7.60s/it] 37%|███▋      | 1632/4399 [3:38:46<5:36:46,  7.30s/it] 37%|███▋      | 1633/4399 [3:38:53<5:32:27,  7.21s/it] 37%|███▋      | 1634/4399 [3:39:02<5:58:54,  7.79s/it] 37%|███▋      | 1635/4399 [3:39:13<6:32:39,  8.52s/it] 37%|███▋      | 1636/4399 [3:39:22<6:47:31,  8.85s/it] 37%|███▋      | 1637/4399 [3:39:30<6:28:57,  8.45s/it] 37%|███▋      | 1638/4399 [3:39:36<6:04:56,  7.93s/it] 37%|███▋      | 1639/4399 [3:39:42<5:37:45,  7.34s/it] 37%|███▋      |
 0: {'loss': 0.6148, 'grad_norm': 1.6710762426409287, 'learning_rate': 7.902536682258775e-06, 'epoch': 0.37}
 0: {'loss': 0.6121, 'grad_norm': 1.616519234324832, 'learning_rate': 7.870138771365893e-06, 'epoch': 0.38}
 0:  1640/4399 [3:39:49<5:29:38,  7.17s/it]                                                        37%|███▋      | 1640/4399 [3:39:49<5:29:38,  7.17s/it] 37%|███▋      | 1641/4399 [3:39:57<5:43:33,  7.47s/it] 37%|███▋      | 1642/4399 [3:40:07<6:18:19,  8.23s/it] 37%|███▋      | 1643/4399 [3:40:17<6:33:15,  8.56s/it] 37%|███▋      | 1644/4399 [3:40:27<6:58:57,  9.12s/it] 37%|███▋      | 1645/4399 [3:40:35<6:42:25,  8.77s/it] 37%|███▋      | 1646/4399 [3:40:43<6:24:44,  8.39s/it] 37%|███▋      | 1647/4399 [3:40:49<6:00:46,  7.87s/it] 37%|███▋      | 1648/4399 [3:40:56<5:44:15,  7.51s/it] 37%|███▋      | 1649/4399 [3:41:04<5:52:08,  7.68s/it] 38%|███▊      | 1650/4399 [3:41:14<6:24:07,  8.38s/it]                                                        38%|███▊      | 1650/4399 [3:41:14<6:24:07,  8.38s/it] 38%|███▊      | 1651/4399 [3:41:23<6:39:46,  8.73s/it] 38%|███▊      | 1652/4399 [3:
 0: {'loss': 0.6297, 'grad_norm': 1.5584877714098937, 'learning_rate': 7.837560130843483e-06, 'epoch': 0.38}
 0: 41:32<6:35:49,  8.65s/it] 38%|███▊      | 1653/4399 [3:41:41<6:37:39,  8.69s/it] 38%|███▊      | 1654/4399 [3:41:48<6:12:03,  8.13s/it] 38%|███▊      | 1655/4399 [3:41:54<5:42:40,  7.49s/it] 38%|███▊      | 1656/4399 [3:41:59<5:17:37,  6.95s/it] 38%|███▊      | 1657/4399 [3:42:08<5:42:15,  7.49s/it] 38%|███▊      | 1658/4399 [3:42:19<6:32:11,  8.59s/it] 38%|███▊      | 1659/4399 [3:42:30<6:59:58,  9.20s/it] 38%|███▊      | 1660/4399 [3:42:40<7:11:06,  9.44s/it]                                                        38%|███▊      | 1660/4399 [3:42:40<7:11:06,  9.44s/it] 38%|███▊      | 1661/4399 [3:42:47<6:34:59,  8.66s/it] 38%|███▊      | 1662/4399 [3:42:53<6:01:39,  7.93s/it] 38%|███▊      | 1663/4399 [3:42:58<5:25:28,  7.14s/it] 38%|███▊      | 1664/4399 [3:43:05<5:27:18,  7.18s/it] 38%|███▊      | 1665/4399 [3:43:16<6:09:32,  8.11s/it] 38%|███▊      | 1666/4399 [3:43:27<6
 0: {'loss': 0.6273, 'grad_norm': 1.818365377816844, 'learning_rate': 7.804802812134384e-06, 'epoch': 0.38}
 0: :49:50,  9.00s/it] 38%|███▊      | 1667/4399 [3:43:37<7:07:06,  9.38s/it] 38%|███▊      | 1668/4399 [3:43:46<6:58:59,  9.21s/it] 38%|███▊      | 1669/4399 [3:43:53<6:30:41,  8.59s/it] 38%|███▊      | 1670/4399 [3:44:00<6:05:18,  8.03s/it]                                                        38%|███▊      | 1670/4399 [3:44:00<6:05:18,  8.03s/it] 38%|███▊      | 1671/4399 [3:44:06<5:40:22,  7.49s/it] 38%|███▊      | 1672/4399 [3:44:12<5:14:32,  6.92s/it] 38%|███▊      | 1673/4399 [3:44:20<5:33:25,  7.34s/it] 38%|███▊      | 1674/4399 [3:44:29<5:59:15,  7.91s/it] 38%|███▊      | 1675/4399 [3:44:40<6:40:43,  8.83s/it] 38%|███▊      | 1676/4399 [3:44:50<6:58:34,  9.22s/it] 38%|███▊      | 1677/4399 [3:44:58<6:32:44,  8.66s/it] 38%|███▊      | 1678/4399 [3:45:04<6:09:41,  8.15s/it] 38%|███▊      | 1679/4399 [3:45:10<5:30:19,  7.29s/it] 38%|███▊      | 1680/4399 [3:45:17<5:32:39,
 0: {'loss': 0.6279, 'grad_norm': 1.7916978405761252, 'learning_rate': 7.771868877932611e-06, 'epoch': 0.38}
 0: {'loss': 0.622, 'grad_norm': 1.5977103551432394, 'learning_rate': 7.738760402053479e-06, 'epoch': 0.38}
 0:   7.34s/it]                                                        38%|███▊      | 1680/4399 [3:45:17<5:32:39,  7.34s/it] 38%|███▊      | 1681/4399 [3:45:25<5:40:00,  7.51s/it] 38%|███▊      | 1682/4399 [3:45:33<5:48:01,  7.69s/it] 38%|███▊      | 1683/4399 [3:45:45<6:40:43,  8.85s/it] 38%|███▊      | 1684/4399 [3:45:54<6:45:31,  8.96s/it] 38%|███▊      | 1685/4399 [3:46:01<6:20:13,  8.41s/it] 38%|███▊      | 1686/4399 [3:46:07<5:48:11,  7.70s/it] 38%|███▊      | 1687/4399 [3:46:13<5:17:46,  7.03s/it] 38%|███▊      | 1688/4399 [3:46:20<5:26:36,  7.23s/it] 38%|███▊      | 1689/4399 [3:46:28<5:28:45,  7.28s/it] 38%|███▊      | 1690/4399 [3:46:38<6:09:58,  8.19s/it]                                                        38%|███▊      | 1690/4399 [3:46:38<6:09:58,  8.19s/it] 38%|███▊      | 1691/4399 [3:46:48<6:31:08,  8.67s/it] 38%|███▊      | 1692/4399 [3:46:59<7:02:04,  9.36s/it] 3
 0: {'loss': 0.6304, 'grad_norm': 1.5745559332160304, 'learning_rate': 7.705479469303e-06, 'epoch': 0.39}
 0: 8%|███▊      | 1693/4399 [3:47:06<6:31:16,  8.68s/it] 39%|███▊      | 1694/4399 [3:47:13<6:10:05,  8.21s/it] 39%|███▊      | 1695/4399 [3:47:18<5:30:13,  7.33s/it] 39%|███▊      | 1696/4399 [3:47:25<5:20:10,  7.11s/it] 39%|███▊      | 1697/4399 [3:47:32<5:22:26,  7.16s/it] 39%|███▊      | 1698/4399 [3:47:42<6:01:52,  8.04s/it] 39%|███▊      | 1699/4399 [3:47:53<6:37:44,  8.84s/it] 39%|███▊      | 1700/4399 [3:48:04<7:11:30,  9.59s/it]                                                        39%|███▊      | 1700/4399 [3:48:04<7:11:30,  9.59s/it] 39%|███▊      | 1701/4399 [3:48:11<6:34:16,  8.77s/it] 39%|███▊      | 1702/4399 [3:48:18<6:11:45,  8.27s/it] 39%|███▊      | 1703/4399 [3:48:26<5:58:36,  7.98s/it] 39%|███▊      | 1704/4399 [3:48:31<5:24:29,  7.22s/it] 39%|███▉      | 1705/4399 [3:48:39<5:37:01,  7.51s/it] 39%|███▉      | 1706/4399 [3:48:50<6:22:31,  8.52s/it] 39%|█
 0: {'loss': 0.618, 'grad_norm': 1.6246175951328776, 'learning_rate': 7.672028175346627e-06, 'epoch': 0.39}
 0: █▉      | 1707/4399 [3:49:02<7:02:35,  9.42s/it] 39%|███▉      | 1708/4399 [3:49:11<7:03:15,  9.44s/it] 39%|███▉      | 1709/4399 [3:49:18<6:30:47,  8.72s/it] 39%|███▉      | 1710/4399 [3:49:24<5:58:42,  8.00s/it]                                                        39%|███▉      | 1710/4399 [3:49:24<5:58:42,  8.00s/it] 39%|███▉      | 1711/4399 [3:49:31<5:37:50,  7.54s/it] 39%|███▉      | 1712/4399 [3:49:37<5:21:32,  7.18s/it] 39%|███▉      | 1713/4399 [3:49:46<5:38:18,  7.56s/it] 39%|███▉      | 1714/4399 [3:49:57<6:25:59,  8.63s/it] 39%|███▉      | 1715/4399 [3:50:06<6:33:59,  8.81s/it] 39%|███▉      | 1716/4399 [3:50:16<6:50:15,  9.17s/it] 39%|███▉      | 1717/4399 [3:50:25<6:42:59,  9.02s/it] 39%|███▉      | 1718/4399 [3:50:31<6:00:35,  8.07s/it] 39%|███▉      | 1719/4399 [3:50:37<5:39:24,  7.60s/it] 39%|███▉      | 1720/4399 [3:50:42<5:10:12,  6.95s/it]                
 0: {'loss': 0.6231, 'grad_norm': 1.7667937874125332, 'learning_rate': 7.638408626577262e-06, 'epoch': 0.39}
 0: {'loss': 0.6166, 'grad_norm': 1.5628655370767195, 'learning_rate': 7.604622939982653e-06, 'epoch': 0.39}
 0:                                         39%|███▉      | 1720/4399 [3:50:43<5:10:12,  6.95s/it] 39%|███▉      | 1721/4399 [3:50:49<5:07:50,  6.90s/it] 39%|███▉      | 1722/4399 [3:51:00<5:52:44,  7.91s/it] 39%|███▉      | 1723/4399 [3:51:09<6:17:49,  8.47s/it] 39%|███▉      | 1724/4399 [3:51:19<6:32:11,  8.80s/it] 39%|███▉      | 1725/4399 [3:51:28<6:30:39,  8.77s/it] 39%|███▉      | 1726/4399 [3:51:35<6:07:26,  8.25s/it] 39%|███▉      | 1727/4399 [3:51:40<5:33:29,  7.49s/it] 39%|███▉      | 1728/4399 [3:51:46<5:05:46,  6.87s/it] 39%|███▉      | 1729/4399 [3:51:53<5:05:20,  6.86s/it] 39%|███▉      | 1730/4399 [3:52:03<5:54:19,  7.97s/it]                                                        39%|███▉      | 1730/4399 [3:52:03<5:54:19,  7.97s/it] 39%|███▉      | 1731/4399 [3:52:12<6:07:11,  8.26s/it] 39%|███▉      | 1732/4399 [3:52:22<6:29:32,  8.76s/it] 39%|███▉      | 1733/
 0: {'loss': 0.6068, 'grad_norm': 1.6659048329706612, 'learning_rate': 7.570673243012062e-06, 'epoch': 0.4}
 0: 4399 [3:52:29<6:09:42,  8.32s/it] 39%|███▉      | 1734/4399 [3:52:36<5:54:08,  7.97s/it] 39%|███▉      | 1735/4399 [3:52:42<5:18:24,  7.17s/it] 39%|███▉      | 1736/4399 [3:52:47<4:53:03,  6.60s/it] 39%|███▉      | 1737/4399 [3:52:54<5:00:59,  6.78s/it] 40%|███▉      | 1738/4399 [3:53:04<5:33:54,  7.53s/it] 40%|███▉      | 1739/4399 [3:53:12<5:49:35,  7.89s/it] 40%|███▉      | 1740/4399 [3:53:22<6:15:29,  8.47s/it]                                                        40%|███▉      | 1740/4399 [3:53:22<6:15:29,  8.47s/it] 40%|███▉      | 1741/4399 [3:53:30<6:10:24,  8.36s/it] 40%|███▉      | 1742/4399 [3:53:38<5:56:41,  8.05s/it] 40%|███▉      | 1743/4399 [3:53:45<5:47:13,  7.84s/it] 40%|███▉      | 1744/4399 [3:53:51<5:26:55,  7.39s/it] 40%|███▉      | 1745/4399 [3:54:00<5:40:02,  7.69s/it] 40%|███▉      | 1746/4399 [3:54:11<6:25:27,  8.72s/it] 40%|███▉      | 1747/4399 [3
 0: {'loss': 0.6209, 'grad_norm': 1.6593852792082144, 'learning_rate': 7.53656167344232e-06, 'epoch': 0.4}
 0: :54:20<6:26:38,  8.75s/it] 40%|███▉      | 1748/4399 [3:54:31<6:58:53,  9.48s/it] 40%|███▉      | 1749/4399 [3:54:38<6:29:46,  8.83s/it] 40%|███▉      | 1750/4399 [3:54:46<6:15:30,  8.51s/it]                                                        40%|███▉      | 1750/4399 [3:54:46<6:15:30,  8.51s/it] 40%|███▉      | 1751/4399 [3:54:52<5:47:33,  7.88s/it] 40%|███▉      | 1752/4399 [3:54:57<5:12:43,  7.09s/it] 40%|███▉      | 1753/4399 [3:55:07<5:41:24,  7.74s/it] 40%|███▉      | 1754/4399 [3:55:18<6:31:08,  8.87s/it] 40%|███▉      | 1755/4399 [3:55:28<6:47:27,  9.25s/it] 40%|███▉      | 1756/4399 [3:55:38<6:51:59,  9.35s/it] 40%|███▉      | 1757/4399 [3:55:46<6:40:18,  9.09s/it] 40%|███▉      | 1758/4399 [3:55:53<6:12:57,  8.47s/it] 40%|███▉      | 1759/4399 [3:55:59<5:33:12,  7.57s/it] 40%|████      | 1760/4399 [3:56:04<5:00:24,  6.83s/it]                                            
 0: {'loss': 0.6171, 'grad_norm': 1.752970945454123, 'learning_rate': 7.502290379243197e-06, 'epoch': 0.4}
 0: {'loss': 0.619, 'grad_norm': 1.6089449465908787, 'learning_rate': 7.467861518442164e-06, 'epoch': 0.4}
 0:             40%|████      | 1760/4399 [3:56:04<5:00:24,  6.83s/it] 40%|████      | 1761/4399 [3:56:11<4:57:00,  6.76s/it] 40%|████      | 1762/4399 [3:56:21<5:43:48,  7.82s/it] 40%|████      | 1763/4399 [3:56:30<6:01:05,  8.22s/it] 40%|████      | 1764/4399 [3:56:40<6:20:19,  8.66s/it] 40%|████      | 1765/4399 [3:56:49<6:27:21,  8.82s/it] 40%|████      | 1766/4399 [3:56:55<5:52:22,  8.03s/it] 40%|████      | 1767/4399 [3:57:01<5:18:30,  7.26s/it] 40%|████      | 1768/4399 [3:57:07<5:03:39,  6.92s/it] 40%|████      | 1769/4399 [3:57:14<5:12:58,  7.14s/it] 40%|████      | 1770/4399 [3:57:23<5:31:59,  7.58s/it]                                                        40%|████      | 1770/4399 [3:57:23<5:31:59,  7.58s/it] 40%|████      | 1771/4399 [3:57:33<6:10:23,  8.46s/it] 40%|████      | 1772/4399 [3:57:42<6:16:40,  8.60s/it] 40%|████      | 1773/4399 [3:57:52<6:28:47,  8.88
 0: {'loss': 0.6295, 'grad_norm': 1.4237020322785707, 'learning_rate': 7.433277258988492e-06, 'epoch': 0.4}
 0: s/it] 40%|████      | 1774/4399 [3:58:00<6:17:57,  8.64s/it] 40%|████      | 1775/4399 [3:58:06<5:48:57,  7.98s/it] 40%|████      | 1776/4399 [3:58:14<5:37:42,  7.73s/it] 40%|████      | 1777/4399 [3:58:20<5:25:30,  7.45s/it] 40%|████      | 1778/4399 [3:58:29<5:46:35,  7.93s/it] 40%|████      | 1779/4399 [3:58:39<6:11:03,  8.50s/it] 40%|████      | 1780/4399 [3:58:49<6:22:56,  8.77s/it]                                                        40%|████      | 1780/4399 [3:58:49<6:22:56,  8.77s/it] 40%|████      | 1781/4399 [3:58:57<6:12:22,  8.53s/it] 41%|████      | 1782/4399 [3:59:04<6:00:03,  8.26s/it] 41%|████      | 1783/4399 [3:59:11<5:35:32,  7.70s/it] 41%|████      | 1784/4399 [3:59:17<5:13:48,  7.20s/it] 41%|████      | 1785/4399 [3:59:23<5:04:22,  6.99s/it] 41%|████      | 1786/4399 [3:59:33<5:45:51,  7.94s/it] 41%|████      | 1787/4399 [3:59:43<6:02:48,  8.33s/it] 
 0: {'loss': 0.6126, 'grad_norm': 2.4736175951169996, 'learning_rate': 7.398539778616742e-06, 'epoch': 0.41}
 0: {'loss': 0.6213, 'grad_norm': 1.6361927980873048, 'learning_rate': 7.363651264709635e-06, 'epoch': 0.41}
 0: 41%|████      | 1788/4399 [3:59:52<6:15:19,  8.62s/it] 41%|████      | 1789/4399 [4:00:02<6:33:00,  9.03s/it] 41%|████      | 1790/4399 [4:00:10<6:20:47,  8.76s/it]                                                        41%|████      | 1790/4399 [4:00:10<6:20:47,  8.76s/it] 41%|████      | 1791/4399 [4:00:16<5:38:00,  7.78s/it] 41%|████      | 1792/4399 [4:00:22<5:16:46,  7.29s/it] 41%|████      | 1793/4399 [4:00:28<5:06:40,  7.06s/it] 41%|████      | 1794/4399 [4:00:37<5:31:01,  7.62s/it] 41%|████      | 1795/4399 [4:00:47<5:55:16,  8.19s/it] 41%|████      | 1796/4399 [4:00:56<6:15:48,  8.66s/it] 41%|████      | 1797/4399 [4:01:04<6:05:21,  8.42s/it] 41%|████      | 1798/4399 [4:01:12<6:00:49,  8.32s/it] 41%|████      | 1799/4399 [4:01:18<5:31:06,  7.64s/it] 41%|████      | 1800/4399 [4:01:25<5:19:18,  7.37s/it]                                                        41%|███
 0: {'loss': 0.598, 'grad_norm': 1.580375097031124, 'learning_rate': 7.328613914160319e-06, 'epoch': 0.41}
 0:       | 1800/4399 [4:01:25<5:19:18,  7.37s/it] 41%|████      | 1801/4399 [4:01:32<5:16:12,  7.30s/it] 41%|████      | 1802/4399 [4:01:41<5:31:28,  7.66s/it] 41%|████      | 1803/4399 [4:01:50<5:54:59,  8.20s/it] 41%|████      | 1804/4399 [4:01:59<6:03:36,  8.41s/it] 41%|████      | 1805/4399 [4:02:07<5:53:42,  8.18s/it] 41%|████      | 1806/4399 [4:02:14<5:46:51,  8.03s/it] 41%|████      | 1807/4399 [4:02:20<5:11:42,  7.22s/it] 41%|████      | 1808/4399 [4:02:26<5:01:11,  6.97s/it] 41%|████      | 1809/4399 [4:02:33<5:03:45,  7.04s/it] 41%|████      | 1810/4399 [4:02:44<5:49:05,  8.09s/it]                                                        41%|████      | 1810/4399 [4:02:44<5:49:05,  8.09s/it] 41%|████      | 1811/4399 [4:02:55<6:28:05,  9.00s/it] 41%|████      | 1812/4399 [4:03:04<6:27:32,  8.99s/it] 41%|████      | 1813/4399 [4:03:12<6:13:04,  8.66s/it] 41%|████     
 0: {'loss': 0.6182, 'grad_norm': 1.7782256814155735, 'learning_rate': 7.293429933234023e-06, 'epoch': 0.41}
 0:  | 1814/4399 [4:03:19<5:46:43,  8.05s/it] 41%|████▏     | 1815/4399 [4:03:24<5:10:18,  7.21s/it] 41%|████▏     | 1816/4399 [4:03:30<4:57:07,  6.90s/it] 41%|████▏     | 1817/4399 [4:03:37<5:01:28,  7.01s/it] 41%|████▏     | 1818/4399 [4:03:47<5:36:59,  7.83s/it] 41%|████▏     | 1819/4399 [4:03:57<6:09:29,  8.59s/it] 41%|████▏     | 1820/4399 [4:04:07<6:20:36,  8.85s/it]                                                        41%|████▏     | 1820/4399 [4:04:07<6:20:36,  8.85s/it] 41%|████▏     | 1821/4399 [4:04:15<6:11:48,  8.65s/it] 41%|████▏     | 1822/4399 [4:04:23<6:07:21,  8.55s/it] 41%|████▏     | 1823/4399 [4:04:30<5:49:29,  8.14s/it] 41%|████▏     | 1824/4399 [4:04:36<5:17:27,  7.40s/it] 41%|████▏     | 1825/4399 [4:04:42<5:01:50,  7.04s/it] 42%|████▏     | 1826/4399 [4:04:51<5:29:02,  7.67s/it] 42%|████▏     | 1827/4399 [4:05:04<6:26:49,  9.02s/it] 
 0: {'loss': 0.6131, 'grad_norm': 2.1771026358082928, 'learning_rate': 7.258101537429145e-06, 'epoch': 0.42}
 0: 42%|████▏     | 1828/4399 [4:05:13<6:30:44,  9.12s/it] 42%|████▏     | 1829/4399 [4:05:23<6:37:55,  9.29s/it] 42%|████▏     | 1830/4399 [4:05:29<5:58:45,  8.38s/it]                                                        42%|████▏     | 1830/4399 [4:05:29<5:58:45,  8.38s/it] 42%|████▏     | 1831/4399 [4:05:35<5:22:45,  7.54s/it] 42%|████▏     | 1832/4399 [4:05:41<5:02:49,  7.08s/it] 42%|████▏     | 1833/4399 [4:05:48<5:01:22,  7.05s/it] 42%|████▏     | 1834/4399 [4:05:57<5:36:56,  7.88s/it] 42%|████▏     | 1835/4399 [4:06:07<5:59:34,  8.41s/it] 42%|████▏     | 1836/4399 [4:06:18<6:28:12,  9.09s/it] 42%|████▏     | 1837/4399 [4:06:28<6:48:52,  9.58s/it] 42%|████▏     | 1838/4399 [4:06:36<6:28:22,  9.10s/it] 42%|████▏     | 1839/4399 [4:06:42<5:39:43,  7.96s/it] 42%|████▏     | 1840/4399 [4:06:49<5:35:53,  7.88s/it]                                            
 0: {'loss': 0.6185, 'grad_norm': 1.948613837063119, 'learning_rate': 7.222630951337729e-06, 'epoch': 0.42}
 0: {'loss': 0.615, 'grad_norm': 2.110798803904155, 'learning_rate': 7.187020408505399e-06, 'epoch': 0.42}
 0:             42%|████▏     | 1840/4399 [4:06:49<5:35:53,  7.88s/it] 42%|████▏     | 1841/4399 [4:06:57<5:29:00,  7.72s/it] 42%|████▏     | 1842/4399 [4:07:05<5:40:00,  7.98s/it] 42%|████▏     | 1843/4399 [4:07:16<6:19:46,  8.91s/it] 42%|████▏     | 1844/4399 [4:07:26<6:26:31,  9.08s/it] 42%|████▏     | 1845/4399 [4:07:34<6:19:30,  8.92s/it] 42%|████▏     | 1846/4399 [4:07:41<5:46:22,  8.14s/it] 42%|████▏     | 1847/4399 [4:07:46<5:09:09,  7.27s/it] 42%|████▏     | 1848/4399 [4:07:52<4:48:28,  6.79s/it] 42%|████▏     | 1849/4399 [4:07:58<4:40:32,  6.60s/it] 42%|████▏     | 1850/4399 [4:08:08<5:21:50,  7.58s/it]                                                        42%|████▏     | 1850/4399 [4:08:08<5:21:50,  7.58s/it] 42%|████▏     | 1851/4399 [4:08:18<5:57:53,  8.43s/it] 42%|████▏     | 1852/4399 [4:08:28<6:14:19,  8.82s/it] 42%|████▏     | 185
 0: {'loss': 0.6099, 'grad_norm': 1.6088870079532525, 'learning_rate': 7.1512721512907025e-06, 'epoch': 0.42}
 0: 3/4399 [4:08:38<6:28:42,  9.16s/it] 42%|████▏     | 1854/4399 [4:08:44<5:55:35,  8.38s/it] 42%|████▏     | 1855/4399 [4:08:50<5:20:00,  7.55s/it] 42%|████▏     | 1856/4399 [4:08:56<5:00:41,  7.09s/it] 42%|████▏     | 1857/4399 [4:09:03<5:02:00,  7.13s/it] 42%|████▏     | 1858/4399 [4:09:12<5:19:21,  7.54s/it] 42%|████▏     | 1859/4399 [4:09:22<5:51:46,  8.31s/it] 42%|████▏     | 1860/4399 [4:09:31<5:58:22,  8.47s/it]                                                        42%|████▏     | 1860/4399 [4:09:31<5:58:22,  8.47s/it] 42%|████▏     | 1861/4399 [4:09:40<6:13:05,  8.82s/it] 42%|████▏     | 1862/4399 [4:09:47<5:45:46,  8.18s/it] 42%|████▏     | 1863/4399 [4:09:53<5:20:19,  7.58s/it] 42%|████▏     | 1864/4399 [4:09:59<4:53:00,  6.94s/it] 42%|████▏     | 1865/4399 [4:10:05<4:44:58,  6.75s/it] 42%|████▏     | 1866/4399 [4:10:14<5:10:00,  7.34s/it] 42%|
 0: {'loss': 0.6116, 'grad_norm': 2.0019237117957904, 'learning_rate': 7.115388430723919e-06, 'epoch': 0.43}
 0: ███▏     | 1867/4399 [4:10:24<5:45:48,  8.19s/it] 42%|████▏     | 1868/4399 [4:10:32<5:49:41,  8.29s/it] 42%|████▏     | 1869/4399 [4:10:42<6:02:01,  8.59s/it] 43%|████▎     | 1870/4399 [4:10:50<6:02:46,  8.61s/it]                                                        43%|████▎     | 1870/4399 [4:10:50<6:02:46,  8.61s/it] 43%|████▎     | 1871/4399 [4:10:56<5:25:53,  7.73s/it] 43%|████▎     | 1872/4399 [4:11:02<5:06:02,  7.27s/it] 43%|████▎     | 1873/4399 [4:11:09<5:02:27,  7.18s/it] 43%|████▎     | 1874/4399 [4:11:17<5:11:07,  7.39s/it] 43%|████▎     | 1875/4399 [4:11:28<6:01:17,  8.59s/it] 43%|████▎     | 1876/4399 [4:11:38<6:09:21,  8.78s/it] 43%|████▎     | 1877/4399 [4:11:49<6:38:32,  9.48s/it] 43%|████▎     | 1878/4399 [4:11:56<6:10:54,  8.83s/it] 43%|████▎     | 1879/4399 [4:12:02<5:30:45,  7.88s/it] 43%|████▎     | 1880/4399 [4:12:07<4:55
 0: {'loss': 0.6009, 'grad_norm': 1.8561710426575182, 'learning_rate': 7.079371506365315e-06, 'epoch': 0.43}
 0: {'loss': 0.6353, 'grad_norm': 1.7052587919145732, 'learning_rate': 7.04322364616286e-06, 'epoch': 0.43}
 0: :28,  7.04s/it]                                                        43%|████▎     | 1880/4399 [4:12:07<4:55:28,  7.04s/it] 43%|████▎     | 1881/4399 [4:12:13<4:50:33,  6.92s/it] 43%|████▎     | 1882/4399 [4:12:23<5:20:59,  7.65s/it] 43%|████▎     | 1883/4399 [4:12:33<5:53:07,  8.42s/it] 43%|████▎     | 1884/4399 [4:12:43<6:14:21,  8.93s/it] 43%|████▎     | 1885/4399 [4:12:54<6:34:58,  9.43s/it] 43%|████▎     | 1886/4399 [4:13:01<6:12:25,  8.89s/it] 43%|████▎     | 1887/4399 [4:13:07<5:35:28,  8.01s/it] 43%|████▎     | 1888/4399 [4:13:13<5:05:20,  7.30s/it] 43%|████▎     | 1889/4399 [4:13:19<4:53:02,  7.00s/it] 43%|████▎     | 1890/4399 [4:13:29<5:33:50,  7.98s/it]                                                        43%|████▎     | 1890/4399 [4:13:29<5:33:50,  7.98s/it] 43%|████▎     | 1891/4399 [4:13:40<6:04:03,  8.71s/it] 43%|████▎     | 1892/4399
 0: {'loss': 0.6204, 'grad_norm': 1.7283370806222578, 'learning_rate': 7.006947126309416e-06, 'epoch': 0.43}
 0:  [4:13:49<6:04:43,  8.73s/it] 43%|████▎     | 1893/4399 [4:13:58<6:09:45,  8.85s/it] 43%|████▎     | 1894/4399 [4:14:06<5:58:00,  8.57s/it] 43%|████▎     | 1895/4399 [4:14:11<5:16:04,  7.57s/it] 43%|████▎     | 1896/4399 [4:14:18<5:06:00,  7.34s/it] 43%|████▎     | 1897/4399 [4:14:26<5:15:59,  7.58s/it] 43%|████▎     | 1898/4399 [4:14:35<5:31:59,  7.96s/it] 43%|████▎     | 1899/4399 [4:14:44<5:54:13,  8.50s/it] 43%|████▎     | 1900/4399 [4:14:54<6:09:57,  8.88s/it]                                                        43%|████▎     | 1900/4399 [4:14:54<6:09:57,  8.88s/it] 43%|████▎     | 1901/4399 [4:15:03<6:12:20,  8.94s/it] 43%|████▎     | 1902/4399 [4:15:11<5:58:39,  8.62s/it] 43%|████▎     | 1903/4399 [4:15:19<5:48:58,  8.39s/it] 43%|████▎     | 1904/4399 [4:15:24<5:07:25,  7.39s/it] 43%|████▎     | 1905/4399 [4:15:31<5:06:32,  7.37s/it] 43%|██
 0: {'loss': 0.613, 'grad_norm': 1.866749775952935, 'learning_rate': 6.970544231099406e-06, 'epoch': 0.43}
 0: █▎     | 1906/4399 [4:15:40<5:20:15,  7.71s/it] 43%|████▎     | 1907/4399 [4:15:49<5:39:18,  8.17s/it] 43%|████▎     | 1908/4399 [4:15:58<5:52:56,  8.50s/it] 43%|████▎     | 1909/4399 [4:16:08<6:01:41,  8.72s/it] 43%|████▎     | 1910/4399 [4:16:14<5:38:13,  8.15s/it]                                                        43%|████▎     | 1910/4399 [4:16:15<5:38:13,  8.15s/it] 43%|████▎     | 1911/4399 [4:16:22<5:34:34,  8.07s/it] 43%|████▎     | 1912/4399 [4:16:29<5:10:53,  7.50s/it] 43%|████▎     | 1913/4399 [4:16:35<5:02:07,  7.29s/it] 44%|████▎     | 1914/4399 [4:16:45<5:30:28,  7.98s/it] 44%|████▎     | 1915/4399 [4:16:56<6:03:16,  8.77s/it] 44%|████▎     | 1916/4399 [4:17:07<6:30:12,  9.43s/it] 44%|████▎     | 1917/4399 [4:17:16<6:26:21,  9.34s/it] 44%|████▎     | 1918/4399 [4:17:24<6:14:45,  9.06s/it] 44%|████▎     | 1919/4399 [4:17:30<5:30:03,  
 0: {'loss': 0.6266, 'grad_norm': 1.767667188682517, 'learning_rate': 6.934017252784978e-06, 'epoch': 0.44}
 0: {'loss': 0.6047, 'grad_norm': 1.7689247471695204, 'learning_rate': 6.897368491431665e-06, 'epoch': 0.44}
 0: 7.99s/it] 44%|████▎     | 1920/4399 [4:17:36<5:13:25,  7.59s/it]                                                        44%|████▎     | 1920/4399 [4:17:36<5:13:25,  7.59s/it] 44%|████▎     | 1921/4399 [4:17:44<5:17:40,  7.69s/it] 44%|████▎     | 1922/4399 [4:17:53<5:30:31,  8.01s/it] 44%|████▎     | 1923/4399 [4:18:02<5:40:59,  8.26s/it] 44%|████▎     | 1924/4399 [4:18:12<6:04:28,  8.84s/it] 44%|████▍     | 1925/4399 [4:18:20<5:58:47,  8.70s/it] 44%|████▍     | 1926/4399 [4:18:27<5:35:45,  8.15s/it] 44%|████▍     | 1927/4399 [4:18:34<5:14:12,  7.63s/it] 44%|████▍     | 1928/4399 [4:18:40<4:56:06,  7.19s/it] 44%|████▍     | 1929/4399 [4:18:47<4:51:19,  7.08s/it] 44%|████▍     | 1930/4399 [4:18:56<5:26:25,  7.93s/it]                                                        44%|████▍     | 1930/4399 [4:18:56<5:26:25,  7.93s/it] 44%|████▍     | 1931/4399 [4:19
 0: {'loss': 0.602, 'grad_norm': 1.4672919259163109, 'learning_rate': 6.860600254773548e-06, 'epoch': 0.44}
 0: :07<5:57:31,  8.69s/it] 44%|████▍     | 1932/4399 [4:19:16<6:05:40,  8.89s/it] 44%|████▍     | 1933/4399 [4:19:25<5:58:51,  8.73s/it] 44%|████▍     | 1934/4399 [4:19:32<5:40:40,  8.29s/it] 44%|████▍     | 1935/4399 [4:19:37<5:05:28,  7.44s/it] 44%|████▍     | 1936/4399 [4:19:43<4:43:05,  6.90s/it] 44%|████▍     | 1937/4399 [4:19:50<4:47:47,  7.01s/it] 44%|████▍     | 1938/4399 [4:20:00<5:15:44,  7.70s/it] 44%|████▍     | 1939/4399 [4:20:09<5:36:27,  8.21s/it] 44%|████▍     | 1940/4399 [4:20:18<5:50:16,  8.55s/it]                                                        44%|████▍     | 1940/4399 [4:20:18<5:50:16,  8.55s/it] 44%|████▍     | 1941/4399 [4:20:27<5:57:57,  8.74s/it] 44%|████▍     | 1942/4399 [4:20:36<5:53:33,  8.63s/it] 44%|████▍     | 1943/4399 [4:20:42<5:16:30,  7.73s/it] 44%|████▍     | 1944/4399 [4:20:47<4:47:55,  7.04s/it] 44%|████
 0: {'loss': 0.6206, 'grad_norm': 1.749343634411902, 'learning_rate': 6.823714858067945e-06, 'epoch': 0.44}
 0:      | 1945/4399 [4:20:53<4:37:04,  6.77s/it] 44%|████▍     | 1946/4399 [4:21:02<4:58:09,  7.29s/it] 44%|████▍     | 1947/4399 [4:21:13<5:43:29,  8.41s/it] 44%|████▍     | 1948/4399 [4:21:23<6:04:50,  8.93s/it] 44%|████▍     | 1949/4399 [4:21:32<6:03:27,  8.90s/it] 44%|████▍     | 1950/4399 [4:21:40<5:59:13,  8.80s/it]                                                        44%|████▍     | 1950/4399 [4:21:40<5:59:13,  8.80s/it] 44%|████▍     | 1951/4399 [4:21:47<5:31:25,  8.12s/it] 44%|████▍     | 1952/4399 [4:21:54<5:20:38,  7.86s/it] 44%|████▍     | 1953/4399 [4:22:02<5:24:47,  7.97s/it] 44%|████▍     | 1954/4399 [4:22:11<5:37:20,  8.28s/it] 44%|████▍     | 1955/4399 [4:22:21<5:51:32,  8.63s/it] 44%|████▍     | 1956/4399 [4:22:30<6:06:11,  8.99s/it] 44%|████▍     | 1957/4399 [4:22:39<6:01:17,  8.88s/it] 45%|████▍     | 1958/4399 [4:22:48<5:56:00,  8.75s/
 0: {'loss': 0.6135, 'grad_norm': 1.8321224203256408, 'learning_rate': 6.786714623949615e-06, 'epoch': 0.45}
 0: {'loss': 0.6244, 'grad_norm': 2.209148688144549, 'learning_rate': 6.749601882284514e-06, 'epoch': 0.45}
 0: it] 45%|████▍     | 1959/4399 [4:22:56<5:51:04,  8.63s/it] 45%|████▍     | 1960/4399 [4:23:01<5:11:02,  7.65s/it]                                                        45%|████▍     | 1960/4399 [4:23:01<5:11:02,  7.65s/it] 45%|████▍     | 1961/4399 [4:23:08<4:57:42,  7.33s/it] 45%|████▍     | 1962/4399 [4:23:16<5:08:45,  7.60s/it] 45%|████▍     | 1963/4399 [4:23:25<5:30:57,  8.15s/it] 45%|████▍     | 1964/4399 [4:23:35<5:46:25,  8.54s/it] 45%|████▍     | 1965/4399 [4:23:44<5:54:30,  8.74s/it] 45%|████▍     | 1966/4399 [4:23:51<5:36:39,  8.30s/it] 45%|████▍     | 1967/4399 [4:23:59<5:27:34,  8.08s/it] 45%|████▍     | 1968/4399 [4:24:06<5:15:30,  7.79s/it] 45%|████▍     | 1969/4399 [4:24:12<4:53:34,  7.25s/it] 45%|████▍     | 1970/4399 [4:24:20<4:59:29,  7.40s/it]                                                        45%|████▍     | 1970/4399 [4:24:20<4:
 0: {'loss': 0.6052, 'grad_norm': 1.648943166970082, 'learning_rate': 6.712378970023075e-06, 'epoch': 0.45}
 0: 59:29,  7.40s/it] 45%|████▍     | 1971/4399 [4:24:30<5:35:08,  8.28s/it] 45%|████▍     | 1972/4399 [4:24:41<6:06:03,  9.05s/it] 45%|████▍     | 1973/4399 [4:24:50<6:08:42,  9.12s/it] 45%|████▍     | 1974/4399 [4:24:58<5:46:37,  8.58s/it] 45%|████▍     | 1975/4399 [4:25:03<5:10:46,  7.69s/it] 45%|████▍     | 1976/4399 [4:25:10<4:54:16,  7.29s/it] 45%|████▍     | 1977/4399 [4:25:16<4:43:56,  7.03s/it] 45%|████▍     | 1978/4399 [4:25:24<5:00:53,  7.46s/it] 45%|████▍     | 1979/4399 [4:25:34<5:26:47,  8.10s/it] 45%|████▌     | 1980/4399 [4:25:45<5:57:13,  8.86s/it]                                                        45%|████▌     | 1980/4399 [4:25:45<5:57:13,  8.86s/it] 45%|████▌     | 1981/4399 [4:25:54<5:59:30,  8.92s/it] 45%|████▌     | 1982/4399 [4:26:02<5:55:34,  8.83s/it] 45%|████▌     | 1983/4399 [4:26:08<5:14:53,  7.82s/it] 45%|████▌     
 0: {'loss': 0.6158, 'grad_norm': 1.6508025643154645, 'learning_rate': 6.675048231053063e-06, 'epoch': 0.45}
 0: | 1984/4399 [4:26:15<5:02:45,  7.52s/it] 45%|████▌     | 1985/4399 [4:26:21<4:46:17,  7.12s/it] 45%|████▌     | 1986/4399 [4:26:29<5:00:09,  7.46s/it] 45%|████▌     | 1987/4399 [4:26:39<5:27:37,  8.15s/it] 45%|████▌     | 1988/4399 [4:26:50<6:00:38,  8.98s/it] 45%|████▌     | 1989/4399 [4:26:59<6:07:22,  9.15s/it] 45%|████▌     | 1990/4399 [4:27:06<5:43:28,  8.55s/it]                                                        45%|████▌     | 1990/4399 [4:27:06<5:43:28,  8.55s/it] 45%|████▌     | 1991/4399 [4:27:12<5:08:11,  7.68s/it] 45%|████▌     | 1992/4399 [4:27:18<4:43:35,  7.07s/it] 45%|████▌     | 1993/4399 [4:27:25<4:42:27,  7.04s/it] 45%|████▌     | 1994/4399 [4:27:32<4:49:14,  7.22s/it] 45%|████▌     | 1995/4399 [4:27:43<5:36:04,  8.39s/it] 45%|████▌     | 1996/4399 [4:27:54<6:00:13,  8.99s/it] 45%|████▌     | 1997/4399 [4:28:02<5:53:55,  8.84s/it] 4
 0: {'loss': 0.5996, 'grad_norm': 1.5887185368862227, 'learning_rate': 6.637612016051975e-06, 'epoch': 0.45}
 0: 5%|████▌     | 1998/4399 [4:28:11<5:47:56,  8.69s/it] 45%|████▌     | 1999/4399 [4:28:17<5:23:00,  8.08s/it] 45%|████▌     | 2000/4399 [4:28:25<5:15:09,  7.88s/it]                                                        45%|████▌     | 2000/4399 [4:28:25<5:15:09,  7.88s/it][INFO|trainer.py:3984] 2025-06-28 01:32:53,352 >> Saving model checkpoint to /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000
 0: [INFO|configuration_utils.py:419] 2025-06-28 01:32:53,358 >> Configuration saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/config.json
 0: [INFO|configuration_utils.py:911] 2025-06-28 01:32:53,360 >> Configuration saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/generation_config.json
 0: [INFO|modeling_utils.py:3580] 2025-06-28 01:33:00,537 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 4 checkpoint shards. You can find where each parameters has been saved in the index located at /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/model.safetensors.index.json.
 0: [INFO|tokenization_utils_base.py:2510] 2025-06-28 01:33:00,541 >> tokenizer config file saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/tokenizer_config.json
 0: [INFO|tokenization_utils_base.py:2519] 2025-06-28 01:33:00,553 >> Special tokens file saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/special_tokens_map.json
 0: [2025-06-28 01:33:00,762] [INFO] [logging.py:107:log_dist] [Rank 0] [Torch] Checkpoint global_step2000 is about to be saved!
19: [2025-06-28 01:33:00,772] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_76_mp_rank_00_model_states.pt...
 5: [2025-06-28 01:33:00,772] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_20_mp_rank_00_model_states.pt...
30: [2025-06-28 01:33:00,772] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_120_mp_rank_00_model_states.pt...
18: [2025-06-28 01:33:00,773] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_72_mp_rank_00_model_states.pt...
 9: [2025-06-28 01:33:00,773] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_36_mp_rank_00_model_states.pt...
15: [2025-06-28 01:33:00,773] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_60_mp_rank_00_model_states.pt...
25: [2025-06-28 01:33:00,773] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_100_mp_rank_00_model_states.pt...
31: [2025-06-28 01:33:00,773] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_124_mp_rank_00_model_states.pt...
 6: [2025-06-28 01:33:00,773] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_24_mp_rank_00_model_states.pt...
24: [2025-06-28 01:33:00,773] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_96_mp_rank_00_model_states.pt...
13: [2025-06-28 01:33:00,773] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_52_mp_rank_00_model_states.pt...
 3: [2025-06-28 01:33:00,773] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_12_mp_rank_00_model_states.pt...
12: [2025-06-28 01:33:00,773] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_48_mp_rank_00_model_states.pt...
23: [2025-06-28 01:33:00,773] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_92_mp_rank_00_model_states.pt...
28: [2025-06-28 01:33:00,773] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_112_mp_rank_00_model_states.pt...
20: [2025-06-28 01:33:00,773] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_80_mp_rank_00_model_states.pt...
27: [2025-06-28 01:33:00,773] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_108_mp_rank_00_model_states.pt...
10: [2025-06-28 01:33:00,773] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_40_mp_rank_00_model_states.pt...
17: [2025-06-28 01:33:00,773] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_68_mp_rank_00_model_states.pt...
16: [2025-06-28 01:33:00,773] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_64_mp_rank_00_model_states.pt...
 4: [2025-06-28 01:33:00,773] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_16_mp_rank_00_model_states.pt...
29: [2025-06-28 01:33:00,773] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_116_mp_rank_00_model_states.pt...
22: [2025-06-28 01:33:00,773] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_88_mp_rank_00_model_states.pt...
14: [2025-06-28 01:33:00,773] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_56_mp_rank_00_model_states.pt...
 0: [2025-06-28 01:33:00,773] [INFO] [logging.py:107:log_dist] [Rank 0] Saving model checkpoint: /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_0_mp_rank_00_model_states.pt
 8: [2025-06-28 01:33:00,773] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_32_mp_rank_00_model_states.pt...
 2: [2025-06-28 01:33:00,773] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_8_mp_rank_00_model_states.pt...
 7: [2025-06-28 01:33:00,774] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_28_mp_rank_00_model_states.pt...
 0: [2025-06-28 01:33:00,774] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_0_mp_rank_00_model_states.pt...
11: [2025-06-28 01:33:00,774] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_44_mp_rank_00_model_states.pt...
 1: [2025-06-28 01:33:00,775] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_4_mp_rank_00_model_states.pt...
21: [2025-06-28 01:33:00,775] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_84_mp_rank_00_model_states.pt...
26: [2025-06-28 01:33:00,775] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_104_mp_rank_00_model_states.pt...
15: [2025-06-28 01:33:00,801] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_60_mp_rank_00_model_states.pt.
19: [2025-06-28 01:33:00,803] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_76_mp_rank_00_model_states.pt.
27: [2025-06-28 01:33:00,804] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_108_mp_rank_00_model_states.pt.
 5: [2025-06-28 01:33:00,804] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_20_mp_rank_00_model_states.pt.
24: [2025-06-28 01:33:00,805] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_96_mp_rank_00_model_states.pt.
 8: [2025-06-28 01:33:00,807] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_32_mp_rank_00_model_states.pt.
 6: [2025-06-28 01:33:00,809] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_24_mp_rank_00_model_states.pt.
25: [2025-06-28 01:33:00,810] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_100_mp_rank_00_model_states.pt.
 0: [2025-06-28 01:33:00,811] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_0_mp_rank_00_model_states.pt.
31: [2025-06-28 01:33:00,815] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_124_mp_rank_00_model_states.pt.
23: [2025-06-28 01:33:00,819] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_92_mp_rank_00_model_states.pt.
28: [2025-06-28 01:33:00,822] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_112_mp_rank_00_model_states.pt.
13: [2025-06-28 01:33:00,823] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_52_mp_rank_00_model_states.pt.
 9: [2025-06-28 01:33:00,823] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_36_mp_rank_00_model_states.pt.
 1: [2025-06-28 01:33:00,824] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_4_mp_rank_00_model_states.pt.
16: [2025-06-28 01:33:00,825] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_64_mp_rank_00_model_states.pt.
18: [2025-06-28 01:33:00,826] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_72_mp_rank_00_model_states.pt.
 2: [2025-06-28 01:33:00,826] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_8_mp_rank_00_model_states.pt.
29: [2025-06-28 01:33:00,826] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_116_mp_rank_00_model_states.pt.
11: [2025-06-28 01:33:00,827] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_44_mp_rank_00_model_states.pt.
30: [2025-06-28 01:33:00,827] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_120_mp_rank_00_model_states.pt.
 4: [2025-06-28 01:33:00,827] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_16_mp_rank_00_model_states.pt.
17: [2025-06-28 01:33:00,827] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_68_mp_rank_00_model_states.pt.
12: [2025-06-28 01:33:00,827] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_48_mp_rank_00_model_states.pt.
14: [2025-06-28 01:33:00,828] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_56_mp_rank_00_model_states.pt.
22: [2025-06-28 01:33:00,828] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_88_mp_rank_00_model_states.pt.
21: [2025-06-28 01:33:00,828] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_84_mp_rank_00_model_states.pt.
20: [2025-06-28 01:33:00,828] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_80_mp_rank_00_model_states.pt.
 7: [2025-06-28 01:33:00,828] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_28_mp_rank_00_model_states.pt.
10: [2025-06-28 01:33:00,828] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_40_mp_rank_00_model_states.pt.
26: [2025-06-28 01:33:00,829] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_104_mp_rank_00_model_states.pt.
 3: [2025-06-28 01:33:00,832] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/zero_pp_rank_12_mp_rank_00_model_states.pt.
 0: [2025-06-28 01:33:00,878] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
 4: [2025-06-28 01:33:00,878] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_16_mp_rank_00_optim_states.pt...
 6: [2025-06-28 01:33:00,878] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_24_mp_rank_00_optim_states.pt...
10: [2025-06-28 01:33:00,878] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_40_mp_rank_00_optim_states.pt...
 9: [2025-06-28 01:33:00,878] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_36_mp_rank_00_optim_states.pt...
 7: [2025-06-28 01:33:00,878] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_28_mp_rank_00_optim_states.pt...
 8: [2025-06-28 01:33:00,878] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_32_mp_rank_00_optim_states.pt...
14: [2025-06-28 01:33:00,878] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_56_mp_rank_00_optim_states.pt...
12: [2025-06-28 01:33:00,878] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_48_mp_rank_00_optim_states.pt...
 1: [2025-06-28 01:33:00,878] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_4_mp_rank_00_optim_states.pt...
15: [2025-06-28 01:33:00,878] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_60_mp_rank_00_optim_states.pt...
 3: [2025-06-28 01:33:00,878] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_12_mp_rank_00_optim_states.pt...
 5: [2025-06-28 01:33:00,878] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_20_mp_rank_00_optim_states.pt...
30: [2025-06-28 01:33:00,878] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_120_mp_rank_00_optim_states.pt...
17: [2025-06-28 01:33:00,878] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_68_mp_rank_00_optim_states.pt...
20: [2025-06-28 01:33:00,878] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_80_mp_rank_00_optim_states.pt...
21: [2025-06-28 01:33:00,878] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_84_mp_rank_00_optim_states.pt...
26: [2025-06-28 01:33:00,878] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_104_mp_rank_00_optim_states.pt...
29: [2025-06-28 01:33:00,878] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_116_mp_rank_00_optim_states.pt...
24: [2025-06-28 01:33:00,878] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_96_mp_rank_00_optim_states.pt...
18: [2025-06-28 01:33:00,878] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_72_mp_rank_00_optim_states.pt...
25: [2025-06-28 01:33:00,878] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_100_mp_rank_00_optim_states.pt...
23: [2025-06-28 01:33:00,878] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_92_mp_rank_00_optim_states.pt...
27: [2025-06-28 01:33:00,878] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_108_mp_rank_00_optim_states.pt...
28: [2025-06-28 01:33:00,878] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_112_mp_rank_00_optim_states.pt...
22: [2025-06-28 01:33:00,878] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_88_mp_rank_00_optim_states.pt...
16: [2025-06-28 01:33:00,878] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_64_mp_rank_00_optim_states.pt...
13: [2025-06-28 01:33:00,878] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_52_mp_rank_00_optim_states.pt...
19: [2025-06-28 01:33:00,878] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_76_mp_rank_00_optim_states.pt...
31: [2025-06-28 01:33:00,878] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_124_mp_rank_00_optim_states.pt...
 2: [2025-06-28 01:33:00,878] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_8_mp_rank_00_optim_states.pt...
11: [2025-06-28 01:33:00,878] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_44_mp_rank_00_optim_states.pt...
 0: [2025-06-28 01:33:01,348] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
 0: [2025-06-28 01:33:01,368] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
 1: [2025-06-28 01:33:03,640] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_4_mp_rank_00_optim_states.pt.
 1: [2025-06-28 01:33:03,641] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_4_mp_rank_00_optim_states.pt
27: [2025-06-28 01:33:03,660] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_108_mp_rank_00_optim_states.pt.
27: [2025-06-28 01:33:03,660] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_108_mp_rank_00_optim_states.pt
22: [2025-06-28 01:33:03,669] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_88_mp_rank_00_optim_states.pt.
22: [2025-06-28 01:33:03,670] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_88_mp_rank_00_optim_states.pt
31: [2025-06-28 01:33:03,677] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_124_mp_rank_00_optim_states.pt.
31: [2025-06-28 01:33:03,678] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_124_mp_rank_00_optim_states.pt
18: [2025-06-28 01:33:03,680] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_72_mp_rank_00_optim_states.pt.
18: [2025-06-28 01:33:03,681] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_72_mp_rank_00_optim_states.pt
 6: [2025-06-28 01:33:03,680] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_24_mp_rank_00_optim_states.pt.
 6: [2025-06-28 01:33:03,680] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_24_mp_rank_00_optim_states.pt
19: [2025-06-28 01:33:03,682] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_76_mp_rank_00_optim_states.pt.
19: [2025-06-28 01:33:03,682] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_76_mp_rank_00_optim_states.pt
14: [2025-06-28 01:33:03,682] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_56_mp_rank_00_optim_states.pt.
14: [2025-06-28 01:33:03,683] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_56_mp_rank_00_optim_states.pt
 2: [2025-06-28 01:33:03,689] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_8_mp_rank_00_optim_states.pt.
 2: [2025-06-28 01:33:03,689] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_8_mp_rank_00_optim_states.pt
28: [2025-06-28 01:33:03,691] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_112_mp_rank_00_optim_states.pt.
28: [2025-06-28 01:33:03,691] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_112_mp_rank_00_optim_states.pt
 4: [2025-06-28 01:33:03,691] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_16_mp_rank_00_optim_states.pt.
 4: [2025-06-28 01:33:03,692] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_16_mp_rank_00_optim_states.pt
10: [2025-06-28 01:33:03,692] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_40_mp_rank_00_optim_states.pt.
10: [2025-06-28 01:33:03,692] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_40_mp_rank_00_optim_states.pt
13: [2025-06-28 01:33:03,693] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_52_mp_rank_00_optim_states.pt.
13: [2025-06-28 01:33:03,693] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_52_mp_rank_00_optim_states.pt
11: [2025-06-28 01:33:03,693] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_44_mp_rank_00_optim_states.pt.
11: [2025-06-28 01:33:03,694] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_44_mp_rank_00_optim_states.pt
25: [2025-06-28 01:33:03,704] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_100_mp_rank_00_optim_states.pt.
25: [2025-06-28 01:33:03,704] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_100_mp_rank_00_optim_states.pt
30: [2025-06-28 01:33:03,705] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_120_mp_rank_00_optim_states.pt.
30: [2025-06-28 01:33:03,705] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_120_mp_rank_00_optim_states.pt
 5: [2025-06-28 01:33:03,705] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_20_mp_rank_00_optim_states.pt.
 5: [2025-06-28 01:33:03,705] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_20_mp_rank_00_optim_states.pt
15: [2025-06-28 01:33:03,707] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_60_mp_rank_00_optim_states.pt.
15: [2025-06-28 01:33:03,707] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_60_mp_rank_00_optim_states.pt
23: [2025-06-28 01:33:03,724] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_92_mp_rank_00_optim_states.pt.
23: [2025-06-28 01:33:03,725] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_92_mp_rank_00_optim_states.pt
12: [2025-06-28 01:33:03,735] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_48_mp_rank_00_optim_states.pt.
12: [2025-06-28 01:33:03,735] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_48_mp_rank_00_optim_states.pt
16: [2025-06-28 01:33:03,757] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_64_mp_rank_00_optim_states.pt.
16: [2025-06-28 01:33:03,757] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_64_mp_rank_00_optim_states.pt
 7: [2025-06-28 01:33:03,759] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_28_mp_rank_00_optim_states.pt.
 7: [2025-06-28 01:33:03,759] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_28_mp_rank_00_optim_states.pt
 9: [2025-06-28 01:33:03,784] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_36_mp_rank_00_optim_states.pt.
 9: [2025-06-28 01:33:03,785] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_36_mp_rank_00_optim_states.pt
21: [2025-06-28 01:33:03,786] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_84_mp_rank_00_optim_states.pt.
21: [2025-06-28 01:33:03,786] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_84_mp_rank_00_optim_states.pt
26: [2025-06-28 01:33:03,792] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_104_mp_rank_00_optim_states.pt.
26: [2025-06-28 01:33:03,793] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_104_mp_rank_00_optim_states.pt
17: [2025-06-28 01:33:03,806] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_68_mp_rank_00_optim_states.pt.
17: [2025-06-28 01:33:03,806] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_68_mp_rank_00_optim_states.pt
20: [2025-06-28 01:33:03,837] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_80_mp_rank_00_optim_states.pt.
20: [2025-06-28 01:33:03,837] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_80_mp_rank_00_optim_states.pt
 3: [2025-06-28 01:33:03,844] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_12_mp_rank_00_optim_states.pt.
 3: [2025-06-28 01:33:03,844] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_12_mp_rank_00_optim_states.pt
24: [2025-06-28 01:33:03,855] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_96_mp_rank_00_optim_states.pt.
24: [2025-06-28 01:33:03,855] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_96_mp_rank_00_optim_states.pt
29: [2025-06-28 01:33:03,890] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_116_mp_rank_00_optim_states.pt.
29: [2025-06-28 01:33:03,891] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_116_mp_rank_00_optim_states.pt
 8: [2025-06-28 01:33:10,150] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_32_mp_rank_00_optim_states.pt.
 8: [2025-06-28 01:33:10,151] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/global_step2000/bf16_zero_pp_rank_32_mp_rank_00_optim_states.pt
 8: [2025-06-28 01:33:10,242] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2000 is ready now!
30: [2025-06-28 01:33:10,242] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2000 is ready now!
28: [2025-06-28 01:33:10,242] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2000 is ready now!
19: [2025-06-28 01:33:10,242] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2000 is ready now!
24: [2025-06-28 01:33:10,242] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2000 is ready now!
11: [2025-06-28 01:33:10,243] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2000 is ready now!
26: [2025-06-28 01:33:10,243] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2000 is ready now!
20: [2025-06-28 01:33:10,243] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2000 is ready now!
13: [2025-06-28 01:33:10,243] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2000 is ready now!
31: [2025-06-28 01:33:10,243] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2000 is ready now!
25: [2025-06-28 01:33:10,243] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2000 is ready now!
12: [2025-06-28 01:33:10,244] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2000 is ready now!
 9: [2025-06-28 01:33:10,244] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2000 is ready now!
22: [2025-06-28 01:33:10,244] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2000 is ready now!
29: [2025-06-28 01:33:10,244] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2000 is ready now!
17: [2025-06-28 01:33:10,244] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2000 is ready now!
 6: [2025-06-28 01:33:10,244] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2000 is ready now!
18: [2025-06-28 01:33:10,244] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2000 is ready now!
 7: [2025-06-28 01:33:10,244] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2000 is ready now!
14: [2025-06-28 01:33:10,244] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2000 is ready now!
 3: [2025-06-28 01:33:10,244] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2000 is ready now!
27: [2025-06-28 01:33:10,244] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2000 is ready now!
15: [2025-06-28 01:33:10,244] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2000 is ready now!
10: [2025-06-28 01:33:10,244] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2000 is ready now!
 5: [2025-06-28 01:33:10,244] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2000 is ready now!
 2: [2025-06-28 01:33:10,244] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2000 is ready now!
 4: [2025-06-28 01:33:10,244] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2000 is ready now!
23: [2025-06-28 01:33:10,244] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2000 is ready now!
 1: [2025-06-28 01:33:10,245] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2000 is ready now!
16: [2025-06-28 01:33:10,247] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2000 is ready now!
 0: [2025-06-28 01:33:10,248] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2000 is ready now!
21: [2025-06-28 01:33:10,249] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2000 is ready now!
 0: [INFO|image_processing_base.py:260] 2025-06-28 01:33:10,295 >> Image processor saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/preprocessor_config.json
 0: [INFO|tokenization_utils_base.py:2510] 2025-06-28 01:33:10,297 >> tokenizer config file saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/tokenizer_config.json
 0: [INFO|tokenization_utils_base.py:2519] 2025-06-28 01:33:10,298 >> Special tokens file saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/special_tokens_map.json
 0: [INFO|processing_utils.py:648] 2025-06-28 01:33:10,895 >> chat template saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2000/chat_template.json
 0: /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
 0:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
 0: {'loss': 0.6053, 'grad_norm': 1.6555534025576637, 'learning_rate': 6.600072682339023e-06, 'epoch': 0.46}
 0:  45%|████▌     | 2001/4399 [4:29:48<20:12:26, 30.34s/it] 46%|████▌     | 2002/4399 [4:29:57<16:01:44, 24.07s/it] 46%|████▌     | 2003/4399 [4:30:09<13:38:51, 20.51s/it] 46%|████▌     | 2004/4399 [4:30:19<11:32:28, 17.35s/it] 46%|████▌     | 2005/4399 [4:30:27<9:44:33, 14.65s/it]  46%|████▌     | 2006/4399 [4:30:37<8:39:28, 13.02s/it] 46%|████▌     | 2007/4399 [4:30:43<7:16:27, 10.95s/it] 46%|████▌     | 2008/4399 [4:30:48<6:07:33,  9.22s/it] 46%|████▌     | 2009/4399 [4:30:56<5:54:28,  8.90s/it] 46%|████▌     | 2010/4399 [4:31:04<5:42:57,  8.61s/it]                                                        46%|████▌     | 2010/4399 [4:31:04<5:42:57,  8.61s/it] 46%|████▌     | 2011/4399 [4:31:16<6:16:52,  9.47s/it] 46%|████▌     | 2012/4399 [4:31:27<6:36:37,  9.97s/it] 46%|████▌     | 2013/4399 [4:31:38<6:48:31, 10.27s/it] 46%|████▌     | 2014/4399 
 0: {'loss': 0.5994, 'grad_norm': 1.6026815117421442, 'learning_rate': 6.562432593726695e-06, 'epoch': 0.46}
 0: [4:31:46<6:22:44,  9.63s/it] 46%|████▌     | 2015/4399 [4:31:52<5:44:41,  8.67s/it] 46%|████▌     | 2016/4399 [4:31:59<5:20:16,  8.06s/it] 46%|████▌     | 2017/4399 [4:32:05<4:56:58,  7.48s/it] 46%|████▌     | 2018/4399 [4:32:14<5:17:27,  8.00s/it] 46%|████▌     | 2019/4399 [4:32:26<6:04:01,  9.18s/it] 46%|████▌     | 2020/4399 [4:32:36<6:15:21,  9.47s/it]                                                        46%|████▌     | 2020/4399 [4:32:36<6:15:21,  9.47s/it] 46%|████▌     | 2021/4399 [4:32:46<6:23:30,  9.68s/it] 46%|████▌     | 2022/4399 [4:32:54<5:57:40,  9.03s/it] 46%|████▌     | 2023/4399 [4:33:00<5:25:38,  8.22s/it] 46%|████▌     | 2024/4399 [4:33:07<5:05:33,  7.72s/it] 46%|████▌     | 2025/4399 [4:33:14<4:58:12,  7.54s/it] 46%|████▌     | 2026/4399 [4:33:22<5:00:01,  7.59s/it] 46%|████▌     | 2027/4399 [4:33:32<5:30:34,  8.36s/it] 46%|███
 0: {'loss': 0.5997, 'grad_norm': 1.534218796453806, 'learning_rate': 6.524694120371913e-06, 'epoch': 0.46}
 0: {'loss': 0.5972, 'grad_norm': 1.4972771723136953, 'learning_rate': 6.4868596386267815e-06, 'epoch': 0.46}
 0: █▌     | 2028/4399 [4:33:41<5:36:38,  8.52s/it] 46%|████▌     | 2029/4399 [4:33:50<5:44:06,  8.71s/it] 46%|████▌     | 2030/4399 [4:33:58<5:34:13,  8.47s/it]                                                        46%|████▌     | 2030/4399 [4:33:58<5:34:13,  8.47s/it] 46%|████▌     | 2031/4399 [4:34:05<5:13:45,  7.95s/it] 46%|████▌     | 2032/4399 [4:34:10<4:47:38,  7.29s/it] 46%|████▌     | 2033/4399 [4:34:16<4:33:11,  6.93s/it] 46%|████▌     | 2034/4399 [4:34:25<4:50:20,  7.37s/it] 46%|████▋     | 2035/4399 [4:34:35<5:22:09,  8.18s/it] 46%|████▋     | 2036/4399 [4:34:45<5:43:16,  8.72s/it] 46%|████▋     | 2037/4399 [4:34:55<5:59:05,  9.12s/it] 46%|████▋     | 2038/4399 [4:35:03<5:50:13,  8.90s/it] 46%|████▋     | 2039/4399 [4:35:09<5:16:23,  8.04s/it] 46%|████▋     | 2040/4399 [4:35:15<4:51:50,  7.42s/it]                                                       
 0: {'loss': 0.6058, 'grad_norm': 1.5072399992957497, 'learning_rate': 6.44893153088895e-06, 'epoch': 0.47}
 0:  46%|████▋     | 2040/4399 [4:35:15<4:51:50,  7.42s/it] 46%|████▋     | 2041/4399 [4:35:23<4:49:49,  7.37s/it] 46%|████▋     | 2042/4399 [4:35:32<5:19:08,  8.12s/it] 46%|████▋     | 2043/4399 [4:35:42<5:40:34,  8.67s/it] 46%|████▋     | 2044/4399 [4:35:51<5:45:13,  8.80s/it] 46%|████▋     | 2045/4399 [4:36:02<6:07:40,  9.37s/it] 47%|████▋     | 2046/4399 [4:36:09<5:41:59,  8.72s/it] 47%|████▋     | 2047/4399 [4:36:16<5:19:07,  8.14s/it] 47%|████▋     | 2048/4399 [4:36:23<5:04:04,  7.76s/it] 47%|████▋     | 2049/4399 [4:36:30<4:53:58,  7.51s/it] 47%|████▋     | 2050/4399 [4:36:38<4:59:21,  7.65s/it]                                                        47%|████▋     | 2050/4399 [4:36:38<4:59:21,  7.65s/it] 47%|████▋     | 2051/4399 [4:36:47<5:13:57,  8.02s/it] 47%|████▋     | 2052/4399 [4:36:59<6:03:32,  9.29s/it] 47%|████▋     | 2053/4399 [4:37:
 0: {'loss': 0.6006, 'grad_norm': 1.7839928092997115, 'learning_rate': 6.410912185451604e-06, 'epoch': 0.47}
 0: 09<6:07:32,  9.40s/it] 47%|████▋     | 2054/4399 [4:37:16<5:44:29,  8.81s/it] 47%|████▋     | 2055/4399 [4:37:22<5:12:13,  7.99s/it] 47%|████▋     | 2056/4399 [4:37:28<4:46:53,  7.35s/it] 47%|████▋     | 2057/4399 [4:37:34<4:32:03,  6.97s/it] 47%|████▋     | 2058/4399 [4:37:43<4:51:50,  7.48s/it] 47%|████▋     | 2059/4399 [4:37:55<5:51:37,  9.02s/it] 47%|████▋     | 2060/4399 [4:38:06<6:08:34,  9.45s/it]                                                        47%|████▋     | 2060/4399 [4:38:06<6:08:34,  9.45s/it] 47%|████▋     | 2061/4399 [4:38:14<5:53:55,  9.08s/it] 47%|████▋     | 2062/4399 [4:38:22<5:41:22,  8.76s/it] 47%|████▋     | 2063/4399 [4:38:29<5:17:27,  8.15s/it] 47%|████▋     | 2064/4399 [4:38:36<5:00:15,  7.72s/it] 47%|████▋     | 2065/4399 [4:38:43<4:55:18,  7.59s/it] 47%|████▋     | 2066/4399 [4:38:51<5:06:02,  7.87s/it] 47%|████▋
 0: {'loss': 0.5946, 'grad_norm': 1.738195655231776, 'learning_rate': 6.372803996353066e-06, 'epoch': 0.47}
 0:      | 2067/4399 [4:39:03<5:44:05,  8.85s/it] 47%|████▋     | 2068/4399 [4:39:14<6:12:46,  9.60s/it] 47%|████▋     | 2069/4399 [4:39:23<6:01:21,  9.31s/it] 47%|████▋     | 2070/4399 [4:39:29<5:34:08,  8.61s/it]                                                        47%|████▋     | 2070/4399 [4:39:30<5:34:08,  8.61s/it] 47%|████▋     | 2071/4399 [4:39:35<4:59:45,  7.73s/it] 47%|████▋     | 2072/4399 [4:39:43<5:05:00,  7.86s/it] 47%|████▋     | 2073/4399 [4:39:50<4:45:01,  7.35s/it] 47%|████▋     | 2074/4399 [4:39:57<4:46:36,  7.40s/it] 47%|████▋     | 2075/4399 [4:40:07<5:20:35,  8.28s/it] 47%|████▋     | 2076/4399 [4:40:18<5:48:15,  8.99s/it] 47%|████▋     | 2077/4399 [4:40:27<5:52:35,  9.11s/it] 47%|████▋     | 2078/4399 [4:40:35<5:29:53,  8.53s/it] 47%|████▋     | 2079/4399 [4:40:41<5:03:39,  7.85s/it] 47%|████▋     | 2080/4399 [4:40:47<4:49:07,  7.48s/i
 0: {'loss': 0.6052, 'grad_norm': 1.6441187960435586, 'learning_rate': 6.3346093632260516e-06, 'epoch': 0.47}
 0: {'loss': 0.62, 'grad_norm': 1.603738288301958, 'learning_rate': 6.296330691146573e-06, 'epoch': 0.48}
 0: t]                                                        47%|████▋     | 2080/4399 [4:40:47<4:49:07,  7.48s/it] 47%|████▋     | 2081/4399 [4:40:54<4:35:17,  7.13s/it] 47%|████▋     | 2082/4399 [4:41:02<4:45:50,  7.40s/it] 47%|████▋     | 2083/4399 [4:41:14<5:36:19,  8.71s/it] 47%|████▋     | 2084/4399 [4:41:23<5:47:04,  9.00s/it] 47%|████▋     | 2085/4399 [4:41:32<5:46:09,  8.98s/it] 47%|████▋     | 2086/4399 [4:41:40<5:31:46,  8.61s/it] 47%|████▋     | 2087/4399 [4:41:47<5:14:29,  8.16s/it] 47%|████▋     | 2088/4399 [4:41:53<4:46:41,  7.44s/it] 47%|████▋     | 2089/4399 [4:42:00<4:43:32,  7.36s/it] 48%|████▊     | 2090/4399 [4:42:09<4:59:16,  7.78s/it]                                                        48%|████▊     | 2090/4399 [4:42:09<4:59:16,  7.78s/it] 48%|████▊     | 2091/4399 [4:42:20<5:37:34,  8.78s/it] 48%|████▊     | 2092/4399 [4:42:29<5:3
 0: {'loss': 0.6111, 'grad_norm': 1.7764870666866284, 'learning_rate': 6.2579703904824755e-06, 'epoch': 0.48}
 0: 8:53,  8.81s/it] 48%|████▊     | 2093/4399 [4:42:38<5:45:45,  9.00s/it] 48%|████▊     | 2094/4399 [4:42:46<5:29:39,  8.58s/it] 48%|████▊     | 2095/4399 [4:42:53<5:18:58,  8.31s/it] 48%|████▊     | 2096/4399 [4:42:59<4:47:29,  7.49s/it] 48%|████▊     | 2097/4399 [4:43:07<4:53:25,  7.65s/it] 48%|████▊     | 2098/4399 [4:43:17<5:17:29,  8.28s/it] 48%|████▊     | 2099/4399 [4:43:27<5:42:27,  8.93s/it] 48%|████▊     | 2100/4399 [4:43:37<5:55:05,  9.27s/it]                                                        48%|████▊     | 2100/4399 [4:43:37<5:55:05,  9.27s/it] 48%|████▊     | 2101/4399 [4:43:47<6:05:10,  9.53s/it] 48%|████▊     | 2102/4399 [4:43:56<5:55:00,  9.27s/it] 48%|████▊     | 2103/4399 [4:44:02<5:17:47,  8.30s/it] 48%|████▊     | 2104/4399 [4:44:08<4:51:10,  7.61s/it] 48%|████▊     | 2105/4399 [4:44:14<4:33:09,  7.14s/it] 48%|████▊     |
 0: {'loss': 0.5904, 'grad_norm': 1.531404492520862, 'learning_rate': 6.21953087674168e-06, 'epoch': 0.48}
 0:  2106/4399 [4:44:23<4:52:51,  7.66s/it] 48%|████▊     | 2107/4399 [4:44:32<5:10:11,  8.12s/it] 48%|████▊     | 2108/4399 [4:44:42<5:30:43,  8.66s/it] 48%|████▊     | 2109/4399 [4:44:51<5:36:19,  8.81s/it] 48%|████▊     | 2110/4399 [4:44:59<5:19:30,  8.37s/it]                                                        48%|████▊     | 2110/4399 [4:44:59<5:19:30,  8.37s/it] 48%|████▊     | 2111/4399 [4:45:07<5:14:00,  8.23s/it] 48%|████▊     | 2112/4399 [4:45:15<5:10:09,  8.14s/it] 48%|████▊     | 2113/4399 [4:45:21<4:48:34,  7.57s/it] 48%|████▊     | 2114/4399 [4:45:29<4:53:39,  7.71s/it] 48%|████▊     | 2115/4399 [4:45:37<5:03:20,  7.97s/it] 48%|████▊     | 2116/4399 [4:45:48<5:35:23,  8.81s/it] 48%|████▊     | 2117/4399 [4:46:00<6:08:40,  9.69s/it] 48%|████▊     | 2118/4399 [4:46:09<5:56:06,  9.37s/it] 48%|████▊     | 2119/4399 [4:46:17<5:40:29,  8.96s/it] 48
 0: {'loss': 0.5834, 'grad_norm': 1.6366730205619506, 'learning_rate': 6.181014570420067e-06, 'epoch': 0.48}
 0: {'loss': 0.6024, 'grad_norm': 1.597830075906264, 'learning_rate': 6.142423896849071e-06, 'epoch': 0.48}
 0: %|████▊     | 2120/4399 [4:46:24<5:27:05,  8.61s/it]                                                        48%|████▊     | 2120/4399 [4:46:24<5:27:05,  8.61s/it] 48%|████▊     | 2121/4399 [4:46:30<4:57:34,  7.84s/it] 48%|████▊     | 2122/4399 [4:46:38<4:53:26,  7.73s/it] 48%|████▊     | 2123/4399 [4:46:48<5:21:25,  8.47s/it] 48%|████▊     | 2124/4399 [4:46:57<5:29:12,  8.68s/it] 48%|████▊     | 2125/4399 [4:47:07<5:38:23,  8.93s/it] 48%|████▊     | 2126/4399 [4:47:16<5:42:54,  9.05s/it] 48%|████▊     | 2127/4399 [4:47:23<5:15:46,  8.34s/it] 48%|████▊     | 2128/4399 [4:47:30<5:00:15,  7.93s/it] 48%|████▊     | 2129/4399 [4:47:37<4:50:46,  7.69s/it] 48%|████▊     | 2130/4399 [4:47:45<4:58:18,  7.89s/it]                                                        48%|████▊     | 2130/4399 [4:47:45<4:58:18,  7.89s/it] 48%|████▊     | 2131/4399 [4:47:55<5:14:22, 
 0: {'loss': 0.5991, 'grad_norm': 1.7200144712068284, 'learning_rate': 6.1037612860429466e-06, 'epoch': 0.49}
 0:  8.32s/it] 48%|████▊     | 2132/4399 [4:48:04<5:23:12,  8.55s/it] 48%|████▊     | 2133/4399 [4:48:13<5:36:59,  8.92s/it] 49%|████▊     | 2134/4399 [4:48:21<5:21:11,  8.51s/it] 49%|████▊     | 2135/4399 [4:48:28<5:01:14,  7.98s/it] 49%|████▊     | 2136/4399 [4:48:34<4:39:11,  7.40s/it] 49%|████▊     | 2137/4399 [4:48:40<4:28:28,  7.12s/it] 49%|████▊     | 2138/4399 [4:48:49<4:42:33,  7.50s/it] 49%|████▊     | 2139/4399 [4:48:58<5:06:08,  8.13s/it] 49%|████▊     | 2140/4399 [4:49:07<5:19:04,  8.47s/it]                                                        49%|████▊     | 2140/4399 [4:49:07<5:19:04,  8.47s/it] 49%|████▊     | 2141/4399 [4:49:17<5:28:21,  8.73s/it] 49%|████▊     | 2142/4399 [4:49:24<5:08:57,  8.21s/it] 49%|████▊     | 2143/4399 [4:49:31<4:59:23,  7.96s/it] 49%|████▊     | 2144/4399 [4:49:39<5:01:27,  8.02s/it] 49%|████▉     | 2145/
 0: {'loss': 0.588, 'grad_norm': 1.51337064366605, 'learning_rate': 6.065029172545765e-06, 'epoch': 0.49}
 0: 4399 [4:49:46<4:41:12,  7.49s/it] 49%|████▉     | 2146/4399 [4:49:54<4:49:09,  7.70s/it] 49%|████▉     | 2147/4399 [4:50:03<5:08:48,  8.23s/it] 49%|████▉     | 2148/4399 [4:50:13<5:30:24,  8.81s/it] 49%|████▉     | 2149/4399 [4:50:23<5:34:45,  8.93s/it] 49%|████▉     | 2150/4399 [4:50:31<5:28:05,  8.75s/it]                                                        49%|████▉     | 2150/4399 [4:50:31<5:28:05,  8.75s/it] 49%|████▉     | 2151/4399 [4:50:37<4:53:12,  7.83s/it] 49%|████▉     | 2152/4399 [4:50:44<4:46:04,  7.64s/it] 49%|████▉     | 2153/4399 [4:50:50<4:28:31,  7.17s/it] 49%|████▉     | 2154/4399 [4:50:57<4:33:01,  7.30s/it] 49%|████▉     | 2155/4399 [4:51:07<4:58:35,  7.98s/it] 49%|████▉     | 2156/4399 [4:51:17<5:19:26,  8.55s/it] 49%|████▉     | 2157/4399 [4:51:26<5:23:30,  8.66s/it] 49%|████▉     | 2158/4399 [4:51:33<5:11:53,  8.35s/it] 49%|█
 0: {'loss': 0.6113, 'grad_norm': 1.8077814733991184, 'learning_rate': 6.02622999527811e-06, 'epoch': 0.49}
 0: {'loss': 0.5796, 'grad_norm': 1.98376352149566, 'learning_rate': 5.987366197383498e-06, 'epoch': 0.49}
 0: ██▉     | 2159/4399 [4:51:40<4:51:14,  7.80s/it] 49%|████▉     | 2160/4399 [4:51:47<4:43:26,  7.60s/it]                                                        49%|████▉     | 2160/4399 [4:51:47<4:43:26,  7.60s/it] 49%|████▉     | 2161/4399 [4:51:54<4:36:50,  7.42s/it] 49%|████▉     | 2162/4399 [4:52:03<4:49:10,  7.76s/it] 49%|████▉     | 2163/4399 [4:52:12<5:09:43,  8.31s/it] 49%|████▉     | 2164/4399 [4:52:21<5:14:59,  8.46s/it] 49%|████▉     | 2165/4399 [4:52:29<5:11:04,  8.35s/it] 49%|████▉     | 2166/4399 [4:52:38<5:12:56,  8.41s/it] 49%|████▉     | 2167/4399 [4:52:45<5:01:49,  8.11s/it] 49%|████▉     | 2168/4399 [4:52:52<4:48:28,  7.76s/it] 49%|████▉     | 2169/4399 [4:52:58<4:27:28,  7.20s/it] 49%|████▉     | 2170/4399 [4:53:05<4:27:05,  7.19s/it]                                                        49%|████▉     | 2170/4399 [4:53:05<4:27:05,  7.19s
 0: {'loss': 0.605, 'grad_norm': 1.7135867858660423, 'learning_rate': 5.948440226074539e-06, 'epoch': 0.5}
 0: /it] 49%|████▉     | 2171/4399 [4:53:15<4:58:21,  8.03s/it] 49%|████▉     | 2172/4399 [4:53:23<5:01:34,  8.13s/it] 49%|████▉     | 2173/4399 [4:53:33<5:22:03,  8.68s/it] 49%|████▉     | 2174/4399 [4:53:41<5:07:39,  8.30s/it] 49%|████▉     | 2175/4399 [4:53:49<5:06:32,  8.27s/it] 49%|████▉     | 2176/4399 [4:53:57<5:07:52,  8.31s/it] 49%|████▉     | 2177/4399 [4:54:03<4:41:53,  7.61s/it] 50%|████▉     | 2178/4399 [4:54:13<5:07:15,  8.30s/it] 50%|████▉     | 2179/4399 [4:54:23<5:25:04,  8.79s/it] 50%|████▉     | 2180/4399 [4:54:32<5:19:03,  8.63s/it]                                                        50%|████▉     | 2180/4399 [4:54:32<5:19:03,  8.63s/it] 50%|████▉     | 2181/4399 [4:54:41<5:26:13,  8.82s/it] 50%|████▉     | 2182/4399 [4:54:48<5:03:50,  8.22s/it] 50%|████▉     | 2183/4399 [4:54:55<4:52:40,  7.92s/it] 50%|████▉     | 2184/4399 [
 0: {'loss': 0.6043, 'grad_norm': 1.578284103477546, 'learning_rate': 5.90945453247884e-06, 'epoch': 0.5}
 0: 4:55:01<4:36:13,  7.48s/it] 50%|████▉     | 2185/4399 [4:55:08<4:22:31,  7.11s/it] 50%|████▉     | 2186/4399 [4:55:14<4:18:42,  7.01s/it] 50%|████▉     | 2187/4399 [4:55:24<4:43:13,  7.68s/it] 50%|████▉     | 2188/4399 [4:55:33<5:05:26,  8.29s/it] 50%|████▉     | 2189/4399 [4:55:43<5:18:07,  8.64s/it] 50%|████▉     | 2190/4399 [4:55:51<5:09:06,  8.40s/it]                                                        50%|████▉     | 2190/4399 [4:55:51<5:09:06,  8.40s/it] 50%|████▉     | 2191/4399 [4:55:57<4:44:56,  7.74s/it] 50%|████▉     | 2192/4399 [4:56:04<4:40:32,  7.63s/it] 50%|████▉     | 2193/4399 [4:56:10<4:24:07,  7.18s/it] 50%|████▉     | 2194/4399 [4:56:18<4:30:49,  7.37s/it] 50%|████▉     | 2195/4399 [4:56:28<4:56:45,  8.08s/it] 50%|████▉     | 2196/4399 [4:56:38<5:21:53,  8.77s/it] 50%|████▉     | 2197/4399 [4:56:48<5:34:33,  9.12s/it] 50%|███
 0: {'loss': 0.6098, 'grad_norm': 2.1990184177382184, 'learning_rate': 5.870411571484654e-06, 'epoch': 0.5}
 0: {'loss': 0.5929, 'grad_norm': 1.9948158862650225, 'learning_rate': 5.831313801586308e-06, 'epoch': 0.5}
 0: ▉     | 2198/4399 [4:56:56<5:17:33,  8.66s/it] 50%|████▉     | 2199/4399 [4:57:03<4:59:33,  8.17s/it] 50%|█████     | 2200/4399 [4:57:10<4:53:23,  8.01s/it]                                                        50%|█████     | 2200/4399 [4:57:10<4:53:23,  8.01s/it] 50%|█████     | 2201/4399 [4:57:17<4:41:57,  7.70s/it] 50%|█████     | 2202/4399 [4:57:25<4:36:31,  7.55s/it] 50%|█████     | 2203/4399 [4:57:34<5:00:46,  8.22s/it] 50%|█████     | 2204/4399 [4:57:44<5:13:12,  8.56s/it] 50%|█████     | 2205/4399 [4:57:54<5:27:16,  8.95s/it] 50%|█████     | 2206/4399 [4:58:00<5:03:44,  8.31s/it] 50%|█████     | 2207/4399 [4:58:08<4:57:07,  8.13s/it] 50%|█████     | 2208/4399 [4:58:14<4:36:26,  7.57s/it] 50%|█████     | 2209/4399 [4:58:20<4:17:16,  7.05s/it] 50%|█████     | 2210/4399 [4:58:28<4:22:57,  7.21s/it]                                                        
 0: {'loss': 0.6013, 'grad_norm': 1.4866942572023003, 'learning_rate': 5.792163684729379e-06, 'epoch': 0.5}
 0: 50%|█████     | 2210/4399 [4:58:28<4:22:57,  7.21s/it] 50%|█████     | 2211/4399 [4:58:37<4:48:50,  7.92s/it] 50%|█████     | 2212/4399 [4:58:48<5:20:07,  8.78s/it] 50%|█████     | 2213/4399 [4:58:57<5:20:27,  8.80s/it] 50%|█████     | 2214/4399 [4:59:06<5:25:25,  8.94s/it] 50%|█████     | 2215/4399 [4:59:14<5:10:48,  8.54s/it] 50%|█████     | 2216/4399 [4:59:21<4:52:46,  8.05s/it] 50%|█████     | 2217/4399 [4:59:28<4:39:44,  7.69s/it] 50%|█████     | 2218/4399 [4:59:36<4:46:18,  7.88s/it] 50%|█████     | 2219/4399 [4:59:46<5:09:34,  8.52s/it] 50%|█████     | 2220/4399 [4:59:55<5:17:16,  8.74s/it]                                                        50%|█████     | 2220/4399 [4:59:55<5:17:16,  8.74s/it] 50%|█████     | 2221/4399 [5:00:05<5:33:42,  9.19s/it] 51%|█████     | 2222/4399 [5:00:12<5:10:00,  8.54s/it] 51%|█████     | 2223/4399 [5:00:2
 0: {'loss': 0.5977, 'grad_norm': 1.8235320578226213, 'learning_rate': 5.7529636861556885e-06, 'epoch': 0.51}
 0: 1<5:07:16,  8.47s/it] 51%|█████     | 2224/4399 [5:00:29<5:00:00,  8.28s/it] 51%|█████     | 2225/4399 [5:00:36<4:47:01,  7.92s/it] 51%|█████     | 2226/4399 [5:00:44<4:56:20,  8.18s/it] 51%|█████     | 2227/4399 [5:00:55<5:21:59,  8.89s/it] 51%|█████     | 2228/4399 [5:01:05<5:28:59,  9.09s/it] 51%|█████     | 2229/4399 [5:01:14<5:31:58,  9.18s/it] 51%|█████     | 2230/4399 [5:01:21<5:09:32,  8.56s/it]                                                        51%|█████     | 2230/4399 [5:01:21<5:09:32,  8.56s/it] 51%|█████     | 2231/4399 [5:01:29<5:06:14,  8.48s/it] 51%|█████     | 2232/4399 [5:01:35<4:35:30,  7.63s/it] 51%|█████     | 2233/4399 [5:01:41<4:20:25,  7.21s/it] 51%|█████     | 2234/4399 [5:01:50<4:40:24,  7.77s/it] 51%|█████     | 2235/4399 [5:02:00<4:58:35,  8.28s/it] 51%|█████     | 2236/4399 [5:02:09<5:05:09,  8.47s/it] 51%|█████ 
 0: {'loss': 0.6017, 'grad_norm': 1.5925695917938147, 'learning_rate': 5.7137162742480455e-06, 'epoch': 0.51}
 0:     | 2237/4399 [5:02:18<5:18:28,  8.84s/it] 51%|█████     | 2238/4399 [5:02:26<5:07:39,  8.54s/it] 51%|█████     | 2239/4399 [5:02:33<4:49:34,  8.04s/it] 51%|█████     | 2240/4399 [5:02:39<4:27:03,  7.42s/it]                                                        51%|█████     | 2240/4399 [5:02:39<4:27:03,  7.42s/it] 51%|█████     | 2241/4399 [5:02:45<4:10:54,  6.98s/it] 51%|█████     | 2242/4399 [5:02:52<4:15:32,  7.11s/it] 51%|█████     | 2243/4399 [5:03:02<4:41:21,  7.83s/it] 51%|█████     | 2244/4399 [5:03:10<4:45:24,  7.95s/it] 51%|█████     | 2245/4399 [5:03:20<5:09:08,  8.61s/it] 51%|█████     | 2246/4399 [5:03:30<5:20:49,  8.94s/it] 51%|█████     | 2247/4399 [5:03:38<5:14:07,  8.76s/it] 51%|█████     | 2248/4399 [5:03:47<5:10:27,  8.66s/it] 51%|█████     | 2249/4399 [5:03:53<4:43:32,  7.91s/it] 51%|█████     | 2250/4399 [5:04:00<4:30:44,  7.56s/it
 0: {'loss': 0.5826, 'grad_norm': 1.7444000407550762, 'learning_rate': 5.674423920374837e-06, 'epoch': 0.51}
 0: {'loss': 0.6101, 'grad_norm': 1.7306738812907054, 'learning_rate': 5.635089098734394e-06, 'epoch': 0.51}
 0: ]                                                        51%|█████     | 2250/4399 [5:04:00<4:30:44,  7.56s/it] 51%|█████     | 2251/4399 [5:04:07<4:30:29,  7.56s/it] 51%|█████     | 2252/4399 [5:04:16<4:47:42,  8.04s/it] 51%|█████     | 2253/4399 [5:04:27<5:12:57,  8.75s/it] 51%|█████     | 2254/4399 [5:04:36<5:17:09,  8.87s/it] 51%|█████▏    | 2255/4399 [5:04:45<5:15:23,  8.83s/it] 51%|█████▏    | 2256/4399 [5:04:51<4:45:01,  7.98s/it] 51%|█████▏    | 2257/4399 [5:04:57<4:23:49,  7.39s/it] 51%|█████▏    | 2258/4399 [5:05:06<4:44:16,  7.97s/it] 51%|█████▏    | 2259/4399 [5:05:15<4:58:47,  8.38s/it] 51%|█████▏    | 2260/4399 [5:05:25<5:10:54,  8.72s/it]                                                        51%|█████▏    | 2260/4399 [5:05:25<5:10:54,  8.72s/it] 51%|█████▏    | 2261/4399 [5:05:34<5:13:27,  8.80s/it] 51%|█████▏    | 2262/
 0: {'loss': 0.5932, 'grad_norm': 1.8869909102754439, 'learning_rate': 5.595714286199198e-06, 'epoch': 0.52}
 0: 4399 [5:05:42<5:10:16,  8.71s/it] 51%|█████▏    | 2263/4399 [5:05:51<5:05:37,  8.59s/it] 51%|█████▏    | 2264/4399 [5:05:57<4:45:21,  8.02s/it] 51%|█████▏    | 2265/4399 [5:06:04<4:29:36,  7.58s/it] 52%|█████▏    | 2266/4399 [5:06:11<4:29:04,  7.57s/it] 52%|█████▏    | 2267/4399 [5:06:20<4:34:53,  7.74s/it] 52%|█████▏    | 2268/4399 [5:06:29<4:51:38,  8.21s/it] 52%|█████▏    | 2269/4399 [5:06:39<5:07:08,  8.65s/it] 52%|█████▏    | 2270/4399 [5:06:47<4:59:19,  8.44s/it]                                                        52%|█████▏    | 2270/4399 [5:06:47<4:59:19,  8.44s/it] 52%|█████▏    | 2271/4399 [5:06:54<4:53:10,  8.27s/it] 52%|█████▏    | 2272/4399 [5:07:02<4:41:53,  7.95s/it] 52%|█████▏    | 2273/4399 [5:07:08<4:25:26,  7.49s/it] 52%|█████▏    | 2274/4399 [5:07:16<4:27:06,  7.54s/it] 52%|█████▏    | 2275/4399 [5:07:26<4
 0: {'loss': 0.5986, 'grad_norm': 1.547100737482447, 'learning_rate': 5.5563019621599145e-06, 'epoch': 0.52}
 0: :52:24,  8.26s/it] 52%|█████▏    | 2276/4399 [5:07:35<5:06:25,  8.66s/it] 52%|█████▏    | 2277/4399 [5:07:45<5:13:35,  8.87s/it] 52%|█████▏    | 2278/4399 [5:07:53<5:10:42,  8.79s/it] 52%|█████▏    | 2279/4399 [5:08:01<4:55:06,  8.35s/it] 52%|█████▏    | 2280/4399 [5:08:07<4:38:43,  7.89s/it]                                                        52%|█████▏    | 2280/4399 [5:08:07<4:38:43,  7.89s/it] 52%|█████▏    | 2281/4399 [5:08:14<4:29:13,  7.63s/it] 52%|█████▏    | 2282/4399 [5:08:21<4:21:34,  7.41s/it] 52%|█████▏    | 2283/4399 [5:08:31<4:49:43,  8.22s/it] 52%|█████▏    | 2284/4399 [5:08:42<5:17:04,  8.99s/it] 52%|█████▏    | 2285/4399 [5:08:52<5:26:13,  9.26s/it] 52%|█████▏    | 2286/4399 [5:09:01<5:23:16,  9.18s/it] 52%|█████▏    | 2287/4399 [5:09:08<4:57:54,  8.46s/it] 52%|█████▏    | 2288/4399 [5:09:15<4:48:28,  8.20s/
 0: {'loss': 0.5971, 'grad_norm': 1.6870889079111129, 'learning_rate': 5.516854608369272e-06, 'epoch': 0.52}
 0: {'loss': 0.5883, 'grad_norm': 1.558953689280556, 'learning_rate': 5.4773747087857844e-06, 'epoch': 0.52}
 0: it] 52%|█████▏    | 2289/4399 [5:09:23<4:46:56,  8.16s/it] 52%|█████▏    | 2290/4399 [5:09:31<4:39:47,  7.96s/it]                                                        52%|█████▏    | 2290/4399 [5:09:31<4:39:47,  7.96s/it] 52%|█████▏    | 2291/4399 [5:09:40<4:46:31,  8.16s/it] 52%|█████▏    | 2292/4399 [5:09:48<4:52:53,  8.34s/it] 52%|█████▏    | 2293/4399 [5:09:58<5:09:40,  8.82s/it] 52%|█████▏    | 2294/4399 [5:10:06<4:54:12,  8.39s/it] 52%|█████▏    | 2295/4399 [5:10:12<4:33:49,  7.81s/it] 52%|█████▏    | 2296/4399 [5:10:20<4:30:00,  7.70s/it] 52%|█████▏    | 2297/4399 [5:10:26<4:14:23,  7.26s/it] 52%|█████▏    | 2298/4399 [5:10:34<4:21:56,  7.48s/it] 52%|█████▏    | 2299/4399 [5:10:42<4:33:46,  7.82s/it] 52%|█████▏    | 2300/4399 [5:10:52<4:48:22,  8.24s/it]                                                        52%|█████
 0: {'loss': 0.6026, 'grad_norm': 2.4332477398228685, 'learning_rate': 5.437864749417337e-06, 'epoch': 0.53}
 0:     | 2300/4399 [5:10:52<4:48:22,  8.24s/it] 52%|█████▏    | 2301/4399 [5:11:00<4:50:11,  8.30s/it] 52%|█████▏    | 2302/4399 [5:11:09<4:51:22,  8.34s/it] 52%|█████▏    | 2303/4399 [5:11:16<4:43:35,  8.12s/it] 52%|█████▏    | 2304/4399 [5:11:23<4:25:36,  7.61s/it] 52%|█████▏    | 2305/4399 [5:11:30<4:19:03,  7.42s/it] 52%|█████▏    | 2306/4399 [5:11:37<4:18:47,  7.42s/it] 52%|█████▏    | 2307/4399 [5:11:47<4:44:40,  8.16s/it] 52%|█████▏    | 2308/4399 [5:11:57<5:01:28,  8.65s/it] 52%|█████▏    | 2309/4399 [5:12:05<5:02:24,  8.68s/it] 53%|█████▎    | 2310/4399 [5:12:14<4:58:11,  8.56s/it]                                                        53%|█████▎    | 2310/4399 [5:12:14<4:58:11,  8.56s/it] 53%|█████▎    | 2311/4399 [5:12:21<4:44:21,  8.17s/it] 53%|█████▎    | 2312/4399 [5:12:28<4:36:21,  7.95s/it] 53%|█████▎    | 2313/439
 0: {'loss': 0.5978, 'grad_norm': 2.1282074798640886, 'learning_rate': 5.398327218164656e-06, 'epoch': 0.53}
 0: 9 [5:12:34<4:17:04,  7.39s/it] 53%|█████▎    | 2314/4399 [5:12:42<4:14:47,  7.33s/it] 53%|█████▎    | 2315/4399 [5:12:50<4:22:14,  7.55s/it] 53%|█████▎    | 2316/4399 [5:12:59<4:44:12,  8.19s/it] 53%|█████▎    | 2317/4399 [5:13:10<5:05:26,  8.80s/it] 53%|█████▎    | 2318/4399 [5:13:19<5:10:38,  8.96s/it] 53%|█████▎    | 2319/4399 [5:13:27<4:57:40,  8.59s/it] 53%|█████▎    | 2320/4399 [5:13:33<4:39:06,  8.06s/it]                                                        53%|█████▎    | 2320/4399 [5:13:33<4:39:06,  8.06s/it] 53%|█████▎    | 2321/4399 [5:13:41<4:29:48,  7.79s/it] 53%|█████▎    | 2322/4399 [5:13:49<4:33:41,  7.91s/it] 53%|█████▎    | 2323/4399 [5:13:56<4:30:44,  7.82s/it] 53%|█████▎    | 2324/4399 [5:14:06<4:52:44,  8.46s/it] 53%|█████▎    | 2325/4399 [5:14:15<4:53:51,  8.50s/it] 53%|█████▎    | 2326/4399 [5:14:24<4:54
 0: {'loss': 0.5966, 'grad_norm': 1.6305217836798755, 'learning_rate': 5.358764604664631e-06, 'epoch': 0.53}
 0: :06,  8.51s/it] 53%|█████▎    | 2327/4399 [5:14:31<4:43:17,  8.20s/it] 53%|█████▎    | 2328/4399 [5:14:39<4:40:05,  8.11s/it] 53%|█████▎    | 2329/4399 [5:14:45<4:17:41,  7.47s/it] 53%|█████▎    | 2330/4399 [5:14:54<4:34:17,  7.95s/it]                                                        53%|█████▎    | 2330/4399 [5:14:54<4:34:17,  7.95s/it] 53%|█████▎    | 2331/4399 [5:15:02<4:35:50,  8.00s/it] 53%|█████▎    | 2332/4399 [5:15:12<4:53:54,  8.53s/it] 53%|█████▎    | 2333/4399 [5:15:23<5:15:52,  9.17s/it] 53%|█████▎    | 2334/4399 [5:15:31<5:12:08,  9.07s/it] 53%|█████▎    | 2335/4399 [5:15:38<4:44:05,  8.26s/it] 53%|█████▎    | 2336/4399 [5:15:46<4:44:55,  8.29s/it] 53%|█████▎    | 2337/4399 [5:15:52<4:25:03,  7.71s/it] 53%|█████▎    | 2338/4399 [5:16:00<4:28:13,  7.81s/it] 53%|█████▎    | 2339/4399 [5:16:08<4:28:30,  7.82s/it]
 0: {'loss': 0.6029, 'grad_norm': 1.6125656108712123, 'learning_rate': 5.3191794001335615e-06, 'epoch': 0.53}
 0: {'loss': 0.606, 'grad_norm': 1.8209984782110218, 'learning_rate': 5.279574097210276e-06, 'epoch': 0.53}
 0:  53%|█████▎    | 2340/4399 [5:16:17<4:40:45,  8.18s/it]                                                        53%|█████▎    | 2340/4399 [5:16:17<4:40:45,  8.18s/it] 53%|█████▎    | 2341/4399 [5:16:27<5:00:18,  8.76s/it] 53%|█████▎    | 2342/4399 [5:16:36<4:56:46,  8.66s/it] 53%|█████▎    | 2343/4399 [5:16:42<4:35:13,  8.03s/it] 53%|█████▎    | 2344/4399 [5:16:50<4:29:07,  7.86s/it] 53%|█████▎    | 2345/4399 [5:16:57<4:24:13,  7.72s/it] 53%|█████▎    | 2346/4399 [5:17:06<4:32:14,  7.96s/it] 53%|█████▎    | 2347/4399 [5:17:13<4:23:29,  7.70s/it] 53%|█████▎    | 2348/4399 [5:17:22<4:33:36,  8.00s/it] 53%|█████▎    | 2349/4399 [5:17:31<4:45:54,  8.37s/it] 53%|█████▎    | 2350/4399 [5:17:40<4:48:49,  8.46s/it]                                                        53%|█████▎    | 2350/4399 [5:17:40<4:48:49,  8.46s/it] 53%|█████▎  
 0: {'loss': 0.6103, 'grad_norm': 1.6974225251947963, 'learning_rate': 5.2399511897991795e-06, 'epoch': 0.54}
 0:   | 2351/4399 [5:17:47<4:41:52,  8.26s/it] 53%|█████▎    | 2352/4399 [5:17:54<4:22:44,  7.70s/it] 53%|█████▎    | 2353/4399 [5:18:00<4:08:55,  7.30s/it] 54%|█████▎    | 2354/4399 [5:18:08<4:15:43,  7.50s/it] 54%|█████▎    | 2355/4399 [5:18:16<4:24:09,  7.75s/it] 54%|█████▎    | 2356/4399 [5:18:27<4:48:34,  8.48s/it] 54%|█████▎    | 2357/4399 [5:18:35<4:51:51,  8.58s/it] 54%|█████▎    | 2358/4399 [5:18:43<4:40:42,  8.25s/it] 54%|█████▎    | 2359/4399 [5:18:50<4:33:18,  8.04s/it] 54%|█████▎    | 2360/4399 [5:18:57<4:22:32,  7.73s/it]                                                        54%|█████▎    | 2360/4399 [5:18:57<4:22:32,  7.73s/it] 54%|█████▎    | 2361/4399 [5:19:03<4:03:59,  7.18s/it] 54%|█████▎    | 2362/4399 [5:19:12<4:17:41,  7.59s/it] 54%|█████▎    | 2363/4399 [5:19:19<4:17:50,  7.60s/it] 54%|█████▎    | 2364/4399 [
 0: {'loss': 0.5953, 'grad_norm': 1.6909532685156352, 'learning_rate': 5.200313172913214e-06, 'epoch': 0.54}
 0: 5:19:30<4:47:48,  8.49s/it] 54%|█████▍    | 2365/4399 [5:19:40<5:05:24,  9.01s/it] 54%|█████▍    | 2366/4399 [5:19:48<4:55:15,  8.71s/it] 54%|█████▍    | 2367/4399 [5:19:56<4:42:34,  8.34s/it] 54%|█████▍    | 2368/4399 [5:20:02<4:24:34,  7.82s/it] 54%|█████▍    | 2369/4399 [5:20:09<4:12:41,  7.47s/it] 54%|█████▍    | 2370/4399 [5:20:17<4:14:48,  7.53s/it]                                                        54%|█████▍    | 2370/4399 [5:20:17<4:14:48,  7.53s/it] 54%|█████▍    | 2371/4399 [5:20:24<4:17:17,  7.61s/it] 54%|█████▍    | 2372/4399 [5:20:34<4:37:07,  8.20s/it] 54%|█████▍    | 2373/4399 [5:20:42<4:37:24,  8.22s/it] 54%|█████▍    | 2374/4399 [5:20:50<4:35:33,  8.16s/it] 54%|█████▍    | 2375/4399 [5:20:58<4:29:15,  7.98s/it] 54%|█████▍    | 2376/4399 [5:21:06<4:27:29,  7.93s/it] 54%|█████▍    | 2377/4399 [5:21:14<4:27:15
 0: {'loss': 0.6042, 'grad_norm': 2.0569754176325263, 'learning_rate': 5.160662542516748e-06, 'epoch': 0.54}
 0: ,  7.93s/it] 54%|█████▍    | 2378/4399 [5:21:21<4:23:48,  7.83s/it] 54%|█████▍    | 2379/4399 [5:21:29<4:24:36,  7.86s/it] 54%|█████▍    | 2380/4399 [5:21:39<4:40:28,  8.34s/it]                                                        54%|█████▍    | 2380/4399 [5:21:39<4:40:28,  8.34s/it] 54%|█████▍    | 2381/4399 [5:21:47<4:43:47,  8.44s/it] 54%|█████▍    | 2382/4399 [5:21:56<4:42:52,  8.41s/it] 54%|█████▍    | 2383/4399 [5:22:04<4:39:24,  8.32s/it] 54%|█████▍    | 2384/4399 [5:22:11<4:33:12,  8.14s/it] 54%|█████▍    | 2385/4399 [5:22:17<4:11:22,  7.49s/it] 54%|█████▍    | 2386/4399 [5:22:25<4:08:52,  7.42s/it] 54%|█████▍    | 2387/4399 [5:22:33<4:13:50,  7.57s/it] 54%|█████▍    | 2388/4399 [5:22:42<4:30:42,  8.08s/it] 54%|█████▍    | 2389/4399 [5:22:51<4:44:16,  8.49s/it] 54%|█████▍    | 2390/4399 [5:23:02<5:09:33,  9.25s/it]  
 0: {'loss': 0.5963, 'grad_norm': 1.9136376434486015, 'learning_rate': 5.12100179536841e-06, 'epoch': 0.54}
 0: {'loss': 0.6054, 'grad_norm': 1.7034839166506506, 'learning_rate': 5.081333428863868e-06, 'epoch': 0.55}
 0:                                                       54%|█████▍    | 2390/4399 [5:23:02<5:09:33,  9.25s/it] 54%|█████▍    | 2391/4399 [5:23:09<4:45:15,  8.52s/it] 54%|█████▍    | 2392/4399 [5:23:16<4:31:33,  8.12s/it] 54%|█████▍    | 2393/4399 [5:23:22<4:08:19,  7.43s/it] 54%|█████▍    | 2394/4399 [5:23:30<4:09:47,  7.48s/it] 54%|█████▍    | 2395/4399 [5:23:38<4:17:11,  7.70s/it] 54%|█████▍    | 2396/4399 [5:23:47<4:33:44,  8.20s/it] 54%|█████▍    | 2397/4399 [5:23:56<4:35:11,  8.25s/it] 55%|█████▍    | 2398/4399 [5:24:05<4:42:14,  8.46s/it] 55%|█████▍    | 2399/4399 [5:24:13<4:39:38,  8.39s/it] 55%|█████▍    | 2400/4399 [5:24:21<4:33:52,  8.22s/it]                                                        55%|█████▍    | 2400/4399 [5:24:21<4:33:52,  8.22s/it] 55%|█████▍    | 2401/4399 [5:24:27<4:13:39,  7.62s/it] 55%|█████▍    |
 0: {'loss': 0.6102, 'grad_norm': 1.6924989474174492, 'learning_rate': 5.0416599408785785e-06, 'epoch': 0.55}
 0:  2402/4399 [5:24:35<4:14:42,  7.65s/it] 55%|█████▍    | 2403/4399 [5:24:43<4:18:42,  7.78s/it] 55%|█████▍    | 2404/4399 [5:24:52<4:29:25,  8.10s/it] 55%|█████▍    | 2405/4399 [5:25:02<4:50:39,  8.75s/it] 55%|█████▍    | 2406/4399 [5:25:10<4:43:32,  8.54s/it] 55%|█████▍    | 2407/4399 [5:25:17<4:30:35,  8.15s/it] 55%|█████▍    | 2408/4399 [5:25:24<4:16:51,  7.74s/it] 55%|█████▍    | 2409/4399 [5:25:31<4:07:53,  7.47s/it] 55%|█████▍    | 2410/4399 [5:25:38<4:07:09,  7.46s/it]                                                        55%|█████▍    | 2410/4399 [5:25:38<4:07:09,  7.46s/it] 55%|█████▍    | 2411/4399 [5:25:47<4:20:59,  7.88s/it] 55%|█████▍    | 2412/4399 [5:25:55<4:25:57,  8.03s/it] 55%|█████▍    | 2413/4399 [5:26:06<4:55:09,  8.92s/it] 55%|█████▍    | 2414/4399 [5:26:16<5:02:32,  9.14s/it] 55%|█████▍    | 2415/4399 [5:2
 0: {'loss': 0.5893, 'grad_norm': 2.444281184349111, 'learning_rate': 5.0019838296104865e-06, 'epoch': 0.55}
 0: 6:23<4:39:47,  8.46s/it] 55%|█████▍    | 2416/4399 [5:26:31<4:35:35,  8.34s/it] 55%|█████▍    | 2417/4399 [5:26:38<4:21:40,  7.92s/it] 55%|█████▍    | 2418/4399 [5:26:45<4:16:30,  7.77s/it] 55%|█████▍    | 2419/4399 [5:26:54<4:22:39,  7.96s/it] 55%|█████▌    | 2420/4399 [5:27:04<4:47:31,  8.72s/it]                                                        55%|█████▌    | 2420/4399 [5:27:04<4:47:31,  8.72s/it] 55%|█████▌    | 2421/4399 [5:27:15<5:05:41,  9.27s/it] 55%|█████▌    | 2422/4399 [5:27:23<4:54:07,  8.93s/it] 55%|█████▌    | 2423/4399 [5:27:30<4:39:28,  8.49s/it] 55%|█████▌    | 2424/4399 [5:27:38<4:33:00,  8.29s/it] 55%|█████▌    | 2425/4399 [5:27:45<4:20:27,  7.92s/it] 55%|█████▌    | 2426/4399 [5:27:53<4:21:33,  7.95s/it] 55%|█████▌    | 2427/4399 [5:28:02<4:31:17,  8.25s/it] 55%|█████▌    | 2428/4399 [5:28:12<4:42:51,  
 0: {'loss': 0.6008, 'grad_norm': 1.4515810132377736, 'learning_rate': 4.962307593422721e-06, 'epoch': 0.55}
 0: {'loss': 0.5968, 'grad_norm': 1.74582174054364, 'learning_rate': 4.922633730686284e-06, 'epoch': 0.55}
 0: 8.61s/it] 55%|█████▌    | 2429/4399 [5:28:22<4:59:56,  9.14s/it] 55%|█████▌    | 2430/4399 [5:28:30<4:49:46,  8.83s/it]                                                        55%|█████▌    | 2430/4399 [5:28:30<4:49:46,  8.83s/it] 55%|█████▌    | 2431/4399 [5:28:37<4:29:49,  8.23s/it] 55%|█████▌    | 2432/4399 [5:28:44<4:19:55,  7.93s/it] 55%|█████▌    | 2433/4399 [5:28:51<4:03:20,  7.43s/it] 55%|█████▌    | 2434/4399 [5:28:57<3:58:31,  7.28s/it] 55%|█████▌    | 2435/4399 [5:29:06<4:08:50,  7.60s/it] 55%|█████▌    | 2436/4399 [5:29:14<4:17:48,  7.88s/it] 55%|█████▌    | 2437/4399 [5:29:25<4:41:37,  8.61s/it] 55%|█████▌    | 2438/4399 [5:29:35<4:54:01,  9.00s/it] 55%|█████▌    | 2439/4399 [5:29:42<4:39:51,  8.57s/it] 55%|█████▌    | 2440/4399 [5:29:49<4:20:27,  7.98s/it]                                                        55%|███
 0: {'loss': 0.597, 'grad_norm': 1.6831263238181162, 'learning_rate': 4.88296473962272e-06, 'epoch': 0.56}
 0: █▌    | 2440/4399 [5:29:49<4:20:27,  7.98s/it] 55%|█████▌    | 2441/4399 [5:29:55<4:03:24,  7.46s/it] 56%|█████▌    | 2442/4399 [5:30:03<4:06:01,  7.54s/it] 56%|█████▌    | 2443/4399 [5:30:11<4:14:48,  7.82s/it] 56%|█████▌    | 2444/4399 [5:30:20<4:28:25,  8.24s/it] 56%|█████▌    | 2445/4399 [5:30:30<4:37:42,  8.53s/it] 56%|█████▌    | 2446/4399 [5:30:40<4:53:48,  9.03s/it] 56%|█████▌    | 2447/4399 [5:30:48<4:42:24,  8.68s/it] 56%|█████▌    | 2448/4399 [5:30:54<4:23:41,  8.11s/it] 56%|█████▌    | 2449/4399 [5:31:01<4:12:28,  7.77s/it] 56%|█████▌    | 2450/4399 [5:31:08<4:01:19,  7.43s/it]                                                        56%|█████▌    | 2450/4399 [5:31:08<4:01:19,  7.43s/it] 56%|█████▌    | 2451/4399 [5:31:17<4:19:06,  7.98s/it] 56%|█████▌    | 2452/4399 [5:31:25<4:15:26,  7.87s/it] 56%|█████▌    | 24
 0: {'loss': 0.5964, 'grad_norm': 2.739622186735266, 'learning_rate': 4.843303118146806e-06, 'epoch': 0.56}
 0: 53/4399 [5:31:34<4:25:52,  8.20s/it] 56%|█████▌    | 2454/4399 [5:31:43<4:35:56,  8.51s/it] 56%|█████▌    | 2455/4399 [5:31:50<4:22:52,  8.11s/it] 56%|█████▌    | 2456/4399 [5:31:59<4:26:24,  8.23s/it] 56%|█████▌    | 2457/4399 [5:32:05<4:06:46,  7.62s/it] 56%|█████▌    | 2458/4399 [5:32:13<4:14:11,  7.86s/it] 56%|█████▌    | 2459/4399 [5:32:22<4:24:25,  8.18s/it] 56%|█████▌    | 2460/4399 [5:32:30<4:20:20,  8.06s/it]                                                        56%|█████▌    | 2460/4399 [5:32:30<4:20:20,  8.06s/it] 56%|█████▌    | 2461/4399 [5:32:39<4:31:06,  8.39s/it] 56%|█████▌    | 2462/4399 [5:32:48<4:38:36,  8.63s/it] 56%|█████▌    | 2463/4399 [5:32:56<4:26:47,  8.27s/it] 56%|█████▌    | 2464/4399 [5:33:04<4:21:15,  8.10s/it] 56%|█████▌    | 2465/4399 [5:33:11<4:10:51,  7.78s/it] 56%|█████▌    | 2466/4399 [5:33:1
 0: {'loss': 0.602, 'grad_norm': 1.5760272350950362, 'learning_rate': 4.803651363709272e-06, 'epoch': 0.56}
 0: 7<4:00:53,  7.48s/it] 56%|█████▌    | 2467/4399 [5:33:26<4:06:56,  7.67s/it] 56%|█████▌    | 2468/4399 [5:33:35<4:21:15,  8.12s/it] 56%|█████▌    | 2469/4399 [5:33:44<4:35:12,  8.56s/it] 56%|█████▌    | 2470/4399 [5:33:53<4:37:50,  8.64s/it]                                                        56%|█████▌    | 2470/4399 [5:33:53<4:37:50,  8.64s/it] 56%|█████▌    | 2471/4399 [5:34:01<4:33:36,  8.51s/it] 56%|█████▌    | 2472/4399 [5:34:10<4:30:20,  8.42s/it] 56%|█████▌    | 2473/4399 [5:34:17<4:17:30,  8.02s/it] 56%|█████▌    | 2474/4399 [5:34:23<4:02:34,  7.56s/it] 56%|█████▋    | 2475/4399 [5:34:31<4:09:02,  7.77s/it] 56%|█████▋    | 2476/4399 [5:34:39<4:11:34,  7.85s/it] 56%|█████▋    | 2477/4399 [5:34:49<4:28:38,  8.39s/it] 56%|█████▋    | 2478/4399 [5:34:58<4:29:53,  8.43s/it] 56%|█████▋    | 2479/4399 [5:35:05<4:23:46,  8.2
 0: {'loss': 0.5739, 'grad_norm': 1.4547216635140232, 'learning_rate': 4.764011973139522e-06, 'epoch': 0.56}
 0: {'loss': 0.5831, 'grad_norm': 1.8700767404166576, 'learning_rate': 4.724387442488427e-06, 'epoch': 0.57}
 0: 4s/it] 56%|█████▋    | 2480/4399 [5:35:13<4:16:03,  8.01s/it]                                                        56%|█████▋    | 2480/4399 [5:35:13<4:16:03,  8.01s/it] 56%|█████▋    | 2481/4399 [5:35:19<3:57:38,  7.43s/it] 56%|█████▋    | 2482/4399 [5:35:26<3:58:35,  7.47s/it] 56%|█████▋    | 2483/4399 [5:35:35<4:03:53,  7.64s/it] 56%|█████▋    | 2484/4399 [5:35:44<4:21:29,  8.19s/it] 56%|█████▋    | 2485/4399 [5:35:52<4:19:57,  8.15s/it] 57%|█████▋    | 2486/4399 [5:36:01<4:31:41,  8.52s/it] 57%|█████▋    | 2487/4399 [5:36:09<4:26:19,  8.36s/it] 57%|█████▋    | 2488/4399 [5:36:16<4:11:31,  7.90s/it] 57%|█████▋    | 2489/4399 [5:36:22<3:55:49,  7.41s/it] 57%|█████▋    | 2490/4399 [5:36:29<3:45:06,  7.08s/it]                                                        57%|█████▋    | 2490/4399 [5:36:29<3:45:06,  7.08s/it] 57%|████
 0: {'loss': 0.5918, 'grad_norm': 1.7929675195764732, 'learning_rate': 4.684780266871139e-06, 'epoch': 0.57}
 0: ▋    | 2491/4399 [5:36:37<3:59:58,  7.55s/it] 57%|█████▋    | 2492/4399 [5:36:45<4:04:32,  7.69s/it] 57%|█████▋    | 2493/4399 [5:36:54<4:11:11,  7.91s/it] 57%|█████▋    | 2494/4399 [5:37:03<4:17:53,  8.12s/it] 57%|█████▋    | 2495/4399 [5:37:10<4:07:17,  7.79s/it] 57%|█████▋    | 2496/4399 [5:37:17<4:07:50,  7.81s/it] 57%|█████▋    | 2497/4399 [5:37:25<4:02:17,  7.64s/it] 57%|█████▋    | 2498/4399 [5:37:31<3:50:51,  7.29s/it] 57%|█████▋    | 2499/4399 [5:37:41<4:19:41,  8.20s/it] 57%|█████▋    | 2500/4399 [5:37:49<4:18:11,  8.16s/it]                                                        57%|█████▋    | 2500/4399 [5:37:49<4:18:11,  8.16s/it][INFO|trainer.py:3984] 2025-06-28 02:42:16,927 >> Saving model checkpoint to /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500
 0: [INFO|configuration_utils.py:419] 2025-06-28 02:42:16,940 >> Configuration saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/config.json
 0: [INFO|configuration_utils.py:911] 2025-06-28 02:42:16,943 >> Configuration saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/generation_config.json
 0: [INFO|modeling_utils.py:3580] 2025-06-28 02:42:24,488 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 4 checkpoint shards. You can find where each parameters has been saved in the index located at /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/model.safetensors.index.json.
 0: [INFO|tokenization_utils_base.py:2510] 2025-06-28 02:42:24,491 >> tokenizer config file saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/tokenizer_config.json
 0: [INFO|tokenization_utils_base.py:2519] 2025-06-28 02:42:24,494 >> Special tokens file saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/special_tokens_map.json
 0: [2025-06-28 02:42:24,656] [INFO] [logging.py:107:log_dist] [Rank 0] [Torch] Checkpoint global_step2500 is about to be saved!
30: [2025-06-28 02:42:24,666] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_120_mp_rank_00_model_states.pt...
 2: [2025-06-28 02:42:24,666] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_8_mp_rank_00_model_states.pt...
 5: [2025-06-28 02:42:24,666] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_20_mp_rank_00_model_states.pt...
10: [2025-06-28 02:42:24,667] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_40_mp_rank_00_model_states.pt...
27: [2025-06-28 02:42:24,667] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_108_mp_rank_00_model_states.pt...
 6: [2025-06-28 02:42:24,667] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_24_mp_rank_00_model_states.pt...
25: [2025-06-28 02:42:24,667] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_100_mp_rank_00_model_states.pt...
19: [2025-06-28 02:42:24,667] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_76_mp_rank_00_model_states.pt...
22: [2025-06-28 02:42:24,667] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_88_mp_rank_00_model_states.pt...
17: [2025-06-28 02:42:24,667] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_68_mp_rank_00_model_states.pt...
15: [2025-06-28 02:42:24,667] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_60_mp_rank_00_model_states.pt...
23: [2025-06-28 02:42:24,667] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_92_mp_rank_00_model_states.pt...
24: [2025-06-28 02:42:24,667] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_96_mp_rank_00_model_states.pt...
 4: [2025-06-28 02:42:24,667] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_16_mp_rank_00_model_states.pt...
28: [2025-06-28 02:42:24,667] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_112_mp_rank_00_model_states.pt...
18: [2025-06-28 02:42:24,667] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_72_mp_rank_00_model_states.pt...
14: [2025-06-28 02:42:24,667] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_56_mp_rank_00_model_states.pt...
 9: [2025-06-28 02:42:24,667] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_36_mp_rank_00_model_states.pt...
20: [2025-06-28 02:42:24,667] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_80_mp_rank_00_model_states.pt...
31: [2025-06-28 02:42:24,667] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_124_mp_rank_00_model_states.pt...
29: [2025-06-28 02:42:24,668] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_116_mp_rank_00_model_states.pt...
 3: [2025-06-28 02:42:24,668] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_12_mp_rank_00_model_states.pt...
12: [2025-06-28 02:42:24,668] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_48_mp_rank_00_model_states.pt...
 8: [2025-06-28 02:42:24,668] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_32_mp_rank_00_model_states.pt...
 7: [2025-06-28 02:42:24,668] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_28_mp_rank_00_model_states.pt...
 1: [2025-06-28 02:42:24,669] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_4_mp_rank_00_model_states.pt...
26: [2025-06-28 02:42:24,669] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_104_mp_rank_00_model_states.pt...
11: [2025-06-28 02:42:24,669] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_44_mp_rank_00_model_states.pt...
13: [2025-06-28 02:42:24,669] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_52_mp_rank_00_model_states.pt...
21: [2025-06-28 02:42:24,670] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_84_mp_rank_00_model_states.pt...
16: [2025-06-28 02:42:24,671] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_64_mp_rank_00_model_states.pt...
30: [2025-06-28 02:42:24,693] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_120_mp_rank_00_model_states.pt.
27: [2025-06-28 02:42:24,696] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_108_mp_rank_00_model_states.pt.
 5: [2025-06-28 02:42:24,700] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_20_mp_rank_00_model_states.pt.
19: [2025-06-28 02:42:24,700] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_76_mp_rank_00_model_states.pt.
10: [2025-06-28 02:42:24,700] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_40_mp_rank_00_model_states.pt.
20: [2025-06-28 02:42:24,700] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_80_mp_rank_00_model_states.pt.
18: [2025-06-28 02:42:24,702] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_72_mp_rank_00_model_states.pt.
 2: [2025-06-28 02:42:24,703] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_8_mp_rank_00_model_states.pt.
31: [2025-06-28 02:42:24,704] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_124_mp_rank_00_model_states.pt.
23: [2025-06-28 02:42:24,705] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_92_mp_rank_00_model_states.pt.
15: [2025-06-28 02:42:24,706] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_60_mp_rank_00_model_states.pt.
24: [2025-06-28 02:42:24,707] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_96_mp_rank_00_model_states.pt.
 6: [2025-06-28 02:42:24,709] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_24_mp_rank_00_model_states.pt.
 8: [2025-06-28 02:42:24,709] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_32_mp_rank_00_model_states.pt.
28: [2025-06-28 02:42:24,710] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_112_mp_rank_00_model_states.pt.
22: [2025-06-28 02:42:24,710] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_88_mp_rank_00_model_states.pt.
25: [2025-06-28 02:42:24,714] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_100_mp_rank_00_model_states.pt.
 9: [2025-06-28 02:42:24,715] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_36_mp_rank_00_model_states.pt.
17: [2025-06-28 02:42:24,716] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_68_mp_rank_00_model_states.pt.
 3: [2025-06-28 02:42:24,718] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_12_mp_rank_00_model_states.pt.
12: [2025-06-28 02:42:24,719] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_48_mp_rank_00_model_states.pt.
 1: [2025-06-28 02:42:24,719] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_4_mp_rank_00_model_states.pt.
 4: [2025-06-28 02:42:24,719] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_16_mp_rank_00_model_states.pt.
 0: [2025-06-28 02:42:24,719] [INFO] [logging.py:107:log_dist] [Rank 0] Saving model checkpoint: /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_0_mp_rank_00_model_states.pt
14: [2025-06-28 02:42:24,719] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_56_mp_rank_00_model_states.pt.
 0: [2025-06-28 02:42:24,720] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_0_mp_rank_00_model_states.pt...
29: [2025-06-28 02:42:24,720] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_116_mp_rank_00_model_states.pt.
26: [2025-06-28 02:42:24,721] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_104_mp_rank_00_model_states.pt.
 7: [2025-06-28 02:42:24,721] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_28_mp_rank_00_model_states.pt.
11: [2025-06-28 02:42:24,722] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_44_mp_rank_00_model_states.pt.
21: [2025-06-28 02:42:24,722] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_84_mp_rank_00_model_states.pt.
13: [2025-06-28 02:42:24,722] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_52_mp_rank_00_model_states.pt.
16: [2025-06-28 02:42:24,727] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_64_mp_rank_00_model_states.pt.
 0: [2025-06-28 02:42:24,744] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/zero_pp_rank_0_mp_rank_00_model_states.pt.
 0: [2025-06-28 02:42:24,950] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
 4: [2025-06-28 02:42:24,950] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_16_mp_rank_00_optim_states.pt...
 9: [2025-06-28 02:42:24,950] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_36_mp_rank_00_optim_states.pt...
 6: [2025-06-28 02:42:24,950] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_24_mp_rank_00_optim_states.pt...
10: [2025-06-28 02:42:24,950] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_40_mp_rank_00_optim_states.pt...
 2: [2025-06-28 02:42:24,950] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_8_mp_rank_00_optim_states.pt...
15: [2025-06-28 02:42:24,950] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_60_mp_rank_00_optim_states.pt...
 7: [2025-06-28 02:42:24,950] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_28_mp_rank_00_optim_states.pt...
 5: [2025-06-28 02:42:24,950] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_20_mp_rank_00_optim_states.pt...
 8: [2025-06-28 02:42:24,950] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_32_mp_rank_00_optim_states.pt...
14: [2025-06-28 02:42:24,950] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_56_mp_rank_00_optim_states.pt...
12: [2025-06-28 02:42:24,950] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_48_mp_rank_00_optim_states.pt...
 1: [2025-06-28 02:42:24,950] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_4_mp_rank_00_optim_states.pt...
19: [2025-06-28 02:42:24,950] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_76_mp_rank_00_optim_states.pt...
25: [2025-06-28 02:42:24,950] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_100_mp_rank_00_optim_states.pt...
23: [2025-06-28 02:42:24,950] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_92_mp_rank_00_optim_states.pt...
28: [2025-06-28 02:42:24,950] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_112_mp_rank_00_optim_states.pt...
21: [2025-06-28 02:42:24,950] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_84_mp_rank_00_optim_states.pt...
30: [2025-06-28 02:42:24,950] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_120_mp_rank_00_optim_states.pt...
22: [2025-06-28 02:42:24,950] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_88_mp_rank_00_optim_states.pt...
31: [2025-06-28 02:42:24,950] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_124_mp_rank_00_optim_states.pt...
17: [2025-06-28 02:42:24,950] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_68_mp_rank_00_optim_states.pt...
20: [2025-06-28 02:42:24,950] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_80_mp_rank_00_optim_states.pt...
29: [2025-06-28 02:42:24,950] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_116_mp_rank_00_optim_states.pt...
24: [2025-06-28 02:42:24,950] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_96_mp_rank_00_optim_states.pt...
18: [2025-06-28 02:42:24,950] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_72_mp_rank_00_optim_states.pt...
26: [2025-06-28 02:42:24,950] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_104_mp_rank_00_optim_states.pt...
27: [2025-06-28 02:42:24,950] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_108_mp_rank_00_optim_states.pt...
16: [2025-06-28 02:42:24,950] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_64_mp_rank_00_optim_states.pt...
13: [2025-06-28 02:42:24,950] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_52_mp_rank_00_optim_states.pt...
11: [2025-06-28 02:42:24,950] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_44_mp_rank_00_optim_states.pt...
 3: [2025-06-28 02:42:24,950] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_12_mp_rank_00_optim_states.pt...
 0: [2025-06-28 02:42:25,432] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
 0: [2025-06-28 02:42:25,439] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
 8: [2025-06-28 02:42:27,688] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_32_mp_rank_00_optim_states.pt.
 8: [2025-06-28 02:42:27,688] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_32_mp_rank_00_optim_states.pt
15: [2025-06-28 02:42:27,703] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_60_mp_rank_00_optim_states.pt.
15: [2025-06-28 02:42:27,703] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_60_mp_rank_00_optim_states.pt
 1: [2025-06-28 02:42:27,717] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_4_mp_rank_00_optim_states.pt.
 1: [2025-06-28 02:42:27,717] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_4_mp_rank_00_optim_states.pt
17: [2025-06-28 02:42:27,747] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_68_mp_rank_00_optim_states.pt.
17: [2025-06-28 02:42:27,747] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_68_mp_rank_00_optim_states.pt
27: [2025-06-28 02:42:27,752] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_108_mp_rank_00_optim_states.pt.
27: [2025-06-28 02:42:27,752] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_108_mp_rank_00_optim_states.pt
22: [2025-06-28 02:42:27,758] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_88_mp_rank_00_optim_states.pt.
22: [2025-06-28 02:42:27,758] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_88_mp_rank_00_optim_states.pt
14: [2025-06-28 02:42:27,758] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_56_mp_rank_00_optim_states.pt.
14: [2025-06-28 02:42:27,758] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_56_mp_rank_00_optim_states.pt
11: [2025-06-28 02:42:27,759] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_44_mp_rank_00_optim_states.pt.
11: [2025-06-28 02:42:27,760] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_44_mp_rank_00_optim_states.pt
 2: [2025-06-28 02:42:27,763] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_8_mp_rank_00_optim_states.pt.
 2: [2025-06-28 02:42:27,763] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_8_mp_rank_00_optim_states.pt
30: [2025-06-28 02:42:27,768] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_120_mp_rank_00_optim_states.pt.
30: [2025-06-28 02:42:27,768] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_120_mp_rank_00_optim_states.pt
 7: [2025-06-28 02:42:27,769] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_28_mp_rank_00_optim_states.pt.
 7: [2025-06-28 02:42:27,770] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_28_mp_rank_00_optim_states.pt
18: [2025-06-28 02:42:27,769] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_72_mp_rank_00_optim_states.pt.
18: [2025-06-28 02:42:27,770] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_72_mp_rank_00_optim_states.pt
28: [2025-06-28 02:42:27,770] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_112_mp_rank_00_optim_states.pt.
28: [2025-06-28 02:42:27,771] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_112_mp_rank_00_optim_states.pt
 3: [2025-06-28 02:42:27,772] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_12_mp_rank_00_optim_states.pt.
 3: [2025-06-28 02:42:27,773] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_12_mp_rank_00_optim_states.pt
 4: [2025-06-28 02:42:27,774] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_16_mp_rank_00_optim_states.pt.
 4: [2025-06-28 02:42:27,774] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_16_mp_rank_00_optim_states.pt
21: [2025-06-28 02:42:27,776] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_84_mp_rank_00_optim_states.pt.
21: [2025-06-28 02:42:27,776] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_84_mp_rank_00_optim_states.pt
 9: [2025-06-28 02:42:27,789] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_36_mp_rank_00_optim_states.pt.
 9: [2025-06-28 02:42:27,790] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_36_mp_rank_00_optim_states.pt
20: [2025-06-28 02:42:27,791] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_80_mp_rank_00_optim_states.pt.
20: [2025-06-28 02:42:27,791] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_80_mp_rank_00_optim_states.pt
26: [2025-06-28 02:42:27,805] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_104_mp_rank_00_optim_states.pt.
26: [2025-06-28 02:42:27,805] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_104_mp_rank_00_optim_states.pt
 6: [2025-06-28 02:42:27,823] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_24_mp_rank_00_optim_states.pt.
 6: [2025-06-28 02:42:27,823] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_24_mp_rank_00_optim_states.pt
19: [2025-06-28 02:42:27,840] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_76_mp_rank_00_optim_states.pt.
19: [2025-06-28 02:42:27,841] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_76_mp_rank_00_optim_states.pt
13: [2025-06-28 02:42:27,849] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_52_mp_rank_00_optim_states.pt.
 5: [2025-06-28 02:42:27,850] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_20_mp_rank_00_optim_states.pt.
13: [2025-06-28 02:42:27,849] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_52_mp_rank_00_optim_states.pt
 5: [2025-06-28 02:42:27,850] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_20_mp_rank_00_optim_states.pt
12: [2025-06-28 02:42:27,861] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_48_mp_rank_00_optim_states.pt.
12: [2025-06-28 02:42:27,862] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_48_mp_rank_00_optim_states.pt
23: [2025-06-28 02:42:27,873] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_92_mp_rank_00_optim_states.pt.
23: [2025-06-28 02:42:27,873] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_92_mp_rank_00_optim_states.pt
25: [2025-06-28 02:42:27,887] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_100_mp_rank_00_optim_states.pt.
25: [2025-06-28 02:42:27,887] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_100_mp_rank_00_optim_states.pt
16: [2025-06-28 02:42:27,891] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_64_mp_rank_00_optim_states.pt.
16: [2025-06-28 02:42:27,891] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_64_mp_rank_00_optim_states.pt
10: [2025-06-28 02:42:27,904] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_40_mp_rank_00_optim_states.pt.
10: [2025-06-28 02:42:27,904] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_40_mp_rank_00_optim_states.pt
31: [2025-06-28 02:42:27,914] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_124_mp_rank_00_optim_states.pt.
31: [2025-06-28 02:42:27,914] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_124_mp_rank_00_optim_states.pt
24: [2025-06-28 02:42:27,925] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_96_mp_rank_00_optim_states.pt.
24: [2025-06-28 02:42:27,925] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_96_mp_rank_00_optim_states.pt
29: [2025-06-28 02:42:27,987] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_116_mp_rank_00_optim_states.pt.
29: [2025-06-28 02:42:27,987] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/global_step2500/bf16_zero_pp_rank_116_mp_rank_00_optim_states.pt
24: [2025-06-28 02:42:28,268] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2500 is ready now!
15: [2025-06-28 02:42:28,268] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2500 is ready now!
23: [2025-06-28 02:42:28,268] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2500 is ready now!
17: [2025-06-28 02:42:28,268] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2500 is ready now!
 1: [2025-06-28 02:42:28,268] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2500 is ready now!
 9: [2025-06-28 02:42:28,269] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2500 is ready now!
 2: [2025-06-28 02:42:28,269] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2500 is ready now!
 5: [2025-06-28 02:42:28,269] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2500 is ready now!
 6: [2025-06-28 02:42:28,269] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2500 is ready now!
 4: [2025-06-28 02:42:28,269] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2500 is ready now!
13: [2025-06-28 02:42:28,269] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2500 is ready now!
29: [2025-06-28 02:42:28,269] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2500 is ready now!
10: [2025-06-28 02:42:28,269] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2500 is ready now!
19: [2025-06-28 02:42:28,269] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2500 is ready now!
25: [2025-06-28 02:42:28,269] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2500 is ready now!
27: [2025-06-28 02:42:28,269] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2500 is ready now!
 3: [2025-06-28 02:42:28,269] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2500 is ready now!
22: [2025-06-28 02:42:28,269] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2500 is ready now!
 7: [2025-06-28 02:42:28,269] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2500 is ready now!
21: [2025-06-28 02:42:28,269] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2500 is ready now!
30: [2025-06-28 02:42:28,269] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2500 is ready now!
12: [2025-06-28 02:42:28,269] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2500 is ready now!
31: [2025-06-28 02:42:28,269] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2500 is ready now!
28: [2025-06-28 02:42:28,269] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2500 is ready now!
18: [2025-06-28 02:42:28,269] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2500 is ready now!
14: [2025-06-28 02:42:28,269] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2500 is ready now!
20: [2025-06-28 02:42:28,269] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2500 is ready now!
11: [2025-06-28 02:42:28,269] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2500 is ready now!
 0: [2025-06-28 02:42:28,270] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2500 is ready now!
 8: [2025-06-28 02:42:28,270] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2500 is ready now!
16: [2025-06-28 02:42:28,271] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2500 is ready now!
26: [2025-06-28 02:42:28,271] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2500 is ready now!
 0: [INFO|image_processing_base.py:260] 2025-06-28 02:42:28,332 >> Image processor saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/preprocessor_config.json
 0: [INFO|tokenization_utils_base.py:2510] 2025-06-28 02:42:28,334 >> tokenizer config file saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/tokenizer_config.json
 0: [INFO|tokenization_utils_base.py:2519] 2025-06-28 02:42:28,342 >> Special tokens file saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/special_tokens_map.json
 0: [INFO|processing_utils.py:648] 2025-06-28 02:42:28,921 >> chat template saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-2500/chat_template.json
 0:  57%|█████▋    | 2501/4399 [5:39:07<15:20:03, 29.09s/it] 57%|█████▋    | 2502/4399 [5:39:17<12:12:12, 23.16s/it] 57%|█████▋    | 2503/4399 [5:39:23<9:35:15, 18.20s/it] /usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
 0:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
 0: {'loss': 0.6027, 'grad_norm': 1.4762540829775088, 'learning_rate': 4.645192940309987e-06, 'epoch': 0.57}
 0:  57%|█████▋    | 2504/4399 [5:39:30<7:49:42, 14.87s/it] 57%|█████▋    | 2505/4399 [5:39:37<6:28:30, 12.31s/it] 57%|█████▋    | 2506/4399 [5:39:44<5:39:46, 10.77s/it] 57%|█████▋    | 2507/4399 [5:39:53<5:24:36, 10.29s/it] 57%|█████▋    | 2508/4399 [5:40:01<5:04:05,  9.65s/it] 57%|█████▋    | 2509/4399 [5:40:11<5:06:50,  9.74s/it] 57%|█████▋    | 2510/4399 [5:40:21<5:02:25,  9.61s/it]                                                        57%|█████▋    | 2510/4399 [5:40:21<5:02:25,  9.61s/it] 57%|█████▋    | 2511/4399 [5:40:29<4:49:52,  9.21s/it] 57%|█████▋    | 2512/4399 [5:40:36<4:30:19,  8.60s/it] 57%|█████▋    | 2513/4399 [5:40:42<4:07:36,  7.88s/it] 57%|█████▋    | 2514/4399 [5:40:50<4:04:52,  7.79s/it] 57%|█████▋    | 2515/4399 [5:40:58<4:06:15,  7.84s/it] 57%|█████▋    | 2516/4399 [5:41:07<4:15:28,  8.14s/it] 57%|███
 0: {'loss': 0.598, 'grad_norm': 1.5310329689564834, 'learning_rate': 4.6056279555774235e-06, 'epoch': 0.57}
 0: ██▋    | 2517/4399 [5:41:15<4:22:28,  8.37s/it] 57%|█████▋    | 2518/4399 [5:41:25<4:30:54,  8.64s/it] 57%|█████▋    | 2519/4399 [5:41:33<4:28:08,  8.56s/it] 57%|█████▋    | 2520/4399 [5:41:40<4:15:42,  8.17s/it]                                                        57%|█████▋    | 2520/4399 [5:41:40<4:15:42,  8.17s/it] 57%|█████▋    | 2521/4399 [5:41:48<4:10:16,  8.00s/it] 57%|█████▋    | 2522/4399 [5:41:56<4:07:51,  7.92s/it] 57%|█████▋    | 2523/4399 [5:42:05<4:18:27,  8.27s/it] 57%|█████▋    | 2524/4399 [5:42:15<4:32:13,  8.71s/it] 57%|█████▋    | 2525/4399 [5:42:23<4:33:49,  8.77s/it] 57%|█████▋    | 2526/4399 [5:42:32<4:29:48,  8.64s/it] 57%|█████▋    | 2527/4399 [5:42:39<4:15:30,  8.19s/it] 57%|█████▋    | 2528/4399 [5:42:46<4:08:27,  7.97s/it] 57%|█████▋    | 2529/4399 [5:42:53<3:54:46,  7.53s/it] 58%|█████▊    | 
 0: {'loss': 0.5833, 'grad_norm': 1.9622473966780658, 'learning_rate': 4.566087804039059e-06, 'epoch': 0.58}
 0: {'loss': 0.5822, 'grad_norm': 1.8641496065757774, 'learning_rate': 4.526574975496781e-06, 'epoch': 0.58}
 0: 2530/4399 [5:43:01<4:03:47,  7.83s/it]                                                        58%|█████▊    | 2530/4399 [5:43:01<4:03:47,  7.83s/it] 58%|█████▊    | 2531/4399 [5:43:10<4:14:59,  8.19s/it] 58%|█████▊    | 2532/4399 [5:43:19<4:20:17,  8.37s/it] 58%|█████▊    | 2533/4399 [5:43:29<4:35:25,  8.86s/it] 58%|█████▊    | 2534/4399 [5:43:38<4:35:46,  8.87s/it] 58%|█████▊    | 2535/4399 [5:43:45<4:18:39,  8.33s/it] 58%|█████▊    | 2536/4399 [5:43:53<4:10:58,  8.08s/it] 58%|█████▊    | 2537/4399 [5:43:59<3:55:21,  7.58s/it] 58%|█████▊    | 2538/4399 [5:44:05<3:42:46,  7.18s/it] 58%|█████▊    | 2539/4399 [5:44:13<3:50:54,  7.45s/it] 58%|█████▊    | 2540/4399 [5:44:23<4:11:07,  8.11s/it]                                                        58%|█████▊    | 2540/4399 [5:44:23<4:11:07,  8.11s/it] 58%|█████▊    | 2541/4399 [5:44:33<4:25:33
 0: {'loss': 0.5973, 'grad_norm': 1.7657446265059784, 'learning_rate': 4.487091958031984e-06, 'epoch': 0.58}
 0: ,  8.58s/it] 58%|█████▊    | 2542/4399 [5:44:41<4:25:23,  8.58s/it] 58%|█████▊    | 2543/4399 [5:44:48<4:05:40,  7.94s/it] 58%|█████▊    | 2544/4399 [5:44:55<3:58:50,  7.73s/it] 58%|█████▊    | 2545/4399 [5:45:02<3:55:18,  7.62s/it] 58%|█████▊    | 2546/4399 [5:45:09<3:49:08,  7.42s/it] 58%|█████▊    | 2547/4399 [5:45:18<3:56:03,  7.65s/it] 58%|█████▊    | 2548/4399 [5:45:26<4:05:16,  7.95s/it] 58%|█████▊    | 2549/4399 [5:45:35<4:15:26,  8.28s/it] 58%|█████▊    | 2550/4399 [5:45:44<4:16:49,  8.33s/it]                                                        58%|█████▊    | 2550/4399 [5:45:44<4:16:49,  8.33s/it] 58%|█████▊    | 2551/4399 [5:45:52<4:14:27,  8.26s/it] 58%|█████▊    | 2552/4399 [5:45:59<4:05:15,  7.97s/it] 58%|█████▊    | 2553/4399 [5:46:06<3:55:44,  7.66s/it] 58%|█████▊    | 2554/4399 [5:46:12<3:43:10,  7.26s/it] 5
 0: {'loss': 0.5877, 'grad_norm': 1.480147081946016, 'learning_rate': 4.447641237848882e-06, 'epoch': 0.58}
 0: 8%|█████▊    | 2555/4399 [5:46:21<3:52:06,  7.55s/it] 58%|█████▊    | 2556/4399 [5:46:30<4:05:02,  7.98s/it] 58%|█████▊    | 2557/4399 [5:46:39<4:17:18,  8.38s/it] 58%|█████▊    | 2558/4399 [5:46:48<4:20:00,  8.47s/it] 58%|█████▊    | 2559/4399 [5:46:55<4:08:37,  8.11s/it] 58%|█████▊    | 2560/4399 [5:47:03<4:05:09,  8.00s/it]                                                        58%|█████▊    | 2560/4399 [5:47:03<4:05:09,  8.00s/it] 58%|█████▊    | 2561/4399 [5:47:10<3:59:40,  7.82s/it] 58%|█████▊    | 2562/4399 [5:47:17<3:50:08,  7.52s/it] 58%|█████▊    | 2563/4399 [5:47:25<3:57:05,  7.75s/it] 58%|█████▊    | 2564/4399 [5:47:34<4:12:32,  8.26s/it] 58%|█████▊    | 2565/4399 [5:47:44<4:24:01,  8.64s/it] 58%|█████▊    | 2566/4399 [5:47:52<4:20:12,  8.52s/it] 58%|█████▊    | 2567/4399 [5:48:01<4:18:48,  8.48s/it] 58%|████
 0: {'loss': 0.5778, 'grad_norm': 1.4704762225294268, 'learning_rate': 4.40822529911797e-06, 'epoch': 0.58}
 0: █▊    | 2568/4399 [5:48:09<4:14:08,  8.33s/it] 58%|█████▊    | 2569/4399 [5:48:15<4:00:23,  7.88s/it] 58%|█████▊    | 2570/4399 [5:48:22<3:46:04,  7.42s/it]                                                        58%|█████▊    | 2570/4399 [5:48:22<3:46:04,  7.42s/it] 58%|█████▊    | 2571/4399 [5:48:30<3:51:02,  7.58s/it] 58%|█████▊    | 2572/4399 [5:48:39<4:10:20,  8.22s/it] 58%|█████▊    | 2573/4399 [5:48:47<4:06:37,  8.10s/it] 59%|█████▊    | 2574/4399 [5:48:56<4:16:01,  8.42s/it] 59%|█████▊    | 2575/4399 [5:49:03<4:02:19,  7.97s/it] 59%|█████▊    | 2576/4399 [5:49:11<4:00:11,  7.91s/it] 59%|█████▊    | 2577/4399 [5:49:19<3:56:19,  7.78s/it] 59%|█████▊    | 2578/4399 [5:49:26<3:52:30,  7.66s/it] 59%|█████▊    | 2579/4399 [5:49:36<4:11:19,  8.29s/it] 59%|█████▊    | 2580/4399 [5:49:46<4:26:05,  8.78s/it]                                
 0: {'loss': 0.5942, 'grad_norm': 2.264305866903697, 'learning_rate': 4.3688466238195855e-06, 'epoch': 0.59}
 0: {'loss': 0.5864, 'grad_norm': 2.0838002818520356, 'learning_rate': 4.329507691587632e-06, 'epoch': 0.59}
 0:                         59%|█████▊    | 2580/4399 [5:49:46<4:26:05,  8.78s/it] 59%|█████▊    | 2581/4399 [5:49:54<4:19:27,  8.56s/it] 59%|█████▊    | 2582/4399 [5:50:02<4:13:05,  8.36s/it] 59%|█████▊    | 2583/4399 [5:50:10<4:13:04,  8.36s/it] 59%|█████▊    | 2584/4399 [5:50:17<3:57:58,  7.87s/it] 59%|█████▉    | 2585/4399 [5:50:23<3:45:09,  7.45s/it] 59%|█████▉    | 2586/4399 [5:50:29<3:34:31,  7.10s/it] 59%|█████▉    | 2587/4399 [5:50:38<3:44:54,  7.45s/it] 59%|█████▉    | 2588/4399 [5:50:47<4:03:51,  8.08s/it] 59%|█████▉    | 2589/4399 [5:50:56<4:09:32,  8.27s/it] 59%|█████▉    | 2590/4399 [5:51:06<4:25:01,  8.79s/it]                                                        59%|█████▉    | 2590/4399 [5:51:06<4:25:01,  8.79s/it] 59%|█████▉    | 2591/4399 [5:51:13<4:07:10,  8.20s/it] 59%|█████▉    | 2592/4399 [5:51:22<4:13:30,  
 0: {'loss': 0.6029, 'grad_norm': 1.483329355490553, 'learning_rate': 4.29021097955343e-06, 'epoch': 0.59}
 0: 8.42s/it] 59%|█████▉    | 2593/4399 [5:51:28<3:55:18,  7.82s/it] 59%|█████▉    | 2594/4399 [5:51:35<3:47:21,  7.56s/it] 59%|█████▉    | 2595/4399 [5:51:44<3:59:51,  7.98s/it] 59%|█████▉    | 2596/4399 [5:51:52<4:01:38,  8.04s/it] 59%|█████▉    | 2597/4399 [5:52:01<4:07:53,  8.25s/it] 59%|█████▉    | 2598/4399 [5:52:11<4:22:10,  8.73s/it] 59%|█████▉    | 2599/4399 [5:52:18<4:09:33,  8.32s/it] 59%|█████▉    | 2600/4399 [5:52:26<4:07:32,  8.26s/it]                                                        59%|█████▉    | 2600/4399 [5:52:26<4:07:32,  8.26s/it] 59%|█████▉    | 2601/4399 [5:52:33<3:52:19,  7.75s/it] 59%|█████▉    | 2602/4399 [5:52:40<3:43:39,  7.47s/it] 59%|█████▉    | 2603/4399 [5:52:48<3:47:52,  7.61s/it] 59%|█████▉    | 2604/4399 [5:52:57<4:04:32,  8.17s/it] 59%|█████▉    | 2605/4399 [5:53:07<4:16:01,  8.56s/it] 59%|
 0: {'loss': 0.5864, 'grad_norm': 1.5330180215147486, 'learning_rate': 4.250958962189739e-06, 'epoch': 0.59}
 0: █████▉    | 2606/4399 [5:53:16<4:19:47,  8.69s/it] 59%|█████▉    | 2607/4399 [5:53:23<4:09:39,  8.36s/it] 59%|█████▉    | 2608/4399 [5:53:32<4:11:04,  8.41s/it] 59%|█████▉    | 2609/4399 [5:53:38<3:55:07,  7.88s/it] 59%|█████▉    | 2610/4399 [5:53:46<3:48:43,  7.67s/it]                                                        59%|█████▉    | 2610/4399 [5:53:46<3:48:43,  7.67s/it] 59%|█████▉    | 2611/4399 [5:53:53<3:48:37,  7.67s/it] 59%|█████▉    | 2612/4399 [5:54:01<3:53:33,  7.84s/it] 59%|█████▉    | 2613/4399 [5:54:12<4:16:33,  8.62s/it] 59%|█████▉    | 2614/4399 [5:54:21<4:17:12,  8.65s/it] 59%|█████▉    | 2615/4399 [5:54:29<4:12:01,  8.48s/it] 59%|█████▉    | 2616/4399 [5:54:36<4:03:22,  8.19s/it] 59%|█████▉    | 2617/4399 [5:54:43<3:49:21,  7.72s/it] 60%|█████▉    | 2618/4399 [5:54:49<3:33:21,  7.19s/it] 60%|█████
 0: {'loss': 0.5753, 'grad_norm': 1.4590942319770204, 'learning_rate': 4.211754111154946e-06, 'epoch': 0.6}
 0: {'loss': 0.5741, 'grad_norm': 1.609886234061156, 'learning_rate': 4.172598895137417e-06, 'epoch': 0.6}
 0: ▉    | 2619/4399 [5:54:57<3:39:08,  7.39s/it] 60%|█████▉    | 2620/4399 [5:55:04<3:42:48,  7.51s/it]                                                        60%|█████▉    | 2620/4399 [5:55:04<3:42:48,  7.51s/it] 60%|█████▉    | 2621/4399 [5:55:14<4:02:04,  8.17s/it] 60%|█████▉    | 2622/4399 [5:55:23<4:10:56,  8.47s/it] 60%|█████▉    | 2623/4399 [5:55:32<4:14:56,  8.61s/it] 60%|█████▉    | 2624/4399 [5:55:41<4:12:54,  8.55s/it] 60%|█████▉    | 2625/4399 [5:55:47<3:53:22,  7.89s/it] 60%|█████▉    | 2626/4399 [5:55:54<3:44:04,  7.58s/it] 60%|█████▉    | 2627/4399 [5:56:02<3:52:47,  7.88s/it] 60%|█████▉    | 2628/4399 [5:56:13<4:12:27,  8.55s/it] 60%|█████▉    | 2629/4399 [5:56:24<4:35:31,  9.34s/it] 60%|█████▉    | 2630/4399 [5:56:33<4:34:49,  9.32s/it]                                                        60%|█████▉    | 2630/4399 [5:56:3
 0: {'loss': 0.5848, 'grad_norm': 1.401408550364115, 'learning_rate': 4.133495779700057e-06, 'epoch': 0.6}
 0: 3<4:34:49,  9.32s/it] 60%|█████▉    | 2631/4399 [5:56:41<4:18:47,  8.78s/it] 60%|█████▉    | 2632/4399 [5:56:49<4:15:37,  8.68s/it] 60%|█████▉    | 2633/4399 [5:56:55<3:53:48,  7.94s/it] 60%|█████▉    | 2634/4399 [5:57:02<3:45:15,  7.66s/it] 60%|█████▉    | 2635/4399 [5:57:12<4:05:05,  8.34s/it] 60%|█████▉    | 2636/4399 [5:57:20<4:01:11,  8.21s/it] 60%|█████▉    | 2637/4399 [5:57:31<4:24:41,  9.01s/it] 60%|█████▉    | 2638/4399 [5:57:39<4:18:41,  8.81s/it] 60%|█████▉    | 2639/4399 [5:57:48<4:14:57,  8.69s/it] 60%|██████    | 2640/4399 [5:57:56<4:07:11,  8.43s/it]                                                        60%|██████    | 2640/4399 [5:57:56<4:07:11,  8.43s/it] 60%|██████    | 2641/4399 [5:58:03<4:00:56,  8.22s/it] 60%|██████    | 2642/4399 [5:58:11<3:52:43,  7.95s/it] 60%|██████    | 2643/4399 [5:58:19<4:01:01,  8.2
 0: {'loss': 0.587, 'grad_norm': 1.6239778285230726, 'learning_rate': 4.09444722712505e-06, 'epoch': 0.6}
 0: 4s/it] 60%|██████    | 2644/4399 [5:58:28<4:02:15,  8.28s/it] 60%|██████    | 2645/4399 [5:58:38<4:14:21,  8.70s/it] 60%|██████    | 2646/4399 [5:58:46<4:16:05,  8.77s/it] 60%|██████    | 2647/4399 [5:58:53<3:57:15,  8.13s/it] 60%|██████    | 2648/4399 [5:59:02<4:08:32,  8.52s/it] 60%|██████    | 2649/4399 [5:59:09<3:47:51,  7.81s/it] 60%|██████    | 2650/4399 [5:59:17<3:55:16,  8.07s/it]                                                        60%|██████    | 2650/4399 [5:59:17<3:55:16,  8.07s/it] 60%|██████    | 2651/4399 [5:59:25<3:48:34,  7.85s/it] 60%|██████    | 2652/4399 [5:59:34<4:02:00,  8.31s/it] 60%|██████    | 2653/4399 [5:59:45<4:22:05,  9.01s/it] 60%|██████    | 2654/4399 [5:59:54<4:26:00,  9.15s/it] 60%|██████    | 2655/4399 [6:00:04<4:27:43,  9.21s/it] 60%|██████    | 2656/4399 [6:00:12<4:18:01,  8.88s/it] 60%|█
 0: {'loss': 0.601, 'grad_norm': 1.3746239718393718, 'learning_rate': 4.055455696258818e-06, 'epoch': 0.6}
 0: █████    | 2657/4399 [6:00:18<3:57:04,  8.17s/it] 60%|██████    | 2658/4399 [6:00:25<3:44:11,  7.73s/it] 60%|██████    | 2659/4399 [6:00:32<3:40:14,  7.59s/it] 60%|██████    | 2660/4399 [6:00:40<3:46:28,  7.81s/it]                                                        60%|██████    | 2660/4399 [6:00:40<3:46:28,  7.81s/it] 60%|██████    | 2661/4399 [6:00:50<4:05:28,  8.47s/it] 61%|██████    | 2662/4399 [6:00:59<4:08:54,  8.60s/it] 61%|██████    | 2663/4399 [6:01:07<3:58:20,  8.24s/it] 61%|██████    | 2664/4399 [6:01:14<3:52:04,  8.03s/it] 61%|██████    | 2665/4399 [6:01:20<3:34:36,  7.43s/it] 61%|██████    | 2666/4399 [6:01:27<3:25:50,  7.13s/it] 61%|██████    | 2667/4399 [6:01:35<3:35:04,  7.45s/it] 61%|██████    | 2668/4399 [6:01:43<3:43:59,  7.76s/it] 61%|██████    | 2669/4399 [6:01:53<3:59:52,  8.32s/it] 61%|██████
 0: {'loss': 0.592, 'grad_norm': 1.4314450112224737, 'learning_rate': 4.016523642357183e-06, 'epoch': 0.61}
 0: {'loss': 0.5949, 'grad_norm': 1.3897780052692628, 'learning_rate': 3.9776535169307626e-06, 'epoch': 0.61}
 0:     | 2670/4399 [6:02:02<4:05:16,  8.51s/it]                                                        61%|██████    | 2670/4399 [6:02:02<4:05:16,  8.51s/it] 61%|██████    | 2671/4399 [6:02:10<3:57:13,  8.24s/it] 61%|██████    | 2672/4399 [6:02:18<3:59:59,  8.34s/it] 61%|██████    | 2673/4399 [6:02:26<3:53:03,  8.10s/it] 61%|██████    | 2674/4399 [6:02:33<3:48:30,  7.95s/it] 61%|██████    | 2675/4399 [6:02:40<3:41:43,  7.72s/it] 61%|██████    | 2676/4399 [6:02:50<3:56:52,  8.25s/it] 61%|██████    | 2677/4399 [6:02:59<4:02:20,  8.44s/it] 61%|██████    | 2678/4399 [6:03:08<4:08:20,  8.66s/it] 61%|██████    | 2679/4399 [6:03:16<4:01:04,  8.41s/it] 61%|██████    | 2680/4399 [6:03:25<4:04:55,  8.55s/it]                                                        61%|██████    | 2680/4399 [6:03:25<4:04:55,  8.55s/it] 61%|██████    | 2681/4399 [6:03:33<4
 0: {'loss': 0.588, 'grad_norm': 1.8131158569992862, 'learning_rate': 3.938847767590608e-06, 'epoch': 0.61}
 0: :02:26,  8.47s/it] 61%|██████    | 2682/4399 [6:03:41<3:55:10,  8.22s/it] 61%|██████    | 2683/4399 [6:03:50<4:07:06,  8.64s/it] 61%|██████    | 2684/4399 [6:04:00<4:13:54,  8.88s/it] 61%|██████    | 2685/4399 [6:04:09<4:21:06,  9.14s/it] 61%|██████    | 2686/4399 [6:04:18<4:15:46,  8.96s/it] 61%|██████    | 2687/4399 [6:04:25<4:02:54,  8.51s/it] 61%|██████    | 2688/4399 [6:04:34<4:05:26,  8.61s/it] 61%|██████    | 2689/4399 [6:04:40<3:41:57,  7.79s/it] 61%|██████    | 2690/4399 [6:04:47<3:30:51,  7.40s/it]                                                        61%|██████    | 2690/4399 [6:04:47<3:30:51,  7.40s/it] 61%|██████    | 2691/4399 [6:04:55<3:35:44,  7.58s/it] 61%|██████    | 2692/4399 [6:05:04<3:51:29,  8.14s/it] 61%|██████    | 2693/4399 [6:05:14<4:03:58,  8.58s/it] 61%|██████    | 2694/4399 [6:05:23<4:13:01,  8.90s/
 0: {'loss': 0.5901, 'grad_norm': 1.768533799688942, 'learning_rate': 3.900108837894069e-06, 'epoch': 0.61}
 0: it] 61%|██████▏   | 2695/4399 [6:05:30<3:50:38,  8.12s/it] 61%|██████▏   | 2696/4399 [6:05:38<3:56:10,  8.32s/it] 61%|██████▏   | 2697/4399 [6:05:44<3:31:54,  7.47s/it] 61%|██████▏   | 2698/4399 [6:05:51<3:31:38,  7.47s/it] 61%|██████▏   | 2699/4399 [6:06:00<3:42:50,  7.86s/it] 61%|██████▏   | 2700/4399 [6:06:10<4:00:31,  8.49s/it]                                                        61%|██████▏   | 2700/4399 [6:06:10<4:00:31,  8.49s/it] 61%|██████▏   | 2701/4399 [6:06:20<4:07:37,  8.75s/it] 61%|██████▏   | 2702/4399 [6:06:28<4:05:16,  8.67s/it] 61%|██████▏   | 2703/4399 [6:06:36<3:55:48,  8.34s/it] 61%|██████▏   | 2704/4399 [6:06:43<3:46:33,  8.02s/it] 61%|██████▏   | 2705/4399 [6:06:49<3:29:39,  7.43s/it] 62%|██████▏   | 2706/4399 [6:06:57<3:31:25,  7.49s/it] 62%|██████▏   | 2707/4399 [6:07:04<3:3
 0: {'loss': 0.6008, 'grad_norm': 1.4161822248269014, 'learning_rate': 3.861439167190941e-06, 'epoch': 0.62}
 0: 4:47,  7.62s/it] 62%|██████▏   | 2708/4399 [6:07:14<3:52:16,  8.24s/it] 62%|██████▏   | 2709/4399 [6:07:23<3:59:32,  8.50s/it] 62%|██████▏   | 2710/4399 [6:07:32<3:59:32,  8.51s/it]                                                        62%|██████▏   | 2710/4399 [6:07:32<3:59:32,  8.51s/it] 62%|██████▏   | 2711/4399 [6:07:39<3:44:41,  7.99s/it] 62%|██████▏   | 2712/4399 [6:07:46<3:41:29,  7.88s/it] 62%|██████▏   | 2713/4399 [6:07:54<3:43:50,  7.97s/it] 62%|██████▏   | 2714/4399 [6:08:00<3:28:12,  7.41s/it] 62%|██████▏   | 2715/4399 [6:08:08<3:29:48,  7.48s/it] 62%|██████▏   | 2716/4399 [6:08:18<3:47:33,  8.11s/it] 62%|██████▏   | 2717/4399 [6:08:27<4:01:26,  8.61s/it] 62%|██████▏   | 2718/4399 [6:08:37<4:06:17,  8.79s/it] 62%|██████▏   | 2719/4399 [6:08:44<3:56:53,  8.46s/it] 62%|██████▏   | 2720/4399
 0: {'loss': 0.582, 'grad_norm': 1.5728382505277558, 'learning_rate': 3.822841190469848e-06, 'epoch': 0.62}
 0: {'loss': 0.5785, 'grad_norm': 1.4334378927541223, 'learning_rate': 3.7843173382049192e-06, 'epoch': 0.62}
 0:  [6:08:53<3:56:15,  8.44s/it]                                                        62%|██████▏   | 2720/4399 [6:08:53<3:56:15,  8.44s/it] 62%|██████▏   | 2721/4399 [6:08:59<3:36:46,  7.75s/it] 62%|██████▏   | 2722/4399 [6:09:05<3:25:28,  7.35s/it] 62%|██████▏   | 2723/4399 [6:09:13<3:27:30,  7.43s/it] 62%|██████▏   | 2724/4399 [6:09:21<3:28:44,  7.48s/it] 62%|██████▏   | 2725/4399 [6:09:31<3:54:08,  8.39s/it] 62%|██████▏   | 2726/4399 [6:09:40<4:01:38,  8.67s/it] 62%|██████▏   | 2727/4399 [6:09:48<3:50:40,  8.28s/it] 62%|██████▏   | 2728/4399 [6:09:56<3:47:50,  8.18s/it] 62%|██████▏   | 2729/4399 [6:10:02<3:31:34,  7.60s/it] 62%|██████▏   | 2730/4399 [6:10:09<3:25:40,  7.39s/it]                                                        62%|██████▏   | 2730/4399 [6:10:09<3:25:40,  7.39s/it] 62%|██████▏   | 2731/4399
 0: {'loss': 0.5988, 'grad_norm': 1.6371711896986156, 'learning_rate': 3.7458700362027434e-06, 'epoch': 0.62}
 0:  [6:10:18<3:37:27,  7.82s/it] 62%|██████▏   | 2732/4399 [6:10:27<3:46:35,  8.16s/it] 62%|██████▏   | 2733/4399 [6:10:37<4:02:33,  8.74s/it] 62%|██████▏   | 2734/4399 [6:10:45<4:02:37,  8.74s/it] 62%|██████▏   | 2735/4399 [6:10:54<4:01:29,  8.71s/it] 62%|██████▏   | 2736/4399 [6:11:03<4:05:31,  8.86s/it] 62%|██████▏   | 2737/4399 [6:11:09<3:38:33,  7.89s/it] 62%|██████▏   | 2738/4399 [6:11:17<3:37:53,  7.87s/it] 62%|██████▏   | 2739/4399 [6:11:24<3:36:27,  7.82s/it] 62%|██████▏   | 2740/4399 [6:11:34<3:49:07,  8.29s/it]                                                        62%|██████▏   | 2740/4399 [6:11:34<3:49:07,  8.29s/it] 62%|██████▏   | 2741/4399 [6:11:43<3:58:00,  8.61s/it] 62%|██████▏   | 2742/4399 [6:11:53<4:05:57,  8.91s/it] 62%|██████▏   | 2743/4399 [6:12:02<4:05:27,  8.89s/it] 62%|██████▏ 
 0: {'loss': 0.5899, 'grad_norm': 2.838619668466997, 'learning_rate': 3.7075017054496265e-06, 'epoch': 0.63}
 0:   | 2744/4399 [6:12:10<4:02:01,  8.77s/it] 62%|██████▏   | 2745/4399 [6:12:16<3:35:00,  7.80s/it] 62%|██████▏   | 2746/4399 [6:12:24<3:37:55,  7.91s/it] 62%|██████▏   | 2747/4399 [6:12:33<3:47:50,  8.28s/it] 62%|██████▏   | 2748/4399 [6:12:41<3:48:44,  8.31s/it] 62%|██████▏   | 2749/4399 [6:12:52<4:10:58,  9.13s/it] 63%|██████▎   | 2750/4399 [6:13:02<4:16:18,  9.33s/it]                                                        63%|██████▎   | 2750/4399 [6:13:02<4:16:18,  9.33s/it] 63%|██████▎   | 2751/4399 [6:13:09<3:58:33,  8.69s/it] 63%|██████▎   | 2752/4399 [6:13:18<4:00:58,  8.78s/it] 63%|██████▎   | 2753/4399 [6:13:25<3:45:39,  8.23s/it] 63%|██████▎   | 2754/4399 [6:13:33<3:40:42,  8.05s/it] 63%|██████▎   | 2755/4399 [6:13:41<3:38:08,  7.96s/it] 63%|██████▎   | 2756/4399 [6:13:49<3:38:40,  7.99s/it] 63%|███
 0: {'loss': 0.5933, 'grad_norm': 1.6428776229744664, 'learning_rate': 3.66921476195913e-06, 'epoch': 0.63}
 0: ███▎   | 2757/4399 [6:13:58<3:47:29,  8.31s/it] 63%|██████▎   | 2758/4399 [6:14:08<4:03:00,  8.89s/it] 63%|██████▎   | 2759/4399 [6:14:15<3:51:02,  8.45s/it] 63%|██████▎   | 2760/4399 [6:14:23<3:44:58,  8.24s/it]                                                        63%|██████▎   | 2760/4399 [6:14:23<3:44:58,  8.24s/it] 63%|██████▎   | 2761/4399 [6:14:30<3:36:10,  7.92s/it] 63%|██████▎   | 2762/4399 [6:14:37<3:26:45,  7.58s/it] 63%|██████▎   | 2763/4399 [6:14:45<3:30:35,  7.72s/it] 63%|██████▎   | 2764/4399 [6:14:53<3:31:00,  7.74s/it] 63%|██████▎   | 2765/4399 [6:15:04<3:58:23,  8.75s/it] 63%|██████▎   | 2766/4399 [6:15:14<4:08:56,  9.15s/it] 63%|██████▎   | 2767/4399 [6:15:23<4:03:14,  8.94s/it] 63%|██████▎   | 2768/4399 [6:15:32<4:06:43,  9.08s/it] 63%|██████▎   | 2769/4399 [6:15:39<3:47:17,  8.37s/it] 
 0: {'loss': 0.5891, 'grad_norm': 1.8448250724563104, 'learning_rate': 3.6310116166199466e-06, 'epoch': 0.63}
 0: {'loss': 0.5817, 'grad_norm': 1.548603021492682, 'learning_rate': 3.5928946750440895e-06, 'epoch': 0.63}
 0: 63%|██████▎   | 2770/4399 [6:15:47<3:46:02,  8.33s/it]                                                        63%|██████▎   | 2770/4399 [6:15:47<3:46:02,  8.33s/it] 63%|██████▎   | 2771/4399 [6:15:55<3:46:55,  8.36s/it] 63%|██████▎   | 2772/4399 [6:16:05<3:57:27,  8.76s/it] 63%|██████▎   | 2773/4399 [6:16:15<4:07:49,  9.14s/it] 63%|██████▎   | 2774/4399 [6:16:24<4:05:21,  9.06s/it] 63%|██████▎   | 2775/4399 [6:16:31<3:49:40,  8.49s/it] 63%|██████▎   | 2776/4399 [6:16:40<3:48:35,  8.45s/it] 63%|██████▎   | 2777/4399 [6:16:45<3:27:00,  7.66s/it] 63%|██████▎   | 2778/4399 [6:16:52<3:18:49,  7.36s/it] 63%|██████▎   | 2779/4399 [6:17:00<3:25:35,  7.61s/it] 63%|██████▎   | 2780/4399 [6:17:08<3:29:58,  7.78s/it]                                                        63%|██████▎   | 2780/4399 [6:17:08<3:29:58,  7.78s/it] 
 0: {'loss': 0.5741, 'grad_norm': 1.5139529552794462, 'learning_rate': 3.5548663374154068e-06, 'epoch': 0.63}
 0: 63%|██████▎   | 2781/4399 [6:17:17<3:39:21,  8.13s/it] 63%|██████▎   | 2782/4399 [6:17:27<3:47:56,  8.46s/it] 63%|██████▎   | 2783/4399 [6:17:35<3:44:36,  8.34s/it] 63%|██████▎   | 2784/4399 [6:17:43<3:46:07,  8.40s/it] 63%|██████▎   | 2785/4399 [6:17:49<3:28:49,  7.76s/it] 63%|██████▎   | 2786/4399 [6:17:57<3:24:54,  7.62s/it] 63%|██████▎   | 2787/4399 [6:18:05<3:29:18,  7.79s/it] 63%|██████▎   | 2788/4399 [6:18:14<3:38:40,  8.14s/it] 63%|██████▎   | 2789/4399 [6:18:23<3:49:55,  8.57s/it] 63%|██████▎   | 2790/4399 [6:18:32<3:50:10,  8.58s/it]                                                        63%|██████▎   | 2790/4399 [6:18:32<3:50:10,  8.58s/it] 63%|██████▎   | 2791/4399 [6:18:39<3:39:24,  8.19s/it] 63%|██████▎   | 2792/4399 [6:18:47<3:38:55,  8.17s/it] 63%|██████▎   | 2793/4399 [6:18:54<3:22:56,
 0: {'loss': 0.5777, 'grad_norm': 1.4350135838679845, 'learning_rate': 3.5169289983384575e-06, 'epoch': 0.64}
 0:   7.58s/it] 64%|██████▎   | 2794/4399 [6:19:00<3:13:53,  7.25s/it] 64%|██████▎   | 2795/4399 [6:19:08<3:21:44,  7.55s/it] 64%|██████▎   | 2796/4399 [6:19:18<3:34:44,  8.04s/it] 64%|██████▎   | 2797/4399 [6:19:26<3:40:57,  8.28s/it] 64%|██████▎   | 2798/4399 [6:19:36<3:54:35,  8.79s/it] 64%|██████▎   | 2799/4399 [6:19:43<3:40:19,  8.26s/it] 64%|██████▎   | 2800/4399 [6:19:52<3:41:15,  8.30s/it]                                                        64%|██████▎   | 2800/4399 [6:19:52<3:41:15,  8.30s/it] 64%|██████▎   | 2801/4399 [6:19:59<3:32:44,  7.99s/it] 64%|██████▎   | 2802/4399 [6:20:06<3:26:35,  7.76s/it] 64%|██████▎   | 2803/4399 [6:20:15<3:32:15,  7.98s/it] 64%|██████▎   | 2804/4399 [6:20:23<3:33:13,  8.02s/it] 64%|██████▍   | 2805/4399 [6:20:33<3:49:50,  8.65s/it] 64%|██████▍   | 2806/4399 [6:2
 0: {'loss': 0.5932, 'grad_norm': 1.5685686113807267, 'learning_rate': 3.4790850466877086e-06, 'epoch': 0.64}
 0: 0:41<3:45:09,  8.48s/it] 64%|██████▍   | 2807/4399 [6:20:50<3:50:48,  8.70s/it] 64%|██████▍   | 2808/4399 [6:20:58<3:46:20,  8.54s/it] 64%|██████▍   | 2809/4399 [6:21:06<3:39:17,  8.27s/it] 64%|██████▍   | 2810/4399 [6:21:13<3:26:37,  7.80s/it]                                                        64%|██████▍   | 2810/4399 [6:21:13<3:26:37,  7.80s/it] 64%|██████▍   | 2811/4399 [6:21:21<3:26:10,  7.79s/it] 64%|██████▍   | 2812/4399 [6:21:28<3:26:21,  7.80s/it] 64%|██████▍   | 2813/4399 [6:21:36<3:25:34,  7.78s/it] 64%|██████▍   | 2814/4399 [6:21:45<3:31:47,  8.02s/it] 64%|██████▍   | 2815/4399 [6:21:53<3:32:48,  8.06s/it] 64%|██████▍   | 2816/4399 [6:22:02<3:41:02,  8.38s/it] 64%|██████▍   | 2817/4399 [6:22:09<3:30:01,  7.97s/it] 64%|██████▍   | 2818/4399 [6:22:16<3:21:18,  7.64s/it] 64%|██████▍   | 2
 0: {'loss': 0.579, 'grad_norm': 1.5037189224789047, 'learning_rate': 3.4413368654571223e-06, 'epoch': 0.64}
 0: {'loss': 0.5832, 'grad_norm': 1.2719700489142218, 'learning_rate': 3.403686831610097e-06, 'epoch': 0.64}
 0: 819/4399 [6:22:24<3:24:50,  7.78s/it] 64%|██████▍   | 2820/4399 [6:22:34<3:41:47,  8.43s/it]                                                        64%|██████▍   | 2820/4399 [6:22:34<3:41:47,  8.43s/it] 64%|██████▍   | 2821/4399 [6:22:42<3:40:03,  8.37s/it] 64%|██████▍   | 2822/4399 [6:22:52<3:53:34,  8.89s/it] 64%|██████▍   | 2823/4399 [6:23:01<3:52:43,  8.86s/it] 64%|██████▍   | 2824/4399 [6:23:10<3:49:14,  8.73s/it] 64%|██████▍   | 2825/4399 [6:23:15<3:26:11,  7.86s/it] 64%|██████▍   | 2826/4399 [6:23:23<3:20:39,  7.65s/it] 64%|██████▍   | 2827/4399 [6:23:30<3:21:33,  7.69s/it] 64%|██████▍   | 2828/4399 [6:23:40<3:36:46,  8.28s/it] 64%|██████▍   | 2829/4399 [6:23:49<3:41:42,  8.47s/it] 64%|██████▍   | 2830/4399 [6:23:58<3:45:28,  8.62s/it]                                                        64%|██████▍   | 2
 0: {'loss': 0.589, 'grad_norm': 1.3991498171473455, 'learning_rate': 3.3661373159297917e-06, 'epoch': 0.65}
 0: 830/4399 [6:23:58<3:45:28,  8.62s/it] 64%|██████▍   | 2831/4399 [6:24:06<3:41:09,  8.46s/it] 64%|██████▍   | 2832/4399 [6:24:15<3:43:57,  8.58s/it] 64%|██████▍   | 2833/4399 [6:24:21<3:25:26,  7.87s/it] 64%|██████▍   | 2834/4399 [6:24:28<3:15:36,  7.50s/it] 64%|██████▍   | 2835/4399 [6:24:35<3:17:37,  7.58s/it] 64%|██████▍   | 2836/4399 [6:24:44<3:22:52,  7.79s/it] 64%|██████▍   | 2837/4399 [6:24:53<3:30:59,  8.10s/it] 65%|██████▍   | 2838/4399 [6:25:03<3:50:48,  8.87s/it] 65%|██████▍   | 2839/4399 [6:25:12<3:50:34,  8.87s/it] 65%|██████▍   | 2840/4399 [6:25:21<3:53:11,  8.97s/it]                                                        65%|██████▍   | 2840/4399 [6:25:21<3:53:11,  8.97s/it] 65%|██████▍   | 2841/4399 [6:25:28<3:34:15,  8.25s/it] 65%|██████▍   | 2842/4399 [6:25:35<3:25:03,  7.90s/it] 65%|████
 0: {'loss': 0.5695, 'grad_norm': 1.7740656914711044, 'learning_rate': 3.328690682869849e-06, 'epoch': 0.65}
 0: █▍   | 2843/4399 [6:25:43<3:25:57,  7.94s/it] 65%|██████▍   | 2844/4399 [6:25:51<3:29:47,  8.10s/it] 65%|██████▍   | 2845/4399 [6:26:01<3:41:10,  8.54s/it] 65%|██████▍   | 2846/4399 [6:26:12<4:02:11,  9.36s/it] 65%|██████▍   | 2847/4399 [6:26:21<4:01:18,  9.33s/it] 65%|██████▍   | 2848/4399 [6:26:29<3:47:38,  8.81s/it] 65%|██████▍   | 2849/4399 [6:26:37<3:40:34,  8.54s/it] 65%|██████▍   | 2850/4399 [6:26:44<3:27:19,  8.03s/it]                                                        65%|██████▍   | 2850/4399 [6:26:44<3:27:19,  8.03s/it] 65%|██████▍   | 2851/4399 [6:26:54<3:41:36,  8.59s/it] 65%|██████▍   | 2852/4399 [6:27:03<3:43:18,  8.66s/it] 65%|██████▍   | 2853/4399 [6:27:13<3:53:56,  9.08s/it] 65%|██████▍   | 2854/4399 [6:27:23<4:02:45,  9.43s/it] 65%|██████▍   | 2855/4399 [6:27:31<3:54:45,  9.12s/it] 65%|
 0: {'loss': 0.5902, 'grad_norm': 1.8618467573678203, 'learning_rate': 3.291349290405493e-06, 'epoch': 0.65}
 0: █████▍   | 2856/4399 [6:27:40<3:54:31,  9.12s/it] 65%|██████▍   | 2857/4399 [6:27:48<3:39:49,  8.55s/it] 65%|██████▍   | 2858/4399 [6:27:54<3:26:39,  8.05s/it] 65%|██████▍   | 2859/4399 [6:28:03<3:27:31,  8.09s/it] 65%|██████▌   | 2860/4399 [6:28:12<3:33:39,  8.33s/it]                                                        65%|██████▌   | 2860/4399 [6:28:12<3:33:39,  8.33s/it] 65%|██████▌   | 2861/4399 [6:28:21<3:42:33,  8.68s/it] 65%|██████▌   | 2862/4399 [6:28:32<4:01:47,  9.44s/it] 65%|██████▌   | 2863/4399 [6:28:42<4:02:12,  9.46s/it] 65%|██████▌   | 2864/4399 [6:28:50<3:55:25,  9.20s/it] 65%|██████▌   | 2865/4399 [6:28:58<3:46:22,  8.85s/it] 65%|██████▌   | 2866/4399 [6:29:05<3:29:21,  8.19s/it] 65%|██████▌   | 2867/4399 [6:29:13<3:28:50,  8.18s/it] 65%|██████▌   | 2868/4399 [6:29:21<3:28:06,  8.1
 0: {'loss': 0.5777, 'grad_norm': 2.1966923464661083, 'learning_rate': 3.2541154898850597e-06, 'epoch': 0.65}
 0: 6s/it] 65%|██████▌   | 2869/4399 [6:29:31<3:40:32,  8.65s/it] 65%|██████▌   | 2870/4399 [6:29:41<3:47:27,  8.93s/it]                                                        65%|██████▌   | 2870/4399 [6:29:41<3:47:27,  8.93s/it] 65%|██████▌   | 2871/4399 [6:29:50<3:48:31,  8.97s/it] 65%|██████▌   | 2872/4399 [6:29:58<3:46:17,  8.89s/it] 65%|██████▌   | 2873/4399 [6:30:06<3:36:57,  8.53s/it] 65%|██████▌   | 2874/4399 [6:30:13<3:22:08,  7.95s/it] 65%|██████▌   | 2875/4399 [6:30:22<3:28:31,  8.21s/it] 65%|██████▌   | 2876/4399 [6:30:30<3:30:09,  8.28s/it] 65%|██████▌   | 2877/4399 [6:30:39<3:35:48,  8.51s/it] 65%|██████▌   | 2878/4399 [6:30:50<3:51:50,  9.15s/it] 65%|██████▌   | 2879/4399 [6:30:58<3:41:52,  8.76s/it] 65%|██████▌   | 2880/4399 [6:31:06<3:39:05,  8.65s/it]                                                  
 0: {'loss': 0.6014, 'grad_norm': 1.6360285327593176, 'learning_rate': 3.2169916258819323e-06, 'epoch': 0.65}
 0: {'loss': 0.5906, 'grad_norm': 1.67269998519838, 'learning_rate': 3.1799800360469134e-06, 'epoch': 0.66}
 0:       65%|██████▌   | 2880/4399 [6:31:06<3:39:05,  8.65s/it] 65%|██████▌   | 2881/4399 [6:31:13<3:23:58,  8.06s/it] 66%|██████▌   | 2882/4399 [6:31:20<3:19:34,  7.89s/it] 66%|██████▌   | 2883/4399 [6:31:29<3:27:39,  8.22s/it] 66%|██████▌   | 2884/4399 [6:31:37<3:28:07,  8.24s/it] 66%|██████▌   | 2885/4399 [6:31:48<3:42:08,  8.80s/it] 66%|██████▌   | 2886/4399 [6:31:57<3:49:18,  9.09s/it] 66%|██████▌   | 2887/4399 [6:32:05<3:41:18,  8.78s/it] 66%|██████▌   | 2888/4399 [6:32:14<3:39:50,  8.73s/it] 66%|██████▌   | 2889/4399 [6:32:21<3:24:56,  8.14s/it] 66%|██████▌   | 2890/4399 [6:32:28<3:19:50,  7.95s/it]                                                        66%|██████▌   | 2890/4399 [6:32:28<3:19:50,  7.95s/it] 66%|██████▌   | 2891/4399 [6:32:38<3:34:05,  8.52s/it] 66%|██████▌   | 2892/4399 [6:32:46<
 0: {'loss': 0.5764, 'grad_norm': 1.6333928028080884, 'learning_rate': 3.1430830509610107e-06, 'epoch': 0.66}
 0: 3:29:33,  8.34s/it] 66%|██████▌   | 2893/4399 [6:32:55<3:33:55,  8.52s/it] 66%|██████▌   | 2894/4399 [6:33:04<3:36:30,  8.63s/it] 66%|██████▌   | 2895/4399 [6:33:12<3:33:06,  8.50s/it] 66%|██████▌   | 2896/4399 [6:33:22<3:40:51,  8.82s/it] 66%|██████▌   | 2897/4399 [6:33:29<3:31:12,  8.44s/it] 66%|██████▌   | 2898/4399 [6:33:36<3:21:51,  8.07s/it] 66%|██████▌   | 2899/4399 [6:33:45<3:22:42,  8.11s/it] 66%|██████▌   | 2900/4399 [6:33:53<3:25:08,  8.21s/it]                                                        66%|██████▌   | 2900/4399 [6:33:53<3:25:08,  8.21s/it] 66%|██████▌   | 2901/4399 [6:34:02<3:28:05,  8.34s/it] 66%|██████▌   | 2902/4399 [6:34:10<3:31:34,  8.48s/it] 66%|██████▌   | 2903/4399 [6:34:18<3:27:01,  8.30s/it] 66%|██████▌   | 2904/4399 [6:34:27<3:30:02,  8.43s/it] 66%|██████▌   | 2905/4
 0: {'loss': 0.5818, 'grad_norm': 1.7551217255523504, 'learning_rate': 3.1063029939886945e-06, 'epoch': 0.66}
 0: 399 [6:34:34<3:18:52,  7.99s/it] 66%|██████▌   | 2906/4399 [6:34:40<3:07:30,  7.54s/it] 66%|██████▌   | 2907/4399 [6:34:49<3:18:00,  7.96s/it] 66%|██████▌   | 2908/4399 [6:34:58<3:23:49,  8.20s/it] 66%|██████▌   | 2909/4399 [6:35:07<3:24:40,  8.24s/it] 66%|██████▌   | 2910/4399 [6:35:16<3:32:36,  8.57s/it]                                                        66%|██████▌   | 2910/4399 [6:35:16<3:32:36,  8.57s/it] 66%|██████▌   | 2911/4399 [6:35:24<3:29:54,  8.46s/it] 66%|██████▌   | 2912/4399 [6:35:32<3:25:54,  8.31s/it] 66%|██████▌   | 2913/4399 [6:35:40<3:24:28,  8.26s/it] 66%|██████▌   | 2914/4399 [6:35:47<3:10:38,  7.70s/it] 66%|██████▋   | 2915/4399 [6:35:55<3:17:52,  8.00s/it] 66%|██████▋   | 2916/4399 [6:36:04<3:23:51,  8.25s/it] 66%|██████▋   | 2917/4399 [6:36:13<3:26:28,  8.36s/it] 66%|██████
 0: {'loss': 0.571, 'grad_norm': 1.6102956306204756, 'learning_rate': 3.0696421811315923e-06, 'epoch': 0.66}
 0:    | 2918/4399 [6:36:22<3:36:27,  8.77s/it] 66%|██████▋   | 2919/4399 [6:36:30<3:30:25,  8.53s/it] 66%|██████▋   | 2920/4399 [6:36:39<3:30:03,  8.52s/it]                                                        66%|██████▋   | 2920/4399 [6:36:39<3:30:03,  8.52s/it] 66%|██████▋   | 2921/4399 [6:36:47<3:23:59,  8.28s/it] 66%|██████▋   | 2922/4399 [6:36:53<3:08:44,  7.67s/it] 66%|██████▋   | 2923/4399 [6:37:02<3:21:48,  8.20s/it] 66%|██████▋   | 2924/4399 [6:37:10<3:14:21,  7.91s/it] 66%|██████▋   | 2925/4399 [6:37:18<3:16:30,  8.00s/it] 67%|██████▋   | 2926/4399 [6:37:27<3:25:35,  8.37s/it] 67%|██████▋   | 2927/4399 [6:37:36<3:29:05,  8.52s/it] 67%|██████▋   | 2928/4399 [6:37:45<3:36:20,  8.82s/it] 67%|██████▋   | 2929/4399 [6:37:52<3:16:40,  8.03s/it] 67%|██████▋   | 2930/4399 [6:37:58<3:07:47,  7.67s/it]           
 0: {'loss': 0.5706, 'grad_norm': 1.5464486580366124, 'learning_rate': 3.033102920882659e-06, 'epoch': 0.67}
 0: {'loss': 0.5917, 'grad_norm': 1.9524055389223756, 'learning_rate': 2.9966875140808072e-06, 'epoch': 0.67}
 0:                                              67%|██████▋   | 2930/4399 [6:37:58<3:07:47,  7.67s/it] 67%|██████▋   | 2931/4399 [6:38:07<3:13:55,  7.93s/it] 67%|██████▋   | 2932/4399 [6:38:15<3:11:07,  7.82s/it] 67%|██████▋   | 2933/4399 [6:38:23<3:14:01,  7.94s/it] 67%|██████▋   | 2934/4399 [6:38:33<3:28:15,  8.53s/it] 67%|██████▋   | 2935/4399 [6:38:41<3:25:53,  8.44s/it] 67%|██████▋   | 2936/4399 [6:38:49<3:24:39,  8.39s/it] 67%|██████▋   | 2937/4399 [6:38:57<3:19:50,  8.20s/it] 67%|██████▋   | 2938/4399 [6:39:04<3:10:56,  7.84s/it] 67%|██████▋   | 2939/4399 [6:39:12<3:11:31,  7.87s/it] 67%|██████▋   | 2940/4399 [6:39:19<3:04:21,  7.58s/it]                                                        67%|██████▋   | 2940/4399 [6:39:19<3:04:21,  7.58s/it] 67%|██████▋   | 2941/4399 [6:39:28<3:16:53,  8.10s/it] 67%|██
 0: {'loss': 0.5835, 'grad_norm': 1.672330877300284, 'learning_rate': 2.9603982537660257e-06, 'epoch': 0.67}
 0: ████▋   | 2942/4399 [6:39:38<3:29:12,  8.62s/it] 67%|██████▋   | 2943/4399 [6:39:47<3:31:55,  8.73s/it] 67%|██████▋   | 2944/4399 [6:39:55<3:26:30,  8.52s/it] 67%|██████▋   | 2945/4399 [6:40:02<3:19:08,  8.22s/it] 67%|██████▋   | 2946/4399 [6:40:09<3:06:22,  7.70s/it] 67%|██████▋   | 2947/4399 [6:40:18<3:12:55,  7.97s/it] 67%|██████▋   | 2948/4399 [6:40:25<3:05:47,  7.68s/it] 67%|██████▋   | 2949/4399 [6:40:33<3:13:28,  8.01s/it] 67%|██████▋   | 2950/4399 [6:40:43<3:25:31,  8.51s/it]                                                        67%|██████▋   | 2950/4399 [6:40:43<3:25:31,  8.51s/it] 67%|██████▋   | 2951/4399 [6:40:52<3:31:43,  8.77s/it] 67%|██████▋   | 2952/4399 [6:41:02<3:34:22,  8.89s/it] 67%|██████▋   | 2953/4399 [6:41:10<3:28:01,  8.63s/it] 67%|██████▋   | 2954/4399 [6:41:16<3:12:16,  7.98s/it
 0: {'loss': 0.5841, 'grad_norm': 1.7647474267669505, 'learning_rate': 2.9242374250349914e-06, 'epoch': 0.67}
 0: ] 67%|██████▋   | 2955/4399 [6:41:25<3:17:35,  8.21s/it] 67%|██████▋   | 2956/4399 [6:41:32<3:08:40,  7.84s/it] 67%|██████▋   | 2957/4399 [6:41:41<3:17:12,  8.21s/it] 67%|██████▋   | 2958/4399 [6:41:50<3:21:34,  8.39s/it] 67%|██████▋   | 2959/4399 [6:41:59<3:27:50,  8.66s/it] 67%|██████▋   | 2960/4399 [6:42:06<3:14:54,  8.13s/it]                                                        67%|██████▋   | 2960/4399 [6:42:06<3:14:54,  8.13s/it] 67%|██████▋   | 2961/4399 [6:42:13<3:07:19,  7.82s/it] 67%|██████▋   | 2962/4399 [6:42:19<2:55:55,  7.35s/it] 67%|██████▋   | 2963/4399 [6:42:28<3:06:13,  7.78s/it] 67%|██████▋   | 2964/4399 [6:42:36<3:05:55,  7.77s/it] 67%|██████▋   | 2965/4399 [6:42:44<3:07:34,  7.85s/it] 67%|██████▋   | 2966/4399 [6:42:52<3:12:33,  8.06s/it] 67%|██████▋   | 2967/4399 [6:43:01<3:13:
 0: {'loss': 0.5886, 'grad_norm': 1.4945540573273572, 'learning_rate': 2.8882073048971836e-06, 'epoch': 0.68}
 0: 53,  8.12s/it] 67%|██████▋   | 2968/4399 [6:43:08<3:07:56,  7.88s/it] 67%|██████▋   | 2969/4399 [6:43:15<3:04:56,  7.76s/it] 68%|██████▊   | 2970/4399 [6:43:21<2:53:13,  7.27s/it]                                                        68%|██████▊   | 2970/4399 [6:43:21<2:53:13,  7.27s/it] 68%|██████▊   | 2971/4399 [6:43:30<3:02:42,  7.68s/it] 68%|██████▊   | 2972/4399 [6:43:38<3:01:47,  7.64s/it] 68%|██████▊   | 2973/4399 [6:43:46<3:08:39,  7.94s/it] 68%|██████▊   | 2974/4399 [6:43:55<3:17:20,  8.31s/it] 68%|██████▊   | 2975/4399 [6:44:03<3:11:29,  8.07s/it] 68%|██████▊   | 2976/4399 [6:44:14<3:30:09,  8.86s/it] 68%|██████▊   | 2977/4399 [6:44:21<3:17:58,  8.35s/it] 68%|██████▊   | 2978/4399 [6:44:27<3:03:00,  7.73s/it] 68%|██████▊   | 2979/4399 [6:44:35<3:06:45,  7.89s/it] 68%|██████▊   | 2980/4399 [
 0: {'loss': 0.5862, 'grad_norm': 13.920593147713989, 'learning_rate': 2.852310162131492e-06, 'epoch': 0.68}
 0: {'loss': 0.5908, 'grad_norm': 1.956365508892054, 'learning_rate': 2.8165482571433655e-06, 'epoch': 0.68}
 0: 6:44:43<3:02:10,  7.70s/it]                                                        68%|██████▊   | 2980/4399 [6:44:43<3:02:10,  7.70s/it] 68%|██████▊   | 2981/4399 [6:44:53<3:21:20,  8.52s/it] 68%|██████▊   | 2982/4399 [6:45:02<3:22:19,  8.57s/it] 68%|██████▊   | 2983/4399 [6:45:11<3:23:41,  8.63s/it] 68%|██████▊   | 2984/4399 [6:45:19<3:19:30,  8.46s/it] 68%|██████▊   | 2985/4399 [6:45:26<3:12:15,  8.16s/it] 68%|██████▊   | 2986/4399 [6:45:32<3:00:01,  7.64s/it] 68%|██████▊   | 2987/4399 [6:45:40<3:00:28,  7.67s/it] 68%|██████▊   | 2988/4399 [6:45:48<2:59:38,  7.64s/it] 68%|██████▊   | 2989/4399 [6:45:56<3:01:47,  7.74s/it] 68%|██████▊   | 2990/4399 [6:46:04<3:07:56,  8.00s/it]                                                        68%|██████▊   | 2990/4399 [6:46:04<3:07:56,  8.00s/it] 68%|██████▊   | 2991/4399 [
 0: {'loss': 0.5704, 'grad_norm': 1.5966620648423344, 'learning_rate': 2.7809238418224727e-06, 'epoch': 0.68}
 0: 6:46:13<3:12:03,  8.18s/it] 68%|██████▊   | 2992/4399 [6:46:21<3:10:25,  8.12s/it] 68%|██████▊   | 2993/4399 [6:46:28<3:05:19,  7.91s/it] 68%|██████▊   | 2994/4399 [6:46:35<2:56:44,  7.55s/it] 68%|██████▊   | 2995/4399 [6:46:43<2:55:51,  7.52s/it] 68%|██████▊   | 2996/4399 [6:46:51<3:05:26,  7.93s/it] 68%|██████▊   | 2997/4399 [6:47:00<3:10:05,  8.14s/it] 68%|██████▊   | 2998/4399 [6:47:09<3:16:27,  8.41s/it] 68%|██████▊   | 2999/4399 [6:47:17<3:14:14,  8.32s/it] 68%|██████▊   | 3000/4399 [6:47:26<3:14:25,  8.34s/it]                                                        68%|██████▊   | 3000/4399 [6:47:26<3:14:25,  8.34s/it][INFO|trainer.py:3984] 2025-06-28 03:51:53,434 >> Saving model checkpoint to /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000
 0: [INFO|configuration_utils.py:419] 2025-06-28 03:51:53,440 >> Configuration saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/config.json
 0: [INFO|configuration_utils.py:911] 2025-06-28 03:51:53,443 >> Configuration saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/generation_config.json
 0: [INFO|modeling_utils.py:3580] 2025-06-28 03:52:01,328 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 4 checkpoint shards. You can find where each parameters has been saved in the index located at /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/model.safetensors.index.json.
 0: [INFO|tokenization_utils_base.py:2510] 2025-06-28 03:52:01,334 >> tokenizer config file saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/tokenizer_config.json
 0: [INFO|tokenization_utils_base.py:2519] 2025-06-28 03:52:01,348 >> Special tokens file saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/special_tokens_map.json
 0: [2025-06-28 03:52:01,528] [INFO] [logging.py:107:log_dist] [Rank 0] [Torch] Checkpoint global_step3000 is about to be saved!
22: [2025-06-28 03:52:01,538] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_88_mp_rank_00_model_states.pt...
30: [2025-06-28 03:52:01,538] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_120_mp_rank_00_model_states.pt...
23: [2025-06-28 03:52:01,538] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_92_mp_rank_00_model_states.pt...
10: [2025-06-28 03:52:01,538] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_40_mp_rank_00_model_states.pt...
15: [2025-06-28 03:52:01,538] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_60_mp_rank_00_model_states.pt...
24: [2025-06-28 03:52:01,538] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_96_mp_rank_00_model_states.pt...
25: [2025-06-28 03:52:01,538] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_100_mp_rank_00_model_states.pt...
 5: [2025-06-28 03:52:01,538] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_20_mp_rank_00_model_states.pt...
20: [2025-06-28 03:52:01,538] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_80_mp_rank_00_model_states.pt...
12: [2025-06-28 03:52:01,538] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_48_mp_rank_00_model_states.pt...
 4: [2025-06-28 03:52:01,538] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_16_mp_rank_00_model_states.pt...
18: [2025-06-28 03:52:01,539] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_72_mp_rank_00_model_states.pt...
 8: [2025-06-28 03:52:01,539] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_32_mp_rank_00_model_states.pt...
 3: [2025-06-28 03:52:01,539] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_12_mp_rank_00_model_states.pt...
28: [2025-06-28 03:52:01,539] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_112_mp_rank_00_model_states.pt...
31: [2025-06-28 03:52:01,539] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_124_mp_rank_00_model_states.pt...
14: [2025-06-28 03:52:01,539] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_56_mp_rank_00_model_states.pt...
 9: [2025-06-28 03:52:01,539] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_36_mp_rank_00_model_states.pt...
27: [2025-06-28 03:52:01,539] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_108_mp_rank_00_model_states.pt...
19: [2025-06-28 03:52:01,539] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_76_mp_rank_00_model_states.pt...
 6: [2025-06-28 03:52:01,539] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_24_mp_rank_00_model_states.pt...
 0: [2025-06-28 03:52:01,539] [INFO] [logging.py:107:log_dist] [Rank 0] Saving model checkpoint: /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_0_mp_rank_00_model_states.pt
 2: [2025-06-28 03:52:01,539] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_8_mp_rank_00_model_states.pt...
29: [2025-06-28 03:52:01,539] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_116_mp_rank_00_model_states.pt...
 0: [2025-06-28 03:52:01,539] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_0_mp_rank_00_model_states.pt...
 7: [2025-06-28 03:52:01,539] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_28_mp_rank_00_model_states.pt...
 1: [2025-06-28 03:52:01,540] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_4_mp_rank_00_model_states.pt...
16: [2025-06-28 03:52:01,541] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_64_mp_rank_00_model_states.pt...
13: [2025-06-28 03:52:01,541] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_52_mp_rank_00_model_states.pt...
17: [2025-06-28 03:52:01,541] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_68_mp_rank_00_model_states.pt...
11: [2025-06-28 03:52:01,541] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_44_mp_rank_00_model_states.pt...
21: [2025-06-28 03:52:01,541] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_84_mp_rank_00_model_states.pt...
26: [2025-06-28 03:52:01,541] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_104_mp_rank_00_model_states.pt...
24: [2025-06-28 03:52:01,565] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_96_mp_rank_00_model_states.pt.
25: [2025-06-28 03:52:01,567] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_100_mp_rank_00_model_states.pt.
30: [2025-06-28 03:52:01,569] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_120_mp_rank_00_model_states.pt.
23: [2025-06-28 03:52:01,570] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_92_mp_rank_00_model_states.pt.
18: [2025-06-28 03:52:01,572] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_72_mp_rank_00_model_states.pt.
 6: [2025-06-28 03:52:01,577] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_24_mp_rank_00_model_states.pt.
 7: [2025-06-28 03:52:01,577] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_28_mp_rank_00_model_states.pt.
27: [2025-06-28 03:52:01,578] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_108_mp_rank_00_model_states.pt.
10: [2025-06-28 03:52:01,580] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_40_mp_rank_00_model_states.pt.
 2: [2025-06-28 03:52:01,582] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_8_mp_rank_00_model_states.pt.
15: [2025-06-28 03:52:01,583] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_60_mp_rank_00_model_states.pt.
31: [2025-06-28 03:52:01,586] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_124_mp_rank_00_model_states.pt.
 8: [2025-06-28 03:52:01,588] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_32_mp_rank_00_model_states.pt.
 9: [2025-06-28 03:52:01,589] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_36_mp_rank_00_model_states.pt.
16: [2025-06-28 03:52:01,591] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_64_mp_rank_00_model_states.pt.
22: [2025-06-28 03:52:01,591] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_88_mp_rank_00_model_states.pt.
28: [2025-06-28 03:52:01,591] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_112_mp_rank_00_model_states.pt.
 5: [2025-06-28 03:52:01,591] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_20_mp_rank_00_model_states.pt.
29: [2025-06-28 03:52:01,593] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_116_mp_rank_00_model_states.pt.
 4: [2025-06-28 03:52:01,593] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_16_mp_rank_00_model_states.pt.
20: [2025-06-28 03:52:01,593] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_80_mp_rank_00_model_states.pt.
19: [2025-06-28 03:52:01,594] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_76_mp_rank_00_model_states.pt.
 3: [2025-06-28 03:52:01,594] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_12_mp_rank_00_model_states.pt.
14: [2025-06-28 03:52:01,595] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_56_mp_rank_00_model_states.pt.
21: [2025-06-28 03:52:01,595] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_84_mp_rank_00_model_states.pt.
26: [2025-06-28 03:52:01,595] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_104_mp_rank_00_model_states.pt.
17: [2025-06-28 03:52:01,595] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_68_mp_rank_00_model_states.pt.
13: [2025-06-28 03:52:01,597] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_52_mp_rank_00_model_states.pt.
 1: [2025-06-28 03:52:01,597] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_4_mp_rank_00_model_states.pt.
12: [2025-06-28 03:52:01,597] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_48_mp_rank_00_model_states.pt.
11: [2025-06-28 03:52:01,599] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_44_mp_rank_00_model_states.pt.
 0: [2025-06-28 03:52:01,631] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/zero_pp_rank_0_mp_rank_00_model_states.pt.
 0: [2025-06-28 03:52:02,070] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
 9: [2025-06-28 03:52:02,070] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_36_mp_rank_00_optim_states.pt...
15: [2025-06-28 03:52:02,070] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_60_mp_rank_00_optim_states.pt...
18: [2025-06-28 03:52:02,070] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_72_mp_rank_00_optim_states.pt...
 4: [2025-06-28 03:52:02,070] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_16_mp_rank_00_optim_states.pt...
 7: [2025-06-28 03:52:02,070] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_28_mp_rank_00_optim_states.pt...
27: [2025-06-28 03:52:02,070] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_108_mp_rank_00_optim_states.pt...
 1: [2025-06-28 03:52:02,070] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_4_mp_rank_00_optim_states.pt...
25: [2025-06-28 03:52:02,070] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_100_mp_rank_00_optim_states.pt...
23: [2025-06-28 03:52:02,070] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_92_mp_rank_00_optim_states.pt...
28: [2025-06-28 03:52:02,070] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_112_mp_rank_00_optim_states.pt...
22: [2025-06-28 03:52:02,070] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_88_mp_rank_00_optim_states.pt...
31: [2025-06-28 03:52:02,070] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_124_mp_rank_00_optim_states.pt...
10: [2025-06-28 03:52:02,070] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_40_mp_rank_00_optim_states.pt...
 2: [2025-06-28 03:52:02,070] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_8_mp_rank_00_optim_states.pt...
13: [2025-06-28 03:52:02,070] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_52_mp_rank_00_optim_states.pt...
19: [2025-06-28 03:52:02,070] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_76_mp_rank_00_optim_states.pt...
 8: [2025-06-28 03:52:02,070] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_32_mp_rank_00_optim_states.pt...
 6: [2025-06-28 03:52:02,070] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_24_mp_rank_00_optim_states.pt...
11: [2025-06-28 03:52:02,070] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_44_mp_rank_00_optim_states.pt...
12: [2025-06-28 03:52:02,070] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_48_mp_rank_00_optim_states.pt...
16: [2025-06-28 03:52:02,070] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_64_mp_rank_00_optim_states.pt...
 5: [2025-06-28 03:52:02,070] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_20_mp_rank_00_optim_states.pt...
14: [2025-06-28 03:52:02,070] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_56_mp_rank_00_optim_states.pt...
21: [2025-06-28 03:52:02,070] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_84_mp_rank_00_optim_states.pt...
30: [2025-06-28 03:52:02,070] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_120_mp_rank_00_optim_states.pt...
29: [2025-06-28 03:52:02,070] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_116_mp_rank_00_optim_states.pt...
24: [2025-06-28 03:52:02,070] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_96_mp_rank_00_optim_states.pt...
17: [2025-06-28 03:52:02,070] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_68_mp_rank_00_optim_states.pt...
 3: [2025-06-28 03:52:02,070] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_12_mp_rank_00_optim_states.pt...
20: [2025-06-28 03:52:02,070] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_80_mp_rank_00_optim_states.pt...
26: [2025-06-28 03:52:02,070] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_104_mp_rank_00_optim_states.pt...
 0: [2025-06-28 03:52:02,599] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
 0: [2025-06-28 03:52:02,607] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
 8: [2025-06-28 03:52:04,821] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_32_mp_rank_00_optim_states.pt.
 8: [2025-06-28 03:52:04,821] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_32_mp_rank_00_optim_states.pt
15: [2025-06-28 03:52:04,833] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_60_mp_rank_00_optim_states.pt.
15: [2025-06-28 03:52:04,833] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_60_mp_rank_00_optim_states.pt
 1: [2025-06-28 03:52:04,834] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_4_mp_rank_00_optim_states.pt.
 1: [2025-06-28 03:52:04,834] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_4_mp_rank_00_optim_states.pt
27: [2025-06-28 03:52:04,871] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_108_mp_rank_00_optim_states.pt.
27: [2025-06-28 03:52:04,871] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_108_mp_rank_00_optim_states.pt
14: [2025-06-28 03:52:04,871] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_56_mp_rank_00_optim_states.pt.
14: [2025-06-28 03:52:04,871] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_56_mp_rank_00_optim_states.pt
26: [2025-06-28 03:52:04,871] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_104_mp_rank_00_optim_states.pt.
26: [2025-06-28 03:52:04,871] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_104_mp_rank_00_optim_states.pt
31: [2025-06-28 03:52:04,878] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_124_mp_rank_00_optim_states.pt.
31: [2025-06-28 03:52:04,878] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_124_mp_rank_00_optim_states.pt
22: [2025-06-28 03:52:04,880] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_88_mp_rank_00_optim_states.pt.
22: [2025-06-28 03:52:04,881] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_88_mp_rank_00_optim_states.pt
30: [2025-06-28 03:52:04,883] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_120_mp_rank_00_optim_states.pt.
30: [2025-06-28 03:52:04,883] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_120_mp_rank_00_optim_states.pt
16: [2025-06-28 03:52:04,883] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_64_mp_rank_00_optim_states.pt.
16: [2025-06-28 03:52:04,883] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_64_mp_rank_00_optim_states.pt
 2: [2025-06-28 03:52:04,889] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_8_mp_rank_00_optim_states.pt.
 2: [2025-06-28 03:52:04,889] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_8_mp_rank_00_optim_states.pt
 7: [2025-06-28 03:52:04,889] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_28_mp_rank_00_optim_states.pt.
 7: [2025-06-28 03:52:04,889] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_28_mp_rank_00_optim_states.pt
10: [2025-06-28 03:52:04,886] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_40_mp_rank_00_optim_states.pt.
10: [2025-06-28 03:52:04,887] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_40_mp_rank_00_optim_states.pt
19: [2025-06-28 03:52:04,894] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_76_mp_rank_00_optim_states.pt.
19: [2025-06-28 03:52:04,894] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_76_mp_rank_00_optim_states.pt
17: [2025-06-28 03:52:04,896] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_68_mp_rank_00_optim_states.pt.
17: [2025-06-28 03:52:04,896] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_68_mp_rank_00_optim_states.pt
25: [2025-06-28 03:52:04,896] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_100_mp_rank_00_optim_states.pt.
25: [2025-06-28 03:52:04,896] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_100_mp_rank_00_optim_states.pt
 3: [2025-06-28 03:52:04,899] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_12_mp_rank_00_optim_states.pt.
 3: [2025-06-28 03:52:04,899] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_12_mp_rank_00_optim_states.pt
28: [2025-06-28 03:52:04,915] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_112_mp_rank_00_optim_states.pt.
28: [2025-06-28 03:52:04,915] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_112_mp_rank_00_optim_states.pt
20: [2025-06-28 03:52:04,950] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_80_mp_rank_00_optim_states.pt.
20: [2025-06-28 03:52:04,950] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_80_mp_rank_00_optim_states.pt
 4: [2025-06-28 03:52:04,957] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_16_mp_rank_00_optim_states.pt.
 4: [2025-06-28 03:52:04,957] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_16_mp_rank_00_optim_states.pt
 6: [2025-06-28 03:52:04,959] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_24_mp_rank_00_optim_states.pt.
 6: [2025-06-28 03:52:04,960] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_24_mp_rank_00_optim_states.pt
21: [2025-06-28 03:52:04,971] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_84_mp_rank_00_optim_states.pt.
21: [2025-06-28 03:52:04,971] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_84_mp_rank_00_optim_states.pt
23: [2025-06-28 03:52:04,982] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_92_mp_rank_00_optim_states.pt.
23: [2025-06-28 03:52:04,982] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_92_mp_rank_00_optim_states.pt
13: [2025-06-28 03:52:04,983] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_52_mp_rank_00_optim_states.pt.
13: [2025-06-28 03:52:04,983] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_52_mp_rank_00_optim_states.pt
18: [2025-06-28 03:52:04,984] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_72_mp_rank_00_optim_states.pt.
18: [2025-06-28 03:52:04,984] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_72_mp_rank_00_optim_states.pt
 5: [2025-06-28 03:52:05,008] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_20_mp_rank_00_optim_states.pt.
 5: [2025-06-28 03:52:05,008] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_20_mp_rank_00_optim_states.pt
11: [2025-06-28 03:52:05,030] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_44_mp_rank_00_optim_states.pt.
11: [2025-06-28 03:52:05,031] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_44_mp_rank_00_optim_states.pt
24: [2025-06-28 03:52:05,032] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_96_mp_rank_00_optim_states.pt.
24: [2025-06-28 03:52:05,032] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_96_mp_rank_00_optim_states.pt
29: [2025-06-28 03:52:05,048] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_116_mp_rank_00_optim_states.pt.
29: [2025-06-28 03:52:05,048] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_116_mp_rank_00_optim_states.pt
 9: [2025-06-28 03:52:05,069] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_36_mp_rank_00_optim_states.pt.
 9: [2025-06-28 03:52:05,069] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_36_mp_rank_00_optim_states.pt
12: [2025-06-28 03:52:05,892] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_48_mp_rank_00_optim_states.pt.
12: [2025-06-28 03:52:05,892] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/global_step3000/bf16_zero_pp_rank_48_mp_rank_00_optim_states.pt
28: [2025-06-28 03:52:09,296] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3000 is ready now!
 3: [2025-06-28 03:52:09,296] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3000 is ready now!
23: [2025-06-28 03:52:09,296] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3000 is ready now!
22: [2025-06-28 03:52:09,296] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3000 is ready now!
24: [2025-06-28 03:52:09,296] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3000 is ready now!
15: [2025-06-28 03:52:09,296] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3000 is ready now!
10: [2025-06-28 03:52:09,296] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3000 is ready now!
 8: [2025-06-28 03:52:09,296] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3000 is ready now!
17: [2025-06-28 03:52:09,296] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3000 is ready now!
14: [2025-06-28 03:52:09,297] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3000 is ready now!
11: [2025-06-28 03:52:09,297] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3000 is ready now!
30: [2025-06-28 03:52:09,297] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3000 is ready now!
20: [2025-06-28 03:52:09,297] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3000 is ready now!
29: [2025-06-28 03:52:09,297] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3000 is ready now!
 9: [2025-06-28 03:52:09,297] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3000 is ready now!
 6: [2025-06-28 03:52:09,297] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3000 is ready now!
 5: [2025-06-28 03:52:09,297] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3000 is ready now!
12: [2025-06-28 03:52:09,297] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3000 is ready now!
25: [2025-06-28 03:52:09,297] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3000 is ready now!
27: [2025-06-28 03:52:09,297] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3000 is ready now!
 2: [2025-06-28 03:52:09,297] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3000 is ready now!
 4: [2025-06-28 03:52:09,297] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3000 is ready now!
19: [2025-06-28 03:52:09,297] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3000 is ready now!
31: [2025-06-28 03:52:09,297] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3000 is ready now!
18: [2025-06-28 03:52:09,297] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3000 is ready now!
13: [2025-06-28 03:52:09,297] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3000 is ready now!
21: [2025-06-28 03:52:09,298] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3000 is ready now!
 1: [2025-06-28 03:52:09,299] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3000 is ready now!
16: [2025-06-28 03:52:09,299] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3000 is ready now!
 7: [2025-06-28 03:52:09,300] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3000 is ready now!
26: [2025-06-28 03:52:09,300] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3000 is ready now!
 0: [2025-06-28 03:52:09,350] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3000 is ready now!
 0: [INFO|image_processing_base.py:260] 2025-06-28 03:52:09,608 >> Image processor saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/preprocessor_config.json
 0: [INFO|tokenization_utils_base.py:2510] 2025-06-28 03:52:09,610 >> tokenizer config file saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/tokenizer_config.json
 0: [INFO|tokenization_utils_base.py:2519] 2025-06-28 03:52:09,611 >> Special tokens file saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/special_tokens_map.json
 0: [INFO|processing_utils.py:648] 2025-06-28 03:52:10,230 >> chat template saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3000/chat_template.json
 0:  68%|██████▊   | 3001/4399 [6:48:46<11:41:32, 30.11s/it] 68%|██████▊   | 3002/4399 [6:48:53<8:55:01, 22.98s/it]  68%|██████▊   | 3003/4399 [6:49:01<7:08:51, 18.43s/it]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
 0:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
 0: {'loss': 0.5678, 'grad_norm': 1.5272541599506484, 'learning_rate': 2.745439159400895e-06, 'epoch': 0.68}
 0:  68%|██████▊   | 3004/4399 [6:49:09<5:57:24, 15.37s/it] 68%|██████▊   | 3005/4399 [6:49:18<5:13:43, 13.50s/it] 68%|██████▊   | 3006/4399 [6:49:28<4:48:50, 12.44s/it] 68%|██████▊   | 3007/4399 [6:49:38<4:31:40, 11.71s/it] 68%|██████▊   | 3008/4399 [6:49:49<4:24:39, 11.42s/it] 68%|██████▊   | 3009/4399 [6:49:56<3:55:43, 10.18s/it] 68%|██████▊   | 3010/4399 [6:50:03<3:30:36,  9.10s/it]                                                        68%|██████▊   | 3010/4399 [6:50:03<3:30:36,  9.10s/it] 68%|██████▊   | 3011/4399 [6:50:12<3:32:13,  9.17s/it] 68%|██████▊   | 3012/4399 [6:50:20<3:22:54,  8.78s/it] 68%|██████▊   | 3013/4399 [6:50:29<3:27:13,  8.97s/it] 69%|██████▊   | 3014/4399 [6:50:38<3:28:37,  9.04s/it] 69%|██████▊   | 3015/4399 [6:50:47<3:25:44,  8.92s/it] 69%|██████▊   | 3016/4399 [6:50:57<3:34:4
 0: {'loss': 0.5796, 'grad_norm': 1.5160749131650466, 'learning_rate': 2.710096444311886e-06, 'epoch': 0.69}
 0: 6,  9.32s/it] 69%|██████▊   | 3017/4399 [6:51:05<3:21:18,  8.74s/it] 69%|██████▊   | 3018/4399 [6:51:11<3:05:51,  8.07s/it] 69%|██████▊   | 3019/4399 [6:51:21<3:17:02,  8.57s/it] 69%|██████▊   | 3020/4399 [6:51:28<3:09:22,  8.24s/it]                                                        69%|██████▊   | 3020/4399 [6:51:28<3:09:22,  8.24s/it] 69%|██████▊   | 3021/4399 [6:51:38<3:20:27,  8.73s/it] 69%|██████▊   | 3022/4399 [6:51:48<3:23:52,  8.88s/it] 69%|██████▊   | 3023/4399 [6:51:57<3:27:33,  9.05s/it] 69%|██████▊   | 3024/4399 [6:52:07<3:31:19,  9.22s/it] 69%|██████▉   | 3025/4399 [6:52:14<3:18:02,  8.65s/it] 69%|██████▉   | 3026/4399 [6:52:20<3:01:20,  7.92s/it] 69%|██████▉   | 3027/4399 [6:52:29<3:07:55,  8.22s/it] 69%|██████▉   | 3028/4399 [6:52:38<3:11:33,  8.38s/it] 69%|██████▉   | 3029/4399 [6
 0: {'loss': 0.5828, 'grad_norm': 1.539787277596397, 'learning_rate': 2.6748979220491646e-06, 'epoch': 0.69}
 0: {'loss': 0.569, 'grad_norm': 1.415898831300919, 'learning_rate': 2.6398458090267774e-06, 'epoch': 0.69}
 0: :52:49<3:33:11,  9.34s/it] 69%|██████▉   | 3030/4399 [6:52:58<3:25:57,  9.03s/it]                                                        69%|██████▉   | 3030/4399 [6:52:58<3:25:57,  9.03s/it] 69%|██████▉   | 3031/4399 [6:53:08<3:32:41,  9.33s/it] 69%|██████▉   | 3032/4399 [6:53:17<3:30:34,  9.24s/it] 69%|██████▉   | 3033/4399 [6:53:24<3:15:15,  8.58s/it] 69%|██████▉   | 3034/4399 [6:53:31<3:06:10,  8.18s/it] 69%|██████▉   | 3035/4399 [6:53:39<3:06:29,  8.20s/it] 69%|██████▉   | 3036/4399 [6:53:47<3:01:00,  7.97s/it] 69%|██████▉   | 3037/4399 [6:53:56<3:12:58,  8.50s/it] 69%|██████▉   | 3038/4399 [6:54:04<3:08:20,  8.30s/it] 69%|██████▉   | 3039/4399 [6:54:13<3:13:47,  8.55s/it] 69%|██████▉   | 3040/4399 [6:54:21<3:10:32,  8.41s/it]                                                        69%|██████▉   | 3040/4399 [6
 0: {'loss': 0.5791, 'grad_norm': 1.4500945605417017, 'learning_rate': 2.604942312439532e-06, 'epoch': 0.69}
 0: :54:21<3:10:32,  8.41s/it] 69%|██████▉   | 3041/4399 [6:54:29<3:01:47,  8.03s/it] 69%|██████▉   | 3042/4399 [6:54:35<2:48:51,  7.47s/it] 69%|██████▉   | 3043/4399 [6:54:42<2:46:52,  7.38s/it] 69%|██████▉   | 3044/4399 [6:54:50<2:50:55,  7.57s/it] 69%|██████▉   | 3045/4399 [6:54:59<3:01:54,  8.06s/it] 69%|██████▉   | 3046/4399 [6:55:08<3:06:40,  8.28s/it] 69%|██████▉   | 3047/4399 [6:55:17<3:14:47,  8.64s/it] 69%|██████▉   | 3048/4399 [6:55:26<3:15:01,  8.66s/it] 69%|██████▉   | 3049/4399 [6:55:33<3:03:40,  8.16s/it] 69%|██████▉   | 3050/4399 [6:55:41<2:58:58,  7.96s/it]                                                        69%|██████▉   | 3050/4399 [6:55:41<2:58:58,  7.96s/it] 69%|██████▉   | 3051/4399 [6:55:48<2:54:58,  7.79s/it] 69%|██████▉   | 3052/4399 [6:55:55<2:51:16,  7.63s/it] 69%|██████▉   |
 0: {'loss': 0.5816, 'grad_norm': 1.4194596487934972, 'learning_rate': 2.570189630124022e-06, 'epoch': 0.7}
 0:  3053/4399 [6:56:07<3:15:38,  8.72s/it] 69%|██████▉   | 3054/4399 [6:56:15<3:10:29,  8.50s/it] 69%|██████▉   | 3055/4399 [6:56:24<3:16:07,  8.76s/it] 69%|██████▉   | 3056/4399 [6:56:33<3:17:26,  8.82s/it] 69%|██████▉   | 3057/4399 [6:56:40<3:06:38,  8.34s/it] 70%|██████▉   | 3058/4399 [6:56:47<2:58:26,  7.98s/it] 70%|██████▉   | 3059/4399 [6:56:55<2:54:56,  7.83s/it] 70%|██████▉   | 3060/4399 [6:57:02<2:50:49,  7.65s/it]                                                        70%|██████▉   | 3060/4399 [6:57:02<2:50:49,  7.65s/it] 70%|██████▉   | 3061/4399 [6:57:12<3:07:13,  8.40s/it] 70%|██████▉   | 3062/4399 [6:57:22<3:17:37,  8.87s/it] 70%|██████▉   | 3063/4399 [6:57:32<3:21:39,  9.06s/it] 70%|██████▉   | 3064/4399 [6:57:41<3:22:25,  9.10s/it] 70%|██████▉   | 3065/4399 [6:57:47<3:05:07,  8.33s/it] 70%|████
 0: {'loss': 0.5712, 'grad_norm': 1.4708486087269477, 'learning_rate': 2.535589950420213e-06, 'epoch': 0.7}
 0: ██▉   | 3066/4399 [6:57:54<2:55:12,  7.89s/it] 70%|██████▉   | 3067/4399 [6:58:02<2:54:41,  7.87s/it] 70%|██████▉   | 3068/4399 [6:58:10<2:54:34,  7.87s/it] 70%|██████▉   | 3069/4399 [6:58:19<3:04:21,  8.32s/it] 70%|██████▉   | 3070/4399 [6:58:28<3:05:21,  8.37s/it]                                                        70%|██████▉   | 3070/4399 [6:58:28<3:05:21,  8.37s/it] 70%|██████▉   | 3071/4399 [6:58:38<3:16:01,  8.86s/it] 70%|██████▉   | 3072/4399 [6:58:47<3:16:40,  8.89s/it] 70%|██████▉   | 3073/4399 [6:58:53<3:01:56,  8.23s/it] 70%|██████▉   | 3074/4399 [6:59:01<2:55:14,  7.94s/it] 70%|██████▉   | 3075/4399 [6:59:08<2:54:03,  7.89s/it] 70%|██████▉   | 3076/4399 [6:59:16<2:54:33,  7.92s/it] 70%|██████▉   | 3077/4399 [6:59:26<3:05:44,  8.43s/it] 70%|██████▉   | 3078/4399 [6:59:36<3:12:58,  8.76s/it] 70%
 0: {'loss': 0.5773, 'grad_norm': 2.2734534885906856, 'learning_rate': 2.501145452033671e-06, 'epoch': 0.7}
 0: {'loss': 0.5719, 'grad_norm': 2.2655988819283857, 'learning_rate': 2.466858303898345e-06, 'epoch': 0.7}
 0: |██████▉   | 3079/4399 [6:59:44<3:10:03,  8.64s/it] 70%|███████   | 3080/4399 [6:59:53<3:13:15,  8.79s/it]                                                        70%|███████   | 3080/4399 [6:59:53<3:13:15,  8.79s/it] 70%|███████   | 3081/4399 [7:00:01<3:05:27,  8.44s/it] 70%|███████   | 3082/4399 [7:00:07<2:51:57,  7.83s/it] 70%|███████   | 3083/4399 [7:00:15<2:51:35,  7.82s/it] 70%|███████   | 3084/4399 [7:00:22<2:48:33,  7.69s/it] 70%|███████   | 3085/4399 [7:00:33<3:06:55,  8.54s/it] 70%|███████   | 3086/4399 [7:00:42<3:13:34,  8.85s/it] 70%|███████   | 3087/4399 [7:00:52<3:17:54,  9.05s/it] 70%|███████   | 3088/4399 [7:01:01<3:17:02,  9.02s/it] 70%|███████   | 3089/4399 [7:01:08<3:06:21,  8.54s/it] 70%|███████   | 3090/4399 [7:01:15<2:54:51,  8.02s/it]                                                        70%
 0: {'loss': 0.5814, 'grad_norm': 1.6707532716185047, 'learning_rate': 2.432730665040011e-06, 'epoch': 0.7}
 0: |███████   | 3090/4399 [7:01:15<2:54:51,  8.02s/it] 70%|███████   | 3091/4399 [7:01:22<2:49:29,  7.78s/it] 70%|███████   | 3092/4399 [7:01:30<2:49:38,  7.79s/it] 70%|███████   | 3093/4399 [7:01:39<2:55:40,  8.07s/it] 70%|███████   | 3094/4399 [7:01:48<3:04:12,  8.47s/it] 70%|███████   | 3095/4399 [7:01:57<3:04:40,  8.50s/it] 70%|███████   | 3096/4399 [7:02:06<3:08:06,  8.66s/it] 70%|███████   | 3097/4399 [7:02:13<2:58:22,  8.22s/it] 70%|███████   | 3098/4399 [7:02:20<2:49:30,  7.82s/it] 70%|███████   | 3099/4399 [7:02:27<2:47:07,  7.71s/it] 70%|███████   | 3100/4399 [7:02:36<2:53:19,  8.01s/it]                                                        70%|███████   | 3100/4399 [7:02:36<2:53:19,  8.01s/it] 70%|███████   | 3101/4399 [7:02:45<3:02:52,  8.45s/it] 71%|███████   | 3102/4399 [7:02:55<3:06:56,  8
 0: {'loss': 0.5686, 'grad_norm': 1.5115087684350166, 'learning_rate': 2.398764684440307e-06, 'epoch': 0.71}
 0: .65s/it] 71%|███████   | 3103/4399 [7:03:03<3:04:45,  8.55s/it] 71%|███████   | 3104/4399 [7:03:12<3:08:42,  8.74s/it] 71%|███████   | 3105/4399 [7:03:19<2:54:43,  8.10s/it] 71%|███████   | 3106/4399 [7:03:25<2:41:17,  7.48s/it] 71%|███████   | 3107/4399 [7:03:33<2:44:44,  7.65s/it] 71%|███████   | 3108/4399 [7:03:40<2:41:48,  7.52s/it] 71%|███████   | 3109/4399 [7:03:50<2:58:53,  8.32s/it] 71%|███████   | 3110/4399 [7:03:59<2:58:56,  8.33s/it]                                                        71%|███████   | 3110/4399 [7:03:59<2:58:56,  8.33s/it] 71%|███████   | 3111/4399 [7:04:06<2:54:43,  8.14s/it] 71%|███████   | 3112/4399 [7:04:16<3:06:08,  8.68s/it] 71%|███████   | 3113/4399 [7:04:24<2:57:24,  8.28s/it] 71%|███████   | 3114/4399 [7:04:30<2:48:40,  7.88s/it] 71%|███████   | 3115/4399 [7:04:3
 0: {'loss': 0.5839, 'grad_norm': 1.5978124936857818, 'learning_rate': 2.364962500901425e-06, 'epoch': 0.71}
 0: 9<2:53:10,  8.09s/it] 71%|███████   | 3116/4399 [7:04:46<2:46:56,  7.81s/it] 71%|███████   | 3117/4399 [7:04:57<3:03:23,  8.58s/it] 71%|███████   | 3118/4399 [7:05:06<3:09:03,  8.86s/it] 71%|███████   | 3119/4399 [7:05:15<3:06:25,  8.74s/it] 71%|███████   | 3120/4399 [7:05:25<3:14:19,  9.12s/it]                                                        71%|███████   | 3120/4399 [7:05:25<3:14:19,  9.12s/it] 71%|███████   | 3121/4399 [7:05:32<3:04:55,  8.68s/it] 71%|███████   | 3122/4399 [7:05:38<2:46:30,  7.82s/it] 71%|███████   | 3123/4399 [7:05:46<2:44:37,  7.74s/it] 71%|███████   | 3124/4399 [7:05:54<2:46:59,  7.86s/it] 71%|███████   | 3125/4399 [7:06:03<2:53:46,  8.18s/it] 71%|███████   | 3126/4399 [7:06:13<3:04:25,  8.69s/it] 71%|███████   | 3127/4399 [7:06:21<3:01:53,  8.58s/it] 71%|███████   | 3128
 0: {'loss': 0.5795, 'grad_norm': 1.590676964756585, 'learning_rate': 2.331326242911426e-06, 'epoch': 0.71}
 0: /4399 [7:06:31<3:10:30,  8.99s/it] 71%|███████   | 3129/4399 [7:06:37<2:55:04,  8.27s/it] 71%|███████   | 3130/4399 [7:06:45<2:48:06,  7.95s/it]                                                        71%|███████   | 3130/4399 [7:06:45<2:48:06,  7.95s/it] 71%|███████   | 3131/4399 [7:06:51<2:41:06,  7.62s/it] 71%|███████   | 3132/4399 [7:07:00<2:45:08,  7.82s/it] 71%|███████   | 3133/4399 [7:07:07<2:42:53,  7.72s/it] 71%|███████   | 3134/4399 [7:07:17<2:55:54,  8.34s/it] 71%|███████▏  | 3135/4399 [7:07:24<2:49:01,  8.02s/it] 71%|███████▏  | 3136/4399 [7:07:35<3:04:54,  8.78s/it] 71%|███████▏  | 3137/4399 [7:07:44<3:04:29,  8.77s/it] 71%|███████▏  | 3138/4399 [7:07:50<2:51:27,  8.16s/it] 71%|███████▏  | 3139/4399 [7:07:58<2:46:27,  7.93s/it] 71%|███████▏  | 3140/4399 [7:08:04<2:37:45,  7.52s/it]          
 0: {'loss': 0.5716, 'grad_norm': 1.544784443155769, 'learning_rate': 2.297858028510215e-06, 'epoch': 0.71}
 0: {'loss': 0.5753, 'grad_norm': 1.2574140306110848, 'learning_rate': 2.264559965156162e-06, 'epoch': 0.72}
 0:                                               71%|███████▏  | 3140/4399 [7:08:04<2:37:45,  7.52s/it] 71%|███████▏  | 3141/4399 [7:08:14<2:51:56,  8.20s/it] 71%|███████▏  | 3142/4399 [7:08:23<2:54:34,  8.33s/it] 71%|███████▏  | 3143/4399 [7:08:31<2:52:15,  8.23s/it] 71%|███████▏  | 3144/4399 [7:08:40<3:00:13,  8.62s/it] 71%|███████▏  | 3145/4399 [7:08:49<2:58:39,  8.55s/it] 72%|███████▏  | 3146/4399 [7:08:55<2:44:46,  7.89s/it] 72%|███████▏  | 3147/4399 [7:09:02<2:40:52,  7.71s/it] 72%|███████▏  | 3148/4399 [7:09:10<2:38:45,  7.61s/it] 72%|███████▏  | 3149/4399 [7:09:17<2:39:15,  7.64s/it] 72%|███████▏  | 3150/4399 [7:09:27<2:49:47,  8.16s/it]                                                        72%|███████▏  | 3150/4399 [7:09:27<2:49:47,  8.16s/it] 72%|███████▏  | 3151/4399 [7:09:36<2:53
 0: {'loss': 0.5803, 'grad_norm': 1.5316939252186326, 'learning_rate': 2.231434149593412e-06, 'epoch': 0.72}
 0: :59,  8.37s/it] 72%|███████▏  | 3152/4399 [7:09:47<3:12:25,  9.26s/it] 72%|███████▏  | 3153/4399 [7:09:55<3:02:08,  8.77s/it] 72%|███████▏  | 3154/4399 [7:10:02<2:51:52,  8.28s/it] 72%|███████▏  | 3155/4399 [7:10:11<2:56:21,  8.51s/it] 72%|███████▏  | 3156/4399 [7:10:19<2:57:13,  8.55s/it] 72%|███████▏  | 3157/4399 [7:10:28<2:58:50,  8.64s/it] 72%|███████▏  | 3158/4399 [7:10:37<3:01:38,  8.78s/it] 72%|███████▏  | 3159/4399 [7:10:45<2:54:30,  8.44s/it] 72%|███████▏  | 3160/4399 [7:10:54<2:59:09,  8.68s/it]                                                        72%|███████▏  | 3160/4399 [7:10:54<2:59:09,  8.68s/it] 72%|███████▏  | 3161/4399 [7:11:02<2:52:09,  8.34s/it] 72%|███████▏  | 3162/4399 [7:11:08<2:36:53,  7.61s/it] 72%|███████▏  | 3163/4399 [7:11:15<2:32:44,  7.42s/it] 72%|███
 0: {'loss': 0.5833, 'grad_norm': 1.4710071394469995, 'learning_rate': 2.198482667719842e-06, 'epoch': 0.72}
 0: ███▏  | 3164/4399 [7:11:23<2:37:59,  7.68s/it] 72%|███████▏  | 3165/4399 [7:11:31<2:40:51,  7.82s/it] 72%|███████▏  | 3166/4399 [7:11:41<2:53:57,  8.47s/it] 72%|███████▏  | 3167/4399 [7:11:49<2:52:48,  8.42s/it] 72%|███████▏  | 3168/4399 [7:11:58<2:55:07,  8.54s/it] 72%|███████▏  | 3169/4399 [7:12:06<2:52:51,  8.43s/it] 72%|███████▏  | 3170/4399 [7:12:13<2:44:37,  8.04s/it]                                                        72%|███████▏  | 3170/4399 [7:12:13<2:44:37,  8.04s/it] 72%|███████▏  | 3171/4399 [7:12:20<2:37:19,  7.69s/it] 72%|███████▏  | 3172/4399 [7:12:28<2:35:39,  7.61s/it] 72%|███████▏  | 3173/4399 [7:12:35<2:35:14,  7.60s/it] 72%|███████▏  | 3174/4399 [7:12:46<2:51:44,  8.41s/it] 72%|███████▏  | 3175/4399 [7:12:54<2:49:32,  8.31s/it] 72%|███████▏  | 3176/4399 [7:
 0: {'loss': 0.5612, 'grad_norm': 1.5202808048999703, 'learning_rate': 2.165707594455724e-06, 'epoch': 0.72}
 0: 13:03<2:56:53,  8.68s/it] 72%|███████▏  | 3177/4399 [7:13:10<2:46:31,  8.18s/it] 72%|███████▏  | 3178/4399 [7:13:16<2:32:34,  7.50s/it] 72%|███████▏  | 3179/4399 [7:13:23<2:30:19,  7.39s/it] 72%|███████▏  | 3180/4399 [7:13:31<2:31:01,  7.43s/it]                                                        72%|███████▏  | 3180/4399 [7:13:31<2:31:01,  7.43s/it] 72%|███████▏  | 3181/4399 [7:13:39<2:35:07,  7.64s/it] 72%|███████▏  | 3182/4399 [7:13:49<2:49:16,  8.35s/it] 72%|███████▏  | 3183/4399 [7:13:56<2:43:12,  8.05s/it] 72%|███████▏  | 3184/4399 [7:14:05<2:48:28,  8.32s/it] 72%|███████▏  | 3185/4399 [7:14:13<2:43:49,  8.10s/it] 72%|███████▏  | 3186/4399 [7:14:20<2:36:21,  7.73s/it] 72%|███████▏  | 3187/4399 [7:14:27<2:32:00,  7.53s/it] 72%|███████▏  | 3188/4399 [7:14:34<2:31:19,  7.50s/it] 72%|
 0: {'loss': 0.5787, 'grad_norm': 1.7130503537580781, 'learning_rate': 2.133110993613058e-06, 'epoch': 0.73}
 0: ███████▏  | 3189/4399 [7:14:42<2:35:06,  7.69s/it] 73%|███████▎  | 3190/4399 [7:14:52<2:47:44,  8.32s/it]                                                        73%|███████▎  | 3190/4399 [7:14:52<2:47:44,  8.32s/it] 73%|███████▎  | 3191/4399 [7:15:02<2:58:45,  8.88s/it] 73%|███████▎  | 3192/4399 [7:15:11<2:55:17,  8.71s/it] 73%|███████▎  | 3193/4399 [7:15:19<2:53:56,  8.65s/it] 73%|███████▎  | 3194/4399 [7:15:25<2:39:25,  7.94s/it] 73%|███████▎  | 3195/4399 [7:15:32<2:33:19,  7.64s/it] 73%|███████▎  | 3196/4399 [7:15:42<2:43:23,  8.15s/it] 73%|███████▎  | 3197/4399 [7:15:49<2:40:33,  8.01s/it] 73%|███████▎  | 3198/4399 [7:16:02<3:08:03,  9.40s/it] 73%|███████▎  | 3199/4399 [7:16:12<3:09:14,  9.46s/it] 73%|███████▎  | 3200/4399 [7:16:19<2:55:19,  8.77s/it]                                    
 0: {'loss': 0.5764, 'grad_norm': 1.4341406106883081, 'learning_rate': 2.1006949177656273e-06, 'epoch': 0.73}
 0: {'loss': 0.5842, 'grad_norm': 1.4854606288811154, 'learning_rate': 2.068461408119745e-06, 'epoch': 0.73}
 0:                     73%|███████▎  | 3200/4399 [7:16:19<2:55:19,  8.77s/it] 73%|███████▎  | 3201/4399 [7:16:27<2:48:43,  8.45s/it] 73%|███████▎  | 3202/4399 [7:16:33<2:37:16,  7.88s/it] 73%|███████▎  | 3203/4399 [7:16:41<2:38:18,  7.94s/it] 73%|███████▎  | 3204/4399 [7:16:49<2:37:00,  7.88s/it] 73%|███████▎  | 3205/4399 [7:16:57<2:35:42,  7.82s/it] 73%|███████▎  | 3206/4399 [7:17:07<2:51:08,  8.61s/it] 73%|███████▎  | 3207/4399 [7:17:17<2:56:57,  8.91s/it] 73%|███████▎  | 3208/4399 [7:17:24<2:50:14,  8.58s/it] 73%|███████▎  | 3209/4399 [7:17:32<2:44:00,  8.27s/it] 73%|███████▎  | 3210/4399 [7:17:39<2:34:25,  7.79s/it]                                                        73%|███████▎  | 3210/4399 [7:17:39<2:34:25,  7.79s/it] 73%|███████▎  | 3211/4399 [7:17:46<2:31:11,  7.64s/it] 73%|█
 0: {'loss': 0.5744, 'grad_norm': 1.4848746464473983, 'learning_rate': 2.0364124943857226e-06, 'epoch': 0.73}
 0: █████▎  | 3212/4399 [7:17:54<2:30:33,  7.61s/it] 73%|███████▎  | 3213/4399 [7:18:03<2:43:21,  8.26s/it] 73%|███████▎  | 3214/4399 [7:18:13<2:49:55,  8.60s/it] 73%|███████▎  | 3215/4399 [7:18:21<2:47:36,  8.49s/it] 73%|███████▎  | 3216/4399 [7:18:30<2:49:51,  8.62s/it] 73%|███████▎  | 3217/4399 [7:18:38<2:46:37,  8.46s/it] 73%|███████▎  | 3218/4399 [7:18:45<2:36:24,  7.95s/it] 73%|███████▎  | 3219/4399 [7:18:53<2:40:40,  8.17s/it] 73%|███████▎  | 3220/4399 [7:19:01<2:39:44,  8.13s/it]                                                        73%|███████▎  | 3220/4399 [7:19:01<2:39:44,  8.13s/it] 73%|███████▎  | 3221/4399 [7:19:10<2:42:03,  8.25s/it] 73%|███████▎  | 3222/4399 [7:19:20<2:53:25,  8.84s/it] 73%|███████▎  | 3223/4399 [7:19:30<2:58:21,  9.10s/it] 73%|███████▎  | 3224/439
 0: {'loss': 0.5726, 'grad_norm': 2.280263615036153, 'learning_rate': 2.0045501946500607e-06, 'epoch': 0.73}
 0: 9 [7:19:39<3:00:23,  9.21s/it] 73%|███████▎  | 3225/4399 [7:19:47<2:50:02,  8.69s/it] 73%|███████▎  | 3226/4399 [7:19:54<2:38:49,  8.12s/it] 73%|███████▎  | 3227/4399 [7:20:00<2:29:03,  7.63s/it] 73%|███████▎  | 3228/4399 [7:20:07<2:27:03,  7.53s/it] 73%|███████▎  | 3229/4399 [7:20:17<2:39:09,  8.16s/it] 73%|███████▎  | 3230/4399 [7:20:28<2:53:41,  8.91s/it]                                                        73%|███████▎  | 3230/4399 [7:20:28<2:53:41,  8.91s/it] 73%|███████▎  | 3231/4399 [7:20:36<2:49:16,  8.70s/it] 73%|███████▎  | 3232/4399 [7:20:46<2:55:48,  9.04s/it] 73%|███████▎  | 3233/4399 [7:20:55<2:56:51,  9.10s/it] 74%|███████▎  | 3234/4399 [7:21:02<2:45:08,  8.51s/it] 74%|███████▎  | 3235/4399 [7:21:09<2:32:57,  7.88s/it] 74%|███████▎  | 3236/4399 [7:21:17<2:34:34,  7.97s/it]
 0: {'loss': 0.5885, 'grad_norm': 1.4931949757465988, 'learning_rate': 1.972876515248367e-06, 'epoch': 0.74}
 0:  74%|███████▎  | 3237/4399 [7:21:26<2:42:33,  8.39s/it] 74%|███████▎  | 3238/4399 [7:21:35<2:47:56,  8.68s/it] 74%|███████▎  | 3239/4399 [7:21:43<2:39:53,  8.27s/it] 74%|███████▎  | 3240/4399 [7:21:52<2:46:42,  8.63s/it]                                                        74%|███████▎  | 3240/4399 [7:21:52<2:46:42,  8.63s/it] 74%|███████▎  | 3241/4399 [7:22:00<2:43:52,  8.49s/it] 74%|███████▎  | 3242/4399 [7:22:07<2:32:27,  7.91s/it] 74%|███████▎  | 3243/4399 [7:22:13<2:24:13,  7.49s/it] 74%|███████▎  | 3244/4399 [7:22:21<2:27:05,  7.64s/it] 74%|███████▍  | 3245/4399 [7:22:30<2:34:05,  8.01s/it] 74%|███████▍  | 3246/4399 [7:22:39<2:37:45,  8.21s/it] 74%|███████▍  | 3247/4399 [7:22:49<2:49:00,  8.80s/it] 74%|███████▍  | 3248/4399 [7:22:58<2:48:02,  8.76s/it] 74%|███████▍  
 0: {'loss': 0.5901, 'grad_norm': 2.168336106683507, 'learning_rate': 1.941393450639032e-06, 'epoch': 0.74}
 0: {'loss': 0.5567, 'grad_norm': 1.4123195721445692, 'learning_rate': 1.910102983277624e-06, 'epoch': 0.74}
 0: | 3249/4399 [7:23:07<2:51:34,  8.95s/it] 74%|███████▍  | 3250/4399 [7:23:14<2:36:35,  8.18s/it]                                                        74%|███████▍  | 3250/4399 [7:23:14<2:36:35,  8.18s/it] 74%|███████▍  | 3251/4399 [7:23:20<2:27:45,  7.72s/it] 74%|███████▍  | 3252/4399 [7:23:28<2:26:49,  7.68s/it] 74%|███████▍  | 3253/4399 [7:23:37<2:32:22,  7.98s/it] 74%|███████▍  | 3254/4399 [7:23:46<2:41:31,  8.46s/it] 74%|███████▍  | 3255/4399 [7:23:55<2:44:39,  8.64s/it] 74%|███████▍  | 3256/4399 [7:24:04<2:44:51,  8.65s/it] 74%|███████▍  | 3257/4399 [7:24:12<2:44:03,  8.62s/it] 74%|███████▍  | 3258/4399 [7:24:19<2:32:39,  8.03s/it] 74%|███████▍  | 3259/4399 [7:24:26<2:24:21,  7.60s/it] 74%|███████▍  | 3260/4399 [7:24:33<2:24:59,  7.64s/it]                                                        74%|
 0: {'loss': 0.5736, 'grad_norm': 1.2763975282273443, 'learning_rate': 1.8790070834920765e-06, 'epoch': 0.74}
 0: ███████▍  | 3260/4399 [7:24:33<2:24:59,  7.64s/it] 74%|███████▍  | 3261/4399 [7:24:42<2:30:27,  7.93s/it] 74%|███████▍  | 3262/4399 [7:24:52<2:44:53,  8.70s/it] 74%|███████▍  | 3263/4399 [7:25:01<2:42:50,  8.60s/it] 74%|███████▍  | 3264/4399 [7:25:10<2:47:30,  8.86s/it] 74%|███████▍  | 3265/4399 [7:25:18<2:41:07,  8.53s/it] 74%|███████▍  | 3266/4399 [7:25:25<2:30:12,  7.95s/it] 74%|███████▍  | 3267/4399 [7:25:32<2:23:56,  7.63s/it] 74%|███████▍  | 3268/4399 [7:25:39<2:24:00,  7.64s/it] 74%|███████▍  | 3269/4399 [7:25:49<2:33:32,  8.15s/it] 74%|███████▍  | 3270/4399 [7:25:59<2:47:44,  8.91s/it]                                                        74%|███████▍  | 3270/4399 [7:25:59<2:47:44,  8.91s/it] 74%|███████▍  | 3271/4399 [7:26:08<2:45:00,  8.78s/it] 74%|███████▍  | 327
 0: {'loss': 0.5767, 'grad_norm': 1.5965014888485003, 'learning_rate': 1.8481077093585948e-06, 'epoch': 0.75}
 0: 2/4399 [7:26:18<2:54:02,  9.27s/it] 74%|███████▍  | 3273/4399 [7:26:26<2:44:53,  8.79s/it] 74%|███████▍  | 3274/4399 [7:26:33<2:33:22,  8.18s/it] 74%|███████▍  | 3275/4399 [7:26:40<2:27:21,  7.87s/it] 74%|███████▍  | 3276/4399 [7:26:47<2:22:22,  7.61s/it] 74%|███████▍  | 3277/4399 [7:26:56<2:29:15,  7.98s/it] 75%|███████▍  | 3278/4399 [7:27:05<2:39:51,  8.56s/it] 75%|███████▍  | 3279/4399 [7:27:15<2:45:47,  8.88s/it] 75%|███████▍  | 3280/4399 [7:27:25<2:49:11,  9.07s/it]                                                        75%|███████▍  | 3280/4399 [7:27:25<2:49:11,  9.07s/it] 75%|███████▍  | 3281/4399 [7:27:32<2:41:18,  8.66s/it] 75%|███████▍  | 3282/4399 [7:27:40<2:36:01,  8.38s/it] 75%|███████▍  | 3283/4399 [7:27:48<2:33:19,  8.24s/it] 75%|███████▍  | 3284/4399 [7:27:55<2:27:24,  7.93s
 0: {'loss': 0.5635, 'grad_norm': 1.3257416584829569, 'learning_rate': 1.8174068065783768e-06, 'epoch': 0.75}
 0: /it] 75%|███████▍  | 3285/4399 [7:28:04<2:33:01,  8.24s/it] 75%|███████▍  | 3286/4399 [7:28:12<2:32:54,  8.24s/it] 75%|███████▍  | 3287/4399 [7:28:21<2:37:10,  8.48s/it] 75%|███████▍  | 3288/4399 [7:28:31<2:44:59,  8.91s/it] 75%|███████▍  | 3289/4399 [7:28:40<2:42:37,  8.79s/it] 75%|███████▍  | 3290/4399 [7:28:47<2:32:17,  8.24s/it]                                                        75%|███████▍  | 3290/4399 [7:28:47<2:32:17,  8.24s/it] 75%|███████▍  | 3291/4399 [7:28:54<2:28:18,  8.03s/it] 75%|███████▍  | 3292/4399 [7:29:03<2:31:14,  8.20s/it] 75%|███████▍  | 3293/4399 [7:29:12<2:37:06,  8.52s/it] 75%|███████▍  | 3294/4399 [7:29:21<2:38:50,  8.63s/it] 75%|███████▍  | 3295/4399 [7:29:31<2:43:46,  8.90s/it] 75%|███████▍  | 3296/4399 [7:29:40<2:45:17,  8.99s/it] 75%|███████
 0: {'loss': 0.5592, 'grad_norm': 1.882108420608904, 'learning_rate': 1.786906308355083e-06, 'epoch': 0.75}
 0: ▍  | 3297/4399 [7:29:47<2:37:27,  8.57s/it] 75%|███████▍  | 3298/4399 [7:29:55<2:30:05,  8.18s/it] 75%|███████▍  | 3299/4399 [7:30:01<2:20:32,  7.67s/it] 75%|███████▌  | 3300/4399 [7:30:08<2:15:46,  7.41s/it]                                                        75%|███████▌  | 3300/4399 [7:30:08<2:15:46,  7.41s/it] 75%|███████▌  | 3301/4399 [7:30:17<2:24:20,  7.89s/it] 75%|███████▌  | 3302/4399 [7:30:26<2:30:14,  8.22s/it] 75%|███████▌  | 3303/4399 [7:30:35<2:35:03,  8.49s/it] 75%|███████▌  | 3304/4399 [7:30:43<2:34:16,  8.45s/it] 75%|███████▌  | 3305/4399 [7:30:51<2:30:04,  8.23s/it] 75%|███████▌  | 3306/4399 [7:30:59<2:30:15,  8.25s/it] 75%|███████▌  | 3307/4399 [7:31:06<2:20:28,  7.72s/it] 75%|███████▌  | 3308/4399 [7:31:13<2:16:13,  7.49s/it] 75%|███████▌  | 3309/4399 [7:31:21<2:20:
 0: {'loss': 0.5761, 'grad_norm': 1.443343608093382, 'learning_rate': 1.7566081352731135e-06, 'epoch': 0.75}
 0: {'loss': 0.5769, 'grad_norm': 1.5364299440807527, 'learning_rate': 1.7265141951766634e-06, 'epoch': 0.75}
 0: 32,  7.74s/it] 75%|███████▌  | 3310/4399 [7:31:31<2:32:35,  8.41s/it]                                                        75%|███████▌  | 3310/4399 [7:31:31<2:32:35,  8.41s/it] 75%|███████▌  | 3311/4399 [7:31:40<2:33:21,  8.46s/it] 75%|███████▌  | 3312/4399 [7:31:49<2:37:25,  8.69s/it] 75%|███████▌  | 3313/4399 [7:31:57<2:34:35,  8.54s/it] 75%|███████▌  | 3314/4399 [7:32:05<2:28:50,  8.23s/it] 75%|███████▌  | 3315/4399 [7:32:11<2:19:23,  7.72s/it] 75%|███████▌  | 3316/4399 [7:32:20<2:23:49,  7.97s/it] 75%|███████▌  | 3317/4399 [7:32:27<2:22:14,  7.89s/it] 75%|███████▌  | 3318/4399 [7:32:36<2:25:18,  8.07s/it] 75%|███████▌  | 3319/4399 [7:32:46<2:37:07,  8.73s/it] 75%|███████▌  | 3320/4399 [7:32:54<2:33:59,  8.56s/it]                                                        75%|███████▌  
 0: {'loss': 0.5877, 'grad_norm': 1.4291079916581029, 'learning_rate': 1.6966263830495939e-06, 'epoch': 0.76}
 0: | 3320/4399 [7:32:54<2:33:59,  8.56s/it] 75%|███████▌  | 3321/4399 [7:33:02<2:29:57,  8.35s/it] 76%|███████▌  | 3322/4399 [7:33:11<2:31:21,  8.43s/it] 76%|███████▌  | 3323/4399 [7:33:17<2:20:46,  7.85s/it] 76%|███████▌  | 3324/4399 [7:33:25<2:20:04,  7.82s/it] 76%|███████▌  | 3325/4399 [7:33:34<2:27:08,  8.22s/it] 76%|███████▌  | 3326/4399 [7:33:42<2:25:55,  8.16s/it] 76%|███████▌  | 3327/4399 [7:33:51<2:30:40,  8.43s/it] 76%|███████▌  | 3328/4399 [7:34:01<2:39:12,  8.92s/it] 76%|███████▌  | 3329/4399 [7:34:09<2:32:56,  8.58s/it] 76%|███████▌  | 3330/4399 [7:34:18<2:32:13,  8.54s/it]                                                        76%|███████▌  | 3330/4399 [7:34:18<2:32:13,  8.54s/it] 76%|███████▌  | 3331/4399 [7:34:25<2:26:41,  8.24s/it] 76%|███████▌  | 3332/4399 [7:34:33<2:26:19,  
 0: {'loss': 0.5877, 'grad_norm': 1.6012498350062092, 'learning_rate': 1.6669465808960978e-06, 'epoch': 0.76}
 0: 8.23s/it] 76%|███████▌  | 3333/4399 [7:34:41<2:22:16,  8.01s/it] 76%|███████▌  | 3334/4399 [7:34:49<2:24:10,  8.12s/it] 76%|███████▌  | 3335/4399 [7:34:57<2:23:32,  8.09s/it] 76%|███████▌  | 3336/4399 [7:35:06<2:28:58,  8.41s/it] 76%|███████▌  | 3337/4399 [7:35:15<2:29:51,  8.47s/it] 76%|███████▌  | 3338/4399 [7:35:22<2:23:21,  8.11s/it] 76%|███████▌  | 3339/4399 [7:35:29<2:16:33,  7.73s/it] 76%|███████▌  | 3340/4399 [7:35:37<2:17:21,  7.78s/it]                                                        76%|███████▌  | 3340/4399 [7:35:37<2:17:21,  7.78s/it] 76%|███████▌  | 3341/4399 [7:35:46<2:21:25,  8.02s/it] 76%|███████▌  | 3342/4399 [7:35:54<2:24:42,  8.21s/it] 76%|███████▌  | 3343/4399 [7:36:03<2:29:27,  8.49s/it] 76%|███████▌  | 3344/4399 [7:36:12<2:31:29,  8.62s/it] 76%|█████
 0: {'loss': 0.5837, 'grad_norm': 1.8725343821404483, 'learning_rate': 1.6374766576222045e-06, 'epoch': 0.76}
 0: █▌  | 3345/4399 [7:36:21<2:34:24,  8.79s/it] 76%|███████▌  | 3346/4399 [7:36:29<2:27:27,  8.40s/it] 76%|███████▌  | 3347/4399 [7:36:37<2:23:17,  8.17s/it] 76%|███████▌  | 3348/4399 [7:36:44<2:17:16,  7.84s/it] 76%|███████▌  | 3349/4399 [7:36:52<2:17:39,  7.87s/it] 76%|███████▌  | 3350/4399 [7:37:00<2:20:26,  8.03s/it]                                                        76%|███████▌  | 3350/4399 [7:37:00<2:20:26,  8.03s/it] 76%|███████▌  | 3351/4399 [7:37:09<2:24:44,  8.29s/it] 76%|███████▌  | 3352/4399 [7:37:18<2:30:42,  8.64s/it] 76%|███████▌  | 3353/4399 [7:37:26<2:22:45,  8.19s/it] 76%|███████▌  | 3354/4399 [7:37:33<2:20:46,  8.08s/it] 76%|███████▋  | 3355/4399 [7:37:40<2:14:49,  7.75s/it] 76%|███████▋  | 3356/4399 [7:37:48<2:13:56,  7.71s/it] 76%|███████▋  | 3357/4399 [7:37:57<
 0: {'loss': 0.5782, 'grad_norm': 1.5461002506190473, 'learning_rate': 1.6082184689180874e-06, 'epoch': 0.76}
 0: 2:18:36,  7.98s/it] 76%|███████▋  | 3358/4399 [7:38:04<2:17:28,  7.92s/it] 76%|███████▋  | 3359/4399 [7:38:13<2:21:01,  8.14s/it] 76%|███████▋  | 3360/4399 [7:38:21<2:19:12,  8.04s/it]                                                        76%|███████▋  | 3360/4399 [7:38:21<2:19:12,  8.04s/it] 76%|███████▋  | 3361/4399 [7:38:29<2:19:53,  8.09s/it] 76%|███████▋  | 3362/4399 [7:38:37<2:18:42,  8.03s/it] 76%|███████▋  | 3363/4399 [7:38:44<2:14:22,  7.78s/it] 76%|███████▋  | 3364/4399 [7:38:51<2:09:17,  7.50s/it] 76%|███████▋  | 3365/4399 [7:38:59<2:13:25,  7.74s/it] 77%|███████▋  | 3366/4399 [7:39:07<2:15:57,  7.90s/it] 77%|███████▋  | 3367/4399 [7:39:16<2:20:47,  8.19s/it] 77%|███████▋  | 3368/4399 [7:39:25<2:23:29,  8.35s/it] 77%|███████▋  | 3369/4399 [7:39:34<2:23:51,  8.38s/it] 77%|██
 0: {'loss': 0.5924, 'grad_norm': 1.5772745298946826, 'learning_rate': 1.579173857141218e-06, 'epoch': 0.77}
 0: {'loss': 0.5711, 'grad_norm': 3.104128709516356, 'learning_rate': 1.5503446512003477e-06, 'epoch': 0.77}
 0: █████▋  | 3370/4399 [7:39:41<2:19:24,  8.13s/it]                                                        77%|███████▋  | 3370/4399 [7:39:41<2:19:24,  8.13s/it] 77%|███████▋  | 3371/4399 [7:39:48<2:15:42,  7.92s/it] 77%|███████▋  | 3372/4399 [7:39:56<2:15:35,  7.92s/it] 77%|███████▋  | 3373/4399 [7:40:05<2:20:12,  8.20s/it] 77%|███████▋  | 3374/4399 [7:40:14<2:21:27,  8.28s/it] 77%|███████▋  | 3375/4399 [7:40:24<2:30:26,  8.81s/it] 77%|███████▋  | 3376/4399 [7:40:33<2:32:05,  8.92s/it] 77%|███████▋  | 3377/4399 [7:40:42<2:31:45,  8.91s/it] 77%|███████▋  | 3378/4399 [7:40:50<2:28:55,  8.75s/it] 77%|███████▋  | 3379/4399 [7:40:57<2:20:43,  8.28s/it] 77%|███████▋  | 3380/4399 [7:41:04<2:13:59,  7.89s/it]                                                        77%|███████▋  | 3380/4399 [7:41:04<2:13:
 0: {'loss': 0.5695, 'grad_norm': 1.3957350887415796, 'learning_rate': 1.5217326664403554e-06, 'epoch': 0.77}
 0: 59,  7.89s/it] 77%|███████▋  | 3381/4399 [7:41:13<2:16:42,  8.06s/it] 77%|███████▋  | 3382/4399 [7:41:21<2:18:41,  8.18s/it] 77%|███████▋  | 3383/4399 [7:41:30<2:23:24,  8.47s/it] 77%|███████▋  | 3384/4399 [7:41:39<2:22:24,  8.42s/it] 77%|███████▋  | 3385/4399 [7:41:48<2:25:46,  8.63s/it] 77%|███████▋  | 3386/4399 [7:41:56<2:24:36,  8.57s/it] 77%|███████▋  | 3387/4399 [7:42:04<2:18:40,  8.22s/it] 77%|███████▋  | 3388/4399 [7:42:10<2:10:56,  7.77s/it] 77%|███████▋  | 3389/4399 [7:42:20<2:20:40,  8.36s/it] 77%|███████▋  | 3390/4399 [7:42:28<2:17:58,  8.20s/it]                                                        77%|███████▋  | 3390/4399 [7:42:28<2:17:58,  8.20s/it] 77%|███████▋  | 3391/4399 [7:42:38<2:26:16,  8.71s/it] 77%|███████▋  | 3392/4399 [7:42:48<2:33:35,  9.15s/it] 77%|███
 0: {'loss': 0.5834, 'grad_norm': 1.4611187596516895, 'learning_rate': 1.4933397045279203e-06, 'epoch': 0.77}
 0: ███▋  | 3393/4399 [7:42:56<2:26:15,  8.72s/it] 77%|███████▋  | 3394/4399 [7:43:04<2:21:46,  8.46s/it] 77%|███████▋  | 3395/4399 [7:43:10<2:11:58,  7.89s/it] 77%|███████▋  | 3396/4399 [7:43:17<2:06:23,  7.56s/it] 77%|███████▋  | 3397/4399 [7:43:26<2:11:29,  7.87s/it] 77%|███████▋  | 3398/4399 [7:43:34<2:14:50,  8.08s/it] 77%|███████▋  | 3399/4399 [7:43:43<2:17:03,  8.22s/it] 77%|███████▋  | 3400/4399 [7:43:53<2:24:50,  8.70s/it]                                                        77%|███████▋  | 3400/4399 [7:43:53<2:24:50,  8.70s/it] 77%|███████▋  | 3401/4399 [7:44:00<2:20:08,  8.43s/it] 77%|███████▋  | 3402/4399 [7:44:09<2:22:34,  8.58s/it] 77%|███████▋  | 3403/4399 [7:44:16<2:13:39,  8.05s/it] 77%|███████▋  | 3404/4399 [7:44:24<2:11:28,  7.93s/it] 77%|███████▋  | 3405/4399 [7:4
 0: {'loss': 0.5867, 'grad_norm': 1.4542297477055626, 'learning_rate': 1.465167553338096e-06, 'epoch': 0.78}
 0: 4:33<2:19:52,  8.44s/it] 77%|███████▋  | 3406/4399 [7:44:43<2:23:17,  8.66s/it] 77%|███████▋  | 3407/4399 [7:44:52<2:26:53,  8.88s/it] 77%|███████▋  | 3408/4399 [7:45:00<2:21:54,  8.59s/it] 77%|███████▋  | 3409/4399 [7:45:08<2:21:11,  8.56s/it] 78%|███████▊  | 3410/4399 [7:45:17<2:21:53,  8.61s/it]                                                        78%|███████▊  | 3410/4399 [7:45:17<2:21:53,  8.61s/it] 78%|███████▊  | 3411/4399 [7:45:24<2:15:25,  8.22s/it] 78%|███████▊  | 3412/4399 [7:45:31<2:08:16,  7.80s/it] 78%|███████▊  | 3413/4399 [7:45:39<2:08:58,  7.85s/it] 78%|███████▊  | 3414/4399 [7:45:48<2:13:06,  8.11s/it] 78%|███████▊  | 3415/4399 [7:45:56<2:14:21,  8.19s/it] 78%|███████▊  | 3416/4399 [7:46:06<2:22:08,  8.68s/it] 78%|███████▊  | 3417/4399 [7:46:14<2:18:40,  8.47s/it] 78%|
 0: {'loss': 0.5704, 'grad_norm': 1.375147699116576, 'learning_rate': 1.4372179868417024e-06, 'epoch': 0.78}
 0: ██████▊  | 3418/4399 [7:46:22<2:17:25,  8.41s/it] 78%|███████▊  | 3419/4399 [7:46:30<2:14:51,  8.26s/it] 78%|███████▊  | 3420/4399 [7:46:39<2:15:48,  8.32s/it]                                                        78%|███████▊  | 3420/4399 [7:46:39<2:15:48,  8.32s/it] 78%|███████▊  | 3421/4399 [7:46:48<2:22:53,  8.77s/it] 78%|███████▊  | 3422/4399 [7:46:56<2:17:53,  8.47s/it] 78%|███████▊  | 3423/4399 [7:47:05<2:18:51,  8.54s/it] 78%|███████▊  | 3424/4399 [7:47:14<2:21:50,  8.73s/it] 78%|███████▊  | 3425/4399 [7:47:22<2:19:13,  8.58s/it] 78%|███████▊  | 3426/4399 [7:47:31<2:20:34,  8.67s/it] 78%|███████▊  | 3427/4399 [7:47:40<2:20:05,  8.65s/it] 78%|███████▊  | 3428/4399 [7:47:47<2:12:23,  8.18s/it] 78%|███████▊  | 3429/4399 [7:47:55<2:12:21,  8.19s/it] 78%|███████▊  | 3430
 0: {'loss': 0.5793, 'grad_norm': 1.6099397309154109, 'learning_rate': 1.4094927649936457e-06, 'epoch': 0.78}
 0: {'loss': 0.5759, 'grad_norm': 1.8658848170541216, 'learning_rate': 1.3819936336220758e-06, 'epoch': 0.78}
 0: /4399 [7:48:03<2:10:11,  8.06s/it]                                                        78%|███████▊  | 3430/4399 [7:48:03<2:10:11,  8.06s/it] 78%|███████▊  | 3431/4399 [7:48:13<2:19:31,  8.65s/it] 78%|███████▊  | 3432/4399 [7:48:23<2:23:59,  8.93s/it] 78%|███████▊  | 3433/4399 [7:48:31<2:22:02,  8.82s/it] 78%|███████▊  | 3434/4399 [7:48:40<2:22:51,  8.88s/it] 78%|███████▊  | 3435/4399 [7:48:48<2:16:36,  8.50s/it] 78%|███████▊  | 3436/4399 [7:48:55<2:11:53,  8.22s/it] 78%|███████▊  | 3437/4399 [7:49:04<2:13:14,  8.31s/it] 78%|███████▊  | 3438/4399 [7:49:13<2:18:42,  8.66s/it] 78%|███████▊  | 3439/4399 [7:49:22<2:20:30,  8.78s/it] 78%|███████▊  | 3440/4399 [7:49:32<2:23:38,  8.99s/it]                                                        78%|███████▊  | 3440/4399 [7:49:32<2:23:38,  8.99s/it] 78%|██
 0: {'loss': 0.5846, 'grad_norm': 1.4074861658206255, 'learning_rate': 1.354722324318468e-06, 'epoch': 0.78}
 0: █████▊  | 3441/4399 [7:49:41<2:22:17,  8.91s/it] 78%|███████▊  | 3442/4399 [7:49:51<2:28:53,  9.34s/it] 78%|███████▊  | 3443/4399 [7:49:57<2:15:39,  8.51s/it] 78%|███████▊  | 3444/4399 [7:50:05<2:08:36,  8.08s/it] 78%|███████▊  | 3445/4399 [7:50:13<2:11:01,  8.24s/it] 78%|███████▊  | 3446/4399 [7:50:21<2:10:20,  8.21s/it] 78%|███████▊  | 3447/4399 [7:50:30<2:11:28,  8.29s/it] 78%|███████▊  | 3448/4399 [7:50:37<2:07:54,  8.07s/it] 78%|███████▊  | 3449/4399 [7:50:48<2:19:35,  8.82s/it] 78%|███████▊  | 3450/4399 [7:50:55<2:13:34,  8.45s/it]                                                        78%|███████▊  | 3450/4399 [7:50:55<2:13:34,  8.45s/it] 78%|███████▊  | 3451/4399 [7:51:03<2:10:01,  8.23s/it] 78%|███████▊  | 3452/4399 [7:51:10<2:03:25,  7.82s/it] 78%|███████▊  | 3453/4399
 0: {'loss': 0.5774, 'grad_norm': 1.3992685223022916, 'learning_rate': 1.3276805543285804e-06, 'epoch': 0.79}
 0:  [7:51:19<2:06:55,  8.05s/it] 79%|███████▊  | 3454/4399 [7:51:28<2:13:03,  8.45s/it] 79%|███████▊  | 3455/4399 [7:51:35<2:06:08,  8.02s/it] 79%|███████▊  | 3456/4399 [7:51:44<2:12:30,  8.43s/it] 79%|███████▊  | 3457/4399 [7:51:53<2:14:17,  8.55s/it] 79%|███████▊  | 3458/4399 [7:52:01<2:12:26,  8.44s/it] 79%|███████▊  | 3459/4399 [7:52:11<2:17:33,  8.78s/it] 79%|███████▊  | 3460/4399 [7:52:17<2:05:33,  8.02s/it]                                                        79%|███████▊  | 3460/4399 [7:52:17<2:05:33,  8.02s/it] 79%|███████▊  | 3461/4399 [7:52:27<2:13:38,  8.55s/it] 79%|███████▊  | 3462/4399 [7:52:35<2:12:34,  8.49s/it] 79%|███████▊  | 3463/4399 [7:52:44<2:13:42,  8.57s/it] 79%|███████▊  | 3464/4399 [7:52:53<2:12:47,  8.52s/it] 79%|███████▉  | 3465/4399 [7:53:02<2:18:01,  8.87s/it] 
 0: {'loss': 0.5681, 'grad_norm': 1.509196489447762, 'learning_rate': 1.3008700264443209e-06, 'epoch': 0.79}
 0: 79%|███████▉  | 3466/4399 [7:53:09<2:08:44,  8.28s/it] 79%|███████▉  | 3467/4399 [7:53:17<2:05:35,  8.09s/it] 79%|███████▉  | 3468/4399 [7:53:24<2:02:18,  7.88s/it] 79%|███████▉  | 3469/4399 [7:53:34<2:10:12,  8.40s/it] 79%|███████▉  | 3470/4399 [7:53:42<2:09:47,  8.38s/it]                                                        79%|███████▉  | 3470/4399 [7:53:42<2:09:47,  8.38s/it] 79%|███████▉  | 3471/4399 [7:53:51<2:10:09,  8.42s/it] 79%|███████▉  | 3472/4399 [7:53:59<2:11:41,  8.52s/it] 79%|███████▉  | 3473/4399 [7:54:09<2:16:09,  8.82s/it] 79%|███████▉  | 3474/4399 [7:54:18<2:15:12,  8.77s/it] 79%|███████▉  | 3475/4399 [7:54:25<2:07:06,  8.25s/it] 79%|███████▉  | 3476/4399 [7:54:32<2:03:06,  8.00s/it] 79%|███████▉  | 3477/4399 [7:54:41<2:05:53,  8.19s/it] 79%|███████▉  |
 0: {'loss': 0.5662, 'grad_norm': 1.5984436880910387, 'learning_rate': 1.2742924288965203e-06, 'epoch': 0.79}
 0:  3478/4399 [7:54:49<2:04:48,  8.13s/it] 79%|███████▉  | 3479/4399 [7:54:57<2:07:45,  8.33s/it] 79%|███████▉  | 3480/4399 [7:55:08<2:16:26,  8.91s/it]                                                        79%|███████▉  | 3480/4399 [7:55:08<2:16:26,  8.91s/it] 79%|███████▉  | 3481/4399 [7:55:18<2:20:27,  9.18s/it] 79%|███████▉  | 3482/4399 [7:55:25<2:11:52,  8.63s/it] 79%|███████▉  | 3483/4399 [7:55:33<2:09:29,  8.48s/it] 79%|███████▉  | 3484/4399 [7:55:40<2:01:14,  7.95s/it] 79%|███████▉  | 3485/4399 [7:55:48<2:03:44,  8.12s/it] 79%|███████▉  | 3486/4399 [7:55:58<2:09:09,  8.49s/it] 79%|███████▉  | 3487/4399 [7:56:06<2:06:51,  8.35s/it] 79%|███████▉  | 3488/4399 [7:56:14<2:07:40,  8.41s/it] 79%|███████▉  | 3489/4399 [7:56:23<2:07:24,  8.40s/it] 79%|███████▉  | 3490/4399 [7:56:31<2:07:36,  8
 0: {'loss': 0.5741, 'grad_norm': 1.4489011090121187, 'learning_rate': 1.2479494352486355e-06, 'epoch': 0.79}
 0: {'loss': 0.5691, 'grad_norm': 1.5323513308579686, 'learning_rate': 1.22184270429136e-06, 'epoch': 0.8}
 0: .42s/it]                                                        79%|███████▉  | 3490/4399 [7:56:31<2:07:36,  8.42s/it] 79%|███████▉  | 3491/4399 [7:56:39<2:04:42,  8.24s/it] 79%|███████▉  | 3492/4399 [7:56:46<1:59:46,  7.92s/it] 79%|███████▉  | 3493/4399 [7:56:54<2:00:04,  7.95s/it] 79%|███████▉  | 3494/4399 [7:57:03<2:05:40,  8.33s/it] 79%|███████▉  | 3495/4399 [7:57:11<2:03:29,  8.20s/it] 79%|███████▉  | 3496/4399 [7:57:20<2:06:33,  8.41s/it] 79%|███████▉  | 3497/4399 [7:57:29<2:07:16,  8.47s/it] 80%|███████▉  | 3498/4399 [7:57:36<2:00:59,  8.06s/it] 80%|███████▉  | 3499/4399 [7:57:44<2:00:27,  8.03s/it] 80%|███████▉  | 3500/4399 [7:57:50<1:51:46,  7.46s/it]                                                        80%|███████▉  | 3500/4399 [7:57:50<1:51:46,  7.46s/it][INFO|trainer.py:3984] 2025-06-28 05:0
 0: 2:16,296 >> Saving model checkpoint to /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500
 0: [INFO|configuration_utils.py:419] 2025-06-28 05:02:16,302 >> Configuration saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/config.json
 0: [INFO|configuration_utils.py:911] 2025-06-28 05:02:16,305 >> Configuration saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/generation_config.json
 0: [INFO|modeling_utils.py:3580] 2025-06-28 05:02:24,391 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 4 checkpoint shards. You can find where each parameters has been saved in the index located at /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/model.safetensors.index.json.
 0: [INFO|tokenization_utils_base.py:2510] 2025-06-28 05:02:24,395 >> tokenizer config file saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/tokenizer_config.json
 0: [INFO|tokenization_utils_base.py:2519] 2025-06-28 05:02:24,396 >> Special tokens file saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/special_tokens_map.json
 0: [2025-06-28 05:02:24,632] [INFO] [logging.py:107:log_dist] [Rank 0] [Torch] Checkpoint global_step3500 is about to be saved!
22: [2025-06-28 05:02:24,642] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_88_mp_rank_00_model_states.pt...
 0: [2025-06-28 05:02:24,642] [INFO] [logging.py:107:log_dist] [Rank 0] Saving model checkpoint: /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_0_mp_rank_00_model_states.pt
24: [2025-06-28 05:02:24,642] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_96_mp_rank_00_model_states.pt...
10: [2025-06-28 05:02:24,642] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_40_mp_rank_00_model_states.pt...
 4: [2025-06-28 05:02:24,642] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_16_mp_rank_00_model_states.pt...
 3: [2025-06-28 05:02:24,642] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_12_mp_rank_00_model_states.pt...
 2: [2025-06-28 05:02:24,642] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_8_mp_rank_00_model_states.pt...
15: [2025-06-28 05:02:24,642] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_60_mp_rank_00_model_states.pt...
 5: [2025-06-28 05:02:24,642] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_20_mp_rank_00_model_states.pt...
 0: [2025-06-28 05:02:24,643] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_0_mp_rank_00_model_states.pt...
18: [2025-06-28 05:02:24,643] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_72_mp_rank_00_model_states.pt...
23: [2025-06-28 05:02:24,643] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_92_mp_rank_00_model_states.pt...
19: [2025-06-28 05:02:24,643] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_76_mp_rank_00_model_states.pt...
20: [2025-06-28 05:02:24,643] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_80_mp_rank_00_model_states.pt...
30: [2025-06-28 05:02:24,643] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_120_mp_rank_00_model_states.pt...
31: [2025-06-28 05:02:24,643] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_124_mp_rank_00_model_states.pt...
 9: [2025-06-28 05:02:24,643] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_36_mp_rank_00_model_states.pt...
26: [2025-06-28 05:02:24,643] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_104_mp_rank_00_model_states.pt...
25: [2025-06-28 05:02:24,643] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_100_mp_rank_00_model_states.pt...
12: [2025-06-28 05:02:24,643] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_48_mp_rank_00_model_states.pt...
28: [2025-06-28 05:02:24,643] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_112_mp_rank_00_model_states.pt...
 6: [2025-06-28 05:02:24,643] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_24_mp_rank_00_model_states.pt...
14: [2025-06-28 05:02:24,643] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_56_mp_rank_00_model_states.pt...
27: [2025-06-28 05:02:24,643] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_108_mp_rank_00_model_states.pt...
29: [2025-06-28 05:02:24,643] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_116_mp_rank_00_model_states.pt...
 8: [2025-06-28 05:02:24,643] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_32_mp_rank_00_model_states.pt...
 7: [2025-06-28 05:02:24,644] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_28_mp_rank_00_model_states.pt...
 1: [2025-06-28 05:02:24,645] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_4_mp_rank_00_model_states.pt...
17: [2025-06-28 05:02:24,645] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_68_mp_rank_00_model_states.pt...
11: [2025-06-28 05:02:24,645] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_44_mp_rank_00_model_states.pt...
16: [2025-06-28 05:02:24,645] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_64_mp_rank_00_model_states.pt...
21: [2025-06-28 05:02:24,645] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_84_mp_rank_00_model_states.pt...
13: [2025-06-28 05:02:24,646] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_52_mp_rank_00_model_states.pt...
22: [2025-06-28 05:02:24,668] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_88_mp_rank_00_model_states.pt.
24: [2025-06-28 05:02:24,669] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_96_mp_rank_00_model_states.pt.
18: [2025-06-28 05:02:24,671] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_72_mp_rank_00_model_states.pt.
30: [2025-06-28 05:02:24,674] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_120_mp_rank_00_model_states.pt.
28: [2025-06-28 05:02:24,674] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_112_mp_rank_00_model_states.pt.
26: [2025-06-28 05:02:24,676] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_104_mp_rank_00_model_states.pt.
14: [2025-06-28 05:02:24,677] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_56_mp_rank_00_model_states.pt.
 0: [2025-06-28 05:02:24,679] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_0_mp_rank_00_model_states.pt.
 6: [2025-06-28 05:02:24,679] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_24_mp_rank_00_model_states.pt.
10: [2025-06-28 05:02:24,679] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_40_mp_rank_00_model_states.pt.
 2: [2025-06-28 05:02:24,680] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_8_mp_rank_00_model_states.pt.
 5: [2025-06-28 05:02:24,681] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_20_mp_rank_00_model_states.pt.
27: [2025-06-28 05:02:24,681] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_108_mp_rank_00_model_states.pt.
 3: [2025-06-28 05:02:24,684] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_12_mp_rank_00_model_states.pt.
 9: [2025-06-28 05:02:24,684] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_36_mp_rank_00_model_states.pt.
31: [2025-06-28 05:02:24,685] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_124_mp_rank_00_model_states.pt.
15: [2025-06-28 05:02:24,686] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_60_mp_rank_00_model_states.pt.
20: [2025-06-28 05:02:24,687] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_80_mp_rank_00_model_states.pt.
23: [2025-06-28 05:02:24,687] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_92_mp_rank_00_model_states.pt.
19: [2025-06-28 05:02:24,688] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_76_mp_rank_00_model_states.pt.
25: [2025-06-28 05:02:24,690] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_100_mp_rank_00_model_states.pt.
12: [2025-06-28 05:02:24,691] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_48_mp_rank_00_model_states.pt.
 4: [2025-06-28 05:02:24,691] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_16_mp_rank_00_model_states.pt.
 7: [2025-06-28 05:02:24,692] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_28_mp_rank_00_model_states.pt.
 1: [2025-06-28 05:02:24,694] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_4_mp_rank_00_model_states.pt.
 8: [2025-06-28 05:02:24,695] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_32_mp_rank_00_model_states.pt.
29: [2025-06-28 05:02:24,695] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_116_mp_rank_00_model_states.pt.
17: [2025-06-28 05:02:24,696] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_68_mp_rank_00_model_states.pt.
21: [2025-06-28 05:02:24,697] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_84_mp_rank_00_model_states.pt.
11: [2025-06-28 05:02:24,697] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_44_mp_rank_00_model_states.pt.
13: [2025-06-28 05:02:24,698] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_52_mp_rank_00_model_states.pt.
16: [2025-06-28 05:02:24,698] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/zero_pp_rank_64_mp_rank_00_model_states.pt.
 0: [2025-06-28 05:02:24,742] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
 4: [2025-06-28 05:02:24,742] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_16_mp_rank_00_optim_states.pt...
 9: [2025-06-28 05:02:24,742] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_36_mp_rank_00_optim_states.pt...
20: [2025-06-28 05:02:24,742] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_80_mp_rank_00_optim_states.pt...
26: [2025-06-28 05:02:24,741] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_104_mp_rank_00_optim_states.pt...
 7: [2025-06-28 05:02:24,742] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_28_mp_rank_00_optim_states.pt...
18: [2025-06-28 05:02:24,742] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_72_mp_rank_00_optim_states.pt...
27: [2025-06-28 05:02:24,742] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_108_mp_rank_00_optim_states.pt...
15: [2025-06-28 05:02:24,742] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_60_mp_rank_00_optim_states.pt...
25: [2025-06-28 05:02:24,742] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_100_mp_rank_00_optim_states.pt...
 1: [2025-06-28 05:02:24,742] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_4_mp_rank_00_optim_states.pt...
23: [2025-06-28 05:02:24,742] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_92_mp_rank_00_optim_states.pt...
28: [2025-06-28 05:02:24,742] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_112_mp_rank_00_optim_states.pt...
13: [2025-06-28 05:02:24,742] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_52_mp_rank_00_optim_states.pt...
19: [2025-06-28 05:02:24,742] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_76_mp_rank_00_optim_states.pt...
 6: [2025-06-28 05:02:24,742] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_24_mp_rank_00_optim_states.pt...
22: [2025-06-28 05:02:24,742] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_88_mp_rank_00_optim_states.pt...
31: [2025-06-28 05:02:24,742] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_124_mp_rank_00_optim_states.pt...
10: [2025-06-28 05:02:24,742] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_40_mp_rank_00_optim_states.pt...
 2: [2025-06-28 05:02:24,742] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_8_mp_rank_00_optim_states.pt...
16: [2025-06-28 05:02:24,742] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_64_mp_rank_00_optim_states.pt...
 8: [2025-06-28 05:02:24,742] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_32_mp_rank_00_optim_states.pt...
 5: [2025-06-28 05:02:24,742] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_20_mp_rank_00_optim_states.pt...
14: [2025-06-28 05:02:24,742] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_56_mp_rank_00_optim_states.pt...
11: [2025-06-28 05:02:24,742] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_44_mp_rank_00_optim_states.pt...
12: [2025-06-28 05:02:24,742] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_48_mp_rank_00_optim_states.pt...
 3: [2025-06-28 05:02:24,742] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_12_mp_rank_00_optim_states.pt...
21: [2025-06-28 05:02:24,742] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_84_mp_rank_00_optim_states.pt...
30: [2025-06-28 05:02:24,742] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_120_mp_rank_00_optim_states.pt...
17: [2025-06-28 05:02:24,742] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_68_mp_rank_00_optim_states.pt...
29: [2025-06-28 05:02:24,742] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_116_mp_rank_00_optim_states.pt...
24: [2025-06-28 05:02:24,742] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_96_mp_rank_00_optim_states.pt...
 0: [2025-06-28 05:02:25,226] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
 0: [2025-06-28 05:02:25,235] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
15: [2025-06-28 05:02:27,502] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_60_mp_rank_00_optim_states.pt.
15: [2025-06-28 05:02:27,503] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_60_mp_rank_00_optim_states.pt
 1: [2025-06-28 05:02:27,504] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_4_mp_rank_00_optim_states.pt.
 1: [2025-06-28 05:02:27,504] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_4_mp_rank_00_optim_states.pt
17: [2025-06-28 05:02:27,514] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_68_mp_rank_00_optim_states.pt.
17: [2025-06-28 05:02:27,514] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_68_mp_rank_00_optim_states.pt
16: [2025-06-28 05:02:27,546] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_64_mp_rank_00_optim_states.pt.
16: [2025-06-28 05:02:27,546] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_64_mp_rank_00_optim_states.pt
11: [2025-06-28 05:02:27,547] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_44_mp_rank_00_optim_states.pt.
11: [2025-06-28 05:02:27,547] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_44_mp_rank_00_optim_states.pt
22: [2025-06-28 05:02:27,548] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_88_mp_rank_00_optim_states.pt.
22: [2025-06-28 05:02:27,548] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_88_mp_rank_00_optim_states.pt
28: [2025-06-28 05:02:27,549] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_112_mp_rank_00_optim_states.pt.
28: [2025-06-28 05:02:27,549] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_112_mp_rank_00_optim_states.pt
 7: [2025-06-28 05:02:27,551] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_28_mp_rank_00_optim_states.pt.
 7: [2025-06-28 05:02:27,552] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_28_mp_rank_00_optim_states.pt
19: [2025-06-28 05:02:27,554] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_76_mp_rank_00_optim_states.pt.
19: [2025-06-28 05:02:27,554] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_76_mp_rank_00_optim_states.pt
18: [2025-06-28 05:02:27,556] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_72_mp_rank_00_optim_states.pt.
18: [2025-06-28 05:02:27,556] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_72_mp_rank_00_optim_states.pt
31: [2025-06-28 05:02:27,557] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_124_mp_rank_00_optim_states.pt.
31: [2025-06-28 05:02:27,557] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_124_mp_rank_00_optim_states.pt
26: [2025-06-28 05:02:27,557] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_104_mp_rank_00_optim_states.pt.
26: [2025-06-28 05:02:27,558] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_104_mp_rank_00_optim_states.pt
 6: [2025-06-28 05:02:27,559] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_24_mp_rank_00_optim_states.pt.
 6: [2025-06-28 05:02:27,559] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_24_mp_rank_00_optim_states.pt
10: [2025-06-28 05:02:27,560] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_40_mp_rank_00_optim_states.pt.
10: [2025-06-28 05:02:27,560] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_40_mp_rank_00_optim_states.pt
20: [2025-06-28 05:02:27,571] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_80_mp_rank_00_optim_states.pt.
20: [2025-06-28 05:02:27,571] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_80_mp_rank_00_optim_states.pt
 3: [2025-06-28 05:02:27,573] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_12_mp_rank_00_optim_states.pt.
 3: [2025-06-28 05:02:27,573] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_12_mp_rank_00_optim_states.pt
 8: [2025-06-28 05:02:27,590] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_32_mp_rank_00_optim_states.pt.
 8: [2025-06-28 05:02:27,590] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_32_mp_rank_00_optim_states.pt
23: [2025-06-28 05:02:27,592] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_92_mp_rank_00_optim_states.pt.
23: [2025-06-28 05:02:27,593] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_92_mp_rank_00_optim_states.pt
 4: [2025-06-28 05:02:27,604] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_16_mp_rank_00_optim_states.pt.
 4: [2025-06-28 05:02:27,604] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_16_mp_rank_00_optim_states.pt
 5: [2025-06-28 05:02:27,606] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_20_mp_rank_00_optim_states.pt.
 5: [2025-06-28 05:02:27,606] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_20_mp_rank_00_optim_states.pt
12: [2025-06-28 05:02:27,604] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_48_mp_rank_00_optim_states.pt.
12: [2025-06-28 05:02:27,604] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_48_mp_rank_00_optim_states.pt
 9: [2025-06-28 05:02:27,615] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_36_mp_rank_00_optim_states.pt.
 9: [2025-06-28 05:02:27,615] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_36_mp_rank_00_optim_states.pt
 2: [2025-06-28 05:02:27,635] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_8_mp_rank_00_optim_states.pt.
 2: [2025-06-28 05:02:27,635] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_8_mp_rank_00_optim_states.pt
30: [2025-06-28 05:02:27,635] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_120_mp_rank_00_optim_states.pt.
30: [2025-06-28 05:02:27,635] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_120_mp_rank_00_optim_states.pt
27: [2025-06-28 05:02:27,646] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_108_mp_rank_00_optim_states.pt.
27: [2025-06-28 05:02:27,646] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_108_mp_rank_00_optim_states.pt
25: [2025-06-28 05:02:27,666] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_100_mp_rank_00_optim_states.pt.
25: [2025-06-28 05:02:27,666] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_100_mp_rank_00_optim_states.pt
21: [2025-06-28 05:02:27,686] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_84_mp_rank_00_optim_states.pt.
21: [2025-06-28 05:02:27,687] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_84_mp_rank_00_optim_states.pt
29: [2025-06-28 05:02:27,695] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_116_mp_rank_00_optim_states.pt.
29: [2025-06-28 05:02:27,695] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_116_mp_rank_00_optim_states.pt
14: [2025-06-28 05:02:27,733] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_56_mp_rank_00_optim_states.pt.
14: [2025-06-28 05:02:27,733] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_56_mp_rank_00_optim_states.pt
24: [2025-06-28 05:02:27,771] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_96_mp_rank_00_optim_states.pt.
24: [2025-06-28 05:02:27,771] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_96_mp_rank_00_optim_states.pt
13: [2025-06-28 05:02:37,195] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_52_mp_rank_00_optim_states.pt.
13: [2025-06-28 05:02:37,195] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/global_step3500/bf16_zero_pp_rank_52_mp_rank_00_optim_states.pt
24: [2025-06-28 05:02:37,296] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3500 is ready now!
25: [2025-06-28 05:02:37,297] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3500 is ready now!
15: [2025-06-28 05:02:37,297] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3500 is ready now!
 7: [2025-06-28 05:02:37,297] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3500 is ready now!
22: [2025-06-28 05:02:37,297] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3500 is ready now!
10: [2025-06-28 05:02:37,297] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3500 is ready now!
 8: [2025-06-28 05:02:37,297] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3500 is ready now!
18: [2025-06-28 05:02:37,297] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3500 is ready now!
13: [2025-06-28 05:02:37,297] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3500 is ready now!
 3: [2025-06-28 05:02:37,298] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3500 is ready now!
26: [2025-06-28 05:02:37,298] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3500 is ready now!
 2: [2025-06-28 05:02:37,298] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3500 is ready now!
23: [2025-06-28 05:02:37,298] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3500 is ready now!
 9: [2025-06-28 05:02:37,298] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3500 is ready now!
27: [2025-06-28 05:02:37,298] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3500 is ready now!
31: [2025-06-28 05:02:37,298] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3500 is ready now!
28: [2025-06-28 05:02:37,298] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3500 is ready now!
30: [2025-06-28 05:02:37,298] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3500 is ready now!
 6: [2025-06-28 05:02:37,298] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3500 is ready now!
19: [2025-06-28 05:02:37,298] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3500 is ready now!
12: [2025-06-28 05:02:37,298] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3500 is ready now!
29: [2025-06-28 05:02:37,298] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3500 is ready now!
14: [2025-06-28 05:02:37,298] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3500 is ready now!
 5: [2025-06-28 05:02:37,298] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3500 is ready now!
11: [2025-06-28 05:02:37,298] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3500 is ready now!
20: [2025-06-28 05:02:37,299] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3500 is ready now!
 4: [2025-06-28 05:02:37,299] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3500 is ready now!
 1: [2025-06-28 05:02:37,300] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3500 is ready now!
17: [2025-06-28 05:02:37,300] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3500 is ready now!
16: [2025-06-28 05:02:37,301] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3500 is ready now!
21: [2025-06-28 05:02:37,301] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3500 is ready now!
 0: [2025-06-28 05:02:37,301] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step3500 is ready now!
 0: [INFO|image_processing_base.py:260] 2025-06-28 05:02:37,351 >> Image processor saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/preprocessor_config.json
 0: [INFO|tokenization_utils_base.py:2510] 2025-06-28 05:02:37,353 >> tokenizer config file saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/tokenizer_config.json
 0: [INFO|tokenization_utils_base.py:2519] 2025-06-28 05:02:37,354 >> Special tokens file saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/special_tokens_map.json
 0: [INFO|processing_utils.py:648] 2025-06-28 05:02:37,954 >> chat template saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-3500/chat_template.json
 0:  80%|███████▉  | 3501/4399 [7:59:18<7:52:05, 31.54s/it]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
 0:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
 0: {'loss': 0.5768, 'grad_norm': 1.93580035212184, 'learning_rate': 1.1959738799381742e-06, 'epoch': 0.8}
 0:  80%|███████▉  | 3502/4399 [7:59:27<6:12:58, 24.95s/it] 80%|███████▉  | 3503/4399 [7:59:37<5:06:17, 20.51s/it] 80%|███████▉  | 3504/4399 [7:59:45<4:10:35, 16.80s/it] 80%|███████▉  | 3505/4399 [7:59:54<3:32:24, 14.26s/it] 80%|███████▉  | 3506/4399 [8:00:02<3:03:59, 12.36s/it] 80%|███████▉  | 3507/4399 [8:00:09<2:43:27, 11.00s/it] 80%|███████▉  | 3508/4399 [8:00:16<2:25:26,  9.79s/it] 80%|███████▉  | 3509/4399 [8:00:26<2:22:55,  9.64s/it] 80%|███████▉  | 3510/4399 [8:00:35<2:20:47,  9.50s/it]                                                        80%|███████▉  | 3510/4399 [8:00:35<2:20:47,  9.50s/it] 80%|███████▉  | 3511/4399 [8:00:44<2:18:18,  9.35s/it] 80%|███████▉  | 3512/4399 [8:00:52<2:13:54,  9.06s/it] 80%|███████▉  | 3513/4399 [8:01:01<2:12:52,  9.00s/it] 80%|███████▉ 
 0: {'loss': 0.5603, 'grad_norm': 1.386950043312628, 'learning_rate': 1.170344591121826e-06, 'epoch': 0.8}
 0:  | 3514/4399 [8:01:09<2:08:04,  8.68s/it] 80%|███████▉  | 3515/4399 [8:01:17<2:02:18,  8.30s/it] 80%|███████▉  | 3516/4399 [8:01:23<1:52:52,  7.67s/it] 80%|███████▉  | 3517/4399 [8:01:32<1:59:55,  8.16s/it] 80%|███████▉  | 3518/4399 [8:01:41<2:04:50,  8.50s/it] 80%|███████▉  | 3519/4399 [8:01:50<2:07:10,  8.67s/it] 80%|████████  | 3520/4399 [8:02:00<2:09:20,  8.83s/it]                                                        80%|████████  | 3520/4399 [8:02:00<2:09:20,  8.83s/it] 80%|████████  | 3521/4399 [8:02:09<2:12:34,  9.06s/it] 80%|████████  | 3522/4399 [8:02:18<2:09:58,  8.89s/it] 80%|████████  | 3523/4399 [8:02:25<2:02:24,  8.38s/it] 80%|████████  | 3524/4399 [8:02:32<1:55:33,  7.92s/it] 80%|████████  | 3525/4399 [8:02:40<1:58:23,  8.13s/it] 80%|████████  | 3526/4399 [8:02:49<2:02:32, 
 0: {'loss': 0.5715, 'grad_norm': 1.571781605431445, 'learning_rate': 1.1449564516917643e-06, 'epoch': 0.8}
 0:  8.42s/it] 80%|████████  | 3527/4399 [8:02:58<2:01:11,  8.34s/it] 80%|████████  | 3528/4399 [8:03:06<2:02:16,  8.42s/it] 80%|████████  | 3529/4399 [8:03:15<2:03:57,  8.55s/it] 80%|████████  | 3530/4399 [8:03:23<1:59:53,  8.28s/it]                                                        80%|████████  | 3530/4399 [8:03:23<1:59:53,  8.28s/it] 80%|████████  | 3531/4399 [8:03:30<1:54:57,  7.95s/it] 80%|████████  | 3532/4399 [8:03:37<1:49:44,  7.59s/it] 80%|████████  | 3533/4399 [8:03:46<1:56:45,  8.09s/it] 80%|████████  | 3534/4399 [8:03:54<1:56:42,  8.10s/it] 80%|████████  | 3535/4399 [8:04:03<2:02:01,  8.47s/it] 80%|████████  | 3536/4399 [8:04:12<2:03:55,  8.62s/it] 80%|████████  | 3537/4399 [8:04:21<2:03:59,  8.63s/it] 80%|████████  | 3538/4399 [8:04:29<2:01:36,  8.47s/it] 80%|█████
 0: {'loss': 0.5786, 'grad_norm': 1.4300369660093386, 'learning_rate': 1.119811060312514e-06, 'epoch': 0.8}
 0: ███  | 3539/4399 [8:04:36<1:55:23,  8.05s/it] 80%|████████  | 3540/4399 [8:04:42<1:47:48,  7.53s/it]                                                        80%|████████  | 3540/4399 [8:04:42<1:47:48,  7.53s/it] 80%|████████  | 3541/4399 [8:04:52<1:57:55,  8.25s/it] 81%|████████  | 3542/4399 [8:05:01<1:58:43,  8.31s/it] 81%|████████  | 3543/4399 [8:05:10<2:04:08,  8.70s/it] 81%|████████  | 3544/4399 [8:05:19<2:05:12,  8.79s/it] 81%|████████  | 3545/4399 [8:05:28<2:05:32,  8.82s/it] 81%|████████  | 3546/4399 [8:05:36<2:00:21,  8.47s/it] 81%|████████  | 3547/4399 [8:05:43<1:53:47,  8.01s/it] 81%|████████  | 3548/4399 [8:05:51<1:52:14,  7.91s/it] 81%|████████  | 3549/4399 [8:06:00<1:59:11,  8.41s/it] 81%|████████  | 3550/4399 [8:06:10<2:03:23,  8.72s/it]                                                   
 0: {'loss': 0.5773, 'grad_norm': 1.5093070111130389, 'learning_rate': 1.0949100003630103e-06, 'epoch': 0.81}
 0: {'loss': 0.5697, 'grad_norm': 1.3359084766895695, 'learning_rate': 1.0702548398368911e-06, 'epoch': 0.81}
 0:      81%|████████  | 3550/4399 [8:06:10<2:03:23,  8.72s/it] 81%|████████  | 3551/4399 [8:06:18<2:02:01,  8.63s/it] 81%|████████  | 3552/4399 [8:06:26<2:00:20,  8.52s/it] 81%|████████  | 3553/4399 [8:06:35<2:00:47,  8.57s/it] 81%|████████  | 3554/4399 [8:06:42<1:53:06,  8.03s/it] 81%|████████  | 3555/4399 [8:06:49<1:50:50,  7.88s/it] 81%|████████  | 3556/4399 [8:06:56<1:45:07,  7.48s/it] 81%|████████  | 3557/4399 [8:07:05<1:50:26,  7.87s/it] 81%|████████  | 3558/4399 [8:07:13<1:51:55,  7.99s/it] 81%|████████  | 3559/4399 [8:07:22<1:55:38,  8.26s/it] 81%|████████  | 3560/4399 [8:07:31<1:59:04,  8.52s/it]                                                        81%|████████  | 3560/4399 [8:07:31<1:59:04,  8.52s/it] 81%|████████  | 3561/4399 [8:07:39<1:57:01,  8.38s/it] 81%|██████
 0: {'loss': 0.5656, 'grad_norm': 1.7624068769000667, 'learning_rate': 1.045847131243768e-06, 'epoch': 0.81}
 0: █  | 3562/4399 [8:07:47<1:57:28,  8.42s/it] 81%|████████  | 3563/4399 [8:07:55<1:54:53,  8.25s/it] 81%|████████  | 3564/4399 [8:08:03<1:52:11,  8.06s/it] 81%|████████  | 3565/4399 [8:08:12<1:54:24,  8.23s/it] 81%|████████  | 3566/4399 [8:08:20<1:54:27,  8.24s/it] 81%|████████  | 3567/4399 [8:08:30<2:03:34,  8.91s/it] 81%|████████  | 3568/4399 [8:08:39<2:03:32,  8.92s/it] 81%|████████  | 3569/4399 [8:08:48<2:04:18,  8.99s/it] 81%|████████  | 3570/4399 [8:08:56<1:58:08,  8.55s/it]                                                        81%|████████  | 3570/4399 [8:08:56<1:58:08,  8.55s/it] 81%|████████  | 3571/4399 [8:09:05<1:59:33,  8.66s/it] 81%|████████  | 3572/4399 [8:09:12<1:53:18,  8.22s/it] 81%|████████  | 3573/4399 [8:09:22<1:59:39,  8.69s/it] 81%|████████  | 3574/4399 [8:09:31<1:59
 0: {'loss': 0.5757, 'grad_norm': 1.5648212111033295, 'learning_rate': 1.021688411511465e-06, 'epoch': 0.81}
 0: :34,  8.70s/it] 81%|████████▏ | 3575/4399 [8:09:40<2:03:13,  8.97s/it] 81%|████████▏ | 3576/4399 [8:09:50<2:05:17,  9.13s/it] 81%|████████▏ | 3577/4399 [8:09:58<2:02:53,  8.97s/it] 81%|████████▏ | 3578/4399 [8:10:06<1:56:29,  8.51s/it] 81%|████████▏ | 3579/4399 [8:10:14<1:55:28,  8.45s/it] 81%|████████▏ | 3580/4399 [8:10:21<1:49:08,  8.00s/it]                                                        81%|████████▏ | 3580/4399 [8:10:21<1:49:08,  8.00s/it] 81%|████████▏ | 3581/4399 [8:10:30<1:51:33,  8.18s/it] 81%|████████▏ | 3582/4399 [8:10:38<1:53:23,  8.33s/it] 81%|████████▏ | 3583/4399 [8:10:47<1:53:20,  8.33s/it] 81%|████████▏ | 3584/4399 [8:10:56<1:59:05,  8.77s/it] 81%|████████▏ | 3585/4399 [8:11:05<1:58:08,  8.71s/it] 82%|████████▏ | 3586/4399 [8:11:12<1:52:06, 
 0: {'loss': 0.5672, 'grad_norm': 1.6122149372166414, 'learning_rate': 9.977802018892345e-07, 'epoch': 0.82}
 0:  8.27s/it] 82%|████████▏ | 3587/4399 [8:11:20<1:48:50,  8.04s/it] 82%|████████▏ | 3588/4399 [8:11:27<1:45:23,  7.80s/it] 82%|████████▏ | 3589/4399 [8:11:35<1:46:55,  7.92s/it] 82%|████████▏ | 3590/4399 [8:11:45<1:54:39,  8.50s/it]                                                        82%|████████▏ | 3590/4399 [8:11:45<1:54:39,  8.50s/it] 82%|████████▏ | 3591/4399 [8:11:55<1:59:26,  8.87s/it] 82%|████████▏ | 3592/4399 [8:12:03<1:57:26,  8.73s/it] 82%|████████▏ | 3593/4399 [8:12:11<1:54:38,  8.53s/it] 82%|████████▏ | 3594/4399 [8:12:19<1:52:38,  8.40s/it] 82%|████████▏ | 3595/4399 [8:12:27<1:50:17,  8.23s/it] 82%|████████▏ | 3596/4399 [8:12:34<1:45:36,  7.89s/it] 82%|████████▏ | 3597/4399 [8:12:43<1:49:15,  8.17s/it] 82%|████████▏ | 3598/4399 [8:12:52<1:51:40,  8.36
 0: {'loss': 0.5775, 'grad_norm': 1.6856655833839722, 'learning_rate': 9.741240078519738e-07, 'epoch': 0.82}
 0: s/it] 82%|████████▏ | 3599/4399 [8:13:00<1:52:03,  8.40s/it] 82%|████████▏ | 3600/4399 [8:13:10<1:55:03,  8.64s/it]                                                        82%|████████▏ | 3600/4399 [8:13:10<1:55:03,  8.64s/it] 82%|████████▏ | 3601/4399 [8:13:18<1:54:59,  8.65s/it] 82%|████████▏ | 3602/4399 [8:13:27<1:53:49,  8.57s/it] 82%|████████▏ | 3603/4399 [8:13:36<1:56:37,  8.79s/it] 82%|████████▏ | 3604/4399 [8:13:43<1:49:20,  8.25s/it] 82%|████████▏ | 3605/4399 [8:13:50<1:46:41,  8.06s/it] 82%|████████▏ | 3606/4399 [8:14:00<1:52:36,  8.52s/it] 82%|████████▏ | 3607/4399 [8:14:10<1:57:32,  8.90s/it] 82%|████████▏ | 3608/4399 [8:14:19<1:56:23,  8.83s/it] 82%|████████▏ | 3609/4399 [8:14:27<1:56:40,  8.86s/it] 82%|████████▏ | 3610/4399 [8:14:35<1:51:55,  8.51s/it]
 0: {'loss': 0.5688, 'grad_norm': 1.5038331836008028, 'learning_rate': 9.50721319005421e-07, 'epoch': 0.82}
 0: {'loss': 0.5601, 'grad_norm': 1.777430299544198, 'learning_rate': 9.275736089923599e-07, 'epoch': 0.82}
 0:                                                         82%|████████▏ | 3610/4399 [8:14:35<1:51:55,  8.51s/it] 82%|████████▏ | 3611/4399 [8:14:43<1:50:23,  8.41s/it] 82%|████████▏ | 3612/4399 [8:14:50<1:43:04,  7.86s/it] 82%|████████▏ | 3613/4399 [8:14:58<1:42:37,  7.83s/it] 82%|████████▏ | 3614/4399 [8:15:06<1:43:59,  7.95s/it] 82%|████████▏ | 3615/4399 [8:15:15<1:47:06,  8.20s/it] 82%|████████▏ | 3616/4399 [8:15:23<1:48:56,  8.35s/it] 82%|████████▏ | 3617/4399 [8:15:31<1:44:24,  8.01s/it] 82%|████████▏ | 3618/4399 [8:15:38<1:43:26,  7.95s/it] 82%|████████▏ | 3619/4399 [8:15:46<1:43:53,  7.99s/it] 82%|████████▏ | 3620/4399 [8:15:53<1:38:28,  7.58s/it]                                                        82%|████████▏ | 3620/4399 [8:15:53<1:38:28,  7.58s/it] 82%|█████
 0: {'loss': 0.5802, 'grad_norm': 1.469685197242696, 'learning_rate': 9.046823353998208e-07, 'epoch': 0.83}
 0: ██▏ | 3621/4399 [8:16:01<1:40:22,  7.74s/it] 82%|████████▏ | 3622/4399 [8:16:10<1:43:02,  7.96s/it] 82%|████████▏ | 3623/4399 [8:16:20<1:51:16,  8.60s/it] 82%|████████▏ | 3624/4399 [8:16:31<1:59:16,  9.23s/it] 82%|████████▏ | 3625/4399 [8:16:38<1:54:12,  8.85s/it] 82%|████████▏ | 3626/4399 [8:16:46<1:47:29,  8.34s/it] 82%|████████▏ | 3627/4399 [8:16:54<1:49:16,  8.49s/it] 82%|████████▏ | 3628/4399 [8:17:02<1:47:01,  8.33s/it] 82%|████████▏ | 3629/4399 [8:17:10<1:44:53,  8.17s/it] 83%|████████▎ | 3630/4399 [8:17:19<1:46:05,  8.28s/it]                                                        83%|████████▎ | 3630/4399 [8:17:19<1:46:05,  8.28s/it] 83%|████████▎ | 3631/4399 [8:17:28<1:50:00,  8.59s/it] 83%|████████▎ | 3632/4399 [8:17:38<1:54:20,  8.94s/it] 83%|███████
 0: {'loss': 0.568, 'grad_norm': 4.509368687983115, 'learning_rate': 8.820489396673049e-07, 'epoch': 0.83}
 0: █▎ | 3633/4399 [8:17:48<1:57:01,  9.17s/it] 83%|████████▎ | 3634/4399 [8:17:56<1:55:25,  9.05s/it] 83%|████████▎ | 3635/4399 [8:18:06<1:57:25,  9.22s/it] 83%|████████▎ | 3636/4399 [8:18:13<1:50:48,  8.71s/it] 83%|████████▎ | 3637/4399 [8:18:20<1:44:10,  8.20s/it] 83%|████████▎ | 3638/4399 [8:18:29<1:44:11,  8.22s/it] 83%|████████▎ | 3639/4399 [8:18:39<1:50:13,  8.70s/it] 83%|████████▎ | 3640/4399 [8:18:47<1:50:10,  8.71s/it]                                                        83%|████████▎ | 3640/4399 [8:18:47<1:50:10,  8.71s/it] 83%|████████▎ | 3641/4399 [8:18:56<1:48:56,  8.62s/it] 83%|████████▎ | 3642/4399 [8:19:04<1:46:23,  8.43s/it] 83%|████████▎ | 3643/4399 [8:19:12<1:44:00,  8.25s/it] 83%|████████▎ | 3644/4399 [8:19:18<1:38:26,  7.82s/it] 83%|████████
 0: {'loss': 0.5672, 'grad_norm': 1.789014955620608, 'learning_rate': 8.596748469960142e-07, 'epoch': 0.83}
 0:  | 3645/4399 [8:19:26<1:38:43,  7.86s/it] 83%|████████▎ | 3646/4399 [8:19:35<1:41:40,  8.10s/it] 83%|████████▎ | 3647/4399 [8:19:45<1:48:19,  8.64s/it] 83%|████████▎ | 3648/4399 [8:19:55<1:53:28,  9.07s/it] 83%|████████▎ | 3649/4399 [8:20:04<1:54:56,  9.20s/it] 83%|████████▎ | 3650/4399 [8:20:12<1:50:10,  8.83s/it]                                                        83%|████████▎ | 3650/4399 [8:20:12<1:50:10,  8.83s/it] 83%|████████▎ | 3651/4399 [8:20:20<1:45:28,  8.46s/it] 83%|████████▎ | 3652/4399 [8:20:27<1:40:57,  8.11s/it] 83%|████████▎ | 3653/4399 [8:20:34<1:36:47,  7.79s/it] 83%|████████▎ | 3654/4399 [8:20:43<1:39:07,  7.98s/it] 83%|████████▎ | 3655/4399 [8:20:51<1:41:44,  8.20s/it] 83%|████████▎ | 3656/4399 [8:21:02<1:49:02,  8.81s/it] 83%|████████▎ | 3
 0: {'loss': 0.5711, 'grad_norm': 1.7248924198894375, 'learning_rate': 8.375614662591097e-07, 'epoch': 0.83}
 0: 657/4399 [8:21:10<1:46:41,  8.63s/it] 83%|████████▎ | 3658/4399 [8:21:17<1:42:40,  8.31s/it] 83%|████████▎ | 3659/4399 [8:21:25<1:40:11,  8.12s/it] 83%|████████▎ | 3660/4399 [8:21:33<1:37:29,  7.91s/it]                                                        83%|████████▎ | 3660/4399 [8:21:33<1:37:29,  7.91s/it] 83%|████████▎ | 3661/4399 [8:21:40<1:36:34,  7.85s/it] 83%|████████▎ | 3662/4399 [8:21:49<1:39:21,  8.09s/it] 83%|████████▎ | 3663/4399 [8:21:58<1:44:00,  8.48s/it] 83%|████████▎ | 3664/4399 [8:22:07<1:45:34,  8.62s/it] 83%|████████▎ | 3665/4399 [8:22:16<1:44:17,  8.53s/it] 83%|████████▎ | 3666/4399 [8:22:23<1:40:38,  8.24s/it] 83%|████████▎ | 3667/4399 [8:22:30<1:36:26,  7.90s/it] 83%|████████▎ | 3668/4399 [8:22:39<1:39:43,  8.18s/it] 83%|████████▎ | 3669/4
 0: {'loss': 0.5697, 'grad_norm': 1.3566789594581548, 'learning_rate': 8.157101899129904e-07, 'epoch': 0.83}
 0: 399 [8:22:46<1:36:03,  7.90s/it] 83%|████████▎ | 3670/4399 [8:22:55<1:40:23,  8.26s/it]                                                        83%|████████▎ | 3670/4399 [8:22:55<1:40:23,  8.26s/it] 83%|████████▎ | 3671/4399 [8:23:05<1:43:26,  8.53s/it] 83%|████████▎ | 3672/4399 [8:23:15<1:49:27,  9.03s/it] 83%|████████▎ | 3673/4399 [8:23:23<1:47:02,  8.85s/it] 84%|████████▎ | 3674/4399 [8:23:31<1:42:37,  8.49s/it] 84%|████████▎ | 3675/4399 [8:23:39<1:40:20,  8.32s/it] 84%|████████▎ | 3676/4399 [8:23:46<1:37:25,  8.09s/it] 84%|████████▎ | 3677/4399 [8:23:55<1:38:35,  8.19s/it] 84%|████████▎ | 3678/4399 [8:24:03<1:38:36,  8.21s/it] 84%|████████▎ | 3679/4399 [8:24:13<1:44:21,  8.70s/it] 84%|████████▎ | 3680/4399 [8:24:22<1:44:06,  8.69s/it]                                              
 0: {'loss': 0.5717, 'grad_norm': 1.9455472512170395, 'learning_rate': 7.941223939096226e-07, 'epoch': 0.84}
 0: {'loss': 0.5806, 'grad_norm': 2.6506877795258648, 'learning_rate': 7.727994376098885e-07, 'epoch': 0.84}
 0:           84%|████████▎ | 3680/4399 [8:24:22<1:44:06,  8.69s/it] 84%|████████▎ | 3681/4399 [8:24:30<1:42:25,  8.56s/it] 84%|████████▎ | 3682/4399 [8:24:37<1:37:25,  8.15s/it] 84%|████████▎ | 3683/4399 [8:24:45<1:35:31,  8.01s/it] 84%|████████▎ | 3684/4399 [8:24:52<1:33:57,  7.88s/it] 84%|████████▍ | 3685/4399 [8:24:59<1:31:27,  7.69s/it] 84%|████████▍ | 3686/4399 [8:25:09<1:36:34,  8.13s/it] 84%|████████▍ | 3687/4399 [8:25:18<1:40:33,  8.47s/it] 84%|████████▍ | 3688/4399 [8:25:26<1:40:42,  8.50s/it] 84%|████████▍ | 3689/4399 [8:25:35<1:40:42,  8.51s/it] 84%|████████▍ | 3690/4399 [8:25:43<1:37:13,  8.23s/it]                                                        84%|████████▍ | 3690/4399 [8:25:43<1:37:13,  8.23s/it] 84%|████████▍ | 3691/4399 [8:25:51<1:38:17,  8.33
 0: {'loss': 0.5844, 'grad_norm': 1.8180406888220284, 'learning_rate': 7.517426636979936e-07, 'epoch': 0.84}
 0: s/it] 84%|████████▍ | 3692/4399 [8:25:59<1:36:00,  8.15s/it] 84%|████████▍ | 3693/4399 [8:26:06<1:33:16,  7.93s/it] 84%|████████▍ | 3694/4399 [8:26:15<1:34:40,  8.06s/it] 84%|████████▍ | 3695/4399 [8:26:24<1:38:09,  8.37s/it] 84%|████████▍ | 3696/4399 [8:26:33<1:40:23,  8.57s/it] 84%|████████▍ | 3697/4399 [8:26:41<1:40:29,  8.59s/it] 84%|████████▍ | 3698/4399 [8:26:49<1:36:44,  8.28s/it] 84%|████████▍ | 3699/4399 [8:26:57<1:36:28,  8.27s/it] 84%|████████▍ | 3700/4399 [8:27:05<1:34:11,  8.08s/it]                                                        84%|████████▍ | 3700/4399 [8:27:05<1:34:11,  8.08s/it] 84%|████████▍ | 3701/4399 [8:27:13<1:33:25,  8.03s/it] 84%|████████▍ | 3702/4399 [8:27:21<1:34:26,  8.13s/it] 84%|████████▍ | 3703/4399 [8:27:31<1:40:15,  8.64s/it]
 0: {'loss': 0.5813, 'grad_norm': 1.5008321403331513, 'learning_rate': 7.309533980969141e-07, 'epoch': 0.84}
 0:  84%|████████▍ | 3704/4399 [8:27:39<1:39:23,  8.58s/it] 84%|████████▍ | 3705/4399 [8:27:50<1:45:22,  9.11s/it] 84%|████████▍ | 3706/4399 [8:27:57<1:39:34,  8.62s/it] 84%|████████▍ | 3707/4399 [8:28:06<1:38:22,  8.53s/it] 84%|████████▍ | 3708/4399 [8:28:14<1:39:01,  8.60s/it] 84%|████████▍ | 3709/4399 [8:28:22<1:34:57,  8.26s/it] 84%|████████▍ | 3710/4399 [8:28:32<1:39:59,  8.71s/it]                                                        84%|████████▍ | 3710/4399 [8:28:32<1:39:59,  8.71s/it] 84%|████████▍ | 3711/4399 [8:28:41<1:42:06,  8.90s/it] 84%|████████▍ | 3712/4399 [8:28:51<1:45:25,  9.21s/it] 84%|████████▍ | 3713/4399 [8:28:59<1:41:46,  8.90s/it] 84%|████████▍ | 3714/4399 [8:29:07<1:37:07,  8.51s/it] 84%|████████▍ | 3715/4399 [8:29:15<1:37:07,  8.52s/it] 84%
 0: {'loss': 0.5651, 'grad_norm': 1.4785352085456813, 'learning_rate': 7.104329498849128e-07, 'epoch': 0.85}
 0: |████████▍ | 3716/4399 [8:29:22<1:32:42,  8.14s/it] 84%|████████▍ | 3717/4399 [8:29:31<1:32:30,  8.14s/it] 85%|████████▍ | 3718/4399 [8:29:39<1:32:47,  8.18s/it] 85%|████████▍ | 3719/4399 [8:29:48<1:37:22,  8.59s/it] 85%|████████▍ | 3720/4399 [8:29:58<1:40:43,  8.90s/it]                                                        85%|████████▍ | 3720/4399 [8:29:58<1:40:43,  8.90s/it] 85%|████████▍ | 3721/4399 [8:30:07<1:39:50,  8.84s/it] 85%|████████▍ | 3722/4399 [8:30:14<1:33:43,  8.31s/it] 85%|████████▍ | 3723/4399 [8:30:22<1:34:52,  8.42s/it] 85%|████████▍ | 3724/4399 [8:30:30<1:32:27,  8.22s/it] 85%|████████▍ | 3725/4399 [8:30:37<1:27:20,  7.78s/it] 85%|████████▍ | 3726/4399 [8:30:45<1:28:28,  7.89s/it] 85%|████████▍ | 3727/4399 [8:30:55<1:35:32,  8.53s/it] 85%|█
 0: {'loss': 0.5715, 'grad_norm': 1.7982080013930888, 'learning_rate': 6.901826112130977e-07, 'epoch': 0.85}
 0: ██████▍ | 3728/4399 [8:31:04<1:37:10,  8.69s/it] 85%|████████▍ | 3729/4399 [8:31:13<1:38:38,  8.83s/it] 85%|████████▍ | 3730/4399 [8:31:21<1:34:54,  8.51s/it]                                                        85%|████████▍ | 3730/4399 [8:31:21<1:34:54,  8.51s/it] 85%|████████▍ | 3731/4399 [8:31:29<1:33:00,  8.35s/it] 85%|████████▍ | 3732/4399 [8:31:37<1:32:33,  8.33s/it] 85%|████████▍ | 3733/4399 [8:31:45<1:29:04,  8.03s/it] 85%|████████▍ | 3734/4399 [8:31:52<1:26:48,  7.83s/it] 85%|████████▍ | 3735/4399 [8:32:01<1:29:59,  8.13s/it] 85%|████████▍ | 3736/4399 [8:32:11<1:34:56,  8.59s/it] 85%|████████▍ | 3737/4399 [8:32:19<1:33:24,  8.47s/it] 85%|████████▍ | 3738/4399 [8:32:26<1:28:34,  8.04s/it] 85%|████████▍ | 3739/4399 [8:32:34<1:28:04,  8.01s/it] 85%|███
 0: {'loss': 0.5832, 'grad_norm': 1.5179319145728585, 'learning_rate': 6.7020365722407e-07, 'epoch': 0.85}
 0: {'loss': 0.5725, 'grad_norm': 2.342340776407392, 'learning_rate': 6.504973459716136e-07, 'epoch': 0.85}
 0: █████▌ | 3740/4399 [8:32:44<1:34:20,  8.59s/it]                                                        85%|████████▌ | 3740/4399 [8:32:44<1:34:20,  8.59s/it] 85%|████████▌ | 3741/4399 [8:32:50<1:27:56,  8.02s/it] 85%|████████▌ | 3742/4399 [8:32:59<1:28:45,  8.11s/it] 85%|████████▌ | 3743/4399 [8:33:08<1:33:49,  8.58s/it] 85%|████████▌ | 3744/4399 [8:33:18<1:36:14,  8.82s/it] 85%|████████▌ | 3745/4399 [8:33:26<1:33:12,  8.55s/it] 85%|████████▌ | 3746/4399 [8:33:33<1:30:18,  8.30s/it] 85%|████████▌ | 3747/4399 [8:33:41<1:27:05,  8.01s/it] 85%|████████▌ | 3748/4399 [8:33:49<1:28:00,  8.11s/it] 85%|████████▌ | 3749/4399 [8:33:57<1:26:49,  8.01s/it] 85%|████████▌ | 3750/4399 [8:34:06<1:31:09,  8.43s/it]                                                        85%|████████▌ | 3
 0: {'loss': 0.5651, 'grad_norm': 1.4439088689441024, 'learning_rate': 6.310649183414924e-07, 'epoch': 0.85}
 0: 750/4399 [8:34:06<1:31:09,  8.43s/it] 85%|████████▌ | 3751/4399 [8:34:15<1:32:49,  8.60s/it] 85%|████████▌ | 3752/4399 [8:34:23<1:31:23,  8.48s/it] 85%|████████▌ | 3753/4399 [8:34:33<1:33:43,  8.71s/it] 85%|████████▌ | 3754/4399 [8:34:40<1:28:57,  8.28s/it] 85%|████████▌ | 3755/4399 [8:34:48<1:26:50,  8.09s/it] 85%|████████▌ | 3756/4399 [8:34:57<1:30:27,  8.44s/it] 85%|████████▌ | 3757/4399 [8:35:03<1:24:02,  7.85s/it] 85%|████████▌ | 3758/4399 [8:35:12<1:25:08,  7.97s/it] 85%|████████▌ | 3759/4399 [8:35:20<1:28:05,  8.26s/it] 85%|████████▌ | 3760/4399 [8:35:31<1:33:52,  8.81s/it]                                                        85%|████████▌ | 3760/4399 [8:35:31<1:33:52,  8.81s/it] 85%|████████▌ | 3761/4399 [8:35:39<1:31:34,  8.61s/it] 86%|████████▌ | 3762/4
 0: {'loss': 0.5669, 'grad_norm': 1.4650413027958606, 'learning_rate': 6.11907597973298e-07, 'epoch': 0.86}
 0: 399 [8:35:46<1:27:30,  8.24s/it] 86%|████████▌ | 3763/4399 [8:35:53<1:23:57,  7.92s/it] 86%|████████▌ | 3764/4399 [8:36:01<1:24:17,  7.97s/it] 86%|████████▌ | 3765/4399 [8:36:09<1:22:11,  7.78s/it] 86%|████████▌ | 3766/4399 [8:36:17<1:24:18,  7.99s/it] 86%|████████▌ | 3767/4399 [8:36:27<1:29:53,  8.53s/it] 86%|████████▌ | 3768/4399 [8:36:37<1:33:44,  8.91s/it] 86%|████████▌ | 3769/4399 [8:36:45<1:32:04,  8.77s/it] 86%|████████▌ | 3770/4399 [8:36:53<1:30:24,  8.62s/it]                                                        86%|████████▌ | 3770/4399 [8:36:53<1:30:24,  8.62s/it] 86%|████████▌ | 3771/4399 [8:37:01<1:26:15,  8.24s/it] 86%|████████▌ | 3772/4399 [8:37:09<1:26:37,  8.29s/it] 86%|████████▌ | 3773/4399 [8:37:16<1:22:48,  7.94s/it] 86%|████████▌ | 3774/4399 [
 0: {'loss': 0.5745, 'grad_norm': 1.4486494323168606, 'learning_rate': 5.930265911834154e-07, 'epoch': 0.86}
 0: 8:37:24<1:21:10,  7.79s/it] 86%|████████▌ | 3775/4399 [8:37:33<1:25:30,  8.22s/it] 86%|████████▌ | 3776/4399 [8:37:42<1:28:17,  8.50s/it] 86%|████████▌ | 3777/4399 [8:37:51<1:28:39,  8.55s/it] 86%|████████▌ | 3778/4399 [8:37:58<1:25:08,  8.23s/it] 86%|████████▌ | 3779/4399 [8:38:06<1:22:50,  8.02s/it] 86%|████████▌ | 3780/4399 [8:38:14<1:23:07,  8.06s/it]                                                        86%|████████▌ | 3780/4399 [8:38:14<1:23:07,  8.06s/it] 86%|████████▌ | 3781/4399 [8:38:22<1:23:57,  8.15s/it] 86%|████████▌ | 3782/4399 [8:38:30<1:21:58,  7.97s/it] 86%|████████▌ | 3783/4399 [8:38:40<1:27:58,  8.57s/it] 86%|████████▌ | 3784/4399 [8:38:49<1:30:16,  8.81s/it] 86%|████████▌ | 3785/4399 [8:38:58<1:31:12,  8.91s/it] 86%|████████▌ | 3786/4399 [8:39:
 0: {'loss': 0.5755, 'grad_norm': 1.5983021036518117, 'learning_rate': 5.744230868890444e-07, 'epoch': 0.86}
 0: 06<1:26:38,  8.48s/it] 86%|████████▌ | 3787/4399 [8:39:13<1:22:59,  8.14s/it] 86%|████████▌ | 3788/4399 [8:39:22<1:24:28,  8.30s/it] 86%|████████▌ | 3789/4399 [8:39:29<1:21:12,  7.99s/it] 86%|████████▌ | 3790/4399 [8:39:37<1:20:55,  7.97s/it]                                                        86%|████████▌ | 3790/4399 [8:39:37<1:20:55,  7.97s/it] 86%|████████▌ | 3791/4399 [8:39:47<1:25:34,  8.45s/it] 86%|████████▌ | 3792/4399 [8:39:56<1:28:12,  8.72s/it] 86%|████████▌ | 3793/4399 [8:40:04<1:26:11,  8.53s/it] 86%|████████▌ | 3794/4399 [8:40:12<1:23:57,  8.33s/it] 86%|████████▋ | 3795/4399 [8:40:21<1:26:23,  8.58s/it] 86%|████████▋ | 3796/4399 [8:40:30<1:26:18,  8.59s/it] 86%|████████▋ | 3797/4399 [8:40:38<1:24:06,  8.38s/it] 86%|████████▋ | 3798/4399 [8:40:45<1:
 0: {'loss': 0.5729, 'grad_norm': 1.4838370472971392, 'learning_rate': 5.560982565333506e-07, 'epoch': 0.86}
 0: 20:52,  8.07s/it] 86%|████████▋ | 3799/4399 [8:40:53<1:21:12,  8.12s/it] 86%|████████▋ | 3800/4399 [8:41:04<1:30:02,  9.02s/it]                                                        86%|████████▋ | 3800/4399 [8:41:04<1:30:02,  9.02s/it] 86%|████████▋ | 3801/4399 [8:41:13<1:28:47,  8.91s/it] 86%|████████▋ | 3802/4399 [8:41:20<1:23:06,  8.35s/it] 86%|████████▋ | 3803/4399 [8:41:27<1:20:25,  8.10s/it] 86%|████████▋ | 3804/4399 [8:41:36<1:21:29,  8.22s/it] 86%|████████▋ | 3805/4399 [8:41:44<1:21:18,  8.21s/it] 87%|████████▋ | 3806/4399 [8:41:51<1:17:58,  7.89s/it] 87%|████████▋ | 3807/4399 [8:42:00<1:19:01,  8.01s/it] 87%|████████▋ | 3808/4399 [8:42:09<1:22:32,  8.38s/it] 87%|████████▋ | 3809/4399 [8:42:18<1:26:05,  8.75s/it] 87%|████████▋ | 3810/4399 [8:42:26<1:22:04
 0: {'loss': 0.5783, 'grad_norm': 1.4459108394555582, 'learning_rate': 5.380532540116878e-07, 'epoch': 0.87}
 0: {'loss': 0.5805, 'grad_norm': 1.5517098716316091, 'learning_rate': 5.202892155989486e-07, 'epoch': 0.87}
 0: ,  8.36s/it]                                                        87%|████████▋ | 3810/4399 [8:42:26<1:22:04,  8.36s/it] 87%|████████▋ | 3811/4399 [8:42:34<1:22:24,  8.41s/it] 87%|████████▋ | 3812/4399 [8:42:44<1:25:32,  8.74s/it] 87%|████████▋ | 3813/4399 [8:42:52<1:23:06,  8.51s/it] 87%|████████▋ | 3814/4399 [8:43:01<1:24:43,  8.69s/it] 87%|████████▋ | 3815/4399 [8:43:09<1:23:43,  8.60s/it] 87%|████████▋ | 3816/4399 [8:43:19<1:27:21,  8.99s/it] 87%|████████▋ | 3817/4399 [8:43:28<1:25:38,  8.83s/it] 87%|████████▋ | 3818/4399 [8:43:35<1:21:04,  8.37s/it] 87%|████████▋ | 3819/4399 [8:43:43<1:19:15,  8.20s/it] 87%|████████▋ | 3820/4399 [8:43:53<1:23:14,  8.63s/it]                                                        87%|████████▋ | 3820/4399 [8:43:53<1:23:14,  8.63s/it] 87%|█
 0: {'loss': 0.5779, 'grad_norm': 1.5096839930975, 'learning_rate': 5.028072598780093e-07, 'epoch': 0.87}
 0: ██████▋ | 3821/4399 [8:44:00<1:18:35,  8.16s/it] 87%|████████▋ | 3822/4399 [8:44:07<1:16:42,  7.98s/it] 87%|████████▋ | 3823/4399 [8:44:15<1:14:54,  7.80s/it] 87%|████████▋ | 3824/4399 [8:44:24<1:19:22,  8.28s/it] 87%|████████▋ | 3825/4399 [8:44:33<1:20:44,  8.44s/it] 87%|████████▋ | 3826/4399 [8:44:40<1:16:07,  7.97s/it] 87%|████████▋ | 3827/4399 [8:44:48<1:18:19,  8.22s/it] 87%|████████▋ | 3828/4399 [8:44:58<1:21:28,  8.56s/it] 87%|████████▋ | 3829/4399 [8:45:06<1:19:21,  8.35s/it] 87%|████████▋ | 3830/4399 [8:45:13<1:15:14,  7.93s/it]                                                        87%|████████▋ | 3830/4399 [8:45:13<1:15:14,  7.93s/it] 87%|████████▋ | 3831/4399 [8:45:20<1:14:30,  7.87s/it] 87%|████████▋ | 3832/4399 [8:45:30<1:18:27,  8.30s/it] 87%|███
 0: {'loss': 0.5805, 'grad_norm': 1.5015198195475241, 'learning_rate': 4.856084876692952e-07, 'epoch': 0.87}
 0: █████▋ | 3833/4399 [8:45:39<1:22:01,  8.69s/it] 87%|████████▋ | 3834/4399 [8:45:46<1:16:23,  8.11s/it] 87%|████████▋ | 3835/4399 [8:45:54<1:17:03,  8.20s/it] 87%|████████▋ | 3836/4399 [8:46:04<1:19:38,  8.49s/it] 87%|████████▋ | 3837/4399 [8:46:11<1:15:37,  8.07s/it] 87%|████████▋ | 3838/4399 [8:46:18<1:14:46,  8.00s/it] 87%|████████▋ | 3839/4399 [8:46:26<1:14:22,  7.97s/it] 87%|████████▋ | 3840/4399 [8:46:35<1:16:41,  8.23s/it]                                                        87%|████████▋ | 3840/4399 [8:46:35<1:16:41,  8.23s/it] 87%|████████▋ | 3841/4399 [8:46:46<1:22:46,  8.90s/it] 87%|████████▋ | 3842/4399 [8:46:52<1:14:45,  8.05s/it] 87%|████████▋ | 3843/4399 [8:46:59<1:13:10,  7.90s/it] 87%|████████▋ | 3844/4399 [8:47:08<1:16:17,  8.25s/it] 87%|████
 0: {'loss': 0.5699, 'grad_norm': 1.8088950367953793, 'learning_rate': 4.6869398196146e-07, 'epoch': 0.88}
 0: ███▋ | 3845/4399 [8:47:16<1:13:55,  8.01s/it] 87%|████████▋ | 3846/4399 [8:47:24<1:15:21,  8.18s/it] 87%|████████▋ | 3847/4399 [8:47:33<1:15:17,  8.18s/it] 87%|████████▋ | 3848/4399 [8:47:42<1:19:34,  8.66s/it] 87%|████████▋ | 3849/4399 [8:47:52<1:21:30,  8.89s/it] 88%|████████▊ | 3850/4399 [8:47:59<1:16:19,  8.34s/it]                                                        88%|████████▊ | 3850/4399 [8:47:59<1:16:19,  8.34s/it] 88%|████████▊ | 3851/4399 [8:48:07<1:15:03,  8.22s/it] 88%|████████▊ | 3852/4399 [8:48:16<1:18:31,  8.61s/it] 88%|████████▊ | 3853/4399 [8:48:25<1:18:08,  8.59s/it] 88%|████████▊ | 3854/4399 [8:48:33<1:18:00,  8.59s/it] 88%|████████▊ | 3855/4399 [8:48:42<1:17:57,  8.60s/it] 88%|████████▊ | 3856/4399 [8:48:51<1:19:33,  8.79s/it] 88%|██████
 0: {'loss': 0.5697, 'grad_norm': 1.3394652551139195, 'learning_rate': 4.5206480784319775e-07, 'epoch': 0.88}
 0: █▊ | 3857/4399 [8:49:02<1:23:30,  9.24s/it] 88%|████████▊ | 3858/4399 [8:49:08<1:15:42,  8.40s/it] 88%|████████▊ | 3859/4399 [8:49:17<1:16:58,  8.55s/it] 88%|████████▊ | 3860/4399 [8:49:27<1:20:44,  8.99s/it]                                                        88%|████████▊ | 3860/4399 [8:49:27<1:20:44,  8.99s/it] 88%|████████▊ | 3861/4399 [8:49:33<1:13:45,  8.22s/it] 88%|████████▊ | 3862/4399 [8:49:42<1:14:48,  8.36s/it] 88%|████████▊ | 3863/4399 [8:49:50<1:14:51,  8.38s/it] 88%|████████▊ | 3864/4399 [8:49:59<1:14:45,  8.38s/it] 88%|████████▊ | 3865/4399 [8:50:10<1:21:04,  9.11s/it] 88%|████████▊ | 3866/4399 [8:50:16<1:12:56,  8.21s/it] 88%|████████▊ | 3867/4399 [8:50:24<1:13:21,  8.27s/it] 88%|████████▊ | 3868/4399 [8:50:33<1:13:27,  8.30s/it] 88%|████████
 0: {'loss': 0.5651, 'grad_norm': 1.4382043731687153, 'learning_rate': 4.357220124361666e-07, 'epoch': 0.88}
 0: ▊ | 3869/4399 [8:50:39<1:09:01,  7.81s/it] 88%|████████▊ | 3870/4399 [8:50:49<1:13:56,  8.39s/it]                                                        88%|████████▊ | 3870/4399 [8:50:49<1:13:56,  8.39s/it] 88%|████████▊ | 3871/4399 [8:50:57<1:13:56,  8.40s/it] 88%|████████▊ | 3872/4399 [8:51:06<1:13:10,  8.33s/it] 88%|████████▊ | 3873/4399 [8:51:16<1:18:41,  8.98s/it] 88%|████████▊ | 3874/4399 [8:51:22<1:11:10,  8.13s/it] 88%|████████▊ | 3875/4399 [8:51:30<1:09:25,  7.95s/it] 88%|████████▊ | 3876/4399 [8:51:41<1:17:12,  8.86s/it] 88%|████████▊ | 3877/4399 [8:51:48<1:13:32,  8.45s/it] 88%|████████▊ | 3878/4399 [8:51:57<1:13:32,  8.47s/it] 88%|████████▊ | 3879/4399 [8:52:05<1:12:42,  8.39s/it] 88%|████████▊ | 3880/4399 [8:52:14<1:13:09,  8.46s/it]                                  
 0: {'loss': 0.5808, 'grad_norm': 1.3943200726466873, 'learning_rate': 4.196666248290643e-07, 'epoch': 0.88}
 0: {'loss': 0.5656, 'grad_norm': 1.5712288109203916, 'learning_rate': 4.038996560128139e-07, 'epoch': 0.88}
 0:                       88%|████████▊ | 3880/4399 [8:52:14<1:13:09,  8.46s/it] 88%|████████▊ | 3881/4399 [8:52:23<1:15:32,  8.75s/it] 88%|████████▊ | 3882/4399 [8:52:30<1:11:16,  8.27s/it] 88%|████████▊ | 3883/4399 [8:52:37<1:07:30,  7.85s/it] 88%|████████▊ | 3884/4399 [8:52:45<1:07:45,  7.89s/it] 88%|████████▊ | 3885/4399 [8:52:53<1:06:39,  7.78s/it] 88%|████████▊ | 3886/4399 [8:53:02<1:12:01,  8.42s/it] 88%|████████▊ | 3887/4399 [8:53:11<1:11:35,  8.39s/it] 88%|████████▊ | 3888/4399 [8:53:19<1:10:19,  8.26s/it] 88%|████████▊ | 3889/4399 [8:53:29<1:14:24,  8.75s/it] 88%|████████▊ | 3890/4399 [8:53:36<1:09:38,  8.21s/it]                                                        88%|████████▊ | 3890/4399 [8:53:36<1:09:38,  8.21s/it] 88%|████████▊ | 3891/4399 [8:53:44<1:
 0: {'loss': 0.5711, 'grad_norm': 1.9876106203449189, 'learning_rate': 3.884220988169146e-07, 'epoch': 0.89}
 0: 08:49,  8.13s/it] 88%|████████▊ | 3892/4399 [8:53:52<1:09:59,  8.28s/it] 88%|████████▊ | 3893/4399 [8:53:59<1:07:20,  7.98s/it] 89%|████████▊ | 3894/4399 [8:54:09<1:10:03,  8.32s/it] 89%|████████▊ | 3895/4399 [8:54:17<1:10:21,  8.38s/it] 89%|████████▊ | 3896/4399 [8:54:26<1:10:38,  8.43s/it] 89%|████████▊ | 3897/4399 [8:54:34<1:10:35,  8.44s/it] 89%|████████▊ | 3898/4399 [8:54:42<1:08:04,  8.15s/it] 89%|████████▊ | 3899/4399 [8:54:49<1:07:19,  8.08s/it] 89%|████████▊ | 3900/4399 [8:54:57<1:06:43,  8.02s/it]                                                        89%|████████▊ | 3900/4399 [8:54:57<1:06:43,  8.02s/it] 89%|████████▊ | 3901/4399 [8:55:05<1:04:54,  7.82s/it] 89%|████████▊ | 3902/4399 [8:55:13<1:05:07,  7.86s/it] 89%|████████▊ | 3903/4399 [8:55:22<1:09:18
 0: {'loss': 0.5711, 'grad_norm': 1.7037874917330003, 'learning_rate': 3.732349278469144e-07, 'epoch': 0.89}
 0: ,  8.38s/it] 89%|████████▊ | 3904/4399 [8:55:31<1:09:51,  8.47s/it] 89%|████████▉ | 3905/4399 [8:55:40<1:11:08,  8.64s/it] 89%|████████▉ | 3906/4399 [8:55:47<1:06:54,  8.14s/it] 89%|████████▉ | 3907/4399 [8:55:55<1:06:14,  8.08s/it] 89%|████████▉ | 3908/4399 [8:56:04<1:08:21,  8.35s/it] 89%|████████▉ | 3909/4399 [8:56:11<1:06:08,  8.10s/it] 89%|████████▉ | 3910/4399 [8:56:19<1:05:47,  8.07s/it]                                                        89%|████████▉ | 3910/4399 [8:56:19<1:05:47,  8.07s/it] 89%|████████▉ | 3911/4399 [8:56:29<1:08:27,  8.42s/it] 89%|████████▉ | 3912/4399 [8:56:36<1:04:50,  7.99s/it] 89%|████████▉ | 3913/4399 [8:56:45<1:09:09,  8.54s/it] 89%|████████▉ | 3914/4399 [8:56:53<1:05:38,  8.12s/it] 89%|████████▉ | 3915/4399 [8:57:01<1:06:16,  8.
 0: {'loss': 0.575, 'grad_norm': 1.6485845552275318, 'learning_rate': 3.583390994230512e-07, 'epoch': 0.89}
 0: 22s/it] 89%|████████▉ | 3916/4399 [8:57:09<1:05:17,  8.11s/it] 89%|████████▉ | 3917/4399 [8:57:17<1:06:24,  8.27s/it] 89%|████████▉ | 3918/4399 [8:57:25<1:04:37,  8.06s/it] 89%|████████▉ | 3919/4399 [8:57:34<1:07:09,  8.39s/it] 89%|████████▉ | 3920/4399 [8:57:42<1:05:54,  8.26s/it]                                                        89%|████████▉ | 3920/4399 [8:57:42<1:05:54,  8.26s/it] 89%|████████▉ | 3921/4399 [8:57:52<1:09:39,  8.74s/it] 89%|████████▉ | 3922/4399 [8:57:59<1:04:52,  8.16s/it] 89%|████████▉ | 3923/4399 [8:58:07<1:05:14,  8.22s/it] 89%|████████▉ | 3924/4399 [8:58:15<1:04:49,  8.19s/it] 89%|████████▉ | 3925/4399 [8:58:23<1:02:40,  7.93s/it] 89%|████████▉ | 3926/4399 [8:58:31<1:04:05,  8.13s/it] 89%|████████▉ | 3927/4399 [8:58:40<1:04:22,  8.18s/i
 0: {'loss': 0.576, 'grad_norm': 1.717290210252285, 'learning_rate': 3.4373555152002247e-07, 'epoch': 0.89}
 0: t] 89%|████████▉ | 3928/4399 [8:58:48<1:04:22,  8.20s/it] 89%|████████▉ | 3929/4399 [8:58:57<1:07:39,  8.64s/it] 89%|████████▉ | 3930/4399 [8:59:05<1:05:49,  8.42s/it]                                                        89%|████████▉ | 3930/4399 [8:59:05<1:05:49,  8.42s/it] 89%|████████▉ | 3931/4399 [8:59:13<1:03:38,  8.16s/it] 89%|████████▉ | 3932/4399 [8:59:23<1:07:00,  8.61s/it] 89%|████████▉ | 3933/4399 [8:59:30<1:03:56,  8.23s/it] 89%|████████▉ | 3934/4399 [8:59:37<1:01:55,  7.99s/it] 89%|████████▉ | 3935/4399 [8:59:46<1:02:50,  8.13s/it] 89%|████████▉ | 3936/4399 [8:59:54<1:02:43,  8.13s/it] 89%|████████▉ | 3937/4399 [9:00:04<1:07:04,  8.71s/it] 90%|████████▉ | 3938/4399 [9:00:12<1:05:16,  8.50s/it] 90%|████████▉ | 3939/4399 [9:00:21<1:05:57,  8.60s/it] 9
 0: {'loss': 0.5765, 'grad_norm': 1.411393885765465, 'learning_rate': 3.294252037079315e-07, 'epoch': 0.9}
 0: {'loss': 0.5705, 'grad_norm': 1.5484912397617019, 'learning_rate': 3.154089570943769e-07, 'epoch': 0.9}
 0: 0%|████████▉ | 3940/4399 [9:00:29<1:03:55,  8.36s/it]                                                        90%|████████▉ | 3940/4399 [9:00:29<1:03:55,  8.36s/it] 90%|████████▉ | 3941/4399 [9:00:36<1:01:56,  8.12s/it] 90%|████████▉ | 3942/4399 [9:00:44<1:00:40,  7.97s/it] 90%|████████▉ | 3943/4399 [9:00:53<1:03:28,  8.35s/it] 90%|████████▉ | 3944/4399 [9:01:01<1:03:19,  8.35s/it] 90%|████████▉ | 3945/4399 [9:01:10<1:04:06,  8.47s/it] 90%|████████▉ | 3946/4399 [9:01:18<1:02:11,  8.24s/it] 90%|████████▉ | 3947/4399 [9:01:25<1:00:09,  7.99s/it] 90%|████████▉ | 3948/4399 [9:01:33<59:36,  7.93s/it]   90%|████████▉ | 3949/4399 [9:01:42<1:00:52,  8.12s/it] 90%|████████▉ | 3950/4399 [9:01:51<1:02:36,  8.37s/it]                                                        90%|██████
 0: {'loss': 0.5752, 'grad_norm': 1.4001467063708322, 'learning_rate': 3.016876942677133e-07, 'epoch': 0.9}
 0: █▉ | 3950/4399 [9:01:51<1:02:36,  8.37s/it] 90%|████████▉ | 3951/4399 [9:02:00<1:04:05,  8.58s/it] 90%|████████▉ | 3952/4399 [9:02:08<1:02:47,  8.43s/it] 90%|████████▉ | 3953/4399 [9:02:17<1:05:26,  8.80s/it] 90%|████████▉ | 3954/4399 [9:02:25<1:02:20,  8.41s/it] 90%|████████▉ | 3955/4399 [9:02:34<1:03:13,  8.54s/it] 90%|████████▉ | 3956/4399 [9:02:42<1:03:28,  8.60s/it] 90%|████████▉ | 3957/4399 [9:02:51<1:02:29,  8.48s/it] 90%|████████▉ | 3958/4399 [9:02:59<1:02:04,  8.45s/it] 90%|████████▉ | 3959/4399 [9:03:08<1:04:00,  8.73s/it] 90%|█████████ | 3960/4399 [9:03:16<1:02:16,  8.51s/it]                                                        90%|█████████ | 3960/4399 [9:03:16<1:02:16,  8.51s/it] 90%|█████████ | 3961/4399 [9:03:26<1:04:56,  8.90s/it] 90%|████████
 0: {'loss': 0.5714, 'grad_norm': 2.0734593847902416, 'learning_rate': 2.88262279241478e-07, 'epoch': 0.9}
 0: █ | 3962/4399 [9:03:34<1:01:20,  8.42s/it] 90%|█████████ | 3963/4399 [9:03:42<1:00:17,  8.30s/it] 90%|█████████ | 3964/4399 [9:03:51<1:02:06,  8.57s/it] 90%|█████████ | 3965/4399 [9:03:57<57:31,  7.95s/it]   90%|█████████ | 3966/4399 [9:04:06<58:26,  8.10s/it] 90%|█████████ | 3967/4399 [9:04:15<1:00:39,  8.43s/it] 90%|█████████ | 3968/4399 [9:04:24<1:01:32,  8.57s/it] 90%|█████████ | 3969/4399 [9:04:33<1:03:18,  8.83s/it] 90%|█████████ | 3970/4399 [9:04:41<1:00:54,  8.52s/it]                                                        90%|█████████ | 3970/4399 [9:04:41<1:00:54,  8.52s/it] 90%|█████████ | 3971/4399 [9:04:49<59:19,  8.32s/it]   90%|█████████ | 3972/4399 [9:04:58<1:00:02,  8.44s/it] 90%|█████████ | 3973/4399 [9:05:04<56:03,  7.90s/it]   90%|█████████ | 3
 0: {'loss': 0.5513, 'grad_norm': 1.947069337405398, 'learning_rate': 2.751335573999803e-07, 'epoch': 0.9}
 0: 974/4399 [9:05:14<59:13,  8.36s/it] 90%|█████████ | 3975/4399 [9:05:22<59:27,  8.41s/it] 90%|█████████ | 3976/4399 [9:05:30<58:00,  8.23s/it] 90%|█████████ | 3977/4399 [9:05:40<1:00:39,  8.63s/it] 90%|█████████ | 3978/4399 [9:05:48<59:32,  8.49s/it]   90%|█████████ | 3979/4399 [9:05:56<58:06,  8.30s/it] 90%|█████████ | 3980/4399 [9:06:04<57:36,  8.25s/it]                                                      90%|█████████ | 3980/4399 [9:06:04<57:36,  8.25s/it] 90%|█████████ | 3981/4399 [9:06:12<57:06,  8.20s/it] 91%|█████████ | 3982/4399 [9:06:21<59:38,  8.58s/it] 91%|█████████ | 3983/4399 [9:06:31<1:01:13,  8.83s/it] 91%|█████████ | 3984/4399 [9:06:38<58:35,  8.47s/it]   91%|█████████ | 3985/4399 [9:06:48<1:00:48,  8.81s/it] 91%|█████████ | 3986/4399 [9:06:55<56:51
 0: {'loss': 0.5555, 'grad_norm': 3.5962656992846047, 'learning_rate': 2.623023554450693e-07, 'epoch': 0.91}
 0: ,  8.26s/it]   91%|█████████ | 3987/4399 [9:07:03<56:53,  8.28s/it] 91%|█████████ | 3988/4399 [9:07:11<54:55,  8.02s/it] 91%|█████████ | 3989/4399 [9:07:18<52:26,  7.68s/it] 91%|█████████ | 3990/4399 [9:07:27<55:03,  8.08s/it]                                                      91%|█████████ | 3990/4399 [9:07:27<55:03,  8.08s/it] 91%|█████████ | 3991/4399 [9:07:35<56:41,  8.34s/it] 91%|█████████ | 3992/4399 [9:07:43<55:35,  8.20s/it] 91%|█████████ | 3993/4399 [9:07:53<59:02,  8.72s/it] 91%|█████████ | 3994/4399 [9:08:00<55:45,  8.26s/it] 91%|█████████ | 3995/4399 [9:08:08<55:07,  8.19s/it] 91%|█████████ | 3996/4399 [9:08:17<55:20,  8.24s/it] 91%|█████████ | 3997/4399 [9:08:23<51:29,  7.69s/it] 91%|█████████ | 3998/4399 [9:08:31<52:23,  7.84s/it] 91%|████
 0: {'loss': 0.5656, 'grad_norm': 1.3925001484714443, 'learning_rate': 2.4976948134408264e-07, 'epoch': 0.91}
 0: ████ | 3999/4399 [9:08:41<55:19,  8.30s/it] 91%|█████████ | 4000/4399 [9:08:48<53:57,  8.11s/it]                                                      91%|█████████ | 4000/4399 [9:08:49<53:57,  8.11s/it][INFO|trainer.py:3984] 2025-06-28 06:13:15,203 >> Saving model checkpoint to /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000
 0: [INFO|configuration_utils.py:419] 2025-06-28 06:13:15,210 >> Configuration saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/config.json
 0: [INFO|configuration_utils.py:911] 2025-06-28 06:13:15,213 >> Configuration saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/generation_config.json
 0: [INFO|modeling_utils.py:3580] 2025-06-28 06:13:22,141 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 4 checkpoint shards. You can find where each parameters has been saved in the index located at /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/model.safetensors.index.json.
 0: [INFO|tokenization_utils_base.py:2510] 2025-06-28 06:13:22,144 >> tokenizer config file saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/tokenizer_config.json
 0: [INFO|tokenization_utils_base.py:2519] 2025-06-28 06:13:22,147 >> Special tokens file saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/special_tokens_map.json
 0: [2025-06-28 06:13:22,305] [INFO] [logging.py:107:log_dist] [Rank 0] [Torch] Checkpoint global_step4000 is about to be saved!
23: [2025-06-28 06:13:22,315] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_92_mp_rank_00_model_states.pt...
15: [2025-06-28 06:13:22,315] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_60_mp_rank_00_model_states.pt...
25: [2025-06-28 06:13:22,316] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_100_mp_rank_00_model_states.pt...
20: [2025-06-28 06:13:22,316] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_80_mp_rank_00_model_states.pt...
19: [2025-06-28 06:13:22,316] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_76_mp_rank_00_model_states.pt...
 9: [2025-06-28 06:13:22,316] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_36_mp_rank_00_model_states.pt...
 5: [2025-06-28 06:13:22,316] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_20_mp_rank_00_model_states.pt...
12: [2025-06-28 06:13:22,316] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_48_mp_rank_00_model_states.pt...
27: [2025-06-28 06:13:22,316] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_108_mp_rank_00_model_states.pt...
14: [2025-06-28 06:13:22,316] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_56_mp_rank_00_model_states.pt...
10: [2025-06-28 06:13:22,316] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_40_mp_rank_00_model_states.pt...
 2: [2025-06-28 06:13:22,316] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_8_mp_rank_00_model_states.pt...
 8: [2025-06-28 06:13:22,316] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_32_mp_rank_00_model_states.pt...
 6: [2025-06-28 06:13:22,316] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_24_mp_rank_00_model_states.pt...
18: [2025-06-28 06:13:22,316] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_72_mp_rank_00_model_states.pt...
 0: [2025-06-28 06:13:22,316] [INFO] [logging.py:107:log_dist] [Rank 0] Saving model checkpoint: /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_0_mp_rank_00_model_states.pt
31: [2025-06-28 06:13:22,316] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_124_mp_rank_00_model_states.pt...
30: [2025-06-28 06:13:22,316] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_120_mp_rank_00_model_states.pt...
24: [2025-06-28 06:13:22,316] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_96_mp_rank_00_model_states.pt...
 4: [2025-06-28 06:13:22,316] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_16_mp_rank_00_model_states.pt...
 7: [2025-06-28 06:13:22,316] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_28_mp_rank_00_model_states.pt...
22: [2025-06-28 06:13:22,316] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_88_mp_rank_00_model_states.pt...
 0: [2025-06-28 06:13:22,317] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_0_mp_rank_00_model_states.pt...
29: [2025-06-28 06:13:22,317] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_116_mp_rank_00_model_states.pt...
26: [2025-06-28 06:13:22,317] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_104_mp_rank_00_model_states.pt...
28: [2025-06-28 06:13:22,317] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_112_mp_rank_00_model_states.pt...
 1: [2025-06-28 06:13:22,317] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_4_mp_rank_00_model_states.pt...
21: [2025-06-28 06:13:22,318] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_84_mp_rank_00_model_states.pt...
16: [2025-06-28 06:13:22,318] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_64_mp_rank_00_model_states.pt...
17: [2025-06-28 06:13:22,318] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_68_mp_rank_00_model_states.pt...
 3: [2025-06-28 06:13:22,318] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_12_mp_rank_00_model_states.pt...
13: [2025-06-28 06:13:22,319] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_52_mp_rank_00_model_states.pt...
11: [2025-06-28 06:13:22,319] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_44_mp_rank_00_model_states.pt...
23: [2025-06-28 06:13:22,339] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_92_mp_rank_00_model_states.pt.
25: [2025-06-28 06:13:22,344] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_100_mp_rank_00_model_states.pt.
 6: [2025-06-28 06:13:22,349] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_24_mp_rank_00_model_states.pt.
15: [2025-06-28 06:13:22,350] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_60_mp_rank_00_model_states.pt.
10: [2025-06-28 06:13:22,350] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_40_mp_rank_00_model_states.pt.
22: [2025-06-28 06:13:22,352] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_88_mp_rank_00_model_states.pt.
14: [2025-06-28 06:13:22,352] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_56_mp_rank_00_model_states.pt.
18: [2025-06-28 06:13:22,352] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_72_mp_rank_00_model_states.pt.
 2: [2025-06-28 06:13:22,355] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_8_mp_rank_00_model_states.pt.
24: [2025-06-28 06:13:22,357] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_96_mp_rank_00_model_states.pt.
 0: [2025-06-28 06:13:22,359] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_0_mp_rank_00_model_states.pt.
27: [2025-06-28 06:13:22,359] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_108_mp_rank_00_model_states.pt.
20: [2025-06-28 06:13:22,361] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_80_mp_rank_00_model_states.pt.
 7: [2025-06-28 06:13:22,363] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_28_mp_rank_00_model_states.pt.
 8: [2025-06-28 06:13:22,364] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_32_mp_rank_00_model_states.pt.
19: [2025-06-28 06:13:22,365] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_76_mp_rank_00_model_states.pt.
28: [2025-06-28 06:13:22,366] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_112_mp_rank_00_model_states.pt.
 5: [2025-06-28 06:13:22,367] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_20_mp_rank_00_model_states.pt.
 9: [2025-06-28 06:13:22,367] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_36_mp_rank_00_model_states.pt.
 1: [2025-06-28 06:13:22,367] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_4_mp_rank_00_model_states.pt.
 3: [2025-06-28 06:13:22,368] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_12_mp_rank_00_model_states.pt.
31: [2025-06-28 06:13:22,368] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_124_mp_rank_00_model_states.pt.
11: [2025-06-28 06:13:22,368] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_44_mp_rank_00_model_states.pt.
26: [2025-06-28 06:13:22,369] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_104_mp_rank_00_model_states.pt.
29: [2025-06-28 06:13:22,369] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_116_mp_rank_00_model_states.pt.
30: [2025-06-28 06:13:22,369] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_120_mp_rank_00_model_states.pt.
12: [2025-06-28 06:13:22,370] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_48_mp_rank_00_model_states.pt.
 4: [2025-06-28 06:13:22,371] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_16_mp_rank_00_model_states.pt.
16: [2025-06-28 06:13:22,371] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_64_mp_rank_00_model_states.pt.
17: [2025-06-28 06:13:22,371] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_68_mp_rank_00_model_states.pt.
21: [2025-06-28 06:13:22,372] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_84_mp_rank_00_model_states.pt.
13: [2025-06-28 06:13:22,373] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/zero_pp_rank_52_mp_rank_00_model_states.pt.
 0: [2025-06-28 06:13:22,415] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
 4: [2025-06-28 06:13:22,415] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_16_mp_rank_00_optim_states.pt...
 6: [2025-06-28 06:13:22,415] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_24_mp_rank_00_optim_states.pt...
10: [2025-06-28 06:13:22,415] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_40_mp_rank_00_optim_states.pt...
 2: [2025-06-28 06:13:22,415] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_8_mp_rank_00_optim_states.pt...
 9: [2025-06-28 06:13:22,415] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_36_mp_rank_00_optim_states.pt...
15: [2025-06-28 06:13:22,415] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_60_mp_rank_00_optim_states.pt...
 7: [2025-06-28 06:13:22,415] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_28_mp_rank_00_optim_states.pt...
 8: [2025-06-28 06:13:22,415] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_32_mp_rank_00_optim_states.pt...
12: [2025-06-28 06:13:22,415] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_48_mp_rank_00_optim_states.pt...
 1: [2025-06-28 06:13:22,415] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_4_mp_rank_00_optim_states.pt...
16: [2025-06-28 06:13:22,415] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_64_mp_rank_00_optim_states.pt...
 5: [2025-06-28 06:13:22,415] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_20_mp_rank_00_optim_states.pt...
25: [2025-06-28 06:13:22,415] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_100_mp_rank_00_optim_states.pt...
23: [2025-06-28 06:13:22,415] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_92_mp_rank_00_optim_states.pt...
28: [2025-06-28 06:13:22,415] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_112_mp_rank_00_optim_states.pt...
14: [2025-06-28 06:13:22,415] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_56_mp_rank_00_optim_states.pt...
19: [2025-06-28 06:13:22,415] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_76_mp_rank_00_optim_states.pt...
21: [2025-06-28 06:13:22,415] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_84_mp_rank_00_optim_states.pt...
30: [2025-06-28 06:13:22,415] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_120_mp_rank_00_optim_states.pt...
22: [2025-06-28 06:13:22,415] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_88_mp_rank_00_optim_states.pt...
31: [2025-06-28 06:13:22,415] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_124_mp_rank_00_optim_states.pt...
29: [2025-06-28 06:13:22,415] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_116_mp_rank_00_optim_states.pt...
24: [2025-06-28 06:13:22,415] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_96_mp_rank_00_optim_states.pt...
17: [2025-06-28 06:13:22,415] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_68_mp_rank_00_optim_states.pt...
20: [2025-06-28 06:13:22,415] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_80_mp_rank_00_optim_states.pt...
18: [2025-06-28 06:13:22,415] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_72_mp_rank_00_optim_states.pt...
26: [2025-06-28 06:13:22,415] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_104_mp_rank_00_optim_states.pt...
27: [2025-06-28 06:13:22,415] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_108_mp_rank_00_optim_states.pt...
 3: [2025-06-28 06:13:22,415] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_12_mp_rank_00_optim_states.pt...
13: [2025-06-28 06:13:22,415] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_52_mp_rank_00_optim_states.pt...
11: [2025-06-28 06:13:22,415] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_44_mp_rank_00_optim_states.pt...
 8: [2025-06-28 06:13:25,150] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_32_mp_rank_00_optim_states.pt.
 8: [2025-06-28 06:13:25,150] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_32_mp_rank_00_optim_states.pt
23: [2025-06-28 06:13:25,169] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_92_mp_rank_00_optim_states.pt.
23: [2025-06-28 06:13:25,169] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_92_mp_rank_00_optim_states.pt
17: [2025-06-28 06:13:25,179] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_68_mp_rank_00_optim_states.pt.
17: [2025-06-28 06:13:25,179] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_68_mp_rank_00_optim_states.pt
 1: [2025-06-28 06:13:25,184] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_4_mp_rank_00_optim_states.pt.
 1: [2025-06-28 06:13:25,184] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_4_mp_rank_00_optim_states.pt
 3: [2025-06-28 06:13:25,193] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_12_mp_rank_00_optim_states.pt.
 3: [2025-06-28 06:13:25,193] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_12_mp_rank_00_optim_states.pt
15: [2025-06-28 06:13:25,194] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_60_mp_rank_00_optim_states.pt.
15: [2025-06-28 06:13:25,194] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_60_mp_rank_00_optim_states.pt
13: [2025-06-28 06:13:25,195] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_52_mp_rank_00_optim_states.pt.
13: [2025-06-28 06:13:25,195] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_52_mp_rank_00_optim_states.pt
18: [2025-06-28 06:13:25,220] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_72_mp_rank_00_optim_states.pt.
18: [2025-06-28 06:13:25,220] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_72_mp_rank_00_optim_states.pt
22: [2025-06-28 06:13:25,220] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_88_mp_rank_00_optim_states.pt.
22: [2025-06-28 06:13:25,220] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_88_mp_rank_00_optim_states.pt
11: [2025-06-28 06:13:25,221] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_44_mp_rank_00_optim_states.pt.
11: [2025-06-28 06:13:25,221] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_44_mp_rank_00_optim_states.pt
31: [2025-06-28 06:13:25,223] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_124_mp_rank_00_optim_states.pt.
31: [2025-06-28 06:13:25,224] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_124_mp_rank_00_optim_states.pt
20: [2025-06-28 06:13:25,225] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_80_mp_rank_00_optim_states.pt.
20: [2025-06-28 06:13:25,225] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_80_mp_rank_00_optim_states.pt
 2: [2025-06-28 06:13:25,227] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_8_mp_rank_00_optim_states.pt.
 2: [2025-06-28 06:13:25,227] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_8_mp_rank_00_optim_states.pt
 4: [2025-06-28 06:13:25,228] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_16_mp_rank_00_optim_states.pt.
 4: [2025-06-28 06:13:25,229] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_16_mp_rank_00_optim_states.pt
10: [2025-06-28 06:13:25,226] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_40_mp_rank_00_optim_states.pt.
10: [2025-06-28 06:13:25,226] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_40_mp_rank_00_optim_states.pt
30: [2025-06-28 06:13:25,229] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_120_mp_rank_00_optim_states.pt.
30: [2025-06-28 06:13:25,230] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_120_mp_rank_00_optim_states.pt
 6: [2025-06-28 06:13:25,230] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_24_mp_rank_00_optim_states.pt.
 6: [2025-06-28 06:13:25,230] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_24_mp_rank_00_optim_states.pt
12: [2025-06-28 06:13:25,219] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_48_mp_rank_00_optim_states.pt.
12: [2025-06-28 06:13:25,219] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_48_mp_rank_00_optim_states.pt
14: [2025-06-28 06:13:25,237] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_56_mp_rank_00_optim_states.pt.
14: [2025-06-28 06:13:25,237] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_56_mp_rank_00_optim_states.pt
16: [2025-06-28 06:13:25,238] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_64_mp_rank_00_optim_states.pt.
16: [2025-06-28 06:13:25,238] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_64_mp_rank_00_optim_states.pt
28: [2025-06-28 06:13:25,250] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_112_mp_rank_00_optim_states.pt.
28: [2025-06-28 06:13:25,250] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_112_mp_rank_00_optim_states.pt
19: [2025-06-28 06:13:25,255] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_76_mp_rank_00_optim_states.pt.
19: [2025-06-28 06:13:25,255] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_76_mp_rank_00_optim_states.pt
25: [2025-06-28 06:13:25,309] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_100_mp_rank_00_optim_states.pt.
25: [2025-06-28 06:13:25,309] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_100_mp_rank_00_optim_states.pt
21: [2025-06-28 06:13:25,309] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_84_mp_rank_00_optim_states.pt.
21: [2025-06-28 06:13:25,310] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_84_mp_rank_00_optim_states.pt
27: [2025-06-28 06:13:25,310] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_108_mp_rank_00_optim_states.pt.
27: [2025-06-28 06:13:25,311] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_108_mp_rank_00_optim_states.pt
 5: [2025-06-28 06:13:25,319] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_20_mp_rank_00_optim_states.pt.
 5: [2025-06-28 06:13:25,320] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_20_mp_rank_00_optim_states.pt
29: [2025-06-28 06:13:25,341] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_116_mp_rank_00_optim_states.pt.
29: [2025-06-28 06:13:25,341] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_116_mp_rank_00_optim_states.pt
 7: [2025-06-28 06:13:25,373] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_28_mp_rank_00_optim_states.pt.
 7: [2025-06-28 06:13:25,373] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_28_mp_rank_00_optim_states.pt
 9: [2025-06-28 06:13:25,377] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_36_mp_rank_00_optim_states.pt.
 9: [2025-06-28 06:13:25,377] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_36_mp_rank_00_optim_states.pt
 0: [2025-06-28 06:13:25,405] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
24: [2025-06-28 06:13:25,447] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_96_mp_rank_00_optim_states.pt.
24: [2025-06-28 06:13:25,447] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_96_mp_rank_00_optim_states.pt
 0: [2025-06-28 06:13:25,456] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
26: [2025-06-28 06:13:25,581] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_104_mp_rank_00_optim_states.pt.
26: [2025-06-28 06:13:25,581] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/global_step4000/bf16_zero_pp_rank_104_mp_rank_00_optim_states.pt
14: [2025-06-28 06:13:27,060] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4000 is ready now!
22: [2025-06-28 06:13:27,060] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4000 is ready now!
 2: [2025-06-28 06:13:27,060] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4000 is ready now!
23: [2025-06-28 06:13:27,060] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4000 is ready now!
 8: [2025-06-28 06:13:27,060] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4000 is ready now!
 5: [2025-06-28 06:13:27,061] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4000 is ready now!
 6: [2025-06-28 06:13:27,061] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4000 is ready now!
31: [2025-06-28 06:13:27,061] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4000 is ready now!
29: [2025-06-28 06:13:27,061] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4000 is ready now!
25: [2025-06-28 06:13:27,061] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4000 is ready now!
 4: [2025-06-28 06:13:27,061] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4000 is ready now!
 7: [2025-06-28 06:13:27,061] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4000 is ready now!
26: [2025-06-28 06:13:27,061] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4000 is ready now!
15: [2025-06-28 06:13:27,061] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4000 is ready now!
20: [2025-06-28 06:13:27,061] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4000 is ready now!
18: [2025-06-28 06:13:27,061] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4000 is ready now!
10: [2025-06-28 06:13:27,061] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4000 is ready now!
30: [2025-06-28 06:13:27,061] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4000 is ready now!
 9: [2025-06-28 06:13:27,061] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4000 is ready now!
24: [2025-06-28 06:13:27,062] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4000 is ready now!
27: [2025-06-28 06:13:27,062] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4000 is ready now!
19: [2025-06-28 06:13:27,062] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4000 is ready now!
 3: [2025-06-28 06:13:27,062] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4000 is ready now!
11: [2025-06-28 06:13:27,062] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4000 is ready now!
28: [2025-06-28 06:13:27,062] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4000 is ready now!
 0: [2025-06-28 06:13:27,062] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4000 is ready now!
12: [2025-06-28 06:13:27,062] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4000 is ready now!
16: [2025-06-28 06:13:27,063] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4000 is ready now!
 1: [2025-06-28 06:13:27,063] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4000 is ready now!
17: [2025-06-28 06:13:27,063] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4000 is ready now!
13: [2025-06-28 06:13:27,063] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4000 is ready now!
21: [2025-06-28 06:13:27,063] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4000 is ready now!
 0: [INFO|image_processing_base.py:260] 2025-06-28 06:13:27,239 >> Image processor saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/preprocessor_config.json
 0: [INFO|tokenization_utils_base.py:2510] 2025-06-28 06:13:27,241 >> tokenizer config file saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/tokenizer_config.json
 0: [INFO|tokenization_utils_base.py:2519] 2025-06-28 06:13:27,242 >> Special tokens file saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/special_tokens_map.json
 0: [INFO|processing_utils.py:648] 2025-06-28 06:13:27,823 >> chat template saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4000/chat_template.json
 0:  91%|█████████ | 4001/4399 [9:10:08<3:15:24, 29.46s/it] 91%|█████████ | 4002/4399 [9:10:15<2:30:49, 22.80s/it]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/cudnn/MHA.cpp:667.)
 0:   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
 0: {'loss': 0.5658, 'grad_norm': 1.6179977103606762, 'learning_rate': 2.3753572427896275e-07, 'epoch': 0.91}
 0:  91%|█████████ | 4003/4399 [9:10:23<2:00:26, 18.25s/it] 91%|█████████ | 4004/4399 [9:10:30<1:38:25, 14.95s/it] 91%|█████████ | 4005/4399 [9:10:37<1:22:03, 12.50s/it] 91%|█████████ | 4006/4399 [9:10:45<1:12:59, 11.14s/it] 91%|█████████ | 4007/4399 [9:10:54<1:08:47, 10.53s/it] 91%|█████████ | 4008/4399 [9:11:01<1:02:46,  9.63s/it] 91%|█████████ | 4009/4399 [9:11:10<1:01:39,  9.49s/it] 91%|█████████ | 4010/4399 [9:11:19<59:28,  9.17s/it]                                                        91%|█████████ | 4010/4399 [9:11:19<59:28,  9.17s/it] 91%|█████████ | 4011/4399 [9:11:26<55:03,  8.52s/it] 91%|█████████ | 4012/4399 [9:11:35<56:20,  8.74s/it] 91%|█████████ | 4013/4399 [9:11:43<54:40,  8.50s/it] 91%|█████████ | 4014/4399 [9:11:51<54:11,  8.44s/it] 91%|███
 0: {'loss': 0.5694, 'grad_norm': 1.391003236899912, 'learning_rate': 2.2560185459656714e-07, 'epoch': 0.91}
 0: █████▏| 4015/4399 [9:12:00<54:09,  8.46s/it] 91%|█████████▏| 4016/4399 [9:12:08<53:29,  8.38s/it] 91%|█████████▏| 4017/4399 [9:12:17<55:14,  8.68s/it] 91%|█████████▏| 4018/4399 [9:12:25<52:30,  8.27s/it] 91%|█████████▏| 4019/4399 [9:12:33<52:34,  8.30s/it] 91%|█████████▏| 4020/4399 [9:12:42<53:12,  8.42s/it]                                                      91%|█████████▏| 4020/4399 [9:12:42<53:12,  8.42s/it] 91%|█████████▏| 4021/4399 [9:12:50<52:55,  8.40s/it] 91%|█████████▏| 4022/4399 [9:12:59<53:28,  8.51s/it] 91%|█████████▏| 4023/4399 [9:13:09<55:26,  8.85s/it] 91%|█████████▏| 4024/4399 [9:13:18<55:45,  8.92s/it] 91%|█████████▏| 4025/4399 [9:13:27<56:58,  9.14s/it] 92%|█████████▏| 4026/4399 [9:13:34<52:52,  8.51s/it] 92%|██████
 0: {'loss': 0.5771, 'grad_norm': 1.5628804106283278, 'learning_rate': 2.1396862376015904e-07, 'epoch': 0.92}
 0: ███▏| 4027/4399 [9:13:43<52:13,  8.42s/it] 92%|█████████▏| 4028/4399 [9:13:51<51:08,  8.27s/it] 92%|█████████▏| 4029/4399 [9:13:58<49:37,  8.05s/it] 92%|█████████▏| 4030/4399 [9:14:06<50:04,  8.14s/it]                                                      92%|█████████▏| 4030/4399 [9:14:06<50:04,  8.14s/it] 92%|█████████▏| 4031/4399 [9:14:15<50:12,  8.19s/it] 92%|█████████▏| 4032/4399 [9:14:22<48:58,  8.01s/it] 92%|█████████▏| 4033/4399 [9:14:33<53:16,  8.73s/it] 92%|█████████▏| 4034/4399 [9:14:39<49:34,  8.15s/it] 92%|█████████▏| 4035/4399 [9:14:47<48:46,  8.04s/it] 92%|█████████▏| 4036/4399 [9:14:55<47:56,  7.93s/it] 92%|█████████▏| 4037/4399 [9:15:02<46:52,  7.77s/it] 92%|█████████▏| 4038/4399 [9:15:10<47:00,  7.81s/it] 92%|████████
 0: {'loss': 0.5689, 'grad_norm': 1.5643458692939396, 'learning_rate': 2.0263676430208766e-07, 'epoch': 0.92}
 0: ▏| 4039/4399 [9:15:20<50:04,  8.35s/it] 92%|█████████▏| 4040/4399 [9:15:28<48:44,  8.15s/it]                                                      92%|█████████▏| 4040/4399 [9:15:28<48:44,  8.15s/it] 92%|█████████▏| 4041/4399 [9:15:37<51:20,  8.61s/it] 92%|█████████▏| 4042/4399 [9:15:43<47:02,  7.91s/it] 92%|█████████▏| 4043/4399 [9:15:52<47:34,  8.02s/it] 92%|█████████▏| 4044/4399 [9:16:00<47:18,  8.00s/it] 92%|█████████▏| 4045/4399 [9:16:07<46:40,  7.91s/it] 92%|█████████▏| 4046/4399 [9:16:17<48:44,  8.28s/it] 92%|█████████▏| 4047/4399 [9:16:26<50:01,  8.53s/it] 92%|█████████▏| 4048/4399 [9:16:34<50:03,  8.56s/it] 92%|█████████▏| 4049/4399 [9:16:45<53:15,  9.13s/it] 92%|█████████▏| 4050/4399 [9:16:51<48:28,  8.33s/it]                                     
 0: {'loss': 0.5753, 'grad_norm': 1.4816310021597205, 'learning_rate': 1.91606989777664e-07, 'epoch': 0.92}
 0: {'loss': 0.5615, 'grad_norm': 2.1931852687792515, 'learning_rate': 1.8087999472022666e-07, 'epoch': 0.92}
 0:                  92%|█████████▏| 4050/4399 [9:16:51<48:28,  8.33s/it] 92%|█████████▏| 4051/4399 [9:17:00<48:54,  8.43s/it] 92%|█████████▏| 4052/4399 [9:17:08<47:52,  8.28s/it] 92%|█████████▏| 4053/4399 [9:17:15<46:41,  8.10s/it] 92%|█████████▏| 4054/4399 [9:17:24<46:53,  8.16s/it] 92%|█████████▏| 4055/4399 [9:17:33<48:54,  8.53s/it] 92%|█████████▏| 4056/4399 [9:17:42<49:32,  8.67s/it] 92%|█████████▏| 4057/4399 [9:17:53<53:04,  9.31s/it] 92%|█████████▏| 4058/4399 [9:18:00<49:04,  8.64s/it] 92%|█████████▏| 4059/4399 [9:18:07<46:46,  8.25s/it] 92%|█████████▏| 4060/4399 [9:18:15<44:51,  7.94s/it]                                                      92%|█████████▏| 4060/4399 [9:18:15<44:51,  7.94s/it] 92%|█████████▏| 4061/4399 [9:18:22<43:29, 
 0: {'loss': 0.5795, 'grad_norm': 1.5759656439373093, 'learning_rate': 1.7045645459740912e-07, 'epoch': 0.93}
 0:  7.72s/it] 92%|█████████▏| 4062/4399 [9:18:31<45:17,  8.07s/it] 92%|█████████▏| 4063/4399 [9:18:41<49:08,  8.78s/it] 92%|█████████▏| 4064/4399 [9:18:49<46:49,  8.39s/it] 92%|█████████▏| 4065/4399 [9:18:59<49:19,  8.86s/it] 92%|█████████▏| 4066/4399 [9:19:07<48:14,  8.69s/it] 92%|█████████▏| 4067/4399 [9:19:14<45:36,  8.24s/it] 92%|█████████▏| 4068/4399 [9:19:23<46:56,  8.51s/it] 92%|█████████▏| 4069/4399 [9:19:31<45:31,  8.28s/it] 93%|█████████▎| 4070/4399 [9:19:40<46:14,  8.43s/it]                                                      93%|█████████▎| 4070/4399 [9:19:40<46:14,  8.43s/it] 93%|█████████▎| 4071/4399 [9:19:49<46:55,  8.58s/it] 93%|█████████▎| 4072/4399 [9:19:57<46:42,  8.57s/it] 93%|█████████▎| 4073/4399 [9:20:07<48:37,  8.95s/
 0: {'loss': 0.5768, 'grad_norm': 1.4416277408527556, 'learning_rate': 1.6033702576860487e-07, 'epoch': 0.93}
 0: it] 93%|█████████▎| 4074/4399 [9:20:14<44:59,  8.31s/it] 93%|█████████▎| 4075/4399 [9:20:21<42:34,  7.88s/it] 93%|█████████▎| 4076/4399 [9:20:29<43:46,  8.13s/it] 93%|█████████▎| 4077/4399 [9:20:38<44:12,  8.24s/it] 93%|█████████▎| 4078/4399 [9:20:47<44:55,  8.40s/it] 93%|█████████▎| 4079/4399 [9:20:57<47:07,  8.84s/it] 93%|█████████▎| 4080/4399 [9:21:05<46:29,  8.75s/it]                                                      93%|█████████▎| 4080/4399 [9:21:05<46:29,  8.75s/it] 93%|█████████▎| 4081/4399 [9:21:15<48:08,  9.08s/it] 93%|█████████▎| 4082/4399 [9:21:22<45:04,  8.53s/it] 93%|█████████▎| 4083/4399 [9:21:30<43:47,  8.32s/it] 93%|█████████▎| 4084/4399 [9:21:38<43:28,  8.28s/it] 93%|█████████▎| 4085/4399 [9:21:45<40:23,  7.72s/it] 93
 0: {'loss': 0.5762, 'grad_norm': 1.6555137147607146, 'learning_rate': 1.5052234544363942e-07, 'epoch': 0.93}
 0: %|█████████▎| 4086/4399 [9:21:54<42:16,  8.10s/it] 93%|█████████▎| 4087/4399 [9:22:03<44:36,  8.58s/it] 93%|█████████▎| 4088/4399 [9:22:13<46:42,  9.01s/it] 93%|█████████▎| 4089/4399 [9:22:23<48:15,  9.34s/it] 93%|█████████▎| 4090/4399 [9:22:30<43:50,  8.51s/it]                                                      93%|█████████▎| 4090/4399 [9:22:30<43:50,  8.51s/it] 93%|█████████▎| 4091/4399 [9:22:37<40:59,  7.98s/it] 93%|█████████▎| 4092/4399 [9:22:46<42:02,  8.22s/it] 93%|█████████▎| 4093/4399 [9:22:53<40:27,  7.93s/it] 93%|█████████▎| 4094/4399 [9:23:01<41:01,  8.07s/it] 93%|█████████▎| 4095/4399 [9:23:10<42:39,  8.42s/it] 93%|█████████▎| 4096/4399 [9:23:19<42:13,  8.36s/it] 93%|█████████▎| 4097/4399 [9:23:28<43:32,  8.65s/it] 93%|█
 0: {'loss': 0.5607, 'grad_norm': 1.6906440830983571, 'learning_rate': 1.4101303164264223e-07, 'epoch': 0.93}
 0: ███████▎| 4098/4399 [9:23:35<41:12,  8.21s/it] 93%|█████████▎| 4099/4399 [9:23:43<40:01,  8.01s/it] 93%|█████████▎| 4100/4399 [9:23:51<40:37,  8.15s/it]                                                      93%|█████████▎| 4100/4399 [9:23:51<40:37,  8.15s/it] 93%|█████████▎| 4101/4399 [9:23:58<39:01,  7.86s/it] 93%|█████████▎| 4102/4399 [9:24:07<39:34,  7.99s/it] 93%|█████████▎| 4103/4399 [9:24:15<40:00,  8.11s/it] 93%|█████████▎| 4104/4399 [9:24:24<40:36,  8.26s/it] 93%|█████████▎| 4105/4399 [9:24:33<42:21,  8.65s/it] 93%|█████████▎| 4106/4399 [9:24:40<40:10,  8.23s/it] 93%|█████████▎| 4107/4399 [9:24:49<39:53,  8.20s/it] 93%|█████████▎| 4108/4399 [9:24:57<40:09,  8.28s/it] 93%|█████████▎| 4109/4399 [9:25:04<38:28,  7.96s/it] 93%|████
 0: {'loss': 0.5531, 'grad_norm': 1.3600446853002017, 'learning_rate': 1.3180968315713584e-07, 'epoch': 0.93}
 0: {'loss': 0.5577, 'grad_norm': 1.5398595690291013, 'learning_rate': 1.2291287951232467e-07, 'epoch': 0.94}
 0: █████▎| 4110/4399 [9:25:13<39:07,  8.12s/it]                                                      93%|█████████▎| 4110/4399 [9:25:13<39:07,  8.12s/it] 93%|█████████▎| 4111/4399 [9:25:22<40:00,  8.33s/it] 93%|█████████▎| 4112/4399 [9:25:30<39:21,  8.23s/it] 93%|█████████▎| 4113/4399 [9:25:39<40:51,  8.57s/it] 94%|█████████▎| 4114/4399 [9:25:47<40:09,  8.45s/it] 94%|█████████▎| 4115/4399 [9:25:55<39:00,  8.24s/it] 94%|█████████▎| 4116/4399 [9:26:05<41:10,  8.73s/it] 94%|█████████▎| 4117/4399 [9:26:12<39:19,  8.37s/it] 94%|█████████▎| 4118/4399 [9:26:20<38:33,  8.23s/it] 94%|█████████▎| 4119/4399 [9:26:29<38:46,  8.31s/it] 94%|█████████▎| 4120/4399 [9:26:37<38:31,  8.28s/it]                                                      94%|█████████▎| 4120/4
 0: {'loss': 0.5668, 'grad_norm': 1.3674495305738048, 'learning_rate': 1.143231809306089e-07, 'epoch': 0.94}
 0: 399 [9:26:37<38:31,  8.28s/it] 94%|█████████▎| 4121/4399 [9:26:46<39:55,  8.62s/it] 94%|█████████▎| 4122/4399 [9:26:54<37:58,  8.23s/it] 94%|█████████▎| 4123/4399 [9:27:01<36:15,  7.88s/it] 94%|█████████▎| 4124/4399 [9:27:09<36:21,  7.93s/it] 94%|█████████▍| 4125/4399 [9:27:17<36:04,  7.90s/it] 94%|█████████▍| 4126/4399 [9:27:25<36:04,  7.93s/it] 94%|█████████▍| 4127/4399 [9:27:34<38:25,  8.48s/it] 94%|█████████▍| 4128/4399 [9:27:43<38:13,  8.46s/it] 94%|█████████▍| 4129/4399 [9:27:54<41:41,  9.26s/it] 94%|█████████▍| 4130/4399 [9:28:00<37:48,  8.43s/it]                                                      94%|█████████▍| 4130/4399 [9:28:00<37:48,  8.43s/it] 94%|█████████▍| 4131/4399 [9:28:09<37:29,  8.39s/it] 94%|█████████▍| 4132/4399 [9:
 0: {'loss': 0.5476, 'grad_norm': 1.413777797804949, 'learning_rate': 1.0604112829630142e-07, 'epoch': 0.94}
 0: 28:16<36:23,  8.18s/it] 94%|█████████▍| 4133/4399 [9:28:25<37:09,  8.38s/it] 94%|█████████▍| 4134/4399 [9:28:33<36:36,  8.29s/it] 94%|█████████▍| 4135/4399 [9:28:41<36:09,  8.22s/it] 94%|█████████▍| 4136/4399 [9:28:51<37:19,  8.52s/it] 94%|█████████▍| 4137/4399 [9:29:01<39:09,  8.97s/it] 94%|█████████▍| 4138/4399 [9:29:08<36:50,  8.47s/it] 94%|█████████▍| 4139/4399 [9:29:15<35:07,  8.11s/it] 94%|█████████▍| 4140/4399 [9:29:23<34:22,  7.97s/it]                                                      94%|█████████▍| 4140/4399 [9:29:23<34:22,  7.97s/it] 94%|█████████▍| 4141/4399 [9:29:31<34:56,  8.13s/it] 94%|█████████▍| 4142/4399 [9:29:39<34:52,  8.14s/it] 94%|█████████▍| 4143/4399 [9:29:47<34:23,  8.06s/it] 94%|█████████▍| 4144/4399 [9:29:56<3
 0: {'loss': 0.5651, 'grad_norm': 1.6388037455359707, 'learning_rate': 9.806724312157512e-08, 'epoch': 0.94}
 0: 4:48,  8.19s/it] 94%|█████████▍| 4145/4399 [9:30:06<36:54,  8.72s/it] 94%|█████████▍| 4146/4399 [9:30:14<35:41,  8.47s/it] 94%|█████████▍| 4147/4399 [9:30:20<33:30,  7.98s/it] 94%|█████████▍| 4148/4399 [9:30:29<33:59,  8.12s/it] 94%|█████████▍| 4149/4399 [9:30:37<33:32,  8.05s/it] 94%|█████████▍| 4150/4399 [9:30:45<32:57,  7.94s/it]                                                      94%|█████████▍| 4150/4399 [9:30:45<32:57,  7.94s/it] 94%|█████████▍| 4151/4399 [9:30:52<31:56,  7.73s/it] 94%|█████████▍| 4152/4399 [9:31:01<33:14,  8.08s/it] 94%|█████████▍| 4153/4399 [9:31:12<36:53,  9.00s/it] 94%|█████████▍| 4154/4399 [9:31:19<33:58,  8.32s/it] 94%|█████████▍| 4155/4399 [9:31:26<33:15,  8.18s/it] 94%|█████████▍| 4156/4399 [9:31:35<33:32,  
 0: {'loss': 0.5565, 'grad_norm': 1.5340305366118518, 'learning_rate': 9.040202751362026e-08, 'epoch': 0.95}
 0: 8.28s/it] 94%|█████████▍| 4157/4399 [9:31:42<32:13,  7.99s/it] 95%|█████████▍| 4158/4399 [9:31:51<32:58,  8.21s/it] 95%|█████████▍| 4159/4399 [9:31:58<32:03,  8.01s/it] 95%|█████████▍| 4160/4399 [9:32:08<34:08,  8.57s/it]                                                      95%|█████████▍| 4160/4399 [9:32:08<34:08,  8.57s/it] 95%|█████████▍| 4161/4399 [9:32:19<36:06,  9.10s/it] 95%|█████████▍| 4162/4399 [9:32:26<33:27,  8.47s/it] 95%|█████████▍| 4163/4399 [9:32:33<31:57,  8.12s/it] 95%|█████████▍| 4164/4399 [9:32:41<31:49,  8.13s/it] 95%|█████████▍| 4165/4399 [9:32:50<32:18,  8.29s/it] 95%|█████████▍| 4166/4399 [9:32:58<31:34,  8.13s/it] 95%|█████████▍| 4167/4399 [9:33:05<30:40,  7.93s/it] 95%|█████████▍| 4168/4399 [9:33:13<30:52,  8.02s/i
 0: {'loss': 0.574, 'grad_norm': 1.4083554739188306, 'learning_rate': 8.304596414302756e-08, 'epoch': 0.95}
 0: t] 95%|█████████▍| 4169/4399 [9:33:24<33:30,  8.74s/it] 95%|█████████▍| 4170/4399 [9:33:32<32:30,  8.52s/it]                                                      95%|█████████▍| 4170/4399 [9:33:32<32:30,  8.52s/it] 95%|█████████▍| 4171/4399 [9:33:39<31:00,  8.16s/it] 95%|█████████▍| 4172/4399 [9:33:46<29:54,  7.90s/it] 95%|█████████▍| 4173/4399 [9:33:55<31:01,  8.24s/it] 95%|█████████▍| 4174/4399 [9:34:04<31:35,  8.42s/it] 95%|█████████▍| 4175/4399 [9:34:12<30:22,  8.14s/it] 95%|█████████▍| 4176/4399 [9:34:20<29:57,  8.06s/it] 95%|█████████▍| 4177/4399 [9:34:30<32:16,  8.72s/it] 95%|█████████▍| 4178/4399 [9:34:37<30:08,  8.18s/it] 95%|█████████▍| 4179/4399 [9:34:44<28:50,  7.87s/it] 95%|█████████▌| 4180/4399 [9:34:52<28:46,  7.88s/it]    
 0: {'loss': 0.5687, 'grad_norm': 1.469126010059308, 'learning_rate': 7.59995162133953e-08, 'epoch': 0.95}
 0: {'loss': 0.5606, 'grad_norm': 1.5289697218085638, 'learning_rate': 6.926312743216312e-08, 'epoch': 0.95}
 0:                                                   95%|█████████▌| 4180/4399 [9:34:52<28:46,  7.88s/it] 95%|█████████▌| 4181/4399 [9:35:00<28:48,  7.93s/it] 95%|█████████▌| 4182/4399 [9:35:08<28:29,  7.88s/it] 95%|█████████▌| 4183/4399 [9:35:16<28:47,  8.00s/it] 95%|█████████▌| 4184/4399 [9:35:24<29:17,  8.18s/it] 95%|█████████▌| 4185/4399 [9:35:35<31:51,  8.93s/it] 95%|█████████▌| 4186/4399 [9:35:44<31:47,  8.95s/it] 95%|█████████▌| 4187/4399 [9:35:51<29:41,  8.40s/it] 95%|█████████▌| 4188/4399 [9:35:59<28:54,  8.22s/it] 95%|█████████▌| 4189/4399 [9:36:07<28:08,  8.04s/it] 95%|█████████▌| 4190/4399 [9:36:14<27:14,  7.82s/it]                                                      95%|█████████▌| 4190/4399 [9:36:14<27:14,  7.82s/it] 95%|████████
 0: {'loss': 0.5737, 'grad_norm': 1.580689682218317, 'learning_rate': 6.283722198267061e-08, 'epoch': 0.95}
 0: ▌| 4191/4399 [9:36:22<27:01,  7.80s/it] 95%|█████████▌| 4192/4399 [9:36:30<27:54,  8.09s/it] 95%|█████████▌| 4193/4399 [9:36:41<29:54,  8.71s/it] 95%|█████████▌| 4194/4399 [9:36:49<29:33,  8.65s/it] 95%|█████████▌| 4195/4399 [9:36:56<27:21,  8.05s/it] 95%|█████████▌| 4196/4399 [9:37:04<27:21,  8.09s/it] 95%|█████████▌| 4197/4399 [9:37:11<26:26,  7.85s/it] 95%|█████████▌| 4198/4399 [9:37:18<25:32,  7.62s/it] 95%|█████████▌| 4199/4399 [9:37:27<26:01,  7.81s/it] 95%|█████████▌| 4200/4399 [9:37:35<26:55,  8.12s/it]                                                      95%|█████████▌| 4200/4399 [9:37:35<26:55,  8.12s/it] 95%|█████████▌| 4201/4399 [9:37:47<29:48,  9.03s/it] 96%|█████████▌| 4202/4399 [9:37:54<28:14,  8.60s/it] 96%|█████████▌| 
 0: {'loss': 0.5743, 'grad_norm': 1.364445456502324, 'learning_rate': 5.672220449744692e-08, 'epoch': 0.96}
 0: 4203/4399 [9:38:02<27:17,  8.35s/it] 96%|█████████▌| 4204/4399 [9:38:11<27:32,  8.47s/it] 96%|█████████▌| 4205/4399 [9:38:19<27:32,  8.52s/it] 96%|█████████▌| 4206/4399 [9:38:27<26:29,  8.24s/it] 96%|█████████▌| 4207/4399 [9:38:35<26:22,  8.24s/it] 96%|█████████▌| 4208/4399 [9:38:44<26:37,  8.36s/it] 96%|█████████▌| 4209/4399 [9:38:54<28:02,  8.85s/it] 96%|█████████▌| 4210/4399 [9:39:02<26:49,  8.52s/it]                                                      96%|█████████▌| 4210/4399 [9:39:02<26:49,  8.52s/it] 96%|█████████▌| 4211/4399 [9:39:08<25:03,  8.00s/it] 96%|█████████▌| 4212/4399 [9:39:16<24:25,  7.84s/it] 96%|█████████▌| 4213/4399 [9:39:24<25:03,  8.08s/it] 96%|█████████▌| 4214/4399 [9:39:32<24:30,  7.95s/it] 96%|█████████▌| 4215/43
 0: {'loss': 0.5586, 'grad_norm': 1.6965941960077662, 'learning_rate': 5.0918460032732266e-08, 'epoch': 0.96}
 0: 99 [9:39:41<25:06,  8.19s/it] 96%|█████████▌| 4216/4399 [9:39:48<24:17,  7.96s/it] 96%|█████████▌| 4217/4399 [9:39:59<26:44,  8.82s/it] 96%|█████████▌| 4218/4399 [9:40:07<25:49,  8.56s/it] 96%|█████████▌| 4219/4399 [9:40:14<24:10,  8.06s/it] 96%|█████████▌| 4220/4399 [9:40:22<23:38,  7.93s/it]                                                      96%|█████████▌| 4220/4399 [9:40:22<23:38,  7.93s/it] 96%|█████████▌| 4221/4399 [9:40:30<23:52,  8.05s/it] 96%|█████████▌| 4222/4399 [9:40:38<23:27,  7.95s/it] 96%|█████████▌| 4223/4399 [9:40:47<24:16,  8.27s/it] 96%|█████████▌| 4224/4399 [9:40:55<24:05,  8.26s/it] 96%|█████████▌| 4225/4399 [9:41:06<26:26,  9.12s/it] 96%|█████████▌| 4226/4399 [9:41:14<25:32,  8.86s/it] 96%|█████████▌| 4227/4399 [9:4
 0: {'loss': 0.5735, 'grad_norm': 1.5970405661800122, 'learning_rate': 4.5426354044232345e-08, 'epoch': 0.96}
 0: 1:20<23:05,  8.06s/it] 96%|█████████▌| 4228/4399 [9:41:29<23:47,  8.35s/it] 96%|█████████▌| 4229/4399 [9:41:37<23:03,  8.14s/it] 96%|█████████▌| 4230/4399 [9:41:46<23:20,  8.29s/it]                                                      96%|█████████▌| 4230/4399 [9:41:46<23:20,  8.29s/it] 96%|█████████▌| 4231/4399 [9:41:53<22:37,  8.08s/it] 96%|█████████▌| 4232/4399 [9:42:02<22:55,  8.24s/it] 96%|█████████▌| 4233/4399 [9:42:12<24:34,  8.88s/it] 96%|█████████▌| 4234/4399 [9:42:20<23:08,  8.42s/it] 96%|█████████▋| 4235/4399 [9:42:26<21:36,  7.91s/it] 96%|█████████▋| 4236/4399 [9:42:35<21:55,  8.07s/it] 96%|█████████▋| 4237/4399 [9:42:42<21:09,  7.83s/it] 96%|█████████▋| 4238/4399 [9:42:50<20:47,  7.75s/it] 96%|█████████▋| 4239/4399 [9:42:58<20
 0: {'loss': 0.5602, 'grad_norm': 1.258569588373073, 'learning_rate': 4.024623236410175e-08, 'epoch': 0.96}
 0: {'loss': 0.5597, 'grad_norm': 1.5164139389764577, 'learning_rate': 3.537842117917356e-08, 'epoch': 0.97}
 0: :53,  7.84s/it] 96%|█████████▋| 4240/4399 [9:43:06<21:18,  8.04s/it]                                                      96%|█████████▋| 4240/4399 [9:43:06<21:18,  8.04s/it] 96%|█████████▋| 4241/4399 [9:43:16<22:22,  8.50s/it] 96%|█████████▋| 4242/4399 [9:43:24<21:51,  8.35s/it] 96%|█████████▋| 4243/4399 [9:43:31<21:09,  8.14s/it] 96%|█████████▋| 4244/4399 [9:43:39<20:26,  7.91s/it] 96%|█████████▋| 4245/4399 [9:43:46<20:02,  7.81s/it] 97%|█████████▋| 4246/4399 [9:43:54<19:55,  7.81s/it] 97%|█████████▋| 4247/4399 [9:44:03<20:49,  8.22s/it] 97%|█████████▋| 4248/4399 [9:44:11<20:26,  8.12s/it] 97%|█████████▋| 4249/4399 [9:44:22<21:59,  8.80s/it] 97%|█████████▋| 4250/4399 [9:44:29<20:49,  8.38s/it]                                                      97%|█
 0: {'loss': 0.5666, 'grad_norm': 1.4686359247508338, 'learning_rate': 3.0823227010414734e-08, 'epoch': 0.97}
 0: ███████▋| 4250/4399 [9:44:29<20:49,  8.38s/it] 97%|█████████▋| 4251/4399 [9:44:36<19:56,  8.09s/it] 97%|█████████▋| 4252/4399 [9:44:44<19:19,  7.89s/it] 97%|█████████▋| 4253/4399 [9:44:53<19:54,  8.18s/it] 97%|█████████▋| 4254/4399 [9:45:00<19:19,  8.00s/it] 97%|█████████▋| 4255/4399 [9:45:09<19:36,  8.17s/it] 97%|█████████▋| 4256/4399 [9:45:17<19:38,  8.24s/it] 97%|█████████▋| 4257/4399 [9:45:27<20:41,  8.74s/it] 97%|█████████▋| 4258/4399 [9:45:35<19:35,  8.34s/it] 97%|█████████▋| 4259/4399 [9:45:41<18:24,  7.89s/it] 97%|█████████▋| 4260/4399 [9:45:51<19:18,  8.34s/it]                                                      97%|█████████▋| 4260/4399 [9:45:51<19:18,  8.34s/it] 97%|█████████▋| 4261/4399 [9:45:59<19:00,  8.26s/it] 97%|████
 0: {'loss': 0.5889, 'grad_norm': 1.3892592089258622, 'learning_rate': 2.658093669362649e-08, 'epoch': 0.97}
 0: █████▋| 4262/4399 [9:46:06<18:23,  8.06s/it] 97%|█████████▋| 4263/4399 [9:46:14<18:03,  7.97s/it] 97%|█████████▋| 4264/4399 [9:46:22<18:01,  8.01s/it] 97%|█████████▋| 4265/4399 [9:46:32<18:42,  8.38s/it] 97%|█████████▋| 4266/4399 [9:46:39<18:06,  8.17s/it] 97%|█████████▋| 4267/4399 [9:46:46<17:12,  7.82s/it] 97%|█████████▋| 4268/4399 [9:46:55<17:22,  7.96s/it] 97%|█████████▋| 4269/4399 [9:47:03<17:25,  8.04s/it] 97%|█████████▋| 4270/4399 [9:47:10<17:02,  7.93s/it]                                                      97%|█████████▋| 4270/4399 [9:47:10<17:02,  7.93s/it] 97%|█████████▋| 4271/4399 [9:47:18<16:35,  7.77s/it] 97%|█████████▋| 4272/4399 [9:47:27<17:03,  8.06s/it] 97%|█████████▋| 4273/4399 [9:47:37<18:09,  8.65s/it] 97%|██████
 0: {'loss': 0.5653, 'grad_norm': 1.359588888957419, 'learning_rate': 2.2651817361382667e-08, 'epoch': 0.97}
 0: ██▋| 4274/4399 [9:47:44<17:23,  8.35s/it] 97%|█████████▋| 4275/4399 [9:47:51<16:24,  7.94s/it] 97%|█████████▋| 4276/4399 [9:47:59<16:07,  7.86s/it] 97%|█████████▋| 4277/4399 [9:48:08<16:28,  8.10s/it] 97%|█████████▋| 4278/4399 [9:48:15<16:10,  8.02s/it] 97%|█████████▋| 4279/4399 [9:48:23<16:01,  8.02s/it] 97%|█████████▋| 4280/4399 [9:48:32<16:10,  8.16s/it]                                                      97%|█████████▋| 4280/4399 [9:48:32<16:10,  8.16s/it] 97%|█████████▋| 4281/4399 [9:48:42<16:57,  8.62s/it] 97%|█████████▋| 4282/4399 [9:48:51<17:01,  8.73s/it] 97%|█████████▋| 4283/4399 [9:48:58<15:49,  8.19s/it] 97%|█████████▋| 4284/4399 [9:49:05<15:24,  8.04s/it] 97%|█████████▋| 4285/4399 [9:49:14<15:46,  8.30s/it] 97%|████████
 0: {'loss': 0.5725, 'grad_norm': 3.115042690130806, 'learning_rate': 1.9036116426208172e-08, 'epoch': 0.98}
 0: ▋| 4286/4399 [9:49:22<15:26,  8.20s/it] 97%|█████████▋| 4287/4399 [9:49:30<15:02,  8.05s/it] 97%|█████████▋| 4288/4399 [9:49:38<15:11,  8.21s/it] 97%|█████████▋| 4289/4399 [9:49:48<15:50,  8.64s/it] 98%|█████████▊| 4290/4399 [9:49:57<15:46,  8.68s/it]                                                      98%|█████████▊| 4290/4399 [9:49:57<15:46,  8.68s/it] 98%|█████████▊| 4291/4399 [9:50:04<14:35,  8.11s/it] 98%|█████████▊| 4292/4399 [9:50:11<14:09,  7.94s/it] 98%|█████████▊| 4293/4399 [9:50:20<14:22,  8.13s/it] 98%|█████████▊| 4294/4399 [9:50:27<13:50,  7.91s/it] 98%|█████████▊| 4295/4399 [9:50:34<13:19,  7.69s/it] 98%|█████████▊| 4296/4399 [9:50:43<13:53,  8.09s/it] 98%|█████████▊| 4297/4399 [9:50:53<14:20,  8.43s/it] 98%|█████████▊| 4
 0: {'loss': 0.5668, 'grad_norm': 1.8688522191237535, 'learning_rate': 1.5734061565000903e-08, 'epoch': 0.98}
 0: 298/4399 [9:51:02<14:28,  8.60s/it] 98%|█████████▊| 4299/4399 [9:51:08<13:18,  7.98s/it] 98%|█████████▊| 4300/4399 [9:51:15<12:48,  7.76s/it]                                                      98%|█████████▊| 4300/4399 [9:51:15<12:48,  7.76s/it] 98%|█████████▊| 4301/4399 [9:51:24<13:11,  8.08s/it] 98%|█████████▊| 4302/4399 [9:51:32<12:47,  7.91s/it] 98%|█████████▊| 4303/4399 [9:51:41<13:12,  8.26s/it] 98%|█████████▊| 4304/4399 [9:51:51<14:11,  8.97s/it] 98%|█████████▊| 4305/4399 [9:52:00<14:00,  8.94s/it] 98%|█████████▊| 4306/4399 [9:52:08<13:31,  8.73s/it] 98%|█████████▊| 4307/4399 [9:52:15<12:30,  8.16s/it] 98%|█████████▊| 4308/4399 [9:52:22<11:49,  7.80s/it] 98%|█████████▊| 4309/4399 [9:52:31<12:09,  8.10s/it] 98%|█████████▊| 4310/439
 0: {'loss': 0.5659, 'grad_norm': 1.5821493053288145, 'learning_rate': 1.2745860704693746e-08, 'epoch': 0.98}
 0: {'loss': 0.5738, 'grad_norm': 1.493185874641736, 'learning_rate': 1.0071702009161743e-08, 'epoch': 0.98}
 0: 9 [9:52:38<11:41,  7.88s/it]                                                      98%|█████████▊| 4310/4399 [9:52:38<11:41,  7.88s/it] 98%|█████████▊| 4311/4399 [9:52:49<12:36,  8.59s/it] 98%|█████████▊| 4312/4399 [9:52:58<12:40,  8.74s/it] 98%|█████████▊| 4313/4399 [9:53:07<12:46,  8.91s/it] 98%|█████████▊| 4314/4399 [9:53:16<12:25,  8.77s/it] 98%|█████████▊| 4315/4399 [9:53:23<11:32,  8.25s/it] 98%|█████████▊| 4316/4399 [9:53:30<10:52,  7.86s/it] 98%|█████████▊| 4317/4399 [9:53:38<10:55,  8.00s/it] 98%|█████████▊| 4318/4399 [9:53:46<10:44,  7.96s/it] 98%|█████████▊| 4319/4399 [9:53:53<10:29,  7.87s/it] 98%|█████████▊| 4320/4399 [9:54:03<10:58,  8.34s/it]                                                      98%|█████████▊| 4320/4399 [9:54:03<10:58,  8.34s/i
 0: {'loss': 0.5728, 'grad_norm': 1.4820964023191343, 'learning_rate': 7.711753867374882e-09, 'epoch': 0.98}
 0: t] 98%|█████████▊| 4321/4399 [9:54:11<10:58,  8.44s/it] 98%|█████████▊| 4322/4399 [9:54:21<11:08,  8.68s/it] 98%|█████████▊| 4323/4399 [9:54:27<10:15,  8.10s/it] 98%|█████████▊| 4324/4399 [9:54:34<09:37,  7.70s/it] 98%|█████████▊| 4325/4399 [9:54:43<09:57,  8.07s/it] 98%|█████████▊| 4326/4399 [9:54:51<09:54,  8.15s/it] 98%|█████████▊| 4327/4399 [9:54:59<09:26,  7.87s/it] 98%|█████████▊| 4328/4399 [9:55:09<10:01,  8.48s/it] 98%|█████████▊| 4329/4399 [9:55:17<09:54,  8.49s/it] 98%|█████████▊| 4330/4399 [9:55:26<09:56,  8.64s/it]                                                      98%|█████████▊| 4330/4399 [9:55:26<09:56,  8.64s/it] 98%|█████████▊| 4331/4399 [9:55:33<09:14,  8.15s/it] 98%|█████████▊| 4332/4399 [9:55:40<08:46,  7.86s/it] 98%
 0: {'loss': 0.5696, 'grad_norm': 1.6486791558932954, 'learning_rate': 5.666164882793257e-09, 'epoch': 0.99}
 0: |█████████▊| 4333/4399 [9:55:50<09:06,  8.28s/it] 99%|█████████▊| 4334/4399 [9:55:57<08:51,  8.17s/it] 99%|█████████▊| 4335/4399 [9:56:06<08:42,  8.17s/it] 99%|█████████▊| 4336/4399 [9:56:15<09:06,  8.67s/it] 99%|█████████▊| 4337/4399 [9:56:23<08:44,  8.46s/it] 99%|█████████▊| 4338/4399 [9:56:33<08:47,  8.65s/it] 99%|█████████▊| 4339/4399 [9:56:39<08:02,  8.05s/it] 99%|█████████▊| 4340/4399 [9:56:46<07:35,  7.73s/it]                                                      99%|█████████▊| 4340/4399 [9:56:46<07:35,  7.73s/it] 99%|█████████▊| 4341/4399 [9:56:55<07:48,  8.07s/it] 99%|█████████▊| 4342/4399 [9:57:03<07:38,  8.04s/it] 99%|█████████▊| 4343/4399 [9:57:11<07:34,  8.11s/it] 99%|█████████▊| 4344/4399 [9:57:20<07:40,  8.37s/it] 99%|██
 0: {'loss': 0.5697, 'grad_norm': 1.6801638366796614, 'learning_rate': 3.935063864011768e-09, 'epoch': 0.99}
 0: ███████▉| 4345/4399 [9:57:29<07:38,  8.49s/it] 99%|█████████▉| 4346/4399 [9:57:38<07:33,  8.56s/it] 99%|█████████▉| 4347/4399 [9:57:45<06:59,  8.07s/it] 99%|█████████▉| 4348/4399 [9:57:51<06:27,  7.59s/it] 99%|█████████▉| 4349/4399 [9:58:00<06:37,  7.95s/it] 99%|█████████▉| 4350/4399 [9:58:08<06:32,  8.01s/it]                                                      99%|█████████▉| 4350/4399 [9:58:08<06:32,  8.01s/it] 99%|█████████▉| 4351/4399 [9:58:16<06:26,  8.05s/it] 99%|█████████▉| 4352/4399 [9:58:24<06:21,  8.11s/it] 99%|█████████▉| 4353/4399 [9:58:34<06:38,  8.67s/it] 99%|█████████▉| 4354/4399 [9:58:44<06:44,  8.99s/it] 99%|█████████▉| 4355/4399 [9:58:51<06:05,  8.30s/it] 99%|█████████▉| 4356/4399 [9:58:58<05:35,  7.80s/it] 99%|████
 0: {'loss': 0.5719, 'grad_norm': 1.6646592408000405, 'learning_rate': 2.518559816645505e-09, 'epoch': 0.99}
 0: ████▉| 4357/4399 [9:59:07<05:46,  8.24s/it] 99%|█████████▉| 4358/4399 [9:59:14<05:22,  7.87s/it] 99%|█████████▉| 4359/4399 [9:59:22<05:20,  8.02s/it] 99%|█████████▉| 4360/4399 [9:59:31<05:26,  8.37s/it]                                                      99%|█████████▉| 4360/4399 [9:59:31<05:26,  8.37s/it] 99%|█████████▉| 4361/4399 [9:59:42<05:43,  9.05s/it] 99%|█████████▉| 4362/4399 [9:59:51<05:29,  8.89s/it] 99%|█████████▉| 4363/4399 [9:59:58<05:06,  8.52s/it] 99%|█████████▉| 4364/4399 [10:00:05<04:43,  8.11s/it] 99%|█████████▉| 4365/4399 [10:00:15<04:55,  8.68s/it] 99%|█████████▉| 4366/4399 [10:00:23<04:33,  8.29s/it] 99%|█████████▉| 4367/4399 [10:00:31<04:22,  8.21s/it] 99%|█████████▉| 4368/4399 [10:00:40<04:21,  8.45s/it] 99%|█████
 0: {'loss': 0.5642, 'grad_norm': 1.5692321584438806, 'learning_rate': 1.416741936469679e-09, 'epoch': 0.99}
 0: ████▉| 4369/4399 [10:00:49<04:21,  8.72s/it] 99%|█████████▉| 4370/4399 [10:00:58<04:11,  8.69s/it]                                                       99%|█████████▉| 4370/4399 [10:00:58<04:11,  8.69s/it] 99%|█████████▉| 4371/4399 [10:01:04<03:45,  8.04s/it] 99%|█████████▉| 4372/4399 [10:01:12<03:33,  7.90s/it] 99%|█████████▉| 4373/4399 [10:01:20<03:30,  8.11s/it] 99%|█████████▉| 4374/4399 [10:01:28<03:17,  7.90s/it] 99%|█████████▉| 4375/4399 [10:01:36<03:09,  7.90s/it] 99%|█████████▉| 4376/4399 [10:01:45<03:08,  8.19s/it] 99%|█████████▉| 4377/4399 [10:01:54<03:06,  8.49s/it]100%|█████████▉| 4378/4399 [10:02:02<02:59,  8.53s/it]100%|█████████▉| 4379/4399 [10:02:09<02:41,  8.08s/it]100%|█████████▉| 4380/4399 [10:02:17<02:30,  7.94s/it]             
 0: {'loss': 0.559, 'grad_norm': 1.493459330244251, 'learning_rate': 6.296796038018915e-10, 'epoch': 1.0}
 0: {'loss': 0.5676, 'grad_norm': 1.6442568676451368, 'learning_rate': 1.5742237913118908e-10, 'epoch': 1.0}
 0:                                          100%|█████████▉| 4380/4399 [10:02:17<02:30,  7.94s/it]100%|█████████▉| 4381/4399 [10:02:25<02:24,  8.03s/it]100%|█████████▉| 4382/4399 [10:02:34<02:17,  8.11s/it]100%|█████████▉| 4383/4399 [10:02:42<02:09,  8.09s/it]100%|█████████▉| 4384/4399 [10:02:51<02:08,  8.59s/it]100%|█████████▉| 4385/4399 [10:03:00<01:59,  8.54s/it]100%|█████████▉| 4386/4399 [10:03:08<01:50,  8.51s/it]100%|█████████▉| 4387/4399 [10:03:15<01:35,  7.97s/it]100%|█████████▉| 4388/4399 [10:03:22<01:23,  7.56s/it]100%|█████████▉| 4389/4399 [10:03:30<01:18,  7.88s/it]100%|█████████▉| 4390/4399 [10:03:38<01:09,  7.74s/it]                                                      100%|█████████▉| 4390/4399 [10:03:38<01:09,  7.74s/it]100%|██████
 0: ██▉| 4391/4399 [10:03:46<01:03,  7.90s/it]100%|█████████▉| 4392/4399 [10:03:56<00:59,  8.52s/it]100%|█████████▉| 4393/4399 [10:04:06<00:53,  8.87s/it]100%|█████████▉| 4394/4399 [10:04:14<00:43,  8.77s/it]100%|█████████▉| 4395/4399 [10:04:21<00:32,  8.09s/it]100%|█████████▉| 4396/4399 [10:04:28<00:23,  7.84s/it]100%|█████████▉| 4397/4399 [10:04:35<00:15,  7.76s/it]100%|█████████▉| 4398/4399 [10:04:42<00:07,  7.53s/it]100%|██████████| 4399/4399 [10:04:50<00:00,  7.57s/it][INFO|trainer.py:3984] 2025-06-28 07:09:11,629 >> Saving model checkpoint to /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399
 0: [INFO|configuration_utils.py:419] 2025-06-28 07:09:11,635 >> Configuration saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/config.json
 0: [INFO|configuration_utils.py:911] 2025-06-28 07:09:11,638 >> Configuration saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/generation_config.json
 0: [INFO|modeling_utils.py:3580] 2025-06-28 07:09:18,429 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 4 checkpoint shards. You can find where each parameters has been saved in the index located at /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/model.safetensors.index.json.
 0: [INFO|tokenization_utils_base.py:2510] 2025-06-28 07:09:18,432 >> tokenizer config file saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/tokenizer_config.json
 0: [INFO|tokenization_utils_base.py:2519] 2025-06-28 07:09:18,435 >> Special tokens file saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/special_tokens_map.json
 0: [2025-06-28 07:09:18,660] [INFO] [logging.py:107:log_dist] [Rank 0] [Torch] Checkpoint global_step4399 is about to be saved!
30: [2025-06-28 07:09:18,672] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_120_mp_rank_00_model_states.pt...
 0: [2025-06-28 07:09:18,673] [INFO] [logging.py:107:log_dist] [Rank 0] Saving model checkpoint: /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_0_mp_rank_00_model_states.pt
 9: [2025-06-28 07:09:18,672] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_36_mp_rank_00_model_states.pt...
22: [2025-06-28 07:09:18,672] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_88_mp_rank_00_model_states.pt...
25: [2025-06-28 07:09:18,673] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_100_mp_rank_00_model_states.pt...
 5: [2025-06-28 07:09:18,673] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_20_mp_rank_00_model_states.pt...
 0: [2025-06-28 07:09:18,673] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_0_mp_rank_00_model_states.pt...
23: [2025-06-28 07:09:18,673] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_92_mp_rank_00_model_states.pt...
 4: [2025-06-28 07:09:18,673] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_16_mp_rank_00_model_states.pt...
14: [2025-06-28 07:09:18,673] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_56_mp_rank_00_model_states.pt...
28: [2025-06-28 07:09:18,673] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_112_mp_rank_00_model_states.pt...
24: [2025-06-28 07:09:18,673] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_96_mp_rank_00_model_states.pt...
15: [2025-06-28 07:09:18,673] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_60_mp_rank_00_model_states.pt...
10: [2025-06-28 07:09:18,673] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_40_mp_rank_00_model_states.pt...
18: [2025-06-28 07:09:18,673] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_72_mp_rank_00_model_states.pt...
20: [2025-06-28 07:09:18,673] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_80_mp_rank_00_model_states.pt...
 2: [2025-06-28 07:09:18,673] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_8_mp_rank_00_model_states.pt...
29: [2025-06-28 07:09:18,673] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_116_mp_rank_00_model_states.pt...
19: [2025-06-28 07:09:18,674] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_76_mp_rank_00_model_states.pt...
 6: [2025-06-28 07:09:18,674] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_24_mp_rank_00_model_states.pt...
26: [2025-06-28 07:09:18,674] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_104_mp_rank_00_model_states.pt...
12: [2025-06-28 07:09:18,674] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_48_mp_rank_00_model_states.pt...
 7: [2025-06-28 07:09:18,674] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_28_mp_rank_00_model_states.pt...
31: [2025-06-28 07:09:18,674] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_124_mp_rank_00_model_states.pt...
27: [2025-06-28 07:09:18,674] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_108_mp_rank_00_model_states.pt...
17: [2025-06-28 07:09:18,674] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_68_mp_rank_00_model_states.pt...
 1: [2025-06-28 07:09:18,675] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_4_mp_rank_00_model_states.pt...
13: [2025-06-28 07:09:18,676] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_52_mp_rank_00_model_states.pt...
11: [2025-06-28 07:09:18,676] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_44_mp_rank_00_model_states.pt...
21: [2025-06-28 07:09:18,676] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_84_mp_rank_00_model_states.pt...
16: [2025-06-28 07:09:18,676] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_64_mp_rank_00_model_states.pt...
 3: [2025-06-28 07:09:18,676] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_12_mp_rank_00_model_states.pt...
 8: [2025-06-28 07:09:18,678] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_32_mp_rank_00_model_states.pt...
25: [2025-06-28 07:09:18,700] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_100_mp_rank_00_model_states.pt.
22: [2025-06-28 07:09:18,702] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_88_mp_rank_00_model_states.pt.
 2: [2025-06-28 07:09:18,708] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_8_mp_rank_00_model_states.pt.
 0: [2025-06-28 07:09:18,708] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_0_mp_rank_00_model_states.pt.
30: [2025-06-28 07:09:18,710] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_120_mp_rank_00_model_states.pt.
 4: [2025-06-28 07:09:18,710] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_16_mp_rank_00_model_states.pt.
 6: [2025-06-28 07:09:18,711] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_24_mp_rank_00_model_states.pt.
15: [2025-06-28 07:09:18,711] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_60_mp_rank_00_model_states.pt.
14: [2025-06-28 07:09:18,712] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_56_mp_rank_00_model_states.pt.
23: [2025-06-28 07:09:18,712] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_92_mp_rank_00_model_states.pt.
28: [2025-06-28 07:09:18,713] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_112_mp_rank_00_model_states.pt.
18: [2025-06-28 07:09:18,714] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_72_mp_rank_00_model_states.pt.
27: [2025-06-28 07:09:18,714] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_108_mp_rank_00_model_states.pt.
26: [2025-06-28 07:09:18,715] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_104_mp_rank_00_model_states.pt.
 9: [2025-06-28 07:09:18,715] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_36_mp_rank_00_model_states.pt.
 5: [2025-06-28 07:09:18,718] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_20_mp_rank_00_model_states.pt.
19: [2025-06-28 07:09:18,718] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_76_mp_rank_00_model_states.pt.
 7: [2025-06-28 07:09:18,720] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_28_mp_rank_00_model_states.pt.
29: [2025-06-28 07:09:18,720] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_116_mp_rank_00_model_states.pt.
17: [2025-06-28 07:09:18,723] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_68_mp_rank_00_model_states.pt.
31: [2025-06-28 07:09:18,726] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_124_mp_rank_00_model_states.pt.
12: [2025-06-28 07:09:18,726] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_48_mp_rank_00_model_states.pt.
 1: [2025-06-28 07:09:18,726] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_4_mp_rank_00_model_states.pt.
20: [2025-06-28 07:09:18,727] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_80_mp_rank_00_model_states.pt.
10: [2025-06-28 07:09:18,728] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_40_mp_rank_00_model_states.pt.
 8: [2025-06-28 07:09:18,729] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_32_mp_rank_00_model_states.pt.
21: [2025-06-28 07:09:18,729] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_84_mp_rank_00_model_states.pt.
11: [2025-06-28 07:09:18,730] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_44_mp_rank_00_model_states.pt.
 3: [2025-06-28 07:09:18,730] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_12_mp_rank_00_model_states.pt.
13: [2025-06-28 07:09:18,731] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_52_mp_rank_00_model_states.pt.
16: [2025-06-28 07:09:18,731] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_64_mp_rank_00_model_states.pt.
24: [2025-06-28 07:09:18,917] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/zero_pp_rank_96_mp_rank_00_model_states.pt.
 0: [2025-06-28 07:09:18,956] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
 4: [2025-06-28 07:09:18,956] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_16_mp_rank_00_optim_states.pt...
25: [2025-06-28 07:09:18,956] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_100_mp_rank_00_optim_states.pt...
 9: [2025-06-28 07:09:18,956] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_36_mp_rank_00_optim_states.pt...
15: [2025-06-28 07:09:18,956] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_60_mp_rank_00_optim_states.pt...
 7: [2025-06-28 07:09:18,957] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_28_mp_rank_00_optim_states.pt...
19: [2025-06-28 07:09:18,956] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_76_mp_rank_00_optim_states.pt...
28: [2025-06-28 07:09:18,956] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_112_mp_rank_00_optim_states.pt...
10: [2025-06-28 07:09:18,956] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_40_mp_rank_00_optim_states.pt...
 2: [2025-06-28 07:09:18,956] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_8_mp_rank_00_optim_states.pt...
16: [2025-06-28 07:09:18,957] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_64_mp_rank_00_optim_states.pt...
 8: [2025-06-28 07:09:18,957] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_32_mp_rank_00_optim_states.pt...
 6: [2025-06-28 07:09:18,956] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_24_mp_rank_00_optim_states.pt...
22: [2025-06-28 07:09:18,956] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_88_mp_rank_00_optim_states.pt...
31: [2025-06-28 07:09:18,956] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_124_mp_rank_00_optim_states.pt...
12: [2025-06-28 07:09:18,956] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_48_mp_rank_00_optim_states.pt...
 1: [2025-06-28 07:09:18,957] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_4_mp_rank_00_optim_states.pt...
 3: [2025-06-28 07:09:18,957] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_12_mp_rank_00_optim_states.pt...
 5: [2025-06-28 07:09:18,956] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_20_mp_rank_00_optim_states.pt...
21: [2025-06-28 07:09:18,957] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_84_mp_rank_00_optim_states.pt...
30: [2025-06-28 07:09:18,956] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_120_mp_rank_00_optim_states.pt...
14: [2025-06-28 07:09:18,956] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_56_mp_rank_00_optim_states.pt...
17: [2025-06-28 07:09:18,956] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_68_mp_rank_00_optim_states.pt...
20: [2025-06-28 07:09:18,956] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_80_mp_rank_00_optim_states.pt...
26: [2025-06-28 07:09:18,956] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_104_mp_rank_00_optim_states.pt...
29: [2025-06-28 07:09:18,956] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_116_mp_rank_00_optim_states.pt...
24: [2025-06-28 07:09:18,956] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_96_mp_rank_00_optim_states.pt...
18: [2025-06-28 07:09:18,956] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_72_mp_rank_00_optim_states.pt...
23: [2025-06-28 07:09:18,956] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_92_mp_rank_00_optim_states.pt...
13: [2025-06-28 07:09:18,957] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_52_mp_rank_00_optim_states.pt...
11: [2025-06-28 07:09:18,957] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_44_mp_rank_00_optim_states.pt...
27: [2025-06-28 07:09:18,957] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_108_mp_rank_00_optim_states.pt...
 0: [2025-06-28 07:09:19,431] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
 0: [2025-06-28 07:09:19,437] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
26: [2025-06-28 07:09:21,686] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_104_mp_rank_00_optim_states.pt.
26: [2025-06-28 07:09:21,686] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_104_mp_rank_00_optim_states.pt
 1: [2025-06-28 07:09:21,712] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_4_mp_rank_00_optim_states.pt.
 1: [2025-06-28 07:09:21,712] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_4_mp_rank_00_optim_states.pt
15: [2025-06-28 07:09:21,723] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_60_mp_rank_00_optim_states.pt.
15: [2025-06-28 07:09:21,723] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_60_mp_rank_00_optim_states.pt
 3: [2025-06-28 07:09:21,724] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_12_mp_rank_00_optim_states.pt.
 3: [2025-06-28 07:09:21,724] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_12_mp_rank_00_optim_states.pt
19: [2025-06-28 07:09:21,753] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_76_mp_rank_00_optim_states.pt.
19: [2025-06-28 07:09:21,754] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_76_mp_rank_00_optim_states.pt
 9: [2025-06-28 07:09:21,759] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_36_mp_rank_00_optim_states.pt.
 9: [2025-06-28 07:09:21,759] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_36_mp_rank_00_optim_states.pt
13: [2025-06-28 07:09:21,760] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_52_mp_rank_00_optim_states.pt.
13: [2025-06-28 07:09:21,761] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_52_mp_rank_00_optim_states.pt
16: [2025-06-28 07:09:21,761] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_64_mp_rank_00_optim_states.pt.
16: [2025-06-28 07:09:21,761] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_64_mp_rank_00_optim_states.pt
22: [2025-06-28 07:09:21,761] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_88_mp_rank_00_optim_states.pt.
22: [2025-06-28 07:09:21,761] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_88_mp_rank_00_optim_states.pt
 6: [2025-06-28 07:09:21,761] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_24_mp_rank_00_optim_states.pt.
 6: [2025-06-28 07:09:21,762] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_24_mp_rank_00_optim_states.pt
31: [2025-06-28 07:09:21,762] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_124_mp_rank_00_optim_states.pt.
31: [2025-06-28 07:09:21,762] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_124_mp_rank_00_optim_states.pt
11: [2025-06-28 07:09:21,765] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_44_mp_rank_00_optim_states.pt.
11: [2025-06-28 07:09:21,766] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_44_mp_rank_00_optim_states.pt
10: [2025-06-28 07:09:21,764] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_40_mp_rank_00_optim_states.pt.
10: [2025-06-28 07:09:21,764] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_40_mp_rank_00_optim_states.pt
18: [2025-06-28 07:09:21,767] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_72_mp_rank_00_optim_states.pt.
18: [2025-06-28 07:09:21,767] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_72_mp_rank_00_optim_states.pt
28: [2025-06-28 07:09:21,770] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_112_mp_rank_00_optim_states.pt.
28: [2025-06-28 07:09:21,770] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_112_mp_rank_00_optim_states.pt
14: [2025-06-28 07:09:21,771] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_56_mp_rank_00_optim_states.pt.
14: [2025-06-28 07:09:21,772] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_56_mp_rank_00_optim_states.pt
12: [2025-06-28 07:09:21,773] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_48_mp_rank_00_optim_states.pt.
12: [2025-06-28 07:09:21,773] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_48_mp_rank_00_optim_states.pt
 7: [2025-06-28 07:09:21,777] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_28_mp_rank_00_optim_states.pt.
 7: [2025-06-28 07:09:21,778] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_28_mp_rank_00_optim_states.pt
 8: [2025-06-28 07:09:21,777] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_32_mp_rank_00_optim_states.pt.
 8: [2025-06-28 07:09:21,778] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_32_mp_rank_00_optim_states.pt
30: [2025-06-28 07:09:21,778] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_120_mp_rank_00_optim_states.pt.
30: [2025-06-28 07:09:21,778] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_120_mp_rank_00_optim_states.pt
 5: [2025-06-28 07:09:21,777] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_20_mp_rank_00_optim_states.pt.
 5: [2025-06-28 07:09:21,777] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_20_mp_rank_00_optim_states.pt
25: [2025-06-28 07:09:21,780] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_100_mp_rank_00_optim_states.pt.
25: [2025-06-28 07:09:21,780] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_100_mp_rank_00_optim_states.pt
21: [2025-06-28 07:09:21,783] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_84_mp_rank_00_optim_states.pt.
21: [2025-06-28 07:09:21,783] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_84_mp_rank_00_optim_states.pt
 2: [2025-06-28 07:09:21,794] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_8_mp_rank_00_optim_states.pt.
 2: [2025-06-28 07:09:21,794] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_8_mp_rank_00_optim_states.pt
23: [2025-06-28 07:09:21,826] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_92_mp_rank_00_optim_states.pt.
23: [2025-06-28 07:09:21,827] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_92_mp_rank_00_optim_states.pt
17: [2025-06-28 07:09:21,843] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_68_mp_rank_00_optim_states.pt.
17: [2025-06-28 07:09:21,844] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_68_mp_rank_00_optim_states.pt
 4: [2025-06-28 07:09:21,847] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_16_mp_rank_00_optim_states.pt.
 4: [2025-06-28 07:09:21,848] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_16_mp_rank_00_optim_states.pt
27: [2025-06-28 07:09:21,861] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_108_mp_rank_00_optim_states.pt.
27: [2025-06-28 07:09:21,862] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_108_mp_rank_00_optim_states.pt
20: [2025-06-28 07:09:21,890] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_80_mp_rank_00_optim_states.pt.
20: [2025-06-28 07:09:21,890] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_80_mp_rank_00_optim_states.pt
24: [2025-06-28 07:09:21,976] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_96_mp_rank_00_optim_states.pt.
24: [2025-06-28 07:09:21,976] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_96_mp_rank_00_optim_states.pt
29: [2025-06-28 07:09:22,021] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_116_mp_rank_00_optim_states.pt.
29: [2025-06-28 07:09:22,021] [INFO] [engine.py:3701:_save_zero_checkpoint] zero checkpoint saved /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/global_step4399/bf16_zero_pp_rank_116_mp_rank_00_optim_states.pt
22: [2025-06-28 07:09:24,213] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4399 is ready now!
27: [2025-06-28 07:09:24,213] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4399 is ready now!
14: [2025-06-28 07:09:24,213] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4399 is ready now!
 5: [2025-06-28 07:09:24,213] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4399 is ready now!
17: [2025-06-28 07:09:24,213] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4399 is ready now!
31: [2025-06-28 07:09:24,214] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4399 is ready now!
25: [2025-06-28 07:09:24,214] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4399 is ready now!
 9: [2025-06-28 07:09:24,214] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4399 is ready now!
20: [2025-06-28 07:09:24,214] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4399 is ready now!
30: [2025-06-28 07:09:24,214] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4399 is ready now!
15: [2025-06-28 07:09:24,214] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4399 is ready now!
18: [2025-06-28 07:09:24,214] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4399 is ready now!
 4: [2025-06-28 07:09:24,214] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4399 is ready now!
23: [2025-06-28 07:09:24,214] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4399 is ready now!
 6: [2025-06-28 07:09:24,214] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4399 is ready now!
10: [2025-06-28 07:09:24,214] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4399 is ready now!
 2: [2025-06-28 07:09:24,214] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4399 is ready now!
 7: [2025-06-28 07:09:24,214] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4399 is ready now!
12: [2025-06-28 07:09:24,214] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4399 is ready now!
29: [2025-06-28 07:09:24,214] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4399 is ready now!
28: [2025-06-28 07:09:24,214] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4399 is ready now!
26: [2025-06-28 07:09:24,215] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4399 is ready now!
19: [2025-06-28 07:09:24,215] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4399 is ready now!
24: [2025-06-28 07:09:24,215] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4399 is ready now!
 3: [2025-06-28 07:09:24,215] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4399 is ready now!
11: [2025-06-28 07:09:24,215] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4399 is ready now!
 1: [2025-06-28 07:09:24,215] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4399 is ready now!
 8: [2025-06-28 07:09:24,216] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4399 is ready now!
16: [2025-06-28 07:09:24,216] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4399 is ready now!
21: [2025-06-28 07:09:24,216] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4399 is ready now!
13: [2025-06-28 07:09:24,216] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4399 is ready now!
 0: [2025-06-28 07:09:24,216] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step4399 is ready now!
 2: [INFO|trainer.py:2681] 2025-06-28 07:09:24,232 >> 
 2: 
 2: Training completed. Do not forget to share your model on huggingface.co/models =)
 2: 
 2: 
18: [INFO|trainer.py:2681] 2025-06-28 07:09:24,233 >> 
18: 
18: Training completed. Do not forget to share your model on huggingface.co/models =)
18: 
18: 
28: [INFO|trainer.py:2681] 2025-06-28 07:09:24,233 >> 
28: 
28: Training completed. Do not forget to share your model on huggingface.co/models =)
28: 
28: 
27: [INFO|trainer.py:2681] 2025-06-28 07:09:24,234 >> 
27: 
27: Training completed. Do not forget to share your model on huggingface.co/models =)
27: 
27: 
25: [INFO|trainer.py:2681] 2025-06-28 07:09:24,234 >> 
25: 
25: Training completed. Do not forget to share your model on huggingface.co/models =)
25: 
25: 
 6: [INFO|trainer.py:2681] 2025-06-28 07:09:24,235 >> 
 6: 
 6: Training completed. Do not forget to share your model on huggingface.co/models =)
 6: 
 6: 
 5: [INFO|trainer.py:2681] 2025-06-28 07:09:24,235 >> 
 5: 
 5: Training completed. Do not forget to share your model on huggingface.co/models =)
 5: 
 5: 
24: [INFO|trainer.py:2681] 2025-06-28 07:09:24,236 >> 
24: 
24: Training completed. Do not forget to share your model on huggingface.co/models =)
24: 
24: 
14: [INFO|trainer.py:2681] 2025-06-28 07:09:24,236 >> 
14: 
14: Training completed. Do not forget to share your model on huggingface.co/models =)
14: 
14: 
29: [INFO|trainer.py:2681] 2025-06-28 07:09:24,237 >> 
29: 
29: Training completed. Do not forget to share your model on huggingface.co/models =)
29: 
29: 
31: [INFO|trainer.py:2681] 2025-06-28 07:09:24,238 >> 
31: 
31: Training completed. Do not forget to share your model on huggingface.co/models =)
31: 
31: 
11: [INFO|trainer.py:2681] 2025-06-28 07:09:24,239 >> 
11: 
11: Training completed. Do not forget to share your model on huggingface.co/models =)
11: 
11: 
16: [INFO|trainer.py:2681] 2025-06-28 07:09:24,239 >> 
16: 
16: Training completed. Do not forget to share your model on huggingface.co/models =)
16: 
16: 
15: [INFO|trainer.py:2681] 2025-06-28 07:09:24,239 >> 
15: 
15: Training completed. Do not forget to share your model on huggingface.co/models =)
15: 
15: 
 8: [INFO|trainer.py:2681] 2025-06-28 07:09:24,240 >> 
 8: 
 8: Training completed. Do not forget to share your model on huggingface.co/models =)
 8: 
 8: 
13: [INFO|trainer.py:2681] 2025-06-28 07:09:24,240 >> 
13: 
13: Training completed. Do not forget to share your model on huggingface.co/models =)
13: 
13: 
26: [INFO|trainer.py:2681] 2025-06-28 07:09:24,240 >> 
26: 
26: Training completed. Do not forget to share your model on huggingface.co/models =)
26: 
26: 
 4: [INFO|trainer.py:2681] 2025-06-28 07:09:24,242 >> 
 4: 
 4: Training completed. Do not forget to share your model on huggingface.co/models =)
 4: 
 4: 
10: [INFO|trainer.py:2681] 2025-06-28 07:09:24,243 >> 
10: 
10: Training completed. Do not forget to share your model on huggingface.co/models =)
10: 
10: 
12: [INFO|trainer.py:2681] 2025-06-28 07:09:24,243 >> 
12: 
12: Training completed. Do not forget to share your model on huggingface.co/models =)
12: 
12: 
19: [INFO|trainer.py:2681] 2025-06-28 07:09:24,244 >> 
19: 
19: Training completed. Do not forget to share your model on huggingface.co/models =)
19: 
19: 
 1: [INFO|trainer.py:2681] 2025-06-28 07:09:24,246 >> 
 1: 
 1: Training completed. Do not forget to share your model on huggingface.co/models =)
 1: 
 1: 
 3: [INFO|trainer.py:2681] 2025-06-28 07:09:24,246 >> 
 3: 
 3: Training completed. Do not forget to share your model on huggingface.co/models =)
 3: 
 3: 
21: [INFO|trainer.py:2681] 2025-06-28 07:09:24,247 >> 
21: 
21: Training completed. Do not forget to share your model on huggingface.co/models =)
21: 
21: 
23: [INFO|trainer.py:2681] 2025-06-28 07:09:24,248 >> 
23: 
23: Training completed. Do not forget to share your model on huggingface.co/models =)
23: 
23: 
 9: [INFO|trainer.py:2681] 2025-06-28 07:09:24,251 >> 
 9: 
 9: Training completed. Do not forget to share your model on huggingface.co/models =)
 9: 
 9: 
22: [INFO|trainer.py:2681] 2025-06-28 07:09:24,252 >> 
22: 
22: Training completed. Do not forget to share your model on huggingface.co/models =)
22: 
22: 
 7: [INFO|trainer.py:2681] 2025-06-28 07:09:24,254 >> 
 7: 
 7: Training completed. Do not forget to share your model on huggingface.co/models =)
 7: 
 7: 
20: [INFO|trainer.py:2681] 2025-06-28 07:09:24,259 >> 
20: 
20: Training completed. Do not forget to share your model on huggingface.co/models =)
20: 
20: 
17: [INFO|trainer.py:2681] 2025-06-28 07:09:24,259 >> 
17: 
17: Training completed. Do not forget to share your model on huggingface.co/models =)
17: 
17: 
30: [INFO|trainer.py:2681] 2025-06-28 07:09:24,259 >> 
30: 
30: Training completed. Do not forget to share your model on huggingface.co/models =)
30: 
30: 
 0: [INFO|image_processing_base.py:260] 2025-06-28 07:09:24,272 >> Image processor saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/preprocessor_config.json
 0: [INFO|tokenization_utils_base.py:2510] 2025-06-28 07:09:24,274 >> tokenizer config file saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/tokenizer_config.json
 0: [INFO|tokenization_utils_base.py:2519] 2025-06-28 07:09:24,275 >> Special tokens file saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/special_tokens_map.json
 0: [INFO|processing_utils.py:648] 2025-06-28 07:09:24,858 >> chat template saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/checkpoint-4399/chat_template.json
 0: [INFO|trainer.py:2681] 2025-06-28 07:09:24,859 >> 
 0: 
 0: Training completed. Do not forget to share your model on huggingface.co/models =)
 0: 
 0: 
 0: {'train_runtime': 36356.9158, 'train_samples_per_second': 30.973, 'train_steps_per_second': 0.121, 'train_loss': 0.6386562572010107, 'epoch': 1.0}
 0:                                                       100%|██████████| 4399/4399 [10:05:55<00:00,  7.57s/it]100%|██████████| 4399/4399 [10:05:55<00:00,  8.26s/it]
 0: [INFO|image_processing_base.py:260] 2025-06-28 07:09:24,871 >> Image processor saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/preprocessor_config.json
 0: [INFO|tokenization_utils_base.py:2510] 2025-06-28 07:09:24,890 >> tokenizer config file saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/tokenizer_config.json
 0: [INFO|tokenization_utils_base.py:2519] 2025-06-28 07:09:24,892 >> Special tokens file saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/special_tokens_map.json
 0: [INFO|processing_utils.py:648] 2025-06-28 07:09:25,416 >> chat template saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/chat_template.json
 0: [INFO|trainer.py:3984] 2025-06-28 07:10:14,679 >> Saving model checkpoint to /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/
 0: [INFO|configuration_utils.py:419] 2025-06-28 07:10:14,685 >> Configuration saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/config.json
 0: [INFO|configuration_utils.py:911] 2025-06-28 07:10:14,687 >> Configuration saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/generation_config.json
12: nid005594:53087:154888 [2] NCCL INFO misc/socket.cc:47 -> 3
12: nid005594:53087:62560 [2] NCCL INFO misc/socket.cc:47 -> 3
12: nid005594:53085:154889 [0] NCCL INFO misc/socket.cc:47 -> 3
12: nid005594:53086:154890 [1] NCCL INFO misc/socket.cc:47 -> 3
12: nid005594:53087:62560 [2] NCCL INFO misc/socket.cc:752 -> 3
12: nid005594:53085:154889 [0] NCCL INFO misc/socket.cc:550 -> 3
12: nid005594:53086:154890 [1] NCCL INFO misc/socket.cc:550 -> 3
12: nid005594:53085:154889 [0] NCCL INFO misc/socket.cc:573 -> 3
12: nid005594:53086:154890 [1] NCCL INFO misc/socket.cc:573 -> 3
12: nid005594:53087:62560 [2] NCCL INFO misc/socket.cc:428 -> 3
12: nid005594:53086:154890 [1] NCCL INFO misc/socket.cc:621 -> 3
12: nid005594:53085:154889 [0] NCCL INFO misc/socket.cc:621 -> 3
12: nid005594:53087:62560 [2] NCCL INFO misc/socket.cc:564 -> 3
12: nid005594:53088:154891 [3] NCCL INFO misc/socket.cc:47 -> 3
12: nid005594:53085:62566 [0] NCCL INFO misc/socket.cc:47 -> 3
12: nid005594:53087:62560 [2] NCCL INFO misc/socket.cc:668 -> 3
12: nid005594:53086:62563 [1] NCCL INFO misc/socket.cc:47 -> 3
12: nid005594:53086:62563 [1] NCCL INFO misc/socket.cc:752 -> 3
12: nid005594:53088:154891 [3] NCCL INFO misc/socket.cc:550 -> 3
12: nid005594:53085:62566 [0] NCCL INFO misc/socket.cc:752 -> 3
12: nid005594:53087:154888 [2] NCCL INFO misc/socket.cc:550 -> 3
12: nid005594:53085:62566 [0] NCCL INFO misc/socket.cc:428 -> 3
12: nid005594:53086:62563 [1] NCCL INFO misc/socket.cc:428 -> 3
12: nid005594:53087:154888 [2] NCCL INFO misc/socket.cc:573 -> 3
12: nid005594:53085:62566 [0] NCCL INFO misc/socket.cc:564 -> 3
12: nid005594:53088:154891 [3] NCCL INFO misc/socket.cc:573 -> 3
12: nid005594:53087:154888 [2] NCCL INFO misc/socket.cc:621 -> 3
12: nid005594:53086:62563 [1] NCCL INFO misc/socket.cc:564 -> 3
12: nid005594:53085:62566 [0] NCCL INFO misc/socket.cc:668 -> 3
12: 
12: nid005594:53087:62560 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
12: nid005594:53088:154891 [3] NCCL INFO misc/socket.cc:621 -> 3
12: nid005594:53086:62563 [1] NCCL INFO misc/socket.cc:668 -> 3
12: 
12: nid005594:53085:62566 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
12: 
12: nid005594:53086:62563 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
12: nid005594:53088:62561 [3] NCCL INFO misc/socket.cc:47 -> 3
12: nid005594:53088:62561 [3] NCCL INFO misc/socket.cc:752 -> 3
12: nid005594:53088:62561 [3] NCCL INFO misc/socket.cc:428 -> 3
12: nid005594:53088:62561 [3] NCCL INFO misc/socket.cc:564 -> 3
12: nid005594:53088:62561 [3] NCCL INFO misc/socket.cc:668 -> 3
12: 
12: nid005594:53088:62561 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
12: nid005594:53085:154889 [0] NCCL INFO misc/socket.cc:47 -> 3
12: nid005594:53086:154890 [1] NCCL INFO misc/socket.cc:47 -> 3
12: nid005594:53085:154889 [0] NCCL INFO misc/socket.cc:58 -> 3
12: nid005594:53086:154890 [1] NCCL INFO misc/socket.cc:58 -> 3
12: nid005594:53085:154889 [0] NCCL INFO misc/socket.cc:775 -> 3
12: nid005594:53086:154890 [1] NCCL INFO misc/socket.cc:775 -> 3
12: nid005594:53085:62566 [0] NCCL INFO misc/socket.cc:826 -> 3
12: 
12: nid005594:53085:62566 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
12: 
12: nid005594:53085:62566 [0] proxy.cc:1521 NCCL WARN [Proxy Service 48] Failed to execute operation Close from rank 48, retcode 3
12: nid005594:53086:62563 [1] NCCL INFO misc/socket.cc:826 -> 3
12: 
12: nid005594:53086:62563 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
12: 
12: nid005594:53086:62563 [1] proxy.cc:1521 NCCL WARN [Proxy Service 49] Failed to execute operation Close from rank 49, retcode 3
12: nid005594:53087:154888 [2] NCCL INFO misc/socket.cc:47 -> 3
12: nid005594:53087:154888 [2] NCCL INFO misc/socket.cc:58 -> 3
12: nid005594:53087:154888 [2] NCCL INFO misc/socket.cc:775 -> 3
12: nid005594:53087:62560 [2] NCCL INFO misc/socket.cc:826 -> 3
12: nid005594:53088:154891 [3] NCCL INFO misc/socket.cc:47 -> 3
12: 
12: nid005594:53087:62560 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
12: nid005594:53088:154891 [3] NCCL INFO misc/socket.cc:58 -> 3
12: 
12: nid005594:53087:62560 [2] proxy.cc:1521 NCCL WARN [Proxy Service 50] Failed to execute operation Close from rank 50, retcode 3
12: nid005594:53088:154891 [3] NCCL INFO misc/socket.cc:775 -> 3
12: nid005594:53088:62561 [3] NCCL INFO misc/socket.cc:826 -> 3
12: 
12: nid005594:53088:62561 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
12: 
12: nid005594:53088:62561 [3] proxy.cc:1521 NCCL WARN [Proxy Service 51] Failed to execute operation Close from rank 51, retcode 3
17: nid005803:180735:283752 [3] NCCL INFO misc/socket.cc:47 -> 3
17: nid005803:180735:283752 [3] NCCL INFO misc/socket.cc:550 -> 3
17: nid005803:180735:283752 [3] NCCL INFO misc/socket.cc:573 -> 3
17: nid005803:180735:283752 [3] NCCL INFO misc/socket.cc:621 -> 3
17: nid005803:180733:283753 [1] NCCL INFO misc/socket.cc:47 -> 3
17: nid005803:180734:283754 [2] NCCL INFO misc/socket.cc:47 -> 3
17: nid005803:180733:283753 [1] NCCL INFO misc/socket.cc:550 -> 3
17: nid005803:180734:283754 [2] NCCL INFO misc/socket.cc:550 -> 3
17: nid005803:180733:283753 [1] NCCL INFO misc/socket.cc:573 -> 3
17: nid005803:180734:283754 [2] NCCL INFO misc/socket.cc:573 -> 3
17: nid005803:180734:283754 [2] NCCL INFO misc/socket.cc:621 -> 3
17: nid005803:180733:283753 [1] NCCL INFO misc/socket.cc:621 -> 3
17: nid005803:180733:190222 [1] NCCL INFO misc/socket.cc:47 -> 3
17: nid005803:180733:190222 [1] NCCL INFO misc/socket.cc:752 -> 3
17: nid005803:180733:190222 [1] NCCL INFO misc/socket.cc:428 -> 3
17: nid005803:180733:190222 [1] NCCL INFO misc/socket.cc:564 -> 3
17: nid005803:180733:190222 [1] NCCL INFO misc/socket.cc:668 -> 3
17: nid005803:180735:190223 [3] NCCL INFO misc/socket.cc:47 -> 3
17: 
17: nid005803:180733:190222 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
17: nid005803:180735:190223 [3] NCCL INFO misc/socket.cc:752 -> 3
17: nid005803:180735:190223 [3] NCCL INFO misc/socket.cc:428 -> 3
17: nid005803:180735:190223 [3] NCCL INFO misc/socket.cc:564 -> 3
17: nid005803:180735:190223 [3] NCCL INFO misc/socket.cc:668 -> 3
17: nid005803:180732:283755 [0] NCCL INFO misc/socket.cc:47 -> 3
17: 
17: nid005803:180735:190223 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
17: nid005803:180734:190225 [2] NCCL INFO misc/socket.cc:47 -> 3
17: nid005803:180732:283755 [0] NCCL INFO misc/socket.cc:550 -> 3
17: nid005803:180734:190225 [2] NCCL INFO misc/socket.cc:752 -> 3
17: nid005803:180732:283755 [0] NCCL INFO misc/socket.cc:573 -> 3
17: nid005803:180734:190225 [2] NCCL INFO misc/socket.cc:428 -> 3
17: nid005803:180734:190225 [2] NCCL INFO misc/socket.cc:564 -> 3
17: nid005803:180732:283755 [0] NCCL INFO misc/socket.cc:621 -> 3
17: nid005803:180734:190225 [2] NCCL INFO misc/socket.cc:668 -> 3
17: nid005803:180732:190228 [0] NCCL INFO misc/socket.cc:47 -> 3
17: 
17: nid005803:180734:190225 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
17: nid005803:180732:190228 [0] NCCL INFO misc/socket.cc:752 -> 3
17: nid005803:180733:283753 [1] NCCL INFO misc/socket.cc:47 -> 3
17: nid005803:180732:190228 [0] NCCL INFO misc/socket.cc:428 -> 3
17: nid005803:180733:283753 [1] NCCL INFO misc/socket.cc:58 -> 3
17: nid005803:180732:190228 [0] NCCL INFO misc/socket.cc:564 -> 3
17: nid005803:180733:283753 [1] NCCL INFO misc/socket.cc:775 -> 3
17: nid005803:180732:190228 [0] NCCL INFO misc/socket.cc:668 -> 3
17: nid005803:180734:283754 [2] NCCL INFO misc/socket.cc:47 -> 3
17: nid005803:180734:283754 [2] NCCL INFO misc/socket.cc:58 -> 3
17: 
17: nid005803:180732:190228 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
17: nid005803:180733:190222 [1] NCCL INFO misc/socket.cc:826 -> 3
17: nid005803:180734:283754 [2] NCCL INFO misc/socket.cc:775 -> 3
17: nid005803:180735:283752 [3] NCCL INFO misc/socket.cc:47 -> 3
17: 
17: nid005803:180733:190222 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
17: nid005803:180734:190225 [2] NCCL INFO misc/socket.cc:826 -> 3
17: 
17: nid005803:180733:190222 [1] proxy.cc:1521 NCCL WARN [Proxy Service 69] Failed to execute operation Close from rank 69, retcode 3
17: nid005803:180735:283752 [3] NCCL INFO misc/socket.cc:58 -> 3
17: 
17: nid005803:180734:190225 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
17: 
17: nid005803:180734:190225 [2] proxy.cc:1521 NCCL WARN [Proxy Service 70] Failed to execute operation Close from rank 70, retcode 3
17: nid005803:180735:283752 [3] NCCL INFO misc/socket.cc:775 -> 3
17: nid005803:180732:283755 [0] NCCL INFO misc/socket.cc:47 -> 3
17: nid005803:180732:283755 [0] NCCL INFO misc/socket.cc:58 -> 3
17: nid005803:180732:283755 [0] NCCL INFO misc/socket.cc:775 -> 3
17: nid005803:180735:190223 [3] NCCL INFO misc/socket.cc:826 -> 3
17: nid005803:180732:190228 [0] NCCL INFO misc/socket.cc:826 -> 3
17: 
17: nid005803:180735:190223 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
17: 
17: nid005803:180732:190228 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
17: 
17: nid005803:180735:190223 [3] proxy.cc:1521 NCCL WARN [Proxy Service 71] Failed to execute operation Close from rank 71, retcode 3
17: 
17: nid005803:180732:190228 [0] proxy.cc:1521 NCCL WARN [Proxy Service 68] Failed to execute operation Close from rank 68, retcode 3
 0: nid005574:69059:171237 [1] NCCL INFO misc/socket.cc:47 -> 3
 0: nid005574:69061:171238 [3] NCCL INFO misc/socket.cc:47 -> 3
 0: nid005574:69059:171237 [1] NCCL INFO misc/socket.cc:550 -> 3
 0: nid005574:69061:171238 [3] NCCL INFO misc/socket.cc:550 -> 3
 0: nid005574:69059:78863 [1] NCCL INFO misc/socket.cc:47 -> 3
 0: nid005574:69061:171238 [3] NCCL INFO misc/socket.cc:573 -> 3
 0: nid005574:69061:171238 [3] NCCL INFO misc/socket.cc:621 -> 3
 0: nid005574:69059:78863 [1] NCCL INFO misc/socket.cc:752 -> 3
 0: nid005574:69059:171237 [1] NCCL INFO misc/socket.cc:573 -> 3
 0: nid005574:69059:171237 [1] NCCL INFO misc/socket.cc:621 -> 3
 0: nid005574:69059:78863 [1] NCCL INFO misc/socket.cc:428 -> 3
 0: nid005574:69059:78863 [1] NCCL INFO misc/socket.cc:564 -> 3
 0: nid005574:69059:78863 [1] NCCL INFO misc/socket.cc:668 -> 3
 0: nid005574:69061:78864 [3] NCCL INFO misc/socket.cc:47 -> 3
 0: 
 0: nid005574:69059:78863 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 0: nid005574:69061:78864 [3] NCCL INFO misc/socket.cc:752 -> 3
 0: nid005574:69061:78864 [3] NCCL INFO misc/socket.cc:428 -> 3
 0: nid005574:69061:78864 [3] NCCL INFO misc/socket.cc:564 -> 3
 0: nid005574:69061:78864 [3] NCCL INFO misc/socket.cc:668 -> 3
 0: 
 0: nid005574:69061:78864 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 0: nid005574:69060:171239 [2] NCCL INFO misc/socket.cc:47 -> 3
 0: nid005574:69060:171239 [2] NCCL INFO misc/socket.cc:550 -> 3
 0: nid005574:69060:171239 [2] NCCL INFO misc/socket.cc:573 -> 3
 0: nid005574:69060:171239 [2] NCCL INFO misc/socket.cc:621 -> 3
 0: nid005574:69060:78866 [2] NCCL INFO misc/socket.cc:47 -> 3
 0: nid005574:69060:78866 [2] NCCL INFO misc/socket.cc:752 -> 3
 0: nid005574:69060:78866 [2] NCCL INFO misc/socket.cc:428 -> 3
 0: nid005574:69059:171237 [1] NCCL INFO misc/socket.cc:47 -> 3
 0: nid005574:69060:78866 [2] NCCL INFO misc/socket.cc:564 -> 3
 0: nid005574:69059:171237 [1] NCCL INFO misc/socket.cc:58 -> 3
 0: nid005574:69060:78866 [2] NCCL INFO misc/socket.cc:668 -> 3
 0: nid005574:69061:171238 [3] NCCL INFO misc/socket.cc:47 -> 3
 0: nid005574:69059:171237 [1] NCCL INFO misc/socket.cc:775 -> 3
 0: nid005574:69061:171238 [3] NCCL INFO misc/socket.cc:58 -> 3
 0: nid005574:69059:78863 [1] NCCL INFO misc/socket.cc:826 -> 3
 0: 
 0: nid005574:69060:78866 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 0: nid005574:69061:171238 [3] NCCL INFO misc/socket.cc:775 -> 3
 0: 
 0: nid005574:69059:78863 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
 0: 
 0: nid005574:69059:78863 [1] proxy.cc:1521 NCCL WARN [Proxy Service 1] Failed to execute operation Close from rank 1, retcode 3
 0: nid005574:69061:78864 [3] NCCL INFO misc/socket.cc:826 -> 3
 0: 
 0: nid005574:69061:78864 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
 0: 
 0: nid005574:69061:78864 [3] proxy.cc:1521 NCCL WARN [Proxy Service 3] Failed to execute operation Close from rank 3, retcode 3
 0: nid005574:69060:171239 [2] NCCL INFO misc/socket.cc:47 -> 3
 0: nid005574:69060:171239 [2] NCCL INFO misc/socket.cc:58 -> 3
 0: nid005574:69060:78866 [2] NCCL INFO misc/socket.cc:826 -> 3
 0: 
 0: nid005574:69060:78866 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
 0: nid005574:69060:171239 [2] NCCL INFO misc/socket.cc:775 -> 3
 0: 
 0: nid005574:69060:78866 [2] proxy.cc:1521 NCCL WARN [Proxy Service 2] Failed to execute operation Close from rank 2, retcode 3
26: nid005920:67123:168063 [0] NCCL INFO misc/socket.cc:47 -> 3
26: nid005920:67123:168063 [0] NCCL INFO misc/socket.cc:550 -> 3
26: nid005920:67123:168063 [0] NCCL INFO misc/socket.cc:573 -> 3
26: nid005920:67123:168063 [0] NCCL INFO misc/socket.cc:621 -> 3
26: nid005920:67123:76593 [0] NCCL INFO misc/socket.cc:47 -> 3
26: nid005920:67124:168062 [1] NCCL INFO misc/socket.cc:47 -> 3
26: nid005920:67123:76593 [0] NCCL INFO misc/socket.cc:752 -> 3
26: nid005920:67124:168062 [1] NCCL INFO misc/socket.cc:550 -> 3
26: nid005920:67123:76593 [0] NCCL INFO misc/socket.cc:428 -> 3
26: nid005920:67124:168062 [1] NCCL INFO misc/socket.cc:573 -> 3
26: nid005920:67123:76593 [0] NCCL INFO misc/socket.cc:564 -> 3
26: nid005920:67124:168062 [1] NCCL INFO misc/socket.cc:621 -> 3
26: nid005920:67123:76593 [0] NCCL INFO misc/socket.cc:668 -> 3
26: 
26: nid005920:67123:76593 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
26: nid005920:67124:76598 [1] NCCL INFO misc/socket.cc:47 -> 3
26: nid005920:67124:76598 [1] NCCL INFO misc/socket.cc:752 -> 3
26: nid005920:67124:76598 [1] NCCL INFO misc/socket.cc:428 -> 3
26: nid005920:67124:76598 [1] NCCL INFO misc/socket.cc:564 -> 3
26: nid005920:67124:76598 [1] NCCL INFO misc/socket.cc:668 -> 3
26: 
26: nid005920:67124:76598 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
26: nid005920:67123:168063 [0] NCCL INFO misc/socket.cc:47 -> 3
26: nid005920:67123:168063 [0] NCCL INFO misc/socket.cc:58 -> 3
26: nid005920:67123:76593 [0] NCCL INFO misc/socket.cc:826 -> 3
26: nid005920:67123:168063 [0] NCCL INFO misc/socket.cc:775 -> 3
26: 
26: nid005920:67123:76593 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
26: 
26: nid005920:67123:76593 [0] proxy.cc:1521 NCCL WARN [Proxy Service 104] Failed to execute operation Close from rank 104, retcode 3
26: nid005920:67126:168064 [3] NCCL INFO misc/socket.cc:47 -> 3
26: nid005920:67126:168064 [3] NCCL INFO misc/socket.cc:550 -> 3
26: nid005920:67126:168064 [3] NCCL INFO misc/socket.cc:573 -> 3
26: nid005920:67126:168064 [3] NCCL INFO misc/socket.cc:621 -> 3
26: nid005920:67126:76592 [3] NCCL INFO misc/socket.cc:47 -> 3
26: nid005920:67126:76592 [3] NCCL INFO misc/socket.cc:752 -> 3
26: nid005920:67126:76592 [3] NCCL INFO misc/socket.cc:428 -> 3
26: nid005920:67126:76592 [3] NCCL INFO misc/socket.cc:564 -> 3
26: nid005920:67126:76592 [3] NCCL INFO misc/socket.cc:668 -> 3
26: nid005920:67125:168065 [2] NCCL INFO misc/socket.cc:47 -> 3
26: 
26: nid005920:67126:76592 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
26: nid005920:67125:168065 [2] NCCL INFO misc/socket.cc:550 -> 3
26: nid005920:67125:168065 [2] NCCL INFO misc/socket.cc:573 -> 3
26: nid005920:67125:168065 [2] NCCL INFO misc/socket.cc:621 -> 3
26: nid005920:67124:168062 [1] NCCL INFO misc/socket.cc:47 -> 3
26: nid005920:67124:168062 [1] NCCL INFO misc/socket.cc:58 -> 3
26: nid005920:67124:168062 [1] NCCL INFO misc/socket.cc:775 -> 3
26: nid005920:67124:76598 [1] NCCL INFO misc/socket.cc:826 -> 3
16: nid005802:6299:108571 [2] NCCL INFO misc/socket.cc:47 -> 3
16: nid005802:6300:108572 [3] NCCL INFO misc/socket.cc:47 -> 3
16: nid005802:6299:108571 [2] NCCL INFO misc/socket.cc:550 -> 3
16: nid005802:6300:108572 [3] NCCL INFO misc/socket.cc:550 -> 3
16: nid005802:6299:108571 [2] NCCL INFO misc/socket.cc:573 -> 3
16: nid005802:6300:108572 [3] NCCL INFO misc/socket.cc:573 -> 3
16: nid005802:6299:108571 [2] NCCL INFO misc/socket.cc:621 -> 3
16: nid005802:6300:108572 [3] NCCL INFO misc/socket.cc:621 -> 3
26: 
26: nid005920:67124:76598 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
26: nid005920:67125:76595 [2] NCCL INFO misc/socket.cc:47 -> 3
26: nid005920:67126:168064 [3] NCCL INFO misc/socket.cc:47 -> 3
26: 
26: nid005920:67124:76598 [1] proxy.cc:1521 NCCL WARN [Proxy Service 105] Failed to execute operation Close from rank 105, retcode 3
26: nid005920:67125:76595 [2] NCCL INFO misc/socket.cc:752 -> 3
16: nid005802:6299:15925 [2] NCCL INFO misc/socket.cc:47 -> 3
16: nid005802:6299:15925 [2] NCCL INFO misc/socket.cc:752 -> 3
16: nid005802:6299:15925 [2] NCCL INFO misc/socket.cc:428 -> 3
16: nid005802:6299:15925 [2] NCCL INFO misc/socket.cc:564 -> 3
16: nid005802:6299:15925 [2] NCCL INFO misc/socket.cc:668 -> 3
16: 
16: nid005802:6299:15925 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
16: nid005802:6300:15926 [3] NCCL INFO misc/socket.cc:47 -> 3
16: nid005802:6300:15926 [3] NCCL INFO misc/socket.cc:752 -> 3
16: nid005802:6300:15926 [3] NCCL INFO misc/socket.cc:428 -> 3
16: nid005802:6300:15926 [3] NCCL INFO misc/socket.cc:564 -> 3
16: nid005802:6300:15926 [3] NCCL INFO misc/socket.cc:668 -> 3
26: nid005920:67126:168064 [3] NCCL INFO misc/socket.cc:58 -> 3
26: nid005920:67125:76595 [2] NCCL INFO misc/socket.cc:428 -> 3
26: nid005920:67126:168064 [3] NCCL INFO misc/socket.cc:775 -> 3
26: nid005920:67125:76595 [2] NCCL INFO misc/socket.cc:564 -> 3
16: 
16: nid005802:6300:15926 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
16: nid005802:6298:108573 [1] NCCL INFO misc/socket.cc:47 -> 3
16: nid005802:6298:108573 [1] NCCL INFO misc/socket.cc:550 -> 3
16: nid005802:6298:108573 [1] NCCL INFO misc/socket.cc:573 -> 3
16: nid005802:6298:108573 [1] NCCL INFO misc/socket.cc:621 -> 3
26: nid005920:67125:76595 [2] NCCL INFO misc/socket.cc:668 -> 3
26: nid005920:67126:76592 [3] NCCL INFO misc/socket.cc:826 -> 3
26: 
26: nid005920:67126:76592 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
16: nid005802:6297:108574 [0] NCCL INFO misc/socket.cc:47 -> 3
16: nid005802:6297:108574 [0] NCCL INFO misc/socket.cc:550 -> 3
16: nid005802:6297:108574 [0] NCCL INFO misc/socket.cc:573 -> 3
16: nid005802:6297:108574 [0] NCCL INFO misc/socket.cc:621 -> 3
26: 
26: nid005920:67125:76595 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
26: 
26: nid005920:67126:76592 [3] proxy.cc:1521 NCCL WARN [Proxy Service 107] Failed to execute operation Close from rank 107, retcode 3
16: nid005802:6299:108571 [2] NCCL INFO misc/socket.cc:47 -> 3
16: nid005802:6298:15928 [1] NCCL INFO misc/socket.cc:47 -> 3
16: nid005802:6300:108572 [3] NCCL INFO misc/socket.cc:47 -> 3
16: nid005802:6299:108571 [2] NCCL INFO misc/socket.cc:58 -> 3
16: nid005802:6298:15928 [1] NCCL INFO misc/socket.cc:752 -> 3
26: nid005920:67125:168065 [2] NCCL INFO misc/socket.cc:47 -> 3
26: nid005920:67125:168065 [2] NCCL INFO misc/socket.cc:58 -> 3
16: nid005802:6300:15926 [3] NCCL INFO misc/socket.cc:826 -> 3
16: nid005802:6298:15928 [1] NCCL INFO misc/socket.cc:428 -> 3
16: nid005802:6299:108571 [2] NCCL INFO misc/socket.cc:775 -> 3
16: nid005802:6298:15928 [1] NCCL INFO misc/socket.cc:564 -> 3
16: nid005802:6297:15931 [0] NCCL INFO misc/socket.cc:47 -> 3
16: nid005802:6298:15928 [1] NCCL INFO misc/socket.cc:668 -> 3
16: 
16: nid005802:6300:15926 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
26: nid005920:67125:168065 [2] NCCL INFO misc/socket.cc:775 -> 3
26: nid005920:67125:76595 [2] NCCL INFO misc/socket.cc:826 -> 3
16: nid005802:6299:15925 [2] NCCL INFO misc/socket.cc:826 -> 3
16: nid005802:6297:15931 [0] NCCL INFO misc/socket.cc:752 -> 3
16: 
16: nid005802:6298:15928 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
16: 
16: nid005802:6300:15926 [3] proxy.cc:1521 NCCL WARN [Proxy Service 67] Failed to execute operation Close from rank 67, retcode 3
16: 
16: nid005802:6299:15925 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
16: nid005802:6297:15931 [0] NCCL INFO misc/socket.cc:428 -> 3
16: 
16: nid005802:6299:15925 [2] proxy.cc:1521 NCCL WARN [Proxy Service 66] Failed to execute operation Close from rank 66, retcode 3
16: nid005802:6297:15931 [0] NCCL INFO misc/socket.cc:564 -> 3
26: 
26: nid005920:67125:76595 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
26: 
26: nid005920:67125:76595 [2] proxy.cc:1521 NCCL WARN [Proxy Service 106] Failed to execute operation Close from rank 106, retcode 3
16: nid005802:6297:15931 [0] NCCL INFO misc/socket.cc:668 -> 3
16: nid005802:6298:108573 [1] NCCL INFO misc/socket.cc:47 -> 3
16: nid005802:6297:108574 [0] NCCL INFO misc/socket.cc:47 -> 3
16: nid005802:6300:108572 [3] NCCL INFO misc/socket.cc:58 -> 3
16: nid005802:6298:108573 [1] NCCL INFO misc/socket.cc:58 -> 3
16: nid005802:6300:108572 [3] NCCL INFO misc/socket.cc:775 -> 3
16: nid005802:6297:108574 [0] NCCL INFO misc/socket.cc:58 -> 3
16: nid005802:6298:108573 [1] NCCL INFO misc/socket.cc:775 -> 3
16: nid005802:6297:108574 [0] NCCL INFO misc/socket.cc:775 -> 3
16: nid005802:6298:15928 [1] NCCL INFO misc/socket.cc:826 -> 3
16: 
16: nid005802:6298:15928 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
16: 
16: nid005802:6297:15931 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
16: 
16: nid005802:6298:15928 [1] proxy.cc:1521 NCCL WARN [Proxy Service 65] Failed to execute operation Close from rank 65, retcode 3
16: nid005802:6297:15931 [0] NCCL INFO misc/socket.cc:826 -> 3
16: 
16: nid005802:6297:15931 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
16: 
16: nid005802:6297:15931 [0] proxy.cc:1521 NCCL WARN [Proxy Service 64] Failed to execute operation Close from rank 64, retcode 3
31: nid005937:256589:65763 [0] NCCL INFO misc/socket.cc:47 -> 3
31: nid005937:256589:65763 [0] NCCL INFO misc/socket.cc:550 -> 3
31: nid005937:256589:65763 [0] NCCL INFO misc/socket.cc:573 -> 3
31: nid005937:256589:65763 [0] NCCL INFO misc/socket.cc:621 -> 3
31: nid005937:256592:65762 [3] NCCL INFO misc/socket.cc:47 -> 3
31: nid005937:256592:65762 [3] NCCL INFO misc/socket.cc:550 -> 3
31: nid005937:256592:65762 [3] NCCL INFO misc/socket.cc:573 -> 3
31: nid005937:256592:65762 [3] NCCL INFO misc/socket.cc:621 -> 3
31: nid005937:256589:266038 [0] NCCL INFO misc/socket.cc:47 -> 3
31: nid005937:256589:266038 [0] NCCL INFO misc/socket.cc:752 -> 3
31: nid005937:256589:266038 [0] NCCL INFO misc/socket.cc:428 -> 3
31: nid005937:256592:266033 [3] NCCL INFO misc/socket.cc:47 -> 3
31: nid005937:256589:266038 [0] NCCL INFO misc/socket.cc:564 -> 3
31: nid005937:256592:266033 [3] NCCL INFO misc/socket.cc:752 -> 3
31: nid005937:256589:266038 [0] NCCL INFO misc/socket.cc:668 -> 3
31: nid005937:256592:266033 [3] NCCL INFO misc/socket.cc:428 -> 3
31: nid005937:256591:65764 [2] NCCL INFO misc/socket.cc:47 -> 3
31: nid005937:256592:266033 [3] NCCL INFO misc/socket.cc:564 -> 3
31: 
31: nid005937:256589:266038 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
31: nid005937:256590:65765 [1] NCCL INFO misc/socket.cc:47 -> 3
31: nid005937:256591:65764 [2] NCCL INFO misc/socket.cc:550 -> 3
31: nid005937:256590:65765 [1] NCCL INFO misc/socket.cc:550 -> 3
31: nid005937:256591:266032 [2] NCCL INFO misc/socket.cc:47 -> 3
31: nid005937:256590:65765 [1] NCCL INFO misc/socket.cc:573 -> 3
31: nid005937:256592:266033 [3] NCCL INFO misc/socket.cc:668 -> 3
31: nid005937:256590:65765 [1] NCCL INFO misc/socket.cc:621 -> 3
31: nid005937:256591:266032 [2] NCCL INFO misc/socket.cc:752 -> 3
31: 
31: nid005937:256592:266033 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
31: nid005937:256591:266032 [2] NCCL INFO misc/socket.cc:428 -> 3
31: nid005937:256590:266035 [1] NCCL INFO misc/socket.cc:47 -> 3
31: nid005937:256590:266035 [1] NCCL INFO misc/socket.cc:752 -> 3
31: nid005937:256591:266032 [2] NCCL INFO misc/socket.cc:564 -> 3
31: nid005937:256589:65763 [0] NCCL INFO misc/socket.cc:47 -> 3
31: nid005937:256590:266035 [1] NCCL INFO misc/socket.cc:428 -> 3
31: nid005937:256589:65763 [0] NCCL INFO misc/socket.cc:58 -> 3
31: nid005937:256591:266032 [2] NCCL INFO misc/socket.cc:668 -> 3
31: nid005937:256590:266035 [1] NCCL INFO misc/socket.cc:564 -> 3
31: nid005937:256590:266035 [1] NCCL INFO misc/socket.cc:668 -> 3
31: nid005937:256589:65763 [0] NCCL INFO misc/socket.cc:775 -> 3
31: nid005937:256591:65764 [2] NCCL INFO misc/socket.cc:573 -> 3
31: nid005937:256592:65762 [3] NCCL INFO misc/socket.cc:47 -> 3
31: 
31: nid005937:256590:266035 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
31: nid005937:256592:65762 [3] NCCL INFO misc/socket.cc:58 -> 3
31: nid005937:256589:266038 [0] NCCL INFO misc/socket.cc:826 -> 3
31: nid005937:256591:65764 [2] NCCL INFO misc/socket.cc:621 -> 3
31: nid005937:256592:65762 [3] NCCL INFO misc/socket.cc:775 -> 3
31: 
31: nid005937:256589:266038 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
31: 
31: nid005937:256591:266032 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
31: 
31: nid005937:256589:266038 [0] proxy.cc:1521 NCCL WARN [Proxy Service 124] Failed to execute operation Close from rank 124, retcode 3
31: nid005937:256592:266033 [3] NCCL INFO misc/socket.cc:826 -> 3
31: 
31: nid005937:256592:266033 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
31: 
31: nid005937:256592:266033 [3] proxy.cc:1521 NCCL WARN [Proxy Service 127] Failed to execute operation Close from rank 127, retcode 3
31: nid005937:256590:65765 [1] NCCL INFO misc/socket.cc:47 -> 3
31: nid005937:256590:65765 [1] NCCL INFO misc/socket.cc:58 -> 3
31: nid005937:256590:266035 [1] NCCL INFO misc/socket.cc:826 -> 3
31: 
31: nid005937:256590:266035 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
31: 
31: nid005937:256590:266035 [1] proxy.cc:1521 NCCL WARN [Proxy Service 125] Failed to execute operation Close from rank 125, retcode 3
31: nid005937:256590:65765 [1] NCCL INFO misc/socket.cc:775 -> 3
31: nid005937:256591:65764 [2] NCCL INFO misc/socket.cc:47 -> 3
31: nid005937:256591:266032 [2] NCCL INFO misc/socket.cc:826 -> 3
 5: nid005582:196713:3940 [0] NCCL INFO misc/socket.cc:47 -> 3
 5: nid005582:196716:3941 [3] NCCL INFO misc/socket.cc:47 -> 3
 5: nid005582:196714:3942 [1] NCCL INFO misc/socket.cc:47 -> 3
 5: nid005582:196713:3940 [0] NCCL INFO misc/socket.cc:550 -> 3
 5: nid005582:196716:3941 [3] NCCL INFO misc/socket.cc:550 -> 3
 5: nid005582:196713:3940 [0] NCCL INFO misc/socket.cc:573 -> 3
 5: nid005582:196714:3942 [1] NCCL INFO misc/socket.cc:550 -> 3
 5: nid005582:196716:3941 [3] NCCL INFO misc/socket.cc:573 -> 3
 5: nid005582:196713:3940 [0] NCCL INFO misc/socket.cc:621 -> 3
 5: nid005582:196714:3942 [1] NCCL INFO misc/socket.cc:573 -> 3
 5: nid005582:196716:3941 [3] NCCL INFO misc/socket.cc:621 -> 3
 5: nid005582:196714:3942 [1] NCCL INFO misc/socket.cc:621 -> 3
31: 
31: nid005937:256591:266032 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
 5: nid005582:196713:206697 [0] NCCL INFO misc/socket.cc:47 -> 3
 5: nid005582:196716:206692 [3] NCCL INFO misc/socket.cc:47 -> 3
 5: nid005582:196714:206696 [1] NCCL INFO misc/socket.cc:47 -> 3
 5: nid005582:196716:206692 [3] NCCL INFO misc/socket.cc:752 -> 3
 5: nid005582:196713:206697 [0] NCCL INFO misc/socket.cc:752 -> 3
 5: nid005582:196716:206692 [3] NCCL INFO misc/socket.cc:428 -> 3
 5: nid005582:196713:206697 [0] NCCL INFO misc/socket.cc:428 -> 3
 5: nid005582:196714:206696 [1] NCCL INFO misc/socket.cc:752 -> 3
 5: nid005582:196716:206692 [3] NCCL INFO misc/socket.cc:564 -> 3
 5: nid005582:196713:206697 [0] NCCL INFO misc/socket.cc:564 -> 3
 5: nid005582:196714:206696 [1] NCCL INFO misc/socket.cc:428 -> 3
 5: nid005582:196716:206692 [3] NCCL INFO misc/socket.cc:668 -> 3
 5: nid005582:196714:206696 [1] NCCL INFO misc/socket.cc:564 -> 3
 5: nid005582:196713:206697 [0] NCCL INFO misc/socket.cc:668 -> 3
31: 
31: nid005937:256591:266032 [2] proxy.cc:1521 NCCL WARN [Proxy Service 126] Failed to execute operation Close from rank 126, retcode 3
31: nid005937:256591:65764 [2] NCCL INFO misc/socket.cc:58 -> 3
31: nid005937:256591:65764 [2] NCCL INFO misc/socket.cc:775 -> 3
 5: nid005582:196714:206696 [1] NCCL INFO misc/socket.cc:668 -> 3
 5: 
 5: nid005582:196716:206692 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 5: 
 5: nid005582:196713:206697 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 5: 
 5: nid005582:196714:206696 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 5: nid005582:196716:3941 [3] NCCL INFO misc/socket.cc:47 -> 3
 5: nid005582:196716:3941 [3] NCCL INFO misc/socket.cc:58 -> 3
 5: nid005582:196716:3941 [3] NCCL INFO misc/socket.cc:775 -> 3
 5: nid005582:196716:206692 [3] NCCL INFO misc/socket.cc:826 -> 3
 5: 
 5: nid005582:196716:206692 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
 5: 
 5: nid005582:196716:206692 [3] proxy.cc:1521 NCCL WARN [Proxy Service 23] Failed to execute operation Close from rank 23, retcode 3
 5: nid005582:196715:3943 [2] NCCL INFO misc/socket.cc:47 -> 3
 5: nid005582:196715:3943 [2] NCCL INFO misc/socket.cc:550 -> 3
 5: nid005582:196715:3943 [2] NCCL INFO misc/socket.cc:573 -> 3
 5: nid005582:196715:3943 [2] NCCL INFO misc/socket.cc:621 -> 3
 5: nid005582:196714:3942 [1] NCCL INFO misc/socket.cc:47 -> 3
 5: nid005582:196714:3942 [1] NCCL INFO misc/socket.cc:58 -> 3
 5: nid005582:196714:3942 [1] NCCL INFO misc/socket.cc:775 -> 3
 5: nid005582:196713:3940 [0] NCCL INFO misc/socket.cc:47 -> 3
 5: nid005582:196714:206696 [1] NCCL INFO misc/socket.cc:826 -> 3
 5: nid005582:196713:3940 [0] NCCL INFO misc/socket.cc:58 -> 3
 5: 
 5: nid005582:196714:206696 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
 5: nid005582:196713:3940 [0] NCCL INFO misc/socket.cc:775 -> 3
 5: 
 5: nid005582:196714:206696 [1] proxy.cc:1521 NCCL WARN [Proxy Service 21] Failed to execute operation Close from rank 21, retcode 3
 5: nid005582:196713:206697 [0] NCCL INFO misc/socket.cc:826 -> 3
 5: 
 5: nid005582:196713:206697 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
 5: 
 5: nid005582:196713:206697 [0] proxy.cc:1521 NCCL WARN [Proxy Service 20] Failed to execute operation Close from rank 20, retcode 3
 5: nid005582:196715:206694 [2] NCCL INFO misc/socket.cc:47 -> 3
 5: nid005582:196715:206694 [2] NCCL INFO misc/socket.cc:752 -> 3
 5: nid005582:196715:206694 [2] NCCL INFO misc/socket.cc:428 -> 3
 5: nid005582:196715:206694 [2] NCCL INFO misc/socket.cc:564 -> 3
 5: nid005582:196715:206694 [2] NCCL INFO misc/socket.cc:668 -> 3
 5: 
 5: nid005582:196715:206694 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 5: nid005582:196715:3943 [2] NCCL INFO misc/socket.cc:47 -> 3
 5: nid005582:196715:3943 [2] NCCL INFO misc/socket.cc:58 -> 3
 5: nid005582:196715:3943 [2] NCCL INFO misc/socket.cc:775 -> 3
 5: nid005582:196715:206694 [2] NCCL INFO misc/socket.cc:826 -> 3
 5: 
 5: nid005582:196715:206694 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
 5: 
 5: nid005582:196715:206694 [2] proxy.cc:1521 NCCL WARN [Proxy Service 22] Failed to execute operation Close from rank 22, retcode 3
 2: nid005577:17425:118763 [3] NCCL INFO misc/socket.cc:47 -> 3
 2: nid005577:17422:118762 [0] NCCL INFO misc/socket.cc:47 -> 3
 2: nid005577:17425:118763 [3] NCCL INFO misc/socket.cc:550 -> 3
 2: nid005577:17424:118761 [2] NCCL INFO misc/socket.cc:47 -> 3
 2: nid005577:17422:118762 [0] NCCL INFO misc/socket.cc:550 -> 3
 2: nid005577:17424:26955 [2] NCCL INFO misc/socket.cc:47 -> 3
 2: nid005577:17425:118763 [3] NCCL INFO misc/socket.cc:573 -> 3
 2: nid005577:17422:118762 [0] NCCL INFO misc/socket.cc:573 -> 3
 2: nid005577:17422:118762 [0] NCCL INFO misc/socket.cc:621 -> 3
 2: nid005577:17425:118763 [3] NCCL INFO misc/socket.cc:621 -> 3
 2: nid005577:17424:26955 [2] NCCL INFO misc/socket.cc:752 -> 3
 2: nid005577:17422:26959 [0] NCCL INFO misc/socket.cc:47 -> 3
 2: nid005577:17425:26953 [3] NCCL INFO misc/socket.cc:47 -> 3
 2: nid005577:17424:26955 [2] NCCL INFO misc/socket.cc:428 -> 3
 2: nid005577:17422:26959 [0] NCCL INFO misc/socket.cc:752 -> 3
 2: nid005577:17425:26953 [3] NCCL INFO misc/socket.cc:752 -> 3
 2: nid005577:17424:26955 [2] NCCL INFO misc/socket.cc:564 -> 3
 2: nid005577:17422:26959 [0] NCCL INFO misc/socket.cc:428 -> 3
 2: nid005577:17425:26953 [3] NCCL INFO misc/socket.cc:428 -> 3
 2: nid005577:17422:26959 [0] NCCL INFO misc/socket.cc:564 -> 3
 2: nid005577:17425:26953 [3] NCCL INFO misc/socket.cc:564 -> 3
 2: nid005577:17424:26955 [2] NCCL INFO misc/socket.cc:668 -> 3
 2: nid005577:17425:26953 [3] NCCL INFO misc/socket.cc:668 -> 3
 2: nid005577:17422:26959 [0] NCCL INFO misc/socket.cc:668 -> 3
 2: nid005577:17424:118761 [2] NCCL INFO misc/socket.cc:550 -> 3
 2: 
 2: nid005577:17425:26953 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 2: 
 2: nid005577:17422:26959 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 2: nid005577:17424:118761 [2] NCCL INFO misc/socket.cc:573 -> 3
 2: nid005577:17424:118761 [2] NCCL INFO misc/socket.cc:621 -> 3
 2: 
 2: nid005577:17424:26955 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 2: nid005577:17423:118764 [1] NCCL INFO misc/socket.cc:47 -> 3
 2: nid005577:17423:118764 [1] NCCL INFO misc/socket.cc:550 -> 3
 2: nid005577:17423:118764 [1] NCCL INFO misc/socket.cc:573 -> 3
 2: nid005577:17423:118764 [1] NCCL INFO misc/socket.cc:621 -> 3
 2: nid005577:17425:118763 [3] NCCL INFO misc/socket.cc:47 -> 3
 2: nid005577:17425:118763 [3] NCCL INFO misc/socket.cc:58 -> 3
 2: nid005577:17425:118763 [3] NCCL INFO misc/socket.cc:775 -> 3
 2: nid005577:17422:118762 [0] NCCL INFO misc/socket.cc:47 -> 3
 2: nid005577:17422:118762 [0] NCCL INFO misc/socket.cc:58 -> 3
 2: nid005577:17422:118762 [0] NCCL INFO misc/socket.cc:775 -> 3
 2: nid005577:17425:26953 [3] NCCL INFO misc/socket.cc:826 -> 3
 2: 
 2: nid005577:17425:26953 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
 2: nid005577:17422:26959 [0] NCCL INFO misc/socket.cc:826 -> 3
 2: nid005577:17423:26956 [1] NCCL INFO misc/socket.cc:47 -> 3
 2: 
 2: nid005577:17425:26953 [3] proxy.cc:1521 NCCL WARN [Proxy Service 11] Failed to execute operation Close from rank 11, retcode 3
 2: nid005577:17423:26956 [1] NCCL INFO misc/socket.cc:752 -> 3
 2: 
 2: nid005577:17422:26959 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
 2: nid005577:17423:26956 [1] NCCL INFO misc/socket.cc:428 -> 3
 2: nid005577:17423:26956 [1] NCCL INFO misc/socket.cc:564 -> 3
 2: nid005577:17423:26956 [1] NCCL INFO misc/socket.cc:668 -> 3
 2: 
 2: nid005577:17422:26959 [0] proxy.cc:1521 NCCL WARN [Proxy Service 8] Failed to execute operation Close from rank 8, retcode 3
 2: 
 2: nid005577:17423:26956 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 2: nid005577:17424:118761 [2] NCCL INFO misc/socket.cc:47 -> 3
 2: nid005577:17424:118761 [2] NCCL INFO misc/socket.cc:58 -> 3
 2: nid005577:17424:118761 [2] NCCL INFO misc/socket.cc:775 -> 3
 2: nid005577:17424:26955 [2] NCCL INFO misc/socket.cc:826 -> 3
 2: 
 2: nid005577:17424:26955 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
 2: 
 2: nid005577:17424:26955 [2] proxy.cc:1521 NCCL WARN [Proxy Service 10] Failed to execute operation Close from rank 10, retcode 3
 2: nid005577:17423:118764 [1] NCCL INFO misc/socket.cc:47 -> 3
 2: nid005577:17423:118764 [1] NCCL INFO misc/socket.cc:58 -> 3
 2: nid005577:17423:118764 [1] NCCL INFO misc/socket.cc:775 -> 3
 2: nid005577:17423:26956 [1] NCCL INFO misc/socket.cc:826 -> 3
 2: 
 2: nid005577:17423:26956 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
 2: 
 2: nid005577:17423:26956 [1] proxy.cc:1521 NCCL WARN [Proxy Service 9] Failed to execute operation Close from rank 9, retcode 3
25: nid005919:107463:211238 [1] NCCL INFO misc/socket.cc:47 -> 3
25: nid005919:107462:211236 [0] NCCL INFO misc/socket.cc:47 -> 3
25: nid005919:107463:211238 [1] NCCL INFO misc/socket.cc:550 -> 3
25: nid005919:107462:211236 [0] NCCL INFO misc/socket.cc:550 -> 3
25: nid005919:107463:211238 [1] NCCL INFO misc/socket.cc:573 -> 3
25: nid005919:107462:211236 [0] NCCL INFO misc/socket.cc:573 -> 3
25: nid005919:107462:211236 [0] NCCL INFO misc/socket.cc:621 -> 3
25: nid005919:107464:211237 [2] NCCL INFO misc/socket.cc:47 -> 3
25: nid005919:107463:211238 [1] NCCL INFO misc/socket.cc:621 -> 3
25: nid005919:107464:211237 [2] NCCL INFO misc/socket.cc:550 -> 3
25: nid005919:107464:211237 [2] NCCL INFO misc/socket.cc:573 -> 3
25: nid005919:107464:211237 [2] NCCL INFO misc/socket.cc:621 -> 3
25: nid005919:107463:116961 [1] NCCL INFO misc/socket.cc:47 -> 3
25: nid005919:107463:116961 [1] NCCL INFO misc/socket.cc:752 -> 3
25: nid005919:107463:116961 [1] NCCL INFO misc/socket.cc:428 -> 3
25: nid005919:107463:116961 [1] NCCL INFO misc/socket.cc:564 -> 3
25: nid005919:107463:116961 [1] NCCL INFO misc/socket.cc:668 -> 3
25: nid005919:107462:116963 [0] NCCL INFO misc/socket.cc:47 -> 3
25: 
25: nid005919:107463:116961 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
25: nid005919:107462:116963 [0] NCCL INFO misc/socket.cc:752 -> 3
25: nid005919:107464:116959 [2] NCCL INFO misc/socket.cc:47 -> 3
25: nid005919:107462:116963 [0] NCCL INFO misc/socket.cc:428 -> 3
25: nid005919:107462:116963 [0] NCCL INFO misc/socket.cc:564 -> 3
25: nid005919:107464:116959 [2] NCCL INFO misc/socket.cc:752 -> 3
25: nid005919:107462:116963 [0] NCCL INFO misc/socket.cc:668 -> 3
25: nid005919:107464:116959 [2] NCCL INFO misc/socket.cc:428 -> 3
25: nid005919:107464:116959 [2] NCCL INFO misc/socket.cc:564 -> 3
25: nid005919:107464:116959 [2] NCCL INFO misc/socket.cc:668 -> 3
25: nid005919:107465:211239 [3] NCCL INFO misc/socket.cc:47 -> 3
25: 
25: nid005919:107462:116963 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
25: nid005919:107465:211239 [3] NCCL INFO misc/socket.cc:550 -> 3
25: 
25: nid005919:107464:116959 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
25: nid005919:107465:211239 [3] NCCL INFO misc/socket.cc:573 -> 3
25: nid005919:107465:211239 [3] NCCL INFO misc/socket.cc:621 -> 3
25: nid005919:107465:116958 [3] NCCL INFO misc/socket.cc:47 -> 3
25: nid005919:107465:116958 [3] NCCL INFO misc/socket.cc:752 -> 3
25: nid005919:107463:211238 [1] NCCL INFO misc/socket.cc:47 -> 3
25: nid005919:107465:116958 [3] NCCL INFO misc/socket.cc:428 -> 3
25: nid005919:107463:211238 [1] NCCL INFO misc/socket.cc:58 -> 3
25: nid005919:107465:116958 [3] NCCL INFO misc/socket.cc:564 -> 3
25: nid005919:107463:211238 [1] NCCL INFO misc/socket.cc:775 -> 3
25: nid005919:107465:116958 [3] NCCL INFO misc/socket.cc:668 -> 3
25: nid005919:107463:116961 [1] NCCL INFO misc/socket.cc:826 -> 3
25: 
25: nid005919:107463:116961 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
25: nid005919:107464:211237 [2] NCCL INFO misc/socket.cc:47 -> 3
25: nid005919:107462:211236 [0] NCCL INFO misc/socket.cc:47 -> 3
25: nid005919:107464:211237 [2] NCCL INFO misc/socket.cc:58 -> 3
25: 
25: nid005919:107463:116961 [1] proxy.cc:1521 NCCL WARN [Proxy Service 101] Failed to execute operation Close from rank 101, retcode 3
25: nid005919:107462:211236 [0] NCCL INFO misc/socket.cc:58 -> 3
25: 
25: nid005919:107465:116958 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
25: nid005919:107464:116959 [2] NCCL INFO misc/socket.cc:826 -> 3
25: nid005919:107462:211236 [0] NCCL INFO misc/socket.cc:775 -> 3
25: 
25: nid005919:107464:116959 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
25: 
25: nid005919:107464:116959 [2] proxy.cc:1521 NCCL WARN [Proxy Service 102] Failed to execute operation Close from rank 102, retcode 3
25: nid005919:107462:116963 [0] NCCL INFO misc/socket.cc:826 -> 3
25: nid005919:107464:211237 [2] NCCL INFO misc/socket.cc:775 -> 3
25: 
25: nid005919:107462:116963 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
25: 
25: nid005919:107462:116963 [0] proxy.cc:1521 NCCL WARN [Proxy Service 100] Failed to execute operation Close from rank 100, retcode 3
25: nid005919:107465:211239 [3] NCCL INFO misc/socket.cc:47 -> 3
25: nid005919:107465:211239 [3] NCCL INFO misc/socket.cc:58 -> 3
25: nid005919:107465:211239 [3] NCCL INFO misc/socket.cc:775 -> 3
25: nid005919:107465:116958 [3] NCCL INFO misc/socket.cc:826 -> 3
25: 
25: nid005919:107465:116958 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
25: 
25: nid005919:107465:116958 [3] proxy.cc:1521 NCCL WARN [Proxy Service 103] Failed to execute operation Close from rank 103, retcode 3
 1: nid005576:147558:250806 [1] NCCL INFO misc/socket.cc:47 -> 3
 1: nid005576:147558:250806 [1] NCCL INFO misc/socket.cc:550 -> 3
 1: nid005576:147558:250806 [1] NCCL INFO misc/socket.cc:573 -> 3
 1: nid005576:147558:250806 [1] NCCL INFO misc/socket.cc:621 -> 3
 1: nid005576:147558:156964 [1] NCCL INFO misc/socket.cc:47 -> 3
 1: nid005576:147558:156964 [1] NCCL INFO misc/socket.cc:752 -> 3
 1: nid005576:147558:156964 [1] NCCL INFO misc/socket.cc:428 -> 3
 1: nid005576:147558:156964 [1] NCCL INFO misc/socket.cc:564 -> 3
 1: nid005576:147558:156964 [1] NCCL INFO misc/socket.cc:668 -> 3
 1: 
 1: nid005576:147558:156964 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
29: nid005932:167681:270268 [1] NCCL INFO misc/socket.cc:47 -> 3
29: nid005932:167681:270268 [1] NCCL INFO misc/socket.cc:550 -> 3
29: nid005932:167681:270268 [1] NCCL INFO misc/socket.cc:573 -> 3
29: nid005932:167681:270268 [1] NCCL INFO misc/socket.cc:621 -> 3
 1: nid005576:147559:250808 [2] NCCL INFO misc/socket.cc:47 -> 3
 1: nid005576:147559:250808 [2] NCCL INFO misc/socket.cc:550 -> 3
 1: nid005576:147559:250808 [2] NCCL INFO misc/socket.cc:573 -> 3
 1: nid005576:147559:250808 [2] NCCL INFO misc/socket.cc:621 -> 3
29: nid005932:167681:177118 [1] NCCL INFO misc/socket.cc:47 -> 3
29: nid005932:167681:177118 [1] NCCL INFO misc/socket.cc:752 -> 3
29: nid005932:167681:177118 [1] NCCL INFO misc/socket.cc:428 -> 3
29: nid005932:167681:177118 [1] NCCL INFO misc/socket.cc:564 -> 3
29: nid005932:167681:177118 [1] NCCL INFO misc/socket.cc:668 -> 3
29: nid005932:167680:270270 [0] NCCL INFO misc/socket.cc:47 -> 3
 1: nid005576:147560:250807 [3] NCCL INFO misc/socket.cc:47 -> 3
29: 
29: nid005932:167681:177118 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
29: nid005932:167680:270270 [0] NCCL INFO misc/socket.cc:550 -> 3
 1: nid005576:147560:250807 [3] NCCL INFO misc/socket.cc:550 -> 3
 1: nid005576:147560:250807 [3] NCCL INFO misc/socket.cc:573 -> 3
 1: nid005576:147560:250807 [3] NCCL INFO misc/socket.cc:621 -> 3
29: nid005932:167680:270270 [0] NCCL INFO misc/socket.cc:573 -> 3
29: nid005932:167680:270270 [0] NCCL INFO misc/socket.cc:621 -> 3
 1: nid005576:147559:156965 [2] NCCL INFO misc/socket.cc:47 -> 3
 1: nid005576:147559:156965 [2] NCCL INFO misc/socket.cc:752 -> 3
 1: nid005576:147559:156965 [2] NCCL INFO misc/socket.cc:428 -> 3
29: nid005932:167680:177120 [0] NCCL INFO misc/socket.cc:47 -> 3
29: nid005932:167682:270271 [2] NCCL INFO misc/socket.cc:47 -> 3
29: nid005932:167680:177120 [0] NCCL INFO misc/socket.cc:752 -> 3
29: nid005932:167682:270271 [2] NCCL INFO misc/socket.cc:550 -> 3
29: nid005932:167680:177120 [0] NCCL INFO misc/socket.cc:428 -> 3
29: nid005932:167682:270271 [2] NCCL INFO misc/socket.cc:573 -> 3
29: nid005932:167680:177120 [0] NCCL INFO misc/socket.cc:564 -> 3
29: nid005932:167682:270271 [2] NCCL INFO misc/socket.cc:621 -> 3
 1: nid005576:147559:156965 [2] NCCL INFO misc/socket.cc:564 -> 3
 1: nid005576:147559:156965 [2] NCCL INFO misc/socket.cc:668 -> 3
29: nid005932:167680:177120 [0] NCCL INFO misc/socket.cc:668 -> 3
29: 
29: nid005932:167680:177120 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
29: nid005932:167682:177116 [2] NCCL INFO misc/socket.cc:47 -> 3
29: nid005932:167681:270268 [1] NCCL INFO misc/socket.cc:47 -> 3
 1: 
 1: nid005576:147559:156965 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 1: nid005576:147558:250806 [1] NCCL INFO misc/socket.cc:47 -> 3
 1: nid005576:147558:250806 [1] NCCL INFO misc/socket.cc:58 -> 3
 1: nid005576:147558:250806 [1] NCCL INFO misc/socket.cc:775 -> 3
29: nid005932:167682:177116 [2] NCCL INFO misc/socket.cc:752 -> 3
29: nid005932:167681:270268 [1] NCCL INFO misc/socket.cc:58 -> 3
29: nid005932:167682:177116 [2] NCCL INFO misc/socket.cc:428 -> 3
29: nid005932:167682:177116 [2] NCCL INFO misc/socket.cc:564 -> 3
29: nid005932:167682:177116 [2] NCCL INFO misc/socket.cc:668 -> 3
29: nid005932:167681:270268 [1] NCCL INFO misc/socket.cc:775 -> 3
 1: nid005576:147560:156963 [3] NCCL INFO misc/socket.cc:47 -> 3
 1: nid005576:147558:156964 [1] NCCL INFO misc/socket.cc:826 -> 3
 1: nid005576:147560:156963 [3] NCCL INFO misc/socket.cc:752 -> 3
29: nid005932:167681:177118 [1] NCCL INFO misc/socket.cc:826 -> 3
29: 
29: nid005932:167682:177116 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
29: 
29: nid005932:167681:177118 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
 1: nid005576:147560:156963 [3] NCCL INFO misc/socket.cc:428 -> 3
 1: 
 1: nid005576:147558:156964 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
 1: nid005576:147560:156963 [3] NCCL INFO misc/socket.cc:564 -> 3
 1: nid005576:147560:156963 [3] NCCL INFO misc/socket.cc:668 -> 3
 1: nid005576:147557:250809 [0] NCCL INFO misc/socket.cc:47 -> 3
 1: 
 1: nid005576:147558:156964 [1] proxy.cc:1521 NCCL WARN [Proxy Service 5] Failed to execute operation Close from rank 5, retcode 3
 1: nid005576:147557:250809 [0] NCCL INFO misc/socket.cc:550 -> 3
29: 
29: nid005932:167681:177118 [1] proxy.cc:1521 NCCL WARN [Proxy Service 117] Failed to execute operation Close from rank 117, retcode 3
 1: nid005576:147557:250809 [0] NCCL INFO misc/socket.cc:573 -> 3
 1: 
 1: nid005576:147560:156963 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 1: nid005576:147557:250809 [0] NCCL INFO misc/socket.cc:621 -> 3
29: nid005932:167682:270271 [2] NCCL INFO misc/socket.cc:47 -> 3
29: nid005932:167682:270271 [2] NCCL INFO misc/socket.cc:58 -> 3
29: nid005932:167682:177116 [2] NCCL INFO misc/socket.cc:826 -> 3
29: nid005932:167680:270270 [0] NCCL INFO misc/socket.cc:47 -> 3
29: nid005932:167680:270270 [0] NCCL INFO misc/socket.cc:58 -> 3
 1: nid005576:147557:156969 [0] NCCL INFO misc/socket.cc:47 -> 3
 1: nid005576:147557:156969 [0] NCCL INFO misc/socket.cc:752 -> 3
 1: nid005576:147557:156969 [0] NCCL INFO misc/socket.cc:428 -> 3
 1: nid005576:147557:156969 [0] NCCL INFO misc/socket.cc:564 -> 3
 1: nid005576:147557:156969 [0] NCCL INFO misc/socket.cc:668 -> 3
 1: nid005576:147559:250808 [2] NCCL INFO misc/socket.cc:47 -> 3
 1: 
 1: nid005576:147557:156969 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 1: nid005576:147559:250808 [2] NCCL INFO misc/socket.cc:58 -> 3
 1: nid005576:147559:250808 [2] NCCL INFO misc/socket.cc:775 -> 3
 1: nid005576:147560:250807 [3] NCCL INFO misc/socket.cc:47 -> 3
29: nid005932:167680:270270 [0] NCCL INFO misc/socket.cc:775 -> 3
29: nid005932:167683:270269 [3] NCCL INFO misc/socket.cc:47 -> 3
 1: nid005576:147559:156965 [2] NCCL INFO misc/socket.cc:826 -> 3
 1: nid005576:147560:250807 [3] NCCL INFO misc/socket.cc:58 -> 3
 1: nid005576:147560:250807 [3] NCCL INFO misc/socket.cc:775 -> 3
 1: 
 1: nid005576:147559:156965 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
 1: nid005576:147560:156963 [3] NCCL INFO misc/socket.cc:826 -> 3
 1: 
 1: nid005576:147559:156965 [2] proxy.cc:1521 NCCL WARN [Proxy Service 6] Failed to execute operation Close from rank 6, retcode 3
 1: 
 1: nid005576:147560:156963 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
29: nid005932:167683:270269 [3] NCCL INFO misc/socket.cc:550 -> 3
29: nid005932:167683:270269 [3] NCCL INFO misc/socket.cc:573 -> 3
29: nid005932:167680:177120 [0] NCCL INFO misc/socket.cc:826 -> 3
29: nid005932:167683:270269 [3] NCCL INFO misc/socket.cc:621 -> 3
29: 
29: nid005932:167680:177120 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
 1: 
 1: nid005576:147560:156963 [3] proxy.cc:1521 NCCL WARN [Proxy Service 7] Failed to execute operation Close from rank 7, retcode 3
29: nid005932:167683:177114 [3] NCCL INFO misc/socket.cc:47 -> 3
29: 
29: nid005932:167680:177120 [0] proxy.cc:1521 NCCL WARN [Proxy Service 116] Failed to execute operation Close from rank 116, retcode 3
29: 
29: nid005932:167682:177116 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
29: nid005932:167683:177114 [3] NCCL INFO misc/socket.cc:752 -> 3
29: nid005932:167683:177114 [3] NCCL INFO misc/socket.cc:428 -> 3
29: 
29: nid005932:167682:177116 [2] proxy.cc:1521 NCCL WARN [Proxy Service 118] Failed to execute operation Close from rank 118, retcode 3
29: nid005932:167683:177114 [3] NCCL INFO misc/socket.cc:564 -> 3
 1: nid005576:147557:250809 [0] NCCL INFO misc/socket.cc:47 -> 3
 1: nid005576:147557:250809 [0] NCCL INFO misc/socket.cc:58 -> 3
29: nid005932:167683:177114 [3] NCCL INFO misc/socket.cc:668 -> 3
29: nid005932:167682:270271 [2] NCCL INFO misc/socket.cc:775 -> 3
29: 
29: nid005932:167683:177114 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 1: nid005576:147557:250809 [0] NCCL INFO misc/socket.cc:775 -> 3
29: nid005932:167683:270269 [3] NCCL INFO misc/socket.cc:47 -> 3
29: nid005932:167683:270269 [3] NCCL INFO misc/socket.cc:58 -> 3
29: nid005932:167683:270269 [3] NCCL INFO misc/socket.cc:775 -> 3
 1: nid005576:147557:156969 [0] NCCL INFO misc/socket.cc:826 -> 3
 1: 
 1: nid005576:147557:156969 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
 1: 
 1: nid005576:147557:156969 [0] proxy.cc:1521 NCCL WARN [Proxy Service 4] Failed to execute operation Close from rank 4, retcode 3
29: nid005932:167683:177114 [3] NCCL INFO misc/socket.cc:826 -> 3
29: 
29: nid005932:167683:177114 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
29: 
29: nid005932:167683:177114 [3] proxy.cc:1521 NCCL WARN [Proxy Service 119] Failed to execute operation Close from rank 119, retcode 3
10: nid005590:110711:213915 [1] NCCL INFO misc/socket.cc:47 -> 3
10: nid005590:110710:213916 [0] NCCL INFO misc/socket.cc:47 -> 3
10: nid005590:110713:213917 [3] NCCL INFO misc/socket.cc:47 -> 3
10: nid005590:110711:213915 [1] NCCL INFO misc/socket.cc:550 -> 3
10: nid005590:110710:213916 [0] NCCL INFO misc/socket.cc:550 -> 3
10: nid005590:110713:213917 [3] NCCL INFO misc/socket.cc:550 -> 3
10: nid005590:110711:213915 [1] NCCL INFO misc/socket.cc:573 -> 3
10: nid005590:110710:213916 [0] NCCL INFO misc/socket.cc:573 -> 3
10: nid005590:110713:213917 [3] NCCL INFO misc/socket.cc:573 -> 3
10: nid005590:110712:213918 [2] NCCL INFO misc/socket.cc:47 -> 3
10: nid005590:110710:213916 [0] NCCL INFO misc/socket.cc:621 -> 3
10: nid005590:110711:120122 [1] NCCL INFO misc/socket.cc:47 -> 3
10: nid005590:110713:213917 [3] NCCL INFO misc/socket.cc:621 -> 3
10: nid005590:110712:213918 [2] NCCL INFO misc/socket.cc:550 -> 3
10: nid005590:110712:213918 [2] NCCL INFO misc/socket.cc:573 -> 3
10: nid005590:110712:213918 [2] NCCL INFO misc/socket.cc:621 -> 3
10: nid005590:110711:120122 [1] NCCL INFO misc/socket.cc:752 -> 3
10: nid005590:110710:120127 [0] NCCL INFO misc/socket.cc:47 -> 3
10: nid005590:110713:120123 [3] NCCL INFO misc/socket.cc:47 -> 3
10: nid005590:110711:120122 [1] NCCL INFO misc/socket.cc:428 -> 3
10: nid005590:110710:120127 [0] NCCL INFO misc/socket.cc:752 -> 3
10: nid005590:110713:120123 [3] NCCL INFO misc/socket.cc:752 -> 3
10: nid005590:110710:120127 [0] NCCL INFO misc/socket.cc:428 -> 3
10: nid005590:110713:120123 [3] NCCL INFO misc/socket.cc:428 -> 3
10: nid005590:110711:120122 [1] NCCL INFO misc/socket.cc:564 -> 3
10: nid005590:110710:120127 [0] NCCL INFO misc/socket.cc:564 -> 3
10: nid005590:110713:120123 [3] NCCL INFO misc/socket.cc:564 -> 3
10: nid005590:110710:120127 [0] NCCL INFO misc/socket.cc:668 -> 3
10: nid005590:110711:120122 [1] NCCL INFO misc/socket.cc:668 -> 3
10: nid005590:110713:120123 [3] NCCL INFO misc/socket.cc:668 -> 3
10: nid005590:110712:120121 [2] NCCL INFO misc/socket.cc:47 -> 3
10: nid005590:110711:213915 [1] NCCL INFO misc/socket.cc:621 -> 3
10: nid005590:110712:120121 [2] NCCL INFO misc/socket.cc:752 -> 3
10: 
10: nid005590:110711:120122 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
10: 
10: nid005590:110710:120127 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
10: 
10: nid005590:110713:120123 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
10: nid005590:110712:120121 [2] NCCL INFO misc/socket.cc:428 -> 3
10: nid005590:110712:120121 [2] NCCL INFO misc/socket.cc:564 -> 3
10: nid005590:110712:120121 [2] NCCL INFO misc/socket.cc:668 -> 3
10: 
10: nid005590:110712:120121 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
10: nid005590:110712:213918 [2] NCCL INFO misc/socket.cc:47 -> 3
10: nid005590:110710:213916 [0] NCCL INFO misc/socket.cc:47 -> 3
10: nid005590:110713:213917 [3] NCCL INFO misc/socket.cc:47 -> 3
10: nid005590:110712:213918 [2] NCCL INFO misc/socket.cc:58 -> 3
10: nid005590:110710:213916 [0] NCCL INFO misc/socket.cc:58 -> 3
10: nid005590:110713:120123 [3] NCCL INFO misc/socket.cc:826 -> 3
13: nid005595:197885:6862 [2] NCCL INFO misc/socket.cc:47 -> 3
13: nid005595:197885:6862 [2] NCCL INFO misc/socket.cc:550 -> 3
13: nid005595:197885:6862 [2] NCCL INFO misc/socket.cc:573 -> 3
13: nid005595:197885:6862 [2] NCCL INFO misc/socket.cc:621 -> 3
10: nid005590:110712:213918 [2] NCCL INFO misc/socket.cc:775 -> 3
10: nid005590:110710:213916 [0] NCCL INFO misc/socket.cc:775 -> 3
10: 
10: nid005590:110713:120123 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
13: nid005595:197885:207696 [2] NCCL INFO misc/socket.cc:47 -> 3
13: nid005595:197885:207696 [2] NCCL INFO misc/socket.cc:752 -> 3
13: nid005595:197885:207696 [2] NCCL INFO misc/socket.cc:428 -> 3
13: nid005595:197885:207696 [2] NCCL INFO misc/socket.cc:564 -> 3
13: nid005595:197885:207696 [2] NCCL INFO misc/socket.cc:668 -> 3
10: nid005590:110712:120121 [2] NCCL INFO misc/socket.cc:826 -> 3
10: 
10: nid005590:110713:120123 [3] proxy.cc:1521 NCCL WARN [Proxy Service 43] Failed to execute operation Close from rank 43, retcode 3
10: 
10: nid005590:110712:120121 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
13: 
13: nid005595:197885:207696 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
13: nid005595:197886:6863 [3] NCCL INFO misc/socket.cc:47 -> 3
13: nid005595:197886:6863 [3] NCCL INFO misc/socket.cc:550 -> 3
13: nid005595:197886:6863 [3] NCCL INFO misc/socket.cc:573 -> 3
13: nid005595:197886:6863 [3] NCCL INFO misc/socket.cc:621 -> 3
23: nid005917:276888:86828 [3] NCCL INFO misc/socket.cc:47 -> 3
23: nid005917:276888:86828 [3] NCCL INFO misc/socket.cc:550 -> 3
23: nid005917:276888:86828 [3] NCCL INFO misc/socket.cc:573 -> 3
23: nid005917:276888:86828 [3] NCCL INFO misc/socket.cc:621 -> 3
23: nid005917:276885:86830 [0] NCCL INFO misc/socket.cc:47 -> 3
23: nid005917:276885:86830 [0] NCCL INFO misc/socket.cc:550 -> 3
23: nid005917:276885:86830 [0] NCCL INFO misc/socket.cc:573 -> 3
10: 
10: nid005590:110712:120121 [2] proxy.cc:1521 NCCL WARN [Proxy Service 42] Failed to execute operation Close from rank 42, retcode 3
10: nid005590:110710:120127 [0] NCCL INFO misc/socket.cc:826 -> 3
10: nid005590:110713:213917 [3] NCCL INFO misc/socket.cc:58 -> 3
13: nid005595:197886:207695 [3] NCCL INFO misc/socket.cc:47 -> 3
13: nid005595:197886:207695 [3] NCCL INFO misc/socket.cc:752 -> 3
23: nid005917:276885:86830 [0] NCCL INFO misc/socket.cc:621 -> 3
23: nid005917:276885:286369 [0] NCCL INFO misc/socket.cc:47 -> 3
23: nid005917:276885:286369 [0] NCCL INFO misc/socket.cc:752 -> 3
23: nid005917:276885:286369 [0] NCCL INFO misc/socket.cc:428 -> 3
23: nid005917:276885:286369 [0] NCCL INFO misc/socket.cc:564 -> 3
23: nid005917:276888:286365 [3] NCCL INFO misc/socket.cc:47 -> 3
23: nid005917:276885:286369 [0] NCCL INFO misc/socket.cc:668 -> 3
23: nid005917:276888:286365 [3] NCCL INFO misc/socket.cc:752 -> 3
23: nid005917:276888:286365 [3] NCCL INFO misc/socket.cc:428 -> 3
23: 
23: nid005917:276885:286369 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
23: nid005917:276887:86831 [2] NCCL INFO misc/socket.cc:47 -> 3
23: nid005917:276886:86829 [1] NCCL INFO misc/socket.cc:47 -> 3
23: nid005917:276888:286365 [3] NCCL INFO misc/socket.cc:564 -> 3
23: nid005917:276887:86831 [2] NCCL INFO misc/socket.cc:550 -> 3
23: nid005917:276886:86829 [1] NCCL INFO misc/socket.cc:550 -> 3
10: 
10: nid005590:110710:120127 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
10: nid005590:110713:213917 [3] NCCL INFO misc/socket.cc:775 -> 3
10: 
10: nid005590:110710:120127 [0] proxy.cc:1521 NCCL WARN [Proxy Service 40] Failed to execute operation Close from rank 40, retcode 3
10: nid005590:110711:213915 [1] NCCL INFO misc/socket.cc:47 -> 3
10: nid005590:110711:120122 [1] NCCL INFO misc/socket.cc:826 -> 3
13: nid005595:197886:207695 [3] NCCL INFO misc/socket.cc:428 -> 3
13: nid005595:197886:207695 [3] NCCL INFO misc/socket.cc:564 -> 3
13: nid005595:197886:207695 [3] NCCL INFO misc/socket.cc:668 -> 3
23: nid005917:276888:286365 [3] NCCL INFO misc/socket.cc:668 -> 3
23: nid005917:276887:86831 [2] NCCL INFO misc/socket.cc:573 -> 3
23: nid005917:276886:86829 [1] NCCL INFO misc/socket.cc:573 -> 3
23: nid005917:276887:86831 [2] NCCL INFO misc/socket.cc:621 -> 3
23: nid005917:276886:86829 [1] NCCL INFO misc/socket.cc:621 -> 3
23: 
23: nid005917:276888:286365 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
10: 
10: nid005590:110711:120122 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
13: 
13: nid005595:197886:207695 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
23: nid005917:276885:86830 [0] NCCL INFO misc/socket.cc:47 -> 3
23: nid005917:276885:86830 [0] NCCL INFO misc/socket.cc:58 -> 3
23: nid005917:276886:286370 [1] NCCL INFO misc/socket.cc:47 -> 3
23: nid005917:276885:86830 [0] NCCL INFO misc/socket.cc:775 -> 3
23: nid005917:276886:286370 [1] NCCL INFO misc/socket.cc:752 -> 3
10: 
10: nid005590:110711:120122 [1] proxy.cc:1521 NCCL WARN [Proxy Service 41] Failed to execute operation Close from rank 41, retcode 3
13: nid005595:197885:6862 [2] NCCL INFO misc/socket.cc:47 -> 3
13: nid005595:197885:6862 [2] NCCL INFO misc/socket.cc:58 -> 3
13: nid005595:197885:6862 [2] NCCL INFO misc/socket.cc:775 -> 3
23: nid005917:276885:286369 [0] NCCL INFO misc/socket.cc:826 -> 3
23: nid005917:276888:86828 [3] NCCL INFO misc/socket.cc:47 -> 3
23: nid005917:276886:286370 [1] NCCL INFO misc/socket.cc:428 -> 3
23: nid005917:276887:286366 [2] NCCL INFO misc/socket.cc:47 -> 3
23: nid005917:276888:286365 [3] NCCL INFO misc/socket.cc:826 -> 3
23: 
23: nid005917:276885:286369 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
10: nid005590:110711:213915 [1] NCCL INFO misc/socket.cc:58 -> 3
10: nid005590:110711:213915 [1] NCCL INFO misc/socket.cc:775 -> 3
13: nid005595:197885:207696 [2] NCCL INFO misc/socket.cc:826 -> 3
13: 
13: nid005595:197885:207696 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
13: 
13: nid005595:197885:207696 [2] proxy.cc:1521 NCCL WARN [Proxy Service 54] Failed to execute operation Close from rank 54, retcode 3
13: nid005595:197884:6864 [1] NCCL INFO misc/socket.cc:47 -> 3
13: nid005595:197884:6864 [1] NCCL INFO misc/socket.cc:550 -> 3
13: nid005595:197884:6864 [1] NCCL INFO misc/socket.cc:573 -> 3
13: nid005595:197884:6864 [1] NCCL INFO misc/socket.cc:621 -> 3
13: nid005595:197884:207698 [1] NCCL INFO misc/socket.cc:47 -> 3
13: nid005595:197884:207698 [1] NCCL INFO misc/socket.cc:752 -> 3
13: nid005595:197884:207698 [1] NCCL INFO misc/socket.cc:428 -> 3
13: nid005595:197884:207698 [1] NCCL INFO misc/socket.cc:564 -> 3
13: nid005595:197884:207698 [1] NCCL INFO misc/socket.cc:668 -> 3
23: nid005917:276886:286370 [1] NCCL INFO misc/socket.cc:564 -> 3
23: nid005917:276887:286366 [2] NCCL INFO misc/socket.cc:752 -> 3
23: 
23: nid005917:276888:286365 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
23: 
23: nid005917:276885:286369 [0] proxy.cc:1521 NCCL WARN [Proxy Service 92] Failed to execute operation Close from rank 92, retcode 3
23: nid005917:276887:286366 [2] NCCL INFO misc/socket.cc:428 -> 3
23: nid005917:276886:286370 [1] NCCL INFO misc/socket.cc:668 -> 3
23: nid005917:276888:86828 [3] NCCL INFO misc/socket.cc:58 -> 3
13: nid005595:197883:6865 [0] NCCL INFO misc/socket.cc:47 -> 3
13: nid005595:197883:6865 [0] NCCL INFO misc/socket.cc:550 -> 3
13: nid005595:197883:6865 [0] NCCL INFO misc/socket.cc:573 -> 3
13: 
13: nid005595:197884:207698 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
13: nid005595:197883:6865 [0] NCCL INFO misc/socket.cc:621 -> 3
13: nid005595:197886:6863 [3] NCCL INFO misc/socket.cc:47 -> 3
23: 
23: nid005917:276886:286370 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
23: nid005917:276887:286366 [2] NCCL INFO misc/socket.cc:564 -> 3
23: nid005917:276888:86828 [3] NCCL INFO misc/socket.cc:775 -> 3
23: nid005917:276887:286366 [2] NCCL INFO misc/socket.cc:668 -> 3
13: nid005595:197886:207695 [3] NCCL INFO misc/socket.cc:826 -> 3
13: 
13: nid005595:197886:207695 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
13: 
13: nid005595:197886:207695 [3] proxy.cc:1521 NCCL WARN [Proxy Service 55] Failed to execute operation Close from rank 55, retcode 3
13: nid005595:197883:207701 [0] NCCL INFO misc/socket.cc:47 -> 3
23: nid005917:276886:86829 [1] NCCL INFO misc/socket.cc:47 -> 3
23: nid005917:276886:86829 [1] NCCL INFO misc/socket.cc:58 -> 3
23: nid005917:276886:86829 [1] NCCL INFO misc/socket.cc:775 -> 3
23: 
23: nid005917:276888:286365 [3] proxy.cc:1521 NCCL WARN [Proxy Service 95] Failed to execute operation Close from rank 95, retcode 3
23: 
23: nid005917:276887:286366 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
13: nid005595:197883:207701 [0] NCCL INFO misc/socket.cc:752 -> 3
13: nid005595:197886:6863 [3] NCCL INFO misc/socket.cc:58 -> 3
13: nid005595:197883:207701 [0] NCCL INFO misc/socket.cc:428 -> 3
13: nid005595:197886:6863 [3] NCCL INFO misc/socket.cc:775 -> 3
13: nid005595:197883:207701 [0] NCCL INFO misc/socket.cc:564 -> 3
23: nid005917:276886:286370 [1] NCCL INFO misc/socket.cc:826 -> 3
23: 
23: nid005917:276886:286370 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
23: nid005917:276887:286366 [2] NCCL INFO misc/socket.cc:826 -> 3
23: 
23: nid005917:276886:286370 [1] proxy.cc:1521 NCCL WARN [Proxy Service 93] Failed to execute operation Close from rank 93, retcode 3
13: nid005595:197883:207701 [0] NCCL INFO misc/socket.cc:668 -> 3
13: 
13: nid005595:197883:207701 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
13: nid005595:197884:6864 [1] NCCL INFO misc/socket.cc:47 -> 3
13: nid005595:197884:6864 [1] NCCL INFO misc/socket.cc:58 -> 3
23: 
23: nid005917:276887:286366 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
23: 
23: nid005917:276887:286366 [2] proxy.cc:1521 NCCL WARN [Proxy Service 94] Failed to execute operation Close from rank 94, retcode 3
23: nid005917:276887:86831 [2] NCCL INFO misc/socket.cc:47 -> 3
23: nid005917:276887:86831 [2] NCCL INFO misc/socket.cc:58 -> 3
23: nid005917:276887:86831 [2] NCCL INFO misc/socket.cc:775 -> 3
13: nid005595:197884:6864 [1] NCCL INFO misc/socket.cc:775 -> 3
13: nid005595:197884:207698 [1] NCCL INFO misc/socket.cc:826 -> 3
13: 
13: nid005595:197884:207698 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
13: 
13: nid005595:197884:207698 [1] proxy.cc:1521 NCCL WARN [Proxy Service 53] Failed to execute operation Close from rank 53, retcode 3
13: nid005595:197883:6865 [0] NCCL INFO misc/socket.cc:47 -> 3
13: nid005595:197883:6865 [0] NCCL INFO misc/socket.cc:58 -> 3
13: nid005595:197883:6865 [0] NCCL INFO misc/socket.cc:775 -> 3
13: nid005595:197883:207701 [0] NCCL INFO misc/socket.cc:826 -> 3
13: 
13: nid005595:197883:207701 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
13: 
13: nid005595:197883:207701 [0] proxy.cc:1521 NCCL WARN [Proxy Service 52] Failed to execute operation Close from rank 52, retcode 3
19: nid005912:12437:113118 [2] NCCL INFO misc/socket.cc:47 -> 3
19: nid005912:12438:113119 [3] NCCL INFO misc/socket.cc:47 -> 3
19: nid005912:12435:113120 [0] NCCL INFO misc/socket.cc:47 -> 3
19: nid005912:12437:113118 [2] NCCL INFO misc/socket.cc:550 -> 3
19: nid005912:12438:113119 [3] NCCL INFO misc/socket.cc:550 -> 3
19: nid005912:12435:113120 [0] NCCL INFO misc/socket.cc:550 -> 3
19: nid005912:12437:113118 [2] NCCL INFO misc/socket.cc:573 -> 3
19: nid005912:12438:113119 [3] NCCL INFO misc/socket.cc:573 -> 3
19: nid005912:12435:113120 [0] NCCL INFO misc/socket.cc:573 -> 3
19: nid005912:12435:113120 [0] NCCL INFO misc/socket.cc:621 -> 3
19: nid005912:12437:113118 [2] NCCL INFO misc/socket.cc:621 -> 3
19: nid005912:12438:113119 [3] NCCL INFO misc/socket.cc:621 -> 3
19: nid005912:12438:21869 [3] NCCL INFO misc/socket.cc:47 -> 3
19: nid005912:12438:21869 [3] NCCL INFO misc/socket.cc:752 -> 3
19: nid005912:12438:21869 [3] NCCL INFO misc/socket.cc:428 -> 3
19: nid005912:12438:21869 [3] NCCL INFO misc/socket.cc:564 -> 3
19: nid005912:12438:21869 [3] NCCL INFO misc/socket.cc:668 -> 3
19: 
19: nid005912:12438:21869 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
19: nid005912:12437:21870 [2] NCCL INFO misc/socket.cc:47 -> 3
19: nid005912:12435:21875 [0] NCCL INFO misc/socket.cc:47 -> 3
19: nid005912:12437:21870 [2] NCCL INFO misc/socket.cc:752 -> 3
19: nid005912:12435:21875 [0] NCCL INFO misc/socket.cc:752 -> 3
19: nid005912:12437:21870 [2] NCCL INFO misc/socket.cc:428 -> 3
19: nid005912:12436:113121 [1] NCCL INFO misc/socket.cc:47 -> 3
19: nid005912:12435:21875 [0] NCCL INFO misc/socket.cc:428 -> 3
19: nid005912:12437:21870 [2] NCCL INFO misc/socket.cc:564 -> 3
19: nid005912:12435:21875 [0] NCCL INFO misc/socket.cc:564 -> 3
19: nid005912:12436:113121 [1] NCCL INFO misc/socket.cc:550 -> 3
19: nid005912:12437:21870 [2] NCCL INFO misc/socket.cc:668 -> 3
19: nid005912:12436:113121 [1] NCCL INFO misc/socket.cc:573 -> 3
19: nid005912:12435:21875 [0] NCCL INFO misc/socket.cc:668 -> 3
19: nid005912:12436:113121 [1] NCCL INFO misc/socket.cc:621 -> 3
19: 
19: nid005912:12437:21870 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
19: 
19: nid005912:12435:21875 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
19: nid005912:12438:113119 [3] NCCL INFO misc/socket.cc:47 -> 3
19: nid005912:12438:113119 [3] NCCL INFO misc/socket.cc:58 -> 3
19: nid005912:12438:113119 [3] NCCL INFO misc/socket.cc:775 -> 3
19: nid005912:12436:21872 [1] NCCL INFO misc/socket.cc:47 -> 3
19: nid005912:12438:21869 [3] NCCL INFO misc/socket.cc:826 -> 3
19: nid005912:12436:21872 [1] NCCL INFO misc/socket.cc:752 -> 3
19: 
19: nid005912:12438:21869 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
19: nid005912:12436:21872 [1] NCCL INFO misc/socket.cc:428 -> 3
19: 
19: nid005912:12438:21869 [3] proxy.cc:1521 NCCL WARN [Proxy Service 79] Failed to execute operation Close from rank 79, retcode 3
19: nid005912:12437:113118 [2] NCCL INFO misc/socket.cc:47 -> 3
19: nid005912:12436:21872 [1] NCCL INFO misc/socket.cc:564 -> 3
19: nid005912:12435:113120 [0] NCCL INFO misc/socket.cc:47 -> 3
19: nid005912:12437:113118 [2] NCCL INFO misc/socket.cc:58 -> 3
19: nid005912:12436:21872 [1] NCCL INFO misc/socket.cc:668 -> 3
19: nid005912:12437:113118 [2] NCCL INFO misc/socket.cc:775 -> 3
19: nid005912:12435:113120 [0] NCCL INFO misc/socket.cc:58 -> 3
19: 
19: nid005912:12436:21872 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
19: nid005912:12437:21870 [2] NCCL INFO misc/socket.cc:826 -> 3
19: nid005912:12435:113120 [0] NCCL INFO misc/socket.cc:775 -> 3
19: 
19: nid005912:12437:21870 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
19: nid005912:12435:21875 [0] NCCL INFO misc/socket.cc:826 -> 3
19: 
19: nid005912:12437:21870 [2] proxy.cc:1521 NCCL WARN [Proxy Service 78] Failed to execute operation Close from rank 78, retcode 3
19: 
19: nid005912:12435:21875 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
19: 
19: nid005912:12435:21875 [0] proxy.cc:1521 NCCL WARN [Proxy Service 76] Failed to execute operation Close from rank 76, retcode 3
19: nid005912:12436:113121 [1] NCCL INFO misc/socket.cc:47 -> 3
19: nid005912:12436:113121 [1] NCCL INFO misc/socket.cc:58 -> 3
19: nid005912:12436:113121 [1] NCCL INFO misc/socket.cc:775 -> 3
19: nid005912:12436:21872 [1] NCCL INFO misc/socket.cc:826 -> 3
19: 
19: nid005912:12436:21872 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
19: 
19: nid005912:12436:21872 [1] proxy.cc:1521 NCCL WARN [Proxy Service 77] Failed to execute operation Close from rank 77, retcode 3
28: nid005929:16033:116163 [3] NCCL INFO misc/socket.cc:47 -> 3
28: nid005929:16033:116163 [3] NCCL INFO misc/socket.cc:550 -> 3
28: nid005929:16033:116163 [3] NCCL INFO misc/socket.cc:573 -> 3
28: nid005929:16033:116163 [3] NCCL INFO misc/socket.cc:621 -> 3
28: nid005929:16030:116164 [0] NCCL INFO misc/socket.cc:47 -> 3
28: nid005929:16033:25501 [3] NCCL INFO misc/socket.cc:47 -> 3
28: nid005929:16032:116162 [2] NCCL INFO misc/socket.cc:47 -> 3
28: nid005929:16033:25501 [3] NCCL INFO misc/socket.cc:752 -> 3
28: nid005929:16030:116164 [0] NCCL INFO misc/socket.cc:550 -> 3
28: nid005929:16032:116162 [2] NCCL INFO misc/socket.cc:550 -> 3
28: nid005929:16030:116164 [0] NCCL INFO misc/socket.cc:573 -> 3
28: nid005929:16033:25501 [3] NCCL INFO misc/socket.cc:428 -> 3
28: nid005929:16032:116162 [2] NCCL INFO misc/socket.cc:573 -> 3
28: nid005929:16033:25501 [3] NCCL INFO misc/socket.cc:564 -> 3
28: nid005929:16030:116164 [0] NCCL INFO misc/socket.cc:621 -> 3
28: nid005929:16032:116162 [2] NCCL INFO misc/socket.cc:621 -> 3
28: nid005929:16033:25501 [3] NCCL INFO misc/socket.cc:668 -> 3
28: nid005929:16032:25499 [2] NCCL INFO misc/socket.cc:47 -> 3
28: nid005929:16032:25499 [2] NCCL INFO misc/socket.cc:752 -> 3
28: 
28: nid005929:16033:25501 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
28: nid005929:16032:25499 [2] NCCL INFO misc/socket.cc:428 -> 3
28: nid005929:16032:25499 [2] NCCL INFO misc/socket.cc:564 -> 3
28: nid005929:16032:25499 [2] NCCL INFO misc/socket.cc:668 -> 3
28: nid005929:16030:25505 [0] NCCL INFO misc/socket.cc:47 -> 3
28: 
28: nid005929:16032:25499 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
28: nid005929:16030:25505 [0] NCCL INFO misc/socket.cc:752 -> 3
28: nid005929:16030:25505 [0] NCCL INFO misc/socket.cc:428 -> 3
28: nid005929:16030:25505 [0] NCCL INFO misc/socket.cc:564 -> 3
28: nid005929:16030:25505 [0] NCCL INFO misc/socket.cc:668 -> 3
28: 
28: nid005929:16030:25505 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
28: nid005929:16033:116163 [3] NCCL INFO misc/socket.cc:47 -> 3
28: nid005929:16033:116163 [3] NCCL INFO misc/socket.cc:58 -> 3
28: nid005929:16033:116163 [3] NCCL INFO misc/socket.cc:775 -> 3
28: nid005929:16033:25501 [3] NCCL INFO misc/socket.cc:826 -> 3
28: 
28: nid005929:16033:25501 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
28: 
28: nid005929:16033:25501 [3] proxy.cc:1521 NCCL WARN [Proxy Service 115] Failed to execute operation Close from rank 115, retcode 3
28: nid005929:16031:116165 [1] NCCL INFO misc/socket.cc:47 -> 3
28: nid005929:16032:116162 [2] NCCL INFO misc/socket.cc:47 -> 3
28: nid005929:16031:116165 [1] NCCL INFO misc/socket.cc:550 -> 3
28: nid005929:16032:116162 [2] NCCL INFO misc/socket.cc:58 -> 3
28: nid005929:16031:116165 [1] NCCL INFO misc/socket.cc:573 -> 3
28: nid005929:16031:116165 [1] NCCL INFO misc/socket.cc:621 -> 3
28: nid005929:16032:116162 [2] NCCL INFO misc/socket.cc:775 -> 3
28: nid005929:16030:116164 [0] NCCL INFO misc/socket.cc:47 -> 3
28: nid005929:16031:25502 [1] NCCL INFO misc/socket.cc:47 -> 3
28: nid005929:16030:116164 [0] NCCL INFO misc/socket.cc:58 -> 3
28: nid005929:16032:25499 [2] NCCL INFO misc/socket.cc:826 -> 3
28: nid005929:16031:25502 [1] NCCL INFO misc/socket.cc:752 -> 3
28: nid005929:16030:116164 [0] NCCL INFO misc/socket.cc:775 -> 3
28: nid005929:16031:25502 [1] NCCL INFO misc/socket.cc:428 -> 3
28: 
28: nid005929:16032:25499 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
28: nid005929:16031:25502 [1] NCCL INFO misc/socket.cc:564 -> 3
28: nid005929:16031:25502 [1] NCCL INFO misc/socket.cc:668 -> 3
28: 
28: nid005929:16032:25499 [2] proxy.cc:1521 NCCL WARN [Proxy Service 114] Failed to execute operation Close from rank 114, retcode 3
28: nid005929:16030:25505 [0] NCCL INFO misc/socket.cc:826 -> 3
28: 
28: nid005929:16031:25502 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
28: 
28: nid005929:16030:25505 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
28: 
28: nid005929:16030:25505 [0] proxy.cc:1521 NCCL WARN [Proxy Service 112] Failed to execute operation Close from rank 112, retcode 3
28: nid005929:16031:116165 [1] NCCL INFO misc/socket.cc:47 -> 3
28: nid005929:16031:116165 [1] NCCL INFO misc/socket.cc:58 -> 3
28: nid005929:16031:25502 [1] NCCL INFO misc/socket.cc:826 -> 3
28: 
28: nid005929:16031:25502 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
28: nid005929:16031:116165 [1] NCCL INFO misc/socket.cc:775 -> 3
28: 
28: nid005929:16031:25502 [1] proxy.cc:1521 NCCL WARN [Proxy Service 113] Failed to execute operation Close from rank 113, retcode 3
24: nid005918:92507:194029 [3] NCCL INFO misc/socket.cc:47 -> 3
24: nid005918:92507:194029 [3] NCCL INFO misc/socket.cc:550 -> 3
24: nid005918:92507:194029 [3] NCCL INFO misc/socket.cc:573 -> 3
24: nid005918:92507:194029 [3] NCCL INFO misc/socket.cc:621 -> 3
24: nid005918:92507:101974 [3] NCCL INFO misc/socket.cc:47 -> 3
24: nid005918:92507:101974 [3] NCCL INFO misc/socket.cc:752 -> 3
24: nid005918:92507:101974 [3] NCCL INFO misc/socket.cc:428 -> 3
24: nid005918:92507:101974 [3] NCCL INFO misc/socket.cc:564 -> 3
24: nid005918:92507:101974 [3] NCCL INFO misc/socket.cc:668 -> 3
24: 
24: nid005918:92507:101974 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
24: nid005918:92505:194031 [1] NCCL INFO misc/socket.cc:47 -> 3
24: nid005918:92505:194031 [1] NCCL INFO misc/socket.cc:550 -> 3
24: nid005918:92505:194031 [1] NCCL INFO misc/socket.cc:573 -> 3
24: nid005918:92505:194031 [1] NCCL INFO misc/socket.cc:621 -> 3
24: nid005918:92504:194030 [0] NCCL INFO misc/socket.cc:47 -> 3
24: nid005918:92504:194030 [0] NCCL INFO misc/socket.cc:550 -> 3
24: nid005918:92504:194030 [0] NCCL INFO misc/socket.cc:573 -> 3
24: nid005918:92504:194030 [0] NCCL INFO misc/socket.cc:621 -> 3
24: nid005918:92506:194032 [2] NCCL INFO misc/socket.cc:47 -> 3
24: nid005918:92504:101979 [0] NCCL INFO misc/socket.cc:47 -> 3
24: nid005918:92505:101978 [1] NCCL INFO misc/socket.cc:47 -> 3
24: nid005918:92506:194032 [2] NCCL INFO misc/socket.cc:550 -> 3
24: nid005918:92504:101979 [0] NCCL INFO misc/socket.cc:752 -> 3
24: nid005918:92505:101978 [1] NCCL INFO misc/socket.cc:752 -> 3
24: nid005918:92504:101979 [0] NCCL INFO misc/socket.cc:428 -> 3
24: nid005918:92506:194032 [2] NCCL INFO misc/socket.cc:573 -> 3
24: nid005918:92507:194029 [3] NCCL INFO misc/socket.cc:47 -> 3
24: nid005918:92504:101979 [0] NCCL INFO misc/socket.cc:564 -> 3
24: nid005918:92505:101978 [1] NCCL INFO misc/socket.cc:428 -> 3
24: nid005918:92504:101979 [0] NCCL INFO misc/socket.cc:668 -> 3
24: nid005918:92506:194032 [2] NCCL INFO misc/socket.cc:621 -> 3
24: nid005918:92507:194029 [3] NCCL INFO misc/socket.cc:58 -> 3
24: nid005918:92505:101978 [1] NCCL INFO misc/socket.cc:564 -> 3
24: 
24: nid005918:92504:101979 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
24: nid005918:92507:194029 [3] NCCL INFO misc/socket.cc:775 -> 3
24: nid005918:92505:101978 [1] NCCL INFO misc/socket.cc:668 -> 3
24: nid005918:92506:101976 [2] NCCL INFO misc/socket.cc:47 -> 3
24: 
24: nid005918:92505:101978 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
24: nid005918:92506:101976 [2] NCCL INFO misc/socket.cc:752 -> 3
24: nid005918:92507:101974 [3] NCCL INFO misc/socket.cc:826 -> 3
24: nid005918:92506:101976 [2] NCCL INFO misc/socket.cc:428 -> 3
24: 
24: nid005918:92507:101974 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
24: nid005918:92506:101976 [2] NCCL INFO misc/socket.cc:564 -> 3
24: nid005918:92504:194030 [0] NCCL INFO misc/socket.cc:47 -> 3
24: nid005918:92506:101976 [2] NCCL INFO misc/socket.cc:668 -> 3
24: nid005918:92504:194030 [0] NCCL INFO misc/socket.cc:58 -> 3
24: 
24: nid005918:92507:101974 [3] proxy.cc:1521 NCCL WARN [Proxy Service 99] Failed to execute operation Close from rank 99, retcode 3
24: nid005918:92505:194031 [1] NCCL INFO misc/socket.cc:47 -> 3
24: 
24: nid005918:92506:101976 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
24: nid005918:92504:194030 [0] NCCL INFO misc/socket.cc:775 -> 3
24: nid005918:92504:101979 [0] NCCL INFO misc/socket.cc:826 -> 3
24: nid005918:92505:194031 [1] NCCL INFO misc/socket.cc:58 -> 3
24: 
24: nid005918:92504:101979 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
24: 
24: nid005918:92504:101979 [0] proxy.cc:1521 NCCL WARN [Proxy Service 96] Failed to execute operation Close from rank 96, retcode 3
24: nid005918:92505:194031 [1] NCCL INFO misc/socket.cc:775 -> 3
24: nid005918:92505:101978 [1] NCCL INFO misc/socket.cc:826 -> 3
24: 
24: nid005918:92505:101978 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
24: 
24: nid005918:92505:101978 [1] proxy.cc:1521 NCCL WARN [Proxy Service 97] Failed to execute operation Close from rank 97, retcode 3
24: nid005918:92506:194032 [2] NCCL INFO misc/socket.cc:47 -> 3
24: nid005918:92506:194032 [2] NCCL INFO misc/socket.cc:58 -> 3
24: nid005918:92506:194032 [2] NCCL INFO misc/socket.cc:775 -> 3
24: nid005918:92506:101976 [2] NCCL INFO misc/socket.cc:826 -> 3
24: 
24: nid005918:92506:101976 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
24: 
24: nid005918:92506:101976 [2] proxy.cc:1521 NCCL WARN [Proxy Service 98] Failed to execute operation Close from rank 98, retcode 3
27: nid005922:80741:183169 [0] NCCL INFO misc/socket.cc:47 -> 3
27: nid005922:80741:183169 [0] NCCL INFO misc/socket.cc:550 -> 3
27: nid005922:80741:183169 [0] NCCL INFO misc/socket.cc:573 -> 3
27: nid005922:80741:183169 [0] NCCL INFO misc/socket.cc:621 -> 3
27: nid005922:80742:183170 [1] NCCL INFO misc/socket.cc:47 -> 3
27: nid005922:80742:183170 [1] NCCL INFO misc/socket.cc:550 -> 3
27: nid005922:80742:183170 [1] NCCL INFO misc/socket.cc:573 -> 3
27: nid005922:80742:183170 [1] NCCL INFO misc/socket.cc:621 -> 3
27: nid005922:80744:183171 [3] NCCL INFO misc/socket.cc:47 -> 3
27: nid005922:80744:183171 [3] NCCL INFO misc/socket.cc:550 -> 3
27: nid005922:80744:183171 [3] NCCL INFO misc/socket.cc:573 -> 3
27: nid005922:80743:183172 [2] NCCL INFO misc/socket.cc:47 -> 3
27: nid005922:80744:183171 [3] NCCL INFO misc/socket.cc:621 -> 3
27: nid005922:80741:90174 [0] NCCL INFO misc/socket.cc:47 -> 3
27: nid005922:80743:183172 [2] NCCL INFO misc/socket.cc:550 -> 3
27: nid005922:80741:90174 [0] NCCL INFO misc/socket.cc:752 -> 3
27: nid005922:80743:183172 [2] NCCL INFO misc/socket.cc:573 -> 3
27: nid005922:80741:90174 [0] NCCL INFO misc/socket.cc:428 -> 3
27: nid005922:80743:183172 [2] NCCL INFO misc/socket.cc:621 -> 3
27: nid005922:80741:90174 [0] NCCL INFO misc/socket.cc:564 -> 3
27: nid005922:80741:90174 [0] NCCL INFO misc/socket.cc:668 -> 3
27: nid005922:80743:90168 [2] NCCL INFO misc/socket.cc:47 -> 3
27: nid005922:80742:90170 [1] NCCL INFO misc/socket.cc:47 -> 3
27: nid005922:80743:90168 [2] NCCL INFO misc/socket.cc:752 -> 3
27: nid005922:80742:90170 [1] NCCL INFO misc/socket.cc:752 -> 3
27: nid005922:80743:90168 [2] NCCL INFO misc/socket.cc:428 -> 3
27: nid005922:80742:90170 [1] NCCL INFO misc/socket.cc:428 -> 3
27: nid005922:80744:90169 [3] NCCL INFO misc/socket.cc:47 -> 3
27: nid005922:80743:90168 [2] NCCL INFO misc/socket.cc:564 -> 3
27: 
27: nid005922:80741:90174 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
27: nid005922:80742:90170 [1] NCCL INFO misc/socket.cc:564 -> 3
27: nid005922:80743:90168 [2] NCCL INFO misc/socket.cc:668 -> 3
27: nid005922:80744:90169 [3] NCCL INFO misc/socket.cc:752 -> 3
27: nid005922:80742:90170 [1] NCCL INFO misc/socket.cc:668 -> 3
27: nid005922:80744:90169 [3] NCCL INFO misc/socket.cc:428 -> 3
27: 
27: nid005922:80743:90168 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
27: nid005922:80744:90169 [3] NCCL INFO misc/socket.cc:564 -> 3
27: 
27: nid005922:80742:90170 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
27: nid005922:80744:90169 [3] NCCL INFO misc/socket.cc:668 -> 3
27: 
27: nid005922:80744:90169 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
27: nid005922:80741:183169 [0] NCCL INFO misc/socket.cc:47 -> 3
27: nid005922:80741:183169 [0] NCCL INFO misc/socket.cc:58 -> 3
27: nid005922:80741:183169 [0] NCCL INFO misc/socket.cc:775 -> 3
27: nid005922:80743:183172 [2] NCCL INFO misc/socket.cc:47 -> 3
27: nid005922:80743:183172 [2] NCCL INFO misc/socket.cc:58 -> 3
27: nid005922:80742:183170 [1] NCCL INFO misc/socket.cc:47 -> 3
27: nid005922:80743:90168 [2] NCCL INFO misc/socket.cc:826 -> 3
27: nid005922:80742:183170 [1] NCCL INFO misc/socket.cc:58 -> 3
27: nid005922:80741:90174 [0] NCCL INFO misc/socket.cc:826 -> 3
27: 
27: nid005922:80743:90168 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
27: nid005922:80742:183170 [1] NCCL INFO misc/socket.cc:775 -> 3
27: 
27: nid005922:80741:90174 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
27: nid005922:80744:183171 [3] NCCL INFO misc/socket.cc:47 -> 3
27: nid005922:80744:183171 [3] NCCL INFO misc/socket.cc:58 -> 3
27: nid005922:80743:183172 [2] NCCL INFO misc/socket.cc:775 -> 3
27: nid005922:80744:183171 [3] NCCL INFO misc/socket.cc:775 -> 3
27: 
27: nid005922:80741:90174 [0] proxy.cc:1521 NCCL WARN [Proxy Service 108] Failed to execute operation Close from rank 108, retcode 3
27: nid005922:80742:90170 [1] NCCL INFO misc/socket.cc:826 -> 3
27: 
27: nid005922:80742:90170 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
27: 
27: nid005922:80742:90170 [1] proxy.cc:1521 NCCL WARN [Proxy Service 109] Failed to execute operation Close from rank 109, retcode 3
27: 
27: nid005922:80743:90168 [2] proxy.cc:1521 NCCL WARN [Proxy Service 110] Failed to execute operation Close from rank 110, retcode 3
27: nid005922:80744:90169 [3] NCCL INFO misc/socket.cc:826 -> 3
27: 
27: nid005922:80744:90169 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
27: 
27: nid005922:80744:90169 [3] proxy.cc:1521 NCCL WARN [Proxy Service 111] Failed to execute operation Close from rank 111, retcode 3
20: nid005913:292682:101209 [1] NCCL INFO misc/socket.cc:47 -> 3
20: nid005913:292684:101211 [3] NCCL INFO misc/socket.cc:47 -> 3
20: nid005913:292682:101209 [1] NCCL INFO misc/socket.cc:550 -> 3
20: nid005913:292684:101211 [3] NCCL INFO misc/socket.cc:550 -> 3
20: nid005913:292682:101209 [1] NCCL INFO misc/socket.cc:573 -> 3
20: nid005913:292684:101211 [3] NCCL INFO misc/socket.cc:573 -> 3
20: nid005913:292682:101209 [1] NCCL INFO misc/socket.cc:621 -> 3
20: nid005913:292684:101211 [3] NCCL INFO misc/socket.cc:621 -> 3
20: nid005913:292682:9585 [1] NCCL INFO misc/socket.cc:47 -> 3
20: nid005913:292682:9585 [1] NCCL INFO misc/socket.cc:752 -> 3
20: nid005913:292682:9585 [1] NCCL INFO misc/socket.cc:428 -> 3
20: nid005913:292682:9585 [1] NCCL INFO misc/socket.cc:564 -> 3
20: nid005913:292682:9585 [1] NCCL INFO misc/socket.cc:668 -> 3
20: 
20: nid005913:292682:9585 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
20: nid005913:292684:9582 [3] NCCL INFO misc/socket.cc:47 -> 3
20: nid005913:292684:9582 [3] NCCL INFO misc/socket.cc:752 -> 3
20: nid005913:292684:9582 [3] NCCL INFO misc/socket.cc:428 -> 3
20: nid005913:292684:9582 [3] NCCL INFO misc/socket.cc:564 -> 3
20: nid005913:292684:9582 [3] NCCL INFO misc/socket.cc:668 -> 3
20: 
20: nid005913:292684:9582 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
20: nid005913:292683:101212 [2] NCCL INFO misc/socket.cc:47 -> 3
20: nid005913:292683:101212 [2] NCCL INFO misc/socket.cc:550 -> 3
20: nid005913:292683:101212 [2] NCCL INFO misc/socket.cc:573 -> 3
20: nid005913:292683:101212 [2] NCCL INFO misc/socket.cc:621 -> 3
20: nid005913:292681:101210 [0] NCCL INFO misc/socket.cc:47 -> 3
20: nid005913:292683:9584 [2] NCCL INFO misc/socket.cc:47 -> 3
20: nid005913:292681:101210 [0] NCCL INFO misc/socket.cc:550 -> 3
20: nid005913:292683:9584 [2] NCCL INFO misc/socket.cc:752 -> 3
20: nid005913:292681:101210 [0] NCCL INFO misc/socket.cc:573 -> 3
20: nid005913:292683:9584 [2] NCCL INFO misc/socket.cc:428 -> 3
20: nid005913:292682:101209 [1] NCCL INFO misc/socket.cc:47 -> 3
20: nid005913:292683:9584 [2] NCCL INFO misc/socket.cc:564 -> 3
20: nid005913:292681:101210 [0] NCCL INFO misc/socket.cc:621 -> 3
20: nid005913:292683:9584 [2] NCCL INFO misc/socket.cc:668 -> 3
20: nid005913:292682:101209 [1] NCCL INFO misc/socket.cc:58 -> 3
20: nid005913:292684:101211 [3] NCCL INFO misc/socket.cc:47 -> 3
20: nid005913:292682:101209 [1] NCCL INFO misc/socket.cc:775 -> 3
20: nid005913:292684:101211 [3] NCCL INFO misc/socket.cc:58 -> 3
20: 
20: nid005913:292683:9584 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
20: nid005913:292684:101211 [3] NCCL INFO misc/socket.cc:775 -> 3
20: nid005913:292682:9585 [1] NCCL INFO misc/socket.cc:826 -> 3
20: nid005913:292684:9582 [3] NCCL INFO misc/socket.cc:826 -> 3
20: nid005913:292681:9588 [0] NCCL INFO misc/socket.cc:47 -> 3
20: 
20: nid005913:292682:9585 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
20: nid005913:292681:9588 [0] NCCL INFO misc/socket.cc:752 -> 3
20: 
20: nid005913:292684:9582 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
20: 
20: nid005913:292682:9585 [1] proxy.cc:1521 NCCL WARN [Proxy Service 81] Failed to execute operation Close from rank 81, retcode 3
20: nid005913:292681:9588 [0] NCCL INFO misc/socket.cc:428 -> 3
20: 
20: nid005913:292684:9582 [3] proxy.cc:1521 NCCL WARN [Proxy Service 83] Failed to execute operation Close from rank 83, retcode 3
20: nid005913:292683:101212 [2] NCCL INFO misc/socket.cc:47 -> 3
20: nid005913:292681:9588 [0] NCCL INFO misc/socket.cc:564 -> 3
20: nid005913:292683:9584 [2] NCCL INFO misc/socket.cc:826 -> 3
20: nid005913:292681:9588 [0] NCCL INFO misc/socket.cc:668 -> 3
20: 
20: nid005913:292683:9584 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
20: nid005913:292683:101212 [2] NCCL INFO misc/socket.cc:58 -> 3
20: nid005913:292683:101212 [2] NCCL INFO misc/socket.cc:775 -> 3
20: 
20: nid005913:292681:9588 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
20: 
20: nid005913:292683:9584 [2] proxy.cc:1521 NCCL WARN [Proxy Service 82] Failed to execute operation Close from rank 82, retcode 3
20: nid005913:292681:101210 [0] NCCL INFO misc/socket.cc:47 -> 3
20: nid005913:292681:101210 [0] NCCL INFO misc/socket.cc:58 -> 3
20: nid005913:292681:101210 [0] NCCL INFO misc/socket.cc:775 -> 3
20: nid005913:292681:9588 [0] NCCL INFO misc/socket.cc:826 -> 3
20: 
20: nid005913:292681:9588 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
20: 
20: nid005913:292681:9588 [0] proxy.cc:1521 NCCL WARN [Proxy Service 80] Failed to execute operation Close from rank 80, retcode 3
 3: nid005580:71821:174882 [2] NCCL INFO misc/socket.cc:47 -> 3
 3: nid005580:71821:174882 [2] NCCL INFO misc/socket.cc:550 -> 3
 3: nid005580:71820:174881 [1] NCCL INFO misc/socket.cc:47 -> 3
 3: nid005580:71821:174882 [2] NCCL INFO misc/socket.cc:573 -> 3
 3: nid005580:71821:174882 [2] NCCL INFO misc/socket.cc:621 -> 3
 3: nid005580:71820:174881 [1] NCCL INFO misc/socket.cc:550 -> 3
 3: nid005580:71821:81298 [2] NCCL INFO misc/socket.cc:47 -> 3
 3: nid005580:71820:174881 [1] NCCL INFO misc/socket.cc:573 -> 3
 3: nid005580:71820:174881 [1] NCCL INFO misc/socket.cc:621 -> 3
 3: nid005580:71821:81298 [2] NCCL INFO misc/socket.cc:752 -> 3
 3: nid005580:71820:81297 [1] NCCL INFO misc/socket.cc:47 -> 3
 3: nid005580:71821:81298 [2] NCCL INFO misc/socket.cc:428 -> 3
 3: nid005580:71822:174884 [3] NCCL INFO misc/socket.cc:47 -> 3
 3: nid005580:71821:81298 [2] NCCL INFO misc/socket.cc:564 -> 3
 3: nid005580:71820:81297 [1] NCCL INFO misc/socket.cc:752 -> 3
 3: nid005580:71821:81298 [2] NCCL INFO misc/socket.cc:668 -> 3
 3: nid005580:71822:174884 [3] NCCL INFO misc/socket.cc:550 -> 3
 3: nid005580:71820:81297 [1] NCCL INFO misc/socket.cc:428 -> 3
 3: nid005580:71820:81297 [1] NCCL INFO misc/socket.cc:564 -> 3
 3: nid005580:71822:174884 [3] NCCL INFO misc/socket.cc:573 -> 3
 3: nid005580:71820:81297 [1] NCCL INFO misc/socket.cc:668 -> 3
 3: nid005580:71822:174884 [3] NCCL INFO misc/socket.cc:621 -> 3
 3: 
 3: nid005580:71821:81298 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 3: 
 3: nid005580:71820:81297 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 3: nid005580:71819:174883 [0] NCCL INFO misc/socket.cc:47 -> 3
 3: nid005580:71819:174883 [0] NCCL INFO misc/socket.cc:550 -> 3
 3: nid005580:71819:174883 [0] NCCL INFO misc/socket.cc:573 -> 3
 3: nid005580:71819:174883 [0] NCCL INFO misc/socket.cc:621 -> 3
 3: nid005580:71819:81302 [0] NCCL INFO misc/socket.cc:47 -> 3
 3: nid005580:71819:81302 [0] NCCL INFO misc/socket.cc:752 -> 3
 3: nid005580:71819:81302 [0] NCCL INFO misc/socket.cc:428 -> 3
 3: nid005580:71819:81302 [0] NCCL INFO misc/socket.cc:564 -> 3
 3: nid005580:71819:81302 [0] NCCL INFO misc/socket.cc:668 -> 3
 3: nid005580:71821:174882 [2] NCCL INFO misc/socket.cc:47 -> 3
 3: 
 3: nid005580:71819:81302 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 3: nid005580:71822:81301 [3] NCCL INFO misc/socket.cc:47 -> 3
 3: nid005580:71821:174882 [2] NCCL INFO misc/socket.cc:58 -> 3
 3: nid005580:71822:81301 [3] NCCL INFO misc/socket.cc:752 -> 3
 3: nid005580:71821:174882 [2] NCCL INFO misc/socket.cc:775 -> 3
 3: nid005580:71822:81301 [3] NCCL INFO misc/socket.cc:428 -> 3
 3: nid005580:71822:81301 [3] NCCL INFO misc/socket.cc:564 -> 3
 3: nid005580:71821:81298 [2] NCCL INFO misc/socket.cc:826 -> 3
 3: nid005580:71822:81301 [3] NCCL INFO misc/socket.cc:668 -> 3
 3: nid005580:71820:174881 [1] NCCL INFO misc/socket.cc:47 -> 3
 3: 
 3: nid005580:71821:81298 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
 3: nid005580:71820:174881 [1] NCCL INFO misc/socket.cc:58 -> 3
 3: 
 3: nid005580:71821:81298 [2] proxy.cc:1521 NCCL WARN [Proxy Service 14] Failed to execute operation Close from rank 14, retcode 3
 3: 
 3: nid005580:71822:81301 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 3: nid005580:71820:174881 [1] NCCL INFO misc/socket.cc:775 -> 3
 3: nid005580:71820:81297 [1] NCCL INFO misc/socket.cc:826 -> 3
 3: nid005580:71822:174884 [3] NCCL INFO misc/socket.cc:47 -> 3
 3: 
 3: nid005580:71820:81297 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
 3: nid005580:71822:174884 [3] NCCL INFO misc/socket.cc:58 -> 3
 3: 
 3: nid005580:71820:81297 [1] proxy.cc:1521 NCCL WARN [Proxy Service 13] Failed to execute operation Close from rank 13, retcode 3
 3: nid005580:71819:174883 [0] NCCL INFO misc/socket.cc:47 -> 3
 3: nid005580:71819:174883 [0] NCCL INFO misc/socket.cc:58 -> 3
 3: nid005580:71819:174883 [0] NCCL INFO misc/socket.cc:775 -> 3
 3: nid005580:71822:174884 [3] NCCL INFO misc/socket.cc:775 -> 3
 3: nid005580:71819:81302 [0] NCCL INFO misc/socket.cc:826 -> 3
 3: nid005580:71822:81301 [3] NCCL INFO misc/socket.cc:826 -> 3
 3: 
 3: nid005580:71819:81302 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
 3: 
 3: nid005580:71819:81302 [0] proxy.cc:1521 NCCL WARN [Proxy Service 12] Failed to execute operation Close from rank 12, retcode 3
 3: 
 3: nid005580:71822:81301 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
 3: 
 3: nid005580:71822:81301 [3] proxy.cc:1521 NCCL WARN [Proxy Service 15] Failed to execute operation Close from rank 15, retcode 3
18: nid005911:38864:140343 [0] NCCL INFO misc/socket.cc:47 -> 3
18: nid005911:38864:140343 [0] NCCL INFO misc/socket.cc:550 -> 3
18: nid005911:38864:140343 [0] NCCL INFO misc/socket.cc:573 -> 3
18: nid005911:38864:140343 [0] NCCL INFO misc/socket.cc:621 -> 3
18: nid005911:38864:48336 [0] NCCL INFO misc/socket.cc:47 -> 3
18: nid005911:38864:48336 [0] NCCL INFO misc/socket.cc:752 -> 3
18: nid005911:38864:48336 [0] NCCL INFO misc/socket.cc:428 -> 3
18: nid005911:38864:48336 [0] NCCL INFO misc/socket.cc:564 -> 3
18: nid005911:38864:48336 [0] NCCL INFO misc/socket.cc:668 -> 3
18: 
18: nid005911:38864:48336 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
18: nid005911:38867:140344 [3] NCCL INFO misc/socket.cc:47 -> 3
18: nid005911:38865:140346 [1] NCCL INFO misc/socket.cc:47 -> 3
18: nid005911:38866:140345 [2] NCCL INFO misc/socket.cc:47 -> 3
18: nid005911:38867:140344 [3] NCCL INFO misc/socket.cc:550 -> 3
18: nid005911:38866:140345 [2] NCCL INFO misc/socket.cc:550 -> 3
18: nid005911:38865:140346 [1] NCCL INFO misc/socket.cc:550 -> 3
18: nid005911:38867:140344 [3] NCCL INFO misc/socket.cc:573 -> 3
18: nid005911:38866:140345 [2] NCCL INFO misc/socket.cc:573 -> 3
18: nid005911:38866:140345 [2] NCCL INFO misc/socket.cc:621 -> 3
18: nid005911:38865:140346 [1] NCCL INFO misc/socket.cc:573 -> 3
18: nid005911:38867:140344 [3] NCCL INFO misc/socket.cc:621 -> 3
18: nid005911:38864:140343 [0] NCCL INFO misc/socket.cc:47 -> 3
18: nid005911:38866:48331 [2] NCCL INFO misc/socket.cc:47 -> 3
18: nid005911:38865:140346 [1] NCCL INFO misc/socket.cc:621 -> 3
18: nid005911:38866:48331 [2] NCCL INFO misc/socket.cc:752 -> 3
18: nid005911:38864:140343 [0] NCCL INFO misc/socket.cc:58 -> 3
18: nid005911:38866:48331 [2] NCCL INFO misc/socket.cc:428 -> 3
18: nid005911:38864:140343 [0] NCCL INFO misc/socket.cc:775 -> 3
18: nid005911:38866:48331 [2] NCCL INFO misc/socket.cc:564 -> 3
18: nid005911:38865:48332 [1] NCCL INFO misc/socket.cc:47 -> 3
18: nid005911:38867:48330 [3] NCCL INFO misc/socket.cc:47 -> 3
18: nid005911:38866:48331 [2] NCCL INFO misc/socket.cc:668 -> 3
18: nid005911:38865:48332 [1] NCCL INFO misc/socket.cc:752 -> 3
18: nid005911:38864:48336 [0] NCCL INFO misc/socket.cc:826 -> 3
18: nid005911:38867:48330 [3] NCCL INFO misc/socket.cc:752 -> 3
18: nid005911:38865:48332 [1] NCCL INFO misc/socket.cc:428 -> 3
18: nid005911:38867:48330 [3] NCCL INFO misc/socket.cc:428 -> 3
 9: nid005588:35935:138381 [0] NCCL INFO misc/socket.cc:47 -> 3
 9: nid005588:35935:138381 [0] NCCL INFO misc/socket.cc:550 -> 3
 9: nid005588:35935:138381 [0] NCCL INFO misc/socket.cc:573 -> 3
 9: nid005588:35935:138381 [0] NCCL INFO misc/socket.cc:621 -> 3
 9: nid005588:35938:138382 [3] NCCL INFO misc/socket.cc:47 -> 3
 9: nid005588:35938:138382 [3] NCCL INFO misc/socket.cc:550 -> 3
 9: nid005588:35938:138382 [3] NCCL INFO misc/socket.cc:573 -> 3
 9: nid005588:35938:138382 [3] NCCL INFO misc/socket.cc:621 -> 3
 9: nid005588:35935:45414 [0] NCCL INFO misc/socket.cc:47 -> 3
18: nid005911:38867:48330 [3] NCCL INFO misc/socket.cc:564 -> 3
18: 
18: nid005911:38866:48331 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
18: 
18: nid005911:38864:48336 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
18: nid005911:38865:48332 [1] NCCL INFO misc/socket.cc:564 -> 3
18: nid005911:38867:48330 [3] NCCL INFO misc/socket.cc:668 -> 3
18: 
18: nid005911:38864:48336 [0] proxy.cc:1521 NCCL WARN [Proxy Service 72] Failed to execute operation Close from rank 72, retcode 3
18: nid005911:38865:48332 [1] NCCL INFO misc/socket.cc:668 -> 3
 9: nid005588:35935:45414 [0] NCCL INFO misc/socket.cc:752 -> 3
 9: nid005588:35935:45414 [0] NCCL INFO misc/socket.cc:428 -> 3
 9: nid005588:35935:45414 [0] NCCL INFO misc/socket.cc:564 -> 3
 9: nid005588:35935:45414 [0] NCCL INFO misc/socket.cc:668 -> 3
 9: 
 9: nid005588:35935:45414 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 9: nid005588:35938:45409 [3] NCCL INFO misc/socket.cc:47 -> 3
 9: nid005588:35936:138383 [1] NCCL INFO misc/socket.cc:47 -> 3
 9: nid005588:35937:138384 [2] NCCL INFO misc/socket.cc:47 -> 3
 9: nid005588:35938:45409 [3] NCCL INFO misc/socket.cc:752 -> 3
 9: nid005588:35936:138383 [1] NCCL INFO misc/socket.cc:550 -> 3
 9: nid005588:35937:138384 [2] NCCL INFO misc/socket.cc:550 -> 3
 9: nid005588:35938:45409 [3] NCCL INFO misc/socket.cc:428 -> 3
 9: nid005588:35937:138384 [2] NCCL INFO misc/socket.cc:573 -> 3
 9: nid005588:35936:138383 [1] NCCL INFO misc/socket.cc:573 -> 3
 9: nid005588:35938:45409 [3] NCCL INFO misc/socket.cc:564 -> 3
 9: nid005588:35937:138384 [2] NCCL INFO misc/socket.cc:621 -> 3
18: 
18: nid005911:38867:48330 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
18: 
18: nid005911:38865:48332 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 9: nid005588:35936:138383 [1] NCCL INFO misc/socket.cc:621 -> 3
 9: nid005588:35938:45409 [3] NCCL INFO misc/socket.cc:668 -> 3
18: nid005911:38866:140345 [2] NCCL INFO misc/socket.cc:47 -> 3
18: nid005911:38866:140345 [2] NCCL INFO misc/socket.cc:58 -> 3
18: nid005911:38866:140345 [2] NCCL INFO misc/socket.cc:775 -> 3
 9: nid005588:35936:45408 [1] NCCL INFO misc/socket.cc:47 -> 3
 9: nid005588:35936:45408 [1] NCCL INFO misc/socket.cc:752 -> 3
 9: nid005588:35936:45408 [1] NCCL INFO misc/socket.cc:428 -> 3
 9: nid005588:35936:45408 [1] NCCL INFO misc/socket.cc:564 -> 3
 9: 
 9: nid005588:35938:45409 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 9: nid005588:35936:45408 [1] NCCL INFO misc/socket.cc:668 -> 3
 9: 
 9: nid005588:35936:45408 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 9: nid005588:35937:45411 [2] NCCL INFO misc/socket.cc:47 -> 3
18: nid005911:38866:48331 [2] NCCL INFO misc/socket.cc:826 -> 3
18: nid005911:38867:140344 [3] NCCL INFO misc/socket.cc:47 -> 3
18: 
18: nid005911:38866:48331 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
 9: nid005588:35937:45411 [2] NCCL INFO misc/socket.cc:752 -> 3
 9: nid005588:35937:45411 [2] NCCL INFO misc/socket.cc:428 -> 3
 9: nid005588:35937:45411 [2] NCCL INFO misc/socket.cc:564 -> 3
 9: nid005588:35937:45411 [2] NCCL INFO misc/socket.cc:668 -> 3
 9: nid005588:35938:138382 [3] NCCL INFO misc/socket.cc:47 -> 3
 9: nid005588:35938:138382 [3] NCCL INFO misc/socket.cc:58 -> 3
18: 
18: nid005911:38866:48331 [2] proxy.cc:1521 NCCL WARN [Proxy Service 74] Failed to execute operation Close from rank 74, retcode 3
18: nid005911:38867:140344 [3] NCCL INFO misc/socket.cc:58 -> 3
18: nid005911:38865:140346 [1] NCCL INFO misc/socket.cc:47 -> 3
18: nid005911:38867:48330 [3] NCCL INFO misc/socket.cc:826 -> 3
 9: nid005588:35938:138382 [3] NCCL INFO misc/socket.cc:775 -> 3
 9: 
 9: nid005588:35937:45411 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
18: nid005911:38865:140346 [1] NCCL INFO misc/socket.cc:58 -> 3
18: nid005911:38865:140346 [1] NCCL INFO misc/socket.cc:775 -> 3
18: 
18: nid005911:38867:48330 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
18: nid005911:38865:48332 [1] NCCL INFO misc/socket.cc:826 -> 3
18: nid005911:38867:140344 [3] NCCL INFO misc/socket.cc:775 -> 3
18: 
18: nid005911:38865:48332 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
 9: nid005588:35935:138381 [0] NCCL INFO misc/socket.cc:47 -> 3
 9: nid005588:35938:45409 [3] NCCL INFO misc/socket.cc:826 -> 3
 9: nid005588:35936:138383 [1] NCCL INFO misc/socket.cc:47 -> 3
 9: 
 9: nid005588:35938:45409 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
 9: nid005588:35935:45414 [0] NCCL INFO misc/socket.cc:826 -> 3
 9: nid005588:35936:138383 [1] NCCL INFO misc/socket.cc:58 -> 3
 9: 
 9: nid005588:35938:45409 [3] proxy.cc:1521 NCCL WARN [Proxy Service 39] Failed to execute operation Close from rank 39, retcode 3
 9: nid005588:35936:45408 [1] NCCL INFO misc/socket.cc:826 -> 3
 9: 
 9: nid005588:35935:45414 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
 9: 
 9: nid005588:35936:45408 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
 9: nid005588:35937:138384 [2] NCCL INFO misc/socket.cc:47 -> 3
 9: 
18: 
18: nid005911:38865:48332 [1] proxy.cc:1521 NCCL WARN [Proxy Service 73] Failed to execute operation Close from rank 73, retcode 3
18: 
18: nid005911:38867:48330 [3] proxy.cc:1521 NCCL WARN [Proxy Service 75] Failed to execute operation Close from rank 75, retcode 3
 9: nid005588:35935:45414 [0] proxy.cc:1521 NCCL WARN [Proxy Service 36] Failed to execute operation Close from rank 36, retcode 3
 9: nid005588:35936:138383 [1] NCCL INFO misc/socket.cc:775 -> 3
 9: nid005588:35937:138384 [2] NCCL INFO misc/socket.cc:58 -> 3
 9: nid005588:35937:138384 [2] NCCL INFO misc/socket.cc:775 -> 3
 9: 
 9: nid005588:35936:45408 [1] proxy.cc:1521 NCCL WARN [Proxy Service 37] Failed to execute operation Close from rank 37, retcode 3
 9: nid005588:35935:138381 [0] NCCL INFO misc/socket.cc:58 -> 3
 9: nid005588:35935:138381 [0] NCCL INFO misc/socket.cc:775 -> 3
 9: nid005588:35937:45411 [2] NCCL INFO misc/socket.cc:826 -> 3
 9: 
 9: nid005588:35937:45411 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
 9: 
 9: nid005588:35937:45411 [2] proxy.cc:1521 NCCL WARN [Proxy Service 38] Failed to execute operation Close from rank 38, retcode 3
14: nid005600:217720:26914 [0] NCCL INFO misc/socket.cc:47 -> 3
14: nid005600:217721:26916 [1] NCCL INFO misc/socket.cc:47 -> 3
14: nid005600:217721:26916 [1] NCCL INFO misc/socket.cc:550 -> 3
14: nid005600:217720:26914 [0] NCCL INFO misc/socket.cc:550 -> 3
14: nid005600:217721:26916 [1] NCCL INFO misc/socket.cc:573 -> 3
14: nid005600:217720:26914 [0] NCCL INFO misc/socket.cc:573 -> 3
14: nid005600:217720:26914 [0] NCCL INFO misc/socket.cc:621 -> 3
14: nid005600:217721:227287 [1] NCCL INFO misc/socket.cc:47 -> 3
14: nid005600:217721:227287 [1] NCCL INFO misc/socket.cc:752 -> 3
14: nid005600:217721:227287 [1] NCCL INFO misc/socket.cc:428 -> 3
14: nid005600:217721:227287 [1] NCCL INFO misc/socket.cc:564 -> 3
14: nid005600:217721:227287 [1] NCCL INFO misc/socket.cc:668 -> 3
14: nid005600:217721:26916 [1] NCCL INFO misc/socket.cc:621 -> 3
14: 
14: nid005600:217721:227287 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
14: nid005600:217723:26915 [3] NCCL INFO misc/socket.cc:47 -> 3
14: nid005600:217723:26915 [3] NCCL INFO misc/socket.cc:550 -> 3
14: nid005600:217723:26915 [3] NCCL INFO misc/socket.cc:573 -> 3
14: nid005600:217723:26915 [3] NCCL INFO misc/socket.cc:621 -> 3
14: nid005600:217720:227290 [0] NCCL INFO misc/socket.cc:47 -> 3
14: nid005600:217720:227290 [0] NCCL INFO misc/socket.cc:752 -> 3
14: nid005600:217720:227290 [0] NCCL INFO misc/socket.cc:428 -> 3
14: nid005600:217720:227290 [0] NCCL INFO misc/socket.cc:564 -> 3
14: nid005600:217720:227290 [0] NCCL INFO misc/socket.cc:668 -> 3
14: 
14: nid005600:217720:227290 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
14: nid005600:217723:227291 [3] NCCL INFO misc/socket.cc:47 -> 3
14: nid005600:217723:227291 [3] NCCL INFO misc/socket.cc:752 -> 3
14: nid005600:217723:227291 [3] NCCL INFO misc/socket.cc:428 -> 3
14: nid005600:217722:26917 [2] NCCL INFO misc/socket.cc:47 -> 3
14: nid005600:217723:227291 [3] NCCL INFO misc/socket.cc:564 -> 3
14: nid005600:217722:26917 [2] NCCL INFO misc/socket.cc:550 -> 3
14: nid005600:217723:227291 [3] NCCL INFO misc/socket.cc:668 -> 3
14: nid005600:217721:26916 [1] NCCL INFO misc/socket.cc:47 -> 3
14: nid005600:217722:26917 [2] NCCL INFO misc/socket.cc:573 -> 3
14: nid005600:217721:26916 [1] NCCL INFO misc/socket.cc:58 -> 3
14: nid005600:217722:26917 [2] NCCL INFO misc/socket.cc:621 -> 3
14: nid005600:217720:26914 [0] NCCL INFO misc/socket.cc:47 -> 3
14: 
14: nid005600:217723:227291 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
14: nid005600:217721:26916 [1] NCCL INFO misc/socket.cc:775 -> 3
14: nid005600:217720:26914 [0] NCCL INFO misc/socket.cc:58 -> 3
14: nid005600:217720:26914 [0] NCCL INFO misc/socket.cc:775 -> 3
14: nid005600:217720:227290 [0] NCCL INFO misc/socket.cc:826 -> 3
14: 
14: nid005600:217720:227290 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
14: nid005600:217722:227288 [2] NCCL INFO misc/socket.cc:47 -> 3
14: 
14: nid005600:217720:227290 [0] proxy.cc:1521 NCCL WARN [Proxy Service 56] Failed to execute operation Close from rank 56, retcode 3
14: nid005600:217721:227287 [1] NCCL INFO misc/socket.cc:826 -> 3
14: nid005600:217722:227288 [2] NCCL INFO misc/socket.cc:752 -> 3
14: nid005600:217722:227288 [2] NCCL INFO misc/socket.cc:428 -> 3
14: 
14: nid005600:217721:227287 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
14: nid005600:217722:227288 [2] NCCL INFO misc/socket.cc:564 -> 3
14: 
14: nid005600:217721:227287 [1] proxy.cc:1521 NCCL WARN [Proxy Service 57] Failed to execute operation Close from rank 57, retcode 3
14: nid005600:217722:227288 [2] NCCL INFO misc/socket.cc:668 -> 3
14: nid005600:217723:26915 [3] NCCL INFO misc/socket.cc:47 -> 3
14: nid005600:217723:26915 [3] NCCL INFO misc/socket.cc:58 -> 3
14: nid005600:217723:26915 [3] NCCL INFO misc/socket.cc:775 -> 3
14: 
14: nid005600:217722:227288 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
14: nid005600:217723:227291 [3] NCCL INFO misc/socket.cc:826 -> 3
14: 
14: nid005600:217723:227291 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
14: 
14: nid005600:217723:227291 [3] proxy.cc:1521 NCCL WARN [Proxy Service 59] Failed to execute operation Close from rank 59, retcode 3
14: nid005600:217722:26917 [2] NCCL INFO misc/socket.cc:47 -> 3
14: nid005600:217722:26917 [2] NCCL INFO misc/socket.cc:58 -> 3
14: nid005600:217722:26917 [2] NCCL INFO misc/socket.cc:775 -> 3
14: nid005600:217722:227288 [2] NCCL INFO misc/socket.cc:826 -> 3
14: 
14: nid005600:217722:227288 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
14: 
14: nid005600:217722:227288 [2] proxy.cc:1521 NCCL WARN [Proxy Service 58] Failed to execute operation Close from rank 58, retcode 3
21: nid005914:166786:269595 [2] NCCL INFO misc/socket.cc:47 -> 3
21: nid005914:166786:269595 [2] NCCL INFO misc/socket.cc:550 -> 3
21: nid005914:166786:269595 [2] NCCL INFO misc/socket.cc:573 -> 3
21: nid005914:166786:269595 [2] NCCL INFO misc/socket.cc:621 -> 3
21: nid005914:166787:269594 [3] NCCL INFO misc/socket.cc:47 -> 3
21: nid005914:166787:269594 [3] NCCL INFO misc/socket.cc:550 -> 3
21: nid005914:166787:269594 [3] NCCL INFO misc/socket.cc:573 -> 3
21: nid005914:166787:269594 [3] NCCL INFO misc/socket.cc:621 -> 3
21: nid005914:166786:176216 [2] NCCL INFO misc/socket.cc:47 -> 3
21: nid005914:166786:176216 [2] NCCL INFO misc/socket.cc:752 -> 3
21: nid005914:166785:269596 [1] NCCL INFO misc/socket.cc:47 -> 3
21: nid005914:166786:176216 [2] NCCL INFO misc/socket.cc:428 -> 3
21: nid005914:166785:269596 [1] NCCL INFO misc/socket.cc:550 -> 3
21: nid005914:166787:176215 [3] NCCL INFO misc/socket.cc:47 -> 3
21: nid005914:166786:176216 [2] NCCL INFO misc/socket.cc:564 -> 3
21: nid005914:166785:269596 [1] NCCL INFO misc/socket.cc:573 -> 3
21: nid005914:166787:176215 [3] NCCL INFO misc/socket.cc:752 -> 3
21: nid005914:166786:176216 [2] NCCL INFO misc/socket.cc:668 -> 3
21: nid005914:166785:269596 [1] NCCL INFO misc/socket.cc:621 -> 3
21: nid005914:166787:176215 [3] NCCL INFO misc/socket.cc:428 -> 3
21: nid005914:166784:269597 [0] NCCL INFO misc/socket.cc:47 -> 3
21: nid005914:166787:176215 [3] NCCL INFO misc/socket.cc:564 -> 3
21: 
21: nid005914:166786:176216 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
21: nid005914:166784:269597 [0] NCCL INFO misc/socket.cc:550 -> 3
21: nid005914:166787:176215 [3] NCCL INFO misc/socket.cc:668 -> 3
21: nid005914:166784:269597 [0] NCCL INFO misc/socket.cc:573 -> 3
21: nid005914:166784:269597 [0] NCCL INFO misc/socket.cc:621 -> 3
21: 
21: nid005914:166787:176215 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
21: nid005914:166785:176220 [1] NCCL INFO misc/socket.cc:47 -> 3
21: nid005914:166785:176220 [1] NCCL INFO misc/socket.cc:752 -> 3
21: nid005914:166786:269595 [2] NCCL INFO misc/socket.cc:47 -> 3
21: nid005914:166785:176220 [1] NCCL INFO misc/socket.cc:428 -> 3
21: nid005914:166786:269595 [2] NCCL INFO misc/socket.cc:58 -> 3
21: nid005914:166785:176220 [1] NCCL INFO misc/socket.cc:564 -> 3
21: nid005914:166786:269595 [2] NCCL INFO misc/socket.cc:775 -> 3
21: nid005914:166785:176220 [1] NCCL INFO misc/socket.cc:668 -> 3
17: nid005803:180735:283752 [3] NCCL INFO comm 0x4006896513a0 rank 71 nranks 128 cudaDev 3 busId 3901000 - Abort COMPLETE
21: nid005914:166784:176218 [0] NCCL INFO misc/socket.cc:47 -> 3
21: 
21: nid005914:166785:176220 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
21: nid005914:166784:176218 [0] NCCL INFO misc/socket.cc:752 -> 3
21: nid005914:166786:176216 [2] NCCL INFO misc/socket.cc:826 -> 3
21: nid005914:166784:176218 [0] NCCL INFO misc/socket.cc:428 -> 3
21: 
21: nid005914:166786:176216 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
21: nid005914:166784:176218 [0] NCCL INFO misc/socket.cc:564 -> 3
21: 
21: nid005914:166786:176216 [2] proxy.cc:1521 NCCL WARN [Proxy Service 86] Failed to execute operation Close from rank 86, retcode 3
21: nid005914:166784:176218 [0] NCCL INFO misc/socket.cc:668 -> 3
 8: nid005586:68927:170708 [1] NCCL INFO misc/socket.cc:47 -> 3
 8: nid005586:68927:170708 [1] NCCL INFO misc/socket.cc:550 -> 3
 8: nid005586:68927:170708 [1] NCCL INFO misc/socket.cc:573 -> 3
 8: nid005586:68927:170708 [1] NCCL INFO misc/socket.cc:621 -> 3
21: 
21: nid005914:166784:176218 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 8: nid005586:68927:78417 [1] NCCL INFO misc/socket.cc:47 -> 3
 8: nid005586:68929:170709 [3] NCCL INFO misc/socket.cc:47 -> 3
 8: nid005586:68929:170709 [3] NCCL INFO misc/socket.cc:550 -> 3
 8: nid005586:68927:78417 [1] NCCL INFO misc/socket.cc:752 -> 3
21: nid005914:166787:269594 [3] NCCL INFO misc/socket.cc:47 -> 3
21: nid005914:166787:269594 [3] NCCL INFO misc/socket.cc:58 -> 3
21: nid005914:166787:269594 [3] NCCL INFO misc/socket.cc:775 -> 3
21: nid005914:166787:176215 [3] NCCL INFO misc/socket.cc:826 -> 3
21: 
21: nid005914:166787:176215 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
21: 
21: nid005914:166787:176215 [3] proxy.cc:1521 NCCL WARN [Proxy Service 87] Failed to execute operation Close from rank 87, retcode 3
 8: nid005586:68929:170709 [3] NCCL INFO misc/socket.cc:573 -> 3
 8: nid005586:68927:78417 [1] NCCL INFO misc/socket.cc:428 -> 3
 8: nid005586:68929:170709 [3] NCCL INFO misc/socket.cc:621 -> 3
 8: nid005586:68927:78417 [1] NCCL INFO misc/socket.cc:564 -> 3
 8: nid005586:68927:78417 [1] NCCL INFO misc/socket.cc:668 -> 3
 8: 
 8: nid005586:68927:78417 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
21: nid005914:166785:269596 [1] NCCL INFO misc/socket.cc:47 -> 3
21: nid005914:166785:269596 [1] NCCL INFO misc/socket.cc:58 -> 3
21: nid005914:166784:269597 [0] NCCL INFO misc/socket.cc:47 -> 3
21: nid005914:166785:269596 [1] NCCL INFO misc/socket.cc:775 -> 3
 8: nid005586:68929:78419 [3] NCCL INFO misc/socket.cc:47 -> 3
 8: nid005586:68927:170708 [1] NCCL INFO misc/socket.cc:47 -> 3
 8: nid005586:68929:78419 [3] NCCL INFO misc/socket.cc:752 -> 3
 8: nid005586:68927:170708 [1] NCCL INFO misc/socket.cc:58 -> 3
 8: nid005586:68929:78419 [3] NCCL INFO misc/socket.cc:428 -> 3
 8: nid005586:68929:78419 [3] NCCL INFO misc/socket.cc:564 -> 3
21: nid005914:166784:176218 [0] NCCL INFO misc/socket.cc:826 -> 3
21: 
21: nid005914:166784:176218 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
21: nid005914:166785:176220 [1] NCCL INFO misc/socket.cc:826 -> 3
21: 
21: nid005914:166784:176218 [0] proxy.cc:1521 NCCL WARN [Proxy Service 84] Failed to execute operation Close from rank 84, retcode 3
21: 
21: nid005914:166785:176220 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
21: 
21: nid005914:166785:176220 [1] proxy.cc:1521 NCCL WARN [Proxy Service 85] Failed to execute operation Close from rank 85, retcode 3
21: nid005914:166784:269597 [0] NCCL INFO misc/socket.cc:58 -> 3
 8: nid005586:68927:170708 [1] NCCL INFO misc/socket.cc:775 -> 3
 8: nid005586:68929:78419 [3] NCCL INFO misc/socket.cc:668 -> 3
21: nid005914:166784:269597 [0] NCCL INFO misc/socket.cc:775 -> 3
 8: nid005586:68927:78417 [1] NCCL INFO misc/socket.cc:826 -> 3
 8: 
 8: nid005586:68929:78419 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 8: nid005586:68928:170711 [2] NCCL INFO misc/socket.cc:47 -> 3
 8: 
 8: nid005586:68927:78417 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
 8: nid005586:68926:170712 [0] NCCL INFO misc/socket.cc:47 -> 3
 8: 
 8: nid005586:68927:78417 [1] proxy.cc:1521 NCCL WARN [Proxy Service 33] Failed to execute operation Close from rank 33, retcode 3
 8: nid005586:68928:170711 [2] NCCL INFO misc/socket.cc:550 -> 3
 8: nid005586:68929:170709 [3] NCCL INFO misc/socket.cc:47 -> 3
 8: nid005586:68928:170711 [2] NCCL INFO misc/socket.cc:573 -> 3
 8: nid005586:68926:170712 [0] NCCL INFO misc/socket.cc:550 -> 3
 8: nid005586:68929:170709 [3] NCCL INFO misc/socket.cc:58 -> 3
 8: nid005586:68928:170711 [2] NCCL INFO misc/socket.cc:621 -> 3
 8: nid005586:68929:170709 [3] NCCL INFO misc/socket.cc:775 -> 3
 8: nid005586:68926:170712 [0] NCCL INFO misc/socket.cc:573 -> 3
 8: nid005586:68928:78414 [2] NCCL INFO misc/socket.cc:47 -> 3
 8: nid005586:68926:170712 [0] NCCL INFO misc/socket.cc:621 -> 3
 8: nid005586:68928:78414 [2] NCCL INFO misc/socket.cc:752 -> 3
 8: nid005586:68928:78414 [2] NCCL INFO misc/socket.cc:428 -> 3
 8: nid005586:68928:78414 [2] NCCL INFO misc/socket.cc:564 -> 3
 8: nid005586:68928:78414 [2] NCCL INFO misc/socket.cc:668 -> 3
 8: nid005586:68929:78419 [3] NCCL INFO misc/socket.cc:826 -> 3
 8: nid005586:68926:78415 [0] NCCL INFO misc/socket.cc:47 -> 3
 8: 
 8: nid005586:68928:78414 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
17: nid005803:180735:283756 [3] NCCL INFO misc/socket.cc:47 -> 3
17: nid005803:180735:283756 [3] NCCL INFO misc/socket.cc:550 -> 3
17: nid005803:180735:283756 [3] NCCL INFO misc/socket.cc:573 -> 3
17: nid005803:180735:283756 [3] NCCL INFO misc/socket.cc:621 -> 3
 8: nid005586:68926:78415 [0] NCCL INFO misc/socket.cc:752 -> 3
 8: 
 8: nid005586:68929:78419 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
 8: nid005586:68926:78415 [0] NCCL INFO misc/socket.cc:428 -> 3
 8: 
 8: nid005586:68929:78419 [3] proxy.cc:1521 NCCL WARN [Proxy Service 35] Failed to execute operation Close from rank 35, retcode 3
 8: nid005586:68926:78415 [0] NCCL INFO misc/socket.cc:564 -> 3
17: nid005803:180735:181295 [3] NCCL INFO misc/socket.cc:47 -> 3
17: nid005803:180735:181295 [3] NCCL INFO misc/socket.cc:752 -> 3
17: nid005803:180735:181295 [3] NCCL INFO misc/socket.cc:428 -> 3
17: nid005803:180735:181295 [3] NCCL INFO misc/socket.cc:564 -> 3
 8: nid005586:68926:78415 [0] NCCL INFO misc/socket.cc:668 -> 3
 8: 
 8: nid005586:68926:78415 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 8: nid005586:68928:170711 [2] NCCL INFO misc/socket.cc:47 -> 3
 8: nid005586:68928:170711 [2] NCCL INFO misc/socket.cc:58 -> 3
 8: nid005586:68928:170711 [2] NCCL INFO misc/socket.cc:775 -> 3
 8: nid005586:68928:78414 [2] NCCL INFO misc/socket.cc:826 -> 3
 8: nid005586:68926:170712 [0] NCCL INFO misc/socket.cc:47 -> 3
17: nid005803:180735:181295 [3] NCCL INFO misc/socket.cc:668 -> 3
 8: 
 8: nid005586:68928:78414 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
 8: nid005586:68926:170712 [0] NCCL INFO misc/socket.cc:58 -> 3
 8: nid005586:68926:170712 [0] NCCL INFO misc/socket.cc:775 -> 3
 8: 
 8: nid005586:68928:78414 [2] proxy.cc:1521 NCCL WARN [Proxy Service 34] Failed to execute operation Close from rank 34, retcode 3
 8: nid005586:68926:78415 [0] NCCL INFO misc/socket.cc:826 -> 3
17: 
17: nid005803:180735:181295 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 8: 
 8: nid005586:68926:78415 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
 8: 
 8: nid005586:68926:78415 [0] proxy.cc:1521 NCCL WARN [Proxy Service 32] Failed to execute operation Close from rank 32, retcode 3
17: nid005803:180735:283756 [3] NCCL INFO misc/socket.cc:47 -> 3
17: nid005803:180735:283756 [3] NCCL INFO misc/socket.cc:58 -> 3
17: nid005803:180735:283756 [3] NCCL INFO misc/socket.cc:775 -> 3
17: nid005803:180735:181295 [3] NCCL INFO misc/socket.cc:826 -> 3
17: 
17: nid005803:180735:181295 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
17: 
17: nid005803:180735:181295 [3] proxy.cc:1521 NCCL WARN [Proxy Service 71] Failed to execute operation Close from rank 71, retcode 3
22: nid005915:274816:84247 [2] NCCL INFO misc/socket.cc:47 -> 3
22: nid005915:274816:84247 [2] NCCL INFO misc/socket.cc:550 -> 3
22: nid005915:274816:84247 [2] NCCL INFO misc/socket.cc:573 -> 3
22: nid005915:274816:84247 [2] NCCL INFO misc/socket.cc:621 -> 3
22: nid005915:274816:284257 [2] NCCL INFO misc/socket.cc:47 -> 3
22: nid005915:274814:84248 [0] NCCL INFO misc/socket.cc:47 -> 3
22: nid005915:274816:284257 [2] NCCL INFO misc/socket.cc:752 -> 3
22: nid005915:274816:284257 [2] NCCL INFO misc/socket.cc:428 -> 3
22: nid005915:274814:84248 [0] NCCL INFO misc/socket.cc:550 -> 3
22: nid005915:274816:284257 [2] NCCL INFO misc/socket.cc:564 -> 3
22: nid005915:274814:84248 [0] NCCL INFO misc/socket.cc:573 -> 3
22: nid005915:274816:284257 [2] NCCL INFO misc/socket.cc:668 -> 3
22: nid005915:274814:84248 [0] NCCL INFO misc/socket.cc:621 -> 3
22: nid005915:274815:84250 [1] NCCL INFO misc/socket.cc:47 -> 3
22: nid005915:274815:84250 [1] NCCL INFO misc/socket.cc:550 -> 3
22: nid005915:274815:84250 [1] NCCL INFO misc/socket.cc:573 -> 3
22: nid005915:274815:84250 [1] NCCL INFO misc/socket.cc:621 -> 3
22: 
22: nid005915:274816:284257 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
22: nid005915:274814:284259 [0] NCCL INFO misc/socket.cc:47 -> 3
22: nid005915:274814:284259 [0] NCCL INFO misc/socket.cc:752 -> 3
22: nid005915:274814:284259 [0] NCCL INFO misc/socket.cc:428 -> 3
22: nid005915:274814:284259 [0] NCCL INFO misc/socket.cc:564 -> 3
22: nid005915:274814:284259 [0] NCCL INFO misc/socket.cc:668 -> 3
22: 
22: nid005915:274814:284259 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
22: nid005915:274815:284258 [1] NCCL INFO misc/socket.cc:47 -> 3
22: nid005915:274817:84249 [3] NCCL INFO misc/socket.cc:47 -> 3
22: nid005915:274815:284258 [1] NCCL INFO misc/socket.cc:752 -> 3
22: nid005915:274817:84249 [3] NCCL INFO misc/socket.cc:550 -> 3
22: nid005915:274815:284258 [1] NCCL INFO misc/socket.cc:428 -> 3
22: nid005915:274817:84249 [3] NCCL INFO misc/socket.cc:573 -> 3
22: nid005915:274816:84247 [2] NCCL INFO misc/socket.cc:47 -> 3
22: nid005915:274815:284258 [1] NCCL INFO misc/socket.cc:564 -> 3
22: nid005915:274816:84247 [2] NCCL INFO misc/socket.cc:58 -> 3
22: nid005915:274815:284258 [1] NCCL INFO misc/socket.cc:668 -> 3
22: nid005915:274817:84249 [3] NCCL INFO misc/socket.cc:621 -> 3
22: nid005915:274816:284257 [2] NCCL INFO misc/socket.cc:826 -> 3
22: nid005915:274817:284255 [3] NCCL INFO misc/socket.cc:47 -> 3
22: 
22: nid005915:274815:284258 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
22: nid005915:274817:284255 [3] NCCL INFO misc/socket.cc:752 -> 3
22: 
22: nid005915:274816:284257 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
22: nid005915:274817:284255 [3] NCCL INFO misc/socket.cc:428 -> 3
22: nid005915:274817:284255 [3] NCCL INFO misc/socket.cc:564 -> 3
22: nid005915:274817:284255 [3] NCCL INFO misc/socket.cc:668 -> 3
22: 
22: nid005915:274816:284257 [2] proxy.cc:1521 NCCL WARN [Proxy Service 90] Failed to execute operation Close from rank 90, retcode 3
22: nid005915:274816:84247 [2] NCCL INFO misc/socket.cc:775 -> 3
22: 
22: nid005915:274817:284255 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
22: nid005915:274815:84250 [1] NCCL INFO misc/socket.cc:47 -> 3
22: nid005915:274815:84250 [1] NCCL INFO misc/socket.cc:58 -> 3
22: nid005915:274814:84248 [0] NCCL INFO misc/socket.cc:47 -> 3
22: nid005915:274815:84250 [1] NCCL INFO misc/socket.cc:775 -> 3
22: nid005915:274814:84248 [0] NCCL INFO misc/socket.cc:58 -> 3
22: nid005915:274814:84248 [0] NCCL INFO misc/socket.cc:775 -> 3
22: nid005915:274815:284258 [1] NCCL INFO misc/socket.cc:826 -> 3
22: 
22: nid005915:274815:284258 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
22: nid005915:274814:284259 [0] NCCL INFO misc/socket.cc:826 -> 3
22: 
22: nid005915:274815:284258 [1] proxy.cc:1521 NCCL WARN [Proxy Service 89] Failed to execute operation Close from rank 89, retcode 3
22: 
22: nid005915:274814:284259 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
22: 
22: nid005915:274814:284259 [0] proxy.cc:1521 NCCL WARN [Proxy Service 88] Failed to execute operation Close from rank 88, retcode 3
22: nid005915:274817:84249 [3] NCCL INFO misc/socket.cc:47 -> 3
22: nid005915:274817:84249 [3] NCCL INFO misc/socket.cc:58 -> 3
22: nid005915:274817:84249 [3] NCCL INFO misc/socket.cc:775 -> 3
22: nid005915:274817:284255 [3] NCCL INFO misc/socket.cc:826 -> 3
22: 
22: nid005915:274817:284255 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
22: 
22: nid005915:274817:284255 [3] proxy.cc:1521 NCCL WARN [Proxy Service 91] Failed to execute operation Close from rank 91, retcode 3
 4: nid005581:264523:72356 [0] NCCL INFO misc/socket.cc:47 -> 3
 4: nid005581:264525:72355 [2] NCCL INFO misc/socket.cc:47 -> 3
 4: nid005581:264524:72358 [1] NCCL INFO misc/socket.cc:47 -> 3
 4: nid005581:264525:72355 [2] NCCL INFO misc/socket.cc:550 -> 3
 4: nid005581:264526:72357 [3] NCCL INFO misc/socket.cc:47 -> 3
 4: nid005581:264524:72358 [1] NCCL INFO misc/socket.cc:550 -> 3
 4: nid005581:264523:72356 [0] NCCL INFO misc/socket.cc:550 -> 3
 4: nid005581:264526:72357 [3] NCCL INFO misc/socket.cc:550 -> 3
 4: nid005581:264525:273960 [2] NCCL INFO misc/socket.cc:47 -> 3
 4: nid005581:264523:72356 [0] NCCL INFO misc/socket.cc:573 -> 3
 4: nid005581:264524:72358 [1] NCCL INFO misc/socket.cc:573 -> 3
 4: nid005581:264526:72357 [3] NCCL INFO misc/socket.cc:573 -> 3
 4: nid005581:264524:72358 [1] NCCL INFO misc/socket.cc:621 -> 3
 4: nid005581:264526:72357 [3] NCCL INFO misc/socket.cc:621 -> 3
 4: nid005581:264523:273966 [0] NCCL INFO misc/socket.cc:47 -> 3
 4: nid005581:264525:273960 [2] NCCL INFO misc/socket.cc:752 -> 3
 4: nid005581:264525:273960 [2] NCCL INFO misc/socket.cc:428 -> 3
 4: nid005581:264525:273960 [2] NCCL INFO misc/socket.cc:564 -> 3
 4: nid005581:264524:273963 [1] NCCL INFO misc/socket.cc:47 -> 3
 4: nid005581:264523:273966 [0] NCCL INFO misc/socket.cc:752 -> 3
 4: nid005581:264526:273962 [3] NCCL INFO misc/socket.cc:47 -> 3
 4: nid005581:264525:273960 [2] NCCL INFO misc/socket.cc:668 -> 3
 4: nid005581:264524:273963 [1] NCCL INFO misc/socket.cc:752 -> 3
 4: nid005581:264526:273962 [3] NCCL INFO misc/socket.cc:752 -> 3
 4: nid005581:264523:273966 [0] NCCL INFO misc/socket.cc:428 -> 3
 4: nid005581:264524:273963 [1] NCCL INFO misc/socket.cc:428 -> 3
 4: nid005581:264525:72355 [2] NCCL INFO misc/socket.cc:573 -> 3
 4: nid005581:264524:273963 [1] NCCL INFO misc/socket.cc:564 -> 3
 4: nid005581:264525:72355 [2] NCCL INFO misc/socket.cc:621 -> 3
 4: nid005581:264524:273963 [1] NCCL INFO misc/socket.cc:668 -> 3
 4: nid005581:264526:273962 [3] NCCL INFO misc/socket.cc:428 -> 3
15: nid005601:210676:18852 [0] NCCL INFO misc/socket.cc:47 -> 3
15: nid005601:210676:18852 [0] NCCL INFO misc/socket.cc:550 -> 3
15: nid005601:210676:18852 [0] NCCL INFO misc/socket.cc:573 -> 3
15: nid005601:210676:18852 [0] NCCL INFO misc/socket.cc:621 -> 3
15: nid005601:210679:18851 [3] NCCL INFO misc/socket.cc:47 -> 3
15: nid005601:210678:18853 [2] NCCL INFO misc/socket.cc:47 -> 3
15: nid005601:210678:18853 [2] NCCL INFO misc/socket.cc:550 -> 3
15: nid005601:210679:18851 [3] NCCL INFO misc/socket.cc:550 -> 3
15: nid005601:210678:18853 [2] NCCL INFO misc/socket.cc:573 -> 3
15: nid005601:210676:220218 [0] NCCL INFO misc/socket.cc:47 -> 3
15: nid005601:210678:18853 [2] NCCL INFO misc/socket.cc:621 -> 3
15: nid005601:210679:18851 [3] NCCL INFO misc/socket.cc:573 -> 3
15: nid005601:210676:220218 [0] NCCL INFO misc/socket.cc:752 -> 3
15: nid005601:210679:18851 [3] NCCL INFO misc/socket.cc:621 -> 3
15: nid005601:210676:220218 [0] NCCL INFO misc/socket.cc:428 -> 3
15: nid005601:210676:220218 [0] NCCL INFO misc/socket.cc:564 -> 3
 4: nid005581:264526:273962 [3] NCCL INFO misc/socket.cc:564 -> 3
 4: nid005581:264523:273966 [0] NCCL INFO misc/socket.cc:564 -> 3
 4: nid005581:264526:273962 [3] NCCL INFO misc/socket.cc:668 -> 3
 4: 
 4: nid005581:264525:273960 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 4: 
 4: nid005581:264524:273963 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 4: nid005581:264523:273966 [0] NCCL INFO misc/socket.cc:668 -> 3
 4: 
 4: nid005581:264526:273962 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 4: nid005581:264523:72356 [0] NCCL INFO misc/socket.cc:621 -> 3
15: nid005601:210676:220218 [0] NCCL INFO misc/socket.cc:668 -> 3
15: 
15: nid005601:210676:220218 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
15: nid005601:210678:220216 [2] NCCL INFO misc/socket.cc:47 -> 3
15: nid005601:210678:220216 [2] NCCL INFO misc/socket.cc:752 -> 3
15: nid005601:210678:220216 [2] NCCL INFO misc/socket.cc:428 -> 3
15: nid005601:210678:220216 [2] NCCL INFO misc/socket.cc:564 -> 3
15: nid005601:210679:220217 [3] NCCL INFO misc/socket.cc:47 -> 3
15: nid005601:210678:220216 [2] NCCL INFO misc/socket.cc:668 -> 3
15: nid005601:210679:220217 [3] NCCL INFO misc/socket.cc:752 -> 3
 4: 
 4: nid005581:264523:273966 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
15: nid005601:210679:220217 [3] NCCL INFO misc/socket.cc:428 -> 3
15: 
15: nid005601:210678:220216 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
15: nid005601:210679:220217 [3] NCCL INFO misc/socket.cc:564 -> 3
15: nid005601:210676:18852 [0] NCCL INFO misc/socket.cc:47 -> 3
15: nid005601:210679:220217 [3] NCCL INFO misc/socket.cc:668 -> 3
15: nid005601:210676:18852 [0] NCCL INFO misc/socket.cc:58 -> 3
15: 
15: nid005601:210679:220217 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
15: nid005601:210676:18852 [0] NCCL INFO misc/socket.cc:775 -> 3
15: nid005601:210676:220218 [0] NCCL INFO misc/socket.cc:826 -> 3
 4: nid005581:264524:72358 [1] NCCL INFO misc/socket.cc:47 -> 3
 4: nid005581:264526:72357 [3] NCCL INFO misc/socket.cc:47 -> 3
 4: nid005581:264524:72358 [1] NCCL INFO misc/socket.cc:58 -> 3
15: 
15: nid005601:210676:220218 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
15: 
15: nid005601:210676:220218 [0] proxy.cc:1521 NCCL WARN [Proxy Service 60] Failed to execute operation Close from rank 60, retcode 3
 6: nid005584:28285:128091 [0] NCCL INFO misc/socket.cc:47 -> 3
 6: nid005584:28287:128094 [2] NCCL INFO misc/socket.cc:47 -> 3
 6: nid005584:28285:128091 [0] NCCL INFO misc/socket.cc:550 -> 3
 6: nid005584:28287:128094 [2] NCCL INFO misc/socket.cc:550 -> 3
 6: nid005584:28285:128091 [0] NCCL INFO misc/socket.cc:573 -> 3
 6: nid005584:28287:128094 [2] NCCL INFO misc/socket.cc:573 -> 3
 6: nid005584:28285:128091 [0] NCCL INFO misc/socket.cc:621 -> 3
 6: nid005584:28287:128094 [2] NCCL INFO misc/socket.cc:621 -> 3
 6: nid005584:28287:37696 [2] NCCL INFO misc/socket.cc:47 -> 3
 6: nid005584:28287:37696 [2] NCCL INFO misc/socket.cc:752 -> 3
 6: nid005584:28287:37696 [2] NCCL INFO misc/socket.cc:428 -> 3
 6: nid005584:28287:37696 [2] NCCL INFO misc/socket.cc:564 -> 3
 6: nid005584:28287:37696 [2] NCCL INFO misc/socket.cc:668 -> 3
 4: nid005581:264526:72357 [3] NCCL INFO misc/socket.cc:58 -> 3
 4: nid005581:264526:72357 [3] NCCL INFO misc/socket.cc:775 -> 3
15: nid005601:210678:18853 [2] NCCL INFO misc/socket.cc:47 -> 3
15: nid005601:210678:18853 [2] NCCL INFO misc/socket.cc:58 -> 3
15: nid005601:210679:18851 [3] NCCL INFO misc/socket.cc:47 -> 3
15: nid005601:210678:18853 [2] NCCL INFO misc/socket.cc:775 -> 3
15: nid005601:210679:18851 [3] NCCL INFO misc/socket.cc:58 -> 3
15: nid005601:210679:18851 [3] NCCL INFO misc/socket.cc:775 -> 3
 6: 
 6: nid005584:28287:37696 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 6: nid005584:28286:128092 [1] NCCL INFO misc/socket.cc:47 -> 3
 6: nid005584:28286:128092 [1] NCCL INFO misc/socket.cc:550 -> 3
 6: nid005584:28286:128092 [1] NCCL INFO misc/socket.cc:573 -> 3
 6: nid005584:28286:128092 [1] NCCL INFO misc/socket.cc:621 -> 3
 6: nid005584:28288:128093 [3] NCCL INFO misc/socket.cc:47 -> 3
 6: nid005584:28285:37700 [0] NCCL INFO misc/socket.cc:47 -> 3
 6: nid005584:28288:128093 [3] NCCL INFO misc/socket.cc:550 -> 3
 6: nid005584:28285:37700 [0] NCCL INFO misc/socket.cc:752 -> 3
 6: nid005584:28288:37694 [3] NCCL INFO misc/socket.cc:47 -> 3
 6: nid005584:28286:37695 [1] NCCL INFO misc/socket.cc:47 -> 3
 6: nid005584:28286:37695 [1] NCCL INFO misc/socket.cc:752 -> 3
 6: nid005584:28285:37700 [0] NCCL INFO misc/socket.cc:428 -> 3
 6: nid005584:28288:37694 [3] NCCL INFO misc/socket.cc:752 -> 3
 4: nid005581:264524:72358 [1] NCCL INFO misc/socket.cc:775 -> 3
 4: nid005581:264525:72355 [2] NCCL INFO misc/socket.cc:47 -> 3
 4: nid005581:264525:72355 [2] NCCL INFO misc/socket.cc:58 -> 3
 4: nid005581:264526:273962 [3] NCCL INFO misc/socket.cc:826 -> 3
 4: nid005581:264525:72355 [2] NCCL INFO misc/socket.cc:775 -> 3
15: nid005601:210678:220216 [2] NCCL INFO misc/socket.cc:826 -> 3
15: 
15: nid005601:210678:220216 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
15: nid005601:210679:220217 [3] NCCL INFO misc/socket.cc:826 -> 3
15: 
15: nid005601:210678:220216 [2] proxy.cc:1521 NCCL WARN [Proxy Service 62] Failed to execute operation Close from rank 62, retcode 3
15: nid005601:210677:18854 [1] NCCL INFO misc/socket.cc:47 -> 3
15: 
15: nid005601:210679:220217 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
15: nid005601:210677:18854 [1] NCCL INFO misc/socket.cc:550 -> 3
15: nid005601:210677:18854 [1] NCCL INFO misc/socket.cc:573 -> 3
15: 
15: nid005601:210679:220217 [3] proxy.cc:1521 NCCL WARN [Proxy Service 63] Failed to execute operation Close from rank 63, retcode 3
15: nid005601:210677:18854 [1] NCCL INFO misc/socket.cc:621 -> 3
 6: nid005584:28286:37695 [1] NCCL INFO misc/socket.cc:428 -> 3
 6: nid005584:28287:128094 [2] NCCL INFO misc/socket.cc:47 -> 3
 6: nid005584:28286:37695 [1] NCCL INFO misc/socket.cc:564 -> 3
 6: nid005584:28287:37696 [2] NCCL INFO misc/socket.cc:826 -> 3
 6: nid005584:28286:37695 [1] NCCL INFO misc/socket.cc:668 -> 3
 6: nid005584:28285:37700 [0] NCCL INFO misc/socket.cc:564 -> 3
 6: nid005584:28288:37694 [3] NCCL INFO misc/socket.cc:428 -> 3
 6: 
 6: nid005584:28287:37696 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
 6: 
 6: nid005584:28286:37695 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 6: nid005584:28285:37700 [0] NCCL INFO misc/socket.cc:668 -> 3
 6: nid005584:28287:128094 [2] NCCL INFO misc/socket.cc:58 -> 3
 6: nid005584:28288:37694 [3] NCCL INFO misc/socket.cc:564 -> 3
 6: nid005584:28287:128094 [2] NCCL INFO misc/socket.cc:775 -> 3
 4: nid005581:264524:273963 [1] NCCL INFO misc/socket.cc:826 -> 3
 4: 
 4: nid005581:264526:273962 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
 4: nid005581:264525:273960 [2] NCCL INFO misc/socket.cc:826 -> 3
 4: 
 4: nid005581:264524:273963 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
 4: 
 4: nid005581:264526:273962 [3] proxy.cc:1521 NCCL WARN [Proxy Service 19] Failed to execute operation Close from rank 19, retcode 3
 4: 
 4: nid005581:264525:273960 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
 4: 
 4: nid005581:264524:273963 [1] proxy.cc:1521 NCCL WARN [Proxy Service 17] Failed to execute operation Close from rank 17, retcode 3
 4: 
 4: nid005581:264525:273960 [2] proxy.cc:1521 NCCL WARN [Proxy Service 18] Failed to execute operation Close from rank 18, retcode 3
15: nid005601:210677:220221 [1] NCCL INFO misc/socket.cc:47 -> 3
15: nid005601:210677:220221 [1] NCCL INFO misc/socket.cc:752 -> 3
15: nid005601:210677:220221 [1] NCCL INFO misc/socket.cc:428 -> 3
 7: nid005585:122007:225047 [2] NCCL INFO misc/socket.cc:47 -> 3
 7: nid005585:122006:225044 [1] NCCL INFO misc/socket.cc:47 -> 3
 7: nid005585:122007:225047 [2] NCCL INFO misc/socket.cc:550 -> 3
 7: nid005585:122006:225044 [1] NCCL INFO misc/socket.cc:550 -> 3
 7: nid005585:122007:225047 [2] NCCL INFO misc/socket.cc:573 -> 3
 7: nid005585:122006:225044 [1] NCCL INFO misc/socket.cc:573 -> 3
 7: nid005585:122006:225044 [1] NCCL INFO misc/socket.cc:621 -> 3
 7: nid005585:122007:225047 [2] NCCL INFO misc/socket.cc:621 -> 3
 7: nid005585:122007:131407 [2] NCCL INFO misc/socket.cc:47 -> 3
 7: nid005585:122005:225045 [0] NCCL INFO misc/socket.cc:47 -> 3
 7: nid005585:122007:131407 [2] NCCL INFO misc/socket.cc:752 -> 3
 7: nid005585:122006:131408 [1] NCCL INFO misc/socket.cc:47 -> 3
 7: nid005585:122005:225045 [0] NCCL INFO misc/socket.cc:550 -> 3
 7: nid005585:122007:131407 [2] NCCL INFO misc/socket.cc:428 -> 3
 7: nid005585:122005:225045 [0] NCCL INFO misc/socket.cc:573 -> 3
 7: nid005585:122006:131408 [1] NCCL INFO misc/socket.cc:752 -> 3
 6: nid005584:28288:37694 [3] NCCL INFO misc/socket.cc:668 -> 3
 6: 
 6: nid005584:28285:37700 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 6: 
 6: nid005584:28287:37696 [2] proxy.cc:1521 NCCL WARN [Proxy Service 26] Failed to execute operation Close from rank 26, retcode 3
 6: nid005584:28288:128093 [3] NCCL INFO misc/socket.cc:573 -> 3
 6: nid005584:28286:128092 [1] NCCL INFO misc/socket.cc:47 -> 3
 6: nid005584:28285:128091 [0] NCCL INFO misc/socket.cc:47 -> 3
 4: nid005581:264523:72356 [0] NCCL INFO misc/socket.cc:47 -> 3
 4: nid005581:264523:72356 [0] NCCL INFO misc/socket.cc:58 -> 3
15: nid005601:210677:220221 [1] NCCL INFO misc/socket.cc:564 -> 3
15: nid005601:210677:220221 [1] NCCL INFO misc/socket.cc:668 -> 3
 7: nid005585:122005:225045 [0] NCCL INFO misc/socket.cc:621 -> 3
 6: nid005584:28288:128093 [3] NCCL INFO misc/socket.cc:621 -> 3
 6: nid005584:28286:128092 [1] NCCL INFO misc/socket.cc:58 -> 3
 6: nid005584:28285:37700 [0] NCCL INFO misc/socket.cc:826 -> 3
 6: 
 6: nid005584:28288:37694 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 6: nid005584:28286:128092 [1] NCCL INFO misc/socket.cc:775 -> 3
 6: nid005584:28286:37695 [1] NCCL INFO misc/socket.cc:826 -> 3
 6: 
 6: nid005584:28285:37700 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
 4: nid005581:264523:72356 [0] NCCL INFO misc/socket.cc:775 -> 3
15: 
15: nid005601:210677:220221 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 7: nid005585:122007:131407 [2] NCCL INFO misc/socket.cc:564 -> 3
 7: nid005585:122006:131408 [1] NCCL INFO misc/socket.cc:428 -> 3
 7: nid005585:122008:225046 [3] NCCL INFO misc/socket.cc:47 -> 3
 7: nid005585:122007:131407 [2] NCCL INFO misc/socket.cc:668 -> 3
 7: nid005585:122006:131408 [1] NCCL INFO misc/socket.cc:564 -> 3
 7: nid005585:122005:131412 [0] NCCL INFO misc/socket.cc:47 -> 3
 7: nid005585:122008:225046 [3] NCCL INFO misc/socket.cc:550 -> 3
 7: nid005585:122006:131408 [1] NCCL INFO misc/socket.cc:668 -> 3
 7: 
 7: nid005585:122007:131407 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 7: nid005585:122005:131412 [0] NCCL INFO misc/socket.cc:752 -> 3
 7: nid005585:122008:225046 [3] NCCL INFO misc/socket.cc:573 -> 3
 7: 
 7: nid005585:122006:131408 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 7: nid005585:122005:131412 [0] NCCL INFO misc/socket.cc:428 -> 3
 7: nid005585:122008:225046 [3] NCCL INFO misc/socket.cc:621 -> 3
 6: 
 6: nid005584:28286:37695 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
 6: 
 6: nid005584:28285:37700 [0] proxy.cc:1521 NCCL WARN [Proxy Service 24] Failed to execute operation Close from rank 24, retcode 3
 6: 
 6: nid005584:28286:37695 [1] proxy.cc:1521 NCCL WARN [Proxy Service 25] Failed to execute operation Close from rank 25, retcode 3
 4: nid005581:264523:273966 [0] NCCL INFO misc/socket.cc:826 -> 3
 4: 
 4: nid005581:264523:273966 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
 4: 
 4: nid005581:264523:273966 [0] proxy.cc:1521 NCCL WARN [Proxy Service 16] Failed to execute operation Close from rank 16, retcode 3
15: nid005601:210677:18854 [1] NCCL INFO misc/socket.cc:47 -> 3
15: nid005601:210677:18854 [1] NCCL INFO misc/socket.cc:58 -> 3
15: nid005601:210677:18854 [1] NCCL INFO misc/socket.cc:775 -> 3
15: nid005601:210677:220221 [1] NCCL INFO misc/socket.cc:826 -> 3
 7: nid005585:122007:225047 [2] NCCL INFO misc/socket.cc:47 -> 3
 7: nid005585:122008:131406 [3] NCCL INFO misc/socket.cc:47 -> 3
 7: nid005585:122005:131412 [0] NCCL INFO misc/socket.cc:564 -> 3
 7: nid005585:122007:225047 [2] NCCL INFO misc/socket.cc:58 -> 3
 7: nid005585:122008:131406 [3] NCCL INFO misc/socket.cc:752 -> 3
 7: nid005585:122007:225047 [2] NCCL INFO misc/socket.cc:775 -> 3
 7: nid005585:122005:131412 [0] NCCL INFO misc/socket.cc:668 -> 3
 7: nid005585:122008:131406 [3] NCCL INFO misc/socket.cc:428 -> 3
 7: nid005585:122008:131406 [3] NCCL INFO misc/socket.cc:564 -> 3
 7: nid005585:122007:131407 [2] NCCL INFO misc/socket.cc:826 -> 3
 7: nid005585:122008:131406 [3] NCCL INFO misc/socket.cc:668 -> 3
 7: 
 7: nid005585:122005:131412 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 7: 
 7: nid005585:122007:131407 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
 7: nid005585:122006:225044 [1] NCCL INFO misc/socket.cc:47 -> 3
 7: 
 6: nid005584:28285:128091 [0] NCCL INFO misc/socket.cc:58 -> 3
 6: nid005584:28285:128091 [0] NCCL INFO misc/socket.cc:775 -> 3
15: 
15: nid005601:210677:220221 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
15: 
15: nid005601:210677:220221 [1] proxy.cc:1521 NCCL WARN [Proxy Service 61] Failed to execute operation Close from rank 61, retcode 3
 7: nid005585:122008:131406 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 7: nid005585:122006:225044 [1] NCCL INFO misc/socket.cc:58 -> 3
 7: 
 7: nid005585:122007:131407 [2] proxy.cc:1521 NCCL WARN [Proxy Service 30] Failed to execute operation Close from rank 30, retcode 3
 6: nid005584:28288:128093 [3] NCCL INFO misc/socket.cc:47 -> 3
 6: nid005584:28288:128093 [3] NCCL INFO misc/socket.cc:58 -> 3
 6: nid005584:28288:128093 [3] NCCL INFO misc/socket.cc:775 -> 3
 6: nid005584:28288:37694 [3] NCCL INFO misc/socket.cc:826 -> 3
 6: 
 6: nid005584:28288:37694 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
 7: nid005585:122006:225044 [1] NCCL INFO misc/socket.cc:775 -> 3
 7: nid005585:122005:225045 [0] NCCL INFO misc/socket.cc:47 -> 3
 7: nid005585:122006:131408 [1] NCCL INFO misc/socket.cc:826 -> 3
 7: nid005585:122005:225045 [0] NCCL INFO misc/socket.cc:58 -> 3
 7: nid005585:122005:225045 [0] NCCL INFO misc/socket.cc:775 -> 3
 7: 
 7: nid005585:122006:131408 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
 6: 
 6: nid005584:28288:37694 [3] proxy.cc:1521 NCCL WARN [Proxy Service 27] Failed to execute operation Close from rank 27, retcode 3
 7: 
 7: nid005585:122006:131408 [1] proxy.cc:1521 NCCL WARN [Proxy Service 29] Failed to execute operation Close from rank 29, retcode 3
 7: nid005585:122008:225046 [3] NCCL INFO misc/socket.cc:47 -> 3
 7: nid005585:122005:131412 [0] NCCL INFO misc/socket.cc:826 -> 3
 7: nid005585:122008:225046 [3] NCCL INFO misc/socket.cc:58 -> 3
 7: nid005585:122008:225046 [3] NCCL INFO misc/socket.cc:775 -> 3
 7: 
 7: nid005585:122005:131412 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
 7: 
 7: nid005585:122005:131412 [0] proxy.cc:1521 NCCL WARN [Proxy Service 28] Failed to execute operation Close from rank 28, retcode 3
 7: nid005585:122008:131406 [3] NCCL INFO misc/socket.cc:826 -> 3
 7: 
 7: nid005585:122008:131406 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
 7: 
 7: nid005585:122008:131406 [3] proxy.cc:1521 NCCL WARN [Proxy Service 31] Failed to execute operation Close from rank 31, retcode 3
11: nid005591:191604:294864 [1] NCCL INFO misc/socket.cc:47 -> 3
11: nid005591:191604:294864 [1] NCCL INFO misc/socket.cc:550 -> 3
11: nid005591:191604:294864 [1] NCCL INFO misc/socket.cc:573 -> 3
11: nid005591:191604:294864 [1] NCCL INFO misc/socket.cc:621 -> 3
11: nid005591:191604:202319 [1] NCCL INFO misc/socket.cc:47 -> 3
11: nid005591:191604:202319 [1] NCCL INFO misc/socket.cc:752 -> 3
11: nid005591:191604:202319 [1] NCCL INFO misc/socket.cc:428 -> 3
11: nid005591:191604:202319 [1] NCCL INFO misc/socket.cc:564 -> 3
11: nid005591:191604:202319 [1] NCCL INFO misc/socket.cc:668 -> 3
11: 
11: nid005591:191604:202319 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
11: nid005591:191606:294865 [3] NCCL INFO misc/socket.cc:47 -> 3
11: nid005591:191606:294865 [3] NCCL INFO misc/socket.cc:550 -> 3
11: nid005591:191606:294865 [3] NCCL INFO misc/socket.cc:573 -> 3
11: nid005591:191606:294865 [3] NCCL INFO misc/socket.cc:621 -> 3
11: nid005591:191604:294864 [1] NCCL INFO misc/socket.cc:47 -> 3
11: nid005591:191604:294864 [1] NCCL INFO misc/socket.cc:58 -> 3
11: nid005591:191604:294864 [1] NCCL INFO misc/socket.cc:775 -> 3
11: nid005591:191604:202319 [1] NCCL INFO misc/socket.cc:826 -> 3
11: nid005591:191605:294866 [2] NCCL INFO misc/socket.cc:47 -> 3
11: nid005591:191603:294867 [0] NCCL INFO misc/socket.cc:47 -> 3
11: 
11: nid005591:191604:202319 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
11: nid005591:191603:294867 [0] NCCL INFO misc/socket.cc:550 -> 3
11: 
11: nid005591:191604:202319 [1] proxy.cc:1521 NCCL WARN [Proxy Service 45] Failed to execute operation Close from rank 45, retcode 3
11: nid005591:191605:294866 [2] NCCL INFO misc/socket.cc:550 -> 3
11: nid005591:191603:294867 [0] NCCL INFO misc/socket.cc:573 -> 3
11: nid005591:191605:294866 [2] NCCL INFO misc/socket.cc:573 -> 3
11: nid005591:191603:294867 [0] NCCL INFO misc/socket.cc:621 -> 3
11: nid005591:191605:294866 [2] NCCL INFO misc/socket.cc:621 -> 3
11: nid005591:191606:202314 [3] NCCL INFO misc/socket.cc:47 -> 3
11: nid005591:191606:202314 [3] NCCL INFO misc/socket.cc:752 -> 3
11: nid005591:191606:202314 [3] NCCL INFO misc/socket.cc:428 -> 3
11: nid005591:191606:202314 [3] NCCL INFO misc/socket.cc:564 -> 3
11: nid005591:191606:202314 [3] NCCL INFO misc/socket.cc:668 -> 3
11: 
11: nid005591:191606:202314 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
11: nid005591:191605:202315 [2] NCCL INFO misc/socket.cc:47 -> 3
11: nid005591:191605:202315 [2] NCCL INFO misc/socket.cc:752 -> 3
11: nid005591:191605:202315 [2] NCCL INFO misc/socket.cc:428 -> 3
11: nid005591:191605:202315 [2] NCCL INFO misc/socket.cc:564 -> 3
11: nid005591:191605:202315 [2] NCCL INFO misc/socket.cc:668 -> 3
11: nid005591:191603:202318 [0] NCCL INFO misc/socket.cc:47 -> 3
11: 
11: nid005591:191605:202315 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
11: nid005591:191603:202318 [0] NCCL INFO misc/socket.cc:752 -> 3
11: nid005591:191603:202318 [0] NCCL INFO misc/socket.cc:428 -> 3
11: nid005591:191603:202318 [0] NCCL INFO misc/socket.cc:564 -> 3
11: nid005591:191603:202318 [0] NCCL INFO misc/socket.cc:668 -> 3
11: 
11: nid005591:191603:202318 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
11: nid005591:191606:294865 [3] NCCL INFO misc/socket.cc:47 -> 3
11: nid005591:191606:294865 [3] NCCL INFO misc/socket.cc:58 -> 3
11: nid005591:191606:294865 [3] NCCL INFO misc/socket.cc:775 -> 3
11: nid005591:191606:202314 [3] NCCL INFO misc/socket.cc:826 -> 3
11: 
11: nid005591:191606:202314 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
11: 
11: nid005591:191606:202314 [3] proxy.cc:1521 NCCL WARN [Proxy Service 47] Failed to execute operation Close from rank 47, retcode 3
11: nid005591:191603:294867 [0] NCCL INFO misc/socket.cc:47 -> 3
11: nid005591:191605:294866 [2] NCCL INFO misc/socket.cc:47 -> 3
11: nid005591:191605:294866 [2] NCCL INFO misc/socket.cc:58 -> 3
11: nid005591:191603:294867 [0] NCCL INFO misc/socket.cc:58 -> 3
11: nid005591:191605:294866 [2] NCCL INFO misc/socket.cc:775 -> 3
11: nid005591:191603:294867 [0] NCCL INFO misc/socket.cc:775 -> 3
11: nid005591:191605:202315 [2] NCCL INFO misc/socket.cc:826 -> 3
11: 
11: nid005591:191605:202315 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
11: 
11: nid005591:191605:202315 [2] proxy.cc:1521 NCCL WARN [Proxy Service 46] Failed to execute operation Close from rank 46, retcode 3
11: nid005591:191603:202318 [0] NCCL INFO misc/socket.cc:826 -> 3
11: 
11: nid005591:191603:202318 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
11: 
11: nid005591:191603:202318 [0] proxy.cc:1521 NCCL WARN [Proxy Service 44] Failed to execute operation Close from rank 44, retcode 3
30: nid005936:49911:151422 [3] NCCL INFO misc/socket.cc:47 -> 3
30: nid005936:49911:151422 [3] NCCL INFO misc/socket.cc:550 -> 3
30: nid005936:49911:151422 [3] NCCL INFO misc/socket.cc:573 -> 3
30: nid005936:49911:151422 [3] NCCL INFO misc/socket.cc:621 -> 3
30: nid005936:49908:151423 [0] NCCL INFO misc/socket.cc:47 -> 3
30: nid005936:49911:59372 [3] NCCL INFO misc/socket.cc:47 -> 3
30: nid005936:49908:151423 [0] NCCL INFO misc/socket.cc:550 -> 3
30: nid005936:49911:59372 [3] NCCL INFO misc/socket.cc:752 -> 3
30: nid005936:49908:151423 [0] NCCL INFO misc/socket.cc:573 -> 3
30: nid005936:49911:59372 [3] NCCL INFO misc/socket.cc:428 -> 3
30: nid005936:49908:151423 [0] NCCL INFO misc/socket.cc:621 -> 3
30: nid005936:49911:59372 [3] NCCL INFO misc/socket.cc:564 -> 3
30: nid005936:49911:59372 [3] NCCL INFO misc/socket.cc:668 -> 3
30: nid005936:49910:151424 [2] NCCL INFO misc/socket.cc:47 -> 3
30: 
30: nid005936:49911:59372 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
30: nid005936:49910:151424 [2] NCCL INFO misc/socket.cc:550 -> 3
30: nid005936:49910:151424 [2] NCCL INFO misc/socket.cc:573 -> 3
30: nid005936:49910:59371 [2] NCCL INFO misc/socket.cc:47 -> 3
30: nid005936:49910:59371 [2] NCCL INFO misc/socket.cc:752 -> 3
30: nid005936:49910:59371 [2] NCCL INFO misc/socket.cc:428 -> 3
30: nid005936:49910:59371 [2] NCCL INFO misc/socket.cc:564 -> 3
30: nid005936:49910:59371 [2] NCCL INFO misc/socket.cc:668 -> 3
30: nid005936:49908:59377 [0] NCCL INFO misc/socket.cc:47 -> 3
30: nid005936:49910:151424 [2] NCCL INFO misc/socket.cc:621 -> 3
30: nid005936:49908:59377 [0] NCCL INFO misc/socket.cc:752 -> 3
30: 
30: nid005936:49910:59371 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
30: nid005936:49908:59377 [0] NCCL INFO misc/socket.cc:428 -> 3
30: nid005936:49908:59377 [0] NCCL INFO misc/socket.cc:564 -> 3
30: nid005936:49908:59377 [0] NCCL INFO misc/socket.cc:668 -> 3
30: nid005936:49909:151425 [1] NCCL INFO misc/socket.cc:47 -> 3
30: nid005936:49909:151425 [1] NCCL INFO misc/socket.cc:550 -> 3
30: 
30: nid005936:49908:59377 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
30: nid005936:49909:151425 [1] NCCL INFO misc/socket.cc:573 -> 3
30: nid005936:49909:151425 [1] NCCL INFO misc/socket.cc:621 -> 3
30: nid005936:49911:151422 [3] NCCL INFO misc/socket.cc:47 -> 3
30: nid005936:49911:151422 [3] NCCL INFO misc/socket.cc:58 -> 3
30: nid005936:49911:151422 [3] NCCL INFO misc/socket.cc:775 -> 3
30: nid005936:49911:59372 [3] NCCL INFO misc/socket.cc:826 -> 3
30: 
30: nid005936:49911:59372 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
30: nid005936:49908:151423 [0] NCCL INFO misc/socket.cc:47 -> 3
30: nid005936:49909:59375 [1] NCCL INFO misc/socket.cc:47 -> 3
30: nid005936:49908:151423 [0] NCCL INFO misc/socket.cc:58 -> 3
30: 
30: nid005936:49911:59372 [3] proxy.cc:1521 NCCL WARN [Proxy Service 123] Failed to execute operation Close from rank 123, retcode 3
30: nid005936:49909:59375 [1] NCCL INFO misc/socket.cc:752 -> 3
30: nid005936:49908:59377 [0] NCCL INFO misc/socket.cc:826 -> 3
30: nid005936:49909:59375 [1] NCCL INFO misc/socket.cc:428 -> 3
30: nid005936:49910:151424 [2] NCCL INFO misc/socket.cc:47 -> 3
30: nid005936:49909:59375 [1] NCCL INFO misc/socket.cc:564 -> 3
30: 
30: nid005936:49908:59377 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
30: nid005936:49910:151424 [2] NCCL INFO misc/socket.cc:58 -> 3
30: nid005936:49909:59375 [1] NCCL INFO misc/socket.cc:668 -> 3
30: nid005936:49910:151424 [2] NCCL INFO misc/socket.cc:775 -> 3
30: 
30: nid005936:49908:59377 [0] proxy.cc:1521 NCCL WARN [Proxy Service 120] Failed to execute operation Close from rank 120, retcode 3
30: 
30: nid005936:49909:59375 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
30: nid005936:49910:59371 [2] NCCL INFO misc/socket.cc:826 -> 3
30: 
30: nid005936:49910:59371 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
30: 
30: nid005936:49910:59371 [2] proxy.cc:1521 NCCL WARN [Proxy Service 122] Failed to execute operation Close from rank 122, retcode 3
30: nid005936:49908:151423 [0] NCCL INFO misc/socket.cc:775 -> 3
30: nid005936:49909:151425 [1] NCCL INFO misc/socket.cc:47 -> 3
30: nid005936:49909:151425 [1] NCCL INFO misc/socket.cc:58 -> 3
30: nid005936:49909:151425 [1] NCCL INFO misc/socket.cc:775 -> 3
30: nid005936:49909:59375 [1] NCCL INFO misc/socket.cc:826 -> 3
30: 
30: nid005936:49909:59375 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
30: 
30: nid005936:49909:59375 [1] proxy.cc:1521 NCCL WARN [Proxy Service 121] Failed to execute operation Close from rank 121, retcode 3
 1: nid005576:147560:250807 [3] NCCL INFO comm 0x400699651260 rank 7 nranks 128 cudaDev 3 busId 3901000 - Abort COMPLETE
 1: nid005576:147560:250810 [3] NCCL INFO misc/socket.cc:47 -> 3
 1: nid005576:147560:250810 [3] NCCL INFO misc/socket.cc:550 -> 3
 1: nid005576:147560:250810 [3] NCCL INFO misc/socket.cc:573 -> 3
 1: nid005576:147560:250810 [3] NCCL INFO misc/socket.cc:621 -> 3
25: nid005919:107465:211239 [3] NCCL INFO comm 0x40069964fe00 rank 103 nranks 128 cudaDev 3 busId 3901000 - Abort COMPLETE
 1: nid005576:147560:148105 [3] NCCL INFO misc/socket.cc:47 -> 3
 1: nid005576:147560:148105 [3] NCCL INFO misc/socket.cc:752 -> 3
 1: nid005576:147560:148105 [3] NCCL INFO misc/socket.cc:428 -> 3
 1: nid005576:147560:148105 [3] NCCL INFO misc/socket.cc:564 -> 3
 1: nid005576:147560:148105 [3] NCCL INFO misc/socket.cc:668 -> 3
 1: 
 1: nid005576:147560:148105 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 1: nid005576:147560:250810 [3] NCCL INFO misc/socket.cc:47 -> 3
 1: nid005576:147560:250810 [3] NCCL INFO misc/socket.cc:58 -> 3
 1: nid005576:147560:250810 [3] NCCL INFO misc/socket.cc:775 -> 3
 1: nid005576:147560:148105 [3] NCCL INFO misc/socket.cc:826 -> 3
 1: 
 1: nid005576:147560:148105 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
 1: 
 1: nid005576:147560:148105 [3] proxy.cc:1521 NCCL WARN [Proxy Service 7] Failed to execute operation Close from rank 7, retcode 3
29: nid005932:167681:270268 [1] NCCL INFO comm 0x4006a164fdf0 rank 117 nranks 128 cudaDev 1 busId 1901000 - Abort COMPLETE
25: nid005919:107465:211240 [3] NCCL INFO misc/socket.cc:47 -> 3
25: nid005919:107465:211240 [3] NCCL INFO misc/socket.cc:550 -> 3
25: nid005919:107465:211240 [3] NCCL INFO misc/socket.cc:573 -> 3
25: nid005919:107465:211240 [3] NCCL INFO misc/socket.cc:621 -> 3
25: nid005919:107465:108031 [3] NCCL INFO misc/socket.cc:47 -> 3
25: nid005919:107465:108031 [3] NCCL INFO misc/socket.cc:752 -> 3
25: nid005919:107465:108031 [3] NCCL INFO misc/socket.cc:428 -> 3
25: nid005919:107465:108031 [3] NCCL INFO misc/socket.cc:564 -> 3
25: nid005919:107465:108031 [3] NCCL INFO misc/socket.cc:668 -> 3
29: nid005932:167681:270272 [1] NCCL INFO misc/socket.cc:47 -> 3
29: nid005932:167681:270272 [1] NCCL INFO misc/socket.cc:550 -> 3
29: nid005932:167681:270272 [1] NCCL INFO misc/socket.cc:573 -> 3
25: 
25: nid005919:107465:108031 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
25: nid005919:107465:211240 [3] NCCL INFO misc/socket.cc:47 -> 3
25: nid005919:107465:211240 [3] NCCL INFO misc/socket.cc:58 -> 3
25: nid005919:107465:211240 [3] NCCL INFO misc/socket.cc:775 -> 3
25: nid005919:107465:108031 [3] NCCL INFO misc/socket.cc:826 -> 3
29: nid005932:167681:270272 [1] NCCL INFO misc/socket.cc:621 -> 3
25: 
25: nid005919:107465:108031 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
25: 
25: nid005919:107465:108031 [3] proxy.cc:1521 NCCL WARN [Proxy Service 103] Failed to execute operation Close from rank 103, retcode 3
29: nid005932:167681:168236 [1] NCCL INFO misc/socket.cc:47 -> 3
29: nid005932:167681:168236 [1] NCCL INFO misc/socket.cc:752 -> 3
29: nid005932:167681:168236 [1] NCCL INFO misc/socket.cc:428 -> 3
29: nid005932:167681:168236 [1] NCCL INFO misc/socket.cc:564 -> 3
29: nid005932:167681:168236 [1] NCCL INFO misc/socket.cc:668 -> 3
29: 
29: nid005932:167681:168236 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
29: nid005932:167681:270272 [1] NCCL INFO misc/socket.cc:47 -> 3
29: nid005932:167681:270272 [1] NCCL INFO misc/socket.cc:58 -> 3
29: nid005932:167681:270272 [1] NCCL INFO misc/socket.cc:775 -> 3
29: nid005932:167681:168236 [1] NCCL INFO misc/socket.cc:826 -> 3
29: 
29: nid005932:167681:168236 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
29: 
29: nid005932:167681:168236 [1] proxy.cc:1521 NCCL WARN [Proxy Service 117] Failed to execute operation Close from rank 117, retcode 3
20: nid005913:292681:101210 [0] NCCL INFO comm 0x40069564fe00 rank 80 nranks 128 cudaDev 0 busId 901000 - Abort COMPLETE
20: nid005913:292681:101213 [0] NCCL INFO misc/socket.cc:47 -> 3
20: nid005913:292681:101213 [0] NCCL INFO misc/socket.cc:550 -> 3
20: nid005913:292681:101213 [0] NCCL INFO misc/socket.cc:573 -> 3
20: nid005913:292681:101213 [0] NCCL INFO misc/socket.cc:621 -> 3
20: nid005913:292681:293231 [0] NCCL INFO misc/socket.cc:47 -> 3
20: nid005913:292681:293231 [0] NCCL INFO misc/socket.cc:752 -> 3
20: nid005913:292681:293231 [0] NCCL INFO misc/socket.cc:428 -> 3
20: nid005913:292681:293231 [0] NCCL INFO misc/socket.cc:564 -> 3
20: nid005913:292681:293231 [0] NCCL INFO misc/socket.cc:668 -> 3
20: 
20: nid005913:292681:293231 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
20: nid005913:292681:101213 [0] NCCL INFO misc/socket.cc:47 -> 3
20: nid005913:292681:101213 [0] NCCL INFO misc/socket.cc:58 -> 3
20: nid005913:292681:101213 [0] NCCL INFO misc/socket.cc:775 -> 3
20: nid005913:292681:293231 [0] NCCL INFO misc/socket.cc:826 -> 3
20: 
20: nid005913:292681:293231 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
20: 
20: nid005913:292681:293231 [0] proxy.cc:1521 NCCL WARN [Proxy Service 80] Failed to execute operation Close from rank 80, retcode 3
26: nid005920:67123:168063 [0] NCCL INFO comm 0x40069964fe00 rank 104 nranks 128 cudaDev 0 busId 901000 - Abort COMPLETE
26: nid005920:67123:168066 [0] NCCL INFO misc/socket.cc:47 -> 3
26: nid005920:67123:168066 [0] NCCL INFO misc/socket.cc:550 -> 3
26: nid005920:67123:168066 [0] NCCL INFO misc/socket.cc:573 -> 3
26: nid005920:67123:168066 [0] NCCL INFO misc/socket.cc:621 -> 3
26: nid005920:67123:67689 [0] NCCL INFO misc/socket.cc:47 -> 3
26: nid005920:67123:67689 [0] NCCL INFO misc/socket.cc:752 -> 3
26: nid005920:67123:67689 [0] NCCL INFO misc/socket.cc:428 -> 3
26: nid005920:67123:67689 [0] NCCL INFO misc/socket.cc:564 -> 3
26: nid005920:67123:67689 [0] NCCL INFO misc/socket.cc:668 -> 3
26: 
26: nid005920:67123:67689 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
26: nid005920:67123:168066 [0] NCCL INFO misc/socket.cc:47 -> 3
26: nid005920:67123:168066 [0] NCCL INFO misc/socket.cc:58 -> 3
26: nid005920:67123:168066 [0] NCCL INFO misc/socket.cc:775 -> 3
26: nid005920:67123:67689 [0] NCCL INFO misc/socket.cc:826 -> 3
26: 
26: nid005920:67123:67689 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
26: 
26: nid005920:67123:67689 [0] proxy.cc:1521 NCCL WARN [Proxy Service 104] Failed to execute operation Close from rank 104, retcode 3
11: nid005591:191606:294865 [3] NCCL INFO comm 0x40069164fb20 rank 47 nranks 128 cudaDev 3 busId 3901000 - Abort COMPLETE
11: nid005591:191606:294868 [3] NCCL INFO misc/socket.cc:47 -> 3
11: nid005591:191606:294868 [3] NCCL INFO misc/socket.cc:550 -> 3
11: nid005591:191606:294868 [3] NCCL INFO misc/socket.cc:573 -> 3
11: nid005591:191606:294868 [3] NCCL INFO misc/socket.cc:621 -> 3
11: nid005591:191606:192154 [3] NCCL INFO misc/socket.cc:47 -> 3
11: nid005591:191606:192154 [3] NCCL INFO misc/socket.cc:752 -> 3
11: nid005591:191606:192154 [3] NCCL INFO misc/socket.cc:428 -> 3
11: nid005591:191606:192154 [3] NCCL INFO misc/socket.cc:564 -> 3
11: nid005591:191606:192154 [3] NCCL INFO misc/socket.cc:668 -> 3
11: 
11: nid005591:191606:192154 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
11: nid005591:191606:294868 [3] NCCL INFO misc/socket.cc:47 -> 3
11: nid005591:191606:294868 [3] NCCL INFO misc/socket.cc:58 -> 3
11: nid005591:191606:294868 [3] NCCL INFO misc/socket.cc:775 -> 3
11: nid005591:191606:192154 [3] NCCL INFO misc/socket.cc:826 -> 3
11: 
11: nid005591:191606:192154 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
11: 
11: nid005591:191606:192154 [3] proxy.cc:1521 NCCL WARN [Proxy Service 47] Failed to execute operation Close from rank 47, retcode 3
30: nid005936:49908:151423 [0] NCCL INFO comm 0x40057d64fe00 rank 120 nranks 128 cudaDev 0 busId 901000 - Abort COMPLETE
30: nid005936:49908:151426 [0] NCCL INFO misc/socket.cc:47 -> 3
30: nid005936:49908:151426 [0] NCCL INFO misc/socket.cc:550 -> 3
30: nid005936:49908:151426 [0] NCCL INFO misc/socket.cc:573 -> 3
30: nid005936:49908:151426 [0] NCCL INFO misc/socket.cc:621 -> 3
30: nid005936:49908:50478 [0] NCCL INFO misc/socket.cc:47 -> 3
30: nid005936:49908:50478 [0] NCCL INFO misc/socket.cc:752 -> 3
30: nid005936:49908:50478 [0] NCCL INFO misc/socket.cc:428 -> 3
30: nid005936:49908:50478 [0] NCCL INFO misc/socket.cc:564 -> 3
30: nid005936:49908:50478 [0] NCCL INFO misc/socket.cc:668 -> 3
30: 
30: nid005936:49908:50478 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
30: nid005936:49908:151426 [0] NCCL INFO misc/socket.cc:47 -> 3
30: nid005936:49908:151426 [0] NCCL INFO misc/socket.cc:58 -> 3
30: nid005936:49908:151426 [0] NCCL INFO misc/socket.cc:775 -> 3
30: nid005936:49908:50478 [0] NCCL INFO misc/socket.cc:826 -> 3
30: 
30: nid005936:49908:50478 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
30: 
30: nid005936:49908:50478 [0] proxy.cc:1521 NCCL WARN [Proxy Service 120] Failed to execute operation Close from rank 120, retcode 3
13: nid005595:197886:6863 [3] NCCL INFO comm 0x40069164e840 rank 55 nranks 128 cudaDev 3 busId 3901000 - Abort COMPLETE
13: nid005595:197886:6866 [3] NCCL INFO misc/socket.cc:47 -> 3
13: nid005595:197886:6866 [3] NCCL INFO misc/socket.cc:550 -> 3
13: nid005595:197886:6866 [3] NCCL INFO misc/socket.cc:573 -> 3
13: nid005595:197886:6866 [3] NCCL INFO misc/socket.cc:621 -> 3
13: nid005595:197886:198477 [3] NCCL INFO misc/socket.cc:47 -> 3
13: nid005595:197886:198477 [3] NCCL INFO misc/socket.cc:752 -> 3
13: nid005595:197886:198477 [3] NCCL INFO misc/socket.cc:428 -> 3
13: nid005595:197886:198477 [3] NCCL INFO misc/socket.cc:564 -> 3
13: nid005595:197886:198477 [3] NCCL INFO misc/socket.cc:668 -> 3
13: 
13: nid005595:197886:198477 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
13: nid005595:197886:6866 [3] NCCL INFO misc/socket.cc:47 -> 3
13: nid005595:197886:6866 [3] NCCL INFO misc/socket.cc:58 -> 3
13: nid005595:197886:6866 [3] NCCL INFO misc/socket.cc:775 -> 3
13: nid005595:197886:198477 [3] NCCL INFO misc/socket.cc:826 -> 3
13: 
13: nid005595:197886:198477 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
13: 
13: nid005595:197886:198477 [3] proxy.cc:1521 NCCL WARN [Proxy Service 55] Failed to execute operation Close from rank 55, retcode 3
13: nid005595:197884:6864 [1] NCCL INFO comm 0x40068d64e840 rank 53 nranks 128 cudaDev 1 busId 1901000 - Abort COMPLETE
13: nid005595:197884:6867 [1] NCCL INFO misc/socket.cc:47 -> 3
13: nid005595:197884:6867 [1] NCCL INFO misc/socket.cc:550 -> 3
13: nid005595:197884:6867 [1] NCCL INFO misc/socket.cc:573 -> 3
13: nid005595:197884:6867 [1] NCCL INFO misc/socket.cc:621 -> 3
13: nid005595:197884:198480 [1] NCCL INFO misc/socket.cc:47 -> 3
13: nid005595:197884:198480 [1] NCCL INFO misc/socket.cc:752 -> 3
13: nid005595:197884:198480 [1] NCCL INFO misc/socket.cc:428 -> 3
13: nid005595:197884:198480 [1] NCCL INFO misc/socket.cc:564 -> 3
13: nid005595:197884:198480 [1] NCCL INFO misc/socket.cc:668 -> 3
13: 
13: nid005595:197884:198480 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
13: nid005595:197884:6867 [1] NCCL INFO misc/socket.cc:47 -> 3
13: nid005595:197884:6867 [1] NCCL INFO misc/socket.cc:58 -> 3
13: nid005595:197884:6867 [1] NCCL INFO misc/socket.cc:775 -> 3
13: nid005595:197884:198480 [1] NCCL INFO misc/socket.cc:826 -> 3
13: 
13: nid005595:197884:198480 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
13: 
13: nid005595:197884:198480 [1] proxy.cc:1521 NCCL WARN [Proxy Service 53] Failed to execute operation Close from rank 53, retcode 3
27: nid005922:80741:183169 [0] NCCL INFO comm 0x40067964fde0 rank 108 nranks 128 cudaDev 0 busId 901000 - Abort COMPLETE
27: nid005922:80741:183173 [0] NCCL INFO misc/socket.cc:47 -> 3
27: nid005922:80741:183173 [0] NCCL INFO misc/socket.cc:550 -> 3
27: nid005922:80741:183173 [0] NCCL INFO misc/socket.cc:573 -> 3
27: nid005922:80741:183173 [0] NCCL INFO misc/socket.cc:621 -> 3
27: nid005922:80741:81294 [0] NCCL INFO misc/socket.cc:47 -> 3
27: nid005922:80741:81294 [0] NCCL INFO misc/socket.cc:752 -> 3
27: nid005922:80741:81294 [0] NCCL INFO misc/socket.cc:428 -> 3
27: nid005922:80741:81294 [0] NCCL INFO misc/socket.cc:564 -> 3
27: nid005922:80741:81294 [0] NCCL INFO misc/socket.cc:668 -> 3
27: 
27: nid005922:80741:81294 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
27: nid005922:80741:183173 [0] NCCL INFO misc/socket.cc:47 -> 3
27: nid005922:80741:183173 [0] NCCL INFO misc/socket.cc:58 -> 3
27: nid005922:80741:183173 [0] NCCL INFO misc/socket.cc:775 -> 3
27: nid005922:80741:81294 [0] NCCL INFO misc/socket.cc:826 -> 3
27: 
27: nid005922:80741:81294 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
27: 
27: nid005922:80741:81294 [0] proxy.cc:1521 NCCL WARN [Proxy Service 108] Failed to execute operation Close from rank 108, retcode 3
21: nid005914:166784:269597 [0] NCCL INFO comm 0x4006a164fe00 rank 84 nranks 128 cudaDev 0 busId 901000 - Abort COMPLETE
21: nid005914:166784:269598 [0] NCCL INFO misc/socket.cc:47 -> 3
21: nid005914:166784:269598 [0] NCCL INFO misc/socket.cc:550 -> 3
21: nid005914:166784:269598 [0] NCCL INFO misc/socket.cc:573 -> 3
21: nid005914:166784:269598 [0] NCCL INFO misc/socket.cc:621 -> 3
21: nid005914:166784:167328 [0] NCCL INFO misc/socket.cc:47 -> 3
21: nid005914:166784:167328 [0] NCCL INFO misc/socket.cc:752 -> 3
21: nid005914:166784:167328 [0] NCCL INFO misc/socket.cc:428 -> 3
21: nid005914:166784:167328 [0] NCCL INFO misc/socket.cc:564 -> 3
21: nid005914:166784:167328 [0] NCCL INFO misc/socket.cc:668 -> 3
21: 
21: nid005914:166784:167328 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
21: nid005914:166784:269598 [0] NCCL INFO misc/socket.cc:47 -> 3
21: nid005914:166784:269598 [0] NCCL INFO misc/socket.cc:58 -> 3
21: nid005914:166784:269598 [0] NCCL INFO misc/socket.cc:775 -> 3
21: nid005914:166784:167328 [0] NCCL INFO misc/socket.cc:826 -> 3
21: 
21: nid005914:166784:167328 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
21: 
21: nid005914:166784:167328 [0] proxy.cc:1521 NCCL WARN [Proxy Service 84] Failed to execute operation Close from rank 84, retcode 3
18: nid005911:38864:140343 [0] NCCL INFO comm 0x40068964fdf0 rank 72 nranks 128 cudaDev 0 busId 901000 - Abort COMPLETE
18: nid005911:38864:140347 [0] NCCL INFO misc/socket.cc:47 -> 3
18: nid005911:38864:140347 [0] NCCL INFO misc/socket.cc:550 -> 3
18: nid005911:38864:140347 [0] NCCL INFO misc/socket.cc:573 -> 3
18: nid005911:38864:140347 [0] NCCL INFO misc/socket.cc:621 -> 3
18: nid005911:38864:39429 [0] NCCL INFO misc/socket.cc:47 -> 3
18: nid005911:38864:39429 [0] NCCL INFO misc/socket.cc:752 -> 3
18: nid005911:38864:39429 [0] NCCL INFO misc/socket.cc:428 -> 3
18: nid005911:38864:39429 [0] NCCL INFO misc/socket.cc:564 -> 3
18: nid005911:38864:39429 [0] NCCL INFO misc/socket.cc:668 -> 3
18: 
18: nid005911:38864:39429 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
18: nid005911:38864:140347 [0] NCCL INFO misc/socket.cc:47 -> 3
18: nid005911:38864:140347 [0] NCCL INFO misc/socket.cc:58 -> 3
18: nid005911:38864:140347 [0] NCCL INFO misc/socket.cc:775 -> 3
18: nid005911:38864:39429 [0] NCCL INFO misc/socket.cc:826 -> 3
18: 
18: nid005911:38864:39429 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
18: 
18: nid005911:38864:39429 [0] proxy.cc:1521 NCCL WARN [Proxy Service 72] Failed to execute operation Close from rank 72, retcode 3
14: nid005600:217720:26914 [0] NCCL INFO comm 0x40066964fdc0 rank 56 nranks 128 cudaDev 0 busId 901000 - Abort COMPLETE
14: nid005600:217720:26918 [0] NCCL INFO misc/socket.cc:47 -> 3
14: nid005600:217720:26918 [0] NCCL INFO misc/socket.cc:550 -> 3
14: nid005600:217720:26918 [0] NCCL INFO misc/socket.cc:573 -> 3
14: nid005600:217720:26918 [0] NCCL INFO misc/socket.cc:621 -> 3
14: nid005600:217720:218276 [0] NCCL INFO misc/socket.cc:47 -> 3
14: nid005600:217720:218276 [0] NCCL INFO misc/socket.cc:752 -> 3
14: nid005600:217720:218276 [0] NCCL INFO misc/socket.cc:428 -> 3
14: nid005600:217720:218276 [0] NCCL INFO misc/socket.cc:564 -> 3
14: nid005600:217720:218276 [0] NCCL INFO misc/socket.cc:668 -> 3
14: 
14: nid005600:217720:218276 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
14: nid005600:217720:26918 [0] NCCL INFO misc/socket.cc:47 -> 3
14: nid005600:217720:26918 [0] NCCL INFO misc/socket.cc:58 -> 3
14: nid005600:217720:26918 [0] NCCL INFO misc/socket.cc:775 -> 3
14: nid005600:217720:218276 [0] NCCL INFO misc/socket.cc:826 -> 3
14: 
14: nid005600:217720:218276 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
14: 
14: nid005600:217720:218276 [0] proxy.cc:1521 NCCL WARN [Proxy Service 56] Failed to execute operation Close from rank 56, retcode 3
 9: nid005588:35937:138384 [2] NCCL INFO comm 0x40068d64fe00 rank 38 nranks 128 cudaDev 2 busId 2901000 - Abort COMPLETE
 9: nid005588:35937:138385 [2] NCCL INFO misc/socket.cc:47 -> 3
 9: nid005588:35937:138385 [2] NCCL INFO misc/socket.cc:550 -> 3
 9: nid005588:35937:138385 [2] NCCL INFO misc/socket.cc:573 -> 3
 9: nid005588:35937:138385 [2] NCCL INFO misc/socket.cc:621 -> 3
 9: nid005588:35937:36501 [2] NCCL INFO misc/socket.cc:47 -> 3
 9: nid005588:35937:36501 [2] NCCL INFO misc/socket.cc:752 -> 3
 9: nid005588:35937:36501 [2] NCCL INFO misc/socket.cc:428 -> 3
 9: nid005588:35937:36501 [2] NCCL INFO misc/socket.cc:564 -> 3
 9: nid005588:35937:36501 [2] NCCL INFO misc/socket.cc:668 -> 3
 9: 
 9: nid005588:35937:36501 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 9: nid005588:35937:138385 [2] NCCL INFO misc/socket.cc:47 -> 3
 9: nid005588:35937:138385 [2] NCCL INFO misc/socket.cc:58 -> 3
 9: nid005588:35937:138385 [2] NCCL INFO misc/socket.cc:775 -> 3
 9: nid005588:35937:36501 [2] NCCL INFO misc/socket.cc:826 -> 3
 9: 
 9: nid005588:35937:36501 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
 9: 
 9: nid005588:35937:36501 [2] proxy.cc:1521 NCCL WARN [Proxy Service 38] Failed to execute operation Close from rank 38, retcode 3
16: nid005802:6297:108574 [0] NCCL INFO comm 0x400669651260 rank 64 nranks 128 cudaDev 0 busId 901000 - Abort COMPLETE
16: nid005802:6297:108576 [0] NCCL INFO misc/socket.cc:47 -> 3
16: nid005802:6297:108576 [0] NCCL INFO misc/socket.cc:550 -> 3
16: nid005802:6297:108576 [0] NCCL INFO misc/socket.cc:573 -> 3
16: nid005802:6297:108576 [0] NCCL INFO misc/socket.cc:621 -> 3
16: nid005802:6297:6910 [0] NCCL INFO misc/socket.cc:47 -> 3
16: nid005802:6297:6910 [0] NCCL INFO misc/socket.cc:752 -> 3
16: nid005802:6297:6910 [0] NCCL INFO misc/socket.cc:428 -> 3
16: nid005802:6297:6910 [0] NCCL INFO misc/socket.cc:564 -> 3
16: nid005802:6297:6910 [0] NCCL INFO misc/socket.cc:668 -> 3
16: 
16: nid005802:6297:6910 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
16: nid005802:6297:108576 [0] NCCL INFO misc/socket.cc:47 -> 3
16: nid005802:6297:108576 [0] NCCL INFO misc/socket.cc:58 -> 3
16: nid005802:6297:108576 [0] NCCL INFO misc/socket.cc:775 -> 3
16: nid005802:6297:6910 [0] NCCL INFO misc/socket.cc:826 -> 3
16: 
16: nid005802:6297:6910 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
16: 
16: nid005802:6297:6910 [0] proxy.cc:1521 NCCL WARN [Proxy Service 64] Failed to execute operation Close from rank 64, retcode 3
 2: nid005577:17422:118762 [0] NCCL INFO comm 0x40069964fe00 rank 8 nranks 128 cudaDev 0 busId 901000 - Abort COMPLETE
 2: nid005577:17422:118765 [0] NCCL INFO misc/socket.cc:47 -> 3
 2: nid005577:17422:118765 [0] NCCL INFO misc/socket.cc:550 -> 3
 2: nid005577:17422:118765 [0] NCCL INFO misc/socket.cc:573 -> 3
 2: nid005577:17422:118765 [0] NCCL INFO misc/socket.cc:621 -> 3
 2: nid005577:17422:17993 [0] NCCL INFO misc/socket.cc:47 -> 3
 2: nid005577:17422:17993 [0] NCCL INFO misc/socket.cc:752 -> 3
 2: nid005577:17422:17993 [0] NCCL INFO misc/socket.cc:428 -> 3
 2: nid005577:17422:17993 [0] NCCL INFO misc/socket.cc:564 -> 3
 2: nid005577:17422:17993 [0] NCCL INFO misc/socket.cc:668 -> 3
 2: 
 2: nid005577:17422:17993 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 2: nid005577:17422:118765 [0] NCCL INFO misc/socket.cc:47 -> 3
 2: nid005577:17422:118765 [0] NCCL INFO misc/socket.cc:58 -> 3
 2: nid005577:17422:118765 [0] NCCL INFO misc/socket.cc:775 -> 3
 2: nid005577:17422:17993 [0] NCCL INFO misc/socket.cc:826 -> 3
 2: 
 2: nid005577:17422:17993 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
 2: 
 2: nid005577:17422:17993 [0] proxy.cc:1521 NCCL WARN [Proxy Service 8] Failed to execute operation Close from rank 8, retcode 3
29: nid005932:167683:270269 [3] NCCL INFO comm 0x4006a1651260 rank 119 nranks 128 cudaDev 3 busId 3901000 - Abort COMPLETE
29: nid005932:167683:270273 [3] NCCL INFO misc/socket.cc:47 -> 3
29: nid005932:167683:270273 [3] NCCL INFO misc/socket.cc:550 -> 3
29: nid005932:167683:270273 [3] NCCL INFO misc/socket.cc:573 -> 3
29: nid005932:167683:270273 [3] NCCL INFO misc/socket.cc:621 -> 3
29: nid005932:167683:168234 [3] NCCL INFO misc/socket.cc:47 -> 3
29: nid005932:167683:168234 [3] NCCL INFO misc/socket.cc:752 -> 3
29: nid005932:167683:168234 [3] NCCL INFO misc/socket.cc:428 -> 3
29: nid005932:167683:168234 [3] NCCL INFO misc/socket.cc:564 -> 3
29: nid005932:167683:168234 [3] NCCL INFO misc/socket.cc:668 -> 3
29: 
29: nid005932:167683:168234 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
29: nid005932:167683:270273 [3] NCCL INFO misc/socket.cc:47 -> 3
29: nid005932:167683:270273 [3] NCCL INFO misc/socket.cc:58 -> 3
29: nid005932:167683:168234 [3] NCCL INFO misc/socket.cc:826 -> 3
29: 
29: nid005932:167683:168234 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
29: 
29: nid005932:167683:168234 [3] proxy.cc:1521 NCCL WARN [Proxy Service 119] Failed to execute operation Close from rank 119, retcode 3
29: nid005932:167683:270273 [3] NCCL INFO misc/socket.cc:775 -> 3
22: nid005915:274814:84248 [0] NCCL INFO comm 0x40067d64fe00 rank 88 nranks 128 cudaDev 0 busId 901000 - Abort COMPLETE
22: nid005915:274814:84251 [0] NCCL INFO misc/socket.cc:47 -> 3
22: nid005915:274814:84251 [0] NCCL INFO misc/socket.cc:550 -> 3
22: nid005915:274814:84251 [0] NCCL INFO misc/socket.cc:573 -> 3
22: nid005915:274814:84251 [0] NCCL INFO misc/socket.cc:621 -> 3
22: nid005915:274814:275366 [0] NCCL INFO misc/socket.cc:47 -> 3
22: nid005915:274814:275366 [0] NCCL INFO misc/socket.cc:752 -> 3
22: nid005915:274814:275366 [0] NCCL INFO misc/socket.cc:428 -> 3
22: nid005915:274814:275366 [0] NCCL INFO misc/socket.cc:564 -> 3
22: nid005915:274814:275366 [0] NCCL INFO misc/socket.cc:668 -> 3
22: 
22: nid005915:274814:275366 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
22: nid005915:274814:84251 [0] NCCL INFO misc/socket.cc:47 -> 3
22: nid005915:274814:84251 [0] NCCL INFO misc/socket.cc:58 -> 3
22: nid005915:274814:84251 [0] NCCL INFO misc/socket.cc:775 -> 3
22: nid005915:274814:275366 [0] NCCL INFO misc/socket.cc:826 -> 3
22: 
22: nid005915:274814:275366 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
22: 
22: nid005915:274814:275366 [0] proxy.cc:1521 NCCL WARN [Proxy Service 88] Failed to execute operation Close from rank 88, retcode 3
10: nid005590:110710:213916 [0] NCCL INFO comm 0x40066964e420 rank 40 nranks 128 cudaDev 0 busId 901000 - Abort COMPLETE
14: nid005600:217723:26915 [3] NCCL INFO comm 0x4006bd64e900 rank 59 nranks 128 cudaDev 3 busId 3901000 - Abort COMPLETE
10: nid005590:110710:213919 [0] NCCL INFO misc/socket.cc:47 -> 3
10: nid005590:110710:213919 [0] NCCL INFO misc/socket.cc:550 -> 3
10: nid005590:110710:213919 [0] NCCL INFO misc/socket.cc:573 -> 3
10: nid005590:110710:213919 [0] NCCL INFO misc/socket.cc:621 -> 3
10: nid005590:110710:111250 [0] NCCL INFO misc/socket.cc:47 -> 3
10: nid005590:110710:111250 [0] NCCL INFO misc/socket.cc:752 -> 3
10: nid005590:110710:111250 [0] NCCL INFO misc/socket.cc:428 -> 3
10: nid005590:110710:111250 [0] NCCL INFO misc/socket.cc:564 -> 3
10: nid005590:110710:111250 [0] NCCL INFO misc/socket.cc:668 -> 3
10: 
10: nid005590:110710:111250 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
10: nid005590:110710:213919 [0] NCCL INFO misc/socket.cc:47 -> 3
10: nid005590:110710:213919 [0] NCCL INFO misc/socket.cc:58 -> 3
10: nid005590:110710:213919 [0] NCCL INFO misc/socket.cc:775 -> 3
10: nid005590:110710:111250 [0] NCCL INFO misc/socket.cc:826 -> 3
10: 
10: nid005590:110710:111250 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
10: 
10: nid005590:110710:111250 [0] proxy.cc:1521 NCCL WARN [Proxy Service 40] Failed to execute operation Close from rank 40, retcode 3
14: nid005600:217723:26919 [3] NCCL INFO misc/socket.cc:47 -> 3
14: nid005600:217723:26919 [3] NCCL INFO misc/socket.cc:550 -> 3
14: nid005600:217723:26919 [3] NCCL INFO misc/socket.cc:573 -> 3
14: nid005600:217723:26919 [3] NCCL INFO misc/socket.cc:621 -> 3
14: nid005600:217723:218272 [3] NCCL INFO misc/socket.cc:47 -> 3
14: nid005600:217723:218272 [3] NCCL INFO misc/socket.cc:752 -> 3
14: nid005600:217723:218272 [3] NCCL INFO misc/socket.cc:428 -> 3
14: nid005600:217723:218272 [3] NCCL INFO misc/socket.cc:564 -> 3
14: nid005600:217723:218272 [3] NCCL INFO misc/socket.cc:668 -> 3
14: 
14: nid005600:217723:218272 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
14: nid005600:217723:26919 [3] NCCL INFO misc/socket.cc:47 -> 3
14: nid005600:217723:26919 [3] NCCL INFO misc/socket.cc:58 -> 3
14: nid005600:217723:26919 [3] NCCL INFO misc/socket.cc:775 -> 3
14: nid005600:217723:218272 [3] NCCL INFO misc/socket.cc:826 -> 3
14: 
14: nid005600:217723:218272 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
14: 
14: nid005600:217723:218272 [3] proxy.cc:1521 NCCL WARN [Proxy Service 59] Failed to execute operation Close from rank 59, retcode 3
 0: nid005574:69059:171237 [1] NCCL INFO comm 0x4006b964e900 rank 1 nranks 128 cudaDev 1 busId 1901000 - Abort COMPLETE
 0: nid005574:69059:171240 [1] NCCL INFO misc/socket.cc:47 -> 3
 0: nid005574:69059:171240 [1] NCCL INFO misc/socket.cc:550 -> 3
 0: nid005574:69059:171240 [1] NCCL INFO misc/socket.cc:573 -> 3
 0: nid005574:69059:171240 [1] NCCL INFO misc/socket.cc:621 -> 3
 0: nid005574:69059:69630 [1] NCCL INFO misc/socket.cc:47 -> 3
 0: nid005574:69059:69630 [1] NCCL INFO misc/socket.cc:752 -> 3
 0: nid005574:69059:69630 [1] NCCL INFO misc/socket.cc:428 -> 3
 0: nid005574:69059:69630 [1] NCCL INFO misc/socket.cc:564 -> 3
 0: nid005574:69059:69630 [1] NCCL INFO misc/socket.cc:668 -> 3
 0: 
 0: nid005574:69059:69630 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 0: nid005574:69059:171240 [1] NCCL INFO misc/socket.cc:47 -> 3
 0: nid005574:69059:171240 [1] NCCL INFO misc/socket.cc:58 -> 3
 0: nid005574:69059:171240 [1] NCCL INFO misc/socket.cc:775 -> 3
 0: nid005574:69059:69630 [1] NCCL INFO misc/socket.cc:826 -> 3
 0: 
 0: nid005574:69059:69630 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
 0: 
 0: nid005574:69059:69630 [1] proxy.cc:1521 NCCL WARN [Proxy Service 1] Failed to execute operation Close from rank 1, retcode 3
23: nid005917:276885:86830 [0] NCCL INFO comm 0x400668a73790 rank 92 nranks 128 cudaDev 0 busId 901000 - Abort COMPLETE
23: nid005917:276885:86832 [0] NCCL INFO misc/socket.cc:47 -> 3
23: nid005917:276885:86832 [0] NCCL INFO misc/socket.cc:550 -> 3
23: nid005917:276885:86832 [0] NCCL INFO misc/socket.cc:573 -> 3
23: nid005917:276885:86832 [0] NCCL INFO misc/socket.cc:621 -> 3
23: nid005917:276885:277435 [0] NCCL INFO misc/socket.cc:47 -> 3
23: nid005917:276885:277435 [0] NCCL INFO misc/socket.cc:752 -> 3
23: nid005917:276885:277435 [0] NCCL INFO misc/socket.cc:428 -> 3
23: nid005917:276885:277435 [0] NCCL INFO misc/socket.cc:564 -> 3
23: nid005917:276885:277435 [0] NCCL INFO misc/socket.cc:668 -> 3
23: 
23: nid005917:276885:277435 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
23: nid005917:276885:86832 [0] NCCL INFO misc/socket.cc:47 -> 3
23: nid005917:276885:86832 [0] NCCL INFO misc/socket.cc:58 -> 3
23: nid005917:276885:277435 [0] NCCL INFO misc/socket.cc:826 -> 3
23: 
23: nid005917:276885:277435 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
23: 
23: nid005917:276885:277435 [0] proxy.cc:1521 NCCL WARN [Proxy Service 92] Failed to execute operation Close from rank 92, retcode 3
23: nid005917:276885:86832 [0] NCCL INFO misc/socket.cc:775 -> 3
 5: nid005582:196713:3940 [0] NCCL INFO comm 0x40068564fdf0 rank 20 nranks 128 cudaDev 0 busId 901000 - Abort COMPLETE
 5: nid005582:196713:3944 [0] NCCL INFO misc/socket.cc:47 -> 3
 5: nid005582:196713:3944 [0] NCCL INFO misc/socket.cc:550 -> 3
 5: nid005582:196713:3944 [0] NCCL INFO misc/socket.cc:573 -> 3
 5: nid005582:196713:3944 [0] NCCL INFO misc/socket.cc:621 -> 3
 5: nid005582:196713:197396 [0] NCCL INFO misc/socket.cc:47 -> 3
 5: nid005582:196713:197396 [0] NCCL INFO misc/socket.cc:752 -> 3
 5: nid005582:196713:197396 [0] NCCL INFO misc/socket.cc:428 -> 3
 5: nid005582:196713:197396 [0] NCCL INFO misc/socket.cc:564 -> 3
 5: nid005582:196713:197396 [0] NCCL INFO misc/socket.cc:668 -> 3
 5: 
 5: nid005582:196713:197396 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 5: nid005582:196713:3944 [0] NCCL INFO misc/socket.cc:47 -> 3
 5: nid005582:196713:3944 [0] NCCL INFO misc/socket.cc:58 -> 3
 5: nid005582:196713:3944 [0] NCCL INFO misc/socket.cc:775 -> 3
 5: nid005582:196713:197396 [0] NCCL INFO misc/socket.cc:826 -> 3
 5: 
 5: nid005582:196713:197396 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
 5: 
 5: nid005582:196713:197396 [0] proxy.cc:1521 NCCL WARN [Proxy Service 20] Failed to execute operation Close from rank 20, retcode 3
11: nid005591:191603:294867 [0] NCCL INFO comm 0x400681651260 rank 44 nranks 128 cudaDev 0 busId 901000 - Abort COMPLETE
11: nid005591:191603:294869 [0] NCCL INFO misc/socket.cc:47 -> 3
11: nid005591:191603:294869 [0] NCCL INFO misc/socket.cc:550 -> 3
11: nid005591:191603:294869 [0] NCCL INFO misc/socket.cc:573 -> 3
11: nid005591:191603:294869 [0] NCCL INFO misc/socket.cc:621 -> 3
11: nid005591:191603:192150 [0] NCCL INFO misc/socket.cc:47 -> 3
11: nid005591:191603:192150 [0] NCCL INFO misc/socket.cc:752 -> 3
11: nid005591:191603:192150 [0] NCCL INFO misc/socket.cc:428 -> 3
11: nid005591:191603:192150 [0] NCCL INFO misc/socket.cc:564 -> 3
11: nid005591:191603:192150 [0] NCCL INFO misc/socket.cc:668 -> 3
11: 
11: nid005591:191603:192150 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
11: nid005591:191603:294869 [0] NCCL INFO misc/socket.cc:47 -> 3
11: nid005591:191603:294869 [0] NCCL INFO misc/socket.cc:58 -> 3
11: nid005591:191603:294869 [0] NCCL INFO misc/socket.cc:775 -> 3
11: nid005591:191603:192150 [0] NCCL INFO misc/socket.cc:826 -> 3
11: 
11: nid005591:191603:192150 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
11: 
11: nid005591:191603:192150 [0] proxy.cc:1521 NCCL WARN [Proxy Service 44] Failed to execute operation Close from rank 44, retcode 3
 6: nid005584:28285:128091 [0] NCCL INFO comm 0x40066564e8c0 rank 24 nranks 128 cudaDev 0 busId 901000 - Abort COMPLETE
 6: nid005584:28285:128095 [0] NCCL INFO misc/socket.cc:47 -> 3
 6: nid005584:28285:128095 [0] NCCL INFO misc/socket.cc:550 -> 3
 6: nid005584:28285:128095 [0] NCCL INFO misc/socket.cc:573 -> 3
 6: nid005584:28285:128095 [0] NCCL INFO misc/socket.cc:621 -> 3
 6: nid005584:28285:28828 [0] NCCL INFO misc/socket.cc:47 -> 3
 6: nid005584:28285:28828 [0] NCCL INFO misc/socket.cc:752 -> 3
 6: nid005584:28285:28828 [0] NCCL INFO misc/socket.cc:428 -> 3
 6: nid005584:28285:28828 [0] NCCL INFO misc/socket.cc:564 -> 3
 6: nid005584:28285:28828 [0] NCCL INFO misc/socket.cc:668 -> 3
 6: 
 6: nid005584:28285:28828 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 6: nid005584:28285:128095 [0] NCCL INFO misc/socket.cc:47 -> 3
 6: nid005584:28285:128095 [0] NCCL INFO misc/socket.cc:58 -> 3
 6: nid005584:28285:128095 [0] NCCL INFO misc/socket.cc:775 -> 3
 6: nid005584:28285:28828 [0] NCCL INFO misc/socket.cc:826 -> 3
 6: 
 6: nid005584:28285:28828 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
 6: 
 6: nid005584:28285:28828 [0] proxy.cc:1521 NCCL WARN [Proxy Service 24] Failed to execute operation Close from rank 24, retcode 3
29: nid005932:167680:270270 [0] NCCL INFO comm 0x40069d64fa60 rank 116 nranks 128 cudaDev 0 busId 901000 - Abort COMPLETE
29: nid005932:167680:270274 [0] NCCL INFO misc/socket.cc:47 -> 3
29: nid005932:167680:270274 [0] NCCL INFO misc/socket.cc:550 -> 3
29: nid005932:167680:270274 [0] NCCL INFO misc/socket.cc:573 -> 3
29: nid005932:167680:270274 [0] NCCL INFO misc/socket.cc:621 -> 3
29: nid005932:167680:168240 [0] NCCL INFO misc/socket.cc:47 -> 3
29: nid005932:167680:168240 [0] NCCL INFO misc/socket.cc:752 -> 3
29: nid005932:167680:168240 [0] NCCL INFO misc/socket.cc:428 -> 3
29: nid005932:167680:168240 [0] NCCL INFO misc/socket.cc:564 -> 3
29: nid005932:167680:168240 [0] NCCL INFO misc/socket.cc:668 -> 3
29: 
29: nid005932:167680:168240 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
29: nid005932:167680:270274 [0] NCCL INFO misc/socket.cc:47 -> 3
29: nid005932:167680:270274 [0] NCCL INFO misc/socket.cc:58 -> 3
29: nid005932:167680:270274 [0] NCCL INFO misc/socket.cc:775 -> 3
29: nid005932:167680:168240 [0] NCCL INFO misc/socket.cc:826 -> 3
29: 
29: nid005932:167680:168240 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
29: 
29: nid005932:167680:168240 [0] proxy.cc:1521 NCCL WARN [Proxy Service 116] Failed to execute operation Close from rank 116, retcode 3
 0: nid005574:69061:171238 [3] NCCL INFO comm 0x40069964e880 rank 3 nranks 128 cudaDev 3 busId 3901000 - Abort COMPLETE
 0: nid005574:69061:171241 [3] NCCL INFO misc/socket.cc:47 -> 3
 0: nid005574:69061:171241 [3] NCCL INFO misc/socket.cc:550 -> 3
 0: nid005574:69061:171241 [3] NCCL INFO misc/socket.cc:573 -> 3
 0: nid005574:69061:171241 [3] NCCL INFO misc/socket.cc:621 -> 3
 0: nid005574:69061:69632 [3] NCCL INFO misc/socket.cc:47 -> 3
 0: nid005574:69061:69632 [3] NCCL INFO misc/socket.cc:752 -> 3
 0: nid005574:69061:69632 [3] NCCL INFO misc/socket.cc:428 -> 3
 0: nid005574:69061:69632 [3] NCCL INFO misc/socket.cc:564 -> 3
 0: nid005574:69061:69632 [3] NCCL INFO misc/socket.cc:668 -> 3
 0: 
 0: nid005574:69061:69632 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 0: nid005574:69061:171241 [3] NCCL INFO misc/socket.cc:47 -> 3
 0: nid005574:69061:171241 [3] NCCL INFO misc/socket.cc:58 -> 3
 0: nid005574:69061:171241 [3] NCCL INFO misc/socket.cc:775 -> 3
 0: nid005574:69061:69632 [3] NCCL INFO misc/socket.cc:826 -> 3
 0: 
 0: nid005574:69061:69632 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
 0: 
 0: nid005574:69061:69632 [3] proxy.cc:1521 NCCL WARN [Proxy Service 3] Failed to execute operation Close from rank 3, retcode 3
11: nid005591:191606:294868 [3] NCCL INFO comm 0xaaaae7d03880 rank 47 nranks 128 cudaDev 3 busId 3901000 - Abort COMPLETE
16: nid005802:6299:108571 [2] NCCL INFO comm 0x4006ad650f90 rank 66 nranks 128 cudaDev 2 busId 2901000 - Abort COMPLETE
16: nid005802:6299:108577 [2] NCCL INFO misc/socket.cc:47 -> 3
16: nid005802:6299:108577 [2] NCCL INFO misc/socket.cc:550 -> 3
16: nid005802:6299:108577 [2] NCCL INFO misc/socket.cc:573 -> 3
16: nid005802:6299:108577 [2] NCCL INFO misc/socket.cc:621 -> 3
16: nid005802:6299:6903 [2] NCCL INFO misc/socket.cc:47 -> 3
16: nid005802:6299:6903 [2] NCCL INFO misc/socket.cc:752 -> 3
16: nid005802:6299:6903 [2] NCCL INFO misc/socket.cc:428 -> 3
16: nid005802:6299:6903 [2] NCCL INFO misc/socket.cc:564 -> 3
16: nid005802:6299:6903 [2] NCCL INFO misc/socket.cc:668 -> 3
16: 
16: nid005802:6299:6903 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
16: nid005802:6299:108577 [2] NCCL INFO misc/socket.cc:47 -> 3
16: nid005802:6299:108577 [2] NCCL INFO misc/socket.cc:58 -> 3
16: nid005802:6299:6903 [2] NCCL INFO misc/socket.cc:826 -> 3
16: 
16: nid005802:6299:6903 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
16: 
16: nid005802:6299:6903 [2] proxy.cc:1521 NCCL WARN [Proxy Service 66] Failed to execute operation Close from rank 66, retcode 3
16: nid005802:6299:108577 [2] NCCL INFO misc/socket.cc:775 -> 3
17: nid005803:180732:283755 [0] NCCL INFO comm 0x400681651260 rank 68 nranks 128 cudaDev 0 busId 901000 - Abort COMPLETE
17: nid005803:180732:283757 [0] NCCL INFO misc/socket.cc:47 -> 3
17: nid005803:180732:283757 [0] NCCL INFO misc/socket.cc:550 -> 3
17: nid005803:180732:283757 [0] NCCL INFO misc/socket.cc:573 -> 3
17: nid005803:180732:283757 [0] NCCL INFO misc/socket.cc:621 -> 3
17: nid005803:180732:181294 [0] NCCL INFO misc/socket.cc:47 -> 3
17: nid005803:180732:181294 [0] NCCL INFO misc/socket.cc:752 -> 3
17: nid005803:180732:181294 [0] NCCL INFO misc/socket.cc:428 -> 3
17: nid005803:180732:181294 [0] NCCL INFO misc/socket.cc:564 -> 3
17: nid005803:180732:181294 [0] NCCL INFO misc/socket.cc:668 -> 3
17: 
17: nid005803:180732:181294 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
17: nid005803:180732:283757 [0] NCCL INFO misc/socket.cc:47 -> 3
17: nid005803:180732:283757 [0] NCCL INFO misc/socket.cc:58 -> 3
17: nid005803:180732:283757 [0] NCCL INFO misc/socket.cc:775 -> 3
17: nid005803:180732:181294 [0] NCCL INFO misc/socket.cc:826 -> 3
17: 
17: nid005803:180732:181294 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
17: 
17: nid005803:180732:181294 [0] proxy.cc:1521 NCCL WARN [Proxy Service 68] Failed to execute operation Close from rank 68, retcode 3
24: nid005918:92507:194029 [3] NCCL INFO comm 0x40069164fe00 rank 99 nranks 128 cudaDev 3 busId 3901000 - Abort COMPLETE
24: nid005918:92507:194033 [3] NCCL INFO misc/socket.cc:47 -> 3
24: nid005918:92507:194033 [3] NCCL INFO misc/socket.cc:550 -> 3
24: nid005918:92507:194033 [3] NCCL INFO misc/socket.cc:573 -> 3
24: nid005918:92507:194033 [3] NCCL INFO misc/socket.cc:621 -> 3
24: nid005918:92507:93084 [3] NCCL INFO misc/socket.cc:47 -> 3
24: nid005918:92507:93084 [3] NCCL INFO misc/socket.cc:752 -> 3
24: nid005918:92507:93084 [3] NCCL INFO misc/socket.cc:428 -> 3
24: nid005918:92507:93084 [3] NCCL INFO misc/socket.cc:564 -> 3
24: nid005918:92507:93084 [3] NCCL INFO misc/socket.cc:668 -> 3
24: 
24: nid005918:92507:93084 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
24: nid005918:92507:194033 [3] NCCL INFO misc/socket.cc:47 -> 3
24: nid005918:92507:194033 [3] NCCL INFO misc/socket.cc:58 -> 3
24: nid005918:92507:194033 [3] NCCL INFO misc/socket.cc:775 -> 3
24: nid005918:92507:93084 [3] NCCL INFO misc/socket.cc:826 -> 3
24: 
24: nid005918:92507:93084 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
24: 
24: nid005918:92507:93084 [3] proxy.cc:1521 NCCL WARN [Proxy Service 99] Failed to execute operation Close from rank 99, retcode 3
13: nid005595:197886:6866 [3] NCCL INFO comm 0xaaaaea46b560 rank 55 nranks 128 cudaDev 3 busId 3901000 - Abort COMPLETE
16: nid005802:6299:108577 [2] NCCL INFO comm 0xaaab08f00a50 rank 66 nranks 128 cudaDev 2 busId 2901000 - Abort COMPLETE
 1: nid005576:147558:250806 [1] NCCL INFO comm 0x40069964fd70 rank 5 nranks 128 cudaDev 1 busId 1901000 - Abort COMPLETE
 1: nid005576:147558:250811 [1] NCCL INFO misc/socket.cc:47 -> 3
 1: nid005576:147558:250811 [1] NCCL INFO misc/socket.cc:550 -> 3
 1: nid005576:147558:250811 [1] NCCL INFO misc/socket.cc:573 -> 3
 1: nid005576:147558:250811 [1] NCCL INFO misc/socket.cc:621 -> 3
 1: nid005576:147558:148104 [1] NCCL INFO misc/socket.cc:47 -> 3
 1: nid005576:147558:148104 [1] NCCL INFO misc/socket.cc:752 -> 3
 1: nid005576:147558:148104 [1] NCCL INFO misc/socket.cc:428 -> 3
 1: nid005576:147558:148104 [1] NCCL INFO misc/socket.cc:564 -> 3
 1: nid005576:147558:148104 [1] NCCL INFO misc/socket.cc:668 -> 3
 1: 
 1: nid005576:147558:148104 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 1: nid005576:147558:250811 [1] NCCL INFO misc/socket.cc:47 -> 3
 1: nid005576:147558:250811 [1] NCCL INFO misc/socket.cc:58 -> 3
 1: nid005576:147558:148104 [1] NCCL INFO misc/socket.cc:826 -> 3
 1: nid005576:147558:250811 [1] NCCL INFO misc/socket.cc:775 -> 3
 1: 
 1: nid005576:147558:148104 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
 1: 
 1: nid005576:147558:148104 [1] proxy.cc:1521 NCCL WARN [Proxy Service 5] Failed to execute operation Close from rank 5, retcode 3
19: nid005912:12435:113120 [0] NCCL INFO comm 0x40066d64e900 rank 76 nranks 128 cudaDev 0 busId 901000 - Abort COMPLETE
19: nid005912:12435:113122 [0] NCCL INFO misc/socket.cc:47 -> 3
19: nid005912:12435:113122 [0] NCCL INFO misc/socket.cc:550 -> 3
19: nid005912:12435:113122 [0] NCCL INFO misc/socket.cc:573 -> 3
19: nid005912:12435:113122 [0] NCCL INFO misc/socket.cc:621 -> 3
19: nid005912:12435:13003 [0] NCCL INFO misc/socket.cc:47 -> 3
19: nid005912:12435:13003 [0] NCCL INFO misc/socket.cc:752 -> 3
19: nid005912:12435:13003 [0] NCCL INFO misc/socket.cc:428 -> 3
19: nid005912:12435:13003 [0] NCCL INFO misc/socket.cc:564 -> 3
19: nid005912:12435:13003 [0] NCCL INFO misc/socket.cc:668 -> 3
19: 
19: nid005912:12435:13003 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
19: nid005912:12435:113122 [0] NCCL INFO misc/socket.cc:47 -> 3
19: nid005912:12435:113122 [0] NCCL INFO misc/socket.cc:58 -> 3
19: nid005912:12435:113122 [0] NCCL INFO misc/socket.cc:775 -> 3
19: nid005912:12435:13003 [0] NCCL INFO misc/socket.cc:826 -> 3
19: 
19: nid005912:12435:13003 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
19: 
19: nid005912:12435:13003 [0] proxy.cc:1521 NCCL WARN [Proxy Service 76] Failed to execute operation Close from rank 76, retcode 3
12: nid005594:53087:154888 [2] NCCL INFO comm 0x40068164e880 rank 50 nranks 128 cudaDev 2 busId 2901000 - Abort COMPLETE
12: nid005594:53087:154892 [2] NCCL INFO misc/socket.cc:47 -> 3
12: nid005594:53087:154892 [2] NCCL INFO misc/socket.cc:550 -> 3
12: nid005594:53087:154892 [2] NCCL INFO misc/socket.cc:573 -> 3
12: nid005594:53087:154892 [2] NCCL INFO misc/socket.cc:621 -> 3
12: nid005594:53087:53628 [2] NCCL INFO misc/socket.cc:47 -> 3
12: nid005594:53087:53628 [2] NCCL INFO misc/socket.cc:752 -> 3
12: nid005594:53087:53628 [2] NCCL INFO misc/socket.cc:428 -> 3
12: nid005594:53087:53628 [2] NCCL INFO misc/socket.cc:564 -> 3
12: nid005594:53087:53628 [2] NCCL INFO misc/socket.cc:668 -> 3
12: 
12: nid005594:53087:53628 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
12: nid005594:53087:154892 [2] NCCL INFO misc/socket.cc:47 -> 3
12: nid005594:53087:154892 [2] NCCL INFO misc/socket.cc:58 -> 3
12: nid005594:53087:154892 [2] NCCL INFO misc/socket.cc:775 -> 3
12: nid005594:53087:53628 [2] NCCL INFO misc/socket.cc:826 -> 3
12: 
12: nid005594:53087:53628 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
12: 
12: nid005594:53087:53628 [2] proxy.cc:1521 NCCL WARN [Proxy Service 50] Failed to execute operation Close from rank 50, retcode 3
 2: nid005577:17424:118761 [2] NCCL INFO comm 0x4006b5648640 rank 10 nranks 128 cudaDev 2 busId 2901000 - Abort COMPLETE
 2: nid005577:17424:118766 [2] NCCL INFO misc/socket.cc:47 -> 3
 2: nid005577:17424:118766 [2] NCCL INFO misc/socket.cc:550 -> 3
 2: nid005577:17424:118766 [2] NCCL INFO misc/socket.cc:573 -> 3
 2: nid005577:17424:118766 [2] NCCL INFO misc/socket.cc:621 -> 3
 2: nid005577:17424:17988 [2] NCCL INFO misc/socket.cc:47 -> 3
 2: nid005577:17424:17988 [2] NCCL INFO misc/socket.cc:752 -> 3
 2: nid005577:17424:17988 [2] NCCL INFO misc/socket.cc:428 -> 3
 2: nid005577:17424:17988 [2] NCCL INFO misc/socket.cc:564 -> 3
 2: nid005577:17424:17988 [2] NCCL INFO misc/socket.cc:668 -> 3
 2: 
 2: nid005577:17424:17988 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 2: nid005577:17424:118766 [2] NCCL INFO misc/socket.cc:47 -> 3
 2: nid005577:17424:118766 [2] NCCL INFO misc/socket.cc:58 -> 3
 2: nid005577:17424:118766 [2] NCCL INFO misc/socket.cc:775 -> 3
 2: nid005577:17424:17988 [2] NCCL INFO misc/socket.cc:826 -> 3
 2: 
 2: nid005577:17424:17988 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
 2: 
 2: nid005577:17424:17988 [2] proxy.cc:1521 NCCL WARN [Proxy Service 10] Failed to execute operation Close from rank 10, retcode 3
28: nid005929:16031:116165 [1] NCCL INFO comm 0x400699647100 rank 113 nranks 128 cudaDev 1 busId 1901000 - Abort COMPLETE
28: nid005929:16031:116166 [1] NCCL INFO misc/socket.cc:47 -> 3
28: nid005929:16031:116166 [1] NCCL INFO misc/socket.cc:550 -> 3
28: nid005929:16031:116166 [1] NCCL INFO misc/socket.cc:573 -> 3
28: nid005929:16031:116166 [1] NCCL INFO misc/socket.cc:621 -> 3
28: nid005929:16031:16580 [1] NCCL INFO misc/socket.cc:47 -> 3
28: nid005929:16031:16580 [1] NCCL INFO misc/socket.cc:752 -> 3
28: nid005929:16031:16580 [1] NCCL INFO misc/socket.cc:428 -> 3
28: nid005929:16031:16580 [1] NCCL INFO misc/socket.cc:564 -> 3
28: nid005929:16031:16580 [1] NCCL INFO misc/socket.cc:668 -> 3
28: 
28: nid005929:16031:16580 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
28: nid005929:16031:116166 [1] NCCL INFO misc/socket.cc:47 -> 3
28: nid005929:16031:16580 [1] NCCL INFO misc/socket.cc:826 -> 3
28: 
28: nid005929:16031:16580 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
28: 
28: nid005929:16031:16580 [1] proxy.cc:1521 NCCL WARN [Proxy Service 113] Failed to execute operation Close from rank 113, retcode 3
28: nid005929:16031:116166 [1] NCCL INFO misc/socket.cc:58 -> 3
28: nid005929:16031:116166 [1] NCCL INFO misc/socket.cc:775 -> 3
21: nid005914:166786:269595 [2] NCCL INFO comm 0x40068564fdf0 rank 86 nranks 128 cudaDev 2 busId 2901000 - Abort COMPLETE
21: nid005914:166786:269599 [2] NCCL INFO misc/socket.cc:47 -> 3
21: nid005914:166786:269599 [2] NCCL INFO misc/socket.cc:550 -> 3
21: nid005914:166786:269599 [2] NCCL INFO misc/socket.cc:573 -> 3
21: nid005914:166786:269599 [2] NCCL INFO misc/socket.cc:621 -> 3
21: nid005914:166786:167325 [2] NCCL INFO misc/socket.cc:47 -> 3
21: nid005914:166786:167325 [2] NCCL INFO misc/socket.cc:752 -> 3
21: nid005914:166786:167325 [2] NCCL INFO misc/socket.cc:428 -> 3
21: nid005914:166786:167325 [2] NCCL INFO misc/socket.cc:564 -> 3
21: nid005914:166786:167325 [2] NCCL INFO misc/socket.cc:668 -> 3
21: 
21: nid005914:166786:167325 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
21: nid005914:166786:269599 [2] NCCL INFO misc/socket.cc:47 -> 3
21: nid005914:166786:269599 [2] NCCL INFO misc/socket.cc:58 -> 3
21: nid005914:166786:269599 [2] NCCL INFO misc/socket.cc:775 -> 3
21: nid005914:166786:167325 [2] NCCL INFO misc/socket.cc:826 -> 3
21: 
21: nid005914:166786:167325 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
21: 
21: nid005914:166786:167325 [2] proxy.cc:1521 NCCL WARN [Proxy Service 86] Failed to execute operation Close from rank 86, retcode 3
 0: nid005574:69060:171239 [2] NCCL INFO comm 0x4006b164e420 rank 2 nranks 128 cudaDev 2 busId 2901000 - Abort COMPLETE
 0: nid005574:69060:171242 [2] NCCL INFO misc/socket.cc:47 -> 3
 0: nid005574:69060:171242 [2] NCCL INFO misc/socket.cc:550 -> 3
 0: nid005574:69060:171242 [2] NCCL INFO misc/socket.cc:573 -> 3
 0: nid005574:69060:171242 [2] NCCL INFO misc/socket.cc:621 -> 3
 0: nid005574:69060:69629 [2] NCCL INFO misc/socket.cc:47 -> 3
 0: nid005574:69060:69629 [2] NCCL INFO misc/socket.cc:752 -> 3
 0: nid005574:69060:69629 [2] NCCL INFO misc/socket.cc:428 -> 3
 0: nid005574:69060:69629 [2] NCCL INFO misc/socket.cc:564 -> 3
 0: nid005574:69060:69629 [2] NCCL INFO misc/socket.cc:668 -> 3
 0: 
 0: nid005574:69060:69629 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 0: nid005574:69060:171242 [2] NCCL INFO misc/socket.cc:47 -> 3
 0: nid005574:69060:171242 [2] NCCL INFO misc/socket.cc:58 -> 3
 0: nid005574:69060:69629 [2] NCCL INFO misc/socket.cc:826 -> 3
 0: 
 0: nid005574:69060:69629 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
 0: 
 0: nid005574:69060:69629 [2] proxy.cc:1521 NCCL WARN [Proxy Service 2] Failed to execute operation Close from rank 2, retcode 3
 0: nid005574:69060:171242 [2] NCCL INFO misc/socket.cc:775 -> 3
27: nid005922:80742:183170 [1] NCCL INFO comm 0x4006996513b0 rank 109 nranks 128 cudaDev 1 busId 1901000 - Abort COMPLETE
27: nid005922:80742:183174 [1] NCCL INFO misc/socket.cc:47 -> 3
27: nid005922:80742:183174 [1] NCCL INFO misc/socket.cc:550 -> 3
27: nid005922:80742:183174 [1] NCCL INFO misc/socket.cc:573 -> 3
27: nid005922:80742:183174 [1] NCCL INFO misc/socket.cc:621 -> 3
27: nid005922:80742:81296 [1] NCCL INFO misc/socket.cc:47 -> 3
27: nid005922:80742:81296 [1] NCCL INFO misc/socket.cc:752 -> 3
27: nid005922:80742:81296 [1] NCCL INFO misc/socket.cc:428 -> 3
27: nid005922:80742:81296 [1] NCCL INFO misc/socket.cc:564 -> 3
27: nid005922:80742:81296 [1] NCCL INFO misc/socket.cc:668 -> 3
27: 
27: nid005922:80742:81296 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
27: nid005922:80742:183174 [1] NCCL INFO misc/socket.cc:47 -> 3
27: nid005922:80742:183174 [1] NCCL INFO misc/socket.cc:58 -> 3
27: nid005922:80742:81296 [1] NCCL INFO misc/socket.cc:826 -> 3
27: 
27: nid005922:80742:81296 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
27: 
27: nid005922:80742:81296 [1] proxy.cc:1521 NCCL WARN [Proxy Service 109] Failed to execute operation Close from rank 109, retcode 3
27: nid005922:80742:183174 [1] NCCL INFO misc/socket.cc:775 -> 3
29: nid005932:167680:270274 [0] NCCL INFO comm 0xaaab03ee4fa0 rank 116 nranks 128 cudaDev 0 busId 901000 - Abort COMPLETE
 3: nid005580:71821:174882 [2] NCCL INFO comm 0x40068564fe00 rank 14 nranks 128 cudaDev 2 busId 2901000 - Abort COMPLETE
 3: nid005580:71821:174885 [2] NCCL INFO misc/socket.cc:47 -> 3
 3: nid005580:71821:174885 [2] NCCL INFO misc/socket.cc:550 -> 3
 3: nid005580:71821:174885 [2] NCCL INFO misc/socket.cc:573 -> 3
 3: nid005580:71821:174885 [2] NCCL INFO misc/socket.cc:621 -> 3
 3: nid005580:71821:72362 [2] NCCL INFO misc/socket.cc:47 -> 3
 3: nid005580:71821:72362 [2] NCCL INFO misc/socket.cc:752 -> 3
 3: nid005580:71821:72362 [2] NCCL INFO misc/socket.cc:428 -> 3
 3: nid005580:71821:72362 [2] NCCL INFO misc/socket.cc:564 -> 3
 3: nid005580:71821:72362 [2] NCCL INFO misc/socket.cc:668 -> 3
 3: 
 3: nid005580:71821:72362 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 3: nid005580:71821:174885 [2] NCCL INFO misc/socket.cc:47 -> 3
 3: nid005580:71821:174885 [2] NCCL INFO misc/socket.cc:58 -> 3
 3: nid005580:71821:174885 [2] NCCL INFO misc/socket.cc:775 -> 3
 3: nid005580:71821:72362 [2] NCCL INFO misc/socket.cc:826 -> 3
 3: 
 3: nid005580:71821:72362 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
 3: 
 3: nid005580:71821:72362 [2] proxy.cc:1521 NCCL WARN [Proxy Service 14] Failed to execute operation Close from rank 14, retcode 3
29: nid005932:167682:270271 [2] NCCL INFO comm 0x400678a86760 rank 118 nranks 128 cudaDev 2 busId 2901000 - Abort COMPLETE
29: nid005932:167682:270276 [2] NCCL INFO misc/socket.cc:47 -> 3
29: nid005932:167682:270276 [2] NCCL INFO misc/socket.cc:550 -> 3
29: nid005932:167682:270276 [2] NCCL INFO misc/socket.cc:573 -> 3
29: nid005932:167682:270276 [2] NCCL INFO misc/socket.cc:621 -> 3
29: nid005932:167682:168237 [2] NCCL INFO misc/socket.cc:47 -> 3
29: nid005932:167682:168237 [2] NCCL INFO misc/socket.cc:752 -> 3
29: nid005932:167682:168237 [2] NCCL INFO misc/socket.cc:428 -> 3
29: nid005932:167682:168237 [2] NCCL INFO misc/socket.cc:564 -> 3
29: nid005932:167682:168237 [2] NCCL INFO misc/socket.cc:668 -> 3
29: 
29: nid005932:167682:168237 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
29: nid005932:167682:270276 [2] NCCL INFO misc/socket.cc:47 -> 3
29: nid005932:167682:270276 [2] NCCL INFO misc/socket.cc:58 -> 3
29: nid005932:167682:270276 [2] NCCL INFO misc/socket.cc:775 -> 3
29: nid005932:167682:168237 [2] NCCL INFO misc/socket.cc:826 -> 3
29: 
29: nid005932:167682:168237 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
29: 
29: nid005932:167682:168237 [2] proxy.cc:1521 NCCL WARN [Proxy Service 118] Failed to execute operation Close from rank 118, retcode 3
 2: nid005577:17422:118765 [0] NCCL INFO comm 0xaaaaf334fcf0 rank 8 nranks 128 cudaDev 0 busId 901000 - Abort COMPLETE
 0: nid005574:69059:171240 [1] NCCL INFO comm 0xaaaad1289f50 rank 1 nranks 128 cudaDev 1 busId 1901000 - Abort COMPLETE
12: nid005594:53085:154889 [0] NCCL INFO comm 0x40068d64fb30 rank 48 nranks 128 cudaDev 0 busId 901000 - Abort COMPLETE
 2: nid005577:17425:118763 [3] NCCL INFO comm 0x40068164e900 rank 11 nranks 128 cudaDev 3 busId 3901000 - Abort COMPLETE
12: nid005594:53085:154893 [0] NCCL INFO misc/socket.cc:47 -> 3
12: nid005594:53085:154893 [0] NCCL INFO misc/socket.cc:550 -> 3
12: nid005594:53085:154893 [0] NCCL INFO misc/socket.cc:573 -> 3
12: nid005594:53085:154893 [0] NCCL INFO misc/socket.cc:621 -> 3
12: nid005594:53085:53633 [0] NCCL INFO misc/socket.cc:47 -> 3
12: nid005594:53085:53633 [0] NCCL INFO misc/socket.cc:752 -> 3
12: nid005594:53085:53633 [0] NCCL INFO misc/socket.cc:428 -> 3
12: nid005594:53085:53633 [0] NCCL INFO misc/socket.cc:564 -> 3
12: nid005594:53085:53633 [0] NCCL INFO misc/socket.cc:668 -> 3
12: 
12: nid005594:53085:53633 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
12: nid005594:53085:154893 [0] NCCL INFO misc/socket.cc:47 -> 3
12: nid005594:53085:154893 [0] NCCL INFO misc/socket.cc:58 -> 3
12: nid005594:53085:154893 [0] NCCL INFO misc/socket.cc:775 -> 3
12: nid005594:53085:53633 [0] NCCL INFO misc/socket.cc:826 -> 3
12: 
12: nid005594:53085:53633 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
12: 
12: nid005594:53085:53633 [0] proxy.cc:1521 NCCL WARN [Proxy Service 48] Failed to execute operation Close from rank 48, retcode 3
 2: nid005577:17425:118767 [3] NCCL INFO misc/socket.cc:47 -> 3
 2: nid005577:17425:118767 [3] NCCL INFO misc/socket.cc:550 -> 3
 2: nid005577:17425:118767 [3] NCCL INFO misc/socket.cc:573 -> 3
 2: nid005577:17425:118767 [3] NCCL INFO misc/socket.cc:621 -> 3
 2: nid005577:17425:17987 [3] NCCL INFO misc/socket.cc:47 -> 3
 2: nid005577:17425:17987 [3] NCCL INFO misc/socket.cc:752 -> 3
 2: nid005577:17425:17987 [3] NCCL INFO misc/socket.cc:428 -> 3
 2: nid005577:17425:17987 [3] NCCL INFO misc/socket.cc:564 -> 3
 2: nid005577:17425:17987 [3] NCCL INFO misc/socket.cc:668 -> 3
 2: 
 2: nid005577:17425:17987 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 2: nid005577:17425:118767 [3] NCCL INFO misc/socket.cc:47 -> 3
 2: nid005577:17425:118767 [3] NCCL INFO misc/socket.cc:58 -> 3
 2: nid005577:17425:17987 [3] NCCL INFO misc/socket.cc:826 -> 3
 2: 
 2: nid005577:17425:17987 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
 2: nid005577:17425:118767 [3] NCCL INFO misc/socket.cc:775 -> 3
 2: 
 2: nid005577:17425:17987 [3] proxy.cc:1521 NCCL WARN [Proxy Service 11] Failed to execute operation Close from rank 11, retcode 3
12: nid005594:53087:154892 [2] NCCL INFO comm 0xaaab36e31f10 rank 50 nranks 128 cudaDev 2 busId 2901000 - Abort COMPLETE
 4: nid005581:264523:72356 [0] NCCL INFO comm 0x40068964fe00 rank 16 nranks 128 cudaDev 0 busId 901000 - Abort COMPLETE
 4: nid005581:264523:72359 [0] NCCL INFO misc/socket.cc:47 -> 3
 4: nid005581:264523:72359 [0] NCCL INFO misc/socket.cc:550 -> 3
 4: nid005581:264523:72359 [0] NCCL INFO misc/socket.cc:573 -> 3
 4: nid005581:264523:72359 [0] NCCL INFO misc/socket.cc:621 -> 3
 4: nid005581:264523:265075 [0] NCCL INFO misc/socket.cc:47 -> 3
 4: nid005581:264523:265075 [0] NCCL INFO misc/socket.cc:752 -> 3
 4: nid005581:264523:265075 [0] NCCL INFO misc/socket.cc:428 -> 3
 4: nid005581:264523:265075 [0] NCCL INFO misc/socket.cc:564 -> 3
 4: nid005581:264523:265075 [0] NCCL INFO misc/socket.cc:668 -> 3
 4: 
 4: nid005581:264523:265075 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 4: nid005581:264523:72359 [0] NCCL INFO misc/socket.cc:47 -> 3
 4: nid005581:264523:72359 [0] NCCL INFO misc/socket.cc:58 -> 3
 4: nid005581:264523:72359 [0] NCCL INFO misc/socket.cc:775 -> 3
 4: nid005581:264523:265075 [0] NCCL INFO misc/socket.cc:826 -> 3
 4: 
 4: nid005581:264523:265075 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
 4: 
 4: nid005581:264523:265075 [0] proxy.cc:1521 NCCL WARN [Proxy Service 16] Failed to execute operation Close from rank 16, retcode 3
30: nid005936:49909:151425 [1] NCCL INFO comm 0x4006b964fdc0 rank 121 nranks 128 cudaDev 1 busId 1901000 - Abort COMPLETE
30: nid005936:49909:151427 [1] NCCL INFO misc/socket.cc:47 -> 3
30: nid005936:49909:151427 [1] NCCL INFO misc/socket.cc:550 -> 3
30: nid005936:49909:151427 [1] NCCL INFO misc/socket.cc:573 -> 3
30: nid005936:49909:151427 [1] NCCL INFO misc/socket.cc:621 -> 3
30: nid005936:49909:50473 [1] NCCL INFO misc/socket.cc:47 -> 3
30: nid005936:49909:50473 [1] NCCL INFO misc/socket.cc:752 -> 3
30: nid005936:49909:50473 [1] NCCL INFO misc/socket.cc:428 -> 3
30: nid005936:49909:50473 [1] NCCL INFO misc/socket.cc:564 -> 3
30: nid005936:49909:50473 [1] NCCL INFO misc/socket.cc:668 -> 3
30: 
30: nid005936:49909:50473 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
30: nid005936:49909:151427 [1] NCCL INFO misc/socket.cc:47 -> 3
30: nid005936:49909:151427 [1] NCCL INFO misc/socket.cc:58 -> 3
30: nid005936:49909:151427 [1] NCCL INFO misc/socket.cc:775 -> 3
30: nid005936:49909:50473 [1] NCCL INFO misc/socket.cc:826 -> 3
30: 
30: nid005936:49909:50473 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
30: 
30: nid005936:49909:50473 [1] proxy.cc:1521 NCCL WARN [Proxy Service 121] Failed to execute operation Close from rank 121, retcode 3
 3: nid005580:71819:174883 [0] NCCL INFO comm 0x40067564e840 rank 12 nranks 128 cudaDev 0 busId 901000 - Abort COMPLETE
 3: nid005580:71819:174886 [0] NCCL INFO misc/socket.cc:47 -> 3
 3: nid005580:71819:174886 [0] NCCL INFO misc/socket.cc:550 -> 3
 3: nid005580:71819:174886 [0] NCCL INFO misc/socket.cc:573 -> 3
 3: nid005580:71819:174886 [0] NCCL INFO misc/socket.cc:621 -> 3
 3: nid005580:71819:72364 [0] NCCL INFO misc/socket.cc:47 -> 3
 3: nid005580:71819:72364 [0] NCCL INFO misc/socket.cc:752 -> 3
 3: nid005580:71819:72364 [0] NCCL INFO misc/socket.cc:428 -> 3
 3: nid005580:71819:72364 [0] NCCL INFO misc/socket.cc:564 -> 3
 3: nid005580:71819:72364 [0] NCCL INFO misc/socket.cc:668 -> 3
 3: 
 3: nid005580:71819:72364 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 3: nid005580:71819:174886 [0] NCCL INFO misc/socket.cc:47 -> 3
 3: nid005580:71819:174886 [0] NCCL INFO misc/socket.cc:58 -> 3
 3: nid005580:71819:174886 [0] NCCL INFO misc/socket.cc:775 -> 3
 3: nid005580:71819:72364 [0] NCCL INFO misc/socket.cc:826 -> 3
 3: 
 3: nid005580:71819:72364 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
 3: 
 3: nid005580:71819:72364 [0] proxy.cc:1521 NCCL WARN [Proxy Service 12] Failed to execute operation Close from rank 12, retcode 3
 7: nid005585:122005:225045 [0] NCCL INFO comm 0x40067964fe00 rank 28 nranks 128 cudaDev 0 busId 901000 - Abort COMPLETE
 7: nid005585:122005:225048 [0] NCCL INFO misc/socket.cc:47 -> 3
 7: nid005585:122005:225048 [0] NCCL INFO misc/socket.cc:550 -> 3
 7: nid005585:122005:225048 [0] NCCL INFO misc/socket.cc:573 -> 3
 7: nid005585:122005:225048 [0] NCCL INFO misc/socket.cc:621 -> 3
 7: nid005585:122005:122554 [0] NCCL INFO misc/socket.cc:47 -> 3
 7: nid005585:122005:122554 [0] NCCL INFO misc/socket.cc:752 -> 3
 7: nid005585:122005:122554 [0] NCCL INFO misc/socket.cc:428 -> 3
 7: nid005585:122005:122554 [0] NCCL INFO misc/socket.cc:564 -> 3
 7: nid005585:122005:122554 [0] NCCL INFO misc/socket.cc:668 -> 3
 7: 
 7: nid005585:122005:122554 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 7: nid005585:122005:225048 [0] NCCL INFO misc/socket.cc:47 -> 3
 7: nid005585:122005:225048 [0] NCCL INFO misc/socket.cc:58 -> 3
 7: nid005585:122005:225048 [0] NCCL INFO misc/socket.cc:775 -> 3
 7: nid005585:122005:122554 [0] NCCL INFO misc/socket.cc:826 -> 3
 7: 
 7: nid005585:122005:122554 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
 7: 
 7: nid005585:122005:122554 [0] proxy.cc:1521 NCCL WARN [Proxy Service 28] Failed to execute operation Close from rank 28, retcode 3
 6: nid005584:28288:128093 [3] NCCL INFO comm 0x400698a880b0 rank 27 nranks 128 cudaDev 3 busId 3901000 - Abort COMPLETE
 6: nid005584:28288:128096 [3] NCCL INFO misc/socket.cc:47 -> 3
 6: nid005584:28288:128096 [3] NCCL INFO misc/socket.cc:550 -> 3
 6: nid005584:28288:128096 [3] NCCL INFO misc/socket.cc:573 -> 3
 6: nid005584:28288:128096 [3] NCCL INFO misc/socket.cc:621 -> 3
 6: nid005584:28288:28825 [3] NCCL INFO misc/socket.cc:47 -> 3
 6: nid005584:28288:28825 [3] NCCL INFO misc/socket.cc:752 -> 3
 6: nid005584:28288:28825 [3] NCCL INFO misc/socket.cc:428 -> 3
 6: nid005584:28288:28825 [3] NCCL INFO misc/socket.cc:564 -> 3
 6: nid005584:28288:28825 [3] NCCL INFO misc/socket.cc:668 -> 3
 6: 
 6: nid005584:28288:28825 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 6: nid005584:28288:128096 [3] NCCL INFO misc/socket.cc:47 -> 3
 6: nid005584:28288:128096 [3] NCCL INFO misc/socket.cc:58 -> 3
 6: nid005584:28288:128096 [3] NCCL INFO misc/socket.cc:775 -> 3
 6: nid005584:28288:28825 [3] NCCL INFO misc/socket.cc:826 -> 3
 6: 
 6: nid005584:28288:28825 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
 6: 
 6: nid005584:28288:28825 [3] proxy.cc:1521 NCCL WARN [Proxy Service 27] Failed to execute operation Close from rank 27, retcode 3
26: nid005920:67126:168064 [3] NCCL INFO comm 0x40067964fd80 rank 107 nranks 128 cudaDev 3 busId 3901000 - Abort COMPLETE
26: nid005920:67126:168067 [3] NCCL INFO misc/socket.cc:47 -> 3
26: nid005920:67126:168067 [3] NCCL INFO misc/socket.cc:550 -> 3
26: nid005920:67126:168067 [3] NCCL INFO misc/socket.cc:573 -> 3
26: nid005920:67126:168067 [3] NCCL INFO misc/socket.cc:621 -> 3
26: nid005920:67126:67686 [3] NCCL INFO misc/socket.cc:47 -> 3
26: nid005920:67126:67686 [3] NCCL INFO misc/socket.cc:752 -> 3
26: nid005920:67126:67686 [3] NCCL INFO misc/socket.cc:428 -> 3
26: nid005920:67126:67686 [3] NCCL INFO misc/socket.cc:564 -> 3
26: nid005920:67126:67686 [3] NCCL INFO misc/socket.cc:668 -> 3
26: 
26: nid005920:67126:67686 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
26: nid005920:67126:168067 [3] NCCL INFO misc/socket.cc:47 -> 3
26: nid005920:67126:168067 [3] NCCL INFO misc/socket.cc:58 -> 3
26: nid005920:67126:67686 [3] NCCL INFO misc/socket.cc:826 -> 3
26: 
26: nid005920:67126:67686 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
26: 
26: nid005920:67126:67686 [3] proxy.cc:1521 NCCL WARN [Proxy Service 107] Failed to execute operation Close from rank 107, retcode 3
26: nid005920:67126:168067 [3] NCCL INFO misc/socket.cc:775 -> 3
 4: nid005581:264524:72358 [1] NCCL INFO comm 0x4006aca88070 rank 17 nranks 128 cudaDev 1 busId 1901000 - Abort COMPLETE
 4: nid005581:264524:72360 [1] NCCL INFO misc/socket.cc:47 -> 3
 4: nid005581:264524:72360 [1] NCCL INFO misc/socket.cc:550 -> 3
 4: nid005581:264524:72360 [1] NCCL INFO misc/socket.cc:573 -> 3
 4: nid005581:264524:72360 [1] NCCL INFO misc/socket.cc:621 -> 3
 4: nid005581:264524:265073 [1] NCCL INFO misc/socket.cc:47 -> 3
 4: nid005581:264524:265073 [1] NCCL INFO misc/socket.cc:752 -> 3
 4: nid005581:264524:265073 [1] NCCL INFO misc/socket.cc:428 -> 3
 4: nid005581:264524:265073 [1] NCCL INFO misc/socket.cc:564 -> 3
 4: nid005581:264524:265073 [1] NCCL INFO misc/socket.cc:668 -> 3
 4: 
 4: nid005581:264524:265073 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 4: nid005581:264524:72360 [1] NCCL INFO misc/socket.cc:47 -> 3
 4: nid005581:264524:72360 [1] NCCL INFO misc/socket.cc:58 -> 3
 4: nid005581:264524:72360 [1] NCCL INFO misc/socket.cc:775 -> 3
 4: nid005581:264524:265073 [1] NCCL INFO misc/socket.cc:826 -> 3
 4: 
 4: nid005581:264524:265073 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
 4: 
 4: nid005581:264524:265073 [1] proxy.cc:1521 NCCL WARN [Proxy Service 17] Failed to execute operation Close from rank 17, retcode 3
 6: nid005584:28287:128094 [2] NCCL INFO comm 0x40068964fb50 rank 26 nranks 128 cudaDev 2 busId 2901000 - Abort COMPLETE
 6: nid005584:28287:128097 [2] NCCL INFO misc/socket.cc:47 -> 3
 6: nid005584:28287:128097 [2] NCCL INFO misc/socket.cc:550 -> 3
 6: nid005584:28287:128097 [2] NCCL INFO misc/socket.cc:573 -> 3
 6: nid005584:28287:128097 [2] NCCL INFO misc/socket.cc:621 -> 3
 6: nid005584:28287:28824 [2] NCCL INFO misc/socket.cc:47 -> 3
 6: nid005584:28287:28824 [2] NCCL INFO misc/socket.cc:752 -> 3
 6: nid005584:28287:28824 [2] NCCL INFO misc/socket.cc:428 -> 3
 6: nid005584:28287:28824 [2] NCCL INFO misc/socket.cc:564 -> 3
 6: nid005584:28287:28824 [2] NCCL INFO misc/socket.cc:668 -> 3
 6: 
 6: nid005584:28287:28824 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 6: nid005584:28287:128097 [2] NCCL INFO misc/socket.cc:47 -> 3
 6: nid005584:28287:128097 [2] NCCL INFO misc/socket.cc:58 -> 3
 6: nid005584:28287:128097 [2] NCCL INFO misc/socket.cc:775 -> 3
 6: nid005584:28287:28824 [2] NCCL INFO misc/socket.cc:826 -> 3
 6: 
 6: nid005584:28287:28824 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
 6: 
 6: nid005584:28287:28824 [2] proxy.cc:1521 NCCL WARN [Proxy Service 26] Failed to execute operation Close from rank 26, retcode 3
26: nid005920:67123:168066 [0] NCCL INFO comm 0xaaab021f2d20 rank 104 nranks 128 cudaDev 0 busId 901000 - Abort COMPLETE
27: nid005922:80741:183173 [0] NCCL INFO comm 0xaaab18560ec0 rank 108 nranks 128 cudaDev 0 busId 901000 - Abort COMPLETE
11: nid005591:191605:294866 [2] NCCL INFO comm 0x4006b56513b0 rank 46 nranks 128 cudaDev 2 busId 2901000 - Abort COMPLETE
11: nid005591:191605:294874 [2] NCCL INFO misc/socket.cc:47 -> 3
11: nid005591:191605:294874 [2] NCCL INFO misc/socket.cc:550 -> 3
11: nid005591:191605:294874 [2] NCCL INFO misc/socket.cc:573 -> 3
11: nid005591:191605:294874 [2] NCCL INFO misc/socket.cc:621 -> 3
11: nid005591:191605:192151 [2] NCCL INFO misc/socket.cc:47 -> 3
11: nid005591:191605:192151 [2] NCCL INFO misc/socket.cc:752 -> 3
11: nid005591:191605:192151 [2] NCCL INFO misc/socket.cc:428 -> 3
11: nid005591:191605:192151 [2] NCCL INFO misc/socket.cc:564 -> 3
11: nid005591:191605:192151 [2] NCCL INFO misc/socket.cc:668 -> 3
11: 
11: nid005591:191605:192151 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
11: nid005591:191605:294874 [2] NCCL INFO misc/socket.cc:47 -> 3
11: nid005591:191605:294874 [2] NCCL INFO misc/socket.cc:58 -> 3
11: nid005591:191605:294874 [2] NCCL INFO misc/socket.cc:775 -> 3
11: nid005591:191605:192151 [2] NCCL INFO misc/socket.cc:826 -> 3
11: 
11: nid005591:191605:192151 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
11: 
11: nid005591:191605:192151 [2] proxy.cc:1521 NCCL WARN [Proxy Service 46] Failed to execute operation Close from rank 46, retcode 3
17: nid005803:180735:283756 [3] NCCL INFO comm 0xaaab10aa06b0 rank 71 nranks 128 cudaDev 3 busId 3901000 - Abort COMPLETE
 0: nid005574:69061:171241 [3] NCCL INFO comm 0xaaaad3e5bbc0 rank 3 nranks 128 cudaDev 3 busId 3901000 - Abort COMPLETE
10: nid005590:110712:213918 [2] NCCL INFO comm 0x40069d64e3d0 rank 42 nranks 128 cudaDev 2 busId 2901000 - Abort COMPLETE
10: nid005590:110712:213920 [2] NCCL INFO misc/socket.cc:47 -> 3
10: nid005590:110712:213920 [2] NCCL INFO misc/socket.cc:550 -> 3
10: nid005590:110712:213920 [2] NCCL INFO misc/socket.cc:573 -> 3
10: nid005590:110712:213920 [2] NCCL INFO misc/socket.cc:621 -> 3
10: nid005590:110712:111248 [2] NCCL INFO misc/socket.cc:47 -> 3
10: nid005590:110712:111248 [2] NCCL INFO misc/socket.cc:752 -> 3
10: nid005590:110712:111248 [2] NCCL INFO misc/socket.cc:428 -> 3
10: nid005590:110712:111248 [2] NCCL INFO misc/socket.cc:564 -> 3
10: nid005590:110712:111248 [2] NCCL INFO misc/socket.cc:668 -> 3
10: 
10: nid005590:110712:111248 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
10: nid005590:110712:213920 [2] NCCL INFO misc/socket.cc:47 -> 3
10: nid005590:110712:213920 [2] NCCL INFO misc/socket.cc:58 -> 3
10: nid005590:110712:213920 [2] NCCL INFO misc/socket.cc:775 -> 3
10: nid005590:110712:111248 [2] NCCL INFO misc/socket.cc:826 -> 3
10: 
10: nid005590:110712:111248 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
10: 
10: nid005590:110712:111248 [2] proxy.cc:1521 NCCL WARN [Proxy Service 42] Failed to execute operation Close from rank 42, retcode 3
28: nid005929:16030:116164 [0] NCCL INFO comm 0x40066164fe00 rank 112 nranks 128 cudaDev 0 busId 901000 - Abort COMPLETE
28: nid005929:16030:116167 [0] NCCL INFO misc/socket.cc:47 -> 3
28: nid005929:16030:116167 [0] NCCL INFO misc/socket.cc:550 -> 3
28: nid005929:16030:116167 [0] NCCL INFO misc/socket.cc:573 -> 3
28: nid005929:16030:116167 [0] NCCL INFO misc/socket.cc:621 -> 3
28: nid005929:16030:16579 [0] NCCL INFO misc/socket.cc:47 -> 3
28: nid005929:16030:16579 [0] NCCL INFO misc/socket.cc:752 -> 3
28: nid005929:16030:16579 [0] NCCL INFO misc/socket.cc:428 -> 3
28: nid005929:16030:16579 [0] NCCL INFO misc/socket.cc:564 -> 3
28: nid005929:16030:16579 [0] NCCL INFO misc/socket.cc:668 -> 3
28: 
28: nid005929:16030:16579 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
28: nid005929:16030:116167 [0] NCCL INFO misc/socket.cc:47 -> 3
28: nid005929:16030:116167 [0] NCCL INFO misc/socket.cc:58 -> 3
28: nid005929:16030:116167 [0] NCCL INFO misc/socket.cc:775 -> 3
28: nid005929:16030:16579 [0] NCCL INFO misc/socket.cc:826 -> 3
28: 
28: nid005929:16030:16579 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
28: 
28: nid005929:16030:16579 [0] proxy.cc:1521 NCCL WARN [Proxy Service 112] Failed to execute operation Close from rank 112, retcode 3
24: nid005918:92506:194032 [2] NCCL INFO comm 0x40067d6513b0 rank 98 nranks 128 cudaDev 2 busId 2901000 - Abort COMPLETE
24: nid005918:92506:194034 [2] NCCL INFO misc/socket.cc:47 -> 3
24: nid005918:92506:194034 [2] NCCL INFO misc/socket.cc:550 -> 3
24: nid005918:92506:194034 [2] NCCL INFO misc/socket.cc:573 -> 3
24: nid005918:92506:194034 [2] NCCL INFO misc/socket.cc:621 -> 3
24: nid005918:92506:93086 [2] NCCL INFO misc/socket.cc:47 -> 3
24: nid005918:92506:93086 [2] NCCL INFO misc/socket.cc:752 -> 3
24: nid005918:92506:93086 [2] NCCL INFO misc/socket.cc:428 -> 3
24: nid005918:92506:93086 [2] NCCL INFO misc/socket.cc:564 -> 3
24: nid005918:92506:93086 [2] NCCL INFO misc/socket.cc:668 -> 3
24: 
24: nid005918:92506:93086 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
24: nid005918:92506:194034 [2] NCCL INFO misc/socket.cc:47 -> 3
24: nid005918:92506:194034 [2] NCCL INFO misc/socket.cc:58 -> 3
24: nid005918:92506:194034 [2] NCCL INFO misc/socket.cc:775 -> 3
24: nid005918:92506:93086 [2] NCCL INFO misc/socket.cc:826 -> 3
24: 
24: nid005918:92506:93086 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
24: 
24: nid005918:92506:93086 [2] proxy.cc:1521 NCCL WARN [Proxy Service 98] Failed to execute operation Close from rank 98, retcode 3
26: nid005920:67124:168062 [1] NCCL INFO comm 0x400689651260 rank 105 nranks 128 cudaDev 1 busId 1901000 - Abort COMPLETE
26: nid005920:67124:168069 [1] NCCL INFO misc/socket.cc:47 -> 3
26: nid005920:67124:168069 [1] NCCL INFO misc/socket.cc:550 -> 3
26: nid005920:67124:168069 [1] NCCL INFO misc/socket.cc:573 -> 3
26: nid005920:67124:168069 [1] NCCL INFO misc/socket.cc:621 -> 3
25: nid005919:107462:211236 [0] NCCL INFO comm 0x40067964fe00 rank 100 nranks 128 cudaDev 0 busId 901000 - Abort COMPLETE
26: nid005920:67124:67687 [1] NCCL INFO misc/socket.cc:47 -> 3
26: nid005920:67124:67687 [1] NCCL INFO misc/socket.cc:752 -> 3
26: nid005920:67124:67687 [1] NCCL INFO misc/socket.cc:428 -> 3
26: nid005920:67124:67687 [1] NCCL INFO misc/socket.cc:564 -> 3
26: nid005920:67124:67687 [1] NCCL INFO misc/socket.cc:668 -> 3
26: 
26: nid005920:67124:67687 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
26: nid005920:67124:168069 [1] NCCL INFO misc/socket.cc:47 -> 3
26: nid005920:67124:168069 [1] NCCL INFO misc/socket.cc:58 -> 3
26: nid005920:67124:168069 [1] NCCL INFO misc/socket.cc:775 -> 3
26: nid005920:67124:67687 [1] NCCL INFO misc/socket.cc:826 -> 3
26: 
26: nid005920:67124:67687 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
26: 
26: nid005920:67124:67687 [1] proxy.cc:1521 NCCL WARN [Proxy Service 105] Failed to execute operation Close from rank 105, retcode 3
25: nid005919:107462:211241 [0] NCCL INFO misc/socket.cc:47 -> 3
25: nid005919:107462:211241 [0] NCCL INFO misc/socket.cc:550 -> 3
25: nid005919:107462:211241 [0] NCCL INFO misc/socket.cc:573 -> 3
25: nid005919:107462:211241 [0] NCCL INFO misc/socket.cc:621 -> 3
25: nid005919:107462:108036 [0] NCCL INFO misc/socket.cc:47 -> 3
25: nid005919:107462:108036 [0] NCCL INFO misc/socket.cc:752 -> 3
25: nid005919:107462:108036 [0] NCCL INFO misc/socket.cc:428 -> 3
25: nid005919:107462:108036 [0] NCCL INFO misc/socket.cc:564 -> 3
25: nid005919:107462:108036 [0] NCCL INFO misc/socket.cc:668 -> 3
25: 
25: nid005919:107462:108036 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
25: nid005919:107462:211241 [0] NCCL INFO misc/socket.cc:47 -> 3
25: nid005919:107462:211241 [0] NCCL INFO misc/socket.cc:58 -> 3
25: nid005919:107462:211241 [0] NCCL INFO misc/socket.cc:775 -> 3
25: nid005919:107462:108036 [0] NCCL INFO misc/socket.cc:826 -> 3
25: 
25: nid005919:107462:108036 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
25: 
25: nid005919:107462:108036 [0] proxy.cc:1521 NCCL WARN [Proxy Service 100] Failed to execute operation Close from rank 100, retcode 3
 7: nid005585:122006:225044 [1] NCCL INFO comm 0x4006716513b0 rank 29 nranks 128 cudaDev 1 busId 1901000 - Abort COMPLETE
 7: nid005585:122006:225049 [1] NCCL INFO misc/socket.cc:47 -> 3
 7: nid005585:122006:225049 [1] NCCL INFO misc/socket.cc:550 -> 3
 7: nid005585:122006:225049 [1] NCCL INFO misc/socket.cc:573 -> 3
 7: nid005585:122006:225049 [1] NCCL INFO misc/socket.cc:621 -> 3
 7: nid005585:122006:122549 [1] NCCL INFO misc/socket.cc:47 -> 3
 7: nid005585:122006:122549 [1] NCCL INFO misc/socket.cc:752 -> 3
 7: nid005585:122006:122549 [1] NCCL INFO misc/socket.cc:428 -> 3
 7: nid005585:122006:122549 [1] NCCL INFO misc/socket.cc:564 -> 3
 7: nid005585:122006:122549 [1] NCCL INFO misc/socket.cc:668 -> 3
 7: 
 7: nid005585:122006:122549 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 7: nid005585:122006:225049 [1] NCCL INFO misc/socket.cc:47 -> 3
 7: nid005585:122006:225049 [1] NCCL INFO misc/socket.cc:58 -> 3
 7: nid005585:122006:225049 [1] NCCL INFO misc/socket.cc:775 -> 3
 7: nid005585:122006:122549 [1] NCCL INFO misc/socket.cc:826 -> 3
 7: 
 7: nid005585:122006:122549 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
 7: 
 7: nid005585:122006:122549 [1] proxy.cc:1521 NCCL WARN [Proxy Service 29] Failed to execute operation Close from rank 29, retcode 3
31: nid005937:256589:65763 [0] NCCL INFO comm 0x400699652800 rank 124 nranks 128 cudaDev 0 busId 901000 - Abort COMPLETE
31: nid005937:256589:65766 [0] NCCL INFO misc/socket.cc:47 -> 3
31: nid005937:256589:65766 [0] NCCL INFO misc/socket.cc:550 -> 3
31: nid005937:256589:65766 [0] NCCL INFO misc/socket.cc:573 -> 3
31: nid005937:256589:65766 [0] NCCL INFO misc/socket.cc:621 -> 3
31: nid005937:256589:257154 [0] NCCL INFO misc/socket.cc:47 -> 3
31: nid005937:256589:257154 [0] NCCL INFO misc/socket.cc:752 -> 3
31: nid005937:256589:257154 [0] NCCL INFO misc/socket.cc:428 -> 3
31: nid005937:256589:257154 [0] NCCL INFO misc/socket.cc:564 -> 3
31: nid005937:256589:257154 [0] NCCL INFO misc/socket.cc:668 -> 3
31: 
31: nid005937:256589:257154 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
31: nid005937:256589:65766 [0] NCCL INFO misc/socket.cc:47 -> 3
31: nid005937:256589:65766 [0] NCCL INFO misc/socket.cc:58 -> 3
31: nid005937:256589:65766 [0] NCCL INFO misc/socket.cc:775 -> 3
31: nid005937:256589:257154 [0] NCCL INFO misc/socket.cc:826 -> 3
31: 
31: nid005937:256589:257154 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
31: 
31: nid005937:256589:257154 [0] proxy.cc:1521 NCCL WARN [Proxy Service 124] Failed to execute operation Close from rank 124, retcode 3
 7: nid005585:122007:225047 [2] NCCL INFO comm 0x4006b564fe00 rank 30 nranks 128 cudaDev 2 busId 2901000 - Abort COMPLETE
 8: nid005586:68928:170711 [2] NCCL INFO comm 0x4006a964f980 rank 34 nranks 128 cudaDev 2 busId 2901000 - Abort COMPLETE
 9: nid005588:35935:138381 [0] NCCL INFO comm 0x40065964fd80 rank 36 nranks 128 cudaDev 0 busId 901000 - Abort COMPLETE
 7: nid005585:122007:225050 [2] NCCL INFO misc/socket.cc:47 -> 3
 7: nid005585:122007:225050 [2] NCCL INFO misc/socket.cc:550 -> 3
 7: nid005585:122007:225050 [2] NCCL INFO misc/socket.cc:573 -> 3
 7: nid005585:122007:225050 [2] NCCL INFO misc/socket.cc:621 -> 3
 7: nid005585:122007:122550 [2] NCCL INFO misc/socket.cc:47 -> 3
 7: nid005585:122007:122550 [2] NCCL INFO misc/socket.cc:752 -> 3
 7: nid005585:122007:122550 [2] NCCL INFO misc/socket.cc:428 -> 3
 7: nid005585:122007:122550 [2] NCCL INFO misc/socket.cc:564 -> 3
 7: nid005585:122007:122550 [2] NCCL INFO misc/socket.cc:668 -> 3
 7: 
 7: nid005585:122007:122550 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 7: nid005585:122007:225050 [2] NCCL INFO misc/socket.cc:47 -> 3
 7: nid005585:122007:225050 [2] NCCL INFO misc/socket.cc:58 -> 3
 7: nid005585:122007:225050 [2] NCCL INFO misc/socket.cc:775 -> 3
 7: nid005585:122007:122550 [2] NCCL INFO misc/socket.cc:826 -> 3
 7: 
 7: nid005585:122007:122550 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
 7: 
 7: nid005585:122007:122550 [2] proxy.cc:1521 NCCL WARN [Proxy Service 30] Failed to execute operation Close from rank 30, retcode 3
 8: nid005586:68928:170713 [2] NCCL INFO misc/socket.cc:47 -> 3
 8: nid005586:68928:170713 [2] NCCL INFO misc/socket.cc:550 -> 3
 8: nid005586:68928:170713 [2] NCCL INFO misc/socket.cc:573 -> 3
 8: nid005586:68928:170713 [2] NCCL INFO misc/socket.cc:621 -> 3
 9: nid005588:35935:138386 [0] NCCL INFO misc/socket.cc:47 -> 3
 9: nid005588:35935:138386 [0] NCCL INFO misc/socket.cc:550 -> 3
 9: nid005588:35935:138386 [0] NCCL INFO misc/socket.cc:573 -> 3
 9: nid005588:35935:138386 [0] NCCL INFO misc/socket.cc:621 -> 3
 8: nid005586:68928:69496 [2] NCCL INFO misc/socket.cc:47 -> 3
 8: nid005586:68928:69496 [2] NCCL INFO misc/socket.cc:752 -> 3
 8: nid005586:68928:69496 [2] NCCL INFO misc/socket.cc:428 -> 3
 8: nid005586:68928:69496 [2] NCCL INFO misc/socket.cc:564 -> 3
 8: nid005586:68928:69496 [2] NCCL INFO misc/socket.cc:668 -> 3
 9: nid005588:35935:36504 [0] NCCL INFO misc/socket.cc:47 -> 3
 9: nid005588:35935:36504 [0] NCCL INFO misc/socket.cc:752 -> 3
 9: nid005588:35935:36504 [0] NCCL INFO misc/socket.cc:428 -> 3
 9: nid005588:35935:36504 [0] NCCL INFO misc/socket.cc:564 -> 3
 8: 
 8: nid005586:68928:69496 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 9: nid005588:35935:36504 [0] NCCL INFO misc/socket.cc:668 -> 3
 8: nid005586:68928:170713 [2] NCCL INFO misc/socket.cc:47 -> 3
 8: nid005586:68928:170713 [2] NCCL INFO misc/socket.cc:58 -> 3
 8: nid005586:68928:170713 [2] NCCL INFO misc/socket.cc:775 -> 3
 9: 
 9: nid005588:35935:36504 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 8: nid005586:68928:69496 [2] NCCL INFO misc/socket.cc:826 -> 3
 9: nid005588:35935:138386 [0] NCCL INFO misc/socket.cc:47 -> 3
 9: nid005588:35935:138386 [0] NCCL INFO misc/socket.cc:58 -> 3
 9: nid005588:35935:138386 [0] NCCL INFO misc/socket.cc:775 -> 3
 9: nid005588:35935:36504 [0] NCCL INFO misc/socket.cc:826 -> 3
 8: 
 8: nid005586:68928:69496 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
 8: 
 8: nid005586:68928:69496 [2] proxy.cc:1521 NCCL WARN [Proxy Service 34] Failed to execute operation Close from rank 34, retcode 3
 9: 
 9: nid005588:35935:36504 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
 9: 
 9: nid005588:35935:36504 [0] proxy.cc:1521 NCCL WARN [Proxy Service 36] Failed to execute operation Close from rank 36, retcode 3
27: nid005922:80743:183172 [2] NCCL INFO comm 0x4006b96513a0 rank 110 nranks 128 cudaDev 2 busId 2901000 - Abort COMPLETE
27: nid005922:80743:183179 [2] NCCL INFO misc/socket.cc:47 -> 3
27: nid005922:80743:183179 [2] NCCL INFO misc/socket.cc:550 -> 3
27: nid005922:80743:183179 [2] NCCL INFO misc/socket.cc:573 -> 3
27: nid005922:80743:183179 [2] NCCL INFO misc/socket.cc:621 -> 3
27: nid005922:80743:81291 [2] NCCL INFO misc/socket.cc:47 -> 3
27: nid005922:80743:81291 [2] NCCL INFO misc/socket.cc:752 -> 3
27: nid005922:80743:81291 [2] NCCL INFO misc/socket.cc:428 -> 3
27: nid005922:80743:81291 [2] NCCL INFO misc/socket.cc:564 -> 3
27: nid005922:80743:81291 [2] NCCL INFO misc/socket.cc:668 -> 3
27: 
27: nid005922:80743:81291 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
27: nid005922:80743:183179 [2] NCCL INFO misc/socket.cc:47 -> 3
27: nid005922:80743:183179 [2] NCCL INFO misc/socket.cc:58 -> 3
27: nid005922:80743:183179 [2] NCCL INFO misc/socket.cc:775 -> 3
27: nid005922:80743:81291 [2] NCCL INFO misc/socket.cc:826 -> 3
27: 
27: nid005922:80743:81291 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
27: 
27: nid005922:80743:81291 [2] proxy.cc:1521 NCCL WARN [Proxy Service 110] Failed to execute operation Close from rank 110, retcode 3
13: nid005595:197884:6867 [1] NCCL INFO comm 0xaaab0cbd2c40 rank 53 nranks 128 cudaDev 1 busId 1901000 - Abort COMPLETE
28: nid005929:16032:116162 [2] NCCL INFO comm 0x40069564e840 rank 114 nranks 128 cudaDev 2 busId 2901000 - Abort COMPLETE
28: nid005929:16032:116168 [2] NCCL INFO misc/socket.cc:47 -> 3
28: nid005929:16032:116168 [2] NCCL INFO misc/socket.cc:550 -> 3
28: nid005929:16032:116168 [2] NCCL INFO misc/socket.cc:573 -> 3
28: nid005929:16032:116168 [2] NCCL INFO misc/socket.cc:621 -> 3
28: nid005929:16032:16575 [2] NCCL INFO misc/socket.cc:47 -> 3
28: nid005929:16032:16575 [2] NCCL INFO misc/socket.cc:752 -> 3
28: nid005929:16032:16575 [2] NCCL INFO misc/socket.cc:428 -> 3
28: nid005929:16032:16575 [2] NCCL INFO misc/socket.cc:564 -> 3
28: nid005929:16032:16575 [2] NCCL INFO misc/socket.cc:668 -> 3
28: 
28: nid005929:16032:16575 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
28: nid005929:16032:116168 [2] NCCL INFO misc/socket.cc:47 -> 3
28: nid005929:16032:116168 [2] NCCL INFO misc/socket.cc:58 -> 3
28: nid005929:16032:116168 [2] NCCL INFO misc/socket.cc:775 -> 3
28: nid005929:16032:16575 [2] NCCL INFO misc/socket.cc:826 -> 3
28: 
28: nid005929:16032:16575 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
28: 
28: nid005929:16032:16575 [2] proxy.cc:1521 NCCL WARN [Proxy Service 114] Failed to execute operation Close from rank 114, retcode 3
29: nid005932:167681:270272 [1] NCCL INFO comm 0xaaaac3b4db00 rank 117 nranks 128 cudaDev 1 busId 1901000 - Abort COMPLETE
19: nid005912:12437:113118 [2] NCCL INFO comm 0x4006a964fe00 rank 78 nranks 128 cudaDev 2 busId 2901000 - Abort COMPLETE
19: nid005912:12437:113123 [2] NCCL INFO misc/socket.cc:47 -> 3
19: nid005912:12437:113123 [2] NCCL INFO misc/socket.cc:550 -> 3
19: nid005912:12437:113123 [2] NCCL INFO misc/socket.cc:573 -> 3
19: nid005912:12437:113123 [2] NCCL INFO misc/socket.cc:621 -> 3
19: nid005912:12437:12999 [2] NCCL INFO misc/socket.cc:47 -> 3
19: nid005912:12437:12999 [2] NCCL INFO misc/socket.cc:752 -> 3
19: nid005912:12437:12999 [2] NCCL INFO misc/socket.cc:428 -> 3
19: nid005912:12437:12999 [2] NCCL INFO misc/socket.cc:564 -> 3
19: nid005912:12437:12999 [2] NCCL INFO misc/socket.cc:668 -> 3
19: 
19: nid005912:12437:12999 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
19: nid005912:12437:113123 [2] NCCL INFO misc/socket.cc:47 -> 3
19: nid005912:12437:113123 [2] NCCL INFO misc/socket.cc:58 -> 3
19: nid005912:12437:113123 [2] NCCL INFO misc/socket.cc:775 -> 3
19: nid005912:12437:12999 [2] NCCL INFO misc/socket.cc:826 -> 3
19: 
19: nid005912:12437:12999 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
19: 
19: nid005912:12437:12999 [2] proxy.cc:1521 NCCL WARN [Proxy Service 78] Failed to execute operation Close from rank 78, retcode 3
25: nid005919:107465:211240 [3] NCCL INFO comm 0xaaaad4543ad0 rank 103 nranks 128 cudaDev 3 busId 3901000 - Abort COMPLETE
16: nid005802:6298:108573 [1] NCCL INFO comm 0x40069964e900 rank 65 nranks 128 cudaDev 1 busId 1901000 - Abort COMPLETE
 1: nid005576:147557:250809 [0] NCCL INFO comm 0x40066d64e900 rank 4 nranks 128 cudaDev 0 busId 901000 - Abort COMPLETE
16: nid005802:6298:108582 [1] NCCL INFO misc/socket.cc:47 -> 3
16: nid005802:6298:108582 [1] NCCL INFO misc/socket.cc:550 -> 3
16: nid005802:6298:108582 [1] NCCL INFO misc/socket.cc:573 -> 3
16: nid005802:6298:108582 [1] NCCL INFO misc/socket.cc:621 -> 3
 1: nid005576:147557:250812 [0] NCCL INFO misc/socket.cc:47 -> 3
 1: nid005576:147557:250812 [0] NCCL INFO misc/socket.cc:550 -> 3
 1: nid005576:147557:250812 [0] NCCL INFO misc/socket.cc:573 -> 3
 1: nid005576:147557:250812 [0] NCCL INFO misc/socket.cc:621 -> 3
 1: nid005576:147557:148110 [0] NCCL INFO misc/socket.cc:47 -> 3
 1: nid005576:147557:148110 [0] NCCL INFO misc/socket.cc:752 -> 3
 1: nid005576:147557:148110 [0] NCCL INFO misc/socket.cc:428 -> 3
 1: nid005576:147557:148110 [0] NCCL INFO misc/socket.cc:564 -> 3
 1: nid005576:147557:148110 [0] NCCL INFO misc/socket.cc:668 -> 3
16: nid005802:6298:6907 [1] NCCL INFO misc/socket.cc:47 -> 3
16: nid005802:6298:6907 [1] NCCL INFO misc/socket.cc:752 -> 3
 1: 
 1: nid005576:147557:148110 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
16: nid005802:6298:6907 [1] NCCL INFO misc/socket.cc:428 -> 3
16: nid005802:6298:6907 [1] NCCL INFO misc/socket.cc:564 -> 3
16: nid005802:6298:6907 [1] NCCL INFO misc/socket.cc:668 -> 3
 1: nid005576:147557:250812 [0] NCCL INFO misc/socket.cc:47 -> 3
 1: nid005576:147557:148110 [0] NCCL INFO misc/socket.cc:826 -> 3
 1: 
 1: nid005576:147557:148110 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
16: 
16: nid005802:6298:6907 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 1: 
 1: nid005576:147557:148110 [0] proxy.cc:1521 NCCL WARN [Proxy Service 4] Failed to execute operation Close from rank 4, retcode 3
16: nid005802:6298:108582 [1] NCCL INFO misc/socket.cc:47 -> 3
16: nid005802:6298:108582 [1] NCCL INFO misc/socket.cc:58 -> 3
16: nid005802:6298:6907 [1] NCCL INFO misc/socket.cc:826 -> 3
 1: nid005576:147557:250812 [0] NCCL INFO misc/socket.cc:58 -> 3
 1: nid005576:147557:250812 [0] NCCL INFO misc/socket.cc:775 -> 3
16: 
16: nid005802:6298:6907 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
16: 
16: nid005802:6298:6907 [1] proxy.cc:1521 NCCL WARN [Proxy Service 65] Failed to execute operation Close from rank 65, retcode 3
16: nid005802:6298:108582 [1] NCCL INFO misc/socket.cc:775 -> 3
18: nid005911:38865:140346 [1] NCCL INFO comm 0x40068564e900 rank 73 nranks 128 cudaDev 1 busId 1901000 - Abort COMPLETE
18: nid005911:38865:140348 [1] NCCL INFO misc/socket.cc:47 -> 3
18: nid005911:38865:140348 [1] NCCL INFO misc/socket.cc:550 -> 3
18: nid005911:38865:140348 [1] NCCL INFO misc/socket.cc:573 -> 3
18: nid005911:38865:140348 [1] NCCL INFO misc/socket.cc:621 -> 3
18: nid005911:38865:39428 [1] NCCL INFO misc/socket.cc:47 -> 3
18: nid005911:38865:39428 [1] NCCL INFO misc/socket.cc:752 -> 3
18: nid005911:38865:39428 [1] NCCL INFO misc/socket.cc:428 -> 3
18: nid005911:38865:39428 [1] NCCL INFO misc/socket.cc:564 -> 3
18: nid005911:38865:39428 [1] NCCL INFO misc/socket.cc:668 -> 3
18: 
18: nid005911:38865:39428 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
18: nid005911:38865:140348 [1] NCCL INFO misc/socket.cc:47 -> 3
18: nid005911:38865:140348 [1] NCCL INFO misc/socket.cc:58 -> 3
18: nid005911:38865:140348 [1] NCCL INFO misc/socket.cc:775 -> 3
18: nid005911:38865:39428 [1] NCCL INFO misc/socket.cc:826 -> 3
18: 
18: nid005911:38865:39428 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
18: 
18: nid005911:38865:39428 [1] proxy.cc:1521 NCCL WARN [Proxy Service 73] Failed to execute operation Close from rank 73, retcode 3
 1: nid005576:147560:250810 [3] NCCL INFO comm 0xaaaaea94c330 rank 7 nranks 128 cudaDev 3 busId 3901000 - Abort COMPLETE
29: nid005932:167683:270273 [3] NCCL INFO comm 0xaaab0adabbc0 rank 119 nranks 128 cudaDev 3 busId 3901000 - Abort COMPLETE
15: nid005601:210679:18851 [3] NCCL INFO comm 0x4006ad64fdf0 rank 63 nranks 128 cudaDev 3 busId 3901000 - Abort COMPLETE
15: nid005601:210679:18855 [3] NCCL INFO misc/socket.cc:47 -> 3
15: nid005601:210679:18855 [3] NCCL INFO misc/socket.cc:550 -> 3
15: nid005601:210679:18855 [3] NCCL INFO misc/socket.cc:573 -> 3
15: nid005601:210679:18855 [3] NCCL INFO misc/socket.cc:621 -> 3
15: nid005601:210679:211239 [3] NCCL INFO misc/socket.cc:47 -> 3
15: nid005601:210679:211239 [3] NCCL INFO misc/socket.cc:752 -> 3
15: nid005601:210679:211239 [3] NCCL INFO misc/socket.cc:428 -> 3
15: nid005601:210679:211239 [3] NCCL INFO misc/socket.cc:564 -> 3
15: nid005601:210679:211239 [3] NCCL INFO misc/socket.cc:668 -> 3
15: 
15: nid005601:210679:211239 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
15: nid005601:210679:18855 [3] NCCL INFO misc/socket.cc:47 -> 3
15: nid005601:210679:18855 [3] NCCL INFO misc/socket.cc:58 -> 3
15: nid005601:210679:18855 [3] NCCL INFO misc/socket.cc:775 -> 3
15: nid005601:210679:211239 [3] NCCL INFO misc/socket.cc:826 -> 3
15: 
15: nid005601:210679:211239 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
15: 
15: nid005601:210679:211239 [3] proxy.cc:1521 NCCL WARN [Proxy Service 63] Failed to execute operation Close from rank 63, retcode 3
29: nid005932:167682:270276 [2] NCCL INFO comm 0xaaab2bddcec0 rank 118 nranks 128 cudaDev 2 busId 2901000 - Abort COMPLETE
25: nid005919:107463:211238 [1] NCCL INFO comm 0x40067d64fe00 rank 101 nranks 128 cudaDev 1 busId 1901000 - Abort COMPLETE
19: nid005912:12438:113119 [3] NCCL INFO comm 0x40069964fe00 rank 79 nranks 128 cudaDev 3 busId 3901000 - Abort COMPLETE
25: nid005919:107463:211243 [1] NCCL INFO misc/socket.cc:47 -> 3
25: nid005919:107463:211243 [1] NCCL INFO misc/socket.cc:550 -> 3
25: nid005919:107463:211243 [1] NCCL INFO misc/socket.cc:573 -> 3
25: nid005919:107463:211243 [1] NCCL INFO misc/socket.cc:621 -> 3
25: nid005919:107463:108030 [1] NCCL INFO misc/socket.cc:47 -> 3
25: nid005919:107463:108030 [1] NCCL INFO misc/socket.cc:752 -> 3
25: nid005919:107463:108030 [1] NCCL INFO misc/socket.cc:428 -> 3
25: nid005919:107463:108030 [1] NCCL INFO misc/socket.cc:564 -> 3
25: nid005919:107463:108030 [1] NCCL INFO misc/socket.cc:668 -> 3
25: 
25: nid005919:107463:108030 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
25: nid005919:107463:211243 [1] NCCL INFO misc/socket.cc:47 -> 3
25: nid005919:107463:211243 [1] NCCL INFO misc/socket.cc:58 -> 3
25: nid005919:107463:211243 [1] NCCL INFO misc/socket.cc:775 -> 3
25: nid005919:107463:108030 [1] NCCL INFO misc/socket.cc:826 -> 3
25: 
25: nid005919:107463:108030 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
25: 
25: nid005919:107463:108030 [1] proxy.cc:1521 NCCL WARN [Proxy Service 101] Failed to execute operation Close from rank 101, retcode 3
19: nid005912:12438:113124 [3] NCCL INFO misc/socket.cc:47 -> 3
19: nid005912:12438:113124 [3] NCCL INFO misc/socket.cc:550 -> 3
19: nid005912:12438:113124 [3] NCCL INFO misc/socket.cc:573 -> 3
19: nid005912:12438:113124 [3] NCCL INFO misc/socket.cc:621 -> 3
19: nid005912:12438:12998 [3] NCCL INFO misc/socket.cc:47 -> 3
19: nid005912:12438:12998 [3] NCCL INFO misc/socket.cc:752 -> 3
19: nid005912:12438:12998 [3] NCCL INFO misc/socket.cc:428 -> 3
19: nid005912:12438:12998 [3] NCCL INFO misc/socket.cc:564 -> 3
19: nid005912:12438:12998 [3] NCCL INFO misc/socket.cc:668 -> 3
19: 
19: nid005912:12438:12998 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
19: nid005912:12438:113124 [3] NCCL INFO misc/socket.cc:47 -> 3
19: nid005912:12438:113124 [3] NCCL INFO misc/socket.cc:58 -> 3
19: nid005912:12438:113124 [3] NCCL INFO misc/socket.cc:775 -> 3
19: nid005912:12438:12998 [3] NCCL INFO misc/socket.cc:826 -> 3
19: 
19: nid005912:12438:12998 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
19: 
19: nid005912:12438:12998 [3] proxy.cc:1521 NCCL WARN [Proxy Service 79] Failed to execute operation Close from rank 79, retcode 3
10: nid005590:110711:213915 [1] NCCL INFO comm 0x4006896528c0 rank 41 nranks 128 cudaDev 1 busId 1901000 - Abort COMPLETE
10: nid005590:110711:213921 [1] NCCL INFO misc/socket.cc:47 -> 3
10: nid005590:110711:213921 [1] NCCL INFO misc/socket.cc:550 -> 3
10: nid005590:110711:213921 [1] NCCL INFO misc/socket.cc:573 -> 3
10: nid005590:110711:213921 [1] NCCL INFO misc/socket.cc:621 -> 3
10: nid005590:110711:111252 [1] NCCL INFO misc/socket.cc:47 -> 3
10: nid005590:110711:111252 [1] NCCL INFO misc/socket.cc:752 -> 3
10: nid005590:110711:111252 [1] NCCL INFO misc/socket.cc:428 -> 3
10: nid005590:110711:111252 [1] NCCL INFO misc/socket.cc:564 -> 3
10: nid005590:110711:111252 [1] NCCL INFO misc/socket.cc:668 -> 3
10: 
10: nid005590:110711:111252 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
10: nid005590:110711:213921 [1] NCCL INFO misc/socket.cc:47 -> 3
10: nid005590:110711:213921 [1] NCCL INFO misc/socket.cc:58 -> 3
10: nid005590:110711:213921 [1] NCCL INFO misc/socket.cc:775 -> 3
10: nid005590:110711:111252 [1] NCCL INFO misc/socket.cc:826 -> 3
10: 
10: nid005590:110711:111252 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
10: 
10: nid005590:110711:111252 [1] proxy.cc:1521 NCCL WARN [Proxy Service 41] Failed to execute operation Close from rank 41, retcode 3
16: nid005802:6300:108572 [3] NCCL INFO comm 0x40069164fe00 rank 67 nranks 128 cudaDev 3 busId 3901000 - Abort COMPLETE
16: nid005802:6300:108583 [3] NCCL INFO misc/socket.cc:47 -> 3
16: nid005802:6300:108583 [3] NCCL INFO misc/socket.cc:550 -> 3
16: nid005802:6300:108583 [3] NCCL INFO misc/socket.cc:573 -> 3
16: nid005802:6300:108583 [3] NCCL INFO misc/socket.cc:621 -> 3
16: nid005802:6300:6904 [3] NCCL INFO misc/socket.cc:47 -> 3
16: nid005802:6300:6904 [3] NCCL INFO misc/socket.cc:752 -> 3
16: nid005802:6300:6904 [3] NCCL INFO misc/socket.cc:428 -> 3
16: nid005802:6300:6904 [3] NCCL INFO misc/socket.cc:564 -> 3
16: nid005802:6300:6904 [3] NCCL INFO misc/socket.cc:668 -> 3
16: 
16: nid005802:6300:6904 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
16: nid005802:6300:108583 [3] NCCL INFO misc/socket.cc:47 -> 3
16: nid005802:6300:108583 [3] NCCL INFO misc/socket.cc:58 -> 3
16: nid005802:6300:108583 [3] NCCL INFO misc/socket.cc:775 -> 3
16: nid005802:6300:6904 [3] NCCL INFO misc/socket.cc:826 -> 3
16: 
16: nid005802:6300:6904 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
16: 
16: nid005802:6300:6904 [3] proxy.cc:1521 NCCL WARN [Proxy Service 67] Failed to execute operation Close from rank 67, retcode 3
21: nid005914:166785:269596 [1] NCCL INFO comm 0x400689651260 rank 85 nranks 128 cudaDev 1 busId 1901000 - Abort COMPLETE
21: nid005914:166785:269600 [1] NCCL INFO misc/socket.cc:47 -> 3
21: nid005914:166785:269600 [1] NCCL INFO misc/socket.cc:550 -> 3
21: nid005914:166785:269600 [1] NCCL INFO misc/socket.cc:573 -> 3
21: nid005914:166785:269600 [1] NCCL INFO misc/socket.cc:621 -> 3
21: nid005914:166785:167327 [1] NCCL INFO misc/socket.cc:47 -> 3
21: nid005914:166785:167327 [1] NCCL INFO misc/socket.cc:752 -> 3
21: nid005914:166785:167327 [1] NCCL INFO misc/socket.cc:428 -> 3
21: nid005914:166785:167327 [1] NCCL INFO misc/socket.cc:564 -> 3
21: nid005914:166785:167327 [1] NCCL INFO misc/socket.cc:668 -> 3
21: 
21: nid005914:166785:167327 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
21: nid005914:166785:269600 [1] NCCL INFO misc/socket.cc:47 -> 3
21: nid005914:166785:269600 [1] NCCL INFO misc/socket.cc:58 -> 3
21: nid005914:166785:269600 [1] NCCL INFO misc/socket.cc:775 -> 3
21: nid005914:166785:167327 [1] NCCL INFO misc/socket.cc:826 -> 3
21: 
21: nid005914:166785:167327 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
21: 
21: nid005914:166785:167327 [1] proxy.cc:1521 NCCL WARN [Proxy Service 85] Failed to execute operation Close from rank 85, retcode 3
 5: nid005582:196714:3942 [1] NCCL INFO comm 0x400689651260 rank 21 nranks 128 cudaDev 1 busId 1901000 - Abort COMPLETE
 5: nid005582:196714:3945 [1] NCCL INFO misc/socket.cc:47 -> 3
 5: nid005582:196714:3945 [1] NCCL INFO misc/socket.cc:550 -> 3
 5: nid005582:196714:3945 [1] NCCL INFO misc/socket.cc:573 -> 3
 5: nid005582:196714:3945 [1] NCCL INFO misc/socket.cc:621 -> 3
 5: nid005582:196714:197397 [1] NCCL INFO misc/socket.cc:47 -> 3
 5: nid005582:196714:197397 [1] NCCL INFO misc/socket.cc:752 -> 3
 5: nid005582:196714:197397 [1] NCCL INFO misc/socket.cc:428 -> 3
 5: nid005582:196714:197397 [1] NCCL INFO misc/socket.cc:564 -> 3
21: nid005914:166787:269594 [3] NCCL INFO comm 0x40069964fe00 rank 87 nranks 128 cudaDev 3 busId 3901000 - Abort COMPLETE
 5: nid005582:196714:197397 [1] NCCL INFO misc/socket.cc:668 -> 3
 5: 
 5: nid005582:196714:197397 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 5: nid005582:196714:3945 [1] NCCL INFO misc/socket.cc:47 -> 3
 5: nid005582:196714:3945 [1] NCCL INFO misc/socket.cc:58 -> 3
 5: nid005582:196714:3945 [1] NCCL INFO misc/socket.cc:775 -> 3
 5: nid005582:196714:197397 [1] NCCL INFO misc/socket.cc:826 -> 3
 5: 
 5: nid005582:196714:197397 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
 5: 
 5: nid005582:196714:197397 [1] proxy.cc:1521 NCCL WARN [Proxy Service 21] Failed to execute operation Close from rank 21, retcode 3
21: nid005914:166787:269601 [3] NCCL INFO misc/socket.cc:47 -> 3
21: nid005914:166787:269601 [3] NCCL INFO misc/socket.cc:550 -> 3
21: nid005914:166787:269601 [3] NCCL INFO misc/socket.cc:573 -> 3
21: nid005914:166787:269601 [3] NCCL INFO misc/socket.cc:621 -> 3
21: nid005914:166787:167324 [3] NCCL INFO misc/socket.cc:47 -> 3
21: nid005914:166787:167324 [3] NCCL INFO misc/socket.cc:752 -> 3
21: nid005914:166787:167324 [3] NCCL INFO misc/socket.cc:428 -> 3
21: nid005914:166787:167324 [3] NCCL INFO misc/socket.cc:564 -> 3
21: nid005914:166787:167324 [3] NCCL INFO misc/socket.cc:668 -> 3
21: 
21: nid005914:166787:167324 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
21: nid005914:166787:269601 [3] NCCL INFO misc/socket.cc:47 -> 3
21: nid005914:166787:269601 [3] NCCL INFO misc/socket.cc:58 -> 3
21: nid005914:166787:269601 [3] NCCL INFO misc/socket.cc:775 -> 3
21: nid005914:166787:167324 [3] NCCL INFO misc/socket.cc:826 -> 3
21: 
21: nid005914:166787:167324 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
21: 
21: nid005914:166787:167324 [3] proxy.cc:1521 NCCL WARN [Proxy Service 87] Failed to execute operation Close from rank 87, retcode 3
23: nid005917:276886:86829 [1] NCCL INFO comm 0x40068164fb30 rank 93 nranks 128 cudaDev 1 busId 1901000 - Abort COMPLETE
16: nid005802:6297:108576 [0] NCCL INFO comm 0xaaab18b83d10 rank 64 nranks 128 cudaDev 0 busId 901000 - Abort COMPLETE
23: nid005917:276886:86833 [1] NCCL INFO misc/socket.cc:47 -> 3
23: nid005917:276886:86833 [1] NCCL INFO misc/socket.cc:550 -> 3
23: nid005917:276886:86833 [1] NCCL INFO misc/socket.cc:573 -> 3
23: nid005917:276886:86833 [1] NCCL INFO misc/socket.cc:621 -> 3
23: nid005917:276886:277431 [1] NCCL INFO misc/socket.cc:47 -> 3
23: nid005917:276886:277431 [1] NCCL INFO misc/socket.cc:752 -> 3
23: nid005917:276886:277431 [1] NCCL INFO misc/socket.cc:428 -> 3
23: nid005917:276886:277431 [1] NCCL INFO misc/socket.cc:564 -> 3
23: nid005917:276886:277431 [1] NCCL INFO misc/socket.cc:668 -> 3
23: 
23: nid005917:276886:277431 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
23: nid005917:276886:86833 [1] NCCL INFO misc/socket.cc:47 -> 3
23: nid005917:276886:86833 [1] NCCL INFO misc/socket.cc:58 -> 3
23: nid005917:276886:86833 [1] NCCL INFO misc/socket.cc:775 -> 3
23: nid005917:276886:277431 [1] NCCL INFO misc/socket.cc:826 -> 3
23: 
23: nid005917:276886:277431 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
23: 
23: nid005917:276886:277431 [1] proxy.cc:1521 NCCL WARN [Proxy Service 93] Failed to execute operation Close from rank 93, retcode 3
 6: nid005584:28285:128095 [0] NCCL INFO comm 0xaaaafc6efb40 rank 24 nranks 128 cudaDev 0 busId 901000 - Abort COMPLETE
10: nid005590:110713:213917 [3] NCCL INFO comm 0x4006a9653dc0 rank 43 nranks 128 cudaDev 3 busId 3901000 - Abort COMPLETE
10: nid005590:110713:213922 [3] NCCL INFO misc/socket.cc:47 -> 3
10: nid005590:110713:213922 [3] NCCL INFO misc/socket.cc:550 -> 3
10: nid005590:110713:213922 [3] NCCL INFO misc/socket.cc:573 -> 3
10: nid005590:110713:213922 [3] NCCL INFO misc/socket.cc:621 -> 3
10: nid005590:110713:111247 [3] NCCL INFO misc/socket.cc:47 -> 3
10: nid005590:110713:111247 [3] NCCL INFO misc/socket.cc:752 -> 3
10: nid005590:110713:111247 [3] NCCL INFO misc/socket.cc:428 -> 3
10: nid005590:110713:111247 [3] NCCL INFO misc/socket.cc:564 -> 3
10: nid005590:110713:111247 [3] NCCL INFO misc/socket.cc:668 -> 3
10: 
10: nid005590:110713:111247 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
10: nid005590:110713:213922 [3] NCCL INFO misc/socket.cc:47 -> 3
10: nid005590:110713:213922 [3] NCCL INFO misc/socket.cc:58 -> 3
10: nid005590:110713:213922 [3] NCCL INFO misc/socket.cc:775 -> 3
10: nid005590:110713:111247 [3] NCCL INFO misc/socket.cc:826 -> 3
10: 
10: nid005590:110713:111247 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
10: 
10: nid005590:110713:111247 [3] proxy.cc:1521 NCCL WARN [Proxy Service 43] Failed to execute operation Close from rank 43, retcode 3
12: nid005594:53086:154890 [1] NCCL INFO comm 0x40067164fdf0 rank 49 nranks 128 cudaDev 1 busId 1901000 - Abort COMPLETE
12: nid005594:53086:154898 [1] NCCL INFO misc/socket.cc:47 -> 3
12: nid005594:53086:154898 [1] NCCL INFO misc/socket.cc:550 -> 3
12: nid005594:53086:154898 [1] NCCL INFO misc/socket.cc:573 -> 3
12: nid005594:53086:154898 [1] NCCL INFO misc/socket.cc:621 -> 3
12: nid005594:53086:53630 [1] NCCL INFO misc/socket.cc:47 -> 3
12: nid005594:53086:53630 [1] NCCL INFO misc/socket.cc:752 -> 3
12: nid005594:53086:53630 [1] NCCL INFO misc/socket.cc:428 -> 3
12: nid005594:53086:53630 [1] NCCL INFO misc/socket.cc:564 -> 3
12: nid005594:53086:53630 [1] NCCL INFO misc/socket.cc:668 -> 3
12: 
12: nid005594:53086:53630 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
12: nid005594:53086:154898 [1] NCCL INFO misc/socket.cc:47 -> 3
12: nid005594:53086:154898 [1] NCCL INFO misc/socket.cc:58 -> 3
12: nid005594:53086:154898 [1] NCCL INFO misc/socket.cc:775 -> 3
12: nid005594:53086:53630 [1] NCCL INFO misc/socket.cc:826 -> 3
12: 
12: nid005594:53086:53630 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
12: 
12: nid005594:53086:53630 [1] proxy.cc:1521 NCCL WARN [Proxy Service 49] Failed to execute operation Close from rank 49, retcode 3
 6: nid005584:28286:128092 [1] NCCL INFO comm 0x40068964fe00 rank 25 nranks 128 cudaDev 1 busId 1901000 - Abort COMPLETE
 6: nid005584:28286:128099 [1] NCCL INFO misc/socket.cc:47 -> 3
 6: nid005584:28286:128099 [1] NCCL INFO misc/socket.cc:550 -> 3
 6: nid005584:28286:128099 [1] NCCL INFO misc/socket.cc:573 -> 3
 6: nid005584:28286:128099 [1] NCCL INFO misc/socket.cc:621 -> 3
 6: nid005584:28286:28829 [1] NCCL INFO misc/socket.cc:47 -> 3
 6: nid005584:28286:28829 [1] NCCL INFO misc/socket.cc:752 -> 3
 6: nid005584:28286:28829 [1] NCCL INFO misc/socket.cc:428 -> 3
 6: nid005584:28286:28829 [1] NCCL INFO misc/socket.cc:564 -> 3
 6: nid005584:28286:28829 [1] NCCL INFO misc/socket.cc:668 -> 3
 6: 
 6: nid005584:28286:28829 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 6: nid005584:28286:128099 [1] NCCL INFO misc/socket.cc:47 -> 3
 6: nid005584:28286:128099 [1] NCCL INFO misc/socket.cc:58 -> 3
 6: nid005584:28286:128099 [1] NCCL INFO misc/socket.cc:775 -> 3
 6: nid005584:28286:28829 [1] NCCL INFO misc/socket.cc:826 -> 3
 6: 
 6: nid005584:28286:28829 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
 6: 
 6: nid005584:28286:28829 [1] proxy.cc:1521 NCCL WARN [Proxy Service 25] Failed to execute operation Close from rank 25, retcode 3
 3: nid005580:71822:174884 [3] NCCL INFO comm 0x4006a164fde0 rank 15 nranks 128 cudaDev 3 busId 3901000 - Abort COMPLETE
30: nid005936:49911:151422 [3] NCCL INFO comm 0x40067564fd80 rank 123 nranks 128 cudaDev 3 busId 3901000 - Abort COMPLETE
 3: nid005580:71822:174887 [3] NCCL INFO misc/socket.cc:47 -> 3
 3: nid005580:71822:174887 [3] NCCL INFO misc/socket.cc:550 -> 3
 3: nid005580:71822:174887 [3] NCCL INFO misc/socket.cc:573 -> 3
 3: nid005580:71822:174887 [3] NCCL INFO misc/socket.cc:621 -> 3
 3: nid005580:71822:72361 [3] NCCL INFO misc/socket.cc:47 -> 3
 3: nid005580:71822:72361 [3] NCCL INFO misc/socket.cc:752 -> 3
 3: nid005580:71822:72361 [3] NCCL INFO misc/socket.cc:428 -> 3
 3: nid005580:71822:72361 [3] NCCL INFO misc/socket.cc:564 -> 3
 3: nid005580:71822:72361 [3] NCCL INFO misc/socket.cc:668 -> 3
 3: 
 3: nid005580:71822:72361 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 3: nid005580:71822:174887 [3] NCCL INFO misc/socket.cc:47 -> 3
 3: nid005580:71822:174887 [3] NCCL INFO misc/socket.cc:58 -> 3
 3: nid005580:71822:174887 [3] NCCL INFO misc/socket.cc:775 -> 3
 3: nid005580:71822:72361 [3] NCCL INFO misc/socket.cc:826 -> 3
 3: 
 3: nid005580:71822:72361 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
 3: 
 3: nid005580:71822:72361 [3] proxy.cc:1521 NCCL WARN [Proxy Service 15] Failed to execute operation Close from rank 15, retcode 3
14: nid005600:217722:26917 [2] NCCL INFO comm 0x40068d6513b0 rank 58 nranks 128 cudaDev 2 busId 2901000 - Abort COMPLETE
30: nid005936:49911:151428 [3] NCCL INFO misc/socket.cc:47 -> 3
30: nid005936:49911:151428 [3] NCCL INFO misc/socket.cc:550 -> 3
30: nid005936:49911:151428 [3] NCCL INFO misc/socket.cc:573 -> 3
30: nid005936:49911:151428 [3] NCCL INFO misc/socket.cc:621 -> 3
30: nid005936:49911:50474 [3] NCCL INFO misc/socket.cc:47 -> 3
30: nid005936:49911:50474 [3] NCCL INFO misc/socket.cc:752 -> 3
30: nid005936:49911:50474 [3] NCCL INFO misc/socket.cc:428 -> 3
30: nid005936:49911:50474 [3] NCCL INFO misc/socket.cc:564 -> 3
30: nid005936:49911:50474 [3] NCCL INFO misc/socket.cc:668 -> 3
30: 
30: nid005936:49911:50474 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
30: nid005936:49911:151428 [3] NCCL INFO misc/socket.cc:47 -> 3
30: nid005936:49911:151428 [3] NCCL INFO misc/socket.cc:58 -> 3
30: nid005936:49911:151428 [3] NCCL INFO misc/socket.cc:775 -> 3
30: nid005936:49911:50474 [3] NCCL INFO misc/socket.cc:826 -> 3
30: 
30: nid005936:49911:50474 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
30: 
30: nid005936:49911:50474 [3] proxy.cc:1521 NCCL WARN [Proxy Service 123] Failed to execute operation Close from rank 123, retcode 3
14: nid005600:217722:26920 [2] NCCL INFO misc/socket.cc:47 -> 3
14: nid005600:217722:26920 [2] NCCL INFO misc/socket.cc:550 -> 3
14: nid005600:217722:26920 [2] NCCL INFO misc/socket.cc:573 -> 3
14: nid005600:217722:26920 [2] NCCL INFO misc/socket.cc:621 -> 3
14: nid005600:217722:218271 [2] NCCL INFO misc/socket.cc:47 -> 3
14: nid005600:217722:218271 [2] NCCL INFO misc/socket.cc:752 -> 3
14: nid005600:217722:218271 [2] NCCL INFO misc/socket.cc:428 -> 3
14: nid005600:217722:218271 [2] NCCL INFO misc/socket.cc:564 -> 3
14: nid005600:217722:218271 [2] NCCL INFO misc/socket.cc:668 -> 3
14: 
14: nid005600:217722:218271 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
14: nid005600:217722:26920 [2] NCCL INFO misc/socket.cc:47 -> 3
14: nid005600:217722:26920 [2] NCCL INFO misc/socket.cc:58 -> 3
14: nid005600:217722:26920 [2] NCCL INFO misc/socket.cc:775 -> 3
14: nid005600:217722:218271 [2] NCCL INFO misc/socket.cc:826 -> 3
14: 
14: nid005600:217722:218271 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
14: 
14: nid005600:217722:218271 [2] proxy.cc:1521 NCCL WARN [Proxy Service 58] Failed to execute operation Close from rank 58, retcode 3
12: nid005594:53088:154891 [3] NCCL INFO comm 0x40068164fe00 rank 51 nranks 128 cudaDev 3 busId 3901000 - Abort COMPLETE
22: nid005915:274816:84247 [2] NCCL INFO comm 0x4006a96513b0 rank 90 nranks 128 cudaDev 2 busId 2901000 - Abort COMPLETE
12: nid005594:53088:154899 [3] NCCL INFO misc/socket.cc:47 -> 3
12: nid005594:53088:154899 [3] NCCL INFO misc/socket.cc:550 -> 3
12: nid005594:53088:154899 [3] NCCL INFO misc/socket.cc:573 -> 3
12: nid005594:53088:154899 [3] NCCL INFO misc/socket.cc:621 -> 3
12: nid005594:53088:53629 [3] NCCL INFO misc/socket.cc:47 -> 3
12: nid005594:53088:53629 [3] NCCL INFO misc/socket.cc:752 -> 3
12: nid005594:53088:53629 [3] NCCL INFO misc/socket.cc:428 -> 3
12: nid005594:53088:53629 [3] NCCL INFO misc/socket.cc:564 -> 3
12: nid005594:53088:53629 [3] NCCL INFO misc/socket.cc:668 -> 3
12: 
12: nid005594:53088:53629 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
12: nid005594:53088:154899 [3] NCCL INFO misc/socket.cc:47 -> 3
12: nid005594:53088:154899 [3] NCCL INFO misc/socket.cc:58 -> 3
12: nid005594:53088:154899 [3] NCCL INFO misc/socket.cc:775 -> 3
12: nid005594:53088:53629 [3] NCCL INFO misc/socket.cc:826 -> 3
12: 
12: nid005594:53088:53629 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
12: 
12: nid005594:53088:53629 [3] proxy.cc:1521 NCCL WARN [Proxy Service 51] Failed to execute operation Close from rank 51, retcode 3
22: nid005915:274816:84252 [2] NCCL INFO misc/socket.cc:47 -> 3
22: nid005915:274816:84252 [2] NCCL INFO misc/socket.cc:550 -> 3
22: nid005915:274816:84252 [2] NCCL INFO misc/socket.cc:573 -> 3
22: nid005915:274816:84252 [2] NCCL INFO misc/socket.cc:621 -> 3
22: nid005915:274816:275361 [2] NCCL INFO misc/socket.cc:47 -> 3
22: nid005915:274816:275361 [2] NCCL INFO misc/socket.cc:752 -> 3
22: nid005915:274816:275361 [2] NCCL INFO misc/socket.cc:428 -> 3
22: nid005915:274816:275361 [2] NCCL INFO misc/socket.cc:564 -> 3
22: nid005915:274816:275361 [2] NCCL INFO misc/socket.cc:668 -> 3
22: 
22: nid005915:274816:275361 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
22: nid005915:274816:84252 [2] NCCL INFO misc/socket.cc:47 -> 3
22: nid005915:274816:84252 [2] NCCL INFO misc/socket.cc:58 -> 3
22: nid005915:274816:84252 [2] NCCL INFO misc/socket.cc:775 -> 3
22: nid005915:274816:275361 [2] NCCL INFO misc/socket.cc:826 -> 3
22: 
22: nid005915:274816:275361 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
22: 
22: nid005915:274816:275361 [2] proxy.cc:1521 NCCL WARN [Proxy Service 90] Failed to execute operation Close from rank 90, retcode 3
 5: nid005582:196715:3943 [2] NCCL INFO comm 0x4006bd651260 rank 22 nranks 128 cudaDev 2 busId 2901000 - Abort COMPLETE
 5: nid005582:196715:3946 [2] NCCL INFO misc/socket.cc:47 -> 3
 5: nid005582:196715:3946 [2] NCCL INFO misc/socket.cc:550 -> 3
 5: nid005582:196715:3946 [2] NCCL INFO misc/socket.cc:573 -> 3
 5: nid005582:196715:3946 [2] NCCL INFO misc/socket.cc:621 -> 3
 5: nid005582:196715:197395 [2] NCCL INFO misc/socket.cc:47 -> 3
 5: nid005582:196715:197395 [2] NCCL INFO misc/socket.cc:752 -> 3
 5: nid005582:196715:197395 [2] NCCL INFO misc/socket.cc:428 -> 3
 5: nid005582:196715:197395 [2] NCCL INFO misc/socket.cc:564 -> 3
 5: nid005582:196715:197395 [2] NCCL INFO misc/socket.cc:668 -> 3
 5: 
 5: nid005582:196715:197395 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 5: nid005582:196715:3946 [2] NCCL INFO misc/socket.cc:47 -> 3
 5: nid005582:196715:3946 [2] NCCL INFO misc/socket.cc:58 -> 3
 5: nid005582:196715:3946 [2] NCCL INFO misc/socket.cc:775 -> 3
 5: nid005582:196715:197395 [2] NCCL INFO misc/socket.cc:826 -> 3
 5: 
 5: nid005582:196715:197395 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
 5: 
 5: nid005582:196715:197395 [2] proxy.cc:1521 NCCL WARN [Proxy Service 22] Failed to execute operation Close from rank 22, retcode 3
31: nid005937:256591:65764 [2] NCCL INFO comm 0x40068964fe00 rank 126 nranks 128 cudaDev 2 busId 2901000 - Abort COMPLETE
31: nid005937:256591:65767 [2] NCCL INFO misc/socket.cc:47 -> 3
31: nid005937:256591:65767 [2] NCCL INFO misc/socket.cc:550 -> 3
31: nid005937:256591:65767 [2] NCCL INFO misc/socket.cc:573 -> 3
31: nid005937:256591:65767 [2] NCCL INFO misc/socket.cc:621 -> 3
31: nid005937:256591:257156 [2] NCCL INFO misc/socket.cc:47 -> 3
31: nid005937:256591:257156 [2] NCCL INFO misc/socket.cc:752 -> 3
31: nid005937:256591:257156 [2] NCCL INFO misc/socket.cc:428 -> 3
31: nid005937:256591:257156 [2] NCCL INFO misc/socket.cc:564 -> 3
31: nid005937:256591:257156 [2] NCCL INFO misc/socket.cc:668 -> 3
31: 
31: nid005937:256591:257156 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
31: nid005937:256591:65767 [2] NCCL INFO misc/socket.cc:47 -> 3
31: nid005937:256591:65767 [2] NCCL INFO misc/socket.cc:58 -> 3
31: nid005937:256591:257156 [2] NCCL INFO misc/socket.cc:826 -> 3
31: 
31: nid005937:256591:257156 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
31: 
31: nid005937:256591:257156 [2] proxy.cc:1521 NCCL WARN [Proxy Service 126] Failed to execute operation Close from rank 126, retcode 3
31: nid005937:256591:65767 [2] NCCL INFO misc/socket.cc:775 -> 3
20: nid005913:292683:101212 [2] NCCL INFO comm 0x40069564fdf0 rank 82 nranks 128 cudaDev 2 busId 2901000 - Abort COMPLETE
20: nid005913:292683:101214 [2] NCCL INFO misc/socket.cc:47 -> 3
20: nid005913:292683:101214 [2] NCCL INFO misc/socket.cc:550 -> 3
20: nid005913:292683:101214 [2] NCCL INFO misc/socket.cc:573 -> 3
20: nid005913:292683:101214 [2] NCCL INFO misc/socket.cc:621 -> 3
20: nid005913:292683:293229 [2] NCCL INFO misc/socket.cc:47 -> 3
20: nid005913:292683:293229 [2] NCCL INFO misc/socket.cc:752 -> 3
20: nid005913:292683:293229 [2] NCCL INFO misc/socket.cc:428 -> 3
20: nid005913:292683:293229 [2] NCCL INFO misc/socket.cc:564 -> 3
20: nid005913:292683:293229 [2] NCCL INFO misc/socket.cc:668 -> 3
20: 
20: nid005913:292683:293229 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
20: nid005913:292683:101214 [2] NCCL INFO misc/socket.cc:47 -> 3
20: nid005913:292683:101214 [2] NCCL INFO misc/socket.cc:58 -> 3
20: nid005913:292683:101214 [2] NCCL INFO misc/socket.cc:775 -> 3
20: nid005913:292683:293229 [2] NCCL INFO misc/socket.cc:826 -> 3
20: 
20: nid005913:292683:293229 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
20: 
20: nid005913:292683:293229 [2] proxy.cc:1521 NCCL WARN [Proxy Service 82] Failed to execute operation Close from rank 82, retcode 3
 2: nid005577:17423:118764 [1] NCCL INFO comm 0x40069164fd80 rank 9 nranks 128 cudaDev 1 busId 1901000 - Abort COMPLETE
 2: nid005577:17423:118772 [1] NCCL INFO misc/socket.cc:47 -> 3
 2: nid005577:17423:118772 [1] NCCL INFO misc/socket.cc:550 -> 3
 2: nid005577:17423:118772 [1] NCCL INFO misc/socket.cc:573 -> 3
 2: nid005577:17423:118772 [1] NCCL INFO misc/socket.cc:621 -> 3
 2: nid005577:17423:17989 [1] NCCL INFO misc/socket.cc:47 -> 3
 2: nid005577:17423:17989 [1] NCCL INFO misc/socket.cc:752 -> 3
 2: nid005577:17423:17989 [1] NCCL INFO misc/socket.cc:428 -> 3
 2: nid005577:17423:17989 [1] NCCL INFO misc/socket.cc:564 -> 3
 2: nid005577:17423:17989 [1] NCCL INFO misc/socket.cc:668 -> 3
 2: 
 2: nid005577:17423:17989 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 4: nid005581:264526:72357 [3] NCCL INFO comm 0x40069d64e840 rank 19 nranks 128 cudaDev 3 busId 3901000 - Abort COMPLETE
 2: nid005577:17423:118772 [1] NCCL INFO misc/socket.cc:47 -> 3
 2: nid005577:17423:118772 [1] NCCL INFO misc/socket.cc:58 -> 3
 2: nid005577:17423:118772 [1] NCCL INFO misc/socket.cc:775 -> 3
 2: nid005577:17423:17989 [1] NCCL INFO misc/socket.cc:826 -> 3
 2: 
 2: nid005577:17423:17989 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
 2: 
 2: nid005577:17423:17989 [1] proxy.cc:1521 NCCL WARN [Proxy Service 9] Failed to execute operation Close from rank 9, retcode 3
 4: nid005581:264526:72361 [3] NCCL INFO misc/socket.cc:47 -> 3
 4: nid005581:264526:72361 [3] NCCL INFO misc/socket.cc:550 -> 3
 4: nid005581:264526:72361 [3] NCCL INFO misc/socket.cc:573 -> 3
 4: nid005581:264526:72361 [3] NCCL INFO misc/socket.cc:621 -> 3
 4: nid005581:264526:265069 [3] NCCL INFO misc/socket.cc:47 -> 3
 4: nid005581:264526:265069 [3] NCCL INFO misc/socket.cc:752 -> 3
 4: nid005581:264526:265069 [3] NCCL INFO misc/socket.cc:428 -> 3
 4: nid005581:264526:265069 [3] NCCL INFO misc/socket.cc:564 -> 3
 4: nid005581:264526:265069 [3] NCCL INFO misc/socket.cc:668 -> 3
 4: 
 4: nid005581:264526:265069 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 4: nid005581:264526:72361 [3] NCCL INFO misc/socket.cc:47 -> 3
 4: nid005581:264526:72361 [3] NCCL INFO misc/socket.cc:58 -> 3
 4: nid005581:264526:72361 [3] NCCL INFO misc/socket.cc:775 -> 3
 4: nid005581:264526:265069 [3] NCCL INFO misc/socket.cc:826 -> 3
 4: 
 4: nid005581:264526:265069 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
 4: 
 4: nid005581:264526:265069 [3] proxy.cc:1521 NCCL WARN [Proxy Service 19] Failed to execute operation Close from rank 19, retcode 3
18: nid005911:38866:140345 [2] NCCL INFO comm 0x4006ad64e900 rank 74 nranks 128 cudaDev 2 busId 2901000 - Abort COMPLETE
18: nid005911:38866:140349 [2] NCCL INFO misc/socket.cc:47 -> 3
18: nid005911:38866:140349 [2] NCCL INFO misc/socket.cc:550 -> 3
18: nid005911:38866:140349 [2] NCCL INFO misc/socket.cc:573 -> 3
18: nid005911:38866:140349 [2] NCCL INFO misc/socket.cc:621 -> 3
18: nid005911:38866:39426 [2] NCCL INFO misc/socket.cc:47 -> 3
18: nid005911:38866:39426 [2] NCCL INFO misc/socket.cc:752 -> 3
18: nid005911:38866:39426 [2] NCCL INFO misc/socket.cc:428 -> 3
18: nid005911:38866:39426 [2] NCCL INFO misc/socket.cc:564 -> 3
18: nid005911:38866:39426 [2] NCCL INFO misc/socket.cc:668 -> 3
18: 
18: nid005911:38866:39426 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
18: nid005911:38866:140349 [2] NCCL INFO misc/socket.cc:47 -> 3
18: nid005911:38866:140349 [2] NCCL INFO misc/socket.cc:58 -> 3
18: nid005911:38866:140349 [2] NCCL INFO misc/socket.cc:775 -> 3
18: nid005911:38866:39426 [2] NCCL INFO misc/socket.cc:826 -> 3
18: 
18: nid005911:38866:39426 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
18: 
18: nid005911:38866:39426 [2] proxy.cc:1521 NCCL WARN [Proxy Service 74] Failed to execute operation Close from rank 74, retcode 3
23: nid005917:276887:86831 [2] NCCL INFO comm 0x40068d64e900 rank 94 nranks 128 cudaDev 2 busId 2901000 - Abort COMPLETE
23: nid005917:276887:86834 [2] NCCL INFO misc/socket.cc:47 -> 3
23: nid005917:276887:86834 [2] NCCL INFO misc/socket.cc:550 -> 3
23: nid005917:276887:86834 [2] NCCL INFO misc/socket.cc:573 -> 3
23: nid005917:276887:86834 [2] NCCL INFO misc/socket.cc:621 -> 3
23: nid005917:276887:277430 [2] NCCL INFO misc/socket.cc:47 -> 3
23: nid005917:276887:277430 [2] NCCL INFO misc/socket.cc:752 -> 3
23: nid005917:276887:277430 [2] NCCL INFO misc/socket.cc:428 -> 3
23: nid005917:276887:277430 [2] NCCL INFO misc/socket.cc:564 -> 3
23: nid005917:276887:277430 [2] NCCL INFO misc/socket.cc:668 -> 3
23: 
23: nid005917:276887:277430 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
23: nid005917:276887:86834 [2] NCCL INFO misc/socket.cc:47 -> 3
23: nid005917:276887:86834 [2] NCCL INFO misc/socket.cc:58 -> 3
23: nid005917:276887:86834 [2] NCCL INFO misc/socket.cc:775 -> 3
23: nid005917:276887:277430 [2] NCCL INFO misc/socket.cc:826 -> 3
23: 
23: nid005917:276887:277430 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
23: 
23: nid005917:276887:277430 [2] proxy.cc:1521 NCCL WARN [Proxy Service 94] Failed to execute operation Close from rank 94, retcode 3
 5: nid005582:196716:3941 [3] NCCL INFO comm 0x40067d64fe00 rank 23 nranks 128 cudaDev 3 busId 3901000 - Abort COMPLETE
 5: nid005582:196716:3947 [3] NCCL INFO misc/socket.cc:47 -> 3
 5: nid005582:196716:3947 [3] NCCL INFO misc/socket.cc:550 -> 3
 5: nid005582:196716:3947 [3] NCCL INFO misc/socket.cc:573 -> 3
 5: nid005582:196716:3947 [3] NCCL INFO misc/socket.cc:621 -> 3
 5: nid005582:196716:197394 [3] NCCL INFO misc/socket.cc:47 -> 3
 5: nid005582:196716:197394 [3] NCCL INFO misc/socket.cc:752 -> 3
 5: nid005582:196716:197394 [3] NCCL INFO misc/socket.cc:428 -> 3
 5: nid005582:196716:197394 [3] NCCL INFO misc/socket.cc:564 -> 3
 5: nid005582:196716:197394 [3] NCCL INFO misc/socket.cc:668 -> 3
 5: 
 5: nid005582:196716:197394 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 5: nid005582:196716:3947 [3] NCCL INFO misc/socket.cc:47 -> 3
 5: nid005582:196716:3947 [3] NCCL INFO misc/socket.cc:58 -> 3
 5: nid005582:196716:3947 [3] NCCL INFO misc/socket.cc:775 -> 3
 5: nid005582:196716:197394 [3] NCCL INFO misc/socket.cc:826 -> 3
 5: 
 5: nid005582:196716:197394 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
 5: 
 5: nid005582:196716:197394 [3] proxy.cc:1521 NCCL WARN [Proxy Service 23] Failed to execute operation Close from rank 23, retcode 3
14: nid005600:217721:26916 [1] NCCL INFO comm 0x400679651260 rank 57 nranks 128 cudaDev 1 busId 1901000 - Abort COMPLETE
14: nid005600:217721:26921 [1] NCCL INFO misc/socket.cc:47 -> 3
14: nid005600:217721:26921 [1] NCCL INFO misc/socket.cc:550 -> 3
14: nid005600:217721:26921 [1] NCCL INFO misc/socket.cc:573 -> 3
14: nid005600:217721:26921 [1] NCCL INFO misc/socket.cc:621 -> 3
14: nid005600:217721:218270 [1] NCCL INFO misc/socket.cc:47 -> 3
14: nid005600:217721:218270 [1] NCCL INFO misc/socket.cc:752 -> 3
14: nid005600:217721:218270 [1] NCCL INFO misc/socket.cc:428 -> 3
14: nid005600:217721:218270 [1] NCCL INFO misc/socket.cc:564 -> 3
14: nid005600:217721:218270 [1] NCCL INFO misc/socket.cc:668 -> 3
14: 
14: nid005600:217721:218270 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
14: nid005600:217721:26921 [1] NCCL INFO misc/socket.cc:47 -> 3
14: nid005600:217721:26921 [1] NCCL INFO misc/socket.cc:58 -> 3
14: nid005600:217721:26921 [1] NCCL INFO misc/socket.cc:775 -> 3
14: nid005600:217721:218270 [1] NCCL INFO misc/socket.cc:826 -> 3
14: 
14: nid005600:217721:218270 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
14: 
14: nid005600:217721:218270 [1] proxy.cc:1521 NCCL WARN [Proxy Service 57] Failed to execute operation Close from rank 57, retcode 3
23: nid005917:276885:86832 [0] NCCL INFO comm 0xaaaae40fdd90 rank 92 nranks 128 cudaDev 0 busId 901000 - Abort COMPLETE
23: nid005917:276888:86828 [3] NCCL INFO comm 0x40069d6513b0 rank 95 nranks 128 cudaDev 3 busId 3901000 - Abort COMPLETE
19: nid005912:12436:113121 [1] NCCL INFO comm 0x40067964fe00 rank 77 nranks 128 cudaDev 1 busId 1901000 - Abort COMPLETE
23: nid005917:276888:86835 [3] NCCL INFO misc/socket.cc:47 -> 3
23: nid005917:276888:86835 [3] NCCL INFO misc/socket.cc:550 -> 3
23: nid005917:276888:86835 [3] NCCL INFO misc/socket.cc:573 -> 3
23: nid005917:276888:86835 [3] NCCL INFO misc/socket.cc:621 -> 3
23: nid005917:276888:277429 [3] NCCL INFO misc/socket.cc:47 -> 3
23: nid005917:276888:277429 [3] NCCL INFO misc/socket.cc:752 -> 3
23: nid005917:276888:277429 [3] NCCL INFO misc/socket.cc:428 -> 3
23: nid005917:276888:277429 [3] NCCL INFO misc/socket.cc:564 -> 3
23: nid005917:276888:277429 [3] NCCL INFO misc/socket.cc:668 -> 3
19: nid005912:12436:113125 [1] NCCL INFO misc/socket.cc:47 -> 3
19: nid005912:12436:113125 [1] NCCL INFO misc/socket.cc:550 -> 3
19: nid005912:12436:113125 [1] NCCL INFO misc/socket.cc:573 -> 3
19: nid005912:12436:113125 [1] NCCL INFO misc/socket.cc:621 -> 3
23: 
23: nid005917:276888:277429 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
19: nid005912:12436:13001 [1] NCCL INFO misc/socket.cc:47 -> 3
19: nid005912:12436:13001 [1] NCCL INFO misc/socket.cc:752 -> 3
19: nid005912:12436:13001 [1] NCCL INFO misc/socket.cc:428 -> 3
19: nid005912:12436:13001 [1] NCCL INFO misc/socket.cc:564 -> 3
23: nid005917:276888:86835 [3] NCCL INFO misc/socket.cc:47 -> 3
23: nid005917:276888:86835 [3] NCCL INFO misc/socket.cc:58 -> 3
23: nid005917:276888:86835 [3] NCCL INFO misc/socket.cc:775 -> 3
19: nid005912:12436:13001 [1] NCCL INFO misc/socket.cc:668 -> 3
23: nid005917:276888:277429 [3] NCCL INFO misc/socket.cc:826 -> 3
23: 
23: nid005917:276888:277429 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
19: 
19: nid005912:12436:13001 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
23: 
23: nid005917:276888:277429 [3] proxy.cc:1521 NCCL WARN [Proxy Service 95] Failed to execute operation Close from rank 95, retcode 3
19: nid005912:12436:113125 [1] NCCL INFO misc/socket.cc:47 -> 3
19: nid005912:12436:113125 [1] NCCL INFO misc/socket.cc:58 -> 3
19: nid005912:12436:113125 [1] NCCL INFO misc/socket.cc:775 -> 3
19: nid005912:12436:13001 [1] NCCL INFO misc/socket.cc:826 -> 3
19: 
19: nid005912:12436:13001 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
19: 
19: nid005912:12436:13001 [1] proxy.cc:1521 NCCL WARN [Proxy Service 77] Failed to execute operation Close from rank 77, retcode 3
 8: nid005586:68926:170712 [0] NCCL INFO comm 0x400665651220 rank 32 nranks 128 cudaDev 0 busId 901000 - Abort COMPLETE
 8: nid005586:68926:170714 [0] NCCL INFO misc/socket.cc:47 -> 3
 8: nid005586:68926:170714 [0] NCCL INFO misc/socket.cc:550 -> 3
 8: nid005586:68926:170714 [0] NCCL INFO misc/socket.cc:573 -> 3
 8: nid005586:68926:170714 [0] NCCL INFO misc/socket.cc:621 -> 3
 8: nid005586:68926:69494 [0] NCCL INFO misc/socket.cc:47 -> 3
 8: nid005586:68926:69494 [0] NCCL INFO misc/socket.cc:752 -> 3
 8: nid005586:68926:69494 [0] NCCL INFO misc/socket.cc:428 -> 3
 8: nid005586:68926:69494 [0] NCCL INFO misc/socket.cc:564 -> 3
 8: nid005586:68926:69494 [0] NCCL INFO misc/socket.cc:668 -> 3
 8: 
 8: nid005586:68926:69494 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 8: nid005586:68926:170714 [0] NCCL INFO misc/socket.cc:47 -> 3
 8: nid005586:68926:170714 [0] NCCL INFO misc/socket.cc:58 -> 3
 8: nid005586:68926:170714 [0] NCCL INFO misc/socket.cc:775 -> 3
 8: nid005586:68926:69494 [0] NCCL INFO misc/socket.cc:826 -> 3
 8: 
 8: nid005586:68926:69494 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
 8: 
 8: nid005586:68926:69494 [0] proxy.cc:1521 NCCL WARN [Proxy Service 32] Failed to execute operation Close from rank 32, retcode 3
15: nid005601:210678:18853 [2] NCCL INFO comm 0x40068d6528c0 rank 62 nranks 128 cudaDev 2 busId 2901000 - Abort COMPLETE
15: nid005601:210678:18856 [2] NCCL INFO misc/socket.cc:47 -> 3
15: nid005601:210678:18856 [2] NCCL INFO misc/socket.cc:550 -> 3
15: nid005601:210678:18856 [2] NCCL INFO misc/socket.cc:573 -> 3
15: nid005601:210678:18856 [2] NCCL INFO misc/socket.cc:621 -> 3
15: nid005601:210678:211238 [2] NCCL INFO misc/socket.cc:47 -> 3
15: nid005601:210678:211238 [2] NCCL INFO misc/socket.cc:752 -> 3
15: nid005601:210678:211238 [2] NCCL INFO misc/socket.cc:428 -> 3
15: nid005601:210678:211238 [2] NCCL INFO misc/socket.cc:564 -> 3
15: nid005601:210678:211238 [2] NCCL INFO misc/socket.cc:668 -> 3
15: 
15: nid005601:210678:211238 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
15: nid005601:210678:18856 [2] NCCL INFO misc/socket.cc:47 -> 3
15: nid005601:210678:18856 [2] NCCL INFO misc/socket.cc:58 -> 3
15: nid005601:210678:18856 [2] NCCL INFO misc/socket.cc:775 -> 3
15: nid005601:210678:211238 [2] NCCL INFO misc/socket.cc:826 -> 3
15: 
15: nid005601:210678:211238 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
15: 
15: nid005601:210678:211238 [2] proxy.cc:1521 NCCL WARN [Proxy Service 62] Failed to execute operation Close from rank 62, retcode 3
19: nid005912:12438:113124 [3] NCCL INFO comm 0xaaaae3c43340 rank 79 nranks 128 cudaDev 3 busId 3901000 - Abort COMPLETE
31: nid005937:256591:65767 [2] NCCL INFO comm 0xaaaafcfbaf70 rank 126 nranks 128 cudaDev 2 busId 2901000 - Abort COMPLETE
17: nid005803:180734:283754 [2] NCCL INFO comm 0x40068564fe00 rank 70 nranks 128 cudaDev 2 busId 2901000 - Abort COMPLETE
17: nid005803:180734:283762 [2] NCCL INFO misc/socket.cc:47 -> 3
17: nid005803:180734:283762 [2] NCCL INFO misc/socket.cc:550 -> 3
17: nid005803:180734:283762 [2] NCCL INFO misc/socket.cc:573 -> 3
17: nid005803:180734:283762 [2] NCCL INFO misc/socket.cc:621 -> 3
17: nid005803:180734:181293 [2] NCCL INFO misc/socket.cc:47 -> 3
17: nid005803:180734:181293 [2] NCCL INFO misc/socket.cc:752 -> 3
17: nid005803:180734:181293 [2] NCCL INFO misc/socket.cc:428 -> 3
17: nid005803:180734:181293 [2] NCCL INFO misc/socket.cc:564 -> 3
17: nid005803:180734:181293 [2] NCCL INFO misc/socket.cc:668 -> 3
17: 
17: nid005803:180734:181293 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
17: nid005803:180734:283762 [2] NCCL INFO misc/socket.cc:47 -> 3
17: nid005803:180734:283762 [2] NCCL INFO misc/socket.cc:58 -> 3
17: nid005803:180734:283762 [2] NCCL INFO misc/socket.cc:775 -> 3
17: nid005803:180734:181293 [2] NCCL INFO misc/socket.cc:826 -> 3
17: 
17: nid005803:180734:181293 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
17: 
17: nid005803:180734:181293 [2] proxy.cc:1521 NCCL WARN [Proxy Service 70] Failed to execute operation Close from rank 70, retcode 3
30: nid005936:49910:151424 [2] NCCL INFO comm 0x4006b964f9d0 rank 122 nranks 128 cudaDev 2 busId 2901000 - Abort COMPLETE
30: nid005936:49910:151429 [2] NCCL INFO misc/socket.cc:47 -> 3
30: nid005936:49910:151429 [2] NCCL INFO misc/socket.cc:550 -> 3
30: nid005936:49910:151429 [2] NCCL INFO misc/socket.cc:573 -> 3
30: nid005936:49910:151429 [2] NCCL INFO misc/socket.cc:621 -> 3
30: nid005936:49910:50472 [2] NCCL INFO misc/socket.cc:47 -> 3
30: nid005936:49910:50472 [2] NCCL INFO misc/socket.cc:752 -> 3
30: nid005936:49910:50472 [2] NCCL INFO misc/socket.cc:428 -> 3
30: nid005936:49910:50472 [2] NCCL INFO misc/socket.cc:564 -> 3
30: nid005936:49910:50472 [2] NCCL INFO misc/socket.cc:668 -> 3
30: 
30: nid005936:49910:50472 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
30: nid005936:49910:151429 [2] NCCL INFO misc/socket.cc:47 -> 3
30: nid005936:49910:151429 [2] NCCL INFO misc/socket.cc:58 -> 3
30: nid005936:49910:151429 [2] NCCL INFO misc/socket.cc:775 -> 3
30: nid005936:49910:50472 [2] NCCL INFO misc/socket.cc:826 -> 3
30: 
30: nid005936:49910:50472 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
30: 
30: nid005936:49910:50472 [2] proxy.cc:1521 NCCL WARN [Proxy Service 122] Failed to execute operation Close from rank 122, retcode 3
26: nid005920:67125:168065 [2] NCCL INFO comm 0x400669651220 rank 106 nranks 128 cudaDev 2 busId 2901000 - Abort COMPLETE
26: nid005920:67125:168073 [2] NCCL INFO misc/socket.cc:47 -> 3
26: nid005920:67125:168073 [2] NCCL INFO misc/socket.cc:550 -> 3
26: nid005920:67125:168073 [2] NCCL INFO misc/socket.cc:573 -> 3
26: nid005920:67125:168073 [2] NCCL INFO misc/socket.cc:621 -> 3
26: nid005920:67125:67685 [2] NCCL INFO misc/socket.cc:47 -> 3
26: nid005920:67125:67685 [2] NCCL INFO misc/socket.cc:752 -> 3
26: nid005920:67125:67685 [2] NCCL INFO misc/socket.cc:428 -> 3
26: nid005920:67125:67685 [2] NCCL INFO misc/socket.cc:564 -> 3
26: nid005920:67125:67685 [2] NCCL INFO misc/socket.cc:668 -> 3
26: 
26: nid005920:67125:67685 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
26: nid005920:67125:168073 [2] NCCL INFO misc/socket.cc:47 -> 3
26: nid005920:67125:168073 [2] NCCL INFO misc/socket.cc:58 -> 3
26: nid005920:67125:168073 [2] NCCL INFO misc/socket.cc:775 -> 3
26: nid005920:67125:67685 [2] NCCL INFO misc/socket.cc:826 -> 3
26: 
26: nid005920:67125:67685 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
26: 
26: nid005920:67125:67685 [2] proxy.cc:1521 NCCL WARN [Proxy Service 106] Failed to execute operation Close from rank 106, retcode 3
24: nid005918:92504:194030 [0] NCCL INFO comm 0x40066d64fe00 rank 96 nranks 128 cudaDev 0 busId 901000 - Abort COMPLETE
24: nid005918:92504:194035 [0] NCCL INFO misc/socket.cc:47 -> 3
24: nid005918:92504:194035 [0] NCCL INFO misc/socket.cc:550 -> 3
24: nid005918:92504:194035 [0] NCCL INFO misc/socket.cc:573 -> 3
24: nid005918:92504:194035 [0] NCCL INFO misc/socket.cc:621 -> 3
24: nid005918:92504:93089 [0] NCCL INFO misc/socket.cc:47 -> 3
24: nid005918:92504:93089 [0] NCCL INFO misc/socket.cc:752 -> 3
24: nid005918:92504:93089 [0] NCCL INFO misc/socket.cc:428 -> 3
24: nid005918:92504:93089 [0] NCCL INFO misc/socket.cc:564 -> 3
24: nid005918:92504:93089 [0] NCCL INFO misc/socket.cc:668 -> 3
24: 
24: nid005918:92504:93089 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
24: nid005918:92504:194035 [0] NCCL INFO misc/socket.cc:47 -> 3
24: nid005918:92504:194035 [0] NCCL INFO misc/socket.cc:58 -> 3
24: nid005918:92504:194035 [0] NCCL INFO misc/socket.cc:775 -> 3
24: nid005918:92504:93089 [0] NCCL INFO misc/socket.cc:826 -> 3
24: 
24: nid005918:92504:93089 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
24: 
24: nid005918:92504:93089 [0] proxy.cc:1521 NCCL WARN [Proxy Service 96] Failed to execute operation Close from rank 96, retcode 3
27: nid005922:80744:183171 [3] NCCL INFO comm 0x40068964fe00 rank 111 nranks 128 cudaDev 3 busId 3901000 - Abort COMPLETE
27: nid005922:80744:183180 [3] NCCL INFO misc/socket.cc:47 -> 3
27: nid005922:80744:183180 [3] NCCL INFO misc/socket.cc:550 -> 3
27: nid005922:80744:183180 [3] NCCL INFO misc/socket.cc:573 -> 3
27: nid005922:80744:183180 [3] NCCL INFO misc/socket.cc:621 -> 3
27: nid005922:80744:81290 [3] NCCL INFO misc/socket.cc:47 -> 3
27: nid005922:80744:81290 [3] NCCL INFO misc/socket.cc:752 -> 3
27: nid005922:80744:81290 [3] NCCL INFO misc/socket.cc:428 -> 3
27: nid005922:80744:81290 [3] NCCL INFO misc/socket.cc:564 -> 3
27: nid005922:80744:81290 [3] NCCL INFO misc/socket.cc:668 -> 3
27: 
27: nid005922:80744:81290 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
27: nid005922:80744:183180 [3] NCCL INFO misc/socket.cc:47 -> 3
27: nid005922:80744:183180 [3] NCCL INFO misc/socket.cc:58 -> 3
27: nid005922:80744:183180 [3] NCCL INFO misc/socket.cc:775 -> 3
27: nid005922:80744:81290 [3] NCCL INFO misc/socket.cc:826 -> 3
27: 
27: nid005922:80744:81290 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
27: 
27: nid005922:80744:81290 [3] proxy.cc:1521 NCCL WARN [Proxy Service 111] Failed to execute operation Close from rank 111, retcode 3
18: nid005911:38864:140347 [0] NCCL INFO comm 0xaaaade95adc0 rank 72 nranks 128 cudaDev 0 busId 901000 - Abort COMPLETE
 1: nid005576:147559:250808 [2] NCCL INFO comm 0x40069d652920 rank 6 nranks 128 cudaDev 2 busId 2901000 - Abort COMPLETE
 1: nid005576:147559:250816 [2] NCCL INFO misc/socket.cc:47 -> 3
 1: nid005576:147559:250816 [2] NCCL INFO misc/socket.cc:550 -> 3
 1: nid005576:147559:250816 [2] NCCL INFO misc/socket.cc:573 -> 3
 1: nid005576:147559:250816 [2] NCCL INFO misc/socket.cc:621 -> 3
 1: nid005576:147559:148106 [2] NCCL INFO misc/socket.cc:47 -> 3
 1: nid005576:147559:148106 [2] NCCL INFO misc/socket.cc:752 -> 3
 1: nid005576:147559:148106 [2] NCCL INFO misc/socket.cc:428 -> 3
 1: nid005576:147559:148106 [2] NCCL INFO misc/socket.cc:564 -> 3
 1: nid005576:147559:148106 [2] NCCL INFO misc/socket.cc:668 -> 3
 1: 
 1: nid005576:147559:148106 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 1: nid005576:147559:250816 [2] NCCL INFO misc/socket.cc:47 -> 3
 1: nid005576:147559:250816 [2] NCCL INFO misc/socket.cc:58 -> 3
 1: nid005576:147559:250816 [2] NCCL INFO misc/socket.cc:775 -> 3
 1: nid005576:147559:148106 [2] NCCL INFO misc/socket.cc:826 -> 3
 1: 
 1: nid005576:147559:148106 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
 1: 
 1: nid005576:147559:148106 [2] proxy.cc:1521 NCCL WARN [Proxy Service 6] Failed to execute operation Close from rank 6, retcode 3
17: nid005803:180733:283753 [1] NCCL INFO comm 0x40069164fa60 rank 69 nranks 128 cudaDev 1 busId 1901000 - Abort COMPLETE
17: nid005803:180733:283763 [1] NCCL INFO misc/socket.cc:47 -> 3
17: nid005803:180733:283763 [1] NCCL INFO misc/socket.cc:550 -> 3
17: nid005803:180733:283763 [1] NCCL INFO misc/socket.cc:573 -> 3
17: nid005803:180733:283763 [1] NCCL INFO misc/socket.cc:621 -> 3
17: nid005803:180733:181291 [1] NCCL INFO misc/socket.cc:47 -> 3
17: nid005803:180733:181291 [1] NCCL INFO misc/socket.cc:752 -> 3
17: nid005803:180733:181291 [1] NCCL INFO misc/socket.cc:428 -> 3
17: nid005803:180733:181291 [1] NCCL INFO misc/socket.cc:564 -> 3
17: nid005803:180733:181291 [1] NCCL INFO misc/socket.cc:668 -> 3
17: 
17: nid005803:180733:181291 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
17: nid005803:180733:283763 [1] NCCL INFO misc/socket.cc:47 -> 3
17: nid005803:180733:283763 [1] NCCL INFO misc/socket.cc:58 -> 3
17: nid005803:180733:283763 [1] NCCL INFO misc/socket.cc:775 -> 3
17: nid005803:180733:181291 [1] NCCL INFO misc/socket.cc:826 -> 3
17: 
17: nid005803:180733:181291 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
17: 
17: nid005803:180733:181291 [1] proxy.cc:1521 NCCL WARN [Proxy Service 69] Failed to execute operation Close from rank 69, retcode 3
13: nid005595:197883:6865 [0] NCCL INFO comm 0x40068164e880 rank 52 nranks 128 cudaDev 0 busId 901000 - Abort COMPLETE
13: nid005595:197883:6878 [0] NCCL INFO misc/socket.cc:47 -> 3
13: nid005595:197883:6878 [0] NCCL INFO misc/socket.cc:550 -> 3
13: nid005595:197883:6878 [0] NCCL INFO misc/socket.cc:573 -> 3
13: nid005595:197883:6878 [0] NCCL INFO misc/socket.cc:621 -> 3
13: nid005595:197883:198479 [0] NCCL INFO misc/socket.cc:47 -> 3
13: nid005595:197883:198479 [0] NCCL INFO misc/socket.cc:752 -> 3
13: nid005595:197883:198479 [0] NCCL INFO misc/socket.cc:428 -> 3
13: nid005595:197883:198479 [0] NCCL INFO misc/socket.cc:564 -> 3
13: nid005595:197883:198479 [0] NCCL INFO misc/socket.cc:668 -> 3
13: 
13: nid005595:197883:198479 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
13: nid005595:197883:6878 [0] NCCL INFO misc/socket.cc:47 -> 3
13: nid005595:197883:198479 [0] NCCL INFO misc/socket.cc:826 -> 3
13: 
13: nid005595:197883:198479 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
13: 
13: nid005595:197883:198479 [0] proxy.cc:1521 NCCL WARN [Proxy Service 52] Failed to execute operation Close from rank 52, retcode 3
13: nid005595:197883:6878 [0] NCCL INFO misc/socket.cc:58 -> 3
13: nid005595:197883:6878 [0] NCCL INFO misc/socket.cc:775 -> 3
13: nid005595:197885:6862 [2] NCCL INFO comm 0x4006a96528c0 rank 54 nranks 128 cudaDev 2 busId 2901000 - Abort COMPLETE
13: nid005595:197885:6879 [2] NCCL INFO misc/socket.cc:47 -> 3
13: nid005595:197885:6879 [2] NCCL INFO misc/socket.cc:550 -> 3
13: nid005595:197885:6879 [2] NCCL INFO misc/socket.cc:573 -> 3
13: nid005595:197885:6879 [2] NCCL INFO misc/socket.cc:621 -> 3
13: nid005595:197885:198478 [2] NCCL INFO misc/socket.cc:47 -> 3
13: nid005595:197885:198478 [2] NCCL INFO misc/socket.cc:752 -> 3
13: nid005595:197885:198478 [2] NCCL INFO misc/socket.cc:428 -> 3
13: nid005595:197885:198478 [2] NCCL INFO misc/socket.cc:564 -> 3
13: nid005595:197885:198478 [2] NCCL INFO misc/socket.cc:668 -> 3
13: nid005595:197885:6879 [2] NCCL INFO misc/socket.cc:47 -> 3
13: nid005595:197885:6879 [2] NCCL INFO misc/socket.cc:58 -> 3
13: nid005595:197885:6879 [2] NCCL INFO misc/socket.cc:775 -> 3
13: 
13: nid005595:197885:198478 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
13: nid005595:197885:198478 [2] NCCL INFO misc/socket.cc:826 -> 3
13: 
13: nid005595:197885:198478 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
13: 
13: nid005595:197885:198478 [2] proxy.cc:1521 NCCL WARN [Proxy Service 54] Failed to execute operation Close from rank 54, retcode 3
11: nid005591:191605:294874 [2] NCCL INFO comm 0xaaaafb513f80 rank 46 nranks 128 cudaDev 2 busId 2901000 - Abort COMPLETE
22: nid005915:274817:84249 [3] NCCL INFO comm 0x4006ad651330 rank 91 nranks 128 cudaDev 3 busId 3901000 - Abort COMPLETE
20: nid005913:292684:101211 [3] NCCL INFO comm 0x40069164e900 rank 83 nranks 128 cudaDev 3 busId 3901000 - Abort COMPLETE
22: nid005915:274817:84253 [3] NCCL INFO misc/socket.cc:47 -> 3
22: nid005915:274817:84253 [3] NCCL INFO misc/socket.cc:550 -> 3
22: nid005915:274817:84253 [3] NCCL INFO misc/socket.cc:573 -> 3
22: nid005915:274817:84253 [3] NCCL INFO misc/socket.cc:621 -> 3
20: nid005913:292684:101215 [3] NCCL INFO misc/socket.cc:47 -> 3
20: nid005913:292684:101215 [3] NCCL INFO misc/socket.cc:550 -> 3
20: nid005913:292684:101215 [3] NCCL INFO misc/socket.cc:573 -> 3
20: nid005913:292684:101215 [3] NCCL INFO misc/socket.cc:621 -> 3
22: nid005915:274817:275360 [3] NCCL INFO misc/socket.cc:47 -> 3
22: nid005915:274817:275360 [3] NCCL INFO misc/socket.cc:752 -> 3
22: nid005915:274817:275360 [3] NCCL INFO misc/socket.cc:428 -> 3
22: nid005915:274817:275360 [3] NCCL INFO misc/socket.cc:564 -> 3
22: nid005915:274817:275360 [3] NCCL INFO misc/socket.cc:668 -> 3
20: nid005913:292684:293226 [3] NCCL INFO misc/socket.cc:47 -> 3
20: nid005913:292684:293226 [3] NCCL INFO misc/socket.cc:752 -> 3
20: nid005913:292684:293226 [3] NCCL INFO misc/socket.cc:428 -> 3
20: nid005913:292684:293226 [3] NCCL INFO misc/socket.cc:564 -> 3
20: nid005913:292684:293226 [3] NCCL INFO misc/socket.cc:668 -> 3
22: 
22: nid005915:274817:275360 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
20: 
20: nid005913:292684:293226 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
22: nid005915:274817:84253 [3] NCCL INFO misc/socket.cc:47 -> 3
22: nid005915:274817:84253 [3] NCCL INFO misc/socket.cc:58 -> 3
22: nid005915:274817:84253 [3] NCCL INFO misc/socket.cc:775 -> 3
22: nid005915:274817:275360 [3] NCCL INFO misc/socket.cc:826 -> 3
20: nid005913:292684:101215 [3] NCCL INFO misc/socket.cc:47 -> 3
20: nid005913:292684:101215 [3] NCCL INFO misc/socket.cc:58 -> 3
20: nid005913:292684:101215 [3] NCCL INFO misc/socket.cc:775 -> 3
22: 
22: nid005915:274817:275360 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
22: 
22: nid005915:274817:275360 [3] proxy.cc:1521 NCCL WARN [Proxy Service 91] Failed to execute operation Close from rank 91, retcode 3
20: nid005913:292684:293226 [3] NCCL INFO misc/socket.cc:826 -> 3
20: 
20: nid005913:292684:293226 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
20: 
20: nid005913:292684:293226 [3] proxy.cc:1521 NCCL WARN [Proxy Service 83] Failed to execute operation Close from rank 83, retcode 3
 8: nid005586:68927:170708 [1] NCCL INFO comm 0x40066ca89660 rank 33 nranks 128 cudaDev 1 busId 1901000 - Abort COMPLETE
 8: nid005586:68927:170715 [1] NCCL INFO misc/socket.cc:47 -> 3
 8: nid005586:68927:170715 [1] NCCL INFO misc/socket.cc:550 -> 3
 8: nid005586:68927:170715 [1] NCCL INFO misc/socket.cc:573 -> 3
 8: nid005586:68927:170715 [1] NCCL INFO misc/socket.cc:621 -> 3
 8: nid005586:68927:69492 [1] NCCL INFO misc/socket.cc:47 -> 3
 8: nid005586:68927:69492 [1] NCCL INFO misc/socket.cc:752 -> 3
 8: nid005586:68927:69492 [1] NCCL INFO misc/socket.cc:428 -> 3
 8: nid005586:68927:69492 [1] NCCL INFO misc/socket.cc:564 -> 3
 8: nid005586:68927:69492 [1] NCCL INFO misc/socket.cc:668 -> 3
 8: 
 8: nid005586:68927:69492 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 8: nid005586:68927:170715 [1] NCCL INFO misc/socket.cc:47 -> 3
 8: nid005586:68927:170715 [1] NCCL INFO misc/socket.cc:58 -> 3
 8: nid005586:68927:170715 [1] NCCL INFO misc/socket.cc:775 -> 3
 8: nid005586:68927:69492 [1] NCCL INFO misc/socket.cc:826 -> 3
 8: 
 8: nid005586:68927:69492 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
 8: 
 8: nid005586:68927:69492 [1] proxy.cc:1521 NCCL WARN [Proxy Service 33] Failed to execute operation Close from rank 33, retcode 3
 3: nid005580:71820:174881 [1] NCCL INFO comm 0x4006b564e160 rank 13 nranks 128 cudaDev 1 busId 1901000 - Abort COMPLETE
 3: nid005580:71820:174888 [1] NCCL INFO misc/socket.cc:47 -> 3
 3: nid005580:71820:174888 [1] NCCL INFO misc/socket.cc:550 -> 3
 3: nid005580:71820:174888 [1] NCCL INFO misc/socket.cc:573 -> 3
 3: nid005580:71820:174888 [1] NCCL INFO misc/socket.cc:621 -> 3
 3: nid005580:71820:72363 [1] NCCL INFO misc/socket.cc:47 -> 3
 3: nid005580:71820:72363 [1] NCCL INFO misc/socket.cc:752 -> 3
 3: nid005580:71820:72363 [1] NCCL INFO misc/socket.cc:428 -> 3
 3: nid005580:71820:72363 [1] NCCL INFO misc/socket.cc:564 -> 3
 3: nid005580:71820:72363 [1] NCCL INFO misc/socket.cc:668 -> 3
 3: 
 3: nid005580:71820:72363 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 3: nid005580:71820:174888 [1] NCCL INFO misc/socket.cc:47 -> 3
 3: nid005580:71820:174888 [1] NCCL INFO misc/socket.cc:58 -> 3
 3: nid005580:71820:174888 [1] NCCL INFO misc/socket.cc:775 -> 3
 3: nid005580:71820:72363 [1] NCCL INFO misc/socket.cc:826 -> 3
 3: 
 3: nid005580:71820:72363 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
 3: 
 3: nid005580:71820:72363 [1] proxy.cc:1521 NCCL WARN [Proxy Service 13] Failed to execute operation Close from rank 13, retcode 3
 7: nid005585:122008:225046 [3] NCCL INFO comm 0x4006956513a0 rank 31 nranks 128 cudaDev 3 busId 3901000 - Abort COMPLETE
 7: nid005585:122008:225051 [3] NCCL INFO misc/socket.cc:47 -> 3
 7: nid005585:122008:225051 [3] NCCL INFO misc/socket.cc:550 -> 3
 7: nid005585:122008:225051 [3] NCCL INFO misc/socket.cc:573 -> 3
 7: nid005585:122008:225051 [3] NCCL INFO misc/socket.cc:621 -> 3
 7: nid005585:122008:122548 [3] NCCL INFO misc/socket.cc:47 -> 3
 7: nid005585:122008:122548 [3] NCCL INFO misc/socket.cc:752 -> 3
 7: nid005585:122008:122548 [3] NCCL INFO misc/socket.cc:428 -> 3
 7: nid005585:122008:122548 [3] NCCL INFO misc/socket.cc:564 -> 3
 7: nid005585:122008:122548 [3] NCCL INFO misc/socket.cc:668 -> 3
 7: 
 7: nid005585:122008:122548 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 7: nid005585:122008:225051 [3] NCCL INFO misc/socket.cc:47 -> 3
 7: nid005585:122008:225051 [3] NCCL INFO misc/socket.cc:58 -> 3
 7: nid005585:122008:225051 [3] NCCL INFO misc/socket.cc:775 -> 3
 7: nid005585:122008:122548 [3] NCCL INFO misc/socket.cc:826 -> 3
 7: 
 7: nid005585:122008:122548 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
 7: 
 7: nid005585:122008:122548 [3] proxy.cc:1521 NCCL WARN [Proxy Service 31] Failed to execute operation Close from rank 31, retcode 3
15: nid005601:210677:18854 [1] NCCL INFO comm 0x40068d64fdf0 rank 61 nranks 128 cudaDev 1 busId 1901000 - Abort COMPLETE
15: nid005601:210677:18857 [1] NCCL INFO misc/socket.cc:47 -> 3
15: nid005601:210677:18857 [1] NCCL INFO misc/socket.cc:550 -> 3
15: nid005601:210677:18857 [1] NCCL INFO misc/socket.cc:573 -> 3
15: nid005601:210677:18857 [1] NCCL INFO misc/socket.cc:621 -> 3
15: nid005601:210677:211240 [1] NCCL INFO misc/socket.cc:47 -> 3
15: nid005601:210677:211240 [1] NCCL INFO misc/socket.cc:752 -> 3
15: nid005601:210677:211240 [1] NCCL INFO misc/socket.cc:428 -> 3
15: nid005601:210677:211240 [1] NCCL INFO misc/socket.cc:564 -> 3
15: nid005601:210677:211240 [1] NCCL INFO misc/socket.cc:668 -> 3
15: 
15: nid005601:210677:211240 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
15: nid005601:210677:18857 [1] NCCL INFO misc/socket.cc:47 -> 3
15: nid005601:210677:18857 [1] NCCL INFO misc/socket.cc:58 -> 3
15: nid005601:210677:18857 [1] NCCL INFO misc/socket.cc:775 -> 3
15: nid005601:210677:211240 [1] NCCL INFO misc/socket.cc:826 -> 3
15: 
15: nid005601:210677:211240 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
15: 
15: nid005601:210677:211240 [1] proxy.cc:1521 NCCL WARN [Proxy Service 61] Failed to execute operation Close from rank 61, retcode 3
24: nid005918:92506:194034 [2] NCCL INFO comm 0xaaab22641a60 rank 98 nranks 128 cudaDev 2 busId 2901000 - Abort COMPLETE
14: nid005600:217720:26918 [0] NCCL INFO comm 0xaaaadc9bcbc0 rank 56 nranks 128 cudaDev 0 busId 901000 - Abort COMPLETE
11: nid005591:191604:294864 [1] NCCL INFO comm 0x4006a564fd80 rank 45 nranks 128 cudaDev 1 busId 1901000 - Abort COMPLETE
11: nid005591:191604:294878 [1] NCCL INFO misc/socket.cc:47 -> 3
11: nid005591:191604:294878 [1] NCCL INFO misc/socket.cc:550 -> 3
11: nid005591:191604:294878 [1] NCCL INFO misc/socket.cc:573 -> 3
11: nid005591:191604:294878 [1] NCCL INFO misc/socket.cc:621 -> 3
11: nid005591:191604:192148 [1] NCCL INFO misc/socket.cc:47 -> 3
11: nid005591:191604:192148 [1] NCCL INFO misc/socket.cc:752 -> 3
11: nid005591:191604:192148 [1] NCCL INFO misc/socket.cc:428 -> 3
11: nid005591:191604:192148 [1] NCCL INFO misc/socket.cc:564 -> 3
11: nid005591:191604:192148 [1] NCCL INFO misc/socket.cc:668 -> 3
11: 
11: nid005591:191604:192148 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
11: nid005591:191604:294878 [1] NCCL INFO misc/socket.cc:47 -> 3
11: nid005591:191604:294878 [1] NCCL INFO misc/socket.cc:58 -> 3
11: nid005591:191604:294878 [1] NCCL INFO misc/socket.cc:775 -> 3
11: nid005591:191604:192148 [1] NCCL INFO misc/socket.cc:826 -> 3
11: 
11: nid005591:191604:192148 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
11: 
11: nid005591:191604:192148 [1] proxy.cc:1521 NCCL WARN [Proxy Service 45] Failed to execute operation Close from rank 45, retcode 3
 7: nid005585:122005:225048 [0] NCCL INFO comm 0xaaab166fca20 rank 28 nranks 128 cudaDev 0 busId 901000 - Abort COMPLETE
 9: nid005588:35938:138382 [3] NCCL INFO comm 0x40069164fe00 rank 39 nranks 128 cudaDev 3 busId 3901000 - Abort COMPLETE
 9: nid005588:35938:138387 [3] NCCL INFO misc/socket.cc:47 -> 3
 9: nid005588:35938:138387 [3] NCCL INFO misc/socket.cc:550 -> 3
 9: nid005588:35938:138387 [3] NCCL INFO misc/socket.cc:573 -> 3
 9: nid005588:35938:138387 [3] NCCL INFO misc/socket.cc:621 -> 3
 9: nid005588:35938:36502 [3] NCCL INFO misc/socket.cc:47 -> 3
 9: nid005588:35938:36502 [3] NCCL INFO misc/socket.cc:752 -> 3
 9: nid005588:35938:36502 [3] NCCL INFO misc/socket.cc:428 -> 3
 9: nid005588:35938:36502 [3] NCCL INFO misc/socket.cc:564 -> 3
 9: nid005588:35938:36502 [3] NCCL INFO misc/socket.cc:668 -> 3
 9: 
 9: nid005588:35938:36502 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 9: nid005588:35938:138387 [3] NCCL INFO misc/socket.cc:47 -> 3
 9: nid005588:35938:138387 [3] NCCL INFO misc/socket.cc:58 -> 3
 9: nid005588:35938:138387 [3] NCCL INFO misc/socket.cc:775 -> 3
 9: nid005588:35938:36502 [3] NCCL INFO misc/socket.cc:826 -> 3
 9: 
 9: nid005588:35938:36502 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
 9: 
 9: nid005588:35938:36502 [3] proxy.cc:1521 NCCL WARN [Proxy Service 39] Failed to execute operation Close from rank 39, retcode 3
 8: nid005586:68929:170709 [3] NCCL INFO comm 0x4006b8a880b0 rank 35 nranks 128 cudaDev 3 busId 3901000 - Abort COMPLETE
 8: nid005586:68929:170716 [3] NCCL INFO misc/socket.cc:47 -> 3
 8: nid005586:68929:170716 [3] NCCL INFO misc/socket.cc:550 -> 3
 8: nid005586:68929:170716 [3] NCCL INFO misc/socket.cc:573 -> 3
 8: nid005586:68929:170716 [3] NCCL INFO misc/socket.cc:621 -> 3
 8: nid005586:68929:69491 [3] NCCL INFO misc/socket.cc:47 -> 3
 8: nid005586:68929:69491 [3] NCCL INFO misc/socket.cc:752 -> 3
 8: nid005586:68929:69491 [3] NCCL INFO misc/socket.cc:428 -> 3
 8: nid005586:68929:69491 [3] NCCL INFO misc/socket.cc:564 -> 3
 8: nid005586:68929:69491 [3] NCCL INFO misc/socket.cc:668 -> 3
 8: 
 8: nid005586:68929:69491 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 8: nid005586:68929:170716 [3] NCCL INFO misc/socket.cc:47 -> 3
 8: nid005586:68929:170716 [3] NCCL INFO misc/socket.cc:58 -> 3
 8: nid005586:68929:170716 [3] NCCL INFO misc/socket.cc:775 -> 3
 8: nid005586:68929:69491 [3] NCCL INFO misc/socket.cc:826 -> 3
 8: 
 8: nid005586:68929:69491 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
 8: 
 8: nid005586:68929:69491 [3] proxy.cc:1521 NCCL WARN [Proxy Service 35] Failed to execute operation Close from rank 35, retcode 3
24: nid005918:92507:194033 [3] NCCL INFO comm 0xaaaae09e21b0 rank 99 nranks 128 cudaDev 3 busId 3901000 - Abort COMPLETE
31: nid005937:256592:65762 [3] NCCL INFO comm 0x400674a86b00 rank 127 nranks 128 cudaDev 3 busId 3901000 - Abort COMPLETE
31: nid005937:256592:65772 [3] NCCL INFO misc/socket.cc:47 -> 3
31: nid005937:256592:65772 [3] NCCL INFO misc/socket.cc:550 -> 3
31: nid005937:256592:65772 [3] NCCL INFO misc/socket.cc:573 -> 3
31: nid005937:256592:65772 [3] NCCL INFO misc/socket.cc:621 -> 3
31: nid005937:256592:257151 [3] NCCL INFO misc/socket.cc:47 -> 3
31: nid005937:256592:257151 [3] NCCL INFO misc/socket.cc:752 -> 3
31: nid005937:256592:257151 [3] NCCL INFO misc/socket.cc:428 -> 3
31: nid005937:256592:257151 [3] NCCL INFO misc/socket.cc:564 -> 3
31: nid005937:256592:257151 [3] NCCL INFO misc/socket.cc:668 -> 3
31: 
31: nid005937:256592:257151 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
31: nid005937:256592:65772 [3] NCCL INFO misc/socket.cc:47 -> 3
31: nid005937:256592:65772 [3] NCCL INFO misc/socket.cc:58 -> 3
31: nid005937:256592:65772 [3] NCCL INFO misc/socket.cc:775 -> 3
31: nid005937:256592:257151 [3] NCCL INFO misc/socket.cc:826 -> 3
31: 
31: nid005937:256592:257151 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
31: 
31: nid005937:256592:257151 [3] proxy.cc:1521 NCCL WARN [Proxy Service 127] Failed to execute operation Close from rank 127, retcode 3
10: nid005590:110710:213919 [0] NCCL INFO comm 0xaaab23d6b530 rank 40 nranks 128 cudaDev 0 busId 901000 - Abort COMPLETE
 7: nid005585:122007:225050 [2] NCCL INFO comm 0xaaaadd869ba0 rank 30 nranks 128 cudaDev 2 busId 2901000 - Abort COMPLETE
31: nid005937:256590:65765 [1] NCCL INFO comm 0x400691651360 rank 125 nranks 128 cudaDev 1 busId 1901000 - Abort COMPLETE
31: nid005937:256590:65773 [1] NCCL INFO misc/socket.cc:47 -> 3
31: nid005937:256590:65773 [1] NCCL INFO misc/socket.cc:550 -> 3
31: nid005937:256590:65773 [1] NCCL INFO misc/socket.cc:573 -> 3
31: nid005937:256590:65773 [1] NCCL INFO misc/socket.cc:621 -> 3
31: nid005937:256590:257152 [1] NCCL INFO misc/socket.cc:47 -> 3
31: nid005937:256590:257152 [1] NCCL INFO misc/socket.cc:752 -> 3
31: nid005937:256590:257152 [1] NCCL INFO misc/socket.cc:428 -> 3
31: nid005937:256590:257152 [1] NCCL INFO misc/socket.cc:564 -> 3
31: nid005937:256590:257152 [1] NCCL INFO misc/socket.cc:668 -> 3
31: 
31: nid005937:256590:257152 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
31: nid005937:256590:65773 [1] NCCL INFO misc/socket.cc:47 -> 3
31: nid005937:256590:65773 [1] NCCL INFO misc/socket.cc:58 -> 3
31: nid005937:256590:257152 [1] NCCL INFO misc/socket.cc:826 -> 3
31: 
31: nid005937:256590:257152 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
31: 
31: nid005937:256590:257152 [1] proxy.cc:1521 NCCL WARN [Proxy Service 125] Failed to execute operation Close from rank 125, retcode 3
31: nid005937:256590:65773 [1] NCCL INFO misc/socket.cc:775 -> 3
26: nid005920:67124:168069 [1] NCCL INFO comm 0xaaab0de132b0 rank 105 nranks 128 cudaDev 1 busId 1901000 - Abort COMPLETE
 4: nid005581:264525:72355 [2] NCCL INFO comm 0x40069564fe00 rank 18 nranks 128 cudaDev 2 busId 2901000 - Abort COMPLETE
 4: nid005581:264525:72362 [2] NCCL INFO misc/socket.cc:47 -> 3
 4: nid005581:264525:72362 [2] NCCL INFO misc/socket.cc:550 -> 3
 4: nid005581:264525:72362 [2] NCCL INFO misc/socket.cc:573 -> 3
 4: nid005581:264525:72362 [2] NCCL INFO misc/socket.cc:621 -> 3
 4: nid005581:264525:265070 [2] NCCL INFO misc/socket.cc:47 -> 3
 4: nid005581:264525:265070 [2] NCCL INFO misc/socket.cc:752 -> 3
 4: nid005581:264525:265070 [2] NCCL INFO misc/socket.cc:428 -> 3
 4: nid005581:264525:265070 [2] NCCL INFO misc/socket.cc:564 -> 3
 4: nid005581:264525:265070 [2] NCCL INFO misc/socket.cc:668 -> 3
 4: 
 4: nid005581:264525:265070 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 4: nid005581:264525:72362 [2] NCCL INFO misc/socket.cc:47 -> 3
 4: nid005581:264525:72362 [2] NCCL INFO misc/socket.cc:58 -> 3
 4: nid005581:264525:72362 [2] NCCL INFO misc/socket.cc:775 -> 3
 4: nid005581:264525:265070 [2] NCCL INFO misc/socket.cc:826 -> 3
 4: 
 4: nid005581:264525:265070 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
 4: 
 4: nid005581:264525:265070 [2] proxy.cc:1521 NCCL WARN [Proxy Service 18] Failed to execute operation Close from rank 18, retcode 3
22: nid005915:274815:84250 [1] NCCL INFO comm 0x40069d64f9d0 rank 89 nranks 128 cudaDev 1 busId 1901000 - Abort COMPLETE
22: nid005915:274815:84254 [1] NCCL INFO misc/socket.cc:47 -> 3
22: nid005915:274815:84254 [1] NCCL INFO misc/socket.cc:550 -> 3
22: nid005915:274815:84254 [1] NCCL INFO misc/socket.cc:573 -> 3
22: nid005915:274815:84254 [1] NCCL INFO misc/socket.cc:621 -> 3
22: nid005915:274815:275364 [1] NCCL INFO misc/socket.cc:47 -> 3
22: nid005915:274815:275364 [1] NCCL INFO misc/socket.cc:752 -> 3
22: nid005915:274815:275364 [1] NCCL INFO misc/socket.cc:428 -> 3
22: nid005915:274815:275364 [1] NCCL INFO misc/socket.cc:564 -> 3
22: nid005915:274815:275364 [1] NCCL INFO misc/socket.cc:668 -> 3
22: 
22: nid005915:274815:275364 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
22: nid005915:274815:84254 [1] NCCL INFO misc/socket.cc:47 -> 3
22: nid005915:274815:84254 [1] NCCL INFO misc/socket.cc:58 -> 3
22: nid005915:274815:84254 [1] NCCL INFO misc/socket.cc:775 -> 3
22: nid005915:274815:275364 [1] NCCL INFO misc/socket.cc:826 -> 3
22: 
22: nid005915:274815:275364 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
22: 
22: nid005915:274815:275364 [1] proxy.cc:1521 NCCL WARN [Proxy Service 89] Failed to execute operation Close from rank 89, retcode 3
 9: nid005588:35936:138383 [1] NCCL INFO comm 0x400698a89620 rank 37 nranks 128 cudaDev 1 busId 1901000 - Abort COMPLETE
 9: nid005588:35936:138388 [1] NCCL INFO misc/socket.cc:47 -> 3
 9: nid005588:35936:138388 [1] NCCL INFO misc/socket.cc:550 -> 3
 9: nid005588:35936:138388 [1] NCCL INFO misc/socket.cc:573 -> 3
 9: nid005588:35936:138388 [1] NCCL INFO misc/socket.cc:621 -> 3
 9: nid005588:35936:36500 [1] NCCL INFO misc/socket.cc:47 -> 3
 9: nid005588:35936:36500 [1] NCCL INFO misc/socket.cc:752 -> 3
 9: nid005588:35936:36500 [1] NCCL INFO misc/socket.cc:428 -> 3
 9: nid005588:35936:36500 [1] NCCL INFO misc/socket.cc:564 -> 3
 9: nid005588:35936:36500 [1] NCCL INFO misc/socket.cc:668 -> 3
 9: 
 9: nid005588:35936:36500 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 9: nid005588:35936:138388 [1] NCCL INFO misc/socket.cc:47 -> 3
 9: nid005588:35936:138388 [1] NCCL INFO misc/socket.cc:58 -> 3
 9: nid005588:35936:138388 [1] NCCL INFO misc/socket.cc:775 -> 3
 9: nid005588:35936:36500 [1] NCCL INFO misc/socket.cc:826 -> 3
 9: 
 9: nid005588:35936:36500 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
 9: 
 9: nid005588:35936:36500 [1] proxy.cc:1521 NCCL WARN [Proxy Service 37] Failed to execute operation Close from rank 37, retcode 3
 4: nid005581:264523:72359 [0] NCCL INFO comm 0xaaaafba8b880 rank 16 nranks 128 cudaDev 0 busId 901000 - Abort COMPLETE
15: nid005601:210676:18852 [0] NCCL INFO comm 0x40068164fe00 rank 60 nranks 128 cudaDev 0 busId 901000 - Abort COMPLETE
15: nid005601:210676:18858 [0] NCCL INFO misc/socket.cc:47 -> 3
15: nid005601:210676:18858 [0] NCCL INFO misc/socket.cc:550 -> 3
15: nid005601:210676:18858 [0] NCCL INFO misc/socket.cc:573 -> 3
15: nid005601:210676:18858 [0] NCCL INFO misc/socket.cc:621 -> 3
15: nid005601:210676:211237 [0] NCCL INFO misc/socket.cc:47 -> 3
15: nid005601:210676:211237 [0] NCCL INFO misc/socket.cc:752 -> 3
15: nid005601:210676:211237 [0] NCCL INFO misc/socket.cc:428 -> 3
15: nid005601:210676:211237 [0] NCCL INFO misc/socket.cc:564 -> 3
15: nid005601:210676:211237 [0] NCCL INFO misc/socket.cc:668 -> 3
15: 
15: nid005601:210676:211237 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
15: nid005601:210676:18858 [0] NCCL INFO misc/socket.cc:47 -> 3
15: nid005601:210676:18858 [0] NCCL INFO misc/socket.cc:58 -> 3
15: nid005601:210676:211237 [0] NCCL INFO misc/socket.cc:826 -> 3
15: 
15: nid005601:210676:211237 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
15: 
15: nid005601:210676:211237 [0] proxy.cc:1521 NCCL WARN [Proxy Service 60] Failed to execute operation Close from rank 60, retcode 3
15: nid005601:210676:18858 [0] NCCL INFO misc/socket.cc:775 -> 3
28: nid005929:16033:116163 [3] NCCL INFO comm 0x4006b164fdc0 rank 115 nranks 128 cudaDev 3 busId 3901000 - Abort COMPLETE
28: nid005929:16033:116169 [3] NCCL INFO misc/socket.cc:47 -> 3
28: nid005929:16033:116169 [3] NCCL INFO misc/socket.cc:550 -> 3
28: nid005929:16033:116169 [3] NCCL INFO misc/socket.cc:573 -> 3
28: nid005929:16033:116169 [3] NCCL INFO misc/socket.cc:621 -> 3
28: nid005929:16033:16576 [3] NCCL INFO misc/socket.cc:47 -> 3
28: nid005929:16033:16576 [3] NCCL INFO misc/socket.cc:752 -> 3
28: nid005929:16033:16576 [3] NCCL INFO misc/socket.cc:428 -> 3
28: nid005929:16033:16576 [3] NCCL INFO misc/socket.cc:564 -> 3
28: nid005929:16033:16576 [3] NCCL INFO misc/socket.cc:668 -> 3
28: 
28: nid005929:16033:16576 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
28: nid005929:16033:116169 [3] NCCL INFO misc/socket.cc:47 -> 3
28: nid005929:16033:116169 [3] NCCL INFO misc/socket.cc:58 -> 3
28: nid005929:16033:116169 [3] NCCL INFO misc/socket.cc:775 -> 3
28: nid005929:16033:16576 [3] NCCL INFO misc/socket.cc:826 -> 3
28: 
28: nid005929:16033:16576 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
28: 
28: nid005929:16033:16576 [3] proxy.cc:1521 NCCL WARN [Proxy Service 115] Failed to execute operation Close from rank 115, retcode 3
25: nid005919:107464:211237 [2] NCCL INFO comm 0x4006b564e420 rank 102 nranks 128 cudaDev 2 busId 2901000 - Abort COMPLETE
25: nid005919:107464:211247 [2] NCCL INFO misc/socket.cc:47 -> 3
25: nid005919:107464:211247 [2] NCCL INFO misc/socket.cc:550 -> 3
25: nid005919:107464:211247 [2] NCCL INFO misc/socket.cc:573 -> 3
25: nid005919:107464:211247 [2] NCCL INFO misc/socket.cc:621 -> 3
25: nid005919:107464:108032 [2] NCCL INFO misc/socket.cc:47 -> 3
25: nid005919:107464:108032 [2] NCCL INFO misc/socket.cc:752 -> 3
25: nid005919:107464:108032 [2] NCCL INFO misc/socket.cc:428 -> 3
25: nid005919:107464:108032 [2] NCCL INFO misc/socket.cc:564 -> 3
25: nid005919:107464:108032 [2] NCCL INFO misc/socket.cc:668 -> 3
25: 
25: nid005919:107464:108032 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
25: nid005919:107464:211247 [2] NCCL INFO misc/socket.cc:47 -> 3
25: nid005919:107464:211247 [2] NCCL INFO misc/socket.cc:58 -> 3
25: nid005919:107464:211247 [2] NCCL INFO misc/socket.cc:775 -> 3
25: nid005919:107464:108032 [2] NCCL INFO misc/socket.cc:826 -> 3
25: 
25: nid005919:107464:108032 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0
25: 
25: nid005919:107464:108032 [2] proxy.cc:1521 NCCL WARN [Proxy Service 102] Failed to execute operation Close from rank 102, retcode 3
21: nid005914:166784:269598 [0] NCCL INFO comm 0xaaab092dcbd0 rank 84 nranks 128 cudaDev 0 busId 901000 - Abort COMPLETE
18: nid005911:38867:140344 [3] NCCL INFO comm 0x40068964e420 rank 75 nranks 128 cudaDev 3 busId 3901000 - Abort COMPLETE
18: nid005911:38867:140354 [3] NCCL INFO misc/socket.cc:47 -> 3
18: nid005911:38867:140354 [3] NCCL INFO misc/socket.cc:550 -> 3
18: nid005911:38867:140354 [3] NCCL INFO misc/socket.cc:573 -> 3
18: nid005911:38867:140354 [3] NCCL INFO misc/socket.cc:621 -> 3
18: nid005911:38867:39427 [3] NCCL INFO misc/socket.cc:47 -> 3
18: nid005911:38867:39427 [3] NCCL INFO misc/socket.cc:752 -> 3
18: nid005911:38867:39427 [3] NCCL INFO misc/socket.cc:428 -> 3
18: nid005911:38867:39427 [3] NCCL INFO misc/socket.cc:564 -> 3
18: nid005911:38867:39427 [3] NCCL INFO misc/socket.cc:668 -> 3
18: 
18: nid005911:38867:39427 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
18: nid005911:38867:140354 [3] NCCL INFO misc/socket.cc:47 -> 3
18: nid005911:38867:140354 [3] NCCL INFO misc/socket.cc:58 -> 3
18: nid005911:38867:140354 [3] NCCL INFO misc/socket.cc:775 -> 3
18: nid005911:38867:39427 [3] NCCL INFO misc/socket.cc:826 -> 3
18: 
18: nid005911:38867:39427 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0
18: 
18: nid005911:38867:39427 [3] proxy.cc:1521 NCCL WARN [Proxy Service 75] Failed to execute operation Close from rank 75, retcode 3
28: nid005929:16030:116167 [0] NCCL INFO comm 0xaaaad57d3fc0 rank 112 nranks 128 cudaDev 0 busId 901000 - Abort COMPLETE
20: nid005913:292682:101209 [1] NCCL INFO comm 0x40066964fdf0 rank 81 nranks 128 cudaDev 1 busId 1901000 - Abort COMPLETE
20: nid005913:292682:101216 [1] NCCL INFO misc/socket.cc:47 -> 3
20: nid005913:292682:101216 [1] NCCL INFO misc/socket.cc:550 -> 3
20: nid005913:292682:101216 [1] NCCL INFO misc/socket.cc:573 -> 3
20: nid005913:292682:101216 [1] NCCL INFO misc/socket.cc:621 -> 3
20: nid005913:292682:293228 [1] NCCL INFO misc/socket.cc:47 -> 3
20: nid005913:292682:293228 [1] NCCL INFO misc/socket.cc:752 -> 3
20: nid005913:292682:293228 [1] NCCL INFO misc/socket.cc:428 -> 3
20: nid005913:292682:293228 [1] NCCL INFO misc/socket.cc:564 -> 3
20: nid005913:292682:293228 [1] NCCL INFO misc/socket.cc:668 -> 3
20: 
20: nid005913:292682:293228 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
20: nid005913:292682:101216 [1] NCCL INFO misc/socket.cc:47 -> 3
20: nid005913:292682:101216 [1] NCCL INFO misc/socket.cc:58 -> 3
20: nid005913:292682:101216 [1] NCCL INFO misc/socket.cc:775 -> 3
20: nid005913:292682:293228 [1] NCCL INFO misc/socket.cc:826 -> 3
20: 
20: nid005913:292682:293228 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
20: 
20: nid005913:292682:293228 [1] proxy.cc:1521 NCCL WARN [Proxy Service 81] Failed to execute operation Close from rank 81, retcode 3
 5: nid005582:196713:3944 [0] NCCL INFO comm 0xaaab12118df0 rank 20 nranks 128 cudaDev 0 busId 901000 - Abort COMPLETE
31: nid005937:256589:65766 [0] NCCL INFO comm 0xaaab2c295d90 rank 124 nranks 128 cudaDev 0 busId 901000 - Abort COMPLETE
 6: nid005584:28286:128099 [1] NCCL INFO comm 0xaaab2173c180 rank 25 nranks 128 cudaDev 1 busId 1901000 - Abort COMPLETE
19: nid005912:12437:113123 [2] NCCL INFO comm 0xaaaaec4bb890 rank 78 nranks 128 cudaDev 2 busId 2901000 - Abort COMPLETE
 7: nid005585:122006:225049 [1] NCCL INFO comm 0xaaab0e87b260 rank 29 nranks 128 cudaDev 1 busId 1901000 - Abort COMPLETE
24: nid005918:92505:194031 [1] NCCL INFO comm 0x4006a564fdf0 rank 97 nranks 128 cudaDev 1 busId 1901000 - Abort COMPLETE
24: nid005918:92505:194045 [1] NCCL INFO misc/socket.cc:47 -> 3
24: nid005918:92505:194045 [1] NCCL INFO misc/socket.cc:550 -> 3
24: nid005918:92505:194045 [1] NCCL INFO misc/socket.cc:573 -> 3
24: nid005918:92505:194045 [1] NCCL INFO misc/socket.cc:621 -> 3
24: nid005918:92505:93088 [1] NCCL INFO misc/socket.cc:47 -> 3
24: nid005918:92505:93088 [1] NCCL INFO misc/socket.cc:752 -> 3
24: nid005918:92505:93088 [1] NCCL INFO misc/socket.cc:428 -> 3
24: nid005918:92505:93088 [1] NCCL INFO misc/socket.cc:564 -> 3
24: nid005918:92505:93088 [1] NCCL INFO misc/socket.cc:668 -> 3
24: 
24: nid005918:92505:93088 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
24: nid005918:92505:194045 [1] NCCL INFO misc/socket.cc:47 -> 3
24: nid005918:92505:194045 [1] NCCL INFO misc/socket.cc:58 -> 3
24: nid005918:92505:194045 [1] NCCL INFO misc/socket.cc:775 -> 3
24: nid005918:92505:93088 [1] NCCL INFO misc/socket.cc:826 -> 3
24: 
24: nid005918:92505:93088 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0
24: 
24: nid005918:92505:93088 [1] proxy.cc:1521 NCCL WARN [Proxy Service 97] Failed to execute operation Close from rank 97, retcode 3
 4: nid005581:264524:72360 [1] NCCL INFO comm 0xaaaad9b8a440 rank 17 nranks 128 cudaDev 1 busId 1901000 - Abort COMPLETE
 9: nid005588:35937:138385 [2] NCCL INFO comm 0xaaaae8a0c3a0 rank 38 nranks 128 cudaDev 2 busId 2901000 - Abort COMPLETE
 3: nid005580:71820:174888 [1] NCCL INFO comm 0xaaaac543b4a0 rank 13 nranks 128 cudaDev 1 busId 1901000 - Abort COMPLETE
20: nid005913:292681:101213 [0] NCCL INFO comm 0xaaab2e755bf0 rank 80 nranks 128 cudaDev 0 busId 901000 - Abort COMPLETE
17: nid005803:180732:283757 [0] NCCL INFO comm 0xaaaad12a2680 rank 68 nranks 128 cudaDev 0 busId 901000 - Abort COMPLETE
 1: nid005576:147557:250812 [0] NCCL INFO comm 0xaaab2078f8e0 rank 4 nranks 128 cudaDev 0 busId 901000 - Abort COMPLETE
 3: nid005580:71819:174886 [0] NCCL INFO comm 0xaaab065e8c10 rank 12 nranks 128 cudaDev 0 busId 901000 - Abort COMPLETE
 7: nid005585:122008:225051 [3] NCCL INFO comm 0xaaaaedf73db0 rank 31 nranks 128 cudaDev 3 busId 3901000 - Abort COMPLETE
30: nid005936:49908:151426 [0] NCCL INFO comm 0xaaaafc2a9750 rank 120 nranks 128 cudaDev 0 busId 901000 - Abort COMPLETE
10: nid005590:110712:213920 [2] NCCL INFO comm 0xaaab104db470 rank 42 nranks 128 cudaDev 2 busId 2901000 - Abort COMPLETE
 1: nid005576:147558:250811 [1] NCCL INFO comm 0xaaaaf8e03070 rank 5 nranks 128 cudaDev 1 busId 1901000 - Abort COMPLETE
25: nid005919:107462:211241 [0] NCCL INFO comm 0xaaab262294f0 rank 100 nranks 128 cudaDev 0 busId 901000 - Abort COMPLETE
30: nid005936:49910:151429 [2] NCCL INFO comm 0xaaaad8cb00f0 rank 122 nranks 128 cudaDev 2 busId 2901000 - Abort COMPLETE
28: nid005929:16031:116166 [1] NCCL INFO comm 0xaaaaf8401170 rank 113 nranks 128 cudaDev 1 busId 1901000 - Abort COMPLETE
12: nid005594:53086:154898 [1] NCCL INFO comm 0xaaaadbafb110 rank 49 nranks 128 cudaDev 1 busId 1901000 - Abort COMPLETE
20: nid005913:292683:101214 [2] NCCL INFO comm 0xaaaaf0f2a8d0 rank 82 nranks 128 cudaDev 2 busId 2901000 - Abort COMPLETE
14: nid005600:217723:26919 [3] NCCL INFO comm 0xaaab2a979520 rank 59 nranks 128 cudaDev 3 busId 3901000 - Abort COMPLETE
22: nid005915:274814:84251 [0] NCCL INFO comm 0xaaaad1683e90 rank 88 nranks 128 cudaDev 0 busId 901000 - Abort COMPLETE
 0: nid005574:69060:171242 [2] NCCL INFO comm 0xaaaaedbf8c70 rank 2 nranks 128 cudaDev 2 busId 2901000 - Abort COMPLETE
11: nid005591:191603:294869 [0] NCCL INFO comm 0xaaaaf7916bf0 rank 44 nranks 128 cudaDev 0 busId 901000 - Abort COMPLETE
19: nid005912:12436:113125 [1] NCCL INFO comm 0xaaaaeb758490 rank 77 nranks 128 cudaDev 1 busId 1901000 - Abort COMPLETE
18: nid005911:38866:140349 [2] NCCL INFO comm 0xaaaafa2a9ac0 rank 74 nranks 128 cudaDev 2 busId 2901000 - Abort COMPLETE
12: nid005594:53085:154893 [0] NCCL INFO comm 0xaaab0e435340 rank 48 nranks 128 cudaDev 0 busId 901000 - Abort COMPLETE
 5: nid005582:196714:3945 [1] NCCL INFO comm 0xaaab201019a0 rank 21 nranks 128 cudaDev 1 busId 1901000 - Abort COMPLETE
 2: nid005577:17424:118766 [2] NCCL INFO comm 0xaaaaec29b7f0 rank 10 nranks 128 cudaDev 2 busId 2901000 - Abort COMPLETE
27: nid005922:80742:183174 [1] NCCL INFO comm 0xaaab00b73210 rank 109 nranks 128 cudaDev 1 busId 1901000 - Abort COMPLETE
26: nid005920:67126:168067 [3] NCCL INFO comm 0xaaab209d4590 rank 107 nranks 128 cudaDev 3 busId 3901000 - Abort COMPLETE
12: nid005594:53088:154899 [3] NCCL INFO comm 0xaaab14e02fb0 rank 51 nranks 128 cudaDev 3 busId 3901000 - Abort COMPLETE
 6: nid005584:28288:128096 [3] NCCL INFO comm 0xaaaaf69fb200 rank 27 nranks 128 cudaDev 3 busId 3901000 - Abort COMPLETE
 2: nid005577:17425:118767 [3] NCCL INFO comm 0xaaab1accc2e0 rank 11 nranks 128 cudaDev 3 busId 3901000 - Abort COMPLETE
17: nid005803:180733:283763 [1] NCCL INFO comm 0xaaab1f57afc0 rank 69 nranks 128 cudaDev 1 busId 1901000 - Abort COMPLETE
27: nid005922:80743:183179 [2] NCCL INFO comm 0xaaab0b1de990 rank 110 nranks 128 cudaDev 2 busId 2901000 - Abort COMPLETE
18: nid005911:38867:140354 [3] NCCL INFO comm 0xaaab31f11170 rank 75 nranks 128 cudaDev 3 busId 3901000 - Abort COMPLETE
 4: nid005581:264526:72361 [3] NCCL INFO comm 0xaaaae8963db0 rank 19 nranks 128 cudaDev 3 busId 3901000 - Abort COMPLETE
22: nid005915:274816:84252 [2] NCCL INFO comm 0xaaaafe3ab720 rank 90 nranks 128 cudaDev 2 busId 2901000 - Abort COMPLETE
21: nid005914:166786:269599 [2] NCCL INFO comm 0xaaab02d82db0 rank 86 nranks 128 cudaDev 2 busId 2901000 - Abort COMPLETE
19: nid005912:12435:113122 [0] NCCL INFO comm 0xaaab04d29d70 rank 76 nranks 128 cudaDev 0 busId 901000 - Abort COMPLETE
26: nid005920:67125:168073 [2] NCCL INFO comm 0xaaaaf841bf30 rank 106 nranks 128 cudaDev 2 busId 2901000 - Abort COMPLETE
16: nid005802:6298:108582 [1] NCCL INFO comm 0xaaab06e0b4f0 rank 65 nranks 128 cudaDev 1 busId 1901000 - Abort COMPLETE
13: nid005595:197885:6879 [2] NCCL INFO comm 0xaaab3c8b15f0 rank 54 nranks 128 cudaDev 2 busId 2901000 - Abort COMPLETE
24: nid005918:92504:194035 [0] NCCL INFO comm 0xaaaaf3895ae0 rank 96 nranks 128 cudaDev 0 busId 901000 - Abort COMPLETE
20: nid005913:292684:101215 [3] NCCL INFO comm 0xaaaae94038c0 rank 83 nranks 128 cudaDev 3 busId 3901000 - Abort COMPLETE
23: nid005917:276887:86834 [2] NCCL INFO comm 0xaaaaf1b2b6f0 rank 94 nranks 128 cudaDev 2 busId 2901000 - Abort COMPLETE
10: nid005590:110713:213922 [3] NCCL INFO comm 0xaaab375e3b60 rank 43 nranks 128 cudaDev 3 busId 3901000 - Abort COMPLETE
15: nid005601:210678:18856 [2] NCCL INFO comm 0xaaab22984300 rank 62 nranks 128 cudaDev 2 busId 2901000 - Abort COMPLETE
 8: nid005586:68927:170715 [1] NCCL INFO comm 0xaaaaec21b350 rank 33 nranks 128 cudaDev 1 busId 1901000 - Abort COMPLETE
21: nid005914:166785:269600 [1] NCCL INFO comm 0xaaaaf1392a50 rank 85 nranks 128 cudaDev 1 busId 1901000 - Abort COMPLETE
27: nid005922:80744:183180 [3] NCCL INFO comm 0xaaaabb7ab7a0 rank 111 nranks 128 cudaDev 3 busId 3901000 - Abort COMPLETE
10: nid005590:110711:213921 [1] NCCL INFO comm 0xaaab10df3460 rank 41 nranks 128 cudaDev 1 busId 1901000 - Abort COMPLETE
 4: nid005581:264525:72362 [2] NCCL INFO comm 0xaaaaf1142f20 rank 18 nranks 128 cudaDev 2 busId 2901000 - Abort COMPLETE
16: nid005802:6300:108583 [3] NCCL INFO comm 0xaaaae402b650 rank 67 nranks 128 cudaDev 3 busId 3901000 - Abort COMPLETE
 8: nid005586:68926:170714 [0] NCCL INFO comm 0xaaab12790160 rank 32 nranks 128 cudaDev 0 busId 901000 - Abort COMPLETE
13: nid005595:197883:6878 [0] NCCL INFO comm 0xaaab1fa69360 rank 52 nranks 128 cudaDev 0 busId 901000 - Abort COMPLETE
15: nid005601:210679:18855 [3] NCCL INFO comm 0xaaab0b2c3130 rank 63 nranks 128 cudaDev 3 busId 3901000 - Abort COMPLETE
21: nid005914:166787:269601 [3] NCCL INFO comm 0xaaaadea21c50 rank 87 nranks 128 cudaDev 3 busId 3901000 - Abort COMPLETE
 3: nid005580:71821:174885 [2] NCCL INFO comm 0xaaaada12b8c0 rank 14 nranks 128 cudaDev 2 busId 2901000 - Abort COMPLETE
14: nid005600:217722:26920 [2] NCCL INFO comm 0xaaaada11bcd0 rank 58 nranks 128 cudaDev 2 busId 2901000 - Abort COMPLETE
 8: nid005586:68928:170713 [2] NCCL INFO comm 0xaaaaf16101a0 rank 34 nranks 128 cudaDev 2 busId 2901000 - Abort COMPLETE
14: nid005600:217721:26921 [1] NCCL INFO comm 0xaaaacda93d30 rank 57 nranks 128 cudaDev 1 busId 1901000 - Abort COMPLETE
28: nid005929:16032:116168 [2] NCCL INFO comm 0xaaab2fba3240 rank 114 nranks 128 cudaDev 2 busId 2901000 - Abort COMPLETE
11: nid005591:191604:294878 [1] NCCL INFO comm 0xaaab196cb950 rank 45 nranks 128 cudaDev 1 busId 1901000 - Abort COMPLETE
 9: nid005588:35935:138386 [0] NCCL INFO comm 0xaaab148fdb70 rank 36 nranks 128 cudaDev 0 busId 901000 - Abort COMPLETE
 2: nid005577:17423:118772 [1] NCCL INFO comm 0xaaaaf479b750 rank 9 nranks 128 cudaDev 1 busId 1901000 - Abort COMPLETE
28: nid005929:16033:116169 [3] NCCL INFO comm 0xaaaade0c3510 rank 115 nranks 128 cudaDev 3 busId 3901000 - Abort COMPLETE
18: nid005911:38865:140348 [1] NCCL INFO comm 0xaaaae2c31590 rank 73 nranks 128 cudaDev 1 busId 1901000 - Abort COMPLETE
 9: nid005588:35938:138387 [3] NCCL INFO comm 0xaaaadbd50910 rank 39 nranks 128 cudaDev 3 busId 3901000 - Abort COMPLETE
22: nid005915:274815:84254 [1] NCCL INFO comm 0xaaab0ea2ac20 rank 89 nranks 128 cudaDev 1 busId 1901000 - Abort COMPLETE
 9: nid005588:35936:138388 [1] NCCL INFO comm 0xaaab298ab220 rank 37 nranks 128 cudaDev 1 busId 1901000 - Abort COMPLETE
 6: nid005584:28287:128097 [2] NCCL INFO comm 0xaaab07a0c730 rank 26 nranks 128 cudaDev 2 busId 2901000 - Abort COMPLETE
30: nid005936:49909:151427 [1] NCCL INFO comm 0xaaaacaa5c1a0 rank 121 nranks 128 cudaDev 1 busId 1901000 - Abort COMPLETE
 5: nid005582:196716:3947 [3] NCCL INFO comm 0xaaab1215f930 rank 23 nranks 128 cudaDev 3 busId 3901000 - Abort COMPLETE
25: nid005919:107463:211243 [1] NCCL INFO comm 0xaaaaf8221890 rank 101 nranks 128 cudaDev 1 busId 1901000 - Abort COMPLETE
 5: nid005582:196715:3946 [2] NCCL INFO comm 0xaaaaeab5be10 rank 22 nranks 128 cudaDev 2 busId 2901000 - Abort COMPLETE
23: nid005917:276888:86835 [3] NCCL INFO comm 0xaaaaf34fa080 rank 95 nranks 128 cudaDev 3 busId 3901000 - Abort COMPLETE
15: nid005601:210677:18857 [1] NCCL INFO comm 0xaaaaee59b4c0 rank 61 nranks 128 cudaDev 1 busId 1901000 - Abort COMPLETE
30: nid005936:49911:151428 [3] NCCL INFO comm 0xaaaad877afc0 rank 123 nranks 128 cudaDev 3 busId 3901000 - Abort COMPLETE
20: nid005913:292682:101216 [1] NCCL INFO comm 0xaaaaf6e99730 rank 81 nranks 128 cudaDev 1 busId 1901000 - Abort COMPLETE
23: nid005917:276886:86833 [1] NCCL INFO comm 0xaaab0f582930 rank 93 nranks 128 cudaDev 1 busId 1901000 - Abort COMPLETE
17: nid005803:180734:283762 [2] NCCL INFO comm 0xaaab0a6d9870 rank 70 nranks 128 cudaDev 2 busId 2901000 - Abort COMPLETE
 3: nid005580:71822:174887 [3] NCCL INFO comm 0xaaab06b93260 rank 15 nranks 128 cudaDev 3 busId 3901000 - Abort COMPLETE
31: nid005937:256592:65772 [3] NCCL INFO comm 0xaaaaedf436d0 rank 127 nranks 128 cudaDev 3 busId 3901000 - Abort COMPLETE
25: nid005919:107464:211247 [2] NCCL INFO comm 0xaaab1682a750 rank 102 nranks 128 cudaDev 2 busId 2901000 - Abort COMPLETE
 1: nid005576:147559:250816 [2] NCCL INFO comm 0xaaab1c4d2400 rank 6 nranks 128 cudaDev 2 busId 2901000 - Abort COMPLETE
31: nid005937:256590:65773 [1] NCCL INFO comm 0xaaab10443c40 rank 125 nranks 128 cudaDev 1 busId 1901000 - Abort COMPLETE
22: nid005915:274817:84253 [3] NCCL INFO comm 0xaaab11483950 rank 91 nranks 128 cudaDev 3 busId 3901000 - Abort COMPLETE
 8: nid005586:68929:170716 [3] NCCL INFO comm 0xaaab0425a760 rank 35 nranks 128 cudaDev 3 busId 3901000 - Abort COMPLETE
24: nid005918:92505:194045 [1] NCCL INFO comm 0xaaab23b3bb80 rank 97 nranks 128 cudaDev 1 busId 1901000 - Abort COMPLETE
15: nid005601:210676:18858 [0] NCCL INFO comm 0xaaab05fd2fb0 rank 60 nranks 128 cudaDev 0 busId 901000 - Abort COMPLETE
 0: [INFO|modeling_utils.py:3580] 2025-06-28 07:10:23,426 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 4 checkpoint shards. You can find where each parameters has been saved in the index located at /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/model.safetensors.index.json.
 0: [INFO|tokenization_utils_base.py:2510] 2025-06-28 07:10:23,429 >> tokenizer config file saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/tokenizer_config.json
 0: [INFO|tokenization_utils_base.py:2519] 2025-06-28 07:10:23,430 >> Special tokens file saved in /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/special_tokens_map.json
 0: ***** train metrics *****
 0:   epoch                    =         1.0
 0:   total_flos               =   4379340GF
 0:   train_loss               =      0.6387
 0:   train_runtime            = 10:05:56.91
 0:   train_samples_per_second =      30.973
 0:   train_steps_per_second   =       0.121
 0: Figure saved at: /capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/training_loss.png
 0: [WARNING|2025-06-28 07:10:23] llamafactory.extras.ploting:148 >> No metric eval_loss to plot.
 0: [WARNING|2025-06-28 07:10:23] llamafactory.extras.ploting:148 >> No metric eval_accuracy to plot.
 0: [INFO|modelcard.py:450] 2025-06-28 07:10:23,806 >> Dropping the following result as it does not have all the necessary fields:
 0: {'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}
 0: nid005574:69058:171278 [0] NCCL INFO misc/socket.cc:47 -> 3
 0: nid005574:69058:171278 [0] NCCL INFO misc/socket.cc:550 -> 3
 0: nid005574:69058:171278 [0] NCCL INFO misc/socket.cc:573 -> 3
 0: nid005574:69058:171278 [0] NCCL INFO misc/socket.cc:621 -> 3
 0: nid005574:69058:78869 [0] NCCL INFO misc/socket.cc:47 -> 3
 0: nid005574:69058:78869 [0] NCCL INFO misc/socket.cc:752 -> 3
 0: nid005574:69058:78869 [0] NCCL INFO misc/socket.cc:428 -> 3
 0: nid005574:69058:78869 [0] NCCL INFO misc/socket.cc:564 -> 3
 0: nid005574:69058:78869 [0] NCCL INFO misc/socket.cc:668 -> 3
 0: 
 0: nid005574:69058:78869 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 0: nid005574:69058:171278 [0] NCCL INFO misc/socket.cc:47 -> 3
 0: nid005574:69058:171278 [0] NCCL INFO misc/socket.cc:58 -> 3
 0: nid005574:69058:171278 [0] NCCL INFO misc/socket.cc:775 -> 3
 0: nid005574:69058:78869 [0] NCCL INFO misc/socket.cc:826 -> 3
 0: 
 0: nid005574:69058:78869 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
 0: 
 0: nid005574:69058:78869 [0] proxy.cc:1521 NCCL WARN [Proxy Service 0] Failed to execute operation Close from rank 0, retcode 3
 0: nid005574:69058:171278 [0] NCCL INFO comm 0x400691650620 rank 0 nranks 128 cudaDev 0 busId 901000 - Abort COMPLETE
 0: nid005574:69058:171279 [0] NCCL INFO misc/socket.cc:47 -> 3
 0: nid005574:69058:171279 [0] NCCL INFO misc/socket.cc:550 -> 3
 0: nid005574:69058:171279 [0] NCCL INFO misc/socket.cc:573 -> 3
 0: nid005574:69058:171279 [0] NCCL INFO misc/socket.cc:621 -> 3
 0: nid005574:69058:69634 [0] NCCL INFO misc/socket.cc:47 -> 3
 0: nid005574:69058:69634 [0] NCCL INFO misc/socket.cc:752 -> 3
 0: nid005574:69058:69634 [0] NCCL INFO misc/socket.cc:428 -> 3
 0: nid005574:69058:69634 [0] NCCL INFO misc/socket.cc:564 -> 3
 0: nid005574:69058:69634 [0] NCCL INFO misc/socket.cc:668 -> 3
 0: 
 0: nid005574:69058:69634 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable
 0: nid005574:69058:171279 [0] NCCL INFO misc/socket.cc:47 -> 3
 0: nid005574:69058:171279 [0] NCCL INFO misc/socket.cc:58 -> 3
 0: nid005574:69058:171279 [0] NCCL INFO misc/socket.cc:775 -> 3
 0: nid005574:69058:69634 [0] NCCL INFO misc/socket.cc:826 -> 3
 0: 
 0: nid005574:69058:69634 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0
 0: 
 0: nid005574:69058:69634 [0] proxy.cc:1521 NCCL WARN [Proxy Service 0] Failed to execute operation Close from rank 0, retcode 3
 0: nid005574:69058:171279 [0] NCCL INFO comm 0xaaab0113f7d0 rank 0 nranks 128 cudaDev 0 busId 901000 - Abort COMPLETE
 0: [1;34mwandb[0m: 
 0: [1;34mwandb[0m: 🚀 View run [33m/capstor/scratch/cscs/ndeperr/checkpoints/qwen2vl_cs_test_full/[0m at: [34mhttps://wandb.ai/krauthammerlab/llamafactory/runs/heonkcdn[0m
 0: [1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250627_210328-heonkcdn/logs[0m
19: Exception ignored in atexit callback: <function dump_compile_times at 0x40015a7439a0>
19: Traceback (most recent call last):
19:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 337, in dump_compile_times
19:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 324, in compile_times
19:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 129, in tabulate
19:   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
19:   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
19:   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
19:   File "<frozen importlib._bootstrap_external>", line 879, in exec_module
19:   File "<frozen importlib._bootstrap_external>", line 1016, in get_code
19:   File "<frozen importlib._bootstrap_external>", line 1073, in get_data
19: OSError: [Errno 107] Transport endpoint is not connected: '/usr/local/lib/python3.10/dist-packages/tabulate/__init__.py'
 9: Exception ignored in atexit callback: <function dump_compile_times at 0x4001839e39a0>
 9: Traceback (most recent call last):
 9:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 337, in dump_compile_times
 9:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 324, in compile_times
 9:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 129, in tabulate
 9:   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
 5: Exception ignored in atexit callback: <function dump_compile_times at 0x4001530839a0>
 5: Traceback (most recent call last):
 5:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 337, in dump_compile_times
 5:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 324, in compile_times
 5:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 129, in tabulate
 5:   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
15: Exception ignored in atexit callback: <function dump_compile_times at 0x40016ed139a0>
15: Traceback (most recent call last):
15:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 337, in dump_compile_times
15:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 324, in compile_times
15:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 129, in tabulate
 9:   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
15:   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
 9:   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
 9:   File "<frozen importlib._bootstrap_external>", line 879, in exec_module
 5:   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
 5:   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
 5:   File "<frozen importlib._bootstrap_external>", line 879, in exec_module
 9:   File "<frozen importlib._bootstrap_external>", line 1016, in get_code
 9:   File "<frozen importlib._bootstrap_external>", line 1073, in get_data
 9: OSError: [Errno 107] Transport endpoint is not connected: '/usr/local/lib/python3.10/dist-packages/tabulate/__init__.py'
15:   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
 5:   File "<frozen importlib._bootstrap_external>", line 1016, in get_code
15:   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
 5:   File "<frozen importlib._bootstrap_external>", line 1073, in get_data
15:   File "<frozen importlib._bootstrap_external>", line 879, in exec_module
 5: OSError: [Errno 107] Transport endpoint is not connected: '/usr/local/lib/python3.10/dist-packages/tabulate/__init__.py'
15:   File "<frozen importlib._bootstrap_external>", line 1016, in get_code
15:   File "<frozen importlib._bootstrap_external>", line 1073, in get_data
15: OSError: [Errno 107] Transport endpoint is not connected: '/usr/local/lib/python3.10/dist-packages/tabulate/__init__.py'
25: Exception ignored in atexit callback: <function dump_compile_times at 0x40016fdf39a0>
25: Traceback (most recent call last):
25:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 337, in dump_compile_times
25:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 324, in compile_times
25:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 129, in tabulate
25:   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
25:   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
25:   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
25:   File "<frozen importlib._bootstrap_external>", line 879, in exec_module
25:   File "<frozen importlib._bootstrap_external>", line 1016, in get_code
25:   File "<frozen importlib._bootstrap_external>", line 1073, in get_data
25: OSError: [Errno 107] Transport endpoint is not connected: '/usr/local/lib/python3.10/dist-packages/tabulate/__init__.py'
23: Exception ignored in atexit callback: <function dump_compile_times at 0x40014b1239a0>
23: Traceback (most recent call last):
23:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 337, in dump_compile_times
23:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 324, in compile_times
23:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 129, in tabulate
23:   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
27: Exception ignored in atexit callback: <function dump_compile_times at 0x4001624739a0>
27: Traceback (most recent call last):
27:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 337, in dump_compile_times
23:   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
27:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 324, in compile_times
27:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 129, in tabulate
23:   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
27:   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
23:   File "<frozen importlib._bootstrap_external>", line 879, in exec_module
23:   File "<frozen importlib._bootstrap_external>", line 1016, in get_code
23:   File "<frozen importlib._bootstrap_external>", line 1073, in get_data
23: OSError: [Errno 107] Transport endpoint is not connected: '/usr/local/lib/python3.10/dist-packages/tabulate/__init__.py'
27:   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
27:   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
27:   File "<frozen importlib._bootstrap_external>", line 879, in exec_module
27:   File "<frozen importlib._bootstrap_external>", line 1016, in get_code
27:   File "<frozen importlib._bootstrap_external>", line 1073, in get_data
27: OSError: [Errno 107] Transport endpoint is not connected: '/usr/local/lib/python3.10/dist-packages/tabulate/__init__.py'
10: Exception ignored in atexit callback: <function dump_compile_times at 0x400164f039a0>
10: Traceback (most recent call last):
10:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 337, in dump_compile_times
10:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 324, in compile_times
10:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 129, in tabulate
10:   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
10:   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
10:   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
10:   File "<frozen importlib._bootstrap_external>", line 879, in exec_module
10:   File "<frozen importlib._bootstrap_external>", line 1016, in get_code
21: Exception ignored in atexit callback: <function dump_compile_times at 0x4001771939a0>
21: Traceback (most recent call last):
21:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 337, in dump_compile_times
10:   File "<frozen importlib._bootstrap_external>", line 1073, in get_data
10: OSError: [Errno 107] Transport endpoint is not connected: '/usr/local/lib/python3.10/dist-packages/tabulate/__init__.py'
21:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 324, in compile_times
21:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 129, in tabulate
21:   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
21:   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
21:   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
21:   File "<frozen importlib._bootstrap_external>", line 879, in exec_module
21:   File "<frozen importlib._bootstrap_external>", line 1016, in get_code
21:   File "<frozen importlib._bootstrap_external>", line 1073, in get_data
21: OSError: [Errno 107] Transport endpoint is not connected: '/usr/local/lib/python3.10/dist-packages/tabulate/__init__.py'
20: Exception ignored in atexit callback: <function dump_compile_times at 0x40015e1b39a0>
20: Traceback (most recent call last):
20:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 337, in dump_compile_times
20:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 324, in compile_times
20:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 129, in tabulate
20:   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
20:   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
20:   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
20:   File "<frozen importlib._bootstrap_external>", line 879, in exec_module
20:   File "<frozen importlib._bootstrap_external>", line 1016, in get_code
20:   File "<frozen importlib._bootstrap_external>", line 1073, in get_data
20: OSError: [Errno 107] Transport endpoint is not connected: '/usr/local/lib/python3.10/dist-packages/tabulate/__init__.py'
 6: Exception ignored in atexit callback: <function dump_compile_times at 0x400158c539a0>
 6: Traceback (most recent call last):
 6:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 337, in dump_compile_times
 6:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 324, in compile_times
 6:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 129, in tabulate
 6:   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
24: Exception ignored in atexit callback: <function dump_compile_times at 0x400187fc39a0>
24: Traceback (most recent call last):
24:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 337, in dump_compile_times
24:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 324, in compile_times
24:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 129, in tabulate
24:   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
 6:   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
 6:   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
24:   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
 6:   File "<frozen importlib._bootstrap_external>", line 879, in exec_module
24:   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
24:   File "<frozen importlib._bootstrap_external>", line 879, in exec_module
 6:   File "<frozen importlib._bootstrap_external>", line 1016, in get_code
24:   File "<frozen importlib._bootstrap_external>", line 1016, in get_code
 6:   File "<frozen importlib._bootstrap_external>", line 1073, in get_data
24:   File "<frozen importlib._bootstrap_external>", line 1073, in get_data
 6: OSError: [Errno 107] Transport endpoint is not connected: '/usr/local/lib/python3.10/dist-packages/tabulate/__init__.py'
24: OSError: [Errno 107] Transport endpoint is not connected: '/usr/local/lib/python3.10/dist-packages/tabulate/__init__.py'
30: Exception ignored in atexit callback: <function dump_compile_times at 0x400160b239a0>
30: Traceback (most recent call last):
30:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 337, in dump_compile_times
30:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 324, in compile_times
30:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 129, in tabulate
30:   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
30:   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
30:   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
30:   File "<frozen importlib._bootstrap_external>", line 879, in exec_module
30:   File "<frozen importlib._bootstrap_external>", line 1016, in get_code
30:   File "<frozen importlib._bootstrap_external>", line 1073, in get_data
30: OSError: [Errno 107] Transport endpoint is not connected: '/usr/local/lib/python3.10/dist-packages/tabulate/__init__.py'
 0: Exception ignored in atexit callback: <function dump_compile_times at 0x4001780039a0>
 0: Traceback (most recent call last):
 0:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 337, in dump_compile_times
 0:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 324, in compile_times
 0:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 129, in tabulate
 0:   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
 0:   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
 0:   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
 0:   File "<frozen importlib._bootstrap_external>", line 879, in exec_module
 0:   File "<frozen importlib._bootstrap_external>", line 1016, in get_code
 0:   File "<frozen importlib._bootstrap_external>", line 1073, in get_data
 0: OSError: [Errno 107] Transport endpoint is not connected: '/usr/local/lib/python3.10/dist-packages/tabulate/__init__.py'
13: Exception ignored in atexit callback: <function dump_compile_times at 0x4001602439a0>
13: Traceback (most recent call last):
13:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 337, in dump_compile_times
13:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 324, in compile_times
13:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 129, in tabulate
13:   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
13:   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
13:   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
13:   File "<frozen importlib._bootstrap_external>", line 879, in exec_module
13:   File "<frozen importlib._bootstrap_external>", line 1016, in get_code
13:   File "<frozen importlib._bootstrap_external>", line 1073, in get_data
13: OSError: [Errno 107] Transport endpoint is not connected: '/usr/local/lib/python3.10/dist-packages/tabulate/__init__.py'
 7: Exception ignored in atexit callback: <function dump_compile_times at 0x400180fb39a0>
 7: Traceback (most recent call last):
 7:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 337, in dump_compile_times
 7:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 324, in compile_times
 7:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 129, in tabulate
 7:   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
 7:   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
 7:   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
 7:   File "<frozen importlib._bootstrap_external>", line 879, in exec_module
 7:   File "<frozen importlib._bootstrap_external>", line 1016, in get_code
 7:   File "<frozen importlib._bootstrap_external>", line 1073, in get_data
 7: OSError: [Errno 107] Transport endpoint is not connected: '/usr/local/lib/python3.10/dist-packages/tabulate/__init__.py'
 1: Exception ignored in atexit callback: <function dump_compile_times at 0x400166a639a0>
 1: Traceback (most recent call last):
 1:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 337, in dump_compile_times
 1:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 324, in compile_times
 1:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 129, in tabulate
 1:   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
 1:   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
 1:   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
 1:   File "<frozen importlib._bootstrap_external>", line 879, in exec_module
17: Exception ignored in atexit callback: <function dump_compile_times at 0x40016ae339a0>
17: Traceback (most recent call last):
17:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 337, in dump_compile_times
17:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 324, in compile_times
 1:   File "<frozen importlib._bootstrap_external>", line 1016, in get_code
17:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 129, in tabulate
 1:   File "<frozen importlib._bootstrap_external>", line 1073, in get_data
17:   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
 1: OSError: [Errno 107] Transport endpoint is not connected: '/usr/local/lib/python3.10/dist-packages/tabulate/__init__.py'
17:   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
17:   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
17:   File "<frozen importlib._bootstrap_external>", line 879, in exec_module
17:   File "<frozen importlib._bootstrap_external>", line 1016, in get_code
17:   File "<frozen importlib._bootstrap_external>", line 1073, in get_data
17: OSError: [Errno 107] Transport endpoint is not connected: '/usr/local/lib/python3.10/dist-packages/tabulate/__init__.py'
28: Exception ignored in atexit callback: <function dump_compile_times at 0x4001560ef9a0>
28: Traceback (most recent call last):
28:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 337, in dump_compile_times
28:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 324, in compile_times
28:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 129, in tabulate
28:   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
28:   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
28:   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
28:   File "<frozen importlib._bootstrap_external>", line 879, in exec_module
28:   File "<frozen importlib._bootstrap_external>", line 1016, in get_code
28:   File "<frozen importlib._bootstrap_external>", line 1073, in get_data
28: OSError: [Errno 107] Transport endpoint is not connected: '/usr/local/lib/python3.10/dist-packages/tabulate/__init__.py'
22: Exception ignored in atexit callback: <function dump_compile_times at 0x4001736739a0>
22: Traceback (most recent call last):
22:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 337, in dump_compile_times
22:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 324, in compile_times
22:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 129, in tabulate
22:   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
 2: Exception ignored in atexit callback: <function dump_compile_times at 0x400181ae39a0>
 2: Traceback (most recent call last):
 2:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 337, in dump_compile_times
 2:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 324, in compile_times
 2:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 129, in tabulate
 2:   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
22:   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
22:   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
22:   File "<frozen importlib._bootstrap_external>", line 879, in exec_module
22:   File "<frozen importlib._bootstrap_external>", line 1016, in get_code
 2:   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
22:   File "<frozen importlib._bootstrap_external>", line 1073, in get_data
22: OSError: [Errno 107] Transport endpoint is not connected: '/usr/local/lib/python3.10/dist-packages/tabulate/__init__.py'
 2:   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
 2:   File "<frozen importlib._bootstrap_external>", line 879, in exec_module
 2:   File "<frozen importlib._bootstrap_external>", line 1016, in get_code
 2:   File "<frozen importlib._bootstrap_external>", line 1073, in get_data
 2: OSError: [Errno 107] Transport endpoint is not connected: '/usr/local/lib/python3.10/dist-packages/tabulate/__init__.py'
26: Exception ignored in atexit callback: <function dump_compile_times at 0x40015de939a0>
26: Traceback (most recent call last):
26:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 337, in dump_compile_times
26:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 324, in compile_times
26:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 129, in tabulate
26:   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
26:   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
26:   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
26:   File "<frozen importlib._bootstrap_external>", line 879, in exec_module
26:   File "<frozen importlib._bootstrap_external>", line 1016, in get_code
26:   File "<frozen importlib._bootstrap_external>", line 1073, in get_data
26: OSError: [Errno 107] Transport endpoint is not connected: '/usr/local/lib/python3.10/dist-packages/tabulate/__init__.py'
16: Exception ignored in atexit callback: <function dump_compile_times at 0x40014f0439a0>
16: Traceback (most recent call last):
16:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 337, in dump_compile_times
16:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 324, in compile_times
16:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 129, in tabulate
16:   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
16:   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
16:   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
16:   File "<frozen importlib._bootstrap_external>", line 879, in exec_module
16:   File "<frozen importlib._bootstrap_external>", line 1016, in get_code
16:   File "<frozen importlib._bootstrap_external>", line 1073, in get_data
16: OSError: [Errno 107] Transport endpoint is not connected: '/usr/local/lib/python3.10/dist-packages/tabulate/__init__.py'
18: Exception ignored in atexit callback: <function dump_compile_times at 0x400188a439a0>
18: Traceback (most recent call last):
18:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 337, in dump_compile_times
18:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 324, in compile_times
18:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 129, in tabulate
18:   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
18:   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
18:   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
18:   File "<frozen importlib._bootstrap_external>", line 879, in exec_module
18:   File "<frozen importlib._bootstrap_external>", line 1016, in get_code
18:   File "<frozen importlib._bootstrap_external>", line 1073, in get_data
18: OSError: [Errno 107] Transport endpoint is not connected: '/usr/local/lib/python3.10/dist-packages/tabulate/__init__.py'
11: Exception ignored in atexit callback: <function dump_compile_times at 0x40017ee6f9a0>
11: Traceback (most recent call last):
11:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 337, in dump_compile_times
11:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 324, in compile_times
11:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 129, in tabulate
11:   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
11:   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
11:   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
11:   File "<frozen importlib._bootstrap_external>", line 879, in exec_module
11:   File "<frozen importlib._bootstrap_external>", line 1016, in get_code
11:   File "<frozen importlib._bootstrap_external>", line 1073, in get_data
11: OSError: [Errno 107] Transport endpoint is not connected: '/usr/local/lib/python3.10/dist-packages/tabulate/__init__.py'
 8: Exception ignored in atexit callback: <function dump_compile_times at 0x40016d3639a0>
 8: Traceback (most recent call last):
 8:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 337, in dump_compile_times
 8:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 324, in compile_times
 8:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 129, in tabulate
 8:   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
 8:   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
 8:   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
 8:   File "<frozen importlib._bootstrap_external>", line 879, in exec_module
 8:   File "<frozen importlib._bootstrap_external>", line 1016, in get_code
 8:   File "<frozen importlib._bootstrap_external>", line 1073, in get_data
 8: OSError: [Errno 107] Transport endpoint is not connected: '/usr/local/lib/python3.10/dist-packages/tabulate/__init__.py'
 4: Exception ignored in atexit callback: <function dump_compile_times at 0x4001735e39a0>
 4: Traceback (most recent call last):
 4:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 337, in dump_compile_times
 4:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 324, in compile_times
 4:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 129, in tabulate
 4:   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
 4:   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
 4:   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
 4:   File "<frozen importlib._bootstrap_external>", line 879, in exec_module
 4:   File "<frozen importlib._bootstrap_external>", line 1016, in get_code
 4:   File "<frozen importlib._bootstrap_external>", line 1073, in get_data
 4: OSError: [Errno 107] Transport endpoint is not connected: '/usr/local/lib/python3.10/dist-packages/tabulate/__init__.py'
 3: Exception ignored in atexit callback: <function dump_compile_times at 0x4001802d39a0>
 3: Traceback (most recent call last):
 3:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 337, in dump_compile_times
 3:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 324, in compile_times
 3:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 129, in tabulate
 3:   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
 3:   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
 3:   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
 3:   File "<frozen importlib._bootstrap_external>", line 879, in exec_module
 3:   File "<frozen importlib._bootstrap_external>", line 1016, in get_code
 3:   File "<frozen importlib._bootstrap_external>", line 1073, in get_data
 3: OSError: [Errno 107] Transport endpoint is not connected: '/usr/local/lib/python3.10/dist-packages/tabulate/__init__.py'
14: Exception ignored in atexit callback: <function dump_compile_times at 0x40016ea139a0>
14: Traceback (most recent call last):
14:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 337, in dump_compile_times
14:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 324, in compile_times
14:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 129, in tabulate
14:   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
14:   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
14:   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
14:   File "<frozen importlib._bootstrap_external>", line 879, in exec_module
14:   File "<frozen importlib._bootstrap_external>", line 1016, in get_code
14:   File "<frozen importlib._bootstrap_external>", line 1073, in get_data
14: OSError: [Errno 107] Transport endpoint is not connected: '/usr/local/lib/python3.10/dist-packages/tabulate/__init__.py'
29: Exception ignored in atexit callback: <function dump_compile_times at 0x4001884039a0>
29: Traceback (most recent call last):
29:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 337, in dump_compile_times
29:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 324, in compile_times
29:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 129, in tabulate
29:   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
29:   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
29:   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
29:   File "<frozen importlib._bootstrap_external>", line 879, in exec_module
29:   File "<frozen importlib._bootstrap_external>", line 1016, in get_code
29:   File "<frozen importlib._bootstrap_external>", line 1073, in get_data
29: OSError: [Errno 107] Transport endpoint is not connected: '/usr/local/lib/python3.10/dist-packages/tabulate/__init__.py'
31: Exception ignored in atexit callback: <function dump_compile_times at 0x40015aaf39a0>
31: Traceback (most recent call last):
31:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 337, in dump_compile_times
31:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 324, in compile_times
31:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 129, in tabulate
31:   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
31:   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
31:   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
31:   File "<frozen importlib._bootstrap_external>", line 879, in exec_module
31:   File "<frozen importlib._bootstrap_external>", line 1016, in get_code
31:   File "<frozen importlib._bootstrap_external>", line 1073, in get_data
31: OSError: [Errno 107] Transport endpoint is not connected: '/usr/local/lib/python3.10/dist-packages/tabulate/__init__.py'
12: Exception ignored in atexit callback: <function dump_compile_times at 0x4001786e39a0>
12: Traceback (most recent call last):
12:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 337, in dump_compile_times
12:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 324, in compile_times
12:   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py", line 129, in tabulate
12:   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
12:   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
12:   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
12:   File "<frozen importlib._bootstrap_external>", line 879, in exec_module
12:   File "<frozen importlib._bootstrap_external>", line 1016, in get_code
12:   File "<frozen importlib._bootstrap_external>", line 1073, in get_data
12: OSError: [Errno 107] Transport endpoint is not connected: '/usr/local/lib/python3.10/dist-packages/tabulate/__init__.py'
